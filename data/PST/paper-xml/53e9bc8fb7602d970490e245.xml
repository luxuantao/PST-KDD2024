<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social Immersive Media Pursuing Best Practices for Multi-user Interactive Camera/projector Exhibits</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Scott</forename><forename type="middle">S</forename><surname>Snibbe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sona Research</orgName>
								<address>
									<addrLine>1073 Howard Street</addrLine>
									<postCode>94103</postCode>
									<settlement>San Francisco</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Hayes</forename><forename type="middle">S</forename><surname>Raffle</surname></persName>
							<email>hayes.raffle@nokia.com</email>
							<affiliation key="aff1">
								<orgName type="department">Nokia Research Center</orgName>
								<address>
									<addrLine>955 Page Mill Road #200</addrLine>
									<postCode>94304</postCode>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Tangible Media Group MIT Media Lab</orgName>
								<address>
									<addrLine>E15-350 20 Ames St</addrLine>
									<postCode>01239</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Social Immersive Media Pursuing Best Practices for Multi-user Interactive Camera/projector Exhibits</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1992BA15FFA6B9B6434D5381E5106140</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Augmented reality</term>
					<term>camera-based interaction</term>
					<term>embodied interaction</term>
					<term>social computing</term>
					<term>computer vision</term>
					<term>animation</term>
					<term>cinema</term>
					<term>learning H.5.1 Multimedia Information Systems: Artificial</term>
					<term>augmented</term>
					<term>and virtual realities</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Based on ten years' experience developing interactive camera/projector systems for public science and culture exhibits, we define a distinct form of augmented reality focused on social interaction: social immersive media. Our work abandons GUI metaphors and builds on the language of cinema, casting users as actors within simulated narrative models. We articulate philosophical goals, design principles, and interaction techniques that create strong emotional responses and social engagement through visceral interaction. We describe approaches to clearly communicate cultural and scientific ideas through the medium. And we demonstrate how practitioners can design interactions that promote specific social behaviors in users.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Over the past three decades, interface designers have developed increasingly more immersive strategies to engage viewers beyond the GUI metaphor in collaboration with interactive graphics systems. Two extremes of this development are virtual reality systems, whose ultimate aim is to artificially generate all channels of sensory input for a single person by placing her in a wholly synthetic world; and what we define here as social immersive media: immersive media that favors interaction in a shared social space using a person's entire body as the "input device," unencumbered by electronics or props. Social immersive media allows users' bodies to control projected interactive graphics and video by collocating a camera or other remote sensors with interactive projected graphics, accompanied by audio and other media. A subset of augmented reality, these experiences are distinguished by unencumbered full-body interaction using invisible sensing infrastructures <ref type="bibr" target="#b23">[26,</ref><ref type="bibr" target="#b24">27,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b17">20]</ref>, rather than wearable technologies, to augment a user's senses <ref type="bibr" target="#b13">[16]</ref>.</p><p>We have created over a hundred social immersive exhibits for science, history and art museums since 1998. Museums incorporate interactive projected exhibits because visceral interaction is particularly suitable for creating enthusiasm and engagement with challenging or unfamiliar topics. Reflecting on the limits of static media, Tom Rockwell, Director of Exhibits for the Exploratorium states: "There are huge areas of science that are too big, too small, too fast or too slow. Snibbe's work lets museum visitors enter these inaccessible realms in new and more immersive ways than ever before." <ref type="bibr" target="#b40">[43]</ref> While single channel video sometimes serves the role of emotionally engaging visitors, museums increasingly include exhibits that physically engage visitors, since research indicates that interaction improves the learning process <ref type="bibr" target="#b36">[39]</ref>. Confucius succinctly summarizes the benefit of interactivity for learning in his well-known 5th century BCE quote: "I hear and I forget. I see and I remember. I do and I understand."</p><p>The public and social context of museums and their increase in civic popularity demands new interaction designs for multiple users that depart from interactive kiosks that were once a mainstay of museums. Social immersive media leverages the public and social nature of the museum context, where pairs, groups or crowds often approach an exhibit at once. Unlike interactive kiosks, social immersive media accommodates the public, social, and informal learning that museums champion. Social immersive media exhibits' success is due in part to meeting young visitors on their own terms with experiences that are emotional, social and physical. These experiences engage people's whole bodies to viscerally "operate" an exhibit, and elicit strong emotional responses: while one would never expect to see a visitor in a science museum jumping up and down and laughing in front of a text panel or movie, it is a common occurrence with social immersive media.</p><p>behavior; and how can we design experiences for the greatest educational and cultural impact?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONTEXT AND RELATED WORK</head><p>Our work builds on camera-based interactive research in interactive arts, tangible interfaces, and interactive games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactive Arts</head><p>Kruger's Videoplace pioneered full-body interaction by combining video cameras with collocated projected animation <ref type="bibr" target="#b23">[26]</ref>. In Videoplace, a user steps into a room with a camera pointed directly at him. Facing the user is a video projection screen upon which his colored silhouette appears as an actor in a simulated two-dimensional virtual world. This playful world includes interactions with animated characters, and remote collaboration with another user of a Videoplace system.</p><p>Since Videoplace, other artists and interaction designers have contributed to computer vision interface research. Rokeby's Very Nervous System is a physical environment that responds to full body movements with a changing musical composition <ref type="bibr" target="#b41">[44]</ref>; Simpson's Shadow Garden <ref type="bibr" target="#b45">[48]</ref> uses shadows to interact with simulated water and butterflies; Utterback's Text Rain <ref type="bibr" target="#b53">[56]</ref> drops words onto users' video images; Rozin's mirrors <ref type="bibr" target="#b42">[45]</ref> create graphical and electromechanical reflections of the user's body; and Levin's Manual Input Sessions <ref type="bibr" target="#b27">[30]</ref> combine real hand shadows with computer graphics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tangible Interfaces</head><p>Wellner's Digital Desk pioneered pointing a camera and projector at the same surface for unencumbered interaction. On a tabletop in front of a user, the system responds to twohanded gestures with simulated graphics, simultaneously integrating real and virtual documents and tools <ref type="bibr" target="#b57">[60]</ref>.</p><p>Like the Digital Desk, Underkoffler's IO Bulb situates camera/projector systems in an intimate physical context to produce interactive surfaces <ref type="bibr" target="#b52">[55]</ref>. For instance, an application for urban planning augments building models with dynamically changing projected light-studies and wind simulations. Underkoffler establishes interaction techniques for camera/projection systems on a small interactive surface using physical props manipulated by one or more users, as well as exploring users' hands themselves as parts of the interface.</p><p>Tangible interface researchers draw on and extend the interface principles of direct manipulation for interactive graphics <ref type="bibr" target="#b19">[22]</ref>: particularly the principles of real-world metaphors for graphical interfaces and rapid incremental feedback to continuous user input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactive Games</head><p>Freeman's computer vision techniques use the whole body as an input device to a videogame with a camera and monitor facing the user <ref type="bibr" target="#b14">[17]</ref>. Sony and Nintendo adapted Freeman's ideas commercially for full-body interactive games with the EyeToy <ref type="bibr">[15]</ref>, which also uses a camera; and with the Wii <ref type="bibr" target="#b34">[37]</ref>, which, instead of a camera, uses an inertial sensor for full-body interaction.</p><p>Exertion Interfaces <ref type="bibr" target="#b33">[36]</ref> use camera/projector systems to create collaborative games that require physical exertion. Although the researchers' focus is improving remote communication via full-body interaction, their findings on how to encourage social interaction, physical exertion and enjoyment are relevant to our work.</p><p>Several systems expand interaction to audiences of thousands. Cinematrix allows an audience to interact with interactive games via red/green colored paddles <ref type="bibr" target="#b7">[9]</ref>; Interactive Audience Participation allows audiences to collaboratively control on-screen video games by leaning and other gestures <ref type="bibr" target="#b29">[32]</ref>; and Squidball tracks the 3D location of large inflated balls over an audience to affect interactive projected games <ref type="bibr" target="#b3">[5]</ref>.</p><p>Commercial examples of camera-based interaction include the Reactrix and Gesturetek systems <ref type="bibr" target="#b38">[41,</ref><ref type="bibr" target="#b16">19]</ref>, which project interactive advertisements onto the floors and walls of public spaces. These commercial systems' interfaces often treat the body as a pointing device, activating discrete interactive projected "buttons" or "sliders". Such designs are based on interaction techniques inherited from GUIs. In contrast, the previously cited examples dynamically respond to the continuous, rather than discrete, gestures of a user or audience. This is also the focus of our work.</p><p>In the following sections, we outline a philosophy and design principles for social immersive media, and review exhibit case studies to illustrate how our interaction designs can direct people's behaviors and experiences (Figure <ref type="figure" target="#fig_0">1</ref>). Our work is substantially influenced by cinema, casting users as actors within a simulated dynamic narrative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SOCIAL IMMERSIVE MEDIA</head><p>"Our body applies itself to space like a hand to an instrument, and when we wish to move about we do not move the body as we move an object. We transport it without instruments as if by magic, since it is ours and because through it we have direct access to space." -Maurice Merleau-Ponty</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Philosophy</head><p>Our approach to media is motivated by the philosophy of phenomenology, pioneered by Edmund Husserl and elaborated by Maurice Merleau-Ponty <ref type="bibr" target="#b30">[33]</ref>. This philosophical view asserts that "reality" only exists as an interplay between consciousness, the perceived world, and our bodies. We each generate a pre-conscious understanding of reality that comes from sensorimotor perception. In simpler terms, we each have a "gut" visceral mode of perception that precedes the analytic, symbolic and linguistic. Language appears to be a higher level and more powerful means to affect the world. Yet we cannot affect our most prized possession, our body, with words at all. We strive to engage users at this phenomenological level by creating interactive media that is first understood by the body and later understood rationally. What does it mean to make media that engages with the visceral part of a person's mind? This question leads to an abandoning of language and its arbitrary signifiers, in favor of non-symbolic and enactive representations of knowledge <ref type="bibr" target="#b4">[6]</ref>.</p><p>Our visceral design philosophy has two important positive side effects. First, these experiences successfully engage users of all ages. Younger viewers 4-10 years old absorb the educational and cultural message only as a secondary experience to their main experience of physical play, since children this age experience the world primarily through full-body interaction <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b36">39]</ref>. In contrast, older users may try to understand what an exhibit is "about" intellectually before physically engaging. The second side effect is that, by focusing on visceral experience and avoiding language, these experiences can be understood across cultures without modification or translation.</p><p>Multi-touch interfaces face the same challenge of socially integrating multiple people's bodies, but in the more intimate arena of a tabletop. In many multi-touch interfaces, multiple users' hands are interpreted merely as a collection of discrete cursors that interface using GUI concepts of pointing, touching, scaling, and mode selection to create a series of individual experiences on the same surface <ref type="bibr" target="#b5">[7]</ref>. In these cases, multi-touch fails to be social and to leverage the principles of direct manipulation that we see both in the physical world and in intuitive computer interfaces <ref type="bibr" target="#b19">[22]</ref>. However, when multi-touch meaningfully responds to the continuously varying gestures of simultaneous multiple users, as in Wilson's work <ref type="bibr" target="#b58">[61]</ref>, then its full social and visceral potential is realized. As in the best multi-touch work, we have developed techniques that abandon discrete interactions in favor of continuous ones, and that focus on visceral interrelationships between multiple users.</p><p>In designing social interactive media, we look as much to the history of cinema as to the history of HCI and interaction design. Cinema is a mature time-based medium for emotional engagement and storytelling. We have found principles of cinema and animation to be overwhelmingly useful in designing for social immersive media <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b26">29]</ref>. However, there is one significant case where this is not true: with rare exception, we have found that the cut, one of the most powerful narrative tools of cinema <ref type="bibr" target="#b1">[3]</ref>, often disengages a user from an immersive experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design Principles</head><p>We have developed the following design principles to reward users' participation by being visceral, responsive and personalized while supporting social interaction. Social immersive media are: • Visceral. The media is experienced physically and emotionally, through whole-body interactions, before it is experienced symbolically or rationally. • Responsive. The media responds immediately, clearly and predictably to users' actions.</p><p>• Continuously variable. The media, like our natural environment, is continuously changing with infinite variability, usually through simulated response to the user's image, silhouette, sound, location, gestures or other uniquely identifiable features. • Socially scalable. Interactions are designed to share with others. Furthermore, interaction, representation, and users' engagement and satisfaction should become richer as more people interact. The unbreakable rule is that if the exhibit fits more than one person, it must work with more than one person. • Socially familiar. The media should augment and reinforce existing collocated social behaviors. • Socially balanced. Interaction equally emphasizes a user's awareness of herself, other users, and the media itself.</p><p>We highlight each principle in the case studies below to demonstrate their application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NARRATIVE MODEL CASE STUDIES</head><p>The following case studies, drawn from a decade of work by Scott Snibbe and Snibbe Interactive, present interaction designs that cast users as actors improvising within a specific temporal structure. We call these temporal structures narrative models, as the choice of model affects the visitor's perception of an exhibit's "story." Each case study demonstrates a narrative model and highlights the implementation of social immersive media design principles.</p><p>Following the case studies we generalize and formalize a set of design strategies (Figure <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiential Narrative: Boundary Functions</head><p>Boundary Functions (Figure <ref type="figure">2</ref>) projects lines between each of the people walking upon its 4m x 4m floor <ref type="bibr" target="#b43">[46]</ref>. These lines demarcate each person's personal space: the space closer to him than to anyone else. As more and more people walk onto this floor, each person's tile changes dynamically to create an overall pattern mathematically described as a Voronoi diagram. The Voronoi pattern relates to phenomena of nature at every scale: from bubbles to the gravitational influence of stars. When people on the floor touch each other, the line between them momentarily disappears, viscerally removing the border between them. Boundary Functions demonstrates the principles of social immersive media. The exhibit is visceral, by responding to a user's whole body movements and each body's relationship to every other nearby body. The exhibit is responsive, updating at 60 Hz and responding to subtle changes in posture. It is continuously variable in that each tile changes continuously to reflect sub-pixel shifts in the unique location and posture of each person standing on the floor. It is socially scalable: the exhibit becomes more visually and socially complex as more people step on its surface. The exhibit is socially familiar by making visible our innate sense of personal space. And the exhibit is socially balanced, in that people view and interact with the projection as frequently as the do with each other. In fact, Boundary Functions often enlivens social interaction and provokes strangers to converse. Through all of these features, we argue that the work is a truly welcoming, yet not sensorially overwhelming social interface that people modulate in and out of their attention to seamlessly blend with natural social interactions in a manner suggested by the principles of ambient media <ref type="bibr" target="#b20">[23]</ref>. In Boundary Functions, social communication flows more easily, achieving the effects of a cocktail party without the alcohol! Beyond visceral play, Boundary Functions contains an educational message and has been included in exhibitions on mathematics, geometry, sociology, psychology, physics and animal behavior. Museum planners have chosen this exhibit not merely for education, but to create enthusiasm for topics that, to many children, seem uninteresting or irrelevant. Finally, Boundary Functions also contains an element of culture and philosophy, appealing to the more sophisticated adult user or art enthusiast. By showing that what we call "personal" space is only defined by our relationship to others and changes without our control, the exhibit suggests a view of reality as interdependent rather than individualistic, provoking thought and conversation.</p><p>Boundary Functions can also be seen as a cultural psychological experiment in the domain of proxemics [2], which studies how closely people stand to each other in different circumstances and cultures. We have observed trends in how people in different countries behave differently in the exhibit. In Germany, people move far from each other. In Japan, people immediately come close to each other and strangers even touch. In New York City, people stand on the floor and do not move-perhaps because space is so scarce in New York and users are more hesitant to give it up. We believe these differences may be attributable to differences in cultural psychology.</p><p>We describe the narrative model of Boundary Functions as experiential. There is a continuous "reality" created by the exhibit whose behavior is predictable, yet continuously variable. The analogue to this experience is a natural environment like a lake, where the responses of the water's ripples are predictable, yet never exactly the same.</p><p>One common critique of Boundary Functions is that there is no response with a single user. In one sense this is a failure to fully satisfy the socially scalable criterion. One argument in favor of this technique is that a work explicitly about social interaction should indeed have no response except in a social environment. Another argument is that, like the power of silence in music, there is a power in nonresponsiveness or a blank screen if used to convey meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Narrative: Deep Walls</head><p>Deep Walls <ref type="bibr" target="#b48">[51]</ref> asks how you can make a movie with your body alone. A naïve approach suggests a photo booth interface, where users watch a countdown to begin; have a set time duration during which they act; and enjoy their performance during a playback period. However, this model makes the user subservient to the media, forcing him to keep track of modes and violating the socially familiar, socially balanced, and responsive criteria of social immersive media. Our approach puts users' bodies in charge of both the performance and its duration.</p><p>In Deep Walls (Figure <ref type="figure" target="#fig_1">3</ref>), users record silhouette movies by performing with their shadows in front of a projection screen. The duration of a performance is determined by the most natural of dramatic gestures: entrances and exits. When users walk in front of the projection screen, the exhibit begins to record their shadows. Upon the last user's exit, the resulting movie loops in one of sixteen cells. If the users danced for five seconds, they see a five second movie.</p><p>If they acted for five minutes, they see a five-minute movie.</p><p>The piece collects the last sixteen movies recorded by visitors in a grid, and the cinematic contents of the grid are limited only by users' own imaginations. Deep Walls is inspired by Alexander's architectural concept of "thick walls" in which architects design walls that can be carved into shelves and cabinets, creating a home that becomes custom-tailored by its inhabitants <ref type="bibr" target="#b0">[1]</ref>. The piece becomes an interactive wall that absorbs and "remembers" the acts taking place before it.</p><p>Users describe surprise and excitement in seeing what others have performed in the piece. People collaborate not only with other actors in front of the projector, but also with movies of previous visitors, in a recursive interaction loop. Despite the simplicity of this interaction technique-where all content comes from the users themselves-users sometimes engage with the piece for hours on end, and return to interact again and again over the course of years.</p><p>Deep Walls is: visceral, using the whole body as interface; responsive by immediately replaying movies at 24-30 Hz; continuously variable by creating a blank canvas to record any duration or type of performance; socially scalable by accommodating group performances without any mode change; socially familiar by echoing the culture of a dance floor; and socially balanced, alternating between engaged performance and animated dialogue as users switch from performer to viewer.</p><p>Deep Walls is structured as an improvised performance narrative: both the users and the piece as a whole are constantly moving forward like an improvisational dance or sketch comedy. The eventual erasure of each episode, far from reducing the energy of the interaction, increases it, as people strive to create a new performance that dramatically "comments" on the prior performances, or that re-enacts a performance that has disappeared.</p><p>A limitation of the performance narrative approach is that it is difficult to impose a more structured narrative because people are focused on their own movements and driven to increasingly energetic and flamboyant acts. Delaying the playback of movies until after users leave the projection creates confusion for many users and, in later versions of this piece, we initiate playback immediately within one of the frames, which dramatically improves users' ability to find their performance and understand the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Episodic Narrative: Three Drops</head><p>Three Drops <ref type="bibr" target="#b49">[52]</ref> allows science museum visitors to become participants in a water simulation at three distinct scales, in order to gain familiarity with differences in behavior at the micro-and nanoscale (Figure <ref type="figure">4</ref>). In the first episode of Three Drops, users take a virtual shower under a simulated showerhead. As people stand in front of the projection the water splashes, puddles, and flows around them. In the next phase of Three Drops, single drops of water drip one at a time onto the visitors. Here, water is magnified a hundredfold. At this scale, the surface tension of water dominates; water behaves so differently that concept of getting "wet" no longer make sense: a drop of water becomes a giant beach ball to catch and throw. Finally, zooming in further, users encounter individual water molecules. These molecules clump together in chains, and stream by from left to right, attracted to users' shadows as if they were positively charged impurities.</p><p>Visitors engage with this exhibit using full body movements: playfully showering, cooperatively bouncing simulated water droplets, and even standing still-a rare sight in a museum filled with children-to make water molecules coalesce around their bodies. Studies describe people engaging with the piece for over two minutes-a long time for science museums-and indicate improved learning compared to briefer interactions with passive video documentation of the same material. We believe these longer interactions are due to the visceral nature of users' interactions: people apply their whole bodies to the exhibit; the responsiveness of the simulation (30 Hz) to users' subtle movements; the continuously variable interactions with physical and molecular simulations rather than prerecorded animations; the socially scalable design that responds to every user in frame, and, with the drop, the transformation into a game of catch with multiple users; socially familiar actions that echo everyday activities; and a socially balanced narrative that alternates between watching the simulation and playing with other users.</p><p>We went through several iterations to arrive at Three Drops' successful final form. We originally planned three side-by-side installations to represent three different scales, however a survey of museums indicated that this amount of space and equipment was impractical, so instead we cut between the three episodes on a single screen. A user study of the first version <ref type="bibr" target="#b44">[47]</ref> found that while people loved interacting with the exhibit, the abrupt cuts from one episode to another (i.e. from human scale shower to 100x scale of water droplets) confused them. People did not understand that they were still interacting with simulated water. This prompted us to add zoom/dissolve transitions between scales in the style of Eames' Powers of <ref type="bibr">10 [14]</ref>, and to add ambient sound to each episode to emphasize that we are still manipulating water. The sound for each episode is, in turn, the sound of a shower, a drip, and, for the molecules, a flowing river. At the end of the molecular episode, the exhibit zooms back out to human scale.</p><p>The narrative model of Three Drops is episodic. The benefit of this model is that we can tell a more complex story, bringing users through narrative episodes that have different imagery and interaction. Unlike a movie, since users arrive continuously, the "narrative" must be designed to remain understandable if entered at any time. The pitfall of this model is losing attention at the transition between episodes, which requires careful design to make a transition brief enough that attention is not lost, or interactive in its own right to maintain engagement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Game Narrative: Fear</head><p>Exhibits that engage users in goal-oriented narratives borrow from interactive video games, a genre that is rapidly moving towards full-body, immersive interaction. Recent studies of Nintendo's Wii <ref type="bibr" target="#b35">[38]</ref>, Sony's EyeToy <ref type="bibr" target="#b25">[28]</ref>, exertion interfaces <ref type="bibr" target="#b33">[36]</ref> and other visceral games <ref type="bibr" target="#b55">[58]</ref> describe the social and physical benefits of integrating immersive media with game content. While turn-taking games include a social element, we feel a central concern of our designs should be to create content that instead allows simultaneous, collocated collaboration and competition among users. We return to our design principle of social scalability: if the exhibit fits more than one user, it should support more than one user. We challenge designers of physically active video games to reach beyond two players alternating in turn, and focus on users' collocated interactions with each other.</p><p>Fear (Figure <ref type="figure">5</ref>) is an interactive exhibit on the science behind feeling scared developed for the Science Museum of Minnesota and the California Science Center. The exhibit creates a projected virtual environment in which users' synthetic shadows appear in a jungle environment via a camera pointed directly at them. In addition to their own shadows, users see the shadows of a pacing jaguar, and fruits dropping from a tree above. The visitors' goal is to collect the fruit without being "eaten." If children move towards the tree when the jaguar is not looking, their shadows appear in grey. Kids collect the tree's fruit in their silhouette arms and hands. When the jaguar turns to look at the players, each player that freezes sees his shadow now in outline, indicating that the jaguar can't see that person, because he is standing still. When someone starts to move while the jaguar looks at him, his shadow turns pink, then red, to indicate that the jaguar has seen him. If he doesn't immediately freeze, the jaguar pounces and attacks the user's shadow, which collapses as the jaguar gnaws, eliciting squeals of mock fear and delight.</p><p>We believe adherence to the principles of social immersive media make this an educationally successful and popular exhibit teaching the freeze or flee response by being visceral; responsive; and continuously variable through incorporating visitors' actual shadows, having a simulated rather than pre-recorded "death," and a continuously variable simulation for collecting fruit. The exhibit is socially scalable by allowing users to pass fruit to each other, and, by letting them compete with each other by pushing one another while the jaguar is looking to cause an attack; the social familiarity of the exhibit comes from its clear children's book-like representation; and it is socially balanced, as kids talk, jostle and laugh together turning their attention from the screen to each other.</p><p>After a player has "died" in the exhibit, his shadow no longer appears on the screen. Unlike the previous exhibits, as a game narrative, Fear has a clear end point and indicates this to the user with the disappearance of his shadow. People then leave the exhibit, which is an important requirement of the museum to avoid bottlenecks or too long of a wait for other visitors.</p><p>In designing this experience, we wanted to prevent users from reaching into the tree branches, or stepping into the jaguar's home behind the tree, because we thought interaction there would be nonsensical and distract from the game goals. By pointing the camera at the users rather than at the screen, we can add an important constraint to this exhibit: we shrink down the visitors' silhouettes and clamp their interaction to a smaller rectangle beneath and to the left of the tree: if a user reaches too high, or walks beyond the tree, his or her projected silhouette elegantly disappears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOWARDS A DESIGN LANGUAGE</head><p>In the case studies, we have shown how our philosophy, design principles, and use of narrative models guide our approach to creating social immersive media. We now summarize specific interaction design techniques and cinematic, environmental, and software design principles, in the service of developing a cohesive design language for this medium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction Design Techniques</head><p>The following interaction design techniques can be applied to engage users and direct their behavior in social immersive media exhibits (Table <ref type="table" target="#tab_0">1</ref>):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of Narrative Model</head><p>We have found the deliberate choice of a narrative model important to shaping an overall social immersive media experience. As discussed in our case studies, the choice of narrative model promotes dwell times varying from minutes to hours. Experiential (Boundary Functions) and performance (Deep Walls) models promote open-ended experiences with long total interaction time; while episodic (Three Drops), and game (Fear) narrative models encourage constrained, shorter experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Continuous vs. Discrete Interaction</head><p>A natural, but misguided approach to social immersive media is to translate the GUI metaphor to social space, where bodies behave like cursors and the screen holds a series of discrete buttons. This approach can be seen in the Eyetoy and Reactrix systems. The problem with this approach is that human social and physical interaction is naturally not discrete, consisting of singular specific events, but rather continuous, comprising continuously varying movements and sounds. Researchers in direct manipulation for screen interfaces have also observed the importance of continuous fine-grained feedback <ref type="bibr" target="#b19">[22]</ref>. In unmediated fullbody interactive experiences, objects should respond continuously and directly to the changing full-body gestures of users, rather than restrict the body to act as a pointer that activates buttons and widgets.</p><p>As mentioned earlier, we have found that discrete changes in temporal sequence-cinematic cuts-can disengage a user from the flow of his interactive experience. The artists of structuralist cinema, who explored cut-less cinema, inspired this response. With multi-minute long single takes, structuralist films can become for the viewer an experience in their own right rather than the depiction of someone else's experience we find in traditional cinema <ref type="bibr" target="#b46">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recording and Replaying</head><p>In the service of creating continuously variable and socially familiar experiences, we often create a recording of the user either as a shadow or a motion recording of her gestures <ref type="bibr" target="#b50">[53]</ref>. Replaying user movements creates a lively alternation between users' recording and observing, and promotes attention. The educational and communicational benefits of high fidelity human movement has also been explored and evaluated in tangible media research <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b15">18,</ref><ref type="bibr" target="#b37">40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shadow and Silhouette</head><p>Using a silhouette or shadow of a user has surprising advantages over a full-color representation. We observe that a picture of a shadow is a quite faithful representation of the shadow (a flat absence of light), while a picture of a person (a 2D variation of color) is substantially dissimilar from our 3D bodies. Thus, paradoxically, a shadow may appear more "real" to the user than a video image. Furthermore, we have observed people's discomfort with a color video representation of themselves, concerned and distracted by their hair, skin, clothes and weight. This may result from self-consciousness or the "uncanny" <ref type="bibr" target="#b31">[34]</ref> likeness of a live video projection of oneself. A shadow representation immediately alleviates these concerns. Finally, users are able to immediately recognize a silhouette of themselves and their friends; however, their shadow remains anonymous to strangers. This ambiguity is not only socially disinhibiting, but it also satisfies laws about privacy, particularly those regulating the capture and display of children's images. Other researchers have also noted the power of shadows in user interfaces <ref type="bibr" target="#b18">[21,</ref><ref type="bibr" target="#b24">27,</ref><ref type="bibr" target="#b32">35,</ref><ref type="bibr" target="#b47">50]</ref>. Our work focuses on the use of silhouettes to create a sense of immediate personalization in an interactive experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Principles of Character Animation</head><p>Like movies, social immersive media are time varying projected experiences. As we design the movement and layout of interface objects, we principally look to the mature time-based medium of cinema, and particularly Thomas and Johnson's seven principles of animation, to create emotionally expressive animated responses <ref type="bibr" target="#b21">[24]</ref>.</p><p>Other user interface professionals have noted the value of adhering to these principles <ref type="bibr" target="#b8">[10]</ref>:</p><p>• Easing in and easing out. Natural actions ease in slowly and come to a halt gradually. Ignoring this principle produces robotic movement and abrupt change. • Overlapping action. Natural movements overlap in time.</p><p>For example, a person does not walk toward a door, halt, then reach for the doorknob. Rather, he simultaneously extends his arm while walking towards the door. • Follow through. Natural actions do not abruptly end, but rather follow through, in the same way a baseball swing does not abruptly end after hitting the ball. • Staging. Since users can only pay attention to one thing at once, the designer must direct users attention to different portions of an experience at different times. This is accomplished by choosing when and where on-screen elements change. In general, there should be one dominant action upon which a user's attention is focused. • Squash and stretch. Real objects deform as they move and interact with the world, either by squashing and stretching as fleshy bodies do, or by motion blur, when captured by a camera. • Exaggeration. Since animated representations are usually simplified compared to the natural world, in order to get the same or greater emotional impact, the designer must exaggerate features, motions, and reactions. • Timing. Human beings are very sensitive to the timing of movements. The same animated poses can be interpreted very differently depending on the time taken to interpolate between them. For example, a head turning in 30ms could mean a character heard a gunshot, while a head turning over 500ms indicates he is feeling pensive. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Environmental considerations</head><p>As discussed by Buxton <ref type="bibr" target="#b6">[8]</ref> and others, scale is a powerful tool to engage different user behaviors. In large-scale museum installations, a principal architectural consideration is to physically situate an exhibit to invite interaction. We have developed spatial guidelines that assure a successful exhibit. First, the exhibit should be in an area of natural human traffic: it is still unnatural for users to expect a video projection to be interactive, so we place the exhibit where they will naturally walk into it. Exhibits should have significant extra space around or in front of the exhibit, so that users can experiment easily and safely with entering and exiting. For that reason, a projection in a cul-de-sac is the least desirable situation. For social immersive media, exhibit lighting should not be too dark, which contradicts what designers might first expect. It is just as important for users to see each other as it is for them to see the exhibit, facilitating social interaction and group learning. To avoid damage, exhibit equipment should be out of reach in the ceiling or well protected by transparent sheet or other materials. Finally, it is essential, and often a legal requirement, to make exhibits accessible to the disabled by incorporating gently sloping ramps to raised areas and wide passageways to accommodate wheelchairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Software Representations</head><p>The choice of software model of the user's body and gestures, and of the graphical response, must change to the most appropriate for a given interface element. Employing software representations of users is inspired by interactive graphics and vision systems for real-time interaction <ref type="bibr" target="#b28">[31,</ref><ref type="bibr" target="#b59">62]</ref> and by non-photorealistic animation techniques <ref type="bibr" target="#b51">[54]</ref>. Both fields have recognized that certain problems are simple to solve in one domain (such as collision detection in a raster image), while complicated or slow to solve using another representation (vector). We transform camera images into simultaneous raster and vector representations, and both discrete and continuous sets. We capture and analyze user gestures as 1d, 2d, 3d and continuity models, and as higher-level abstractions of movement (e.g. hand/head, fast/slow, concave/convex).</p><p>The insight not only to employ multiple representations, but also to change representation on the fly, comes directly from the history of cinema and animation. Starting in the 1920s with pioneers like Emile Cohl, animation and special effects artists have changed cinematic representation from frame-to-frame to the technique most convenient to accomplish an effect; switching from live action to animation, stop-motion, or optical printing <ref type="bibr" target="#b9">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION: DESIGNING SOCIAL BEHAVIOR</head><p>When we first installed Boundary Functions we noticed that, in addition to describing people's social relationships, the piece also changed peoples' ways of relating to each other. In particular, by drawing a line on the floor, users seem to almost universally want to step on that line. Due to the responsiveness of the exhibit, however, the line slips away. This produces a positive feedback loop where, the quicker the line slips away, the harder and harder a user tries to step on that line. Since making this first observation, we have learned to control user behavior by choosing different interaction techniques. Examples include: • Energizing. By providing interactive elements that slip away (such as lines on the floor), or by repeating users' own movements, we can increase the amount of movement and positive emotion in a social situation. • Calming. By rewarding stillness, as in Three Drops' last segment, where molecules coalesce around viewers' shadows, we can induce stillness and mindfulness <ref type="bibr" target="#b56">[59]</ref>. • Competing. By having a finite resource or score that users compete for (such as collecting fruit); a penalty they must avoid (being killed, or halting interactivity); or side-byside comparison of personalized media elements, we can provoke competition. • Performing. By incorporating a representation of the user, particularly an animated one as in Deep Walls, we encourage performance even from people who describe themselves as shy. This is highly dependent upon the ability of the representation to preserve privacy. • Disinhibition. By rewarding gross movements either by responsiveness, or by incorporating a representation of the user, behavior can become increasingly uninhibited. Darrell observed this in his Magic Mirror, which distorts people's faces via computer vision. While observing the direct video-out from the exhibit, the authors noted that people twisted their faces into grotesque forms because the exhibit was already distorting their face <ref type="bibr" target="#b11">[13]</ref>. • Learning. Rather than operating a simulation using remote controllers, users become part of the simulation itself, exploring and internalizing new ideas. Our installations may serve as what Vygotsky refers to as a pivot <ref type="bibr" target="#b54">[57]</ref>: a transitional object that helps users move towards internalizing abstract concepts such as those demonstrated by our four case studies: personal space (Boundary Functions), cinematic recording (Deep Walls), the nanoscale (Three Drops), and the freeze and flee response (Fear). We are encouraged by Crowley's observation that, "the complexity, extended time-scale, and socially-embedded nature of in vivo learning and development are not just annoyances to be controlled by an experimenter; they are fundamental, irreducible characteristics of how learning actually occurs." <ref type="bibr" target="#b10">[12]</ref> • Dwell time. Museums often have very specific requirements for dwell time-in some cases requiring an exhibit to push people along after less than a minute; in others wishing to engage visitors indefinitely. We have discussed some of the techniques for limiting dwell time above: by incorporating a cinematic cut; by removing the visitors' avatar; or by demarking a clear beginning and end. The key techniques for increasing dwell time are to be continuously variable, and to be personalized by users' own movement. Another is by inviting competition with an unlimited cap on the scoring mechanism.</p><p>Designers of social interactive exhibits need to remain aware that they are designing behavior. These social behavior design principles establish a theoretical foundation that combines with our specific interaction design techniques to support the design process. Designers must inevitably complement these principles with the creative processes of intuition, feedback and experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION AND FUTURE WORK</head><p>The design principles outlined in this article serve as a series of best practices for creating highly effective and engaging augmented reality experiences that promote not just individual but social engagement. Our philosophy, approach, and design principles formalize a language for large-scale multi-user exhibits that other designers may build on.</p><p>We have participated in several user studies and are interested in how to evaluate social immersive media both for mechanically measurable criteria such as dwell time, and also for less easily measurable social criteria such as learning. Reeves wrote an excellent summary of the challenges in evaluating this medium and differences between user interface, art, and museum approaches to evaluation <ref type="bibr" target="#b39">[42]</ref>. Integrating the disparate ways of evaluating interactive media across the fields of HCI, psychology and museology is an important challenge for the field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Guidelines for designing users' interactions with social immersive media.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Deep Walls: performance narrative. Figure 2. Boundary Functions: experiential narrative.</figDesc><graphic coords="4,327.18,54.00,216.00,130.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Figure 4. Three Drops: episodic narrative.Figure5. Fear: game narrative.</figDesc><graphic coords="5,65.40,54.00,216.00,131.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Interaction design techniques of the case studies.</head><label>1</label><figDesc></figDesc><table><row><cell>Interaction</cell><cell>Boundary</cell><cell></cell><cell>Three</cell><cell></cell></row><row><cell>Technique</cell><cell>Functions</cell><cell>Deep Walls</cell><cell>Drops</cell><cell>Fear</cell></row><row><cell>Narrative</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="4">Experiential Performance Episodic Game</cell></row><row><cell>Continuous</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Interaction</cell><cell>X</cell><cell>X</cell><cell>X</cell><cell>X</cell></row><row><cell>Record &amp;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Replay</cell><cell></cell><cell>X</cell><cell></cell><cell></cell></row><row><cell>Shadow</cell><cell>/</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Silhouette</cell><cell></cell><cell>X</cell><cell></cell><cell>X</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by the National Science Foundation under grant 0742297. We gratefully acknowledge their support. Case study exhibits were created by Scott Snibbe and Snibbe Interactive and funded in part by the NSF Nanoscale Informal Science Education Network and the NSF Science Museum Exhibit Collaborative (SMEC) in collaboration with the Science Museum of Minnesota, the California Science Center, and the Exploratorium. Chris Bregler of NYU provided important intellectual and material support for this research. Michael Ang and Alan Shimoide engineered Three Drops and Fear.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A Pattern Language</title>
		<author>
			<persName><forename type="first">C</forename><surname>Alexander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Transformation of Cinema, 1907-1915</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bowser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">inTouch: A Medium for Haptic Interpersonal Communication</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dahley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ext. Abstracts CHI &apos;97</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<biblScope unit="page" from="363" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Squidball: An Experiment in Large-Scale Motion Capture and Game Design. Intelligent Technologies for Interactive Entertainment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Towards a Theory of Instruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bruner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Belknap Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multi-Touch Systems that I Have Known and Loved</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large displays in automotive design</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Video Imaging Method and Apparatus for Audience Participation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">US Patent</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">266</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Animation: from cartoons to the user interface</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Before Mickey: The Animated Film</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crafton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>University of Chicago Press</publisher>
			<biblScope unit="page" from="1898" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Crowley</surname></persName>
		</author>
		<title level="m">Designing for Science: Implications From Everyday, Classroom, and Professional Settings</title>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Magic Morphin&apos; Mirror: Person Detection and Tracking</title>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page">964</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Eames</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eames</surname></persName>
		</author>
		<author>
			<persName><surname>Powers Of Ten</surname></persName>
		</author>
		<ptr target="http://www.powersof10.com" />
		<imprint>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Augmented Reality: A New Way of Seeing: Computer scientists are developing systems that can enhance and enrich a user&apos;s view of the world</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<date type="published" when="2002-04">April, 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Computer Vision for Interactive Computer Graphics</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1998-06">May-June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Curlybot: designing a new class of computational toys</title>
		<author>
			<persName><forename type="first">P</forename><surname>Frei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI 2000</title>
		<meeting>CHI 2000</meeting>
		<imprint>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="http://www.gesturetek.com" />
		<title level="m">GestureTek</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Martial Arts in Artificial Reality</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hämäläinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ilmonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Höysniemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nykänen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A. Interactive shadows</title>
		<author>
			<persName><forename type="first">K</forename><surname>Herndon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zeleznik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Conner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName><surname>Van Dam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST 1992</title>
		<meeting>UIST 1992</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Direct Manipulation Interfaces</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hollan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer interaction: A Multidisciplinary Approach</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Baecker</surname></persName>
		</editor>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="468" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ambientROOM: integrating ambient media with architectural space</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;98</title>
		<meeting>CHI &apos;98</meeting>
		<imprint>
			<biblScope unit="page" from="173" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Disney Animation: The Illusion of Life</title>
		<author>
			<persName><forename type="first">F</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Abbeville Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Electronic Baroque: Jerde Cities</title>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">M</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">You Are Here: The Jerde Partnership CHI 2009 ~ New Media Experiences</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2 April 8th. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Videoplace -An Artificial Reality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gionfriddo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinrichen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Environmental Technology Making the Real World Virtual</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krueger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="36" to="37" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Understanding Movement as Input for Interaction. A Study of Two Eyetoy Games</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Larssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Computers as Theatre</title>
		<author>
			<persName><forename type="first">B</forename><surname>Laurel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Addison-Wesley Pub. Comp</publisher>
			<pubPlace>Reading, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sounds from Shapes: Audiovisual Performance with Hand Silhouette Contours in The Manual Input Sessions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIME</title>
		<meeting>NIME</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The ALIVE System: Wireless, Full-Body Interaction with Autonomous Agents</title>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>ACM Multimedia Systems</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Techniques for Interactive Audience Participation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Maynes-Aminzade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICMI</title>
		<meeting>ICMI</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Phenomenology of Perception (Transl. Colin Smith)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Merleau-Ponty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bukimi no tani / The uncanny valley</title>
		<author>
			<persName><forename type="first">Masahiro</forename><forename type="middle">;</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Macdorman</surname></persName>
		</author>
		<author>
			<persName><surname>Minato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T. Trans.). Energy</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="33" to="35" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Transforming Your Shadow into Colorful Visual Media -Multi-Projection of Complementary Colors</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Minomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kakehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proccedings of Advances in Computer Entertainment (ACE)</title>
		<meeting>cedings of Advances in Computer Entertainment (ACE)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Exertion Interfaces: sports over a distance for social bonding and fun</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agamanolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Nintendo</forename><surname>Wii</surname></persName>
		</author>
		<ptr target="http://www.nintendo.com/wii" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Games for physical activity: A Preliminary Examination of the Nintendo Wii</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Symposium on Computer Science in Sport</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The Grasp of Consciousness</title>
		<author>
			<persName><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Topobo: a constructive assembly system with kinetic memory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Raffle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="647" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<ptr target="http://www.reactrix.com" />
		<title level="m">Reactrix</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Research techniques for augmented reality</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reeves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>University of Nottingham</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Rockwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>San</surname></persName>
		</author>
		<author>
			<persName><surname>Exploratorium</surname></persName>
		</author>
		<ptr target="http://www.snibbeinteractive.com" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transforming Mirrors: Subjectivity and Control in Interactive Media</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rokeyby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Critical Issues in Interactive Media</title>
		<imprint>
			<publisher>Simon Penny, SUNY press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Rozin</surname></persName>
		</author>
		<ptr target="http://www.smoothware.com/danny/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cyberarts 98: International Compendium Prix Ars Electronica</title>
		<author>
			<persName><surname>Schenck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ars Electronica</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m">Science Museum of Minnesota, Comparative Report Formative Evaluation Exhibit Package Prototypes</title>
		<imprint>
			<date type="published" when="2007-05">May, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Shadow</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><surname>Garden</surname></persName>
		</author>
		<title level="m">SIGGRAPH 2002 Electronic Art and Animation Catalog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Sitney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Film</forename><surname>Visionary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2d edition</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Shadow Reaching: A New Perspective on Interaction for Large Wall Displays</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shoemaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Booth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
		<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Screen and Shadow</title>
		<author>
			<persName><forename type="first">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName><surname>Body</surname></persName>
		</author>
		<ptr target="http://snibbe.com/scott/SMAC/smac_jan03.html" />
	</analytic>
	<monogr>
		<title level="j">San Francisco Media Arts Council (SMAC) Journal</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Three Drops. ArtNano: New Approaches for Visualizing the Nanoscale</title>
		<author>
			<persName><forename type="first">S</forename><surname>Snibbe</surname></persName>
		</author>
		<ptr target="http://www.nisenet.org/artnano/artists/snibbe/artwork/" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Interactive Dynamic Abstraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NPAR 2000</title>
		<meeting>NPAR 2000<address><addrLine>Annecy, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Non-Photorealistic Computer Graphics: Modeling, Rendering, and Animation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Strothotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schlechtweg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Emancipated Pixels: Real-World Graphics In The Luminous Room</title>
		<author>
			<persName><forename type="first">J</forename><surname>Underkoffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ullmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;99</title>
		<meeting>SIGGRAPH &apos;99</meeting>
		<imprint>
			<biblScope unit="page" from="385" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Text</forename><surname>Utterback</surname></persName>
		</author>
		<author>
			<persName><surname>Rain</surname></persName>
		</author>
		<ptr target="http://www.camilleutterback.com/textrain.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Vygotsky</surname></persName>
		</author>
		<title level="m">Mind in Society: Development of Higher Psychological Processes</title>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Unencumbered Full Body Interaction in Video Games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Warren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>MFADT Program, Parsons School of Design</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The coming age of calm technology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Beyond Calculation: The Next Fifty Years of Computing</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Denning</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Metcalfe</surname></persName>
		</editor>
		<imprint>
			<publisher>Copernicus</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Interacting with paper on the DigitalDesk</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM, v</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="87" to="96" />
			<date type="published" when="1993-07">July 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Bringing physics to the surface</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
		<idno>UIST &apos;08</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="67" to="76" />
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An object-oriented framework for the integration of interactive animation techniques</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zeleznik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1991-07">July 1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
