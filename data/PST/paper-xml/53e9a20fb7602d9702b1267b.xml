<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolutionary Optimization: Pitfalls and Booby Traps</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Weise</surname></persName>
							<email>tweise@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Nature Inspired Computation and Applications Laboratory</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Raymond</forename><surname>Chiong</surname></persName>
							<email>rchiong@swin.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Higher Education</orgName>
								<orgName type="institution">Swinburne University of Technology</orgName>
								<address>
									<addrLine>50 Melba Avenue</addrLine>
									<postCode>3140</postCode>
									<settlement>Lilydale</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Ke</forename><surname>Tang</surname></persName>
							<email>ketang@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Nature Inspired Computation and Applications Laboratory</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evolutionary Optimization: Pitfalls and Booby Traps</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">66166ADA43CC889B78798C55060DC1C0</idno>
					<idno type="DOI">10.1007/s11390-012-1274-4</idno>
					<note type="submission">Received August 31, 2011; revised February 23, 2012.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>evolutionary computing</term>
					<term>problem difficulty</term>
					<term>optimization</term>
					<term>meta-heuristics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Evolutionary computation (EC), a collective name for a range of metaheuristic black-box optimization algorithms, is one of the fastest-growing areas in computer science. Many manuals and "how-to"s on the use of different EC methods as well as a variety of free or commercial software libraries are widely available nowadays. However, when one of these methods is applied to a real-world task, there can be many pitfalls and booby traps lurking -certain aspects of the optimization problem that may lead to unsatisfactory results even if the algorithm appears to be correctly implemented and executed. These include the convergence issues, ruggedness, deceptiveness, and neutrality in the fitness landscape, epistasis, non-separability, noise leading to the need for robustness, as well as dimensionality and scalability issues, among others. In this article, we systematically discuss these related hindrances and present some possible remedies. The goal is to equip practitioners and researchers alike with a clear picture and understanding of what kind of problems can render EC applications unsuccessful and how to avoid them from the start.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Every task with the goal of finding certain configuraticons considered as best in the context of pre-defined criteria can be viewed as an optimization problem. If these problems are formally specified, they can be solved algorithmically either with a dedicated, problemspecific algorithm (such as Dijkstra's algorithm for finding shortest path trees on graphs) or with a more general optimization method. The set of optimization algorithms ranges from mathematical (e.g., using Lagrange Multipliers), numerical (e.g., the Regula Falsi) and simple heuristic (e.g., A * -search) approaches to randomized metaheuristics such as the evolutionary computation (EC) methods. The latter is the focus of this special issue.</p><p>When skimming through the articles in this issue, the reader will find many successful examples and variants of different EC techniques (a detailed overview on EC can be found in [1-3]). However, questions such as these may arise: "Why are there so many different optimization methods?", "Is optimization a complicated process? If so, why?", "What makes an optimization problem difficult to solve?", "Which are the things I should consider when tackling a particular optimization task?", and so on. In this article, our aim is to provide some answers to these questions by discussing a list of fundamental issues that are often seen as "obstacles" in the evolutionary optimization domain.</p><p>To start with, there are many design decisions in implementing EC methods. For effective optimization, it is important to understand not only the problem being studied, but also how that problem interacts with the applied technique(s). Design choices that do not address issues related to convergence, ruggedness, deceptiveness and neutrality in the fitness landscape, epistasis, non-separability, noise, dimensionality, scalability and so on can hamper the effectiveness of the optimization effort. By using clear definitions and illustrations to describe these fundamental issues, we hope to increase awareness among computer scientists and practitioners about how to avoid pitfalls and how EC can be applied more efficiently in real-world environments (see [4]).</p><p>It is necessary to note that this article is not intended to be a tutorial of how to apply a particular EC method, e.g., an evolutionary algorithm (EA), to specific problems <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref> or how to address subject matters such as multi-objectivity <ref type="bibr" target="#b6">[7]</ref> , constraint handling <ref type="bibr" target="#b7">[8]</ref> , or the inclusion of problem-specific knowledge <ref type="bibr" target="#b8">[9]</ref> . For the practical application of EC methods in general and EAs in particular, several books exist <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref> . Instead, our aim is to take a closer look at what features of the problem or search space may decrease the solution quality even if the algorithm implementation appears to be correct and "make sense". Considering these features (and corresponding countermeasures) before developing an EA application (or, at least, when trying to improve its performance) may lead to significantly better results.</p><p>The article is also not a survey on problem complexity. Research studies on this topic are typically carried out from an analytical, mathematical, or theoretical perspective, with the goal to derive approximations for the expected runtime of the problem solvers <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> . These approaches usually focus on benchmark problems or specific classes of optimization tasks, but there is also progress towards developing more general theorems <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> . Here, we do not intend to provide a rigorous theoretical treatment of pitfalls and possible traps in evolutionary optimization, but simply to present a top-down view of some "complications" that may be encountered during the optimization process.</p><p>Our focus is therefore on the design decisions of EC methods. The effectiveness of these design decisions is often influenced by their actual implementation and the associated parameter values used in the optimization process. While parameter values are important for gaining the most benefit from an EC implementation, design decisions such as problem representation, operator design, and population structure are often considered to be even more critical <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> .</p><p>In the remainder of this section, we will introduce the basic terminologies used throughout this article, describe some possible scenarios of the fitness landscape, and briefly discuss complexity theory. After which, we start off with the topic of convergence in Section 2, followed by other issues possibly leading to unsatisfying convergence, such as ruggedness (Section 3), deceptiveness (Section 4), or neutrality (Section 5) in the fitness landscape. One way ruggedness, neutrality, and deceptiveness can be manifested is from the genotypephenotype mapping through a phenomenon known as epistasis (Section 6). Optimization can also become more complicated if solutions that are sought have to be robust against noise (Section 7). A high number of objective functions (Section 8) or a large problem scale (Section 9) increases the runtime requirement while also decreasing the expected quality of the solutions. As shown in the overview provided in Table <ref type="table">1</ref> and Table 2, we discuss not only these interrelated issues in optimization, but also list their corresponding countermeasures (which is actually an m-to-n relation). If an optimization algorithm performs well in the presence of some of the problematic facets, this good performance has to be paid for with a loss of solution quality in a different situation -this fact has been formalized in the No Free Lunch Theorem, which we will discuss in Section 10. Finally, we conclude our review on the various issues with a summary in Section 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Basic Terminologies</head><p>Throughout this article, we will utilize terminologies commonly used in the EC community. Most of these terminologies are inspired from actual biological phenomena. Fig. <ref type="figure">1</ref> shows the spaces involved in a typical evolutionary optimization scenario. The candidate solutions (or phenotypes) x of an optimization problem are elements of the problem space X (also called the solution space). Their utility is evaluated by m 1 objective functions f , which embody the optimization criteria (usually subject to minimization). Together, these functions can be considered as one vector function f : X → R m .</p><p>The objective functions are the only direct source of information available to an EA. It uses this information to decide which candidate solutions are interesting and subsequently combines and/or modifies them in order to sample new points in the problem space. If these two processes can be conducted in a meaningful way, with a certain chance of finding better candidate solutions, the EA can progress towards an optimum -an issue which we discuss in Subsection 3.1 in more detail.</p><p>The search operations (such as the unary mutation or the binary recombination/crossover operation) utilized by the EA often do not work directly on the phenotypes. Instead, they are applied to the elements (the genotypes) of a search space G (the genome). The genotypes are encoded representations of the candidate solutions, which are mapped to the problem space by a genotype-phenotype mapping gpm : G → X. A traditional genetic algorithm (GA), for instance, may utilize a bit-string based encoding as the search space, which can be mapped to a real-valued problem space for function optimization <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref> . In the common case that G = X, i.e., when the variables are processed in their "natural form" <ref type="bibr" target="#b21">[22]</ref> , the genotype-phenotype mapping is the identity mapping.</p><p>EAs manage a population, i.e., a set of individuals (genotype and the corresponding phenotype), which undergo evaluation, selection, and reproduction in each iteration (generation). Before selection, a single scalar fitness value is assigned to each individual. The fitness denotes the priority of an individual for being selected as the parent for offspring in the next generation, i.e., its chance of being chosen as the input to a search operation. This fitness, in general, is determined by a fitness assignment process that usually relies on the objective value(s) of the candidate solution stored in the individual record. It often relates these objective values to those of other candidate solutions in the population, e.g., by computing the individual's (Pareto) rank among them. The fitness may, however, also include additional information <ref type="bibr" target="#b16">[17]</ref> such as diversity metrics (see, e.g., Subsection 2.2.5).</p><p>If only a single objective function is to be optimized (i.e., m = 1 and f = f ), it is sometimes referred to as the fitness function as well, so there exists some ambiguity in the terminology <ref type="bibr" target="#b0">[1]</ref> . From the latter, the term "fitness landscape" is derived, which refers to the visualization of an objective function (and not of the results of a fitness assignment process).</p><p>An illustration of the spaces and sets involved in (evolutionary) optimization is given in Figs. <ref type="figure">1</ref> and<ref type="figure">2</ref>, where the candidate solutions are coordinate pairs decoded from bit strings (the genotypes) via the genotypephenotype mapping. Each element of a genotype that can be modified by a search operation is called a gene. The term building block denotes groups of gene settings that together form an essential element of an individual.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Fitness Landscapes</head><p>As aforementioned, the most important information sources for an optimization algorithm are the m 1 objective functions that rate the quality of possible solutions to an optimization problem. A function is "difficult" from a mathematical perspective in this context if it is not continuous, not differentiable, or if it has multiple maxima and minima. This understanding of difficulty comes very close to the intuitive curves in Fig. <ref type="figure" target="#fig_1">3</ref> where we sketch a number of possible scenarios of the fitness landscape (objective function plots) that we are going to discuss in this article. The objective values in the figure are subject to minimization and the small bubbles represent candidate solutions under investigation. An arrow from one bubble to another means that the second individual is found by applying a search operation to the first one. As can be seen, there are different objective function shapes that can pose to be difficult for an optimization algorithm to proceed its search in this manner. EAs typically work on multiple solutions simultaneously and, as a result, the search space navigation can be difficult to visualize. These graphs thus provide a simplified visualization of the theories discussed rather than an accurate depiction of the EA search process. The structure of EAs enables them to often overcome some local optima, deception, ruggedness, and neutrality.</p><p>From these plots, it may also seem that the shape of the fitness landscape is defined by the objective function only. However, this is not true from the perspective of an EA. Here, the representation, i.e., the choice of search space, search operations, and the genotypephenotype mapping, has a tremendous impact on the effective shape of the fitness landscape <ref type="bibr" target="#b22">[23]</ref> . As outlined in the previous subsection, an EA conducts its search by applying the search operators to genotypes in a search space that are mapped to phenotypes in a problem space which, in turn, are evaluated by the objective functions, as illustrated in Fig. <ref type="figure">2</ref>. The concept of adjacency amongst candidate solutions from the viewpoint of an EA hence depends on the representation used and not on their proximity in the problem space (unless both spaces are the same, that is). In any case, many of the problematic issues which we will discuss in this article are closely related to the choice of representation, as can be seen directly in Tables <ref type="table">1</ref> and<ref type="table">2</ref> and, for instance in Subsections 3.2.4, 4.2.1, 5.1.2, and 6.2.1.</p><p>An important feature of the fitness landscape is that it may have different global and local structures. Fig. <ref type="figure" target="#fig_2">4</ref> illustrates one objective function graph (in the top-left sub graph) from which regions are successively selected and "zoomed in". As can be seen, different sections of this function may exhibit different problematic features or issues. It is thus necessary to remember that the characteristic of an objective function may seem to be dynamic <ref type="bibr" target="#b23">[24]</ref> and change during the course of optimization when the global optimum is approached.</p><p>Before going into the details of difficult fitness landscape features, we would like to briefly review the term difficult itself from the perspectives of both traditional, deterministic, exact algorithms as well as EAs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Problem Hardness</head><p>One of the basic goals of computer science is to find the best algorithm for solving a given class of problems. The performance measures used to rate an algorithm's  efficiency are 1) the time it takes to produce the desired outcome and 2) the storage space it needs for internal data, i.e., its time and space complexity. Both of these can be described as functions of the input size of the algorithm for best, average, and worst-case input situations, which are usually simplified using the big-O family notations.</p><p>The computational complexity of a problem is bounded by the best algorithm known for that problem. It states how much resources are necessary for solving the given problem, or, from the opposite point of view, tells whether the given resources are sufficient for this purpose.</p><p>The set of all problem classes that can be solved on a computer ① within polynomial time is called P. These are problems which are said to be exactly solvable in a feasible way. The set of problem classes that allows solution verification in polynomial time is called N P, which also comprises all the problems from P (P ⊆ N P). A problem A is hard for a complexity class if every other problem in this class can be reduced to it, i.e., if the other problems can be re-formulated so that they can also be solved with an algorithm for A. Exactly solving any N P-hard problem is difficult as it may require super-polynomial, exponential time.</p><p>Solving such a problem to optimality is thus not always possible. When dealing with N P-hard problems that have more than a certain number of variables, we may need to give up some solution quality in order to make the problem computationally tractable. EAs use some random process in their execution. These stochastic algorithms (usually) trade in solution correctness, i.e., the guarantee to find the global optimum, for a lower runtime. In other words, if we apply an EA, we would normally not expect to find the global optima but some reasonably good approximations within feasible time. The limits of this speed-up are discussed in Subsection 9.1.</p><p>While N P-hard problems can be considered to be difficult for any exact method, the question about which problems are GA-or EA-hard arises. This question has been considered from several perspectives <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref> , and the most notable discussions can be found in [15, 29]: Problem instance classes for which the expected worst case first hitting time, i.e., the number of steps required to find a global optimum, of a particular EA has an exponential lower bound are "EA-hard" (for that EA). In [15], two such classes have been proposed for (1 + 1) EAs: 1) wide-gap problems, where there is a very low probability that the EA can escape a local optimum towards a region with higher utility, and 2) long-path problems, where advancement towards better objective values has a reasonably high probability, but the necessary number of such steps is very high. It should be noted that some instance classes of N P-hard problems can be EA-easy <ref type="bibr" target="#b29">[30]</ref> .</p><p>Finding out how hard certain problems are for EAs is an active research area and much work has been devoted to finding the asymptotical complexity of these stochastic algorithms in different scenarios <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Convergence</head><p>An optimization algorithm has converged 1) if it cannot reach new candidate solutions anymore or 2) if it keeps on producing candidate solutions from a "small" ② subset of the problem space <ref type="bibr" target="#b1">[2]</ref> . Optimization ① or Deterministic Turing Machine.</p><p>② According to a suitable metric like the number of modifications or mutations that need to be applied to a given solution in order to leave this subset.</p><p>processes will usually converge at some point in time. In the ideal case, convergence happens towards the global optimum. One of the problems in evolutionary optimization is that it is often not possible to determine whether the best solution currently known is situated on a local or global optimum and thus, if the convergence is acceptable. In other words, it is not clear whether the optimization process can be stopped, whether it should concentrate on refining the current optimum, or whether it should examine other parts of the search space instead. This, of course, can only become cumbersome if there are multiple (local) optima, i.e., the problem is multi-modal <ref type="bibr" target="#b30">[31]</ref> , as depicted in Fig. <ref type="figure" target="#fig_1">3(c</ref>). It is worthwhile to note that convergence often occurs much more quickly in the objective space than in the search and solution spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Issues</head><p>There are at least three basic problems related to the convergence of an optimization algorithm: premature, non-uniform, and domino convergence. The first one is considerably the most important in optimization, but the latter ones may cause a lot of inconveniences too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Premature and Non-Uniform Convergence</head><p>The main goal in EC is to find solutions that are as close to the true global optimum as possible. An optimization process is considered to have prematurely converged to a local optimum if it is no longer able (or extremely unlikely) to explore other parts of the search space than the area currently being examined and there exists another region that contains a superior solution. In case that there is more than one global optimum, then the second goal is to discover as many of them as possible.</p><p>In single-objective optimization, all the global optima have the same objective values but reside on different peaks (or hyperplanes) of the objective function. The presence of multiple such optima is the focus of research on multi-modal optimization <ref type="bibr" target="#b31">[32]</ref> .</p><p>In multi-objective optimization, there are usually many global optima due to the trade-off of the objectives. Take the task of finding a good car, for example, where the criteria speed and fuel consumption would be traded-off. The optimization process should discover both, slower, environmentally friendly cars and fast cars that need more gasoline.</p><p>In some optimization problems, the number of (globally) optimal solutions is too large to provide all of them to the human operator. On these cases, the subset of delivered solutions should well represent the range of possible results, i.e., it should be a uniform sample of all possible optimal features. If only some of the optimal features are presented to the human operator, e.g., only the fast cars in the above example, the convergence is said to be non-uniform <ref type="bibr" target="#b32">[33]</ref> .</p><p>Fig. <ref type="figure" target="#fig_3">5</ref> illustrates these issues on the examples of a (e) Good convergence and bad spread (bi-objective). (f) Good convergence and spread (bi-objective).</p><p>single-objective (Figs. 5(a)∼5(c)) and a bi-objective optimization task (Figs. 5(d)∼5(f)); objectives are subject to minimization. Fig. <ref type="figure" target="#fig_3">5</ref>(a) shows the result of having a very good spread (or diversity) of solutions, but the points are far away from the optima. Fig. <ref type="figure" target="#fig_3">5(d</ref>) is a sketch of the same issue for a bi-objective problem: the discovered solutions are diverse, but distant from the true Pareto front of best trade-offs. Such results are not attractive because they do not provide optimal solutions and we would consider the convergence to be premature in this case. The second examples (Fig. <ref type="figure" target="#fig_3">5</ref>(b) and Fig. <ref type="figure" target="#fig_3">5</ref>(e)) contain solution sets that are very close to the true optima but cover them only partially, so the decision maker could lose important options. Finally, the optimization results depicted in Fig. <ref type="figure" target="#fig_3">5</ref>(c) and Fig. <ref type="figure" target="#fig_3">5</ref>(f) have the two desirable properties of good convergence (i.e., the solutions are very close to optimal) and spread (i.e., the whole trade-off curve between the two objectives is covered).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Domino Convergence</head><p>The phenomenon of domino convergence <ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref> occurs when the candidate solutions have features contributing to significantly different degrees to the total fitness. If these features are encoded separately, they are likely to be treated with different priorities. If, for example, optimization takes place over R and the first element of a solution vector is much more important (from the perspective of the objective function) than the second one, its priority during the optimization process will be much higher too.</p><p>Although this seems to be legit, it can prevent us from finding the global optimum: gene values with strong positive influence on the objective values, for instance, will quickly be adopted by the optimization process (i.e., "converge"). During this time, the values of the genes with smaller contribution are ignored. Their state may remain rather random and hitchhike through the generations in genotypes with good configurations of the more salient genes <ref type="bibr" target="#b35">[36]</ref> . They do not receive evolutionary pressure until the optimal configurations of these genes have been accumulated. This sequential convergence phenomenon is called domino convergence due to its resemblance to a row of falling domino stones <ref type="bibr" target="#b34">[35]</ref> .</p><p>In the worst case, the contributions of the less influential genes may look almost like noise and they are not optimized at all. This leads to premature convergence, since the global optimum which would involve optimal configurations of all genes will not be discovered. Here, restarting the optimization process will not help because it will turn out the same way with very high probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Diversity, Exploration, and Exploitation</head><p>In biology, diversity is referred to as the variety and abundance of organisms at a given place and time <ref type="bibr" target="#b36">[37]</ref> . Genetic diversity is the fuel of evolution and essential for a species' robustness against and adaptivity to environmental changes. In EAs, maintaining a diverse population is very important as well. Losing diversity means approaching a state where all the candidate solutions under investigation become similar to each other. Consequently, no new areas in the search space will be explored and the optimization process will not make any further progress.</p><p>The process of finding points in new areas of the search space that are rather distant from the currently investigated candidate solutions is called exploration <ref type="bibr" target="#b37">[38]</ref> . Exploration increases diversity but often leads to the creation of solutions inferior to those that have already been investigated. However, like in biology, there is a small chance that new genetic material can lead to the discovery of superior traits.</p><p>On the other hand, exploitation is the process of improving and combining the traits of the (best) currently known solutions. Exploitation-based search operations often perform small changes in individuals, producing new, very similar candidate solutions. This would give rise to some steady improvement in fitness for a period of time, but it also reduces diversity in the population since offspring and parents become more and more similar to each other. Another problem with exploitation is that possibly existing better solutions which may be located in distant areas of the problem space will not be discovered.</p><p>Exploration versus exploitation <ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> is therefore the dilemma of deciding which of the two principles to apply and to which degree at a certain stage of optimization. It is sketched in Fig. <ref type="figure" target="#fig_4">6</ref> and can be observed in many areas of optimization. More or less synonymous to exploitation and exploration are the terms intensification and diversification <ref type="bibr" target="#b40">[41]</ref> . Optimization algorithms that favor exploitation over exploration have higher convergence speed but run the risk of not finding the optimal solution and may get stuck at a local optimum. Then again, algorithms that perform excessive exploration may never improve their candidate solutions well enough to find the global optimum or it may take them very long to discover it.</p><p>Almost all components of optimization strategies can either be used for increasing exploitation or in favor of exploration. Exploitation can be achieved by building unary search operations (e.g., mutation operators) that improve an existing solution in small steps. However, mutation in an EA can also be implemented in a way that introduces much randomness into the individuals, effectively turning it into an exploration operator. Selection operations choose a set of the most promising candidate solutions that will be investigated in the next iteration of the algorithm. They can either return a small group of best individuals (exploitation) or a wide range of existing candidate solutions (exploration).</p><p>A good example for the exploration vs exploitation dilemma is the simulated annealing algorithm <ref type="bibr" target="#b41">[42]</ref> . It is often modified to a faster form called simulated quenching, which focuses on exploitation but loses the guaranteed convergence to the optimum <ref type="bibr" target="#b42">[43]</ref> . Another good example is given in [44-45], where it is shown that for some problems, the selection pressure and mutation rate of an EA must be balanced extremely well in order to achieve a polynomial expected runtime. Too much exploitation or exploration may both lead to an exponential expected first hitting time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Countermeasures</head><p>There is no general approach to prevent unsatisfying convergence as this phenomenon may have a variety of different causes. The probability of an optimization process getting caught in a local optimum depends on the characteristics of the problem at hand and the parameter settings as well as on features of the optimization algorithms applied <ref type="bibr" target="#b32">[33]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Balanced Exploration and Exploitation</head><p>Generally, optimization algorithms should employ at least one search operation of explorative character and at least one that is able to exploit good solutions further. There exists a vast body of research on the trade-off between exploration and exploitation that optimization algorithms have to face <ref type="bibr" target="#b37">[38]</ref> , ranging from targeted initialization of the population <ref type="bibr" target="#b45">[46]</ref> , mining data from the optimization process <ref type="bibr" target="#b46">[47]</ref> , to devising specialized population structures <ref type="bibr" target="#b47">[48]</ref> and specialized search operators <ref type="bibr" target="#b48">[49]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Search Operator Design</head><p>A very basic measure to decrease the probability of premature convergence is to make sure that the search operations are complete, i.e., to make sure that they can (theoretically at least) reach every point in the search space from every other point. Then, it is possible to escape arbitrary local optima with non-zero probability.</p><p>A good example for this is the modification to evolutionary programming (EP) introduced in [50]: By replacing the usually applied normally distributed mutations with Lévy distributed ones, the probability to reach distant points in a real-coded search space within a single mutation step is increased and better results could be obtained. In [51], the large impact of search operator design on the solution quality for a combinatorial problem is confirmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Restarting</head><p>A very crude yet sometimes effective measure is to restart the optimization process at randomly or strategically chosen points in time. One example for this is the Greedy Randomized Adaptive Search Procedure (GRASP) <ref type="bibr" target="#b51">[52]</ref> , which continuously restarts the process of creating an initial solution and refines it with local search. Still, this approach is likely to fail in domino convergence situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Low Selection Pressure and/or Larger Population Size</head><p>Generally, the higher the chance that candidate solutions with bad fitness are investigated instead of being discarded in favor of seemingly better ones, the lower the chance of getting stuck at a local optimum. This is the exact idea which distinguishes simulated annealing from hill climbing. It is known that simulated annealing can find the global optimum, whereas simple hill climbers are likely to prematurely converge since they always proceed with the best candidate solution discovered so far.</p><p>In an EA, too, using low selection pressure decreases the chance of premature convergence and can lead to a better approximation of the true global optima. However, such an approach also decreases the speed with which good solutions are exploited and thus, increases the runtime. Also, too low of a selection pressure may cause genetic drift, which we will put into the context of neutrality and evolvability in Subsection 5.1.1.</p><p>Increasing the population size may be useful as well, since larger populations can maintain more individuals and hence, cover many different solutions. This coverage can lead to a lower selection pressure. However, the idea that larger populations will lead to better optimization results does not always hold <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref> . For these reasons, both population-sizing <ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> and selection <ref type="bibr" target="#b13">[14]</ref> are highly-active research areas in the EC community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">Sharing, Niching, and Clearing</head><p>As opposed to increasing the population size, it is also possible to "gain more" from the smaller populations. In order to extend the duration of the evolution in EAs, many methods have been devised for steering the search away from areas which have already been frequently sampled. In steady-state EAs it is common to remove duplicate genotypes from the population <ref type="bibr" target="#b55">[56]</ref> .</p><p>More generally, the exploration capabilities of an optimizer can be improved by integrating density metrics into the fitness assignment process. The most popular of such approaches are sharing and niching <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref> . The strength pareto-type algorithms, which are widely accepted to be highly efficient, use another idea: they adapt the number of individuals a candidate solution dominates as the density measure <ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref> . In the simple convergence prevention method <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref> , candidate solutions with the same objective values are deleted based on a given probability. In the clearing approach <ref type="bibr" target="#b63">[64]</ref> , all individuals are grouped according to their distance in the phenotypic or genotypic space and all but a certain number of individuals from each group receive the worst possible fitness. The efficiency of all these diversity preservation methods strongly depends on the situation -a method suitable for one scenario may cause problems in another <ref type="bibr" target="#b64">[65]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.6">Clustering of Candidate Solutions</head><p>A more explicit method to prevent premature convergence is to cluster the search space or population of an EA. This allows the optimization method to track multiple different basins of attraction at the same time and increases the chance of finding the global optimum in one of them. Particularly in the context of estimation of distribution algorithms (EDAs), various such methods have been proposed <ref type="bibr" target="#b65">[66]</ref><ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.7">Self-Adaptation</head><p>Another approach against premature convergence is to introduce the capability of self-adaptation, allowing the optimization algorithm to change its strategies or to modify its parameters depending on its current state. Such behaviors, however, are often implemented not in order to prevent premature convergence but to speed up the optimization process (which may lead to premature convergence to local optima) <ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.8">Multi-Objectivization</head><p>Recently, the idea of using helper objectives <ref type="bibr" target="#b71">[72]</ref> has emerged. Here, a single-objective problem is transformed into a multi-objective one by adding new objective functions <ref type="bibr" target="#b72">[73]</ref><ref type="bibr" target="#b74">[74]</ref><ref type="bibr" target="#b75">[75]</ref><ref type="bibr" target="#b76">[76]</ref><ref type="bibr" target="#b77">[77]</ref> . In some cases, such changes can speed up the optimization process <ref type="bibr" target="#b78">[78]</ref> . The new objectives are often derived from the main objective by decomposition <ref type="bibr" target="#b78">[78]</ref> or from certain characteristics of the problem <ref type="bibr" target="#b75">[75]</ref> . They are then optimized together with the original objective function with some multi-objective techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Ruggedness</head><p>Optimization algorithms generally depend on some form of trends ③ in the fitness landscape. Ideally, the objective functions would be continuous and exhibit low total variation ④ (as sketched in Fig. <ref type="figure" target="#fig_1">3(b)</ref>), so that the optimizer can track the trend easily. If an objective function is unsteady or goes up and down frequently, it becomes more complicated to find the right directions to proceed during the optimization process (see Fig. <ref type="figure" target="#fig_5">7</ref> and Fig. <ref type="figure" target="#fig_1">3(d)</ref>). The more rugged the function gets, the harder it is to optimize it. In short, one could say ruggedness is multi-modality (see Fig. <ref type="figure" target="#fig_1">3(c</ref>)) plus steep ascends and descends in the fitness landscape. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Issue: Weak Causality</head><p>During an optimization process, new points in the search space are created by the search operations. Generally, we can assume that the inputs of the search operations correspond to points that have previously been selected. Usually, the better or the more promising an individual is, the higher are its chances of being selected for further investigation. Reversing this statement suggests that individuals being passed to the search operations are likely to have good fitness. Since the fitness of a candidate solution depends on its features, it can be assumed that the features of these individuals are promising, too. It should thus be possible for the optimizer to introduce small changes to ③ Using the word "gradient" here would be too restrictive and mathematical.</p><p>④ http://en.wikipedia.org/wiki/Total variation, Nov. 25, 2011.  these features (by modifying the genes encoding them slightly) in order to find out whether they can be improved any further. Normally, such exploitive modifications should also lead to small changes in the objective values and hence, in the fitness of the candidate solution.</p><p>Strong causality (locality) means that small changes in the features of an object also lead to small changes in its behavior <ref type="bibr" target="#b79">[79]</ref><ref type="bibr" target="#b80">[80]</ref> . In fitness landscapes with weak (low) causality, small changes in the candidate solutions often lead to large changes in the objective values. It then becomes harder to decide which region of the problem space to explore and the optimizer cannot find reliable trend information to follow. The lower the causality of an optimization problem, the more rugged its fitness landscape is, which leads to degeneration of the performance of the optimizer <ref type="bibr" target="#b81">[81]</ref> . This does not necessarily mean that it is impossible to find good solutions, but it may take longer time to do so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Countermeasures</head><p>Ruggedness in the fitness landscape is hard to mitigate. In population-based approaches, using large population sizes and applying methods to increase diversity can reduce the influence of ruggedness, but only up to a certain degree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Hybridization with Local Search</head><p>Often, EAs are combined with a local search technique applied to each individual in the population before presenting it to the evolutionary process. Two such common approaches are Lamarckian evolution <ref type="bibr" target="#b82">[82]</ref> (performing a local search on the genotype level) and the Baldwin effect <ref type="bibr" target="#b82">[82]</ref><ref type="bibr" target="#b83">[83]</ref> (local search on the phenotype level). Memetic algorithms <ref type="bibr" target="#b84">[84]</ref><ref type="bibr" target="#b85">[85]</ref><ref type="bibr" target="#b86">[86]</ref> and other hybrid approaches <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b87">[87]</ref><ref type="bibr" target="#b88">[88]</ref> also fall into this category. Since the EA only receives individuals residing in local optima resulting from the local search procedure(s), the fitness landscape may seem to be less rugged from its perspective <ref type="bibr" target="#b89">[89]</ref><ref type="bibr" target="#b90">[90]</ref> . However, local search can also lead to much higher selection pressure and thus swing the pendulum to the problem of premature convergence <ref type="bibr" target="#b2">[3]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Landscape Approximation</head><p>In order to smoothen out a rugged landscape, it can be approximated by parameterizing a function based on the knowledge gathered from previously sampled candidate solutions. The optimization process can then be performed on this smooth approximation, which, in turn, is updated in each step. The goal here is not to find a function that perfectly represents the fitness landscape, but to work on a much smoother function without changing the location of the global optimum. In [90], for example, a k-dimensional quadratic polynomial is used to approximate the fitness function. The second advantage of this idea is that a new candidate solution can be created by directly solving the approximation function analytically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Two-Staged Optimization</head><p>Another approach is to apply a two-staged optimization process <ref type="bibr" target="#b91">[91]</ref> where two different algorithms are applied sequentially. Here, the first optimization method should be an algorithm with strong global optimization abilities, which discovers the most promising area in the search space and is not easily distracted from rugged objectives (e.g., an EDA). Then, an algorithm that is quick to exploit and follow the trend in a landscape, such as differential evolution (DE), is applied to the subspace discovered by the first algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Better Operator and Search Space Design</head><p>Weak causality is often caused, to some extent, by bad design of the solution representation and search operations. We pointed out that exploration operations are important for minimizing the risk of premature convergence. Exploitation operators are equally important for refining the solution quality. In order to apply optimization algorithms in an efficient manner, it is necessary to find representations that allow for iterative modifications with bounded influence on the objective values <ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b92">[92]</ref><ref type="bibr" target="#b93">[93]</ref> , i.e., exploitation. This can eventually lead to better candidate solutions. Fortunately, many problems where their formulation is inspired by a real-world problem share the feature that improved solutions can often be built from other good solutions, i.e., often exhibit strong causality. A comprehensive collection of examples for representations that exhibit this property in real-world application domains can be found in [4].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Deceptiveness</head><p>Especially annoying fitness landscapes show deceptiveness (or deceptivity). The gradient of deceptive objective functions leads the optimization process away from the optima, as illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>(e) as well as Fig. <ref type="figure" target="#fig_6">8</ref>. The term deceptiveness is mainly used for the GA in the context of the Schema Theorem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b94">[94]</ref><ref type="bibr" target="#b95">[95]</ref> . Schemas describe certain areas (hyperplanes) in the search space. If an optimization algorithm has discovered an area with better average fitness compared to other regions, it will focus on exploring this region based on the assumption that highly fit areas are likely to contain the true optimum. Objective functions where this is not the case are considered to be deceptive <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b96">96]</ref> . It is interesting that some problems with the highest level of deceptiveness appear to be easy for GAs <ref type="bibr" target="#b21">[22]</ref> , whereas an increasing amount of deceptiveness generally leads to a steep increase in problem hardness <ref type="bibr" target="#b97">[97]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Issue</head><p>An objective function is deceptive if a greedy local search algorithm would be steered in a direction leading away from all global optima in large parts of the search space. The basic problem caused by deceptiveness is that the information accumulated by an optimizer actually guides it away from the optimum. Search algorithms that strictly follow a path towards improving fitness will not be able to discover the global optimum in this case. In other words, they may perform worse than non-repeating random sampling, a random walk, or an exhaustive enumeration method in terms of the first hitting time of the global optimum. These most primitive search methods sample new candidate solutions without taking into account the utility of the already investigated solutions and hence are not vulnerable to deceptiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Countermeasures</head><p>Solving tasks with deceptive objective functions perfectly involves sampling many individuals with very bad features and fitness. This contradicts the basic ideas of metaheuristics and thus, there are no really efficient countermeasures against high degrees of objective function deceptivity. Using large population sizes, maintaining high diversity (see, e.g., Subsections 2.2.5 and 2.2.6), and utilizing linkage learning (see Subsection 6.2.3) provide at least a small chance of finding good solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Representation Design</head><p>Like weak causality, deceptiveness can also be caused by the design of the representation. Utilizing a more suitable search space, search operations, and genotypephenotype mapping may make an optimization problem much less deceptive. Notice that the representation is a part of the optimization algorithm which produces the inputs of the objective function (see Fig. <ref type="figure">1</ref>). Changing it can change the behavior of the objective function from the perspective of the optimization process significantly. Combining different representations in an EA may lead to better results as shown in [98]. This can be a feasible approach if the nature of the problem is too complex to manually design a non-deceptive representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Niching and Memory</head><p>Applying the diversity increasing methods mentioned in Subsection 2.2.5 (such as niching and the simple convergence prevention method) can delay the convergence of the optimization process and thus, increase the chance to escape from deceptive local optima. Recent studies of particle swarm optimization (PSO) <ref type="bibr" target="#b99">[99]</ref> show that the local memory property of the simulated particles can lead to some niching behavior, which is especially suitable for this purpose as well. Here, the lbest PSO with ring topology discussed in [99] is noteworthy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Preventing Convergence</head><p>Another approach to counteract deceptiveness is to stop the optimization algorithm from converging altogether. If the population of an EA is prevented from collapsing to a certain area of the search space and is always kept "moving", deceptive basins of attraction will be left eventually.</p><p>The Fitness Uniform Selection Scheme <ref type="bibr" target="#b100">[100]</ref><ref type="bibr" target="#b101">[101]</ref> takes the idea a step further. Instead of selecting the most promising candidate solutions, a diverse population with individuals from all fitness levels is maintained in order to avoid getting stuck at a local optimum. To achieve this, in each generation the best and worst individuals (with the smallest and largest fitness, say f s and f l ) in the population are first determined. For each slot in the new population, a random value r uniformly distributed between f s and f l is drawn and the individual with the fitness closest to r will be selected. The selected candidate solutions will be diverse in terms of fitness and the population basically maintains a path of individuals out of the current local optimum.</p><p>If the optimization problem lacks causality and the fitness landscape is very rugged, however, this method may fail. If structurally similar points within a small subset of the search space may possess very different fitness, the search may get trapped within that subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Novelty Search</head><p>In Novelty Search <ref type="bibr" target="#b102">[102]</ref><ref type="bibr" target="#b103">[103]</ref><ref type="bibr" target="#b104">[104]</ref> , the objective function f is completely abandoned. The reason is that, on one hand, in the case of deceptivity f may be misleading and guide the search away from the global optima. On the other hand, it is also not clear whether f would reward stepping stones, i.e., the intermediate solutions between the initially chosen starting points and the global optimum. In many genetic programming (GP) applications <ref type="bibr" target="#b92">[92,</ref><ref type="bibr" target="#b105">105]</ref> , for example, the intermediate steps obtained by modifying a bad program iteratively towards a perfect solution rarely form a sequence of improving fitness and even needle-in-a-haystack situations (see Subsection 5.1.3) are common.</p><p>Novelty Search thus does not employ a traditional fitness measure since it may not help the optimizer to discover and combine building blocks anyway. Instead, an archive of past candidate solutions is kept and updated and selection will choose the individuals that differ the most from the archived ones. As more and more candidate solutions with different behaviors are discovered, chances are that one amongst them is an acceptable solution. This method led to good results in the evolution of virtual creatures <ref type="bibr" target="#b104">[104]</ref> , walking behaviors <ref type="bibr" target="#b103">[103]</ref> , and navigation control <ref type="bibr" target="#b102">[102]</ref><ref type="bibr" target="#b103">[103]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Neutrality</head><p>The outcome of the application of a search operation to an element of the search space is neutral if it yields no change in the objective values <ref type="bibr" target="#b107">[107]</ref><ref type="bibr" target="#b108">[108]</ref> . It is challenging for optimization algorithms if the best candidate solution currently known is situated on a plane of the fitness landscape, i.e., all adjacent candidate solutions have the same objective values. As illustrated in Fig. <ref type="figure" target="#fig_1">3</ref>(f) and Fig. <ref type="figure" target="#fig_7">9</ref>, an optimizer cannot find any gradient information in this case and thus there is no direction as to which way to proceed in a systematic manner. From its point of view, each search operation will yield identical individuals. Furthermore, optimization algorithms usually maintain a list of the best individuals found, which will eventually overflow and require pruning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Issues</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Evolvability</head><p>Another metaphor in EC that has been borrowed from biological systems is evolvability <ref type="bibr" target="#b109">[109]</ref> . In biology, the meaning of this word is twofold <ref type="bibr" target="#b110">[110]</ref> : 1) a biological system is evolvable if it is able to generate heritable, selectable phenotypic variations <ref type="bibr" target="#b111">[111]</ref> ; and 2) a system is evolvable if it can acquire new characteristics via genetic changes that help the organism(s) to survive and to reproduce. In the optimization domain, the evolvability of an optimization process defines how likely the search operations will lead to candidate solutions with new (and eventually, better) objective values. (The direct probability of success <ref type="bibr" target="#b79">[79,</ref><ref type="bibr" target="#b112">112]</ref> , i.e., the chance of search operators producing offspring fitter than their parents, is also sometimes referred to as evolvability in the context of EAs <ref type="bibr" target="#b113">[113]</ref><ref type="bibr" target="#b114">[114]</ref> .) In Subsections 4.2.3, 4.2.4, and (part of) 2.2.5, we already argued that preventing an optimization process from converging, i.e., keeping it in an evolvable state, may enable it to discover better results.</p><p>The link between evolvability and neutrality has been discussed by many researchers <ref type="bibr" target="#b110">[110,</ref><ref type="bibr" target="#b115">115]</ref> . The evolvability of neutral parts of a fitness landscape depends on the optimization algorithm used. For example, the evolvability of hill climbing-like approaches can be especially low, since the search operations cannot directly provide improvements or even changes in fitness. This could then degenerate the optimization process to a random walk, as illustrated in Fig. <ref type="figure" target="#fig_1">3(f)</ref>. Using the ND fitness landscapes, i.e., landscapes with a well-defined degree of neutrality, it has been shown that neutrality may "destroy" useful information such as correlation <ref type="bibr" target="#b116">[116]</ref> .</p><p>Researchers in molecular evolution, on the other hand, found indications that the majority of mutations in biology have no selective influence <ref type="bibr" target="#b117">[117]</ref> , and that the transformation from genotypes to phenotypes is a many-to-one mapping. Neutrality in natural genomes is often considered as beneficial if it concerns only a subset of the properties peculiar to the offspring while allowing meaningful modifications of the others <ref type="bibr" target="#b110">[110,</ref><ref type="bibr" target="#b118">118]</ref> .</p><p>The theory of punctuated equilibria <ref type="bibr" target="#b119">[119]</ref> states that species experience long periods of evolutionary inactivity, which are interrupted by sudden, localized, and rapid phenotypic evolutions. It is assumed that the populations explore networks of neutral genetic changes during the time of stasis until, suddenly, a relevant change in a genotype leads to a better adapted phenotype <ref type="bibr" target="#b120">[120]</ref> and reproduces quickly. Similar phenomena can be observed and have been utilized in EAs <ref type="bibr" target="#b121">[121]</ref><ref type="bibr" target="#b122">[122]</ref> .</p><p>Another example for neutrality in biology is degeneracy: the ability of elements that are structurally different to perform the same function or yield the same output <ref type="bibr" target="#b123">[123]</ref> while also having additional, unique features. Similarly, degeneracy of the properties of candidate solutions introduced by the chosen solution representation in an optimization process can improve its robustness and ability to adapt <ref type="bibr" target="#b124">[124]</ref> .</p><p>The key to differentiating between "good" and "bad" neutrality is its degree in relation to the number of possible solutions maintained by an optimization algorithm. The illustrative example in Fig. <ref type="figure" target="#fig_8">10</ref> shows that a certain amount of neutral reproduction can foster the progress of optimization. In Fig. <ref type="figure" target="#fig_8">10</ref>(a), a scenario of premature convergence is depicted. Fig. <ref type="figure" target="#fig_8">10(b)</ref> shows that a little shot of neutrality could form a bridge to the global optimum. The optimizer now has a chance to escape the smaller peak if it is able to find and follow that bridge, i.e., the evolvability of the system has increased. If this bridge gets wider, as sketched in Fig. <ref type="figure" target="#fig_8">10(c</ref>), the chance of finding the global optimum increases as well. Then again, if the bridge gets too wide (see Fig. <ref type="figure" target="#fig_8">10(d</ref>)), the optimization process may end up in a scenario like Fig. <ref type="figure" target="#fig_1">3(f)</ref> where it cannot find any direction.</p><p>Drift, a term stemming from the area of population genetics, describes the loss of population diversity resulting from the stochastic nature of selection in a finite population (in both nature and EAs) <ref type="bibr" target="#b117">[117,</ref><ref type="bibr" target="#b126">126]</ref> . In neutral parts of the fitness landscape or under low selection pressure, this effect is very likely. A reduction of diversity in the population generally is a negative effect (see Subsection 2.1.3).</p><p>Unlike ruggedness, which is always bad for the performance of optimization algorithms, neutrality has aspects that may further as well as hinder the process of finding good solutions. Generally, we can state that very high degrees of neutrality degenerate optimization processes to random walk. On the other hand, some forms of neutral pathways can improve evolvability and hence increase the chance of finding good solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Redundancy</head><p>Redundancy in the context of EAs is a feature of the genotype-phenotype mapping and it means that multiple genotypes are mapped to the same phenotype, i.e., the genotype-phenotype mapping is not injective. The role of redundancy in the genome is as controversial as that of neutrality <ref type="bibr" target="#b127">[127]</ref> . There exist many accounts of its positive influence on the optimization process. In [128-129], redundant genotype-phenotype mappings are developed using voting (via uniform redundancy as well as a non-trivial approach), Turing machine-like binary instructions, cellular automata, and random Boolean networks (RBNs) <ref type="bibr" target="#b130">[130]</ref> . Except for the trivial voting mechanism based on uniform redundancy, the mappings could induce neutral pathways that were beneficial for exploring the problem space. The RBN approach in particular provided very good results <ref type="bibr" target="#b128">[128]</ref><ref type="bibr" target="#b129">[129]</ref> .</p><p>Redundancy can have a strong impact on the explorability of the problem space. When utilizing a oneto-one mapping, the translation of a slightly modified genotype will always result in a different phenotype. If there exists a many-to-one mapping between genotypes and phenotypes, the search operations can create offspring genotypes that are different from their parents but still translate to the same phenotype. The optimizer may now walk along a path through this "neutral network". If many genotypes along this path can be modified to different offspring, many new candidate solutions can be reached <ref type="bibr" target="#b128">[128]</ref> .</p><p>In the Cartesian GP method, neutrality is explicitly introduced to increase evolvability <ref type="bibr" target="#b131">[131]</ref><ref type="bibr" target="#b132">[132]</ref> . Yet, simple uniform redundancy is not necessarily beneficial for the optimization process and may even slow it down <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b129">129]</ref> . If the population of individuals under investigation contains many isomorphic genotypes, i.e., genotypes that encode the same phenotype, a slow-down may also occur <ref type="bibr" target="#b55">[56]</ref> . If this isomorphism can be identified and removed, a significant speed-up may be gained <ref type="bibr" target="#b55">[56]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Needle-in-a-Haystack Problems</head><p>Besides fully deceptive problems, one of the worst cases found in fitness landscapes is the needle-in-ahaystack problem <ref type="bibr" target="#b26">[27]</ref> (see Fig. <ref type="figure" target="#fig_7">9</ref> and Fig. <ref type="figure" target="#fig_1">3(g)</ref>), where the optimum occurs as an isolated spike in a plane <ref type="bibr" target="#b93">[93,</ref><ref type="bibr" target="#b133">133]</ref> . In other words, this is the combination of small instances of extreme ruggedness with a general lack of information in the fitness landscape. Such problems are extremely hard to solve and the optimization process often will converge prematurely or take very long to find the global optimum. An example of this kind of fitness landscapes is the all-or-nothing property often inherent to GP <ref type="bibr" target="#b92">[92]</ref><ref type="bibr" target="#b93">[93]</ref><ref type="bibr" target="#b134">[134]</ref><ref type="bibr" target="#b135">[135]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Countermeasures</head><p>Extreme cases of neutrality, especially the needlein-a-haystack-type fitness landscapes, are hard to combat. Hybridization of an EA with local search is sometimes recommended in such situations <ref type="bibr" target="#b83">[83]</ref> . Multiobjectivization (see Subsection 8.2.2) and increasing the population size can possibly reduce the impact of neutrality too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Selection Pressure</head><p>Higher selection pressure may be useful if the neutral regions in the fitness landscape still exhibit marginally different objective values that could be exploited to find a way out. It should be noted that fitness proportionate selection methods (e.g., "Roulette-Wheel Selection") may perform very badly in such a case, since they will assign the essentially same reproduction probability to all individuals. Other methods such as Tournament Selection, which only consider the less-then relation instead of absolute fitness values and proportions, will be not affected.</p><p>In the case where all objective values in the neutral regions are identical, a strong emphasis on diversity, possibly achieved by sharing and niching in the problem or search space (see Subsection 2.2.5), may drive the search out of the neutral region faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Representation</head><p>Uniform redundancy in the genome should be avoided as it causes adverse forms of neutrality. In [22,  136], it is stated that the representation of phenotypic traits in the search space should be as short as possible. The length of different genes and the numbers of their alleles should be as small as possible. However, as we discussed earlier, non-trivial representations with a well-adjusted degree of redundancy may exhibit a higher evolvability and thus lead to a more robust and steadily improving optimization process <ref type="bibr" target="#b132">[132]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Memory</head><p>In Tabu Search, recently performed search steps are memorized and not performed again. This allows the algorithm to escape small neutral areas. Similar techniques could be applied in EAs as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Epistasis, Pleiotropy, and Separability</head><p>In biology, epistasis is defined as a form of interaction between different genes <ref type="bibr" target="#b137">[137]</ref> . According to [138], the interaction between genes is epistatic if the effect of altering one gene on the fitness depends on the allelic state of other genes. In (evolutionary) optimization, epistasis is the non-linear interaction of two or more genes of the genotypes as expressed in objective function values after the genotype-phenotype mapping. Two genes interact epistatically if the contribution of one of these genes to the objective value depends on the value of the other gene <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b139">[139]</ref><ref type="bibr" target="#b140">[140]</ref><ref type="bibr" target="#b141">[141]</ref> . Epistasis can also be considered as the higher-order or non-main effects in a model predicting fitness values based on the interactions of the genes from the viewpoint of Design of Experiments <ref type="bibr" target="#b77">[77]</ref> .</p><p>On one hand, we speak of minimal epistasis when every gene is independent of every other gene. Then, the optimization process equals finding the best value for each gene and can most efficiently be carried out by a simple greedy search iteratively applied to each gene while keeping the others constant <ref type="bibr" target="#b139">[139]</ref> . On the other hand, a problem is maximally epistatic when no proper subset of genes is independent of any other gene <ref type="bibr" target="#b141">[141]</ref> . The effects of epistasis are closely related to another biological phenomenon: Pleiotropy, which denotes that a single gene is responsible for multiple phenotypical traits <ref type="bibr" target="#b109">[109]</ref> .</p><p>Like epistasis, pleiotropy can sometimes lead to unexpected improvements but often is harmful for an evolutionary system <ref type="bibr" target="#b114">[114]</ref> . Both phenomena may easily intertwine. If one gene epistatically influences, for instance, two others that are responsible for distinct phenotypical traits, it has both epistatic and pleiotropic effects. We will therefore consider pleiotropy and epistasis together, and when discussing the effects of the latter, we also implicitly refer to the former.</p><p>In Fig. <ref type="figure" target="#fig_9">11</ref>, we illustrate a fictional dinosaur along with a snippet of its fictional genome consisting of four genes. Gene 1 influences the color of the creature and is neither pleiotropic nor has any epistatic relations. Gene 2, however, exhibits pleiotropy since it determines the length of the hind legs and forelegs. At the same time, it is epistatically connected with gene 3, which also influences the length of the forelegs -maybe preventing them from looking exactly like the hind legs. The fourth gene is again pleiotropic by determining the shape of the bone armors on the top of the dinosaur's skull and on its snout.</p><p>In the area of optimization over continuous problem spaces, epistasis and pleiotropy are closely related to the term separability. Separability is a feature of the objective function(s) of an optimization problem <ref type="bibr" target="#b142">[142]</ref> . A function of X variables is separable if it can be rewritten as a sum of X functions of just one variable <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b143">143]</ref> . Hence, the genes involved in the problem can be optimized independently of each other, i.e., are minimally epistatic, and the problem is said to be separable. A function f : R X → R is separable <ref type="bibr" target="#b144">[144]</ref> if and only if the condition given in ( <ref type="formula">1</ref> Otherwise, f (x) is called a non-separable function. If a function f (x) is separable, the parameters x 1 , . . . , x X forming the candidate solution x are called independent. A separable problem is decomposable. A function f : R X → R is k-non-separable if at most k of its parameters x i are not independent. A non-separable function f (x) is called fully non-separable if any two of its parameters x i are not independent. The higher the degree of non-separability, the harder a function will usually become for optimization <ref type="bibr" target="#b144">[144]</ref><ref type="bibr" target="#b145">[145]</ref> . Often, the term non-separable is used in the sense of fully nonseparable. In between separable and fully non-separable problems, a variety of partially separable problems exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The Issue</head><p>As sketched in Fig. <ref type="figure" target="#fig_0">12</ref>, epistasis has a strong influence on many of the previously discussed issues. If one variable (gene) of a point (genotype) in the search space can "turn off" or affect the expression of other genes, modifying this gene will lead to a large change in the features of the phenotype. Hence, the causality will be weakened and ruggedness ensues in the fitness landscape. It also becomes harder to define search operations with an exploitive character. Moreover, subsequent changes to the "deactivated" genes may have no influence on the phenotype at all, which would then increase the degree of neutrality in the search space. Representations and genotypes with low pleiotropy often lead to better and more robust solutions <ref type="bibr" target="#b146">[146]</ref> . Fig. <ref type="figure" target="#fig_0">12</ref>. Influence of epistasis on the fitness landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Countermeasures</head><p>Epistasis is a root cause for multiple related issues in optimization tasks. The symptoms of epistasis can be mitigated with the same methods that increase the chance of finding good solutions in the presence of ruggedness or neutrality. Other methods are discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Choice of the Representation</head><p>Epistasis itself is again an issue resulting from the choice of the search space structure, the search operations, the genotype-phenotype mapping, and the structure of the problem space. Avoiding epistatic effects should be a major concern during the design phase. Choosing the solution space and the genotypephenotype mapping correctly can lead to great improvements in the quality of the solutions produced by the optimization process <ref type="bibr" target="#b92">[92]</ref><ref type="bibr" target="#b93">[93]</ref><ref type="bibr" target="#b135">135,</ref><ref type="bibr" target="#b147">147]</ref> . Introducing specialized search operations can achieve similar effects <ref type="bibr" target="#b148">[148]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Adjusting Selection Pressure</head><p>Using larger populations and favoring explorative search operations could be helpful in epistatic problems, since these are ways to increase diversity. On the other hand, applying 1) higher selection pressure, i.e., increasing the chance of picking the best candidate solutions for further investigation instead of the weaker ones, and 2) extinctive selection, i.e., only working with the newest produced set of candidate solutions while discarding their parents, can also increase the reliability of an optimizer to find good solutions <ref type="bibr" target="#b148">[148]</ref> . These two concepts are slightly contradicting, so careful adjustment of the algorithm settings appears to be vital in epistatic environments. Higher selection pressure also leads to earlier convergence <ref type="bibr" target="#b148">[148]</ref> , a fact we already discussed in Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Linkage and Interaction Learning</head><p>According to [149], linkage is "the tendency for alleles of different genes to be passed together from one generation to the next" in genetics. This usually indicates that these genes are closely located in the same chromosome. In the context of EAs, this notation is not useful since identifying spatially close elements inside the genotypes is trivial. Instead, we are interested in different genes that have a joint effect on the fitness <ref type="bibr" target="#b150">[150]</ref> .</p><p>Identifying these linked genes, i.e., learning their epistatic interaction, is very helpful for the optimization process. Such knowledge can be used to protect building blocks from being destroyed by the search operations (such as crossover in GAs), for instance. Finding approaches for linkage learning for binary <ref type="bibr" target="#b150">[150]</ref><ref type="bibr" target="#b151">[151]</ref> and real-valued <ref type="bibr" target="#b152">[152]</ref> genomes has become a popular research area. Two important methods derived from this research are the messy GA (mGA) <ref type="bibr" target="#b153">[153]</ref> and the Bayesian Optimization Algorithm (BOA) <ref type="bibr" target="#b154">[154]</ref> .</p><p>Module acquisition <ref type="bibr" target="#b155">[155]</ref> may be considered as such an effort too. Here, an additional reproduction operation can group connected components of a genotype together into an atomic group, which becomes immune to modification by other reproduction operators. In GP, this is similar to adding a new automatically defined function that represents a subtree of the program individual.</p><p>Especially promising in numerical optimization is the Variable Interaction Learning (VIL) technique <ref type="bibr" target="#b156">[156]</ref> that can detect which genes have non-separable relations. These are then grouped together and the resulting division of the genotypes can be optimized separately in a cooperative-coevolution approach <ref type="bibr" target="#b156">[156]</ref><ref type="bibr" target="#b157">[157]</ref> , see Subsection 9.2.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Noise and Robustness</head><p>Noise is an undesired and unpredictable random disturbance to a signal. In the context of optimization, three types of noise can be distinguished <ref type="bibr" target="#b158">[158]</ref> . The first form is noise in the objective functions or in the training data used <ref type="bibr" target="#b159">[159]</ref> . In many applications of machine learning or optimization where a model for a given system is to be learned, data samples including the input of the system and its measured response are used for training. Besides inexactnesses and fluctuations in the input data of the optimization process, perturbations are also likely to occur during the application of its results, which takes place after the optimization has finished. This category subsumes the other two types of noise: perturbations that may arise from inaccuracies in the process of realizing the solutions and environmentally induced perturbations during the applications of the products. The effects of noise in optimization have been the subject of many studies <ref type="bibr" target="#b160">[160]</ref><ref type="bibr" target="#b161">[161]</ref> . Many optimization algorithms and theoretical results have been proposed to deal with noise. Some of them are, for instance, specialized GAs <ref type="bibr" target="#b162">[162]</ref><ref type="bibr" target="#b163">[163]</ref> , Evolution Strategics (ESs) <ref type="bibr" target="#b164">[164]</ref><ref type="bibr" target="#b165">[165]</ref> , and PSO algorithms <ref type="bibr" target="#b166">[166]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Issue: Need for Robustness</head><p>The goal of optimization is to find the global optima of the objective functions. While this is fully true from a theoretical point of view, it may not suffice in practice. Optimization problems are normally used to find good parameters or designs for components or plans to be put into action by human beings or machines. As we have discussed, there will always be noise and perturbations in practical realizations of the results of optimization. Designs, plans, and procedures must address the fact that no process is perfect. As a result, practitioners may desire a relatively good and yet predictable solution that can tolerate a certain degree of imprecision during its application in lieu of a less predictable but globally optimal solution.</p><p>A system in engineering or biology is robust if it is able to function properly in the face of genetic or environmental perturbations <ref type="bibr" target="#b109">[109]</ref> . A local optimum (or even a non-optimal element) for which slight disturbances only lead to gentle performance degenerations is usually favored over a global optimum located in a highly rugged area of the fitness landscape <ref type="bibr" target="#b167">[167]</ref> . In other words, local optima in regions of the fitness landscape with strong causality are sometimes better than global optima with weak causality. Of course, the level of this acceptability is application-dependent. Fig. <ref type="figure" target="#fig_11">13</ref> illustrates the issue of local optima which are robust vs global optima which are not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Countermeasures</head><p>For the special case where the solution space is a real vector space, several approaches for dealing with the need for robustness have been developed. Inspired by Taguchi methods <ref type="bibr" target="#b168">[168]</ref> , possible disturbances are represented by a vector δ in the method suggested in [169]. The objective function can be rewritten as f (x, δ) <ref type="bibr" target="#b170">[170]</ref> if δ follows a stochastic distribution with known (measured, approximated) parameters. The probability distribution of δ then can be sampled a number of t times and the mean values of f (x, δ) are used during the optimization process <ref type="bibr" target="#b170">[170]</ref> .</p><p>This method turns the optimization algorithm into something like a maximum likelihood estimator and also corresponds to using multiple, different training scenarios during the objective function evaluation. By adding random noise and artificial perturbations to the training cases, the chance of obtaining robust solutions that are stable when applied or realized under noisy conditions can be higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Dimensionality</head><p>Many engineering or scheduling problems involve multiple, often conflicting, optimization criteria. In logistic planning tasks <ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref> , for instance, the goals are 1) to fulfill as many transportation orders within their respective time windows as possible, 2) at the lowest possible cost, and 3) with as little CO 2 emissions as possible. We refer to the number m of objective functions of an optimization problem as its dimension (or dimensionality). Later in this article, we will discuss issues arising from a large number of decision variables, which we put under the heading scalability in Section 9.</p><p>The most common way to define optima in multiobjective problems (MOPs) is to use the Pareto domination relation. A candidate solution x 1 is said to dominate another candidate solution x 2 (x 1 ≺ x 2 ) in an mobjective optimization problem if and only if its corresponding vector of objective values f (x 1 ) is (partially) less than the one of x 2 , i.e., i ∈ 1..m ⇒ f i (x 1 ) f i (x 2 ) and ∃i ∈ 1..m : f i (x 1 ) &lt; f i (x 2 ), in minimization problems. More precisely, this is called weak dominance; strong dominance requires x 1 to be strictly better than x 2 in all objectives. However, the latter notion is usually not applied in the optimization domain. The solutions in the Pareto optimal set (also called Pareto set or Pareto efficient frontier ) are not (weakly) dominated by any other solution in the problem space, i.e., globally optimal with respect to the dominance relation <ref type="bibr" target="#b171">[171]</ref><ref type="bibr" target="#b172">[172]</ref><ref type="bibr" target="#b173">[173]</ref> . These are the elements we would like to find, or at least approximate as closely as possible, with optimization (see Fig. <ref type="figure" target="#fig_3">5</ref> in Subsection 2.1.1).</p><p>Many studies in the literature consider mainly biobjective problems <ref type="bibr" target="#b174">[174]</ref> . Consequently, many algorithms have been designed to deal with that kind of problems. However, MOPs having a higher number of objective functions are common in practice -sometimes the number of objectives reaches double figures <ref type="bibr" target="#b175">[175]</ref> -leading to the so-called many-objective optimization <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b174">174,</ref><ref type="bibr" target="#b176">[176]</ref><ref type="bibr" target="#b177">[177]</ref><ref type="bibr" target="#b178">[178]</ref> . This term has been coined by the Operations Research community to denote problems with more than two or three objective functions <ref type="bibr" target="#b179">[179]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Issue: Many-Objective Optimization</head><p>When the dimension of MOPs increases, the majority of the candidate solutions become non-dominated. Traditional multi-objective EAs (MOEAs), however, assign fitness mainly based on information about the Pareto domination relation in the population, usually combined with some diversity metric. Examples include the NSGA-II <ref type="bibr" target="#b180">[180]</ref> (Pareto rank combined with the crowding distance in the objective space), SPEA-2 <ref type="bibr" target="#b60">[61]</ref> (Pareto-domination based strength together with distance to the k nearest neighbor in the objective space), and PESA <ref type="bibr" target="#b181">[181]</ref> (Pareto domination and number of other individuals in the same hyper-box in a grid defined over the search space). It thus can be assumed that Pareto-based optimization approaches (maybe extended with diversity preservation methods) will not perform well in problems with four or more objectives <ref type="bibr" target="#b182">[182]</ref> . Results from the application of such algorithms to two or three objectives cannot simply be extrapolated to larger numbers of optimization criteria <ref type="bibr" target="#b174">[174]</ref> . In [183], Pareto optimality is considered as unfair and imperfect in many-objective problems and [182] indicated that:</p><p>1) an optimizer that produces an entire Pareto set in one run is better than generating the Pareto set through many single-objective optimizations using an aggregation approach if the number of objective function evaluations is fixed, and that 2) optimizers that use Pareto ranking based methods to sort the population will be very effective for small numbers of objectives, but not perform as effectively for many-objective optimization in comparison with methods based on other approaches.</p><p>The results in [174, 176, 184] further demonstrated the degeneration of the performance of traditional multi-objective metaheuristics in many-objective problems in comparison with single-objective approaches. Various elements distant from the true Pareto frontier may survive as hardly-dominated solutions and lead to a decrease in the probability of producing new candidate solutions dominating the existing ones <ref type="bibr" target="#b185">[185]</ref> . This phenomenon is called dominance resistance. The problem of redundant solutions is recognized and demonstrated with an example function (provided as part of a test function suite for continuous multiobjective optimization) in [186].</p><p>In addition to these algorithm-sided limitations, [187] suggested that a human mind <ref type="bibr" target="#b188">[188]</ref> will not be able to make efficient decisions if more than a dozen of objectives are involved. Visualizing the solutions in a human-understandable way becomes more complex with the rising number of dimensions too <ref type="bibr" target="#b189">[189]</ref> .</p><p>The number of non-dominated elements in random samples increases quickly with the dimension <ref type="bibr" target="#b190">[190]</ref> . The hyper-surface of the Pareto frontier may increase exponentially with the number of objective functions <ref type="bibr" target="#b189">[189]</ref> . Like in [189], we would like to illustrate this issue with an experiment.</p><p>Assume that a population-based optimization approach is used to solve a many-objective problem. The algorithm will fill the initial population with n randomly created individuals. The distribution of the probability P (#dom = o|m, n) that a randomly selected individual from this initial population is nondominated (in this population) depends on the population size n and the number of objective functions m. We have approximated this probability distribution using experiments with n m-dimensional vectors where each element is drawn from the same uniform distribution for several values of m spanning from m = 2 to m = 20 and with n = 3 to n = 3 600.</p><p>The fraction of non-dominated elements in the random populations is illustrated in Fig. <ref type="figure" target="#fig_12">14</ref>, based on the arithmetic means of 100 000 runs for each configuration. It rises (roughly) exponentially with m, whereas the population size n seems to have only an approximately logarithmically positive influence. If we list the population sizes required to keep the fraction of non-dominated candidate solutions at the same level as in the case of n = 5 and m = 2 (at around 0.457), we find that for m = 3 ⇒ n ≈ 12, for m = 4 ⇒ n ≈ 35, for m = 5 ⇒ n ≈ 90, for m = 6 ⇒ n ≈ 250, for m = 7 ⇒ n ≈ 650, and for m = 8 ⇒ n ≈ 1 800. An extremely coarse rule of thumb here would hence be that around 0.6e m individuals are required in the population to hold the proportion of non-dominated candidate solutions at around 46% in this experiment.</p><p>The increasing dimensionality of the objective space leads to three main problems <ref type="bibr" target="#b189">[189]</ref> :</p><p>1) The performance of traditional approaches based solely on Pareto comparisons deteriorates.</p><p>2) The utility of the solutions cannot be understood by the human operator anymore.</p><p>3) The number of possible Pareto-optimal solutions may increase exponentially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Countermeasures</head><p>Various countermeasures have been proposed against the problem of dimensionality. Surveys on current approaches to many-objective optimization with EC methods, to the difficulties arising in manyobjective and on benchmark problems, have been provided in [189, 191]. In the following we list a number of approaches for many-objective optimization, some of which are based on the information provided in [189].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Increasing the Population Size</head><p>The most trivial measure is to increase the population size. This, however, works only for a few objective functions and we have to "throw" in exponentially more individuals in order to neutralize the influence of many objectives (as can be seen in Fig. <ref type="figure" target="#fig_12">14</ref>). Hence, increasing the population size will not get us far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.2">Multi-Archive Approaches</head><p>On large numbers of objectives, traditional MOEAs usually exhibit either convergence close to the Pareto front or a good spread alongside it <ref type="bibr" target="#b174">[174,</ref><ref type="bibr" target="#b176">176]</ref> . One possible solution is to use two archives <ref type="bibr" target="#b192">[192]</ref><ref type="bibr" target="#b193">[193]</ref> in the algorithms: one for diversity and one for convergence, with the goal to combine the two positive features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3">Increasing the Selection Pressure</head><p>The way multi-objective approaches scale with increasing dimensionality can be improved by increasing the selection pressure into the direction of the Pareto frontier. Ishibuchi et al. <ref type="bibr" target="#b189">[189]</ref> distinguished approaches that modify the definition of domination in order to reduce the number of non-dominated candidate solutions in the population <ref type="bibr" target="#b194">[194]</ref> and methods that assign different ranks to non-dominated solutions <ref type="bibr" target="#b195">[195]</ref><ref type="bibr" target="#b196">[196]</ref><ref type="bibr" target="#b197">[197]</ref><ref type="bibr" target="#b198">[198]</ref> . Relying on fuzzy Pareto methods instead of pure Pareto comparisons is proposed in [179].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.4">Indicator Function-Based Approaches</head><p>Fitness assignment methods not based on Pareto dominance can also be applied <ref type="bibr" target="#b189">[189]</ref> . One approach is to use indicator functions such as those involving hypervolume metrics <ref type="bibr" target="#b199">[199]</ref><ref type="bibr" target="#b200">[200]</ref> . Hypervolume metrics have been shown to be able to approximate the Pareto frontier <ref type="bibr" target="#b201">[201]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.5">Scalarizing Approaches</head><p>Another possible countermeasure is to use scalarizing functions <ref type="bibr" target="#b189">[189]</ref> for fitness assignment in order to treat many-objective problems with single-objective style methods. Several studies <ref type="bibr" target="#b182">[182,</ref><ref type="bibr" target="#b199">199]</ref> showed that this method can produce better results than applying traditional MOEAs such as NSGA-II <ref type="bibr" target="#b180">[180]</ref> or SPEA 2 <ref type="bibr" target="#b60">[61]</ref> , but also refuted the idea that Pareto-based algorithms cannot cope with their performance in general. Other scalarizing methods can be found in [202-203].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.6">Limiting the Search Area in the Objective Space</head><p>Furthermore, we can limit the search area in the objective space. This leads to a decrease in the number of non-dominated points <ref type="bibr" target="#b189">[189]</ref> and can be achieved by either incorporating preference information <ref type="bibr" target="#b204">[204]</ref><ref type="bibr" target="#b205">[205]</ref> or by reducing the dimensionality <ref type="bibr" target="#b206">[206]</ref><ref type="bibr" target="#b207">[207]</ref><ref type="bibr" target="#b208">[208]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.7">Visualization Methods</head><p>Approaches for visualizing solutions of manyobjective problems in order to make them more comprehensible have been provided in [209-210].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Scalability</head><p>An increasing number of objective functions can threaten the performance of optimization algorithms. We referred to this as the dimensionality problem, i.e., the dimension of the objective space. There is another space-related issue -the "curse of dimensionality" of the search space, i.e., the exponential increase of its volume with the number of genes (or decision variables) <ref type="bibr" target="#b211">[211]</ref><ref type="bibr" target="#b212">[212]</ref> . To better distinguish between the dimensionality of the objective space and the search space, we will refer to the latter as scale.</p><p>As an example, we illustrate small-scale versus largescale problems using discrete or continuous vectorbased search spaces. If we search, for instance, on one gene having values in the natural interval 1..10, there are ten points that could be the optimal solution. When the search space is composed of two such genes, i.e., (1..10) 2 , there exist one hundred possible results and for (1..10) 3 , it is already one thousand. In other words, the number of elements that could be a solution to an optimization problem grows exponentially with the number of genes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">The Issue</head><p>The issue of scale has already been introduced in Subsection 1.3, where we discussed the computational complexity as a measure of how many algorithm steps are needed to solve a problem consisting of X decision variables. As can be seen in Fig. <ref type="figure" target="#fig_13">15</ref>, if the number t( X ) of algorithm steps, i.e., the runtime, needed to solve a problem grows exponentially with the problem size X , it quickly exceeds any feasible bound. However, in Subsection 1.3, the issue was considered from the perspective of deterministic algorithms, which are supposed to solve a problem to optimality. As a remedy for the infeasible runtime of these algorithms, we then suggested to apply stochastic optimization methods. Although these may be able to solve problems with a several magnitudes higher scale in a close-tooptimal way, their performance deteriorates with rising scales too. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Countermeasures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.1">Parallelization and Distribution</head><p>When facing problems of large scale, the main "obstacle" is the high runtime requirement. Thus, any measure of using as much computational power as available can be a remedy. Obviously, there (currently) exists no way to solve large-scale N P-hard prob-lems exactly within feasible time. With more computers, cores, or hardware, a linear (actually, only sublinear <ref type="bibr" target="#b214">[214]</ref> ) improvement of runtime can be achieved at most.</p><p>However, for problems residing in the grey area between feasible and infeasible, distributed computing <ref type="bibr" target="#b215">[215]</ref> may be the method of choice.</p><p>There is a long tradition of parallelizing and distributing the computational workload in EC <ref type="bibr" target="#b216">[216]</ref><ref type="bibr" target="#b217">[217]</ref><ref type="bibr" target="#b218">[218]</ref><ref type="bibr" target="#b219">[219]</ref> . The basic ways to parallelize an EA are:</p><p>1) Local Parallelization. To parallelize the execution by using hardware with multiple CPUs <ref type="bibr" target="#b220">[220]</ref> in a single computer, or, as is the current trend.</p><p>2) by utilizing modern graphics processing inits (GPUs) <ref type="bibr" target="#b221">[221]</ref><ref type="bibr" target="#b222">[222]</ref> to evaluate and process the individuals in a population in parallel.</p><p>3) Parallel Restarts. It is also possible to run different instances of the same algorithm on multiple CPUs or computers in a network at the same time, which would be a parallel version of the restarting strategy.</p><p>4) Master/Slave Approach <ref type="bibr" target="#b223">[223]</ref> . If the evaluation of a candidate solution is very time consuming, this step can be parallelized to several workers (threads or computers in a network), which receive their task from a single central server maintaining a global population.</p><p>5) Island Model <ref type="bibr" target="#b224">[224]</ref> . Alternatively, each node (or thread) may maintain an own population and, from time to time, exchange promising candidate solutions with neighboring nodes in the topology.</p><p>6) Of course, any combination of the above is possible <ref type="bibr" target="#b219">[219]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.2">Generative Representations</head><p>Another way, possibly the best way, to tackle a largescale problem is to "solve" it as a small-scale problem. For some optimization tasks, it is possible to choose a search space G having a smaller size (e.g., a small number G of genes) than the problem space X (i.e., having X &gt; G decision variables). Indirect genotypephenotype mappings can link the spaces together.</p><p>Here, one option is the generative mapping, which step-by-step constructs a complex phenotype by translating a genotype according to some static rules. Grammatical evolution <ref type="bibr" target="#b225">[225]</ref> , for instance, unfolds a start symbol according to a grammar with rules identified in a genotype. This recursive process can basically lead to arbitrarily complex phenotypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.3">Developmental Representations</head><p>Applying a developmental, ontogenic mapping <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b226">226]</ref> that uses feedback from simulations or objective functions in the process of building a candidate solution is another possible countermeasure. If, for instance, a rigid truss composed of X = 600 beams is to be found, instead of optimizing the volumes of each of the beams directly, the goal would be to find a suitable function that receives as a parameter the mechanical stress on a given beam and returns how much the cross section of the beam should be increased.</p><p>Beginning with a basic beam structure, the mechanical stress is evaluated and the function is applied to each of the beams. The updated truss is simulated again and the process is repeated a couple of times. The resulting structure would be the phenotype. The genotype can be an artificial neural network representing the function, encoded as real vectors containing the neural weights, thus having much fewer variables (e.g., G = 12). Moreover, G is independent from X , and therefore, much larger problem spaces can become tangible and excellent results may be obtained in reasonable time, likely with better quality and faster than using generative mappings <ref type="bibr" target="#b17">[18]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.4">Adaptive Encodings</head><p>Somewhat in between purely generative and a developmental approach is the Dynamic Parameter Encoding (DPE) method <ref type="bibr" target="#b20">[21]</ref> , which is basically a dynamic genotype-phenotype mapping for binary-encoded real vectors. Traditionally, the number of bits in each gene is fixed and corresponds to the desired precision. In DPE, the interval in the problem space represented by each gene is assigned dynamically, iteratively shrinking down from the full range: If the GA used for optimization has converged to some values of the bits of a gene, a zooming operation changes the meaning of that gene to now represent the corresponding sub-interval only. This way, the number of bits needed to achieve a given solution precision can be significantly reduced. In other words, although it still needs one gene in the genotype per decision variable in the phenotype, the genes themselves only consist of a few bits (e.g., three) and are thus much more compact than in fixed genotype-phenotype mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.5">Exploiting Separability</head><p>If a large-scale problem cannot be solved as a single small-scale problem, solving it as multiple small-scale problems may be another option for saving runtime. Sometimes, parts of candidate solutions are independent from each other and can be optimized more or less separately. In such a case (low epistasis, see Section 6), a large-scale problem can be divided into several components of smaller-scale to be optimized separately. If solving a problem of scale X takes 2 X algorithm steps, solving two problems of scale 0.5 X will clearly lead to a great runtime reduction. Such a reduction may even be worth the sacrifice of some solution quality. If the optimization problem at hand exhibits low epistasis or is separable, such a sacrifice may even be avoided.</p><p>Coevolution has shown to be an efficient approach in combinatorial optimization <ref type="bibr" target="#b228">[227]</ref> .</p><p>If extended with a cooperative component (i.e., to Cooperative Coevolution <ref type="bibr" target="#b156">[156]</ref><ref type="bibr" target="#b157">[157]</ref> ), it can efficiently exploit separability in numerical problems and lead to better results <ref type="bibr" target="#b156">[156,</ref><ref type="bibr" target="#b229">228]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.6">Combination of Techniques</head><p>Generally speaking, it can be a good idea to concurrently use different sets of algorithms <ref type="bibr" target="#b230">[229]</ref> or portfolios <ref type="bibr" target="#b231">[230]</ref> to work on the same or different populations. This way, the strengths of different optimization methods can be combined. In the beginning, for instance, an algorithm with good convergence speed may be granted more runtime. Later, the focus can shift towards methods that can retain diversity and are not prone to premature convergence. Alternatively, a sequential approach can be performed, which starts with one algorithm and switches to another one when no further improvements can be found <ref type="bibr" target="#b91">[91]</ref> . By doing this, an interesting area in the search space can first be discovered, and then be investigated more thoroughly.</p><p>10 No Free Lunch Theorem So far, we have discussed various difficulties that could arise when applying an optimization algorithm to a given problem. The fact that not a single optimization method is likely to be able to outperform all other methods on all problems can easily be accepted. Instead, we see a variety of optimization methods specialized in solving different types of problems. There are also algorithms that may deliver good results for many different problem classes, but could be outperformed by highly specialized methods in each of them. These facts have been formalized by Wolpert and Macready <ref type="bibr" target="#b232">[231]</ref> in their No Free Lunch Theorems for search and optimization algorithms.</p><p>The performance of an algorithm a executed for p steps on an optimization problem can be defined as the conditional probability of finding a particular sample (such as the global optimum). Wolpert and Macready <ref type="bibr" target="#b232">[231]</ref> proved that the sum of such probabilities over all possible optimization problems on finite domains is always identical for all optimization algorithms. This means that the average performance over all finite problems is independent of the algorithm applied. From this theorem, we can immediately follow that, in order to outperform algorithm a 1 in one optimization problem, algorithm a 2 will necessarily perform worse in another problem, as sketched in Fig. 16. This implies that it is impossible for any optimization algorithm to always outperform non-repeating random walks or exhaustive enumerations. In practice, an optimizer is not applied to all possible problems but to only some, restricted classes. In terms of these classes, it is well possible to perform comparisons and to make statements regarding which algorithms perform the best (which, by the way, is often the topic of challenges and competitions <ref type="bibr" target="#b142">[142]</ref><ref type="bibr" target="#b143">[143]</ref> ). Furthermore, it was recently shown that the No Free Lunch Theorem holds only in a weaker form for countable infinite and not for continuous domains <ref type="bibr" target="#b233">[232]</ref> .</p><p>Another interpretation of the No Free Lunch Theorem is that every useful optimization algorithm utilizes some form of problem-specific knowledge. In [233], it is stated that without such knowledge, search algorithms cannot exceed the performance of simple enumerations. Incorporating knowledge starts with relying on simple assumptions like causality (see Subsection 3.1). The more problem specific knowledge is integrated into the algorithm structure, the better the algorithm can perform <ref type="bibr" target="#b17">[18]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Concluding Remarks</head><p>The subject of this article is to address questions about issues that make optimization problems difficult to solve, with a particular focus on evolutionary optimization. We have discussed a variety of scenarios that can influence/affect the optimization process and lead to disappointing results.</p><p>If an optimization process has converged prematurely, it is said to be trapped in a non-optimal region of the search space from which it cannot "escape" anymore (Section 2). Ruggedness (Section 3) and deceptiveness (Section 4) in the fitness landscape, often caused by epistatic effects (Section 6), can misguide the search into such a region. Neutrality and redundancy (Section 5) may either slow down optimization or con-tribute positively. Noise is present in virtually all practical optimization problems. The solutions that are derived for them should thus be robust (Section 7). Also, many practical problems are multi-objective in nature, i.e., involve the optimization of more than one criterion at a time (see Section 8).</p><p>The No Free Lunch Theorem argues that it is not possible to develop a universal optimization algorithm, the problem-solving machine that can provide us with near-optimal solutions in short time for every possible optimization task in finite domains. Such a statement may sound depressing for those who are new to this subject.</p><p>Actually, quite the opposite is the case, at least from the point of view of a researcher. The No Free Lunch Theorem means that there will always be new ideas, new approaches that will lead to better optimization algorithms to solve a given problem. Instead of being doomed to obsolescence, it is far more likely that most of the currently known optimization methods have at least one niche, one area where they could excel in. This fact has contributed to the emergence of memetic, hybrid and the new area of portfolio-type algorithms <ref type="bibr" target="#b231">[230]</ref> , which combine different optimization methods.</p><p>It is most likely that the "puzzle" ⑤ of optimization algorithms as sketched in Fig. <ref type="figure" target="#fig_15">17</ref> will never be completed. There will always be a chance that an inspiring moment, an observation in nature, for instance, may lead to the invention of a new optimization algorithm that performs better in some problem areas than all the currently known ones. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig.1. Involved spaces and sets in (evolutionary) optimization. (a) Involved spaces. (b) Involved sets/elements.</figDesc><graphic coords="4,132.86,208.92,345.60,316.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Examples of different possible scenarios in the fitness landscape (under minimization). (a) Best case. (b) Multi-modal with low total variation. (c) Multi-modal with higher total variation. (d) Rugged (multi-modal + high total variation). (e) Deceptive. (f) Neutral. (g) Needle-in-a-haystack. (h) Nightmare.</figDesc><graphic coords="5,57.86,521.57,496.08,191.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Artificial example of how landscape features may change depending on the selected region of the graph.</figDesc><graphic coords="6,135.86,103.19,340.20,167.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. Optimal solution approximation sets. (a) Bad convergence and good spread (single-objective). (b) Good convergence and bad spread (single-objective). (c) Good convergence and spread (single-objective). (d) Bad convergence and good spread (bi-objective).</figDesc><graphic coords="7,86.86,466.15,437.76,234.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. Exploration vs exploitation.</figDesc><graphic coords="8,314.33,620.45,240.96,114.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. Landscape difficulty increases with increasing ruggedness.</figDesc><graphic coords="10,314.33,463.98,240.96,54.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. Increasingly difficult landscapes caused by deceptivity.</figDesc><graphic coords="12,56.38,98.01,240.96,72.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Landscape difficulty caused by neutrality.</figDesc><graphic coords="13,56.38,553.61,240.96,62.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Possible positive and negative influence of neutrality (inspired by [125]). (a) Premature convergence. (b) Small neutral bridge. (c) Wide neutral bridge. (d) Neutral bridge too wide.</figDesc><graphic coords="14,57.86,565.16,496.08,152.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Pleiotropy and epistasis in a dinosaur's genome.</figDesc><graphic coords="16,56.38,103.11,240.96,171.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>) holds. arg min x1,...,x X f (x 1 , . . . , x X ) = (arg min x1 f (x 1 , . . .), . . . , arg min x X f (. . . , x X )). (1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig.13. A robust local optimum vs an "unstable" global optimum.</figDesc><graphic coords="17,327.33,593.46,215.40,122.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .</head><label>14</label><figDesc>Fig.14. Proportion P (#dom = o|m, n) of non-dominated candidate solutions for several population sizes n and dimensionalities m.</figDesc><graphic coords="19,68.38,572.83,217.20,140.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig.15. Illustration of the rising speed of some functions, inspired by [213].</figDesc><graphic coords="20,314.33,412.13,240.96,193.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig.16. A visualization of the No Free Lunch Theorem.</figDesc><graphic coords="22,319.33,135.17,231.48,161.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .</head><label>17</label><figDesc>Fig.17. Puzzle of optimization algorithms.</figDesc><graphic coords="23,62.38,490.55,229.08,159.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Thomas Weise et al.: Evolutionary Optimization: Pitfalls and Booby Traps 911</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Regular Paper This work was supported in part by the National Natural Science Foundation of China under Grant Nos. U0835002, 61175065, and 61150110488, the Natural Science Foundation of Anhui Province of China under Grant No. 1108085J16, the European Union 7th Framework Program under Grant No. 247619, the Chinese Academy of Sciences Fellowship for Young International Scientists under Grant No. CX05040000001, and Special Financial Grant from the China Postdoctoral Science Foundation under Grant No. 201104329.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Distributed Systems Group of the Fachbereich Elektrotechnik and Informatik, University of Kassel, Germany in 2009. Since 2009, he is with the Nature Inspired Computation and Applications Laboratory, School of Computer Science and Technology, University of Science and Technology of China. His major research interests include evolutionary computation, genetic programming (GP), and real-world applications of optimization algorithms. His experience ranges from applying GP to distributed systems and multi-agent systems, efficient web service composition for Service Oriented Architectures, to solving large-scale real-world vehicle routing problems for multimodal logistics and transportation. Besides being the author/co-author of over 60 refereed publications, Dr. Weise also authors the electronic book Global Optimization Algorithms -Theory and Application which is freely available at his website http://www.it-weise.de/.</p><p>Raymond Chiong is with the Faculty of Higher Education Lilydale, Swinburne University of Technology, Australia.</p><p>He has been lecturing in computer science/information systems for many years. His teaching has focused on programming and databases. Besides teaching, he has been actively pursuing research in computational and artificial intelligence, with a particular interest in the applications of nature-inspired computational methodologies to various optimisation, scheduling and planning problems. He is the Editor-in-Chief of the Interdisciplinary Journal of Information, Knowledge, and Management (IJIKM), and Editor of the journal Engineering Applications of Artificial Intelligence (EAAI). He also serves on the review board/program committee of several international journals and conferences. To date, he has more than 70 refereed publications in books, journals and conference proceedings. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Evolutionary optimization. In Variants of Evolutionary Algorithms for Real-World Applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clerc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K A</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Neri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<editor>Chiong R, Weise T, Michalewicz Z</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="1" to="29" />
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Global Optimization Algorithms -Theory and Application</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<ptr target="http://www.it-weise.de/projects/book.pdf" />
	</analytic>
	<monogr>
		<title level="m">Germany: it-weise.de</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Introduction to Evolutionary Computing</title>
		<title level="s">Natural Computing Series</title>
		<meeting><address><addrLine>New York, USA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Variants of Evolutionary Algorithms for Real-World Applications</title>
		<editor>Chiong R, Weise T, Michalewicz Z</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A genetic algorithm tutorial</title>
		<author>
			<persName><forename type="first">L</forename><surname>Whitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="65" to="85" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Genetic Algorithms + Data Structures = Evolution Programs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag GmbH</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A short tutorial on evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st International Conference on Evolutionary Multi-Criterion Optimization</title>
		<meeting>the 1st International Conference on Evolutionary Multi-Criterion Optimization<address><addrLine>Zürich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03-07">2001. March 7-9, 2001</date>
			<biblScope unit="page" from="21" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Theoretical and numerical constrainthandling techniques used with evolutionary algorithms: A survey of the state of the art</title>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="issue">11-12</biblScope>
			<biblScope unit="page" from="1245" to="1287" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms and the problem-specific knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Trojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd National Conference on Evolutionary Computation and Global Optimization</title>
		<meeting>the 2nd National Conference on Evolutionary Computation and Global Optimization<address><addrLine>Rytro, Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">September 16-19, 1997</date>
			<biblScope unit="page" from="281" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Natural Intelligence for Scheduling, Planning and Packing Problems</title>
		<editor>Chiong R, Dhakal S</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m">Nature-Inspired Informatics for Intelligent Applications and Knowledge Discovery: Implications in Business, Science and Engineering</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</editor>
		<meeting><address><addrLine>Hershey, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Information Science Reference</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Nature-Inspired Algorithms for Optimisation</title>
		<editor>Chiong R</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis of computational time of simple estimation of distribution algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Choosing selection pressure for wide-gap problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="926" to="934" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards an analytic framework for analysing the computation time of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="59" to="97" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A note on problem difficulty measures in black-box optimization: Classification, realizations and predictability</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><surname>Reeves C R</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="443" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A diversity classification scheme for genetic algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Lochtefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Ciarallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 61st Annual IIE Conference and Expo (IERC2011)</title>
		<meeting>the 61st Annual IIE Conference and Expo (IERC2011)<address><addrLine>Reno, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">May 21-25, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A study on scalable representations for evolutionary optimization of ground structures. Evolutionary Computation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="453" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An analysis of the behavior of a class of genetic adaptive systems</title>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">IDDFS -iteratively deepening depth-first search, ACOant colony optimization, LCS -learning classifier systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st Workshop on Foundations of Genetic ⑤ So far undefined abbreviations: RFD -river formation ynamics</title>
		<meeting>the 1st Workshop on Foundations of Genetic ⑤ So far undefined abbreviations: RFD -river formation ynamics<address><addrLine>Bloomington, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-07-15">1990. July 15-18, 1990</date>
			<biblScope unit="page" from="205" to="218" />
		</imprint>
	</monogr>
	<note>Genetic algorithms for real parameter optimization</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic parameter encoding for genetic algorithms</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Belew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="21" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Genetic Algorithms in Search, Optimization, and Machine Learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley Longman Publishing Co., Inc</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Representations for Genetic and Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rothlauf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Physica-Verlag GmbH &amp; Co</publisher>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deception considered harmful</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd Workshop on Foundations of Genetic Algorithms (FOGA1992)</title>
		<meeting>the 2nd Workshop on Foundations of Genetic Algorithms (FOGA1992)<address><addrLine>Vail, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">July 26-29, 1992</date>
			<biblScope unit="page" from="75" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bitwise regularity and GA-hardness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Leblanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1998 IEEE International Conference on Evolutionary Computation (CEC1998)</title>
		<meeting>the 1998 IEEE International Conference on Evolutionary Computation (CEC1998)<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">May 4-9, 1998</date>
			<biblScope unit="page" from="517" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Some facts about so called GAhardness measures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Naudts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kallel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rapport Interne (R.I.)</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<date type="published" when="1998">1998</date>
			<publisher>CMAP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fitness distributions and GA hardness</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 8th International Conference on Parallel Problem Solving from Nature<address><addrLine>Birmingham, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">September 18-22, 2008</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">GA-hardness revisited</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference (GECCO2003), Part I</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO2003), Part I<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">July 12-16, 2003</date>
			<biblScope unit="page" from="1584" to="1585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Time complexity of evolutionary algorithms for combinatorial optimization: A decade of results</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Oliveto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="293" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Analysis of the (1+1)-ea for finding approximate solutions to vertex cover problems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Oliveto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1006" to="1029" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Genetic algorithm difficulty and the modality of the fitness landscape</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd Workshop on Foundations of Genetic Algorithms</title>
		<meeting>the 3rd Workshop on Foundations of Genetic Algorithms<address><addrLine>Estes Park, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-08-02">July 31-August 2, 1994</date>
			<biblScope unit="page" from="243" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Comparison of multi-modal optimization algorithms based on evolutionary algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 8th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">July 8-12, 2006</date>
			<biblScope unit="page" from="1305" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Why is optimization difficult? In Nature-Inspired Algorithms for Optimisation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zapf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nebro</forename><surname>Urbaneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Computational Intelligence</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Genetic algorithms and fitness variance with an application to the automated design of artificial neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Rudnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Oregon Graduate Institute of Science &amp; Technology</publisher>
		</imprint>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Domino convergence, drift, and the temporal-salience structure of problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Â</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1998 IEEE International Conference on Evolutionary Computation</title>
		<meeting>the 1998 IEEE International Conference on Evolutionary Computation<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">May 4-9, 1998</date>
			<biblScope unit="page" from="535" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The royal road for genetic algorithms: Fitness landscapes and GA performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st European Conference on Artificial Life (ECAL1991)</title>
		<meeting>the 1st European Conference on Artificial Life (ECAL1991)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">December 11-13, 1991</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On the influence of phenotype plasticity on genotype diversity</title>
		<author>
			<persName><forename type="first">I</forename><surname>Paenke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st IEEE Symposium on Foundations of Computational Intelligence (FOCI2007)</title>
		<meeting>the 1st IEEE Symposium on Foundations of Computational Intelligence (FOCI2007)<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">April 1-5, 2007</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Genetic algorithms -Computer programs that &quot;evolve&quot; in ways that resemble natural selection can solve complex problems even their creators do not fully understand</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="50" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On evolutionary exploration and exploitation</title>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Schippers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamenta Informaticae</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="35" to="50" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tabu search -Part ii</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ORSA Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="206" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A note on the finite time behaviour of simulated annealing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schrader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="476" to="484" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Simulated annealing: Practice versus theory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ingber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical and Computer Modelling</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="29" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On the impact of mutation-selection balance on the runtime of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Lehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="241" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Theoretical analysis of rank-based mutation -Combining exploration and exploitation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Oliveto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Lehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 10th IEEE Congress on Evolutionary Computation</title>
		<meeting>the 10th IEEE Congress on Evolutionary Computation<address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">May 18-21, 2009</date>
			<biblScope unit="page" from="1455" to="1462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Superior exploration-exploitation balance in shuffled complex evolution</title>
		<author>
			<persName><forename type="first">N</forename><surname>Muttil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Hydraulic Engineering</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1202" to="1205" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Intelligent exploration for genetic algorithms: Using self-organizing maps in evolutionary computation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Amor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference (GECCO2005)</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO2005)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">June 25-27, 2005</date>
			<biblScope unit="page" from="1531" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adaptive cellular memetic algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krasnogor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="256" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cixl2: A crossover operator for evolutionary algorithms based on population features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ortiz-Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hervás-Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C A R</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evolutionary programming using the mutations based on the Lévy probability distribution</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An empirical study of genetic operators in genetic algorithms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microprocessing and Microprogramming</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1-5</biblScope>
			<biblScope unit="page" from="707" to="714" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Greedy randomized adaptive search procedures</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Feo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Resende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Global Optimization</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="133" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Optimizing epochal evolutionary search: Population-size dependent theory</title>
		<author>
			<persName><forename type="first">E</forename><surname>Van Nimwegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Crutchfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="114" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A large population size can be unhelpful in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">436</biblScope>
			<biblScope unit="page" from="54" to="70" />
			<date type="published" when="2012-06">2012. June</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">From an individual to a population: An analysis of the first hitting time of population-based evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="495" to="511" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Representational redundancy in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Asenstorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd IEEE International Conference on Evolutionary Computation (CEC1995)</title>
		<meeting>the 2nd IEEE International Conference on Evolutionary Computation (CEC1995)<address><addrLine>Perth, WA, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-12-01">November 29-December 1, 1995</date>
			<biblScope unit="page" from="631" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference on Genetic Algorithms and their Applications</title>
		<meeting>the 2nd International Conference on Genetic Algorithms and their Applications<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">July 28-31, 1987</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An investigation of niche and species formation in genetic function optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd International Conference on Genetic Algorithms (ICGA 1989)</title>
		<meeting>the 3rd International Conference on Genetic Algorithms (ICGA 1989)<address><addrLine>Fairfax, VA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">June 4-7, 1989</date>
			<biblScope unit="page" from="42" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Massive multimodality, deception, and genetic algorithms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd Parallel Problem Solving from Nature</title>
		<meeting>the 2nd Parallel Problem Solving from Nature<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">September 28-30, 1992</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An evolutionary algorithm for multiobjective optimization: The strength pareto approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIK-Report</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<date type="published" when="1998">1998</date>
			<publisher>ETH) Zürich</publisher>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering and Networks Laboratory (TIK), Department of Electrical Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Improving the strength pareto evolutionary algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><surname>Spea</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>ETH) Zürich</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering and Networks Laboratory (TIK), Department of Electrical Engineering</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">TIK-Report</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Solving real-world vehicle routing problems with evolutionary algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Podlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gorldt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Intelligence for Scheduling, Planning and Packing Problems (Studies in Computational Intelligence</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Dhakal</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">250</biblScope>
			<biblScope unit="page" from="29" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Evolutionary freight transportation planning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Podlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Reinhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gorldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Geihs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Giacobini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Brabazon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Cagnonj</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">5484</biblScope>
			<biblScope unit="page" from="768" to="777" />
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A clearing procedure as a niching method for genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pétrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE International Conference on Evolutionary Computation (CEC1996)</title>
		<meeting>the IEEE International Conference on Evolutionary Computation (CEC1996)<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="page" from="798" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Every niching method has its niche: Fitness sharing and implicit sharing compared</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Darwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 4th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 4th International Conference on Parallel Problem Solving from Nature<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">September 22-24, 1996</date>
			<biblScope unit="page" from="398" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A framework for multi-model edas with model recombination</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niemczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wan</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the EvoApplications</title>
		<meeting>the EvoApplications<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04-27">2011. April 27-29, 2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="304" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Clustering and learning gaussian distribution for continuous optimization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics -Part C: Applications and Reviews</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A hybrid evolutionary algorithm based on edas and clustering analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 26th Chinese Control Conference (CCC2007)</title>
		<meeting>the 26th Chinese Control Conference (CCC2007)<address><addrLine>Zhangjiajie, Hunan, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">July 26-31, 2007</date>
			<biblScope unit="page" from="754" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Multiobjective HBOA, clustering, and scalability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pelikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference (GECCO2005), Washington</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO2005), Washington<address><addrLine>DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">June 25-27, 2005</date>
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Self-adaptation and global convergence: A counter-example</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC1999)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC1999)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">July 6-9, 1999</date>
			<biblScope unit="page" from="646" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Self-adaptive mutations may lead to premature convergence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="410" to="414" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Helper-objective optimization strategies for the job-shop scheduling problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Lochtefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Ciarallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4161" to="4174" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Reducing local optima in single-objective problems by multi-objectivization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Watson R A, Corne</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m">Proc. the 1st International Conference on Evolutionary Multi-Criterion Optimization</title>
		<meeting>the 1st International Conference on Evolutionary Multi-Criterion Optimization<address><addrLine>Zürich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03-07">2001. March 7-9, 2001</date>
			<biblScope unit="page" from="269" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Helper-objectives: Using multi-objective evolutionary algorithms for single-objective optimisation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Modelling and Algorithms</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="347" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms and multi-objectivization for the travelling salesman problem</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jähne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 11th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Montréal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">July 8-12, 2009</date>
			<biblScope unit="page" from="595" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Deterministic helper objective sequence applied to the job-shop scheduling problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Lochtefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Ciarallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">July 7-11, 2010</date>
			<biblScope unit="page" from="431" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Multiobjectivization via helperobjectives with the tunable objectives problem</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Lochtefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Ciarallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="373" to="390" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Multiobjectivization by decomposition of scalar cost functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Handl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S C</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 10th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 10th International Conference on Parallel Problem Solving from Nature<address><addrLine>Dortmund, North Rhine-Westphalia, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">September 13-17, 2008</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</author>
		<author>
			<persName><surname>Evolutionsstrategie</surname></persName>
		</author>
		<title level="m">Optimierung technischer systeme nach prinzipien der biologischen evolution</title>
		<meeting><address><addrLine>Stuttgart, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
		<respStmt>
			<orgName>Technische Universität Berlin</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Rechenberg I. Evolutionsstrategie &apos;94. Bad Cannstadt</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Frommann-Holzboog Verlag</publisher>
			<pubPlace>Stuttgart, Baden-Württemberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Landscape ruggedness in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kolarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE International Conference on Evolutionary Computation</title>
		<meeting>the IEEE International Conference on Evolutionary Computation<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">April 13-16, 1997</date>
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Lamarckian evolution, the baldwin effect and function optimization</title>
		<author>
			<persName><forename type="first">L D</forename><surname>Whitley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V S</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Mathias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 3rd Conference on Parallel Problem Solving from Nature<address><addrLine>Jerusalem, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">October 9-14, 1994</date>
			<biblScope unit="page" from="6" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">How learning can guide evolution</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="495" to="502" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Memetic algorithms using guided local search: A case study</title>
		<author>
			<persName><forename type="first">D</forename><surname>Holstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P ;</forename><surname>Moscato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Ideas in Optimization</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</editor>
		<meeting><address><addrLine>Maidenhead, England</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill Ltd</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A gentle introduction to memetic algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Metaheuristics</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kochenberger</surname></persName>
		</editor>
		<meeting><address><addrLine>Norwell, MA, USA; Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers and Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="105" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Formal memetic algorithms</title>
		<author>
			<persName><forename type="first">N J</forename><surname>Radcliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Surry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Fogarty</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">865</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1994">1994</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">How genetic algorithms really work -I. mutation and hillclimbing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mühlenbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Parallel Problem Solving from Nature 2 (PPSN II)</title>
		<meeting>the Parallel Problem Solving from Nature 2 (PPSN II)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">September 28-30, 1992</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Handbook of Genetic Algorithms</title>
		<editor>Davis L</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Thomson Publishing Group, Inc</publisher>
			<pubPlace>Stamford, CT, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Adding learning to the cellular development of neural networks: Evolution and the baldwin effect</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gruau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Whitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="213" to="233" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Evolutionary search of approximated n-dimensional landscapes</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Newton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Knowledge-Based and Intelligent Engineering Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="172" to="183" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Estimation of distribution and differential evolution cooperation for large scale economic load dispatch optimization of power systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences -Informatics and Computer Science Intelligent Systems Applications</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2405" to="2420" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Evolving distributed algorithms with genetic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="242" to="265" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Evolving distributed algorithms with genetic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Genetic algorithms and walsh functions: Part i, a gentle introduction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="152" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Genetic algorithms and walsh functions: Part ii, deception and its analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="171" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Deceptiveness and genetic algorithm dynamics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Liepins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Vose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st Workshop on Foundations of Genetic Algorithms (FOGA1990)</title>
		<meeting>the 1st Workshop on Foundations of Genetic Algorithms (FOGA1990)<address><addrLine>Bloomington, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">July 15-18, 1990</date>
			<biblScope unit="page" from="36" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A tunable model for multi-objective, epistatic, rugged, and neutral fitness landscapes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niemczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Skubch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reichle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Geihs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>GECCO</publisher>
			<date type="published" when="2008-07-12">2008. July 12-16, 2008</date>
			<biblScope unit="page" from="795" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Using multiple representations in evolutionary algorithms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>La Jolla, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">July 16-19, 2000</date>
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Niching without niching parameters: Particle swarm optimization using a ring topology</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="150" to="169" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Fitness uniform selection to preserve genetic diversity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">May 12-17, 2002</date>
			<biblScope unit="page" from="783" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Fitness uniform optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="568" to="589" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Exploiting open-endedness to solve problems through the search for novelty</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th International Conference on Artificial Life</title>
		<meeting>the 11th International Conference on Artificial Life<address><addrLine>Winchester, Hampshire, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">August 5-8, 2008</date>
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Abandoning objectives: Evolution through the search for novelty alone</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="223" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Evolving a diversity of virtual creatures through novelty search and local competition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">July 12-16, 2011</date>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Novel loop structures and the evolution of mathematical algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 14th European Conference on Genetic Programming</title>
		<meeting>the 14th European Conference on Genetic Programming<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04-27">EuroGP2011. April 27-29, 2011</date>
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Evolving distributed algorithms with genetic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st ACM/SIGEVO Sunmit on Genetic and Evolutionary Computation</title>
		<meeting>the 1st ACM/SIGEVO Sunmit on Genetic and Evolutionary Computation<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">June 12-14, 2009</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Neutrality in fitness landscapes</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Reidys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Stadler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="321" to="350" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Ruggedness and neutrality -the NKP family of fitness landscapes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Barnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 6th International Conference on Artificial Life</title>
		<meeting>the 6th International Conference on Artificial Life<address><addrLine>Los Angeles, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">June 27-29, 1998</date>
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Evolvability and speed of evolutionary algorithms in the light of recent developments in biology</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-01">2010. January</date>
		</imprint>
	</monogr>
	<note>Journal of Artificial Evolution and Applications</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Robustness, evolvability, and neutrality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEBS Letters</title>
		<imprint>
			<biblScope unit="volume">579</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1772" to="1778" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Kirschner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gerhart</surname></persName>
		</author>
		<author>
			<persName><surname>Evolvability</surname></persName>
		</author>
		<title level="m">Proc. the National Academy of Science of the United States of America</title>
		<meeting>the National Academy of Science of the United States of America</meeting>
		<imprint>
			<publisher>PNAS</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="8420" to="8427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Toward a theory of evolution strategies: The (µ, λ)-theory</title>
		<author>
			<persName><forename type="first">H</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="407" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Fitness distance correlation analysis: An instructive counterexample</title>
		<author>
			<persName><forename type="first">L</forename><surname>Altenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 7th International Conference on Genetic Algorithms (ICGA1997), East Lansing</title>
		<meeting>the 7th International Conference on Genetic Algorithms (ICGA1997), East Lansing<address><addrLine>MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">July 19-23, 1997</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">The schema theorem and price&apos;s theorem</title>
		<author>
			<persName><forename type="first">L</forename><surname>Altenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd Workshop on Foundations of Genetic Algorithms</title>
		<meeting>the 3rd Workshop on Foundations of Genetic Algorithms<address><addrLine>Estes Park, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-08-02">July 31-August 2, 1994</date>
			<biblScope unit="page" from="23" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Program evolvability under environmental variations and neutrality</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 9th European Conference on Advances in Artificial Life (ECAL2007)</title>
		<meeting>the 9th European Conference on Advances in Artificial Life (ECAL2007)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 10-14, 2007</date>
			<biblScope unit="page" from="835" to="844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Deceptiveness and neutrality the ND family of fitness landscapes</title>
		<author>
			<persName><forename type="first">W</forename><surname>Beaudoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vérel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Collard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Escazut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 8th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">July 8-12, 2006</date>
			<biblScope unit="page" from="507" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">The Neutral Theory of Molecular Evolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kimura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Neutrality: A necessity for selfadaptation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Toussaint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Honolulu, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">May 12-17, 2002</date>
			<biblScope unit="page" from="1354" to="1359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Punctuated equilibrium comes of age</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Eldredge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6452</biblScope>
			<biblScope unit="page" from="223" to="227" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Statistical dynamics of the royal road genetic algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Van Nimwegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Crutchfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="41" to="102" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Punctuated equilibria: A parallel genetic algorithm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference on Genetic Algorithms and their Applications</title>
		<meeting>the 2nd International Conference on Genetic Algorithms and their Applications<address><addrLine>Cambridge, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">July 28-31, 1987</date>
			<biblScope unit="page" from="148" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Island (migration) models: Evolutionary algorithms based on punctuated equilibria</title>
		<author>
			<persName><forename type="first">W N</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lienig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Evolutionary Computation</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IOP), and CRC Press, Inc</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="448" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Degeneracy and complexity in biological systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the National Academy of Science of the United States of America</title>
		<meeting>the National Academy of Science of the United States of America</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="13763" to="13768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">The role of degenerate robustness in the evolvability of multi-agent systems in dynamic environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Whitacre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rohlfshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th International Conference on Parallel Problem Solving From Nature, Part 1</title>
		<meeting>the 11th International Conference on Parallel Problem Solving From Nature, Part 1<address><addrLine>Kraków, Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">September 11-15, 2010</date>
			<biblScope unit="page" from="284" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Fitness landscapes and evolvability</title>
		<author>
			<persName><forename type="first">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Husbands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Layzell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Counteracting genetic drift and disruptive recombination in (µ + , λ)-ea on multimodal fitness landscapes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Preuß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schönemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Emmerich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference (GECCO2005)</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO2005)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">June 25-27, 2005</date>
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Burden and benefits of redundancy</title>
		<author>
			<persName><forename type="first">K</forename><surname>Weicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Weicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 6th Workshop on Foundations of Genetic Algorithms</title>
		<meeting>the 6th Workshop on Foundations of Genetic Algorithms<address><addrLine>Charlottesville, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">July 21-23, 2001</date>
			<biblScope unit="page" from="313" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Neutral search spaces for artificial evolution: A lesson from life</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shackleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 7th International Conference on Artificial Life</title>
		<meeting>the 7th International Conference on Artificial Life<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">August 1-2, 2000</date>
			<biblScope unit="page" from="162" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">An investigation of redundant genotype-phenotype mappings and their role in evolutionary search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shackleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ebner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>La Jolla, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">July 16-19, 2000</date>
			<biblScope unit="page" from="493" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">The Origins of Order: Self-Organization and Selection in Evolution</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kauffman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Oxford University Press, Inc</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">The advantages of landscape neutrality in digital circuit evolution</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Vassilev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd International Conference on Evolvable Systems -From Biology to Hardware</title>
		<meeting>the 3rd International Conference on Evolvable Systems -From Biology to Hardware<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">April 17-19, 2000</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Finding needles in haystacks is not hard with neutrality</title>
		<author>
			<persName><forename type="first">G T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 5th European Conference on Genetic Programming</title>
		<meeting>the 5th European Conference on Genetic Programming<address><addrLine>Kinsale, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">April 3-5, 2002</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Making genetic algorithm fly: A lesson from the wright brothers</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Technology for Developers</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Fraglets -A metabolistic execution model for communication protocols</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tschudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd Annual Symposium on Autonomous Intelligent Networks and Systems (AINS2003)</title>
		<meeting>the 2nd Annual Symposium on Autonomous Intelligent Networks and Systems (AINS2003)<address><addrLine>Menlo Park, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07-01">June 30-July 1, 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Evolving distributed algorithms with genetic programming: Election</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zapf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st ACM/SIGEVO Summit on Genetic and Evolutionary Computation</title>
		<meeting>the 1st ACM/SIGEVO Summit on Genetic and Evolutionary Computation<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">June 12-14, 2009</date>
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Robust encodings in genetic algorithms: A survey of encoding issues</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ronald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE International Conference on Evolutionary Computation (CEC1997)</title>
		<meeting>the IEEE International Conference on Evolutionary Computation (CEC1997)<address><addrLine>Indianapolis, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">April 13-16, 1997</date>
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">The language of gene interaction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1167" to="1171" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Progeny test and individual performance as indicators of an animal&apos;s breeding value</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Dairy Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1935">1935</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Epistasis variance: A viewpoint on GA-hardness</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Davidor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st Workshop on Foundations of Genetic Algorithms</title>
		<meeting>the 1st Workshop on Foundations of Genetic Algorithms<address><addrLine>Bloomington, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">July 15-18, 1990</date>
			<biblScope unit="page" from="23" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Nk fitness landscapes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Altenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Evolutionary Computation</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Fogel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press, Inc</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>chapter B2.7.2</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Epistasis on finite and infinite spaces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Naudts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Verschoren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th International Conference on Systems Research, Informatics and Cybernetics</title>
		<meeting>the 8th International Conference on Systems Research, Informatics and Cybernetics<address><addrLine>Baden-Baden, Baden-Württemberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">August 14-18, 1996</date>
			<biblScope unit="page" from="19" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Benchmark functions for the CEC&apos;2008 special session and competition on large scale global optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Macnish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Inspired Computation and Applications Laboratory</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science and Technology, University of Science and Technology of China</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Benchmark functions for the CEC&apos;2010 special session and competition on large-scale global optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Nature Inspired Computation and Applications Laboratory, School of Computer Science and Technology, University of Science and Technology of China</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Bioinspired continuous optimization: The coming of age</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mauny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ros</forename><forename type="middle">R</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2007)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2007)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 25-28, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Differential evolution and non-separability: Using selective pressure to focus search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lunacek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Whitley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 9th Genetic and Evolutionary Computation Conference</title>
		<meeting>the 9th Genetic and Evolutionary Computation Conference<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">July 7-11, 2007</date>
			<biblScope unit="page" from="1428" to="1435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Simulating evolution with a computational model of embryogeny: Obtaining robustness from evolved individuals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th European Conference on Advances in Artificial Life</title>
		<meeting>the 8th European Conference on Advances in Artificial Life<address><addrLine>Canterbury, Kent, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 5-9, 2005</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Rule-based genetic programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zapf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Geihs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference on Bio-Inspired Models of Network, Information, and Computing Systems</title>
		<meeting>the 2nd International Conference on Bio-Inspired Models of Network, Information, and Computing Systems<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">December 10-13, 2007</date>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Mutation strategy improves gas performance on epistatic problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shinkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A H</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2002)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2002)<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">May 12-17, 2002</date>
			<biblScope unit="page" from="968" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Instant Notes in Genetics (1st edition)</title>
		<author>
			<persName><forename type="first">P C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Hickey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>BIOS Scientific Publishers Ltd., Taylor and Francis LLC, Science Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Linkage identification by nonmonotonicity detection for overlapping functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Munetomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="398" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Learning gene linkage to efficiently solve problems of bounded difficulty using genetic algorithms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Harik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Multi-objective test problems, linkages, and evolutionary methodologies</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 8th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">July 8-12, 2006</date>
			<biblScope unit="page" from="1141" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Messy genetic algorithms: Motivation, analysis, and first results</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Korb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="493" to="530" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Linkage problem, distribution estimation, and bayesian networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cantú-Paz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pelikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="340" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Evolutionary module acquisition</title>
		<author>
			<persName><forename type="first">Angeline</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pollack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd Annual Conf. Evolutionary Programming</title>
		<meeting>the 2nd Annual Conf. Evolutionary Programming<address><addrLine>La Jolla, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">February 25-26, 1993</date>
			<biblScope unit="page" from="154" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Large-scale global optimization using cooperative coevolution with variable interaction learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th International Conference on Parallel Problem Solving From Nature, Part 2</title>
		<meeting>the 11th International Conference on Parallel Problem Solving From Nature, Part 2<address><addrLine>Kraków, Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">September 11-15, 2010</date>
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Cooperative coevolution: An architecture for evolving coadapted subcomponents</title>
		<author>
			<persName><forename type="first">M A</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Evolutionary optimization in uncertain environments -A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="317" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">Evolutionary Computation in Dynamic and Uncertain Environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">Genetic algorithms, selection schemes, and the varying effects of noise. Evolutionary Computation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="113" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">The effect of function noise on GP efficiency</title>
		<author>
			<persName><forename type="first">J Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Goos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hartmanis</surname></persName>
		</editor>
		<editor>
			<persName><surname>Van Leeuwen</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">956</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Genetic algorithms in noisy environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="101" to="120" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Optimization of noisy fitness functions by means of genetic algorithms using history of search with test of estimation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Honolulu, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">May 12-17, 2002</date>
			<biblScope unit="page" from="360" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Evolution strategies applied to perturbed objective functions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hammel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st IEEE Conference on Evolutionary Computation</title>
		<meeting>the 1st IEEE Conference on Evolutionary Computation<address><addrLine>Orlando, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">June 27-29, 1994</date>
			<biblScope unit="page" from="40" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Evolution strategies on noisy functions: How to improve convergence properties</title>
		<author>
			<persName><forename type="first">U</forename><surname>Hammel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 3rd Conference on Parallel Problem Solving from Nature<address><addrLine>Jerusalem, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">October 9-14, 1994</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Particle swarm optimization for function optimization in noisy environment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="908" to="919" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Creating robust solutions by means of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 5th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 5th International Conference on Parallel Problem Solving from Nature<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">September 27-30, 1998</date>
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Introduction to Quality Engineering: Designing Quality into Products and Processes. Chiyoda-ku</title>
		<author>
			<persName><forename type="first">G</forename><surname>Taguchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>APO) and Kraus International Publications</publisher>
			<pubPlace>Tokyo, Japan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Robust optical coating design with evolutionary strategies</title>
		<author>
			<persName><forename type="first">H</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="5477" to="5483" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Robust design of multilayer optical coatings by means of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wiesmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hammel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="162" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Comparison of multiobjective evolutionary algorithms: Empirical results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="195" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="444" to="447" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">On a multi-objective evolutionary algorithm and its convergence to the pareto set</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1998 IEEE International Conference on Evolutionary Computation, Anchorage</title>
		<meeting>the 1998 IEEE International Conference on Evolutionary Computation, Anchorage<address><addrLine>AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-09">May 4-9, 1998</date>
			<biblScope unit="page" from="511" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Performance scaling of multiobjective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference on Evolutionary Multi-Criterion Optimization</title>
		<meeting>the 2nd International Conference on Evolutionary Multi-Criterion Optimization<address><addrLine>Faro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">April 8-11, 2003</date>
			<biblScope unit="page" from="367" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms for Solving Multi-Objective Problems</title>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Lamont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Springer US and Kluwer Academic Publishers</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
		<title level="m" type="main">Performance scaling of multi-objective evolutionary algorithms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Khare</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science, University of Birmingham</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master Thesis</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Ranking methods in many-objective evolutionary algorithms. In Nature-Inspired Algorithms for Optimisation</title>
		<author>
			<persName><forename type="first">López</forename><surname>Jaimes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Santana-Quintero L V</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Computational Intelligence</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Chiong</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="413" to="434" />
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<title level="m" type="main">On the evolutionary optimisation of many objectives</title>
		<author>
			<persName><forename type="first">R</forename><surname>Purshouse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>Department of Automatic Control and Systems Engineering, University of Sheffield</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">On the optimal solution definition for many-criteria optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Amato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Annual Meeting of the North American Fuzzy Information Processing Society</title>
		<meeting>the Annual Meeting of the North American Fuzzy Information essing Society<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">June 27-29, 2002</date>
			<biblScope unit="page" from="233" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: Nsga-ii</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">The pareto envelopebased selection algorithm for multiobjective optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Oates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 6th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 6th International Conference on Parallel Problem Solving from Nature<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">September 18-20, 2000</date>
			<biblScope unit="page" from="839" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Evolutionary many-objective optimisation: Many once or one many?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2005)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2005)<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">September 2-5, 2005</date>
			<biblScope unit="page" from="222" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">A new evolutionary decision theory for manyobjective optimization problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Symposium on Advances in Computation and Intelligence</title>
		<meeting>the 2nd International Symposium on Advances in Computation and Intelligence<address><addrLine>Wuhan, Hubei, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 21-23, 2007</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Comparison between singleobjective and multi-objective genetic algorithms: Performance comparison and performance measures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2006)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2006)<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">July 16-21, 2006</date>
			<biblScope unit="page" from="3959" to="3966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Failure of pareto-based moeas: Does non-dominated really mean near to optimal?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Gangnamgu, Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">May 27-30, 2001</date>
			<biblScope unit="page" from="957" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Scalable multiobjective optimization test problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2002), Honolulu</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2002), Honolulu<address><addrLine>HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">May 12-17, 2002</date>
			<biblScope unit="page" from="825" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Building criteria: A prerequisite for MCDA</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bouyssou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Selected Readings from the 3rd International Summer School on Multicriteria Decision Aid: Methods, Applications, and Software (MCDA1990)</title>
		<meeting><address><addrLine>Monte Estoril, Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">July 23-27, 1990</date>
			<biblScope unit="page" from="58" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">The magical number seven, plus or minus two: Some limits on our capacity for processing information</title>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="97" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Evolutionary manyobjective optimization: A short review</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsukamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2008)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2008)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">June 1-6, 2008</date>
			<biblScope unit="page" from="2424" to="2431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>John Wiley &amp; Sons Ltd</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Some techniques to deal with many-objective problems</title>
		<author>
			<persName><forename type="first">López</forename><surname>Jaimes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Coello</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th Annual Conference Companion on Genetic and Evolutionary Computation Conference</title>
		<meeting>the 11th Annual Conference Companion on Genetic and Evolutionary Computation Conference<address><addrLine>Montréal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07-08">2009. July 8-12, 2009</date>
			<biblScope unit="page" from="2693" to="2696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">A new multi-objective evolutionary optimisation algorithm: The two-archive algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Praditwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2006 International Conference on Computational Intelligence and Security (CIS2006)</title>
		<meeting>the 2006 International Conference on Computational Intelligence and Security (CIS2006)<address><addrLine>Guangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">November 3-6, 2006</date>
			<biblScope unit="page" from="286" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Software module clustering as a multi-objective search problem</title>
		<author>
			<persName><forename type="first">K</forename><surname>Praditwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="282" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Controlling dominance area of solutions and its impact on the performance of moeas</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)</title>
		<meeting>the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)<address><addrLine>Matsushima, Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">March 5-8, 2007</date>
			<biblScope unit="page" from="5" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Multi-objective optimisation based on relation favour</title>
		<author>
			<persName><forename type="first">N</forename><surname>Drechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Drechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 1st International Conference on Evolutionary Multi-Criterion Optimization</title>
		<meeting>the 1st International Conference on Evolutionary Multi-Criterion Optimization<address><addrLine>Zürich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03-07">2001. March 7-9, 2001</date>
			<biblScope unit="page" from="154" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Substitute distance assignments in NSGA-II for handling many-objective optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Köppen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)</title>
		<meeting>the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)<address><addrLine>Matsushima, Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">March 5-8, 2007</date>
			<biblScope unit="page" from="727" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Techniques for highly multiobjective optimisation: Some nondominated points are better than others</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 9th Genetic and Evolutionary Computation Conference</title>
		<meeting>the 9th Genetic and Evolutionary Computation Conference<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">July 7-11, 2007</date>
			<biblScope unit="page" from="773" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Ranking-dominance and manyobjective optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kukkonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lampinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2007)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2007)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 25-28, 2007</date>
			<biblScope unit="page" from="3983" to="3990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">Pareto-, aggregation-, and indicator-based methods in many-objective optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naujoks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)</title>
		<meeting>the 4th International Conference on Evolutionary Multi-Criterion Optimization (EMO2007)<address><addrLine>Matsushima, Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">March 5-8, 2007</date>
			<biblScope unit="page" from="742" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Iterative approach to indicator-based multiobjective optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsukamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc the IEEE Congress on Evolutionary Computation (CEC2007)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2007)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 25-28, 2007</date>
			<biblScope unit="page" from="3967" to="3974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">The maximum hypervolume set yields near-optimal approximation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bringmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Genetic and Evolutionary Computation Conference (GECCO2010)</title>
		<meeting>the Genetic and Evolutionary Computation Conference (GECCO2010)<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">July 7-11, 2010</date>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Incorporation of scalarizing fitness functions into evolutionary multiobjective optimization algorithms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Doi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 9th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 9th International Conference on Parallel Problem Solving from Nature<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">September 9-13, 2006</date>
			<biblScope unit="page" from="493" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">A general-purpose many-objective optimiser</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><surname>Msops-Ii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 25-28, 2007</date>
			<biblScope unit="page" from="3944" to="3951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Many-objective optimization: An engineering design perspective</title>
		<author>
			<persName><forename type="first">P J</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Purshouse R C, Lygoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd International Conference on Evolutionary Multi-Criterion Optimization</title>
		<meeting>the 3rd International Conference on Evolutionary Multi-Criterion Optimization<address><addrLine>Guanajuato, México</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">March 9-11, 2005</date>
			<biblScope unit="page" from="14" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Reference point based multi-objective optimization using evolutionary algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sundar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 8th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">July 8-12, 2006</date>
			<biblScope unit="page" from="635" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Are all objectives necessary? On dimensionality reduction in evolutionary multiobjective optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 9th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 9th International Conference on Parallel Problem Solving from Nature<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">September 9-13, 2006</date>
			<biblScope unit="page" from="533" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Dimensionality reduction of objectives and constraints in multi-objective optimization problems: A system design perspective</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deb</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2008)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2008)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">June 1-6, 2008</date>
			<biblScope unit="page" from="3204" to="3211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Improving hypervolume-based multiobjective evolutionary algorithms by using objective reduction methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation (CEC2007)</title>
		<meeting>the IEEE Congress on Evolutionary Computation (CEC2007)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 25-28, 2007</date>
			<biblScope unit="page" from="2086" to="2093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Visualization techniques for mining of solutions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Furuhashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yoshikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 8th International Symposium on Advanced Intelligent Systems (ISIS2007)</title>
		<meeting>the 8th International Symposium on Advanced Intelligent Systems (ISIS2007)<address><addrLine>Sokcho, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 5-8, 2007</date>
			<biblScope unit="page" from="68" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Visualization of pareto-sets in evolutionary multi-objective optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Köppen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 7th International Conference on Hybrid Intelligent Systems, Kaiserslautern</title>
		<meeting>the 7th International Conference on Hybrid Intelligent Systems, Kaiserslautern<address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">September 17-19, 2007</date>
			<biblScope unit="page" from="156" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<title level="m" type="main">Dynamic Programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957">1957</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<title level="m" type="main">Adaptive Control Processes: A Guided Tour</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961">1961</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Combinatorial problems i: Finding solutions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 2nd Asian-Pacific School on Statistical Physics and Interdisciplinary Applications</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">March 3-14, 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Validity of the single processor approach to achieving large-scale computing capabilities</title>
		<author>
			<persName><forename type="first">G</forename><surname>Amdahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Spring Joint Computer Conference (AFIPS)</title>
		<meeting>the Spring Joint Computer Conference (AFIPS)<address><addrLine>Atlantic City, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967">April 18-20, 1967</date>
			<biblScope unit="page" from="483" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">A new asynchronous parallel evolutionary algorithm for function optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 7th International Conference on Parallel Problem Solving from Nature</title>
		<meeting>the 7th International Conference on Parallel Problem Solving from Nature<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">September 7-11, 2002</date>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">A survey of parallel genetic algorithms. Calculateurs Parallèles</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cantú-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Réseaux et Systèmes Répartis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="171" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">A survey of parallel distributed genetic algorithms</title>
		<author>
			<persName><forename type="first">Alba</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Troya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complexity</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="31" to="52" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Parallelism and evolutionary algorithms</title>
		<author>
			<persName><forename type="first">Alba</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tomassini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="443" to="462" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">DGPF -An adaptable framework for distributed multi-objective search algorithms applied to the genetic programming of sensor networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Geihs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 2nd International Conference on Bioinspired Optimization Methods and their Applications (BIOMA2006)</title>
		<meeting>the 2nd International Conference on Bioinspired Optimization Methods and their Applications (BIOMA2006)<address><addrLine>Ljubljana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">October 9-10, 2006</date>
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
	<note>Slovenia</note>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Implementation of standard genetic algorithm on mimd machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Männer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 3rd Conference on Parallel Problem Solving from Natur</title>
		<meeting>the 3rd Conference on Parallel Problem Solving from Natur<address><addrLine>Jerusalem, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">October 9-14, 1994</date>
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">A SIMD interpreter for genetic programming on GPU graphics cards</title>
		<author>
			<persName><forename type="first">B</forename><surname>Langdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th European Conference on Genetic Programming</title>
		<meeting>the 11th European Conference on Genetic Programming<address><addrLine>Naples, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-03-26">EuroGP2008. March 26-28, 2008</date>
			<biblScope unit="page" from="73" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Nonlinear optimization with a massively parallel evolution strategy-pattern search algorithm on graphics hardware</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1770" to="1781" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Analysis of a master-slave architecture for distributed evolutionary computations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dubreuil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parizeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics -Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="235" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Parallel evolutionary programming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tongchim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the IEEE Congress on Evolutionary Computation</title>
		<meeting>the IEEE Congress on Evolutionary Computation<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">June 20-23, 2004</date>
			<biblScope unit="page" from="1362" to="1367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<title level="m" type="main">Grammatical Evolution: Evolutionary Automatic Programming in an Arbitrary Language</title>
		<author>
			<persName><forename type="first">M</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ryan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer Science+Business Media, Inc</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<title level="m" type="main">Building processes optimization: Toward an artificial ontogeny based approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Devert</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Centre</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Recherche</forename><surname>Saclay -Île-De-France</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecole Doctorale d&apos;Informatique and Institut National de Recherche en Informatique et en Automatique</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Université Paris-Sud</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">Simulated co-evolution as the mechanism for emergent planning and scheduling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Husbands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 4th International Conference on Genetic Algorithms (ICGA 1991)</title>
		<meeting>the 4th International Conference on Genetic Algorithms (ICGA 1991)<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">July 13-16, 1991</date>
			<biblScope unit="page" from="264" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Large scale evolutionary optimization using cooperative coevolution</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences -Informatics and Computer Science Intelligent Systems Applications</title>
		<imprint>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page">178</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Hybrid evolutionary algorithms for large scale continuous problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Latorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Peña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaforas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 11th Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the 11th Annual Conference on Genetic and Evolutionary Computation<address><addrLine>Montréal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07-08">2009. July 8-12, 2009</date>
			<biblScope unit="page" from="1863" to="1864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Population-based algorithm portfolios for numerical optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="782" to="800" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Continuous lunches are free plus the design of optimal optimization algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Teytaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="146" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">The algebra of genetic algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Radcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="339" to="384" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Thomas Weise received the Diplom Informatiker (equivalent to M.Sc.) degree from the</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Chemnitz University of Technology</orgName>
		</respStmt>
	</monogr>
	<note>and the Ph.D. degree at the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
