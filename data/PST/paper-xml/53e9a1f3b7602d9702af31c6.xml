<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A new design method based on artificial bee colony algorithm for digital IIR filters</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Nurhan</forename><surname>Karaboga</surname></persName>
							<email>nurhan_k@erciyes.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Faculty of Engineering</orgName>
								<orgName type="department" key="dep2">Department of Electrical-Electronics Engineering</orgName>
								<orgName type="institution">Erciyes University</orgName>
								<address>
									<postCode>38039</postCode>
									<settlement>Melikgazi, Kayseri</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A new design method based on artificial bee colony algorithm for digital IIR filters</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E086FF866F27A27AE919A00155AE277</idno>
					<idno type="DOI">10.1016/j.jfranklin.2008.11.003</idno>
					<note type="submission">Received 7 August 2007; received in revised form 28 June 2008; accepted 18 November 2008</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Digital IIR filters</term>
					<term>System identification</term>
					<term>Swarm-based optimization</term>
					<term>Artificial bee colony algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Digital filters can be broadly classified into two groups: recursive (infinite impulse response (IIR)) and non-recursive (finite impulse response (FIR)). An IIR filter can provide a much better performance than the FIR filter having the same number of coefficients. However, IIR filters might have a multi-modal error surface. Therefore, a reliable design method proposed for IIR filters must be based on a global search procedure. Artificial bee colony (ABC) algorithm has been recently introduced for global optimization. The ABC algorithm simulating the intelligent foraging behaviour of honey bee swarm is a simple, robust, and very flexible algorithm. In this work, a new method based on ABC algorithm for designing digital IIR filters is described and its performance is compared with that of a conventional optimization algorithm (LSQ-nonlin) and particle swarm optimization (PSO) algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Filtering is a process by which the frequency spectrum of a signal is modified, reshaped, or manipulated according to some desired specifications. Design of a digital filter is the process of synthesizing and implementing a filter network so that a set of prescribed excitations results in a set of desired responses <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. Digital filters can be broadly classified into two groups: recursive and non-recursive. The output from a recursive digital filter depends on one or more previous output values, as well as on inputs. In other words, it involves feedback. From the digital signal processing point of view, its great advantage is computational economy. A filter characteristic requiring more coefficients in a nonrecursive realization can often be obtained using just a few recursive coefficients. However, there are two potential disadvantages <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. First, a recursive filter may become unstable if its feedback coefficients are chosen badly during the adaptation process. This problem can be easily handled by limiting the parameter space. Secondly, recursive designs cannot generally provide the linear-phase responses so readily achieved by non-recursive methods. Apart from these two disadvantages, the possibility of having a multi-modal error surface is another important design challenge for recursive filters. In order to overcome this problem, a design method which can achieve the global minima in a multi-modal error surface is required. However, the conventional design methods, widely employed to tackle the problem, based on gradient search can easily be stuck at local minima of error surface. Therefore, some researchers have attempted to develop the design methods based on modern global optimization algorithms such as the simulated annealing (SA) <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>, and differential evolution algorithm <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>Swarm intelligence has become a research interest to many research scientists from various areas in recent years. The swarm intelligence can be defined as any attempt for designing algorithms or distributed problem-solving devices inspired by the collective behaviour of insects and other animal societies <ref type="bibr" target="#b18">[19]</ref>. More specifically, swarm intelligence term can be used in a general manner to refer to any restrained collection of interacting agents or individuals. The classical examples of swarm: bees swarming around their hive; a colony of ants; a flock of birds; and an immune system which is a swarm of cells and a crowd that is a swarm of people. Recently, particle swarm optimization algorithm has been introduced for numerical optimization problems <ref type="bibr" target="#b19">[20]</ref> and successfully applied to digital filter design and other real-world problems <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. PSO algorithm that is a populationbased stochastic optimization technique models the social behaviour of bird flocking or fish schooling <ref type="bibr" target="#b19">[20]</ref> and is well adapted to the optimization of nonlinear functions in multidimensional space. PSO consists of a swarm of particles moving in a search space of possible solutions for a problem. Every particle has a position vector representing a candidate solution to the problem and a velocity vector. Moreover, each particle contains a small memory that stores its own best position seen so far and a global best position obtained through communication with its neighbour particles. Miranda and Fonseca <ref type="bibr" target="#b22">[23]</ref> have proposed an improved version of PSO called evolutionary particle swarm optimization (EPSO). In <ref type="bibr" target="#b22">[23]</ref>, it is presented that EPSO which joins together the characteristics of evolutionary and of particle swarm algorithms is much more reliable than PSO for practical applications.</p><p>In 2005, Karaboga <ref type="bibr" target="#b23">[24]</ref> introduced a bee swarm algorithm called artificial bee colony (ABC) algorithm for numerical optimization problems; and Basturk and Karaboga <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> compared the performance of ABC with that of some other well-known population-based optimization algorithms. In this work, firstly the performance comparison of PSO, EPSO, and ABC algorithms are presented on a set of numeric test functions. Secondly, a new method based on ABC algorithm is described for designing IIR filters. The paper is organized as follows: Section 2 presents ABC algorithm. Section 3 describes the problem. In Section 4, the performance of ABC is compared with that of PSO and EPSO on a set of a well-known numeric test functions <ref type="bibr" target="#b22">[23]</ref> and LSQ-nonlin, which is a conventional optimization algorithm, PSO and ABC algorithms are applied to the design of low-and high-order digital IIR filters and the results obtained are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Artificial bee colony algorithm</head><p>The flowchart of the artificial bee colony algorithm is given in Fig. <ref type="figure" target="#fig_0">1</ref>. Each cycle of the search consists of three steps after initialization stage: placing the employed bees onto the food sources and calculating their nectar amounts; placing the onlookers onto the food sources and calculating the nectar amounts; and determining the scout bees and placing them onto the randomly determined food sources. In the ABC, a food source position represents a possible solution to the problem to be optimized. Therefore, at the initialization step, a set of food source positions are randomly produced and also the values of control parameters of the algorithm are assigned. The nectar amount of a food source corresponds to the quality of the solution represented by that food source. So the nectar amounts of the food sources existing at the initial positions are determined. In other words, the quality values of the initial solutions are calculated. Each employed bee is moved onto her food source area for determining a new food source within the neighbourhood of the present one, and then its nectar amount is evaluated. If the nectar amount of the new one is higher, then she forgets the previous one and memorizes the new one. After the employed bees complete their search, they come back into the hive and share their information about the nectar amounts of their sources with the onlookers waiting on the dance area. All onlookers successively determine a food source area with a probability based on their nectar amounts. If the nectar amount of a food source is much higher when compared with other food sources, it means that this source will be chosen by most of the onlookers. This process is similar to the natural selection process in evolutionary algorithms. Each onlooker determines a neighbour food source within the neighbourhood of the one to which she has been assigned and then its nectar amount is evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yes</head><p>A honey bee colony has scouts that are the colony's explorers who do not need any guidance while looking for food. They are primarily concerned with finding any kind of food source. As a result of such behaviour, the scouts are characterized by low search costs and a low average in food source quality. Occasionally, the scouts can accidentally discover rich, entirely unknown food sources. In the case of artificial bees, the artificial scouts could have the fast discovery of the group of feasible solutions as a task. In ABC algorithm, at most one employed bee at each cycle is selected and classified as the scout bee. The selection of the scout bee is controlled by a control parameter called ''limit''. If a solution representing a food source cannot be improved by a predetermined number of trials, it means that the associated food source has been exhausted by the bees and then the employed bee of this food source becomes a scout. The position of the abandoned food source is replaced with a randomly produced food position. The number of trials for releasing a food source is equal to the value of ''limit'' which is an important control parameter of ABC algorithm. These three steps are repeated until the termination criteria are satisfied.</p><p>As other social foragers, bees search for food sources in a way that maximizes the ratio E/T (where E is the energy obtained and T the time spent for foraging). In the case of bee swarms, E is proportional to the nectar amount of food sources discovered by bees and the bee swarm works to maximize the honey being stored inside the hive. In a maximization problem, the goal is to find the maximum of the objective function F(y), yAR p .</p><p>Assume that y i is the position of the ith food source (ith solution to the problem); F(y i ) represents the nectar amount of the food source located at y ( the quality of solution) and is proportional to the energy E(y i ). Let PðcÞ ¼ fy i ðcÞji ¼ 1; 2; . . . ; sg (c: cycle, s: number of food sources around the hive) represent the population of food source positions being visited by bees. As mentioned before, the preference of a food source by an onlooker bee mainly depends on the nectar amount F(y) of that food source. As the nectar amount of a food source increases, the probability with that the source is chosen by an onlooker bee increases proportionally. The probability with that the food source located at y i is selected by an onlooker bee can be calculated by</p><formula xml:id="formula_0">p i ¼ F ðy i Þ P s k¼1 F ðy k Þ (1)</formula><p>where s is the number of food sources (number of solutions in the population) and is also equal to the number of employed bees in the colony. An onlooker bee selects a food source region depending on the probabilities calculated and determines a neighbour food source around the chosen one. For example, in the selection process for the first onlooker, a random number is produced between [0,1] and if this number is less than p 1 , the first food source (solution) is selected for the first onlooker. Otherwise, this random number is compared with p 2 and if less than that, the second source is chosen. Otherwise, the probability of third source is checked. This process is repeated until all onlookers are distributed onto the food sources (solutions). In this way, most of the onlookers are recruited to the food sources with high nectar amount (the solutions with high fitness value) that have been determined by the employed bees. Assume that the position of the food source selected by the onlooker is y i . The neighbour food source position of y i is calculated as the following:</p><formula xml:id="formula_1">y i ðc þ 1Þ ¼ y i ðcÞ þ f i ðy i ðcÞ À y k ðcÞÞ<label>(2)</label></formula><p>where f i is a randomly produced number in the interval [À1,+1] to find a food source with more nectar around y i (c) and k is a randomly produced index which is different from i.</p><p>If the nectar amount F(y i (c+1)) at y i (c+1) is higher than F(y i (c)) at y i (c), then the artificial bee memorizes y i (c+1) and shares her information with onlooker bees; and the position y i (c) of the food source i is changed to be y i (c+1), otherwise y i (c) is kept as it is. As mentioned before, every food source has only one employed bee; therefore, the number of employed bees is equal to the number of food sources. If the position y i of the food source i cannot be improved through the predetermined number of trials ''limit'' of bees, then the food source i is abandoned and then the employed bee becomes a scout. The scout starts to search for a new food source randomly, and after finding the new one, the new position is accepted to be y i (c+1).</p><p>The ABC algorithm has three control parameters: colony size (number of employed bees or food source positions), maximum cycle number or iteration number, and the limit value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Definition of the problem</head><p>Consider the IIR filter with the input-output relationship governed by</p><formula xml:id="formula_2">yðkÞ þ X M i¼1 a i yðk À iÞ ¼ X L i¼0 b i xðk À iÞ<label>(3)</label></formula><p>where x(k) and y(k) are the filter's input and output, respectively, and M (XL) is the filter order. The transfer function of this IIR filter can be written in the following general form:</p><formula xml:id="formula_3">HðzÞ ¼ BðzÞ AðzÞ ¼ P L i¼0 b i z Ài 1 þ P M i¼1 a i z Ài (4)</formula><p>Hence, the design of this filter can be considered as a minimization problem of the cost function J(w) stated as the following: min w2W</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>JðwÞ</head><p>(5</p><formula xml:id="formula_4">)</formula><p>where w ¼ ½b 0 b 1 . . . b L a 1 a 2 . . . a M T is the filter coefficient vector.</p><p>The aim is to minimize the cost function J(w) by adjusting w. The cost function is usually expressed as the time-averaged cost function defined by</p><formula xml:id="formula_5">JðwÞ ¼ 1 N X N k¼1 ðdðkÞ À yðkÞÞ 2 (6)</formula><p>where d(k) and y(k) are the desired and actual responses of the filter, respectively, and N is the number of samples used for the calculation of cost function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Simulation results</head><p>In this section, firstly the performance of the ABC algorithm is compared with that of the PSO algorithm and its improved version EPSO on a set of numeric test functions; and secondly LSQ-nonlin, PSO, and ABC algorithms are applied to the design of low-and high-order digital IIR filters for the purpose of system identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Numeric function optimization</head><p>Four functions (F1-F4) presented in Table <ref type="table" target="#tab_0">1</ref> have been used by Miranda and Fonseca to demonstrate the superiority of EPSO over the classic PSO <ref type="bibr" target="#b22">[23]</ref>. These functions are as follows:</p><p>F1 (Sphere): The first function is smooth, unimodal, strongly convex, and symmetric. F2 (Banana): Rosenbrock's valley is a classic optimization function, also known as Banana function. The global optimum is inside a long, narrow, parabolic shaped flat valley. To find the valley is trivial, however, convergence to the global optimum is difficult and hence this problem has been repeatedly used to assess the performance of optimization algorithms.</p><p>F3 (Schaffer): This function is the two-dimensional Schaffer's function. F4 (Alpine): This function is interesting for testing the search of an extremum since there are many local extrema depending on x max while there is only one global extrema.</p><p>To demonstrate the superiority of the ABC algorithm over the classic PSO and EPSO, the average number of evaluations that three algorithms need to reach the stopping criterion are compared. The maximum number of evaluations was fixed in 200,000 and the average number of evaluations to meet the stopping criterion is presented in Table <ref type="table" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head><formula xml:id="formula_6">100ðx iþ1 À x 2 i Þ 2 þ ðx i À 1Þ 2 0px i p30 100 F3 0:5 þ ðsin ffiffiffiffiffiffiffiffiffi ffi x 2 þy 2 p Þ 2 À0:5 ð1:0þ0:001ðx 2 þy 2 ÞÞ 2 À50px i p50 1.0EÀ10 F4 sinðx 1 Þsinðx 2 Þ ffiffiffiffiffiffiffiffiffi ffi x 1 x 2 p 0px i p100 98.9627</formula><p>The average function values produced by three algorithms for a fixed number of evaluations were also compared. So, considering a number of evaluations of 200,000, the results in Table <ref type="table">3</ref> were obtained.</p><p>The average results of ABC algorithm presented in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref> were obtained for 30 runs. For every run, the initial population was randomly created by means of using different seed numbers. The results belonging to the ABC algorithm in Tables <ref type="table" target="#tab_1">2</ref> and<ref type="table">3</ref> were achieved using the following parameter values: colony size ¼ 20; limit value ¼ 20D. From Table <ref type="table" target="#tab_1">2</ref>, it is seen that the convergence speed of ABC is better than PSO and EPSO for F1, F2, and F4. For F3, ABC is better than PSO but worse than EPSO. In terms of the quality of solutions found after 200,000 evaluations, the ABC algorithm outperforms PSO and EPSO on F1 and F2 functions. On F3 and F4 functions, EPSO and ABC produce similar performances. Consequently, compared with PSO and EPSO, ABC shows better or similar performance on the set of test functions considered in <ref type="bibr" target="#b22">[23]</ref>. Particularly, the performance of ABC becomes much clearer on the functions with many variables such as F1 and F2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Digital IIR filter design</head><p>Application of IIR filter in system identification has been widely studied since many problems encountered in signal processing can be characterized as a system identification problem (Fig. <ref type="figure" target="#fig_1">2</ref>). Therefore, in the simulation study, IIR filters are designed for the system identification purpose. In this case, the parameters of the filters are successively adjusted by the ABC algorithm until the error between the output of the filter and the unknown system is minimized. The filter coefficients are encoded in the string form as shown in Fig. <ref type="figure" target="#fig_2">3</ref>. The fitness value of a solution i in the population is determined by using the following formula: where J(w) i is the cost function value computed for the solution i and k the number of the poles outside the unit circle. Using this fitness function, the poles of the IIR filters being designed by algorithms are forced to move into the unit circle. Hence, the IIR filters of which the stability condition is satisfied are produced at the end of each run. Simulation results were carried out on four filter examples. The first two examples (low-order IIR filters) used in the simulation studies were taken from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27]</ref> and the third one from <ref type="bibr" target="#b26">[27]</ref>. The results of the ABC-based method were compared with that of LSQ-nonlin which is a conventional optimization algorithm and PSO. LSQ-nonlin is a nonlinear least-squares data fitting algorithm <ref type="bibr" target="#b27">[28]</ref>, more specifically the algorithm implemented in the Optimization Toolbox of Matlab.</p><formula xml:id="formula_7">fitðiÞ ¼ 1 k þ JðwÞ i<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head><p>In order to carry out the comparison of the algorithms in similar conditions, the values of the similar control parameters of the algorithms were chosen to be equal to each other. For example; swarm size and colony size of the algorithms were equal to each other. Table <ref type="table" target="#tab_2">4</ref> shows the control parameter values used for PSO and ABC algorithms in the first two IIR filter design examples. In the table, X min and X max represent the minimum and maximum limit values of the filter parameters.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head><formula xml:id="formula_8">f 1 ¼ 2, f 2 ¼ 2, w ¼ 0.8 limit value ¼ 40 Iteration ¼ 100 Iteration ¼ 100 X max ¼ 2, X min ¼ À2 V max ¼ 0.15X max X max ¼ 2 V min ¼ 0.15X min X min ¼ À2</formula><p>Example 1. In the first example, the unknown plant and the filter had the following transfer functions:</p><formula xml:id="formula_9">H½z À1 ¼ 1 1 À 1:2z À1 þ 0:6z À2 ; H M ½z À1 ¼ 1 1 À a 1 z À1 À a 2 z À2<label>(8)</label></formula><p>The input, x(k), to the system and the filter was a white sequence. Since the filter order is equal to the system order, a local minima problem does not occur. Fig. <ref type="figure" target="#fig_3">4</ref> presents the error surface for this filter. Fig. <ref type="figure">5</ref> shows the evolution of the mean-square-error (MSE) averaged over 50 different runs of LSQ-nonlin, ABC, and PSO. Each run had a randomly chosen initial w. Fig. <ref type="figure">6</ref> also demonstrates the evolution of parameters for a run.</p><p>Example 2. In the second example, the plant was a second-order system and the filter was a first-order IIR filter with the following transfer functions:</p><formula xml:id="formula_10">H½z À1 ¼ 0:05 À 0:4z À1 1:0 À 1:1314z À1 þ 0:25z À2 ; H M ½z À1 ¼ b 1 À az À1<label>(9)</label></formula><p>The system input was a uniform white sequence. The data length used in calculating the MSE was N ¼ 100. Since the reduced order filter is employed the MSE is multi-modal. The error surface is given in Fig. <ref type="figure" target="#fig_5">7</ref>. Fig. <ref type="figure" target="#fig_6">8</ref> presents the cost-function value versus number of cost-function evaluations averaged over 50 random runs. Each run had a randomly chosen initial w as in the first example. Fig. <ref type="figure">9</ref> presents the evolution of both parameters for a run.</p><p>Example 3. In the third example, the plant was a sixth-order system and had the transfer function <ref type="bibr" target="#b28">[29]</ref>: The IIR filter was the fourth-order and had the following transfer function:</p><formula xml:id="formula_11">H½z À1 ¼ 1 À 0:4z À2 À 0:65z À4 þ 0:26z À6 1 À 0:77z À2 À 0:8498z À4 þ 0:6486z À6 ARTICLE IN PRESS</formula><formula xml:id="formula_12">H M ½z À1 ¼ b 0 þ b 1 z À1 þ b 2 z À2 þ b 3 z À3 þ b 4 z À4 1 þ a 1 z À1 þ a 2 z À2 þ a 3 z À3 þ a 4 z À4<label>(10)</label></formula><p>Since the system was a sixth-order system and the filter fourth order, the error surface is not unimodal as in the second example. The system input was a uniform white sequence   the poles and the zeros of the stable filter designed with the minimum MSE value by using the parameter values given in Table <ref type="table" target="#tab_3">5</ref> for algorithms. The control parameter values employed in this example were the same as in the first two examples except the iteration number and limit value. In this example, the algorithms were run for 500 iterations and limit value for ABC was 180. Example 4. In the fourth example, the unknown plant was a 24th-order system and the IIR filter to be designed was the 20th order. Both of them had the following transfer function:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head><formula xml:id="formula_13">H½z À1 ¼ b 0 þ b 1 z À1 þ b 2 z À2 þ Á Á Á þ b ðLÀ1Þ z ðLÀ1Þ þ b L z L 1 þ a 1 z À1 þ a 2 z À2 þ Á Á Á þ a ðMÀ1Þ z ðMÀ1Þ þ a M z M<label>(11)</label></formula><p>The coefficients of the unknown plant are given in the first two columns of Table <ref type="table" target="#tab_4">6</ref>. Since the system was 24th order and the filter 20th order, the error surface is not unimodal. The system input was a uniform white sequence and the data length in calculating the MSE was N ¼ 1000 in this example. Fig. <ref type="figure" target="#fig_9">14</ref>   cost-function iterations averaged over 50 random runs. Fig. <ref type="figure" target="#fig_10">15</ref> demonstrates the positions and zeros of the stable filters with the minimum MSE value designed by using the parameter values given in Table <ref type="table" target="#tab_4">6</ref> for each algorithm. The control parameter values employed in this example were the same as in the first three examples except the iteration number and limit value. In this example, the algorithms were run for 1000 iterations and limit value for ABC was 1000.</p><p>From Figs. <ref type="figure">5</ref> and<ref type="figure" target="#fig_6">8</ref>, it is seen that the ABC algorithm can design an acceptable filter only after 10 iterations. From the figures, it is also clear that although PSO seems more quick through the first iterations, it has problem with the fine tuning of the parameters due to its poor local search ability. For the LSQ-nonlin, it can be concluded that it often fails while discovering the global minimum in Example 2.</p><p>For the high-order filter examples, as expected, the algorithms require more iterations to design an acceptable filter. For the third example, the ABC algorithm needs about 100 cycles, PSO does 250 iterations and LSQ-nonlin needs more than 500 iterations for designing a stable filter having similar performance. From Figs. <ref type="figure" target="#fig_0">11</ref> and<ref type="figure" target="#fig_1">12</ref>, it is very clear that the fine tuning ability of ABC is much better than PSO. In the case of ABC, the values It is a known fact that the control parameters of an optimization algorithm might affect its performance significantly. Therefore, in order to investigate how much the proposed design method is affected by the control parameters limit value and colony size of ABC, more simulations were carried out on the filter examples. Firstly, for each example, the algorithm was run 50 times for each colony size: 10, 20, 40, and 80. The mean MSE values and standard deviations calculated are presented in Table <ref type="table" target="#tab_6">8</ref>. In all cases, the total evaluation number was 10,000. It means that iteration number was 1000 for the colony size 10, 500 for 20, 250 for 40 and 125 for 80. Notice that in the case of the first example MSE value is very small since it is a unimodal problem. From Table <ref type="table" target="#tab_6">8</ref>, it can be concluded that when the colony size increases or decreases too much and total evaluation number is fixed, the performance might get worse. Therefore, an appropriate value for colony size should be assigned. For the examples considered in this work, the appropriate value for this control parameter should be between 20 and 40. MSE and SD values computed for different limit values when the colony size and the iteration number are fixed are presented in Table <ref type="table" target="#tab_7">9</ref>. As in previous simulations, the algorithm was run 50 times using different seed numbers for each limit value. From Table <ref type="table" target="#tab_7">9</ref>, it can be said that the limit value should be at least equal to 100. Otherwise, the algorithm is not able to make the fine tuning process sufficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head><p>In Table <ref type="table" target="#tab_8">10</ref>, the computation times required for a run by the algorithms for each example are presented. It is clear that the LSQ-nonlin algorithm needs less time as compared with PSO and ABC. However, its performance highly depends on the initial solution. If it converges to a local minimum, it cannot get out of this region even if maximum iteration number is increased and not design an acceptable filter. Therefore, it might be necessary for the algorithm to be run several times with different initial solutions to design a filter satisfying required features. However, the ABC-based method can produce an acceptable filter for each run. From the table, it is seen that the computation time of the ABC method is less than PSO. Notice that as the order of the filters increases, the difference between the computation times of LSQ-nonlin and ABC methods decreases. Consequently, ABC is a new population-based algorithm and it has the advantages of finding the true global minimum of a multi-modal search space regardless of the initial parameter values, fast convergence, being simple and flexible, and using very few control parameters. In this work, a new design method for digital IIR filters, which is based on the ABC algorithm, was described. The new method produced good solutions to both the unimodal and multi-modal filter cases. From the simulation results obtained for the test functions and the filter examples, it can be stated that, particularly in terms of the final solution the performance of ABC is better than that of PSO and LSQ-nonlin due to its good global and local search ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ARTICLE IN PRESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>A new design method based on the artificial bee colony algorithm was introduced for designing low-and high-order digital IIR filters. The performance of the proposed method was compared with that of a well-known conventional optimization algorithm and particle swarm optimization algorithm on unimodal and multi-model IIR filter design problems for the system identification purpose. From the simulation results, it was observed that the method based on the artificial bee colony algorithm seems as an alternative approach for designing digital low-and high-order IIR filters. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flow chart of the ABC algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Block diagram of system identification process using the IIR filter designed by the ABC algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Representation of a solution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Error surface for the first filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Cost-function value versus number of iterations averaged over 50 random runs for LSQ-nonlin, PSO, and ABC algorithms (Example 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Error surface for the second filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Cost-function value versus number of evaluations averaged over 50 random runs for LSQ-nonlin, PSO, and ABC (Example 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig. 9. Evolution of the parameters of the second filter for PSO and ABC algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .Fig. 12 .Fig. 13 .</head><label>111213</label><figDesc>Fig. 11. Evolution of the denominator parameters of the high-order filter for both algorithms: (a) PSO and (b) ABC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Cost-function value versus number of evaluations averaged over 50 random runs for LSQ-nonlin, PSO, and ABC (Example 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The pole-zero positions of the filters with the minimum MSE designed by algorithms: (a) ABC algorithm, (b) PSO algorithm, and (c) LSQ-nonlin algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Test functions and stopping criteria.</figDesc><table><row><cell>Function number</cell><cell cols="2">Function</cell><cell>Limits</cell><cell>Stopping criterion</cell></row><row><cell>F1</cell><cell>P 30</cell><cell>i x 2</cell><cell>À50px i p50</cell><cell>0.01</cell></row><row><cell></cell><cell>i¼1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>F2</cell><cell>P 30</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>i¼1</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Comparison of ABC with the classical PSO and EPSO.</figDesc><table><row><cell>Function</cell><cell>PSO</cell><cell>EPSO</cell><cell>ABC</cell></row><row><cell>F1</cell><cell>161625.0</cell><cell>16421.4</cell><cell>6113.6</cell></row><row><cell>F2</cell><cell>180310.8</cell><cell>27005.3</cell><cell>10135.2</cell></row><row><cell>F3</cell><cell>59547.0</cell><cell>11862.2</cell><cell>51202.4</cell></row><row><cell>F4</cell><cell>199190.1</cell><cell>78539.8</cell><cell>5125.3</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Comparison of ABC with the classical PSO and EPSO.</cell><cell></cell><cell></cell></row><row><cell>Function</cell><cell>PSO</cell><cell>EPSO</cell><cell>ABC</cell></row><row><cell>F1</cell><cell>1.91EÀ02</cell><cell>7.81EÀ04</cell><cell>2.486EÀ16</cell></row><row><cell>F2</cell><cell>114.443</cell><cell>33.8828</cell><cell>4.391669</cell></row><row><cell>F3</cell><cell>5.45EÀ11</cell><cell>2.15EÀ13</cell><cell>2.5EÀ12</cell></row><row><cell>F4</cell><cell>86.1071</cell><cell>98.9627</cell><cell>98.9627</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Control parameter values of the algorithms used for the first two examples.</figDesc><table><row><cell>PSO algorithm</cell><cell>ABC algorithm</cell></row><row><cell>Swarm size ¼ 20</cell><cell>Colony size ¼ 20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>The values found by LSQ-nonlin, ABC, and PSO algorithms for the coefficients of the filter designed with the minimum MSE in Example 3.</figDesc><table><row><cell>Coefficients</cell><cell>ABC (0.0015)</cell><cell>PSO (0.0056)</cell><cell>LSQ-nonlin (0.0008)</cell></row><row><cell>a 1</cell><cell>0.086</cell><cell>0.086</cell><cell>0.0008</cell></row><row><cell>a 2</cell><cell>À0.066</cell><cell>À0.067</cell><cell>À0.0048</cell></row><row><cell>a 3</cell><cell>À0.078</cell><cell>À0.078</cell><cell>À0.0023</cell></row><row><cell>a 4</cell><cell>À0.798</cell><cell>À0.798</cell><cell>À0.8597</cell></row><row><cell>b 0</cell><cell>0.995</cell><cell>1.000</cell><cell>0.9994</cell></row><row><cell>b 1</cell><cell>0.103</cell><cell>0.119</cell><cell>0.0003</cell></row><row><cell>b 2</cell><cell>0.282</cell><cell>0.286</cell><cell>0.3414</cell></row><row><cell>b 3</cell><cell>À0.073</cell><cell>À0.067</cell><cell>À0.0044</cell></row><row><cell>b 4</cell><cell>À0.347</cell><cell>À0.339</cell><cell>À0.3940</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6</head><label>6</label><figDesc>The coefficients of the unknown plant and IIR filters with the minimum MSE value designed by the algorithms.of the filter parameters converge to their final values very quickly and smoothly. For Example 4, ABC is able to design acceptable filters around 1000 iterations and continuously can improve the solutions. PSO needs more iterations for convergence and LSQ-nonlin cannot improve the solutions after a certain number of iterations although it seems quite quicker through the first iterations. For all examples, the MSE values obtained by the algorithms after 50 runs and the standard deviations (SD) calculated are given in Table7. From Table7, it is clear that LSQ-nonlin has the highest MSE and SD values for the examples. This is because the conventional technique LSQ-nonlin has a serious problem with the local minima. Its performance highly depends on the initial solution. This is a result expected from a gradient-based optimization algorithm. The proposed method produces the minimum MSE and SD values. This shows that the ABC algorithm is more robust than other two algorithms. It means that its performance does not depend on initialization process too much.</figDesc><table><row><cell></cell><cell cols="2">Unknown plant</cell><cell>ABC</cell><cell></cell><cell>PSO</cell><cell></cell><cell cols="2">LSQ-nonlin</cell></row><row><cell></cell><cell cols="2">(elliptic filter)</cell><cell cols="2">(MSE ¼ 0.0199)</cell><cell cols="2">(MSE ¼ 0.0232)</cell><cell cols="2">(MSE ¼ 0.0129)</cell></row><row><cell>Coefficients</cell><cell>b</cell><cell cols="2">a(1.0 e+003) b</cell><cell>a</cell><cell>b</cell><cell>a</cell><cell>b</cell><cell>a</cell></row><row><cell>1</cell><cell>0.0006</cell><cell>0.0010</cell><cell>0.1089</cell><cell>1</cell><cell>À0.0385</cell><cell>1</cell><cell></cell><cell>0.0084 1</cell></row><row><cell>2</cell><cell cols="2">0.0029 À0.0043</cell><cell>À0.1032</cell><cell cols="3">0.0030 À0.0436 À0.3104</cell><cell></cell><cell>0.0154 0.6738</cell></row><row><cell>3</cell><cell>0.0122</cell><cell>0.0182</cell><cell cols="2">0.0094 À0.0001</cell><cell>0.0256</cell><cell>0.2274</cell><cell></cell><cell>0.0269 0.7790</cell></row><row><cell>4</cell><cell cols="2">0.0355 À0.0502</cell><cell>0.0877</cell><cell>0.3539</cell><cell>0.0413</cell><cell>0.1045</cell><cell></cell><cell>0.0905 0.6790</cell></row><row><cell>5</cell><cell>0.0913</cell><cell>0.1271</cell><cell cols="2">0.1558 À0.0186</cell><cell cols="2">0.0933 À0.0022</cell><cell></cell><cell>0.2298 0.6279</cell></row><row><cell>6</cell><cell cols="2">0.1942 À0.2615</cell><cell>0.1275</cell><cell>0.1636</cell><cell>0.1804</cell><cell>0.2759</cell><cell></cell><cell>0.4118 0.3461</cell></row><row><cell>7</cell><cell>0.3700</cell><cell>0.4894</cell><cell>0.1304</cell><cell>0.0255</cell><cell>0.2000</cell><cell>0.2618</cell><cell></cell><cell>0.5751 0.4206</cell></row><row><cell>8</cell><cell cols="2">0.6202 À0.7995</cell><cell cols="2">0.0702 À0.1489</cell><cell>0.0501</cell><cell>0.2305</cell><cell></cell><cell>0.6457 0.4827</cell></row><row><cell>9</cell><cell>0.9425</cell><cell>1.1928</cell><cell cols="3">À0.0564 À0.0891 À0.0680</cell><cell>0.0515</cell><cell></cell><cell>0.5723 0.5886</cell></row><row><cell>10</cell><cell cols="2">1.2912 À1.5988</cell><cell>À0.0484</cell><cell cols="2">0.1535 À0.1167</cell><cell>0.2371</cell><cell></cell><cell>0.3912 0.4645</cell></row><row><cell>11</cell><cell>1.6161</cell><cell>1.9647</cell><cell cols="4">0.0691 À0.0538 À0.0446 À0.0458</cell><cell></cell><cell>0.2375 0.4755</cell></row><row><cell>12</cell><cell cols="2">1.8434 À2.1971</cell><cell>0.1356</cell><cell>0.0733</cell><cell>0.1068</cell><cell>0.0588</cell><cell></cell><cell>0.2270 0.4541</cell></row><row><cell>13</cell><cell>1.9280</cell><cell>2.2563</cell><cell>0.0725</cell><cell>0.1684</cell><cell>0.2162</cell><cell>0.1007</cell><cell></cell><cell>0.3214 0.4625</cell></row><row><cell>14</cell><cell cols="2">1.8434 À2.1174</cell><cell cols="2">0.0391 À0.2447</cell><cell>0.1235</cell><cell>0.0706</cell><cell></cell><cell>0.3779 0.3147</cell></row><row><cell>15</cell><cell>1.6161</cell><cell>1.8223</cell><cell cols="4">À0.3083 À0.0030 À0.0461 À0.1110</cell><cell></cell><cell>0.3200 0.2092</cell></row><row><cell>16</cell><cell cols="2">1.2912 À1.4298</cell><cell>À0.0496</cell><cell cols="2">0.2592 À0.0883</cell><cell>0.0597</cell><cell></cell><cell>0.2154 0.1145</cell></row><row><cell>17</cell><cell>0.9425</cell><cell>1.0239</cell><cell cols="3">0.0441 À0.0385 À0.0249</cell><cell>0.2294</cell><cell></cell><cell>0.1509 0.1153</cell></row><row><cell>18</cell><cell cols="2">0.6202 À0.6619</cell><cell cols="3">0.1359 À0.1967 À0.0462</cell><cell>0.0539</cell><cell></cell><cell>0.1239 0.0799</cell></row><row><cell>19</cell><cell>0.3700</cell><cell>0.3867</cell><cell>À0.0473</cell><cell cols="2">0.0681 À0.0371</cell><cell>0.0427</cell><cell></cell><cell>0.0757 0.0527</cell></row><row><cell>20</cell><cell cols="2">0.1942 À0.1994</cell><cell>À0.0396</cell><cell cols="3">0.0532 À0.0378 À0.0270</cell><cell></cell><cell>0.0143 0.0899</cell></row><row><cell>21</cell><cell>0.0913</cell><cell>0.0914</cell><cell cols="2">À0.5000 À0.0850</cell><cell>0.0158</cell><cell cols="3">0.0563 À0.0127 0.2193</cell></row><row><cell>22</cell><cell cols="2">0.0355 À0.0350</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>23</cell><cell>0.0122</cell><cell>0.0116</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>24</cell><cell cols="2">0.0029 À0.0027</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>25</cell><cell>0.0006</cell><cell>0.0005</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>The average MSE and SD values obtained by algorithms for the examples.</figDesc><table><row><cell></cell><cell>ABC</cell><cell>PSO</cell><cell>LSQ-nonlin</cell></row><row><cell>Example 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>0.0000</cell><cell>0.0002</cell><cell>0.0573</cell></row><row><cell>SD</cell><cell>0.0000</cell><cell>0.0001</cell><cell>0.0717</cell></row><row><cell>Example 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>0.0610</cell><cell>0.0646</cell><cell>0.2563</cell></row><row><cell>SD</cell><cell>0.0121</cell><cell>0.0185</cell><cell>0.1178</cell></row><row><cell>Example 3</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>0.0015</cell><cell>0.0056</cell><cell>0.0420</cell></row><row><cell>SD</cell><cell>0.0005</cell><cell>0.0018</cell><cell>0.0611</cell></row><row><cell>Example 4</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>0.0421</cell><cell>0.0764</cell><cell>0.1140</cell></row><row><cell>SD</cell><cell>0.0186</cell><cell>0.0219</cell><cell>0.0966</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>MSE and SD values calculated for different colony sizes when the total evaluation number is fixed.</figDesc><table><row><cell>Colony size</cell><cell>Example 1</cell><cell>Example 2</cell><cell>Example 3</cell><cell>Example 4</cell></row><row><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>5.1410 Â 10 À16</cell><cell>0.0706</cell><cell>0.0144</cell><cell>0.1409</cell></row><row><cell>SD</cell><cell>6.2527 Â 10 À16</cell><cell>0.0021</cell><cell>0.0069</cell><cell>0.0940</cell></row><row><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>1.4861 Â 10 À14</cell><cell>0.0697</cell><cell>0.0112</cell><cell>0.1226</cell></row><row><cell>SD</cell><cell>3.8353 Â 10 À14</cell><cell>0.0014</cell><cell>0.0039</cell><cell>0.0638</cell></row><row><cell>40</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>2.5644 Â 10 À7</cell><cell>0.0684</cell><cell>0.0142</cell><cell>0.1277</cell></row><row><cell>SD</cell><cell>6.4913 Â 10 À7</cell><cell>0.0016</cell><cell>0.0045</cell><cell>0.0244</cell></row><row><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MSE</cell><cell>7.6973 Â 10 À6</cell><cell>0.076</cell><cell>0.0195</cell><cell>0.1496</cell></row><row><cell>SD</cell><cell>8.8152 Â 10 À6</cell><cell>0.0018</cell><cell>0.0040</cell><cell>0.0380</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc>MSE and SD values calculated for different limit values when the iteration number and colony size are fixed.</figDesc><table><row><cell>Limit</cell><cell>Example 1</cell><cell>Example 2</cell><cell>Example 3</cell><cell>Example 4</cell></row><row><cell>value</cell><cell>(iteration ¼ 100)</cell><cell>(iteration ¼ 100)</cell><cell>(iteration ¼ 500)</cell><cell>(iteration ¼ 1000)</cell></row><row><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">MSE 0.0233</cell><cell>0.0690</cell><cell>0.1106</cell><cell>0.5260</cell></row><row><cell>SD</cell><cell>0.0029</cell><cell>0.0018</cell><cell>0.0341</cell><cell>0.7701</cell></row><row><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">MSE 0.0022</cell><cell>0.0666</cell><cell>0.0971</cell><cell>0.1054</cell></row><row><cell>SD</cell><cell>0.0004</cell><cell>0.0021</cell><cell>0.0288</cell><cell>0.0768</cell></row><row><cell>500</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">MSE 0.0021</cell><cell>0.0674</cell><cell>0.1175</cell><cell>0.1295</cell></row><row><cell>SD</cell><cell>0.0003</cell><cell>0.0015</cell><cell>0.0453</cell><cell>0.0826</cell></row><row><cell>1000</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">MSE 0.0020</cell><cell>0.0687</cell><cell>0.1093</cell><cell>0.0917</cell></row><row><cell>SD</cell><cell>0.0004</cell><cell>0.0021</cell><cell>0.0287</cell><cell>0.0646</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10</head><label>10</label><figDesc>Computation times required for each run by the algorithms (in s).</figDesc><table><row><cell></cell><cell>Max iteration number</cell><cell>ABC</cell><cell>PSO</cell><cell>LSQ-nonlin</cell></row><row><cell>Example 1</cell><cell>100</cell><cell>1.2200</cell><cell>4.2400</cell><cell>0.4850</cell></row><row><cell>Example 2</cell><cell>100</cell><cell>2.9400</cell><cell>4.9100</cell><cell>0.8690</cell></row><row><cell>Example 3</cell><cell>500</cell><cell>4.9000</cell><cell>7.0820</cell><cell>2.3290</cell></row><row><cell>Example 4</cell><cell>1000</cell><cell>26.3250</cell><cell>28.3600</cell><cell>16.0940</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>N.Karaboga  / Journal of the Franklin Institute 346 (2009) 328-348</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spectral-subtraction speech enhancement in multirate systems with and without non-uniform and adaptive bandwidths</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gulzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Heute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="1613" to="1631" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Processing arbitrary-length signals with linear-phase cosine-modulated filter banks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kliewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1515" to="1533" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Design of IIR digital filters based on eigenvalue problem</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwakura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1325" to="1333" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal design of IIR digital filters with robust stability using conic-quadraicprogramming updates</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hinamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1581" to="1592" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive IIR filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Shynk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ASSP Magazine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="4" to="21" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Error surface of recursive adaptive filters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Stearns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="763" to="766" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive IIR filtering of nonstationary signals</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radenkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="183" to="195" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Genetic and annealing approaches to adaptive digital filtering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nambiar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 26th Asilomar Conference on Signals, Systems and Computers</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="871" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Design of multidimensional finite-wordlength FIR and IIR filters by simulated annealing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Radecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dubois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="424" to="431" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Digital IIR filter design using adaptive simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Istepanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Luk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="241" to="251" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recursive adaptive filter design using an adaptive genetic algorithm</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Etter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on ASSP</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="635" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Genetic algorithms and their applications</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="22" to="37" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The genetic search approach: a new learning algorithm for IIR filtering</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="38" to="46" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Design of 2-D multiplierless IIR filters using the genetic algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thamvichai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Haupt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems-I: Fundamental Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="878" to="882" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Design of 1-D FIR filters with genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jullien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Lashkari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Circuits and Systems</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="295" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Design of two dimensional recursive filters using genetic algorithms</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Mastorakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">F</forename><surname>Gonos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N S</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems-I: Fundamental Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="634" to="639" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Digital IIR filter design using differential evolution algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karaboga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Applied Signal Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Design of digital FIR filters by using differential evolution algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cetinkaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circuits Systems and Signal Processing Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<title level="m">Fundamentals of Computational Swarm Intelligence</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1995 IEEE International Conference on Neural Networks</title>
		<meeting>the 1995 IEEE International Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Filter approximation using explicit time and frequency domain specifications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">O</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">M</forename><surname>O'reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Annual Conference on Genetic and Evolutionary Computation</title>
		<meeting>the Eighth Annual Conference on Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FIR filter design: frequency sampling filters by particle swarm optimization algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Machine Learning and Cybernetics</title>
		<meeting>the Third International Conference on Machine Learning and Cybernetics</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="2322" to="2327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">New evolutionary particle swarm algorithm (EPSO) applied to voltage/VAR control</title>
		<author>
			<persName><forename type="first">V</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fonseca</surname></persName>
		</author>
		<ptr target="http://www.pscc02.org/papers/s21pos.pdfS" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Power Systems Computation Conference</title>
		<meeting>the 14th Power Systems Computation Conference<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">An idea based on honey bee swarm for numerical optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<idno>-TR06</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Erciyes University, Engineering Faculty, Computer Engineering Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">An artificial bee colony (ABC) algorithm for numeric function optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>IEEE Swarm Intelligence Symposium</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive simulated annealing for optimisation in signal processing applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Luk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Alternatives to neural networks for inferential measurement</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ponton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klemes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="42" to="47" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adaptive recursive filtering using evolutionary algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Flockton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Algorithms in Engineering Applications</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Dasgupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="361" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">D. degrees in electronics engineering from the Erciyes University, Turkey, in 1987, 1990, and 1995, respectively. From 1987 to 1995, she was a research assistant in the department of electronics engineering at the Erciyes University. Currently, she is an associated professor at the same department. From 1992 to 1994, she also worked as an academic visitor in the University of Wales College of Cardiff, UK. Her current research interests include genetic algorithms, ant colony algorithms</title>
		<imprint>
			<publisher>Nurhan Karaboga received the B.S., M.S., and Ph</publisher>
		</imprint>
	</monogr>
	<note>simulated annealing algorithm, differential evolution algorithm, immune algorithm, digital filter design, and data communication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
