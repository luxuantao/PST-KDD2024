<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Collaborative Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-06-02">2 Jun 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hanxiong</forename><surname>Chen</surname></persName>
							<email>hanxiong.chen@rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shaoyun</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yunqi</forename><surname>Li</surname></persName>
							<email>yunqi.li@rutgers.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
							<email>yongfeng.zhang@rutgers.edu</email>
							<affiliation key="aff3">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Collaborative Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-06-02">2 Jun 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2005.08129v2[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Collaborative Filtering</term>
					<term>Recommender Systems</term>
					<term>Neural-Symbolic Learning</term>
					<term>Neural Logic Reasoning</term>
					<term>Collaborative Reasoning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Collaborative Filtering (CF) has been an important approach to recommender systems. However, existing CF methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the relevance patterns in data, so that a user embedding can be matched with appropriate item embeddings using designed or learned similarity functions. We argue that as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of logical reasoning in the data.</p><p>Inspired by recent progress on neural-symbolic machine learning, we propose a framework to integrate the power of embedding learning and logical reasoning, where the embeddings capture similarity patterns in data from perceptual perspectives, and the logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a Modularized Logical Neural Network architecture, which learns basic logical operations such as AND, OR, and NOT as neural modules based on logical regularizer, and learns logic variables as vector embeddings. In this way, each logic expression can be equivalently organized as a neural network, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on several real-world datasets verified the advantages of our framework compared with both traditional shallow and deep models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Collaborative Filtering (CF) is an important approach to recommender systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b37">38]</ref>. By leveraging the wisdom of crowd, CF methods predict a user's future preferences based on his or her previous records. Many existing CF methods are designed based on the fundamental idea of similarity matching, with either designed or learned matching functions, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>(a). For example, early CF algorithms, such as User-based CF <ref type="bibr" target="#b36">[37]</ref> and Itembased CF <ref type="bibr" target="#b40">[41]</ref>, consider the row and column vectors in the original user-item rating matrix as the user and item representations (i.e., Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, and collaborations, contact the owner/authors(s). © 2020 Copyright held by the owner/author(s). embedding), and a manually designed weighted average function is used as the matching function f (•) to calculate the relevance score between each user u and a candidate item v. The advance of machine learning has further extended CF methods for improved accuracy. One prominent example is Matrix Factorization (MF) techniques for CF <ref type="bibr" target="#b24">[25]</ref>, which takes inner product as the matching function f (•), and learns the user and item embeddings in the inner product space to fit ground-truth user-item interactions.</p><p>Researchers have further explored CF algorithms under the similarity matching framework. One approach is to learn better embeddings. For example, context-aware CF integrates context information such as time and location to learn informative embeddings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24]</ref>, and various heterogeneous information sources can be used to enrich the embeddings <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b49">50]</ref>, such as text <ref type="bibr" target="#b50">[51]</ref>, image <ref type="bibr" target="#b13">[14]</ref>, and knowledge graphs <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b47">48]</ref>. We can also explicitly consider a user's behavior history to learn better embeddings (Figure <ref type="figure" target="#fig_1">1(b)</ref>), such as in sequential recommendation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16]</ref>. Another approach is to use better matching functions. For example, use vector translation instead inner product for similarity matching <ref type="bibr" target="#b12">[13]</ref>, or learn a distance function in linear space based on metric learning <ref type="bibr" target="#b17">[18]</ref>, or even learn a universal matching function in non-linear space based on neural networks <ref type="bibr" target="#b14">[15]</ref>.</p><p>Similarity matching-based CF methods have been successful in many real-world recommender systems. However, as a cognition rather than a perception task, recommendation requires not only the ability of pattern learning and matching, but also the ability of cognitive reasoning, because a user's future behavior may not be simply driven by its similarity with the user's previous behaviors, but instead by the user's cognitive reasoning procedure about what to do next. For example, if a user has purchased a laptop before, this does not lead to the user purchasing similar laptops in the future, rather, one would expect the user to purchase further equipment such as a laptop bag. Such a reasoning procedure may exhibit certain logical structures, such as (a ∨b) ∧ ¬c → v, as shown in Figure <ref type="figure" target="#fig_1">1(c)</ref>, which means that if the user likes a or b, and does not like c, then he/she would probability like v. The AI community has realized the importance of advancing AI techniques from perception to cognition tasks <ref type="bibr" target="#b1">[2]</ref>. As a representative cognitive reasoning task, we hope an intelligent recommendation system would be able to discover and leverage the logical relations in data, so as to reason over the data for the prediction of user's future behaviors.</p><p>To achieve this goal, we propose a Neural Logic Recommendation (NLR) framework based on Modularized Logical Neural Networks (MLNN), which integrates the power of embedding learning and logical reasoning in a shared architecture. An example is shown in Figure <ref type="figure" target="#fig_0">1</ref>(c) to illustrate the basic idea. In particular, the model learns each basic logical operation such as AND (∧), OR (∨), and NOT (¬) as a neural module based on logical regularizers. In this way, the recommendation problem can be formalized as estimating the probability that a future behavior v is true given user's previous behaviors, such as (a ∨ b) ∧ ¬c → v in the example. Based on the definition of material implication (→) <ref type="foot" target="#foot_0">1</ref> , this reduces to the T/F evaluation of ¬((a ∨ b) ∧ ¬c) ∨ v, which only includes basic logical operations. As a result, the logical expression can be identically transformed into a neural architecture based on the logical neural modules, as shown in Figure <ref type="figure" target="#fig_0">1</ref>(c), which finally decides the T/F value of the expression. In this way, differentiable neural networks and symbolic reasoning are bridged in a shared architecture for optimization and inference. Although not a main focus of the paper, the framework may also bring better interpretability since the decision making procedure is more transparent.</p><p>To the best of our knowledge, this is one of the first work to bridge logical reasoning and embedding learning for personalized recommendation. The key contributions of our paper are as follows:</p><p>• We propose a novel neural logic recommendation framework to bridge symbolic logical reasoning and continuous embedding learning in a neural architecture. • We introduce logical regularizers as constraints to regularize the behavior of neural networks. • We dynamically construct the network structure according to the given logical expression, which enables logic priors to be added to the neural network structure. • We conduct experiments on several real-world recommendation datasets to analyze the behavior of our framework. In the following, we first review some related work in Section 2. In section 3, we introduce some background knowledge, and then explain the details of our framework in Section 4. We describe the experimental results on different datasets to verify the effectiveness of our approach in Section 5, and finally, Section 6 concludes the work with possible future directions to explore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Collaborative Filtering (CF) has been important approaches to recommender systems. Due to its long-time research history and the wide scope of literature, it is hardly possible to cover all CF algorithms, so we review some representative methods in this section, and a more comprehensive review can be seen in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Early approaches to CF consider the user-item rating matrix and conduct rating prediction with user-based <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b36">37]</ref> or item-based <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41]</ref> collaborative filtering methods. With the development of dimension reduction methods, latent factor models such as matrix factorization are later widely adopted in recommender systems, such as singular value decomposition <ref type="bibr" target="#b24">[25]</ref>, non-negative matrix factorization <ref type="bibr" target="#b25">[26]</ref>, and probabilistic matrix factorization <ref type="bibr" target="#b32">[33]</ref>. In these approaches, each user and item is learned as a latent vector to calculate the matching score of the user-item pairs.</p><p>Recently, the development of deep learning and neural network models has further extended collaborative filtering methods for recommendation. The relevant methods can be broadly classified into two sub-categories: similarity learning approach, and representation learning approach. The similarity learning approach adopts simple user/item representations (such as one-hot) and learns a complex matching function (such as a prediction network) to calculate user-item matching scores <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18]</ref>, while the representation learning approach learns rich user/item representations and adopts a simple matching function (e.g., inner product) for matching score calculation <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. Another important research direction is learning to rank for recommendation, which learns the relative ordering of items instead of the absolute preference scores. The most representative method on this direction is perhaps Bayesian personalized ranking (BPR) <ref type="bibr" target="#b35">[36]</ref>, which is a pair-wise learning to rank method. It is also further generalized to take other information sources such as images <ref type="bibr" target="#b13">[14]</ref>.</p><p>Although many CF approaches have been successfully applied in recommendation tasks, existing methods mostly model recommendation as a perception task based on similarity matching, instead of a cognition task based on logical reasoning. However, users' future behaviors may not be simply driven by the similarity with their previous behavior, but a concrete reasoning procedure about what to do next. Though few research work is seen in the recommendation literature, integrating logical reasoning and neural networks has been considered in other research contexts.</p><p>According to <ref type="bibr" target="#b2">[3]</ref>, connectionism in AI can date back to 1943 <ref type="bibr" target="#b30">[31]</ref>, which is arguably the first neural-symbolic system for Boolean logic. Since then, most neural-symbolic systems focused on representing, computing, and learning languages other than classical propositional logics <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b41">42]</ref>. Neural-symbolic learning has also been applied to knowledge extraction, representation and reasoning tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref>. More recently, it has been shown that argumentation frameworks, abductive reasoning, and normative multi-agent systems can also be represented by neural symbolic frameworks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. It is encouraging to see that a variety of forms of reasoning can be realized by the same framework that specializes in different ways <ref type="bibr" target="#b2">[3]</ref>. Another approach to integrating machine learning and logical reasoning is Markov Logic Networks (MLN) <ref type="bibr" target="#b38">[39]</ref>, which combines probabilistic graphical models with first-order logic. It leverages domain knowledge and logic rules to learn graph structure and conduct inference, which has been shown to be effective for reasoning on knowledge graphs <ref type="bibr" target="#b34">[35]</ref>.</p><p>In a broader sense, the AI community has realized the importance of advancing AI from perception to cognition tasks <ref type="bibr" target="#b1">[2]</ref>, and researchers have been exploring the possibility of integrating deep learning with logical inference <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b45">46]</ref>. However, as far as we know, there has been no work on neural logic reasoning approaches to recommendation systems. As a representative cognition task, we hope future intelligent recommendation systems can model higherlevel cognitive intelligence for informed planning, reasoning, and decision making. </p><formula xml:id="formula_0">NOT Negation ¬T = F r 1 = 1 |X| x∈X 1 + Sim(NOT(x), x) Double Negation ¬(¬x ) = x r 2 = 1 |X| x∈X 1 − Sim(NOT(NOT(x)), x) AND Identity x ∧ T = x r 3 = 1 |X| x∈X 1 − Sim(AND(x, T), x) Annihilator x ∧ F = F r 4 = 1 |X| x∈X 1 − Sim(AND(x, F), F) Idempotence x ∧ x = x r 5 = 1 |X| x∈X 1 − Sim(AND(x, x), x) Complementation x ∧ ¬x = F r 6 = 1 |X| x∈X 1 − Sim(AND(x, NOT(x)), F) OR Identity x ∨ F = x r 7 = 1 |X| x∈X 1 − Sim(OR(x, F), x) Annihilator x ∨ T = T r 8 = 1 |X| x∈X 1 − Sim(OR(x, T), T) Idempotence x ∨ x = x r 9 = 1 |X| x∈X 1 − Sim(OR(x, x), x) Complementation x ∨ ¬x = T r 10 = 1 |X| x∈X 1 − Sim(OR(x, NOT(x)), T) AND/OR Associativity x ∨ (y ∨ z) = (x ∨ y) ∨ z Random Shuffling of Logic Variables x ∧ (y ∧ z) = (x ∧ y) ∧ z commutativity x ∨ y = y ∨ x x ∧ y = y ∧ x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section, we briefly introduce some logical operators and basic laws of logic used in this work. We start from propositional logic, which includes three basic operations: AND (conjunction), OR (disjunction), and NOT (negation). Each variable, such as x, is called a literal. A flat operation over literals, such as (x ∧y), is called a clause, while operations over clauses, such as</p><formula xml:id="formula_1">(x ∧ y) ∨ (a ∧ b ∧ c),</formula><p>is called an expression. Each logical operation should satisfy some basic laws in propositional logic, for example, the double negation law of NOT: ¬(¬x) = x. We list some laws used in our work in Table <ref type="table" target="#tab_0">1</ref>. Another useful law not listed in the table is the De Morgan's Law, which states that:</p><formula xml:id="formula_2">¬(x ∧ y) ⇔ ¬x ∨ ¬y ¬(x ∨ y) ⇔ ¬x ∧ ¬y<label>(1)</label></formula><p>Besides these operations and laws, we need another secondary logical operation x → y, which is called material implication. This operation can be equivalently transformed using basic operations:</p><formula xml:id="formula_3">x → y ⇔ ¬x ∨ y (2)</formula><p>Propositional logic is a very useful language for symbolic reasoning. However, the symbolic nature of the language makes it difficult to be "learned" from data based on continuous optimization. To solve the problem, we borrow the idea of distributed representation learning <ref type="bibr" target="#b31">[32]</ref>, and propose a neural-symbolic framework for logical reasoning in a continuous space. Specifically, each literal x is learned as a vector embedding x, and each logical operation (e.g., ∧) is learned as a neural module (e.g., z = AND(x, y)). As a result, an expression can be organized as a neural architecture (Figure <ref type="figure" target="#fig_1">1(c)</ref>), which evaluates the T/F value of the expression in a latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NEURAL LOGIC RECOMMENDATION</head><p>In this section, we present our Neural Logic Recommendation (NLR) framework, which encapsulates logical reasoning into a dynamic neural architecture. To achieve this goal, we first formalize recommendation into a logical reasoning problem. Then we introduce how to dynamically assemble the literals and logical operations into a neural network based on the given logical expression. After that, we present the logical regularizers, which regularize the behavior of neural modules to conduct certain logical operations. At the end of the section, we provide the learning algorithm to train our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reasoning with Implicit Feedback</head><p>One fundamental goal of personalized recommendation is to predict a user's future behavior given the user's previous behaviors. We first consider users' implicit feedbacks, i.e., we only know if a user has interacted with an item or not, but do not know if the user likes or dislikes the interacted item. Suppose a user's interaction histories are items a, b and c (could be more), then the problem of recommending item v or not, reduces to the problem of deciding if the following implication statement is True or False:</p><formula xml:id="formula_4">a ∧ b ∧ c → v<label>(3)</label></formula><p>It should be noted that a logic variable in the expression (e.g., a) means the event that "user likes item a", while ¬a means the event that "user dislikes item a". As a result, each variable represents a proposition, which enables us to conduct propositional inference over the variables. Intuitively, we use the simple logical expression to decide if the user's previous behaviors would imply that the user likes a new item v. We will introduce how to learn the proposition embeddings in the next section.</p><p>Based on the definition of material implication (Eq.( <ref type="formula">2</ref>)), the above statement can be rewritten using only the basic logical operations:</p><formula xml:id="formula_5">¬(a ∧ b ∧ c) ∨ v<label>(4)</label></formula><p>Based on De Morgan's Law (Eq.( <ref type="formula" target="#formula_2">1</ref>)), this can be further rewritten into a statement using only two basic operations ¬ and ∨:</p><p>(¬a ∨ ¬b ∨ ¬c) ∨ v</p><p>One can see that the same logical statement (e.g., Eq.( <ref type="formula" target="#formula_4">3</ref>)) can be written into logically identical but literally different forms (Eq.( <ref type="formula" target="#formula_5">4</ref>) and Eq.( <ref type="formula" target="#formula_6">5</ref>)). As a result, a natural question to ask is which form should we use to build the neural architecture. As we will show in the experiments later, it is beneficial if the neural network only needs to train two logical operation modules (¬ and ∨) instead of all three modules (¬, ∧ and ∨). As a result, we choose Eq.( <ref type="formula" target="#formula_6">5</ref>) as the basic logical form to introduce the NLR framework in this section, and we will experiment with different forms in later sections.</p><p>The above introduced formalization maps recommendation to a reasoning problem based on implicit feedbacks. However, the formalization is not personalized because user's personalized information is not encoded into the reasoning process. In the following, we further extend items to events for personalized recommendation.</p><p>Suppose we have a user u 1 ∈ U and a set of items v 1 , v 2 , v 3 , v 4 ∈ V, where U and V are user and item sets. Let the interaction history of u 1 be {v 1 , v 2 , v 3 }, and then we represent these interactions</p><formula xml:id="formula_7">⟨u 1 , v 1 ⟩, ⟨u 1 , v 2 ⟩, ⟨u 1 , v 3 ⟩ as events e 1</formula><p>1 , e 1 2 , e 1  3 , where e i j means user u i interacted with item v j before. As a result, the personalized recommendation problem becomes predicting if the previous events e 1  1 , e 1 2 , e 1 3 would imply a new event e 1 4 by deciding if the following statement is true:</p><formula xml:id="formula_8">e 1 1 ∧ e 1 2 ∧ e 1 3 → e 1 4 (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>which, still, can be re-written using two logical operations:</p><formula xml:id="formula_10">(¬e 1 1 ∨ ¬e 1 2 ∨ ¬e 1 3 ) ∨ e 1 4 (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>where e 1 4 is for ⟨u 1 , v 4 ⟩. As we will illustrate later, the embedding of event e i j will consider both user u i and item v j , so that the model can make recommendations tailored to a particular user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reasoning with Explicit Feedback</head><p>Sometimes users will not only interact with items, but also will tell us if she likes or dislikes the item. Such implicit feedback signals are very informative for the recommendation task, as a result, it would be very beneficial if we can take the explicit feedbacks into the logical reasoning procedure.</p><p>Fortunately, it is very easy to extend the above formalization for reasoning with explicit feedback. In particular, we extend the definition of event e i j to describe the user attitude towards an interacted item. Specifically, we use e i j to represent that user u i interacted with item v j with positive feedback, and use ¬e i j to show that user u i interacted with item v j with negative feedback. Still take the previous example, if user u 1 interacted with v 1 , v 2 , v 3 , and gave positive feedback on v 1 , v 2 , while negative feedback on v 3 , then if or not to recommend v 4 depends on the T/F of the following statement:</p><formula xml:id="formula_12">e 1 1 ∧ e 1 2 ∧ ¬e 1 3 → e 1 4 (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>which is equivalently written as:</p><formula xml:id="formula_14">(¬e 1 1 ∨ ¬e 1 2 ∨ ¬¬e 1 3 ) ∨ e 1 4<label>(9)</label></formula><p>Here, we preserve the double negation to make sure the negation modular will be adequately trained in the neural network, which will be explained with more detail in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Logical Modules</head><p>We have introduced how to formalize a recommendation task into a logical reasoning procedure. Now we introduce how to build the neural architecture based on the given logical expression. We use the implicit feedback case as a running example in this section, and later will generalize to explicit feedback cases. Suppose a user u 1 interacted with v 1 , v 2 , v 3 , and our model needs to predict if item v 4 would be interacted by u 1 . We first use a multilayer perceptron (MLP) network to encode the user and item interactions into event vectors. The following equation shows encoding a pair of user and item vectors into one event vector with a two-layer neural network:</p><formula xml:id="formula_15">v 1 u 1 Encoder v 2 u 1 v 3 u 1 v 4 u 1 OR Similarity TRUE Events Encoder Logic Neural Network TRUE/FALSE Evaluation LOSS NOT NOT NOT e 1 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R 2 g P x L 8 k 6 h d h L W z G A + M n j 3 R 1 7 d s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 5 7 C R b B U 0 l E U B C h I I j H C q Y t t L F s t p N 2 6 W Y T d j d K C f 0 N X j w o 4 t U f 4 E / x 5 j / x 6 P b j o K 0 P B h 7 v z T A z L 0 g 4 U 9 p x v q z c 0 v L K 6 l p + v b C x u b W 9 U 9 z d q 6 s 4 l R Q 9 G v N Y N g O i k D O B n m a a Y z O R S K K A Y y M Y X I 7 9 x j 1 K x W J x q 4 c J + h H p C R Y y S r S R P O y 4 d 2 6 n W H Y q z g T 2 I n F n p F w t X V x 9 D L 4 f a p 3 i Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O O o 0 E 4 V J o Q O S A 9 b h g o S o f K z y b E j + 9 A o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c m n Y E J w 5 1 9 e J P X j i n t S O b k x a Z z D F H k o w Q E c g Q u n U I V r q I E H F B g 8 w j O 8 W M J 6 s l 6 t t 2 l r z p r N 7 M M f W O 8 / p 4 u R l g = = &lt; / l a t e x i t &gt; e 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j J g R d K 5 A G U U A l 3 G D / E v + V V i z C J s = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 g N A Q U R A o J 4 j O A m g W Q N s 5 P e Z M j s 7 D I z q 4 S Q b / D i Q R G v f o C f 4 s 0 / 8 e j k c d D E g o a i q p v u r i D h T G n H + b I y K 6 t r 6 x v Z z d z W 9 s 7 u X n 7 / o K 7 i V F L 0 a M x j 2 Q y I Q s 4 E e p p p j s 1 E I o k C j o 1 g c D n x G / c o F Y v F r R 4 m 6 E e k J 1 j I K N F G 8 r B T v n M 7 + a J T c q a w l 4 k 7 J 8 V q 4 e L q Y / D 9 U O v k P 9 v d m K Y R C k 0 5 U a r l O o n 2 R 0 R q R j m O c + 1 U Y U L o g P S w Z a g g E S p / N D 1 2 b B 8 b p W u H s T Q l t D 1 V f 0 + M S K T U M A p M Z 0 R 0 X y 1 6 E / E / r 5 X q 8 M w f M Z G k G g W d L Q p T b u v Y n n x u d 5 l E q v n Q E E I l M 7 f a t E 8 k o d r k k z M h u I s v L 5 N 6 u e R W S p U b k 8 Y 5 z J C F A h z B C b h w C l W 4 h h p 4 Q I H B I z z D i y W s J + v V e p u 1 Z q z 5 z C H 8 g f X + A 6 k R k Z c = &lt; / l a t e x i t &gt; e 1 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b n W W I s A n Y u u y x I m G Z 8 q d 8 6 5 A Q Q 8 = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 j V g I I I A U E 8 R n C T Q L K G 2 U l v M m R 2 d p m Z V U L I N 3 j x o I h X P 8 B P 8 e a f e H T y O G h i Q U N R 1 U 1 3 V 5 B w p r T j f F m Z p e W V 1 b X s e m 5 j c 2 t 7 J 7 + 7 V 1 N x K i l 6 N O a x b A R E I W c C P c 0 0 x 0 Y i k U Q B x 3 r Q v x z 7 9 X u U i s X i V g 8 S 9 C P S F S x k l G g j e d g + u X P b + a J T c i a w F 4 k 7 I 8 V K 4 e L q o / / 9 U G 3 n P 1 u d m K Y R C k 0 5 U a r p O o n 2 h 0 R q R j m O c q 1 U Y U J o n 3 S x a a g g E S p / O D l 2 Z B 8 a p W O H s T Q l t D 1 R f 0 8 M S a T U I A p M Z 0 R 0 T 8 1 7 Y / E / r 5 n q 8 M w f M p G k G g W d L g p T b u v Y H n 9 u d 5 h E q v n A E E I l M 7 f a t E c k o d r k k z M h u P M v L 5 L a c c k t l 8 o 3 J o 1 z m C I L B T i A I 3 D h F C p w D V X w g A K D R 3 i G F 0 t Y T 9 a r 9 T Z t z V i z m X 3 4 A + v 9 B 6 q X k Z g = &lt; / l a t e x i t &gt; e 1 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u D d b r Z u t w V i 9 o 5 e 3 e D X 8 L V X m H 9 s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 W M v w S J 4 K o k U F E Q o C O K x g m k L b S y b 7 a R d u t m E 3 Y 1 S Q n + D F w + K e P U H + F O 8 + U 8 8 u v 0 4 a O u D g c d 7 M 8 z M C x L O l H a c L 2 t p e W V 1 b T 2 3 k d / c 2 t 7 Z L e z t 1 1 W c S o o e j X k s m w F R y J l A T z P N s Z l I J F H A s R E M L s d + 4 x 6 l Y r G 4 1 c M E / Y j 0 B A s Z J d p I H n Y q d 2 6 n U H L K z g T 2 I n F n p F Q t X l x 9 D L 4 f a p 3 C Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O M o 3 0 4 V J o Q O S A 9 b h g o S o f K z y b E j + 8 g o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c k n b 0 J w 5 1 9 e J P W T s l s p V 2 5 M G u c w R Q 6 K c A j H 4 M I p V O E a a u A B B Q a P 8 A w v l r C e r F f r b d q 6 Z M 1 m D u A P r P c f r B 2 R m Q = = &lt; / l a t</formula><formula xml:id="formula_16">e i j = W T 2 ϕ(W 1 u i v j + b 1 ) + b 2<label>(10)</label></formula><p>where u i , v j ∈ R d are randomly initialized user and item vectors in d dimensional space; W 1 , W 2 ∈ R n×d are the weight matrices; b 1 , b 2 ∈ R n are bias terms; e i j ∈ R n represents the encoded event vector, and ϕ(•) is the rectified linear unit (ReLU) activation function:</p><formula xml:id="formula_17">ϕ(x) = max(0, x).</formula><p>With these event vectors, the next step is to construct the neural architecture to model the logical expression in Eq. <ref type="bibr" target="#b6">(7)</ref>, which is now shown as vector representations based on event embeddings:</p><formula xml:id="formula_18">(¬e 1 1 ∨ ¬e 1 2 ∨ ¬e 1 3 ) ∨ e 1 4 (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>Our goal is to calculate the above logical expression in a continuous representation space, and the space is characterized by two constant vectors T and F (F = ¬T). We expect that the final event vector of the expression would be close to T if v 4 should be recommended, and F otherwise. To achieve this goal, we represent each logical operation ∧, ∨, ¬ as a neural module AND(•, •), OR(•, •), and NOT(•), where each neural module is also an MLP network (Eq.(10)). For example, the AND(•, •) module takes two event embeddings e 1 and e 2 as input, and outputs a new event embedding, which represents the event that both e 1 and e 2 happens.</p><p>Based on the event embeddings and logical modules, we can then assemble a neural architecture for Eq.( <ref type="formula" target="#formula_18">11</ref>), as shown in Figure <ref type="figure">2</ref>. By sending each input event embedding into the NOT(•) module, we can calculate the negation of the events. After that, we combine both the negated events and the event embedding e 1 4 into the OR(•, •) module, so as to generate the final event embedding of the whole logical expression. The OR(•, •) operation can only take two event embeddings at each time, to calculate the joint embedding of more than two events using OR, we first feed in two events, e.g. e i j and e i j ′ . The output vector h i j, j ′ is treated as the representation of event e i j ∨ e i j ′ in the logical representation space. The next event vector e i j ′′ and the previous output h i j, j ′ will be sent to this OR neural module again to get the embedding of three disjunction events. We conduct this recurrently until the entire OR expression is calculated. The process, which is shown in Figure <ref type="figure">2</ref>, can be represented by the following equations:</p><formula xml:id="formula_20">¬e 1 j = NOT(e 1 j ), ∀j ∈ {1, 2, 3} Exp = OR ¬e 1 1 , ¬e 1 2 , ¬e 1 3 , e 1 4 (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>The final output Exp is the vector representation of the logical Expression in Eq. <ref type="bibr" target="#b10">(11)</ref>. To determine if the expression represents true or false, we examine if the final event embedding Exp is close to the constant true vector (T) in the logical space. The true vector is a randomly initialized anchor vector, which sets a basis for all of the high dimensional latent vectors in the logical space. It would never be updated after its initialization. If a vector represents true, then the vector should be close to this true vector, otherwise it should be far from the true vector. Any measure can be used to compare the Exp and T vectors. In this work, we use the most simple cosine measure:</p><formula xml:id="formula_22">P(Exp = T) = Exp • T ∥Exp∥∥T∥<label>(13)</label></formula><p>The above illustration is based on implicit feedback reasoning. To conduct reasoning based on explicit feedbacks such as Eq.( <ref type="formula" target="#formula_14">9</ref>), we only need to slightly modify the neural architecture in Figure <ref type="figure">2</ref>. In particular, positive events are still fed into the neural network as before, but negative events will pass through an extra NOT(•) module before feeding into the original architecture, as illustrated in Figure <ref type="figure" target="#fig_2">3</ref>. In this design, we preserve the double negation structure instead of deleting both of them to make sure the negation module can be adequately optimized in the model training procedure.</p><p>Since the number of variables (i.e., interactions) and the numbers of negative feedbacks vary for different users, the length and structure of the logical expression would be different. As a result, the neural structure are different for different users, which will be dynamically assembled according to the input expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Logical Regularizer</head><p>We have defined three logical neural modules. However, by now they are just plain MLP neural networks. We need to guarantee that each logical module is really performing the expected logical operation in the latent space. To achieve this goal, we add logical regularizer to the neural modules to constrain their behaviors. The regularizers and their corresponding laws are listed in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Let x represent an event embedding, which could be the original user-item interaction event, or any intermediate event during the logical neural network calculation, or the final event embedding of the logical expression. Let X be the set of all event embeddings, and let Sim(•, •) be a similarity function, which is cosine similarity in our implementation. As noted before, T is the constant vector representing true, which is randomly initialized and never updated    during model learning, and F is the vector representing false, which is obtained through NOT(T). We take the double negation rule r 2 as an example to explain the basic idea of logical regularizers. For the NOT(•) module to perform negation operation in the latent space, we require it to satisfy the double negation law:</p><formula xml:id="formula_23">W z G A + M n j 3 R 1 7 d s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 5 7 C R b B U 0 l E U B C h I I j H C q Y t t L F s t p N 2 6 W Y T d j d K C f 0 N X j w o 4 t U f 4 E / x 5 j / x 6 P b j o K 0 P B h 7 v z T A z L 0 g 4 U 9 p x v q z c 0 v L K 6 l p + v b C x u b W 9 U 9 z d q 6 s 4 l R Q 9 G v N Y N g O i k D O B n m a a Y z O R S K K A Y y M Y X I 7 9 x j 1 K x W J x q 4 c J + h H p C R Y y S r S R P O y 4 d 2 6 n W H Y q z g T 2 I n F n p F w t X V x 9 D L 4 f a p 3 i Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O O o 0 E 4 V J o Q O S A 9 b h g o S o f K z y b E j + 9 A o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c m n Y E J w 5 1 9 e J P X j i n t S O b k x a Z z D F H k o w Q E c g Q u n U I V r q I E H F B g 8 w j O 8 W M J 6 s l 6 t t 2 l r z p r N 7 M M f W O 8 / p 4 u R l g = = &lt; / l a t e x i t &gt; e 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j J g R d K 5 A G U U A l 3 G D / E v + V V i z C J s = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 g N A Q U R A o J 4 j O A m g W Q N s 5 P e Z M j s 7 D I z q 4 S Q b / D i Q R G v f o C f 4 s 0 / 8 e j k c d D E g o a i q p v u r i D h T G n H + b I y K 6 t r 6 x v Z z d z W 9 s 7 u X n 7 / o K 7 i V F L 0 a M x j 2 Q y I Q s 4 E e p p p j s 1 E I o k C j o 1 g c D n x G / c o F Y v F r R 4 m 6 E e k J 1 j I K N F G 8 r B T v n M 7 + a T c q a w l 4 k 7 J 8 V q 4 e L q Y / D 9 U O v k P 9 v d m K Y R C k 0 5 U a r l O o n 2 R 0 R q R j m O c + 1 U Y U L o g P S w Z a g g E S p / N D 1 2 b B 8 b p W u H s T Q l t D 1 V f 0 + M S K T U M A p M Z 0 R 0 X y 1 6 E / E / r 5 X q 8 M w f M Z G k G g W d L Q p T b u v Y n n x u d 5 l E q v n Q E E I l M 7 f a t E 8 k o d r k k z M h u I s v L 5 N 6 u e R W S p U b k 8 Y 5 z J C F A h z B C b h w C l W 4 h h p 4 Q I H B I z z D i y W s J + v V e p u 1 Z q z 5 z C H 8 g f X + A 6 k R k Z c = &lt; / l a t e x i t &gt; e 1 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b n W W I s A n Y u u y x I m G Z 8 q d 8 6 5 A Q Q 8 = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 j V g I I I A U E 8 R n C T Q L K G 2 U l v M m R 2 d p m Z V U L I N 3 j x o I h X P 8 B P 8 e a f e H T y O G h i Q U N R 1 U 1 3 V 5 B w p r T j f F m Z p e W V 1 b X s e m 5 j c 2 t 7 J 7 + 7 V 1 N x K i l 6 N O a x b A R E I W c C P c 0 0 x 0 Y i k U Q B x 3 r Q v x z 7 9 X u U i s X i V g 8 S 9 C P S F S x k l G g j e d g + u X P b + a J T c i a w F 4 k 7 I 8 V K 4 e L q o / / 9 U G 3 n P 1 u d m K Y R C k 0 5 U a r p O o n 2 h 0 R q R j m O c q 1 U Y U J o n 3 S x a a g g E S p / O D l 2 Z B 8 a p W O H s T Q l t D 1 R f 0 8 M S a T U I A p M Z 0 R 0 T 8 1 7 Y / E / r 5 n q 8 M w f M p G k G g W d L g p T b u v Y H n 9 u d 5 h E q v n A E E I l M 7 f a t E c k o d r k k z M h u P M v L 5 L a c c k t l 8 o 3 J o 1 z m C I L B T i A I 3 D h F C p w D V X w g A K D R 3 i G F 0 t Y T 9 a r 9 T Z t z V i z m X 3 4 A + v 9 B 6 q X k Z g = &lt; / l a t e x i t &gt;<label>(</label></formula><formula xml:id="formula_24">Q Q 8 = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 j V g I I I A U E 8 R n C T Q L K G 2 U l v M m R 2 d p m Z V U L I N 3 j x o I h X P 8 B P 8 e a f e H T y O G h i Q U N R 1 U 1 3 V 5 B w p r T j f F m Z p e W V 1 b X s e m 5 j c 2 t 7 J 7 + 7 V 1 N x K i l 6 N O a x b A R E I W c C P c 0 0 x 0 Y i k U Q B x 3 r Q v x z 7 9 X u U i s X i V g 8 S 9 C P S F S x k l G g j e d g + u X P b + a J T c i a w F 4 k 7 I 8 V K 4 e L q o / / 9 U G 3 n P 1 u d m K Y R C k 0 5 U a r p O o n 2 h 0 R q R j m O c q 1 U Y U J o n 3 S x a a g g E S p / O D l 2 Z B 8 a p W O H s T Q l t D 1 R f 0 8 M S a T U I A p M Z 0 R 0 T 8 1 7 Y / E / r 5 n q 8 M w f M p G k G g W d L g p T b u v Y H n 9 u d 5 h E q v n A E E I l M 7 f a t E c k o d r k k z M h u P M v L 5 L a c c k t l 8 o 3 J o 1 z m C I L B T i A I 3 D h F C p w D V X w g A K D R 3 i G F 0 t Y T 9 a r 9 T Z t z V i z m X 3 4 A + v 9 B 6 q X k Z g = &lt; / l a t e x i t &gt; e 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j J g R d K 5 A G U U A l 3 G D / E v + V V i z C J s = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 g N A Q U R A o J 4 j O A m g W Q N s 5 P e Z M j s 7 D I z q 4 S Q b / D i Q R G v f o C f 4 s 0 / 8 e j k c d D E g o a i q p v u r i D h T G n H + b I y K 6 t r 6 x v Z z d z W 9 s 7 u X n 7 / o K 7 i V F L 0 a M x j 2 Q y I Q s 4 E e p p p j s 1 E I o k C j o 1 g c D n x G / c o F Y v F r R 4 m 6 E e k J 1 j I K N F G 8 r B T v n M 7 + a J T c q a w l 4 k 7 J 8 V q 4 e L q Y / D 9 U O v k P 9 v d m K Y R C k 0 5 U a r l O o n 2 R 0 R q R j m O c + 1 U Y U L o g P S w Z a g g E S p / N D 1 2 b B 8 b p W u H s T Q l t D 1 V f 0 + M S K T U M A p M Z 0 R 0 X y 1 6 E / E / r 5 X q 8 M w f M Z G k G g W d L Q p T b u v Y n n x u d 5 l E q v n Q E E I l M 7 f a t E 8 k o d r k k z M h u I s v L 5 N 6 u e R W S p U b k 8 Y 5 z J C F A h z B C b h w C l W 4 h h p 4 Q I H B I z z D i y W s J + v V e p u 1 Z q z 5 z C H 8 g f X + A 6 k R k Z c = &lt; / l a t e x i t &gt; e 1 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R 2 g P x L 8 k 6 h d h L W z G A + M n j 3 R 1 7 d s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 5 7 C R b B U 0 l E U B C h I I j H C q Y t t L F s t p N 2 6 W Y T d j d K C f 0 N X j w o 4 t U f 4 E / x 5 j / x 6 P b j o K 0 P B h 7 v z T A z L 0 g 4 U 9 p x v q z c 0 v L K 6 l p + v b C x u b W 9 U 9 z d q 6 s 4 l R Q 9 G v N Y N g O i k D O B n m a a Y z O R S K K A Y y M Y X I 7 9 x j 1 K x W J x q 4 c J + h H p C R Y y S r S R P O y 4 d 2 6 n W H Y q z g T 2 I n F n p F w t X V x 9 D L 4 f a p 3 i Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O O o 0 E 4 V J o Q O S A</formula><p>x ≡ NOT(NOT(x)) <ref type="bibr" target="#b13">(14)</ref> which means that any event embedding, if negated for twice, should return to itself. To constrain the behavior of the negation module, we design a regularizer to maximize the cosine similarity between the output of NOT(NOT(x)) and x, which is equivalent to minimizing:</p><formula xml:id="formula_25">1 − Sim (NOT(NOT(x)), x)<label>(15)</label></formula><p>To make sure that the neural module can perform the same operation not only to the initial input event vectors, but also to all the intermediate hidden events and the final event, we apply the regularizer to all the event embeddings X in the logical space, which gives us the final regularizer for the double negation law:</p><formula xml:id="formula_26">r 2 = 1 |X| x∈X 1 − Sim(NOT(NOT(x)), x)<label>(16)</label></formula><p>where |X| is the size of the entire event space. We would not introduce the details for all of the regularizers listed in Table <ref type="table" target="#tab_0">1</ref>, since they are designed in similar ways. The only difference is the regularizer for negation law r 1 , where we conduct one plus the similarity instead of one minus similarity, because we want to maximize the distance between NOT(x) and x, such as T and F. The final regularizer considering all laws is:</p><formula xml:id="formula_27">L loдicReд = i r i<label>(17)</label></formula><p>The associative and commutative law can not be easily represented as regularizers. Instead, we randomly shuffle the order of the input events every iteration during the training process to make the learned AND and OR modules satisfy these two laws.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Learning Algorithm</head><p>In this work, we employ the pair-wise learning algorithm <ref type="bibr" target="#b35">[36]</ref> for model training. Specifically, we conduct negative sampling on each given expression during the training process. Suppose we know that user u interated with items v i−1 , v i−2 , v i−3 right before item v i . Then we can sample another item v j ∈ V that the user did not interact with. Based on this, we build the structured neural network in terms of the following two expressions:</p><formula xml:id="formula_28">C ui = ¬e u v i −1 ∨ ¬e u v i −2 ∨ ¬e u v i −3 ∨ e u v i C − u j = ¬e u v i −1 ∨ ¬e u v i −2 ∨ ¬e u v i −3 ∨ e u v j<label>(18)</label></formula><p>where C u,i is the expression for our observed data, and C − u, j is the expression for negative sampled data. Then, we have a pair of truth evaluation results:</p><formula xml:id="formula_29">p + u,i = P LNN(e u v i −1 , e u v i −2 , e u v i −3 , e u v i ) = T p − u, j = P LNN(e u v i −1 , e u v i −2 , e u v i −3 , e u v j ) = T (<label>19</label></formula><formula xml:id="formula_30">)</formula><p>where LNN is the logic neural network structure as in Figure <ref type="figure">2</ref>.</p><p>Then we calculate puij = p + u,i − p − u, j to represent the difference between these two expressions, and apply an optimization algorithm to maximize this difference. In real implementation, we sample n negative items for each user-item pair. We use V − to represent the negative sample set, where V − ⊂ V, v j ∈ V − and v i V − . The loss function can be written as:</p><formula xml:id="formula_31">L l nn = − u ∈U v i ∈V v j ∈V − ln σ ( puij ) + λ Θ ∥Θ∥ 2 2 (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>where Θ represents the parameter vector of the model, λ Θ is the weight for Frobenius norm of the model parameters, and σ (•) is the logistic sigmoid function: σ (x) = 1 1+e −x . Maximizing puij is equivalent to minimizing L l nn . The pseudo-code for calculating the logic neural network loss is given in Appendix A.2. Now we can combine the logic regularizer together with our pairwise learning loss to get the final loss function:</p><formula xml:id="formula_33">L = L l nn + λ r L loдic Reд<label>(21)</label></formula><p>where λ r is the weight for logic regularizers. We apply the same weight to all the logic regularizers since they are equally important to regularize the logical behavior of the model. We apply back propagation <ref type="bibr" target="#b39">[40]</ref> to optimize the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>As the key motivation of this work is to develop a novel neural logic recommendation framework to harness the power of collaborative filtering and logical reasoning for personalized recommendation, we aim to answer the following research questions via experiments.</p><p>• RQ1: What is the performance of the NLR framework in terms of ranking tasks? Does it outperform state-of-the-art models? (Section 5.5) • RQ2: How does the logic regularizer help to improve the performance? (Section 5.6) • RQ3: Does the logical prior over the neural network structure help to improve the performance? (Section 5.7) • RQ4: Can we model the recommendation problem with pure Boolean logic? (Section 5.8)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We experiment with three publicly available datasets. The statistics of the datasets are summarized in Table <ref type="table" target="#tab_2">2</ref>. The size of these three datasets ranges from 10K up to million level, and they cover movies as well as e-commerce recommendation scenarios.</p><p>ML100k <ref type="bibr" target="#b11">[12]</ref>. A popular dataset maintained by Grouplens, which has been used by many researchers. It includes 100,000 movie ratings ranging from 1 to 5 from 943 users and 1,682 movies. Amazon 5-core <ref type="bibr" target="#b29">[30]</ref>. This is the Amazon e-commerce dataset, which includes user, item and rating information spanning from May 1996 to July 2014. Compared with ML100k, this is a relatively sparse dataset. It covers 24 different categories, and we take Movies and TV and Electronics, which are two million-scale datasets.</p><p>Following common practice, we consider 1-3 ratings as negative feedback, and 4-5 ratings as positive feedback. Details of the dataset pre-processing procedure are provided in the Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>To evaluate the top-K recommendation performance, we use standard metrics such as Normalized Discounted Cumulative Gain at rank K (NDCG@K) and Hit Ratio at rank K (HR@K). In our experiments, the result of all metrics are averaged over all users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>To examine the effectiveness of our proposed neural logic recommendation model, we compare with two traditional shallow methods (Biased-MF and SVD++), two deep models (DMF and NeuMF), as well as two session-based models (GRU4Rec and STAMP).</p><p>• Biased-MF <ref type="bibr" target="#b24">[25]</ref>: This is a well-known recommendation algorithm by adding user, item and global bias terms into matrix factorization.</p><p>• SVD++ <ref type="bibr" target="#b22">[23]</ref>: It is also a matrix factorization based method, which extends Singular Value Decomposition (SVD) by considering user history interactions when modeling the users. • DMF <ref type="bibr" target="#b46">[47]</ref>: Deep Matrix Factorization is a deep model for recommendation, which uses multiple non-linear layers to process the raw user-item interaction matrix. • NeuMF <ref type="bibr" target="#b14">[15]</ref>: A neural network-based collaborative filtering algorithm, which employs a non-linear prediction network for user and item matching. • GRU4Rec <ref type="bibr" target="#b15">[16]</ref>: A session-based recommendation model, which uses RNN to capture the sequential dependencies in user's historical interactions.</p><p>• STAMP <ref type="bibr" target="#b27">[28]</ref>: A session-based recommendation model based on attention mechanism, which can capture user's long-term and short-term preferences. We train all of the models with pair-wise methods based on negative sampling. For each user-item pair in the validation and test set, we randomly sample 100 negative items for ranking evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental Settings</head><p>We use the same train, validation and test datasets for our model and baseline methods in experiments. All the model's parameters are tuned on the validation set based on NDCG@5. For fair comparison, all models, except for DMF, are set with an embedding size of 64 and optimized using mini-batch Adam <ref type="bibr" target="#b20">[21]</ref> with a batch size of 128. For our NLR model, the number of layers for all MLP modules are set to 2. We apply ReLU non-linear activation function between Table <ref type="table">3</ref>: Results of recommendation performance on three datasets with metrics NDCG (N) and Hit Ratio (HR). The strongest baselines are marked with underlines. We use bold font to mark the best results from all models for each comparison. We use * to indicate that the performance is significantly better than the best baseline based on paired t-test at level of 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ML100k</head><p>Movies and TV Electronics N@5 N@10 HR@5 HR@10 N@5 N@10 HR@5 HR@10 N@5 N@10 HR@5 HR@10 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Performance of NLR framework (RQ1)</head><p>To evaluate the performance of our NLR framework, we report the results, including NDCG and hit ratio (HR), on all the datasets in Table <ref type="table">3</ref>. We use NLR-I to represent our model with implicit feedbacks as the input, while NLR-E means our model with explicit feedbacks (negative/positive). It shows that our model consistently outperforms all the comparative methods under the given metrics. We give the relative improvement of our model against the strongest baseline results in the last row of the table. From the comparison, we notice that the shallow matrix factorization based algorithms -Biased-MF and SVD++ -have similar performance on most of the measures. They are powerful and efficient by training with pair-wise loss for ranking tasks. Deep neural models such as DMF and NeuMF also reach a reasonable performance on some tasks. Since our model make use of user historical interactions, it is meaningful to compare our model with session-based recommendation methods. For both GRU4Rec and STAMP, they use implicit feedbacks for training the model and make use of sequential information. For fairness concern, we compare our implicit model NLR-I with the two baselines. The reported data shows that our model is able to compete with the session-based models. What we need to notice is that our model shuffles the input variables every epoch. That means we actually did not use the order information. However, our logic neural network can still beat the other two session-based models significantly in most of the measures even using less information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">The Effect of Logical Regularizers (RQ2)</head><p>In this section, we answer the question that if the logic regularizers would help to improve the performance. We tune the logical regularizer weight λ r from 10 −5 to 1. The corresponding NDCG@10   and HR@10 are given in Figure <ref type="figure" target="#fig_8">5</ref>(a)-(c). We can see that the best performance would be reached by assigning 0.1 to the weight of logic regularizers. This result shows that it is useful to apply logical constraints to the neural networks to improve the recommendation performance. However, the constraints need to be carefully adjusted. If the constraints too weak or too strong, the performance of the recommendation model would be negatively influenced.</p><formula xml:id="formula_34">AND NOT OR e 1 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R 2 g P x L 8 k 6 h d h L W z G A + M n j 3 R 1 7 d s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 5 7 C R b B U 0 l E U B C h I I j H C q Y t t L F s t p N 2 6 W Y T d j d K C f 0 N X j w o 4 t U f 4 E / x 5 j / x 6 P b j o K 0 P B h 7 v z T A z L 0 g 4 U 9 p x v q z c 0 v L K 6 l p + v b C x u b W 9 U 9 z d q 6 s 4 l R Q 9 G v N Y N g O i k D O B n m a a Y z O R S K K A Y y M Y X I 7 9 x j 1 K x W J x q 4 c J + h H p C R Y y S r S R P O y 4 d 2 6 n W H Y q z g T 2 I n F n p F w t X V x 9 D L 4 f a p 3 i Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O O o 0 E 4 V J o Q O S A 9 b h g o S o f K z y b E j + 9 A o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c m n Y E J w 5 1 9 e J P X j i n t S O b k x a Z z D F H k o w Q E c g Q u n U I V r q I E H F B g 8 w j O 8 W M J 6 s l 6 t t 2 l r z p r N 7 M M f W O 8 / p 4 u R l g = = &lt; / l a t e x i t &gt; e 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j J g R d K 5 A G U U A l 3 G D / E v + V V i z C J s = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 g N A Q U R A o J 4 j O A m g W Q N s 5 P e Z M j s 7 D I z q 4 S Q b / D i Q R G v f o C f 4 s 0 / 8 e j k c d D E g o a i q p v u r i D h T G n H + b I y K 6 t r 6 x v Z z d z W 9 s 7 u X n 7 / o K 7 i V F L 0 a M x j 2 Q y I Q s 4 E e p p p j s 1 E I o k C j o 1 g c D n x G / c o F Y v F r R 4 m 6 E e k J 1 j I K N F G 8 r B T v n M 7 + a J T c q a w l 4 k 7 J 8 V q 4 e L q Y / D 9 U O v k P 9 v d m K Y R C k 0 5 U a r l O o n 2 R 0 R q R j m O c + 1 U Y U L o g P S w Z a g g E S p / N D 1 2 b B 8 b p W u H s T Q l t D 1 V f 0 + M S K T U M A p M Z 0 R 0 X y 1 6 E / E / r 5 X q 8 M w f M Z G k G g W d L Q p T b u v Y n n x u d 5 l E q v n Q E E I l M 7 f a t E 8 k o d r k k z M h u I s v L 5 N 6 u e R W S p U b k 8 Y 5 z J C F A h z B C b h w C l W 4 h h p 4 Q I H B I z z D i y W s J + v V e p u 1 Z q z 5 z C H 8 g f X + A 6 k R k Z c = &lt; / l a t e x i t &gt; e 1 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b n W W I s A n Y u u y x I m G Z 8 q d 8 6 5 A Q Q 8 = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 j V g I I I A U E 8 R n C T Q L K G 2 U l v M m R 2 d p m Z V U L I N 3 j x o I h X P 8 B P 8 e a f e H T y O G h i Q U N R 1 U 1 3 V 5 B w p r T j f F m Z p e W V 1 b X s e m 5 j c 2 t 7 J 7 + 7 V 1 N x K i l 6 N O a x b A R E I W c C P c 0 0 x 0 Y i k U Q B x 3 r Q v x z 7 9 X u U i s X i V g 8 S 9 C P S F S x k l G g j e d g + u X P b + a J T c i a w F 4 k 7 I 8 V K 4 e L q o / / 9 U G 3 n P 1 u d m K Y R C k 0 5 U a r p O o n 2 h 0 R q R j m O c q 1 U Y U J o n 3 S x a a g g E S p / O D l 2 Z B 8 a p W O H s T Q l t D 1 R f 0 8 M S a T U I A p M Z 0 R 0 T 8 1 7 Y / E / r 5 n q 8 M w f M p G k G g W d L g p T b u v Y H n 9 u d 5 h E q v n A E E I l M 7 f a t E c k o d r k k z M h u P M v L 5 L a c c k t l 8 o 3 J o 1 z m C I L B T i A I 3 D h F C p w D V X w g A K D R 3 i G F 0 t Y T 9 a r 9 T Z t z V i z m X 3 4 A + v 9 B 6 q X k Z g = &lt; / l a t e x i t &gt; e 1 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u D d b r Z u t w V i 9 o 5 e 3 e D X 8 L V X m H 9 s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 W M v w S J 4 K o k U F E Q o C O K x g m k L b S y b 7 a R d u t m E 3 Y 1 S Q n + D F w + K e P U H + F O 8 + U 8 8 u v 0 4 a O u D g c d 7 M 8 z M C x L O l H a c L 2 t p e W V 1 b T 2 3 k d / c 2 t 7 Z L e z t 1 1 W c S o o e j X k s m w F R y J l A T z P N s Z l I J F H A s R E M L s d + 4 x 6 l Y r G 4 1 c M E / Y j 0 B A s Z J d p I H n Y q d 2 6 n U H L K z g T 2 I n F n p F Q t X l x 9 D L 4 f a p 3 C Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O M o 3 0 4 V J o Q O S A 9 b h g o S o f K z y b E j + 8 g o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c k n b 0 J w 5 1 9 e J P W T s l s p V 2 5 M G u c w R Q 6 K c A j H 4 M I p V O E a a u A B B Q a P 8 A w v l r C e r F f r b d q 6 Z M 1 m D u A P r P c f r B 2 R m Q = = &lt; / l a t e x i t &gt; (a) EqModel AND OR NOT e 1 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " R 2 g P x L 8 k 6 h d h L W z G A + M n j 3 R 1 7 d s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 5 7 C R b B U 0 l E U B C h I I j H C q Y t t L F s t p N 2 6 W Y T d j d K C f 0 N X j w o 4 t U f 4 E / x 5 j / x 6 P b j o K 0 P B h 7 v z T A z L 0 g 4 U 9 p x v q z c 0 v L K 6 l p + v b C x u b W 9 U 9 z d q 6 s 4 l R Q 9 G v N Y N g O i k D O B n m a a Y z O R S K K A Y y M Y X I 7 9 x j 1 K x W J x q 4 c J + h H p C R Y y S r S R P O y 4 d 2 6 n W H Y q z g T 2 I n F n p F w t X V x 9 D L 4 f a p 3 i Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O O o 0 E 4 V J o Q O S A 9 b h g o S o f K z y b E j + 9 A o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c m n Y E J w 5 1 9 e J P X j i n t S O b k x a Z z D F H k o w Q E c g Q u n U I V r q I E H F B g 8 w j O 8 W M J 6 s l 6 t t 2 l r z p r N 7 M M f W O 8 / p 4 u R l g = = &lt; / l a t e x i t &gt; e 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j J g R d K 5 A G U U A l 3 G D / E v + V V i z C J s = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 g N A Q U R A o J 4 j O A m g W Q N s 5 P e Z M j s 7 D I z q 4 S Q b / D i Q R G v f o C f 4 s 0 / 8 e j k c d D E g o a i q p v u r i D h T G n H + b I y K 6 t r 6 x v Z z d z W 9 s 7 u X n 7 / o K 7 i V F L 0 a M x j 2 Q y I Q s 4 E e p p p j s 1 E I o k C j o 1 g c D n x G / c o F Y v F r R 4 m 6 E e k J 1 j I K N F G 8 r B T v n M 7 + a J T c q a w l 4 k 7 J 8 V q 4 e L q Y / D 9 U O v k P 9 v d m K Y R C k 0 5 U a r l O o n 2 R 0 R q R j m O c + 1 U Y U L o g P S w Z a g g E S p / N D 1 2 b B 8 b p W u H s T Q l t D 1 V f 0 + M S K T U M A p M Z 0 R 0 X y 1 6 E / E / r 5 X q 8 M w f M Z G k G g W d L Q p T b u v Y n n x u d 5 l E q v n Q E E I l M 7 f a t E 8 k o d r k k z M h u I s v L 5 N 6 u e R W S p U b k 8 Y 5 z J C F A h z B C b h w C l W 4 h h p 4 Q I H B I z z D i y W s J + v V e p u 1 Z q z 5 z C H 8 g f X + A 6 k R k Z c = &lt; / l a t e x i t &gt; e 1 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b n W W I s A n Y u u y x I m G Z 8 q d 8 6 5 A Q Q 8 = " &gt; A A A B 7 H i c b V D L S g N B E O y N r x h f U Y + 5 L A b B U 9 j V g I I I A U E 8 R n C T Q L K G 2 U l v M m R 2 d p m Z V U L I N 3 j x o I h X P 8 B P 8 e a f e H T y O G h i Q U N R 1 U 1 3 V 5 B w p r T j f F m Z p e W V 1 b X s e m 5 j c 2 t 7 J 7 + 7 V 1 N x K i l 6 N O a x b A R E I W c C P c 0 0 x 0 Y i k U Q B x 3 r Q v x z 7 9 X u U i s X i V g 8 S 9 C P S F S x k l G g j e d g + u X P b + a J T c i a w F 4 k 7 I 8 V K 4 e L q o / / 9 U G 3 n P 1 u d m K Y R C k 0 5 U a r p O o n 2 h 0 R q R j m O c q 1 U Y U J o n 3 S x a a g g E S p / O D l 2 Z B 8 a p W O H s T Q l t D 1 R f 0 8 M S a T U I A p M Z 0 R 0 T 8 1 7 Y / E / r 5 n q 8 M w f M p G k G g W d L g p T b u v Y H n 9 u d 5 h E q v n A E E I l M 7 f a t E c k o d r k k z M h u P M v L 5 L a c c k t l 8 o 3 J o 1 z m C I L B T i A I 3 D h F C p w D V X w g A K D R 3 i G F 0 t Y T 9 a r 9 T Z t z V i z m X 3 4 A + v 9 B 6 q X k Z g = &lt; / l a t e x i t &gt;</formula><formula xml:id="formula_35">V X m H 9 s = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 W M v w S J 4 K o k U F E Q o C O K x g m k L b S y b 7 a R d u t m E 3 Y 1 S Q n + D F w + K e P U H + F O 8 + U 8 8 u v 0 4 a O u D g c d 7 M 8 z M C x L O l H a c L 2 t p e W V 1 b T 2 3 k d / c 2 t 7 Z L e z t 1 1 W c S o o e j X k s m w F R y J l A T z P N s Z l I J F H A s R E M L s d + 4 x 6 l Y r G 4 1 c M E / Y j 0 B A s Z J d p I H n Y q d 2 6 n U H L K z g T 2 I n F n p F Q t X l x 9 D L 4 f a p 3 C Z 7 s b 0 z R C o S k n S r V c J 9 F + R q R m l O M o 3 0 4 V J o Q O S A</formula><p>In Table <ref type="table">3</ref>, NLR-E mod shows the performance of our explicit feedback model without using logical regularizers (i.e., λ r = 0). By comparing NLR-E mod and NLR-E, we can see that the recommendation performance improves by using logical regularizers. We also conduct paired t-test between the two models, and the improvements are significant at the level of 0.05 except for NDCG@10 on ML100k dataset. This result shows that logical regularizers do help to improve the recommendation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">The Effect of Logic Prior over Structure (RQ3)</head><p>Our logical neural network structure is characterized by two important features: modularity and logical regularization. Modularity means that we dynamically assemble the neural structure according to the logical expression. Each network module is responsible for a specific operation, and the entire network structure varies in terms of the logical experessions. As a result, different user and item interaction histories would result in different network structures during both training and testing, and this is a big difference between our framework and traditional deep learning models whose network structures are static. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ML100k</head><p>Movies and TV Electronics N@5 N@10 HR@5 HR@10 N@5 N@10 HR@5 HR@10 N@5 N@10 HR@5 HR@10  As we mentioned in Section 4.1, the same logical statement (e.g., Eq.( <ref type="formula" target="#formula_4">3</ref>)) can be written into logically identical but literally different expressions (Eq.( <ref type="formula" target="#formula_5">4</ref>) and ( <ref type="formula" target="#formula_6">5</ref>)), and different expressions will result in different network structures in our model. In the previous modeling and experiments, we used the two operation (¬, ∨) expression to build the network structure (Figure <ref type="figure">2</ref>). However, it would be interesting to see what happens if we use other logically identical but literally different expressions to build the network structure.</p><p>To answer the question, we explore two alternative network structures. One is a logically equivalent model (EqModel), i.e., we still use the logical expression e 1  1 ∧ e 1 2 ∧ e 1 3 → e 1 4 to model our task. However, it is represented as ¬(e 1  1 ∧ e 1 2 ∧ e 1 3 ) ∨ e 1 4 , instead of (¬e 1 1 ∨ ¬e 1 2 ∨ ¬e 1 3 ) ∨ e 1 4 that we used before (Eq.( <ref type="formula" target="#formula_18">11</ref>)). Figure <ref type="figure" target="#fig_5">4</ref>(a) shows the network structure of the logically equivalent model. One can see that although this model is logically equivalent to NLR, the neural structures are different. Besides, the original network only needs to train two modules (¬, ∨), while the new network needs to train all three modules (¬, ∧, ∨).</p><p>Another model is a logically nonequivalent model, noted as a comparative model (CMPModel). We apply the logic expression e 1  4 → e 1 1 ∧ e 1 2 ∧ e 1 3 , which is equivalent to ¬e 1 4 ∨ (e 1 1 ∧ e 1 2 ∧ e 1 3 ), to build the neural structure. Figure <ref type="figure" target="#fig_7">4(b)</ref> shows the network structure of the CMPModel. One can see that the model attempts to use future events to predict the previous events, which violates our logical intuition about the recommendation task.</p><p>In Table <ref type="table" target="#tab_4">4</ref>, we give the p-value of paired t-test between the EqModel and the original NLR-E model, as well as between the CMPModel and NLR-E, based on 5-round random experiments. For each model, the reported results are the best score among the repeated experiments. We copy the results of GRU4Rec, which is overall the best baseline model in Table <ref type="table">3</ref>, for easy reference.</p><p>We have two key observations from the results in Table <ref type="table" target="#tab_4">4</ref>. First, we see that both NLR-E and EqModel consistently outperform the GRU4Rec baseline, while the CMPModel is generally not better than the baseline. Besides, the CMPModel is significantly worse than the original NLR-E model (shown by p-value 2,3 in the table). This observation shows that a correct and reasonable logical structure is important to the performance of the model.</p><p>Another observation comes by comparing NLR-E and EqModel. By looking at the p-value between the two models (i.e., p-value 1,3 ), we see that the two models are comparable on ML100k dataset (i.e., NLR-E is not significantly better than EqModel), while NLR-E is indeed significantly better than EqModel on the two Amazon datasets. The underlying reason may arise from two factors -the complexity of model, and the sufficiency of data. As shown in Table <ref type="table" target="#tab_2">2</ref>, the MovieLens dataset is 2 magnitudes denser than the Amazon datasets. Since NLR-E and EqModel are logically equivalent, they achieve comparable performance when the training data is sufficient. However, NLR-E only needs to train two neural models (¬, ∨), while EqModel has to train three modules (¬, ∧, ∨), thus EqModel has a higher model complexity than NLR-E. As a result, NLR-E achieves better performance when the training data is sparse.</p><p>From this experiment, we can learn that it is important to use a reasonable logical prior to construct the model for a specific task. In addition, when there are multiple logically equivalent structures, we tend to use a simpler network structure (i.e., fewer modules) instead of a complex one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Boolean Logic Modeling (RQ4)</head><p>In our model, we did not apply constraints to the event embeddings, as a result, they can be learned as flexible vectors in the logical space. In this experiment, we apply a constraint that any event embedding can only be either T or F vector, to explore if the recommendation task can be modeled based on Boolean logic. To do so, we assume that the encoder network is a prediction network, which predicts if a user would give positive feedback to an item.</p><p>We first concatenate the user u and item v's embeddings, and feed it into the encoder network. Before further feeding the encoded event embedding e u v into the logic neural network, we calculate the mean square error (MSE) between this event embedding and the T or F vector, where the MSE between two vectors x and y is defined as MSE(x, y) = 1 n ∥x − y∥ 2 2 (n is the dimension of the vector). If the user has a positive feedback on the item, we minimize the MSE between the event vector and the T vector, otherwise with the F vector. The prediction loss function is written as:</p><formula xml:id="formula_36">L pr edict = MSE(e u v , G)<label>(22)</label></formula><p>where G represents the ground-truth vector, which is T or F, depending on the user likes or dislikes the item. Then, we add this loss to the model loss function in Eq.( <ref type="formula" target="#formula_33">21</ref>) to achieve the following new loss function:</p><p>L Bool ean = L l nn + λ r L loдic Reд + λ p L pr edict <ref type="bibr" target="#b22">(23)</ref> where λ p is the weight of the prediction loss. By adding this loss, the model tries to polarize the event embeddings to either T or F. The logic network would then conducts reasoning in an approximate binary space when the prediction loss is minimized to a very small number (0.0001 in our experiment). We present the results of NDCG@10 on ML100k with λ p ∈ [0.001, 0.01, 0.1, 1] in Figure <ref type="figure" target="#fig_8">5(d)</ref>.</p><p>From the results, we can see that the ranking performance heavily drops with the increase of the prediction loss weight. A large λ p would limit the expressiveness power of the latent embeddings, which further limits the ability of logic neural network to properly model the recommendation task. This experiment shows that it is important to blend the power of embedding learning into logical reasoning for accuracy decision making in a logical space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed a novel Neural Logic Recommendation (NLR) framework, which models recommendation as a reasoning task by integrating logical structures and neural networks for collaborative filtering. Experiments show that our method provides significant improvement over representative baselines on recommendation tasks. We conducted further experiments to explore the behavior of our model under different settings, so as to understand why the model achieves good performance. Results show that appropriate logical regularization is helpful to the recommendation performance. Though not a key focus of this work, our framework may bring better interpretability to recommender systems, since the decision making procedure is more transparent. We will explore this interpretability perspective in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A.1 Data Preprocessing</head><p>We transform the rating information, which come with 1 to 5 ratings, to 0 and 1, which represents the negative or positive explicit feedbacks. Ratings equal to or higher than 4 are mapped to 1 (positive), while those equal to or lower than 3 are transformed to 0 (negative). Then we sort the datasets by time. For each user and item pair in the dataset, we select its corresponding most recent n history interactions to build the logic expression. Here we set the length of history to 5, which means each user item pair comes with 5 history interactions. For those items from the earliest 5 interactions of each user, we put them into the training data. Users with less than 5 interactions are put in training dataset. We conduct leave-one-out operation to create the validation set and test set, which means that the last two interactions of each user are assigned to validation set and test set, respectively. Test sets are preferred if there remains only one expression for the user. For the models with implicit feedback as input, we simply ignore the rating information in the experiments, since the entire historical interactions are used. There is no difference between implicit feedback dataset and explicit feedback dataset except for the rating information.</p><p>A. Initialize Θ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Loss ← 0 4:</p><p>for u ∈ U , v i ∈ V do 5:</p><p>V hist ← drawHistory(v i ) ▷ obtain history of ⟨u, v i ⟩ 6:</p><p>V − ← Sample(v i , V , n) ▷ get n negative samples of v i </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Additional Experimental Settings</head><p>For DMF, we implemented the model with two two-layer neural networks for modeling users and items respectively. Since the author claimed that the increment of vector size would help to improve the performance, we tune the hidden vector size to 128 to reach the best performance on all the tasks; For NeuMF, we use a 3-layer MLP with the sizes 32, 16, 8 as mentioned by the author. The final output layer has only 1 layer with dimension 64; For both the GRU4Rec and STAMP, we use 5 as the history length, which is the same as our model used for the experiments. The size of hidden state vectors of both models are 64; For the CMPModel and EqModel, we apply the same parameters as our NLR model to guarantee that the differences in the reported results are resulted from the variation of the structure of the neural networks.</p><p>For training process, early-stopping is conducted according to the performance on the validation set. We run the experiments with five different random seeds and report the best results of each model. The p-value of paired t-test are calculated based on these 5 round random experiments. We use both the ℓ 2 -regularization and dropout to prevent overfitting. The weight of ℓ 2 -regularization λ Θ is set between 1 × 10 −6 to 1 × 10 −4 and dropout ratio is set to 0.2. Vector sizes of the variables and the user/item vectors are 64. The maximum training epoch is set to 100.</p><p>All the neural network parameters for DMF, NeuMF, GRU4Rec, STAMP, NLR, CMPModel and EqModel are initialized from a normal distribution with 0 mean and 0.01 standard deviation. Our framework is implemented with PyTorch <ref type="bibr" target="#b33">[34]</ref> version 1.4 on an NVIDIA Geforce 2080Ti GPU. The operating system is Ubuntu 16.04 LTS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of the fundamental structure of different collaborative filtering algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 &lt;</head><label>1</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " R 2 g P x L 8 k 6 h d h L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 &lt;</head><label>3</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " b n W W I s A n Y u u y x I m G Z 8 q d 8 6 5 A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>9 b h g o S o f K z y b E j + 9 A o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c m n Y E J w 5 1 9 e J P X j i n t S O b k x a Z z D F H k o w Q E c g Q u n U I V r q I E H F B g 8 w j O 8 W M J 6 s l 6 t t 2 l r z p r N 7 M M f W O 8 / p 4 u R l g = = &lt; / l a t e x i t &gt; (b) Explicit Feedback</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Reasoning over implicit (a) and explicit (b) feedbacks. The figure only shows the Logic Neural Network portion of Figure 2, other parts of the model are unchanged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>e 1 4 &lt;</head><label>4</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " u D d b r Z u t w V i 9 o 5 e 3 e D X 8 L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>9 b h g o S o f K z y b E j + 8 g o X T u M p S m h 7 Y n 6 e y I j k V L D K D C d E d F 9 N e + N x f + 8 V q r D M z 9 j I k k 1 C j p d F K b c 1 r E 9 / t z u M o l U 8 6 E h h E p m b r V p n 0 h C t c k n b 0 J w 5 1 9 e J P W T s l s p V 2 5 M G u c w R Q 6 K c A j H 4 M I p V O E a a u A B B Q a P 8 A w v l r C e r F f r b d q 6 Z M 1 m D u A P r P c f r B 2 R m Q = = &lt; / l a t e x i t &gt; (b) CMPModel</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison between the network structure that follows the logical prior (a) and violates the logical prior (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a)-(c): NDCG@10 (Red) and HR@10 (Blue) according to the increase of logic regularizer weight λ r . (d): NDCG@10 according to the increase of prediction loss weight λ p on ML100k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>7 :E 10 : 14 : 15 :</head><label>7101415</label><figDesc>← ENCODE(V hist ) ▷ obtain event vectors 8:e i ← ENCODE(v i ) 9: p + ui ← P(LN N (E, e i ) = True) for v j ∈ V − do 11:e j ← ENCODE(v j )12:p − u j ← P(LN N (E, e j ) = True)Loss ← Loss + ln σ ( puij ) Loss ← −Loss + λ Θ ∥Θ∥ 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Logical laws and the corresponding equation that each logical module should satisfy in our neural architecture. Some of the laws are guaranteed by adding an explicit logical regularizer into the training loss function, while others are guaranteed by randomly shuffling the logic variables during model training. Sim(•, •) represents a similarity measure function.</figDesc><table><row><cell>Law</cell><cell>Equation</cell><cell>Logical Regularizer r i</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>e x i t &gt; Figure2: Implementation of our NLR framework. The gray boxes with yellow or blue circles represent latent embeddings, e.g., user embedding u 1 , and item embeddings v 1 ∼ v 4 ; blue boxes with green circles represent event embeddings in the logical space, where the encoder is a multi-layer neural network that encodes user-item interactions; NOT and OR are neural logic modules; Dashed arrows mean that the order of encoded events are randomly shuffled each round.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the datasets in our experiments.</figDesc><table><row><cell>Dataset</cell><cell cols="4">#Users #Items #Interaction Density</cell></row><row><cell>ML100k</cell><cell>943</cell><cell>1,682</cell><cell>100,000</cell><cell>6.30%</cell></row><row><cell cols="3">Movies &amp; TV 123,961 50,053</cell><cell>1,697,533</cell><cell>0.027%</cell></row><row><cell cols="3">Electronics 192,404 63,002</cell><cell>1,689,188</cell><cell>0.014%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The learning rate is 0.001, the weight of ℓ 2 regularizer is 0.0001 for ML100k dataset and 0.00001 for Amazon datasets. The logical regularizer weight we use to report the results is 0.1. The implementation details of baseline models, as well as the hardware and software settings are provided in Appendix A.3.</figDesc><table><row><cell>Biased-MF</cell><cell>0.3024</cell><cell>0.3659</cell><cell>0.4501</cell><cell>0.6486</cell><cell>0.3962</cell><cell>0.4392</cell><cell>0.5346</cell><cell>0.6676</cell><cell>0.3092</cell><cell>0.3472</cell><cell>0.4179</cell><cell>0.5354</cell></row><row><cell>SVD++</cell><cell>0.3087</cell><cell>0.3685</cell><cell>0.4586</cell><cell>0.6433</cell><cell>0.3918</cell><cell>0.4335</cell><cell>0.5224</cell><cell>0.6512</cell><cell>0.2775</cell><cell>0.3172</cell><cell>0.3848</cell><cell>0.5077</cell></row><row><cell>DMF</cell><cell>0.3023</cell><cell>0.3661</cell><cell>0.4480</cell><cell>0.6450</cell><cell>0.4006</cell><cell>0.4455</cell><cell>0.5455</cell><cell>0.6843</cell><cell>0.2775</cell><cell>0.3143</cell><cell>0.3783</cell><cell>0.4922</cell></row><row><cell>NeuMF</cell><cell>0.3002</cell><cell>0.3592</cell><cell>0.4490</cell><cell>0.6316</cell><cell>0.3791</cell><cell>0.4211</cell><cell>0.5134</cell><cell>0.6429</cell><cell>0.3026</cell><cell>0.3358</cell><cell>0.4031</cell><cell>0.5123</cell></row><row><cell>GRU4Rec</cell><cell>0.3564</cell><cell>0.4122</cell><cell>0.5134</cell><cell>0.6856</cell><cell>0.4038</cell><cell>0.4459</cell><cell>0.5287</cell><cell>0.6688</cell><cell>0.3154</cell><cell>0.3551</cell><cell>0.4284</cell><cell>0.5511</cell></row><row><cell>STAMP</cell><cell>0.3560</cell><cell>0.4070</cell><cell>0.5159</cell><cell>0.6730</cell><cell>0.3935</cell><cell>0.4366</cell><cell>0.5246</cell><cell>0.6577</cell><cell>0.3095</cell><cell>0.3489</cell><cell>0.4196</cell><cell>0.5430</cell></row><row><cell>NLR-I</cell><cell>0.3697</cell><cell>0.4219</cell><cell>0.5265</cell><cell>0.6890</cell><cell>0.4152</cell><cell>0.4550</cell><cell>0.5479</cell><cell>0.6709</cell><cell>0.3226</cell><cell>0.3604</cell><cell>0.4331</cell><cell>0.5500</cell></row><row><cell>NLR-E mod</cell><cell>0.3671</cell><cell>0.4219</cell><cell>0.5180</cell><cell>0.6890</cell><cell>0.4126</cell><cell>0.4535</cell><cell>0.5444</cell><cell>0.6705</cell><cell>0.3272</cell><cell>0.3649</cell><cell>0.4377</cell><cell>0.5544</cell></row><row><cell>NLR-E</cell><cell cols="12">0.3760* 0.4240* 0.5456* 0.6943* 0.4255* 0.4670* 0.5611* 0.6891 0.3499* 0.3878* 0.4639* 0.5812*</cell></row><row><cell cols="2">Improvement 5.50%</cell><cell>2.86%</cell><cell>5.76%</cell><cell>1.27%</cell><cell>5.37%</cell><cell>4.73%</cell><cell>2.86%</cell><cell>0.70%</cell><cell>10.94%</cell><cell>9.21%</cell><cell>8.29%</cell><cell>5.46%</cell></row><row><cell>layers.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ranking performance under different logical structures. "*" indicates the significance at the level of 0.05</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>2 Pseudo Code to Calcuate the Logic Neural Network Loss Algorithm 1 Logic Neural Network Loss Input: Training User set U , item set V , model parameters Θ, L 2 regularizer weight λ Θ Output: Model loss</figDesc><table /><note>1: procedure CalcLNNLoss 2:</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">Material implication can be represented by basic logical operations: x → y ⇔ ¬x ∨y</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Context-Aware Recommender Systems</title>
		<author>
			<persName><forename type="first">Gediminas</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bamshad</forename><surname>Mobasher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Tuzhilin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="217" to="253" />
		</imprint>
	</monogr>
	<note>Recommender systems handbook</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">From System 1 Deep Learning to System 2 Deep Learning</title>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Artur D'avila</forename><surname>Tarek R Besold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Garcez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Uwe</forename><surname>Hitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><forename type="middle">C</forename><surname>Kühnberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priscila</forename><forename type="middle">Machado</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName><surname>Vieira Lima</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03902</idno>
		<title level="m">Neural-symbolic learning and reasoning: A survey and interpretation</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName><forename type="first">Antony</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Connectionist inference models</title>
				<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1331" to="1355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sequential recommendation with user memory networks</title>
		<author>
			<persName><forename type="first">Hongteng</forename><surname>Xu Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Knowledge-based neurocomputing</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Cloete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacek</surname></persName>
		</author>
		<author>
			<persName><surname>Zurada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural logic machines</title>
		<author>
			<persName><forename type="first">Honghua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Learning Representations</title>
				<meeting>the Seventh International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Michael D Ekstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="81" to="173" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neural-symbolic cognitive reasoning</title>
		<author>
			<persName><forename type="first">Sd'avila</forename><surname>Artur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><forename type="middle">C</forename><surname>Garcez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dov</forename><forename type="middle">M</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><surname>Gabbay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The connectionist inductive learning and logic programming system</title>
		<author>
			<persName><forename type="first">Artur</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Avila</forename><surname>Garcez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerson</forename><surname>Zaverucha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="59" to="77" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Neural-symbolic learning systems: foundations and applications</title>
		<author>
			<persName><surname>Artur S D'avila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krysia</forename><forename type="middle">B</forename><surname>Garcez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dov</forename><forename type="middle">M</forename><surname>Broda</surname></persName>
		</author>
		<author>
			<persName><surname>Gabbay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The movielens datasets: History and context</title>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm TIST</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Translation-based recommendation</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">VBPR: Visual Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Neural Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno>WWW. 173-182</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linas</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><surname>Tikk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards a new massively parallel computational model for logic programming</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Hölldobler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvonne</forename><surname>Kalinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fg</forename><forename type="middle">Wissensverarbeitung</forename><surname>Ki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAIâĂŹ94 workshop on Combining Symbolic and Connectioninst Processing</title>
				<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Collaborative metric learning</title>
		<author>
			<persName><forename type="first">Cheng-Kang</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Estrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In In WWW. 193-201</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural Logic Reinforcement Learning</title>
		<author>
			<persName><forename type="first">Zhengyao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
				<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiverse Recommendation: N-dimensional Tensor Factorization for Context-aware Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Amatriain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linas</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nuria</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RecSys</title>
		<imprint>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GroupLens: applying collaborative filtering to Usenet news</title>
		<author>
			<persName><forename type="first">Bradley</forename><forename type="middle">N</forename><surname>Joseph A Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><forename type="middle">R</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Collaborative Filtering with Temporal Dynamics</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="447" to="455" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Algorithms for non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seung</forename><surname>Sebastian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="556" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Amazon.Com Recommendations: Item-to-Item Collaborative Filtering</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>York</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIC.2003.1167344</idno>
		<ptr target="https://doi.org/10.1109/MIC.2003.1167344" />
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="76" to="80" />
			<date type="published" when="2003-01">2003. Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">STAMP: shortterm attention/memory priority model for session-based recommendation</title>
		<author>
			<persName><forename type="first">Qiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Refuoe</forename><surname>Mokhosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1831" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deepproblog: Neural probabilistic logic programming</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Manhaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastijan</forename><surname>Dumancic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelika</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raedt</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3749" to="3759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Targett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Qinfeng Shi, and Anton van den Hengel</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Logical Calculus of the Idea Immanent in Neural Nets</title>
		<author>
			<persName><forename type="first">Walter</forename><surname>Ws Mccelloch</surname></persName>
		</author>
		<author>
			<persName><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin ofMathematical Biophysics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="115" to="133" />
			<date type="published" when="1943">1943. 1943</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Probabilistic logic neural networks for reasoning</title>
		<author>
			<persName><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7710" to="7720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th conference on uncertainty in artificial intelligence</title>
				<meeting>the 25th conference on uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">GroupLens: an open architecture for collaborative filtering of netnews</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neophytos</forename><surname>Iacovou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitesh</forename><surname>Suchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bergstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSCW</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Introduction to Recommender Systems Handbook</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bracha</forename><surname>Shapira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<publisher>Springer US</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Markov logic networks</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="136" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986">1986. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">SHRUTI: A neurally motivated architecture for rapid, scalable inference</title>
		<author>
			<persName><forename type="first">Lokendra</forename><surname>Shastri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perspectives of Neural-Symbolic Integration</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="183" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Knowledge-based artificial neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jude</forename><forename type="middle">W</forename><surname>Towell</surname></persName>
		</author>
		<author>
			<persName><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="119" to="165" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">DKN: Deep knowledge-aware network for news recommendation</title>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1835" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Integrating Deep Learning with Logic Fusion for Information Extraction</title>
		<author>
			<persName><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinno</forename><surname>Jialin Pan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep Matrix Factorization Models for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hong-Jian</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Collaborative Knowledge Base Embedding for Recommender Systems</title>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Jing Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep learning based recommender system: A survey and new perspectives</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Joint representation learning for top-n recommendation with heterogeneous information sources</title>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1449" to="1458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Joint deep modeling of users and items using reviews for recommendation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vahid</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
