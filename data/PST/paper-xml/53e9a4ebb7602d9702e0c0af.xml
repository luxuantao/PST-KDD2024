<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-Precision Pointing on Large Wall Displays using Small Handheld Devices</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Nancel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ Paris-Sud &amp; CNRS (LRI</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Chapuis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ Paris-Sud &amp; CNRS (LRI</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emmanuel</forename><surname>Pietriga</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">INRIA CHILE -CIRIC</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xing-Dong</forename><surname>Yang</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pourang</forename><surname>Irani</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Manitoba</orgName>
								<address>
									<settlement>Orsay, Orsay, Santiago, Alberta, Manitoba</settlement>
									<country>France, France, Chile, Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michel</forename><surname>Beaudouin-Lafon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Univ Paris-Sud &amp; CNRS (LRI</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">High-Precision Pointing on Large Wall Displays using Small Handheld Devices</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">013BCC0ECBC6BA0DDB63049D80EB3DC6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.5.2 [Information interfaces and presentation]: User Interfaces. -Graphical user interfaces Wall Displays</term>
					<term>Handheld Devices</term>
					<term>Pointing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction. We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93% of a typical tablet device's screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Ultra-high-resolution wall-sized displays enable the interactive visualization of massive datasets <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27]</ref>. Application domains range from scientific visualization to computer-aided design and command &amp; control centers. Usually made of a mosaic of LCD panels, such displays typically feature a resolution of 100 pixels per inch. Beyond their significantly increased display capacity, they afford a more physical form of navigation than lower-resolution large displays <ref type="bibr" target="#b1">[2]</ref>: users can get an overview of the data from a distance, the wall fully fitting in their field of view; and they can see more details about a particular region of interest by stepping closer to the wall.</p><p>To fully take advantage of the capabilities of this new generation of wall-sized displays, users must be able to move freely in front of them. They must also be able to interact with them from any location, without being tethered by clumsy equipment. This entails two main requirements, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>: <ref type="bibr" target="#b0">(1)</ref> users must be able to remotely select graphical objects, which can be very small and difficult to reach; and</p><p>Portable surfaces have been used in prior work as pads for interacting with virtual environments, e.g., to take notes <ref type="bibr" target="#b29">[30]</ref>, or as devices to facilitate remote pointing <ref type="bibr" target="#b22">[23]</ref>. We argue that portable devices can actually accommodate both types of tasks simultaneously, enabling users to perform truly highprecision remote pointing and to manipulate the objects selected thereby. The device can also act as a secondary display. The type of portable device, e.g., a tablet or a smartphone, and the kind of interface controls and interaction techniques that it should provide are largely application-dependent. As a first step, we focus in this paper on the design and evaluation of high-precision remote pointing techniques (requirement #1) that use only a fraction of the surface of a portable device for pointing (requirement #2).</p><p>We introduce a design space for techniques that use a handheld device with an area dedicated to pointing that varies in size, and relative pointing acceleration functions specifically tuned to the particular context of ultra-high-resolution wallsized displays. Several of these techniques can be coupled with information about the user's natural head movements, which we have observed to be a good predictor of the next target location. We systematically evaluate these techniques, showing that purely relative techniques can be surprisingly efficient when tuned carefully, even with small pointing areas. We also show that even smaller pointing areas can be used with similar performance levels by combining head orientation for coarse pointing with touch-based relative pointing. Our techniques generated very positive user feedback, considering the difficulty of the tasks, and fared as well as stateof-the-art remote pointing techniques while enabling additional interactions through the handheld device. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LITERATURE REVIEW</head><p>Target acquisition on wall-sized displays. Laser pointers or ray-casting <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b16">17]</ref> are the most common absolute positioning method for pointing from a distance. However, raycasting does not adapt well to ultra-high-resolution displays as hand tremor and involuntary motion due to fatigue are amplified when the user moves further away from the display <ref type="bibr" target="#b24">[25]</ref>. In a controlled study, Kopper et al. <ref type="bibr" target="#b21">[22]</ref> showed that the speed of a distal pointing task can be described as a function of the angular amplitude of movement and the angular size of the target. Their model presents two fundamental differences between a distal pointing task and the one modeled by Fitts' law. In distal pointing, the size of the target has a much larger effect on movement time than the amplitude. Unlike a Fitts' pointing task, difficulty of distal pointing grows quadratically, rather than linearly. The pointing model based on angular target size supports recent empirical findings showing that ray-casting is fast with large distant objects but error-prone with smaller items <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b33">34]</ref>. By contrast, techniques that use relative control <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b3">4]</ref> enable more precise cursor positioning and easier acquisition of small targets.</p><p>Interactions using head tracking. Object selection is often preceded by a visual search for the target. Head orientation provides a good approximation of where a user is looking <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">28]</ref>, and can be exploited in conjunction with any pointing device used in the environment <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28]</ref>. Head movements have been shown to support a variety of interaction techniques <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20]</ref>. Our approach integrates head orientation with cursor selection. It was inspired by Ashdown et al. <ref type="bibr" target="#b0">[1]</ref>, who use head orientation for positioning a cursor on the monitor of interest, thereby reducing mouse displacements in a multi-monitor setup.</p><p>Dual-mode target acquisition. Hybrid pointing consists of combining absolute pointing for rapid cursor movements with relative pointing for accuracy. For example, ray-casting, which uses absolute positioning, can be improved by combining it with relative cursor movements <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>Adaptive Pointing <ref type="bibr" target="#b20">[21]</ref> allows switching between two modes based on the speed of the user's hand movements. A study showed that such a hybrid control mechanism reduces error rates by 63% over ray-casting. Mode-switching is implicit, requiring users to adjust their visual search and pointing actions when the switch occurs <ref type="bibr" target="#b13">[14]</ref>. By contrast, explicit mode switching lets users control when to switch between relative and absolute positioning <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b10">11]</ref>. However, the overhead introduced by the mode switch cancels out what is gained by using ray-casting for rapid movements <ref type="bibr" target="#b33">[34]</ref>. Alternatives to explicit mode switching include tracking eye gaze or body motion to anticipate or perform part of the targeting action. Zhai et al. <ref type="bibr" target="#b35">[36]</ref> developed MAGIC pointing, a technique that uses eye gaze to rapidly move the cursor as close as possible to the target on a single desktop monitor. To finish the pointing task, users then move the cursor to the target with a standard trackpad.</p><p>To avoid the cost of explicit mode switching, our approach uses head motion to move the cursor as close as possible to the intended target area. Other techniques can then be used to precisely position the cursor on the target.</p><p>Pointing via mobile touch-screens. The use of mobile devices to control distant objects has received much attention in recent years. One approach is to control a remote cursor via the mobile device's touch-screen. For example, ARC-Pad enables both absolute and relative pointing on a large display via the touch-screen of a mobile device <ref type="bibr" target="#b22">[23]</ref>. Alternatives include using embedded sensors, such as tilt <ref type="bibr" target="#b30">[31]</ref> or the phone's camera <ref type="bibr" target="#b7">[8]</ref>. With Touch Projector <ref type="bibr" target="#b7">[8]</ref>, users aim the mobile device's camera at the display and manipulate its content by touching and dragging content on the small screen. The techniques we have designed use some of these approaches for remote control of the cursor.</p><p>Pointing Facilitation Techniques. Pointing time can be improved either by reducing distance to target, increasing target width, or a combination of both. Drag-and-pop <ref type="bibr" target="#b2">[3]</ref> and the Vacuum <ref type="bibr" target="#b5">[6]</ref> are two examples designed specifically for use on large displays. Such techniques generally rely on prior knowledge of potential targets, while our work focuses on generic, target-agnostic pointing techniques. Combining our approach with pointing facilitation techniques is certainly possible since the latter make few assumptions about the physical input device used, but is left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TECHNIQUES</head><p>We consider contexts of use where the primary purpose of the handheld device is to accommodate widgets for the advanced control of objects selected via pointing. The area dedicated to pointing on the device, or pointing zone, should therefore not be too large. However, if too small, pointing will likely be inefficient. Our goal is to identify the best trade-off between screen real-estate allocation and good pointing performance.</p><p>Relative Pointing -As mentioned earlier, a simple absolute mapping from the handheld device to a ultra-high-resolution wall display does not work, because one pixel on the handheld maps to several dozen pixels on the wall, even if we were to make the pointing zone full-screen. Relative mapping, i.e., using the pointing zone as a touchpad, enables users to point precisely but requires careful tuning of the pointer acceleration function, which can be a complex and tedious process. The acceleration functions implemented in major operating systems have been parameterized for desktop environments <ref type="bibr" target="#b8">[9]</ref>. They work for single-and multi-monitor display configurations, but are not adapted to ultra-high-resolution walls, which typically feature a 200-to-400 inches diagonal and a very high resolution, e.g., 20 480 × 6 400 for the 228-inch (5.79 meters) display wall in Figure <ref type="figure" target="#fig_0">1</ref>. Previous work <ref type="bibr" target="#b25">[26]</ref> showed that basic relative pointing, if tuned properly, could actually be a viable candidate for high-precision pointing on wall displays. One of our contributions is a method to obtain such optimized transfer functions.</p><p>Dual-Precision Pointing -Pointer acceleration functions dynamically adjust the control-display (CD) gain based on the dynamics of users' movements. An alternative approach is to let users explicitly switch between different CD gains, typically between a Coarse mode that allows fast repositioning of the cursor across large distances, and a slower but more Precise mode that users can engage when they want to adjust the cursor position to acquire a very small target <ref type="bibr" target="#b25">[26]</ref>. The main challenge when designing dual-precision techniques is to seamlessly integrate the two modes so as to minimize the cognitive and motor costs of switching. All the techniques presented in this paper assign the Precise mode to single-finger drag gestures performed with the dominant hand in the pointing zone. Given our requirements that users should be free to move in front of the display, and since the non-dominant hand will typically hold the device, this leaves two main options for Coarse mode control: use the dominant hand in a different configuration, or use a different body part.</p><p>We experimented with several options to eventually identify two viable candidates through iterative design, prototyping, piloting and tuning: head orientation, and double-finger drag gestures with the dominant hand in the pointing zone. Both approaches are detailed below.</p><p>Two-finger pad-based coarse pointing -This technique is inspired by ARC-Pad <ref type="bibr" target="#b22">[23]</ref> (Absolute+Relative Cursor Pad), a dual-precision pointing technique that provides users with an absolute and a relative pointing mode. A typical ARC-Pad pointing task is composed of a tap on a touch-sensitive handheld device, followed by a drag gesture. The tap gesture coarsely positions the cursor on the large display according to an absolute mapping of the handheld device's surface to the large display. The following drag gesture is interpreted as relative movements of the cursor to adjust its position. The original technique was designed for, and evaluated on, much lower-resolution large displays than those considered here. It proved very difficult to use with very small targets on ultrahigh-resolution wall displays, mainly because the absolute mapping is far too imprecise in that context and often requires several relative-mode drag gestures to adjust the cursor's position, causing much clutching in the second phase. We thus enhanced the original technique and created ARC-Pad 2F .</p><p>ARC-Pad 2F ( 2F stands for two fingers) distinguishes between absolute and relative pointing by the number of fingers involved in performing the pointing gestures rather than the type of gesture performed. A single-finger drag gesture controls the cursor in relative mode (as with the original ARC-Pad); a drag gesture performed with two conjoined fingers is interpreted as absolute positioning of the cursor. In contrast to the original method that used taps for absolute positioning, users can now adjust the cursor position in absolute mode by dragging with two fingers, and then switch to relative mode for more precise, relative adjustments of the cursor position. The switch from absolute to relative mode is triggered whenever at least one of the fingers is lifted from the pad's surface. This means that users can either lift a single finger at the current location and continue dragging, or they can lift both fingers, adjust their hand position relative to the pad, and touch anywhere on the surface with a single finger. This second option can be very useful when pointing at a target near the edges of the display, as it allows users to initiate relative drag gestures from the center of the pointing zone, in any direction.</p><p>Head-based coarse pointing -The second viable approach that we identified for Coarse control uses the natural movements of the head that occur when remotely pointing at targets on a wall. Confirming prior work <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36]</ref>, we observed that users consistently stabilize their gaze and lock it on the target before acquiring it. While tracking the users' gaze is not a practical option in our context, we found head orientation to be a good coarse indirect indicator of where users are looking <ref type="foot" target="#foot_0">1</ref> , and thus a good predictor of the rough location of the next intended target on the wall display.</p><p>Our technique controls the cursor's location in Coarse mode through a linear interpolation from a comfortable angular operating range to the dimensions of the display. We favored an indirect mapping over direct ray-casting (or laser pointing) for two reasons. First, being perspective-based, ray-casting would have caused targets of the same absolute size to have noticeably different motor sizes depending on their location with respect to the user's physical position, as illustrated in Figure <ref type="figure" target="#fig_1">2</ref>-a (this effect gets amplified as users get closer to the display). Our mapping allows any area of the display to be reached with equal motor precision. We also wanted to optimize the input operating range, within the limits of comfortable neck positions. As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>-b, we addressed these issues by mapping a location-independent, fixed-size angular operating range centered on the orthogonal projection of the user's location on the flat display surface. This ensures that when users move in front of the display, looking straight ahead always sets the cursor exactly in front of them. As they look further away, the cursor is progressively offset from the head's direction (up to 9 • ), accounting for extra eye rotation. This offset makes it possible to point at targets on the sides of the wall comfortably while maximizing accuracy in the central area.</p><p>Cost of Switching -We observed during the early phases of development and pilot testing that users would sometimes hesitate to switch to Precise mode. This could happen because they thought that they could complete the task in Coarse mode, eventually failing or succeeding but at the cost of longer task completion times. This could also happen because they wanted to get as close as possible to the target before switching to Precise mode, sometimes loosing a significant amount of time in doing so for no actual benefit since the time lost in Coarse mode was not compensated by larger time savings in Precise mode.</p><p>This raised a question that we had not anticipated: beyond minimizing the motor cost of switching between modes, is it possible to minimize the cognitive cost associated with making the decision to switch between the two modes?</p><p>We explored an approach where the cognitive load is transferred to the perceptual system, hypothesizing that this would significantly reduce the mode switching cost. We designed variations of the above techniques that artificially limit the precision of the Coarse pointing mode: users approach the target fast and know when to switch to precise mode simply because there is no other option.</p><p>We discretized the wall display into cells according to its 8×4 matrix of 30" LCD panels. Using portions of the LCD panels, e.g. halves or quarters, would have made the cells too small for precise acquisition. We also wanted to avoid having cells inconsistently crossing screen bezels. In Coarse mode, users can only jump from screen to screen. Jumping to a screen puts the cursor at the center of that screen, and users have to switch to Precise mode to reposition the cursor within it. We call this process discretization to emphasize that the pointing resolution in Coarse mode is artificially degraded while keeping the same physical input resolution.</p><p>The resulting technique, when coupled with Head control, is somewhat reminiscent of the Rake cursor <ref type="bibr" target="#b6">[7]</ref> and similar multi-cursor desktop pointing techniques <ref type="bibr" target="#b31">[32]</ref> that use eye gaze to select the active cursor in a matrix of cursors all controlled with the same input device, such as a mouse.</p><p>Four dual-precision pointing techniques -We eventually narrowed our design space down to four pointing techniques by combining the two coarse input control techniques (padbased vs. head-based) with the two coarse mode input precisions described above (continuous vs. discretized) -see Figure <ref type="figure" target="#fig_2">3</ref>. As mentioned earlier, all four techniques, summarized below, use the handheld device's pointing zone to control the cursor in Precise mode, with optimized CD gain transfer functions. Head-based techniques feature a 500ms delay after finger release from the handheld's surface before switching back to coarse mode, giving users enough time to clutch or tap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONTROL-DISPLAY TRANSFER FUNCTIONS</head><p>As mentioned earlier, optimizing the transfer functions that control pointer acceleration in relative mode for ultra-highresolution wall displays is challenging. In this section, we explain our method for calibrating those functions.</p><p>Pointer acceleration consists of applying a transfer function to the Control-Display (CD) gain based on the pointer's dynamics. The literature on CD gain transfer functions for such high-resolution and large display surfaces is sparse. Apart from recent work by Casiez et al. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> that provides a general framework but does not directly address our configuration, the only documented calibration methods are those related to PRISM <ref type="bibr" target="#b12">[13]</ref> and its refinements <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b14">15]</ref>. But these calibration methods were designed to support absoluteto-relative transfer functions for pointing techniques that feature an implicit switch between absolute and relative modes. While we later compare our techniques with the latest developments in this area, those calibration methods are of little use in our context. All of our techniques use pointer acceleration in precise mode, and some of them in coarse mode as well. The CD gain must be large at high input speeds so the user can traverse the entire screen (15 000 to 30 000 pixels) quickly with no or little clutching. Conversely, the CD gain must be small at low input speeds for high-precision cursor control. Some operating systems use sigmoid transfer functions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> that are characterized by a slope that smoothly gets steeper before decreasing again, as illustrated in Figure <ref type="figure" target="#fig_4">4</ref>. The lower slopes at each end of the curve enable higher precision at low input velocities and bound cursor speed. To model such curves, we use a generalized logistic function:</p><formula xml:id="formula_0">CD(x) = CDmax -CD min 1 + e -λ(x-V inf ) + CD min</formula><p>where:</p><formula xml:id="formula_1">V inf = ratio inf .(Vmax -V min ) + V min .</formula><p>This function can be tuned with six parameters: V min and Vmax bound the input We tune these parameter values as follows:</p><p>1. V min and Vmax are respectively the 90 th quantile and the median of two corpora of velocities corresponding to voluntarily slow and fast finger movements on a tablet;</p><p>2. CD min = Wminor L 100×resdevice maps the lower bound for the amplitude of input movements that are considered usable for selecting a target (the equivalent of 100 input pixels at device resolution res device ) to the minimum target size W min or to the cursor width L <ref type="bibr" target="#b25">[26]</ref> for relative Coarse modes; 3. The initial value for CDmax is L min(widthinput,height input ) or Amax widthinput , mapping either the smallest dimension of the input zone to the expected Precise mode amplitude L <ref type="bibr" target="#b25">[26]</ref>, or the input zone width to the maximum pointing amplitude A max for mode-less techniques and Coarse modes (A max in our experiment corresponds to mostly horizontal movements).</p><p>4. ratio inf , λ and CDmax are adjusted so the transition between the highest and lowest CD gains is as smooth as possible.</p><p>The main criterion for deciding that a given function is properly tuned is that users can perform the most difficult task (largest amplitude, smallest target width) and no further parameter adjustment improves pointing performance or the users' subjective perception of smoothness and precision.</p><p>Three volunteers were asked to test the techniques in an informal iterative design process of 800 pointing trials per user on average, before reaching a consensus. Table <ref type="table" target="#tab_0">1</ref> gives the parameter values that we obtained for the two pointing zones that served in the experiments reported below: a large zone that fits within a tablet device in portrait mode, and a small zone that fits within a smartphone in landscape mode.</p><p>Generally-speaking, V min and Vmax have lower values for the small zone because the physical (motor) space dedicated to pointing is smaller. Similarly, the small zone features a higher CDmax, allowing for faster cursor movements so as to compensate for the smaller operating range. Discrete techniques feature a higher CDmax than Continuous ones to compensate for the larger distance between the target and the point where the mode switch has to be performed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPARING THE DUAL-PRECISION TECHNIQUES</head><p>We conducted two experiments to evaluate the performance of the four dual-precision pointing techniques introduced above, ContHead, ContPad, DiscHead and DiscPad, and to assess the cost of mode switching. The two experiments followed the same design but used different devices: a tablet with a large pointing zone in the first experiment, and a smartphone with a small pointing zone in the second one. For the sake of clarity, we use subscripts ( L for Large and S for Small) when referring specifically to either the tablet or smartphone implementation, e.g., ContHead L and ContHead S .</p><p>Our hypotheses are as follows:</p><p>(H1) Discrete techniques lower the cognitive (and thus overall) cost of mode switching by leaving no choice to users about when to switch between modes, leading to a shorter coarse pointing phase than Continuous techniques. (H2) Head-based techniques make mode switching cognitively less demanding, as they use different body parts to control the two modes. Pad-based techniques use the fingers in both modes and for mode switching. With Headbased techniques, a mode switch is triggered when the finger comes into contact with the pointing zone.</p><p>Related to (H1), we expect an effect of forcing the mode switch with Discrete techniques on the time spent in the precise phase, since this often entails engaging Precise pointing mode significantly farther away from the target than with Continuous techniques.</p><p>We also expect to observe relative differences between the two experiments due to the smaller pointing zone used in the second one: we expect Head-based techniques to be at an advantage in the second experiment, since the smaller size of the pointing zone will hinder performance of Pad-based techniques in Coarse mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Design and Procedure</head><p>Apparatus. We used a wall-sized display consisting of 32 high-resolution 30" LCD panels (2560 × 1600 pixels each, 100 dpi, 1 mm ∼ 4 pixels) laid out in an 8 × 4 matrix, 5.5 meters wide and 1.8 meters high for a total resolution of 22080×7360 when including bezels (Figure <ref type="figure" target="#fig_0">1</ref>) <ref type="bibr" target="#b4">[5]</ref>. This wall display is driven by a cluster of 16 computers, each equipped with two high-end graphic cards (one per screen), and a master workstation. The experiments' software was implemented with jBricks <ref type="bibr" target="#b28">[29]</ref>. We used a VICON motion-capture system to track passive IR retroreflective markers and provide the 3D coordinates of the participants' head with sub-millimeter accuracy at 200Hz. Participants stood up, 2 meters away from the display. Given this position and the size of the wall, the operating range of the head was π/2 × π/5 rad.</p><p>Trials. The task consisted in acquiring circular targets of width W. Participants first had to dwell for half a second in a dedicated zone in coarse mode, and could then acquire the target, positioned at a distance A from the cursor's position. Experimental conditions combined one of two target widths (W): 18 pixels (4.16 mm), 80 pixels (18.48 mm), and one of three movement amplitudes (A): 2760 pixels (width of one LCD panel, 0.637 m), 8280 pixels (width of 3 LCD panels, 1.912 m), 13 800 pixels (width of 5 LCD panels, 3.187 m).</p><p>Regarding the difficulty of these pointing tasks: according to Casiez et al. <ref type="bibr" target="#b9">[10]</ref>, the highest Fitts' Index of Difficulty (ID) tested prior to their article was 7.6 bits in a desktop context (A= 30 cm, W= 1.5 mm). In this same article they report a univariate (1D) Fitts' experiment with IDs as high as 9 (A= 4.5 m, W= 9 mm) on a 25ppi projected display. The highest ID tested in our studies is 9.54 using bivariate pointing tasks (2D) tasks. To our knowledge, such a level of difficulty was never evaluated before in this context.</p><p>For each movement amplitude A, targets were pseudo randomly positioned inside one of six LCD panels so that the average distance from the center of that panel to the target was about 600 pixels (150 mm). We chose this value so as to neither advantage nor disadvantage Discrete techniques (relative to the size of a screen), given that those techniques position the cursor at the center of the most recently visited panel.</p><p>Design and Procedure. Both experiments used a 4 × 2 × 3 within-subject design with factors TECH (technique), W and A. We blocked by technique and used a Latin square to balance the presentation order of techniques among participants. At the beginning of each block of a Head technique, participants were asked to stand still and stare at the center of the display for 5 seconds to calibrate the center of their head's operating range, in order to balance the angular offsets described earlier. Each block started with a training session composed of two parts. In the first part, W and A were set to their largest values. The operator explained the technique and asked participants to practice until their performance stabilized, i.e. when they performed six consecutive trials with a movement time (MT) variation within 40% of their average. Participants were allowed to practice longer if they wanted to.</p><p>The second training phase consisted of three blocks of six trials whose purpose was to put participants in conditions closer to the actual trials to be performed next: largest W and largest A, smallest W and medium A, smallest W and smallest A. The remaining TECH blocks were measured and decomposed into six sub-blocks composed of six replications of each of the W × A conditions described earlier. For both experiments, sessions lasted 40 minutes on average. At the end of a session, participants answered a questionnaire about their preferences and were encouraged to make comments.</p><p>Participants. The same 12 participants (10 men, 2 women; 24 to 38 year-old, avg. 29.6, med. 28.5) served in both experiments. All had normal or corrected-to-normal vision and were right-handed. All were daily users of personal computers and smartphones. Only two used tablets regularly.</p><p>Measures. We measure movement time MT and error rate.</p><p>MT begins when participants start moving after having dwelled 0.5 s inside a circle centered on the start target, and stops at the first press event on target. We split MT into movement time of the coarse phase, CMT, and movement time of the precise phase, PMT, according to the time of the last switch to precise mode. We also wanted to measure the cost of mode switching. However finding a coherent measure of the duration of mode switching for all techniques is difficult: there is no explicit marker for the beginning of the switch with headbased techniques, since in coarse mode the finger is hovering over the device; switching to precise mode with Pad-based techniques can be performed in two ways, one of which is immediate (lifting one of the fingers). To evaluate the cost of mode switching, we measure VPT, the time between the last move event in coarse mode and the velocity peak in the subsequent precise phase. VPT is a "technique-agnostic" measure that provides a satisfying approximation of the time between coarse cursor stabilization and use of precise mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tablet Experiment</head><p>In this first experiment, we used a tablet (Apple iPad I) with a resolution of 768 × 1024 pixels. Participants had to hold the tablet vertically. The pointing zone used the top 768 × 256 pixels (148 × 49 mm), resulting in an input resolution of 5.2 dot/mm. Its aspect ratio matched that of the wall display. Table <ref type="table" target="#tab_0">1</ref> summarizes the CD gain parameters.</p><p>Quantitative-objective Results. We removed a few outliers: 0.69% of the trials had an unreasonable residual / predicted ratio. These outliers were mainly due to Wi-Fi transmission problems. As expected, MT distributions per condition are skewed. We thus perform our analyses using median values, per participant, on the model TECH × W × A × Rand(Participant). Figure <ref type="figure" target="#fig_5">5</ref> graphs MT for each technique <ref type="foot" target="#foot_1">2</ref> .</p><p>An ANOVA reveals a significant effect of TECH on MT (F 3,33 = 11.4, p &lt; 0.0001). A post-hoc t-test with Bonferroni correction shows that ContHead L is significantly faster than all other techniques (all p's &lt; 0.001): 9% faster than ContPad L , 15% faster than DiscPad L , and 14% faster than DiscHead L . The only other significant difference is between ContPad L and DiscPad L , the former being 6% faster.</p><p>We also observe, as expected, significant effects of target width W (F 1,11 = 459, p &lt; 0.0001) and movement amplitude A (F 2,22 = 43.8, p &lt; 0.0001) on MT, participants being faster with the larger target and the smallest distance. We do not observe any interaction effect TECH × W or TECH × A.</p><p>The overall error rate is 5.9%. An ANOVA reveals no effect of TECH on error rate (F 3,33 = 0.61, p = 0.6151) and no significant interaction. Again, as expected, we find a significant effect of W on error rate (F 1,11 = 11.5, p = 0.0061): 8.4% for small targets and 3.4% for larger ones. We also measure a significant effect of A (F 2,22 = 4.00, p = 0.0329), although the magnitude of the difference is small: 4.9% for the largest amplitude, 6.9% and 5.9% for the medium and small ones.</p><p>As illustrated in Figure <ref type="figure" target="#fig_5">5</ref>, the time spent in the coarse phase is slightly shorter with Discrete techniques than with Continuous techniques. However, this difference is not statistically significant -(H1) is not supported -and is not large enough to make Discrete techniques more efficient than Continuous ones. Indeed, the time spent in precise mode is far longer with the Discrete techniques. We tentatively attribute this to the fact that the last mode switch is performed 150 mm away from the target on average with Discrete techniques, compared to 67 mm with ContHead L and 71 mm with ContPad L .</p><p>ContHead L and ContPad L feature very similar coarse pointing times (CMT) and distance-to-target at mode-switch time. ContHead L 's shorter task time is mainly due to performance improvements during the precise pointing phase (Figure <ref type="figure" target="#fig_5">5</ref>). We observed that velocity peaks occur earlier with ContHead L than with ContPad L (average VPT of 462 ms vs. 735 ms). Distances from the mode-switch location to the target are similar for Headand Pad-based techniques, and their acceleration curves have the same input characteristics (V min , Vmax and ratio inf ). We thus expected the velocity peaks of ContHead L and ContPad L to occur at similar times. But participants actually required more time to reach full speed with ContPad L . This suggests that the cost of mode switching is indeed lower for Head-based techniques than for Padbased ones -supporting (H2) -possibly because of the cognitive cost entailed by switching between two very different CD gains whereas the input device / method remains the same.</p><p>Quantitative-subjective Results. Overall, participants preferred to use Head-based techniques (10 out of 12) and Continuous techniques (8 out of 12). 7 participants ranked ContHead L first, 4 ranked DiscHead L first and 2 ranked ContPad L first. However, there were no strong complaints about any particular technique, except for one participant who clearly stated that he disliked Discrete techniques.</p><p>Several participants complained about the lack of tactile feedback, which made it difficult to know when the fingers were leaving the pointing zone. They expressed the need for some sort of physical boundary to delimit the pointing zone, as featured by laptop touchpads. Only one participant answered that holding the tablet for 40 minutes was indeed a cause of fatigue when we inquired about this potential issue. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smartphone Experiment</head><p>The second experiment used a smartphone (Apple iPod Touch) with a resolution of 480 × 320 pixels. Participants had to hold the device horizontally. The pointing zone used the top 480 × 166 pixels (75 × 26 mm, same aspect ratio as the display), resulting in an input resolution of 6.4 dot/mm. CD gain parameters are given in Table <ref type="table" target="#tab_0">1</ref>.</p><p>We took participants' comments about the lack of tactile feedback into account, and used easily removable tape to delimit the pointing zone (3 mm wide, 0.8 mm thick). Preliminary tests had shown that the tape did make it much easier to find the input zone without looking at the surface and to anticipate fingers crossing the pointing zone's boundaries.</p><p>Results are very similar to those of the tablet experiment reported above. We observe an effect of TECH on MT (no interaction with A and W), and an effect of A and W, as expected. (H2) is also supported by the data. We get similar error rates, and an overall subjective preference for ContHead S . Movement time, split between the coarse and precise phases, is shown in Figure <ref type="figure" target="#fig_6">6</ref> using the same scale as in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>Regarding the coarse pointing phase, this time we observe a significant effect of TECH (F 3,33 = 5.39, p = 0.0039). DiscHead S is significantly faster than all other techniques, and DiscPad S and ContHead S are significantly faster than ContPad S (for this phase). With the smaller pointing zone used in this experiment, we do observe the hypothesized advantage for discrete techniques (H1). However, the time gained during the coarse phase is again not large enough to make Discrete techniques faster than Continuous ones.</p><p>Since we did not counterbalance the order of pointing zone sizes (all participants performed the tablet experiment first), and since we added tactile feedback using tape to delimit the zone in the second experiment, we cannot formally compare overall performance across both experiments. However, we can make three informal observations. First, the movement time difference between ContHead S and ContPad S is larger for the smartphone (13%) than for the tablet (9%); Second, ContPad S is not significantly faster than DiscPad S , as opposed to ContPad L vs. DiscPad L ; Third, Figures <ref type="figure" target="#fig_5">5</ref> and<ref type="figure" target="#fig_6">6</ref> suggest that DiscHead performed better with the smartphone than with the tablet, relative to ContPad and DiscPad. These observations suggest that as we had anticipated, Head-based techniques are at an advantage with smaller pointing zones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPARISON WITH STATE-OF-THE-ART TECHNIQUES</head><p>The above experiments identified ContHead as the fastest and preferred technique. As a follow-up, we wanted to evaluate the cost of using a handheld device for pointing.  <ref type="figure"></ref>and<ref type="figure" target="#fig_6">6</ref>). This makes ContHead S a more interesting technique overall, since using a smaller pointing zone means that the device can accommodate more control widgets. We briefly describe the techniques selected for comparison below.</p><p>We noticed during early pilot studies that purely relative pointing techniques can actually be viable candidates for high-precision pointing, provided that their acceleration function is properly tuned. We thus decided to include purely relative, trackpad-like pointing in this experiment. We tested two different pointing zone sizes, equal to those of the pointing zones used in the previous experiments. For the purpose of experimental comparison, those were considered as distinct techniques, called RelaSmall and RelaLarge, each tuned with its own optimized transfer function. As discussed before, the literature on calibrating transfer functions for relative pointing techniques is scarce. The functions used by major operating systems do not meet the requirements of ultra-highresolution wall-sized displays in terms of speed and precision. We therefore used the transfer function calibration method initially developed for our dual-precision techniques. Parameter values are given in Table <ref type="table" target="#tab_0">1</ref>. Compared to the functions used in the first two experiments, these two functions feature a much higher CDmax that allows traveling much larger distances without too much clutching.</p><p>To avoid introducing a confound due to the device itself, we decided to use a tablet for all techniques that required a handheld device: ContHead S , RelaSmall and RelaLarge. We compared those three techniques with two techniques from the literature: LaserGyro and SmoothPoint.</p><p>LaserGyro is a mid-air dual-precision technique that provides coarse control of the cursor's position with ray-casting and enables precise adjustments with relative angular motion. Mode switches are triggered with a button. This technique, inspired by Vogel et al.'s work on distant freehand pointing <ref type="bibr" target="#b33">[34]</ref>, has been shown to perform very well <ref type="bibr" target="#b25">[26]</ref>.</p><p>SmoothPoint <ref type="bibr" target="#b14">[15]</ref> also combines ray-casting with relative pointing. However, the transition between the two modes is progressive, based on a transfer function that depends on input motion velocity. The authors of <ref type="bibr" target="#b14">[15]</ref> propose a method to tune this function, but pilot tests in our environment revealed that this method does not scale to large surfaces with high pixel densities such as those typically encountered on ultra-high-resolution wall displays: the difference between the minimum and maximum CD gain values is too high, causing the precise mode to be very jerky when selecting small targets such as those considered here. We transposed the calibration method described in <ref type="bibr" target="#b14">[15]</ref> to our context<ref type="foot" target="#foot_2">3</ref> to the best of our abilities, iterating until the technique eventually enabled us to achieve pointing tasks with the target sizes and movement amplitudes considered in our experiments.</p><p>In this third experiment, we tested a total of five techniques (TECH): ContHead S , RelaSmall, RelaLarge, SmoothPoint and LaserGyro. The apparatus, design, and procedure were exactly the same as in the previous experiments. We added a physical border around the large and small pointing zones on the tablet to limit the need to look at the input device by providing tactile feedback when the fingers were about to leave the zone. We used a 5×5 latin square to balance technique ordering. 15 participants served in the experiment (10 of them had participated in the previous experiments 1.5 months before, 5 were new and assigned to the same Latin square).</p><p>Quantitative-objective Results. As in the previous experiment we removed a few outliers (1.28%). Figure <ref type="figure" target="#fig_7">7</ref> shows movement time MT by W and A. For ContHead S the results are very close to those of the previous experiments. We observe that SmoothPoint performs poorly compared to all other techniques (significantly so, for each W and A condition). For the sake of conciseness, we do not report figures for Smooth-Point in post-hoc tests, even though it was, of course, included in the corresponding statistical computations.</p><p>An ANOVA reveals a significant effect of TECH on MT (F 4,56 = 20.5, p &lt; 0.0001). A post-hoc t-test with Bonferonni correction shows that ContHead S , LaserGyro and RelaLarge are all significantly faster than RelaSmall (with speed-ups of 5.4%, 8% and 9%, respectively). This time, the ANOVA reveals significant interactions TECH × W (F 4,56 = 5.90, p = 0.0005) and TECH × A (F 8,112 = 2.60, p = 0.0122) on MT. One cause for these interactions is Smooth-Point, which is slower for small targets than for larger ones, and faster for the largest amplitude. We can also observe (Figure <ref type="figure" target="#fig_7">7</ref>) that the two relative techniques, RelaSmall and RelaLarge, are faster for the small width and the small amplitude. Indeed, post-hoc tests show that (i) for small targets, the only significant result is that RelaLarge is faster than Re-laSmall, and for large targets, ContHead S and LaserGyro are also significantly faster than RelaSmall; (ii) for the small amplitude the only significant results are that RelaLarge is faster than RelaSmall and ContHead S , while for the large amplitude the only significant results are that both RelaLarge and ContHead S are significantly faster than RelaSmall.</p><p>The overall error rate is 9.6%. ContHead S , RelaSmall and RelaLarge feature low error rates (3.90%, 3.52% and 4.04%) with only marginal differences between large and small targets (2.5% vs 5.17%). LaserGyro and SmoothPoint also feature low error rates for large targets (0.70% and 5.60%), but the error rate rises dramatically for small targets: 25.6% and 43.0%. We had not anticipated such an increase in error rate from our pilot studies. The problem turned out to come from the fact that clicking with the handheld wireless mouse caused small hand movements which, in turn, caused small cursor displacements that were sometimes large enough to make the cursor leave the target. We furthered our analysis by measuring the time to first click (instead of first click on the target). This did not change the results for LaserGyro. However, results were slightly different for SmoothPoint, which remained slower than RelaSmall in all conditions but not significantly so for the small target + large amplitude condition.</p><p>Quantitative-subjective Results. At the end of the experiment, we asked participants to rank the techniques on a fivepoint Likert scale in terms of preference, fatigue and perceived performance. Figure <ref type="figure" target="#fig_8">8</ref> summarizes the results in a boxplot. Kruskal-Wallis tests revealed a significant effect of TECH on Preference (χ 2 4 = 28.5, p &lt; 0.0001) and Performance (χ 2 4 = 23.4, p = 0.0001), but not on Fatigue. Posthoc tests using Mann-Whitney tests with Bonferroni correction show that (i) ContHead S and LaserGyro were preferred to both RelaSmall and SmoothPoint; (ii) RelaLarge was preferred to SmoothPoint; (iii) ContHead S , LaserGyro and Re-laLarge were perceived as faster than SmoothPoint; and (iv) LaserGyro and ContHead S were perceived as (marginally) faster than RelaLarge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion and Design Guidelines</head><p>Results show that using a handheld device for high precision pointing enables users to point at least as efficiently as stateof-the-art mid-air pointing techniques in terms of both speed and accuracy, while leaving a large portion of the handheld's surface available for additional, application-specific widgets.</p><p>The three techniques that perform best in terms of movement time and preference are RelaLarge, ContHead and Laser-Gyro. While there is no significant speed difference between them, each technique has its own strengths and limitations, making it suitable to specific contexts of use.</p><p>While relative pointing is not novel, making it work efficiently in such challenging contexts is an interesting result. Indeed, existing functions, even elaborate ones such as that of SmoothPoint, were designed for lower-resolution environments, and fare poorly with the high Fitts' IDs considered here. RelaLarge, based on the CD transfer function tuning method introduced in this paper, provides pointing performance that matches that of more elaborate techniques. It is straightforward to implement and does not require specific equipment to track spatial position and orientation.</p><p>RelaSmall is also quite an achievement, considering that it provides enough precision to perform bivariate pointing tasks of high difficulty (up to 9.5) with a pointing zone of 20 cm 2 only (approximately 1/4 th of RelaLarge's surface area). Given that the pointing zone dimensions of RelaLarge preclude its use on smartphones, RelaSmall can be seen as an interesting option. Indeed, the technique will only incur a 5-to-10-percent performance decrease compared to more efficient techniques, which can be considered an acceptable tradeoff when only small handheld devices are available, or when a large portion of the handheld's screen real-estate should be allocated to additional interface widgets. This performance decrease can be avoided by using Cont-Head, which achieves the same level of performance as Re-laLarge but on a much smaller input area, equivalent to that of RelaSmall. ContHead should be considered when the tasks and context of use require many additional interface widgets or when only smartphones are available, provided that tracking the location and orientation of the head is possible.</p><p>Finally, LaserGyro causes many more errors than other techniques for small values of W, as the tremor caused by pressing a physical button, even if comparatively small, is large enough to severely hinder acquiring very small targets. This problem does not happen with tablet-based techniques since their tapping mechanism is algorithmically decoupled from their pointing mechanism. Another drawback of this technique is that it cannot accommodate additional interface widgets on the input device. However, LaserGyro leaves the nondominant hand free to perform other interactions, making it a relevant option when the task requires operating additional input devices, provided that pointing task IDs are lower than 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION AND FUTURE WORK</head><p>This paper investigated the use of handheld devices for very difficult remote pointing tasks on wall displays, where only a portion of the handheld's surface is dedicated to pointing. The goal is to leave the larger part of this surface to task-specific widgets, since pointing is rarely sufficient on its own to interact with wall displays. We designed and evaluated techniques that use various input channels to improve pointing at very small targets across large amplitudes.</p><p>Our most successful design, ContHead, lets users perform pointing actions at two levels of granularity: coarse pointing uses the natural movements of the head when moving the cursor across large distances; precise pointing uses a small pointing zone on the handheld device to perform relative pointing movements via finger gestures. When compared with stateof-the-art techniques that are not constrained by our requirements, the technique performs well even with high indices of difficulty, beyond those tested in previous work. ContHead was also rated as one of the best techniques overall in terms of subjective preference and perceived performance.</p><p>Purely relative techniques using only the touch surface of the handheld device performed better than we had originally anticipated. This led us to carefully investigate Control-Display transfer functions that enable both very fast pointing across large amplitudes while minimizing clutching, and precise cursor adjustments to acquire targets only a few millimeters in diameter. We showed that with a large-enough pointing zone and proper tuning, such a relative technique competes with the most efficient dual-mode techniques.</p><p>In future work we plan to investigate how to automatically couple and decouple cursor position from head orientation since it is not always desirable, in real contexts of use, to have them tied together. One possible solution would be to detect situations where the user is likely to initiate pointing actions, e.g., using information about the handheld device and the position of the hand <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Interacting with a wall display using a tablet that features both an area dedicated to high-precision pointing for the remote selection of graphical objects on the wall, and control widgets to act on those objects.</figDesc><graphic coords="1,325.86,574.53,230.91,119.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The problem of varying angular motor size with ray-casting (a) can be addressed using an indirect absolute mapping (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The four dual-precision techniques. (A) The three device / pointing zone pairs used in our experiments: tablet with large zone (Experiments 1 and 3), smartphone with small zone (Experiment 2) and tablet with small zone (Experiment 3). (B) The four coarse (absolute) modes, combinations of Head vs. ARC-Pad 2F and Discrete vs. Continuous. (C) In all cases, using a single finger in the pointing area switches to precise (relative) mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>•</head><label></label><figDesc>ARC-Pad 2F + Continuous = ContPad: two conjoined fingers in the handheld's pointing zone activate Coarse mode (absolute mapping of the zone to the wall); a single finger activates Precise mode (relative cursor displacements). • ARC-Pad 2F + Discrete = DiscPad: same as above but pointing precision in Coarse mode is artificially restricted: the cursor can only get positioned at the center of any given LCD panel, requiring a switch to Precise mode for any further cursor position adjustments. • Head + Continuous = ContHead: head orientation provides Coarse control of the cursor, without any artificial restriction on pointing precision. Touching the pointing zone on the handheld automatically switches to Precise mode (relative cursor displacements). • Head + Discrete = DiscHead: same as above, but pointing precision in Coarse mode is artificially restricted. Head orientation can only make the cursor jump to the center of any given LCD panel, as with DiscPad.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. An example of logistic sigmoid curve (large zone RelaLarge) range of the function by specifying lower and upper velocities beyond which accurate control becomes difficult; ratio inf sets the function's inflection point within this range; CD min and CDmax are asymptotic values that define the function's output range. Finally, λ ∈ [0; ∞] defines the curve's slope at its inflection point (λ = 0 yields a constant function, λ = ∞ a step function). Adjusting λ smoothes the curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. MT for each TECH (tablet experiment). Black lines that split the four bars indicate the time of the last switch to precise mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. MT for each TECH (smartphone experiment). Black lines that split the four bars indicate the time of the last switch to precise mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. MT for each TECH by W and by A for the last experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Preference, fatigue and (self-reported) perceived performance for each TECH on a five-point Likert item (5 is best, 1 is worst).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Large zone: V min = 0.006m/s, Vmax = 0.37m/s, CD min = 0.22 Small zone: V min = 0.003m/s, Vmax = 0.19m/s, CD min = 0.27 Transfer function parameter values.</figDesc><table><row><cell>Size</cell><cell>Technique</cell><cell>CDmax</cell><cell>λ</cell><cell>ratio inf</cell></row><row><cell>Large</cell><cell>ContHead L</cell><cell>9.9</cell><cell>19.9</cell><cell>0.4</cell></row><row><cell>zone</cell><cell>ContPad L</cell><cell>6.6</cell><cell>17.5</cell><cell>0.4</cell></row><row><cell>148 × 49 (mm)</cell><cell>DiscHead L DiscPad L</cell><cell>12.9</cell><cell>17.5</cell><cell>0.4</cell></row><row><cell></cell><cell>RelaLarge</cell><cell>43.1</cell><cell>20.0</cell><cell>0.5</cell></row><row><cell>Small zone</cell><cell>ContHead S ContPad S</cell><cell>6.3</cell><cell>26.5</cell><cell>0.4</cell></row><row><cell>75 × 26 (mm)</cell><cell>DiscHead S DiscPad S</cell><cell>16.4</cell><cell>26.5</cell><cell>0.7</cell></row><row><cell></cell><cell>RelaSmall</cell><cell>83.0</cell><cell>22.5</cell><cell>1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>To this end, we ran a third experiment to compare ContHead to state-ofthe-art remote pointing techniques. Such techniques do not meet requirement #2, i.e., accommodating widgets used for other purposes than pointing, but this comparison enables us to put our results in a more general context. The comparison involves the version of ContHead that uses a small pointing zone, ContHead S , on a tablet. ContHead S and ContHead L feature very similar performance (see Figures 5</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Users rotate their head to look at off-centered targets so as to minimize the effort put on ocular muscles<ref type="bibr" target="#b11">[12]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In all our bar charts, the mean is taken over the medians of each experimental condition (including Participant). Error bars represent the corresponding 95% confidence limit.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>We did not use our logistic function because the transfer function associated with SmoothPoint is part of the technique<ref type="bibr" target="#b14">[15]</ref>.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Combining head tracking and mouse input for a GUI on multiple monitors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ashdown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI EA &apos;05</title>
		<meeting>CHI EA &apos;05</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1188" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Move to improve: promoting physical navigation to increase user performance with large displays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;07</title>
		<meeting>CHI &apos;07</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Drag-and-Pop and Drag-and-Pick: Techniques for Accessing Remote Screen Content on Touch and Pen-operated Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cutrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Czerwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zierlinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERACT &apos;03</title>
		<meeting>INTERACT &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Soap: a pointing device that works in mid-air</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;06</title>
		<meeting>UIST &apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="43" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-surface interaction in the WILD room</title>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gjerlufsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Klokmose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mackay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pillias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Primet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="48" to="56" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Vacuum: facilitating the manipulation of distant objects</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;05</title>
		<meeting>CHI &apos;05</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="361" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rake cursor: improving pointing performance with concurrent input channels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blanch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;09</title>
		<meeting>CHI &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1415" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Touch projector: mobile interaction through video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;10</title>
		<meeting>CHI &apos;10</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2287" to="2296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">No more bricolage!: methods and tools to characterize, replicate and compare pointing transfer functions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roussel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;11</title>
		<meeting>UIST &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="603" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The impact of control-display gain on user performance in pointing tasks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cockburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">HCI</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="215" to="250" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hybridpointing: fluid switching between absolute and relative pointing with a direct input device</title>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;06</title>
		<meeting>UIST &apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Coordination of the eyes and head: movement kinematics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Sparks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Brain Res</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="22" to="32" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">PRISM interaction for enhancing control in immersive virtual environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Frees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ToCHI</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Smoothed pointing: A user-friendly technique for precision enhanced remote pointing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ciampi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Minutolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CISIS &apos;10</title>
		<meeting>CISIS &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="712" to="717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Design and comparative evaluation of smoothed pointing: A velocity-oriented remote pointing enhancement technique</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Minutolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJHCS</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="287" to="300" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The use of eye movements in human-computer interaction techniques: what you look at is what you get</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="152" to="169" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A comparison of ray pointing techniques for very large displays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nacenta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Jorge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GI &apos;10</title>
		<meeting>GI &apos;10</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="269" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interaction with a projection screen using a camera-tracked laser pointer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kirstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MMM &apos;98</title>
		<meeting>MMM &apos;98</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="191" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Vision-based face tracking system for window interface: prototype application and empirical studies</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kitajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Koike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI EA &apos;01</title>
		<meeting>CHI EA &apos;01</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="359" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Head-tracked orbital viewing: an interaction technique for immersive virtual environments</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kollerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Mine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;96</title>
		<meeting>UIST &apos;96</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="81" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive pointingdesign and evaluation of a precision enhancing technique for absolute pointing devices</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Konig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gerken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dierdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERACT &apos;09</title>
		<meeting>INTERACT &apos;09</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="658" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A human motor behavior model for distal pointing tasks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kopper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJHCS</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="603" to="615" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Arc-pad: absolute+relative cursor positioning for large displays with a mobile touchscreen</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;09</title>
		<meeting>UIST &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="153" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Head gesture recognition in intelligent interfaces: the role of context in improving recognition</title>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IUI &apos;06</title>
		<meeting>IUI &apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="32" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Interacting at a distance: measuring the performance of laser pointers and other devices</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;02</title>
		<meeting>CHI &apos;02</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Precision pointing for ultra-high-resolution wall displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
		<idno>RR-7624</idno>
	</analytic>
	<monogr>
		<title level="j">INRIA</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mid-air pan-and-zoom on wall-sized displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;11</title>
		<meeting>CHI &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pointing gesture recognition based on 3d-tracking of face, hands and head orientation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICMI &apos;03</title>
		<meeting>ICMI &apos;03</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="140" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rapid development of user interfaces on cluster-driven wall displays with jBricks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Primet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EICS &apos;11</title>
		<meeting>EICS &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="185" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Virtual Notepad: Handwriting in Immersive VR</title>
		<author>
			<persName><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tomokazu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weghorst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VRAIS &apos;98</title>
		<meeting>VRAIS &apos;98</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="126" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tilt techniques: Investigating the dexterity of wrist-based input</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gustafson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;09</title>
		<meeting>CHI &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1943" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Disambiguating ninja cursors with eye gaze</title>
		<author>
			<persName><forename type="first">K.-J</forename><surname>Räihä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Špakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;09</title>
		<meeting>CHI &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1411" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Amplitude of human head movements associated with horizontal saccades</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Stahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Brain Res</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="41" to="54" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distant freehand pointing and clicking on very large, high resolution displays</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;05</title>
		<meeting>UIST &apos;05</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bitouch and bipad: Designing bimanual interaction for hand-held tablets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;12</title>
		<meeting>CHI &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Manual and gaze input cascaded (MAGIC) pointing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ihde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;00</title>
		<meeting>CHI &apos;00</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
