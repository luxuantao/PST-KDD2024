<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Multiple Kernel Similarity Learning for Visual Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hao</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online Multiple Kernel Similarity Learning for Visual Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EC4BD34FCEDAEA83F3BB63E26C914729</idno>
					<idno type="DOI">10.1109/TPAMI.2013.149</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Similarity search</term>
					<term>kernel methods</term>
					<term>multiple kernel learning</term>
					<term>online learning</term>
					<term>content-based image retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent years have witnessed a number of studies on distance metric learning to improve visual similarity search in Content-Based Image Retrieval (CBIR). Despite their successes, most existing methods on distance metric learning are limited in two aspects. First, they usually assume the target proximity function follows the family of Mahalanobis distances, which limits their capacity of measuring similarity of complex patterns in real applications. Second, they often cannot effectively handle the similarity measure of multi-modal data that may originate from multiple resources. To overcome these limitations, this paper investigates an online kernel similarity learning framework for learning kernel-based proximity functions, which goes beyond the conventional linear distance metric learning approaches. Based on the framework, we propose a novel Online Multiple Kernel Similarity (OMKS) learning method, which learns a flexible nonlinear proximity function with multiple kernels to improve visual similarity search in CBIR. We evaluate the proposed technique for CBIR on a variety of image data sets, in which encouraging results show that OMKS outperforms the state-of-the-art techniques significantly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Similarity search plays a fundamental role in a variety of multimedia retrieval tasks <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, which has been extensively studied in multimedia and computer vision fields, especially for Content-Based Image Retrieval (CBIR) <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. The crux of visual similarity search is to find some proximity function that can effectively measure distance/similarity between images <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. In a conventional CBIR system, given images represented in a vector space, the typical choices of such proximity functions are Euclidean distance and its variants, which are often not flexible enough to measure the proximity of images due to the nature of the fixed rigid functions.</p><p>In recent years, researchers have noticed the limitations of conventional rigid proximity functions in image similarity search. To address this issue, one group of active research studies are the Distance Metric Learning (DML) algorithms <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, which usually learn to optimize the distance metric of proximity measure to improve image similarity search in CBIR. Despite the success of various DML algorithms to improve similarity search of CBIR, most existing DML algorithms are limited in two aspects. First, they typically assume the target proximity function follows the form of general Mahalanobis distances and restricts the DML task in finding an optimal linear distance metric, which may limit its capacity of measuring similarity of complex image patterns in real applications. Second, even though there are few existing works <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> for learning nonlinear similarity function with kernel, they usually do not handle the similarity with multiple kernels.</p><p>To overcome the limitations of existing work, in this paper, we propose a novel Online Multiple Kernel Similarity (OMKS) learning scheme, which ranks images by learning pairwise similarity of images that are represented in multiple modalities using multiple kernels. Unlike the conventional DML techniques, the target similarity function learned by OMKS can be any nonlinear function in some reproducing kernel Hilbert spaces induced by some predefined kernels. And different from some batch kernel-based DML algorithms, OMKS learns with multiple kernels in an online learning fashion <ref type="bibr" target="#b13">[14]</ref>. Thus, OMKS is able to learn a much more flexible and powerful proximity function to improve image similarity search in CBIR.</p><p>The OMKS task is however very challenging because it must on one hand learn an optimal kernel-based similarity function for each kernel in each modality, and on the other hand determine an optimal combination of multiple kernels in building the final similarity function for similarity search with all modalities. To attack the challenges, we propose a unifying online learning scheme for OMKS, which learns both the optimal similarity function with each individual kernel and the optimal combination of multiple kernels in a coherent and scalable online learning framework. In particular, we apply the online passive aggressive learning technique <ref type="bibr" target="#b14">[15]</ref> to learn the kernel-based similarity function for each individual kernel, and the well-known Hedging online learning technique to learn the optimal combination weights of multiple kernels, from a sequence of triplet training data. As a summary, our key contributions include:</p><p>• We propose a novel framework of learning kernel-based proximity functions with multiple kernels for visual similarity search. To the best of our knowledge, this is the first online learning work in CBIR that learns to rank images based on kernel-based similarity function using multiple kernels. • We present an online learning algorithm for OMKS, which learns both the optimal kernel-based similarity function with an individual kernel and the optimal combination of multiple kernels. • We conduct an extensive set of experiments to evaluate the performance of the proposed technique for CBIR on several image data sets. The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 gives some preliminaries of the related techniques. Section 4 introduces the problem definition and presents the proposed online learning algorithm for OMKS, followed by theoretical analysis in Section 5. Section 6 discusses the experimental results, and section 7 sets out the conclusion of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>This section reviews related work which can be generally grouped into three major categories as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Distance Metric Learning</head><p>Distance Metric Learning (DML) from side information (e.g., relevance feedback logs <ref type="bibr" target="#b15">[16]</ref> or user-generated contents of social images <ref type="bibr" target="#b16">[17]</ref>) has been actively studied in CBIR for several years. In general, most DML works aim to learn an optimal distance metric in the family of Mahalanobis distances, which can be viewed as an equivalent problem of learning an optimal linear projection of original data into a new space, where Euclidean distance is adopted to measure proximity between objects.</p><p>In literature, various DML techniques have been proposed in both machine learning <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> and multimedia <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Some wellknown techniques include Relevant Component Analysis (RCA) <ref type="bibr" target="#b17">[18]</ref>, Discriminative Component Analysis (DCA) <ref type="bibr" target="#b4">[5]</ref> using the idea of Fisher's Linear Discriminant Analysis, Large Margin Nearest Neighbor (LMNN) <ref type="bibr" target="#b19">[20]</ref>, Metric Learning by Collapsing Classes <ref type="bibr" target="#b22">[23]</ref>, learning globally-consistent local distance functions <ref type="bibr" target="#b23">[24]</ref>, Regularized Distance Metric Learning <ref type="bibr" target="#b8">[9]</ref> and Laplacian Regularized Metric Learning (LRML) <ref type="bibr" target="#b10">[11]</ref>, and so on.</p><p>In general, the DML task is cast as a Semi-Definite Programming (SDP) problem due to the impose of Positive Semi-Definite (PSD) constraint on the solution, which is computationally intensive, especially when data is of high dimensionality. Some recent work has attempted to resolve the challenge, such as ITML <ref type="bibr" target="#b24">[25]</ref> and OA-SIS <ref type="bibr" target="#b25">[26]</ref>. ITML uses LogDet divergence which can enforce positive semi-definiteness automatically to bypass the PSD constraint. OASIS drops the PSD constraint and resolves the DML task by an online learning algorithm to maximize the large margin criterion. OASIS is in general a linear metric learning method. Our technique is partially inspired to overcome the limitations of OASIS by studying kernel-based learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Kernel-based Learning for Image Retrieval</head><p>Kernel-based learning techniques are not new for image retrieval. Our technique differs from the existing kernelbased learning techniques proposed for image retrieval in literature. For example, kernel SVM algorithms have been proposed for active learning in CBIR <ref type="bibr" target="#b26">[27]</ref>, which however address different types of problems as ours.</p><p>In literature, several kernel-based distance metric learning algorithms <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> were proposed for learning similarity functions in CBIR. Also, a family of metric learning algorithms including LMNN and NCA have been shown to be able to be kernelized by KPCA trick <ref type="bibr" target="#b11">[12]</ref>. Some recent work also reveals the connections between metric and kernel learning in <ref type="bibr" target="#b12">[13]</ref>, which may naturally provide kernelization for a larger class of metric learning methods. Our techniques differ from these approaches in two key aspects. First, they are designed to learn with a single kernel while the proposed algorithm learns with multiple kernels; and second, they usually run in a batch learning approach, which does not scale to large-scale applications. In contrast, we present online learning algorithms for learning a similarity function with multiple kernels.</p><p>We also note that our work is very different from existing kernel learning studies, such as KernelBoost <ref type="bibr" target="#b29">[30]</ref> and nonparametric kernel learning <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, which mainly aim to learn a kernel function/matrix consistent with given constraints. Unlike these studies, the proposed technique learns a kernel-based similarity function, instead of a kernel function, from constraints.</p><p>Finally, some recent studies also proposed online learning techniques to learn kernel-based similarity function for text-based image search. For example, PAMIR <ref type="bibr" target="#b2">[3]</ref> proposed to learn a discriminative model for the image retrieval from text queries using online learning techniques. Our study differs from PAMIR because PAMIR is specially designed for text-based queries and thus cannot be directly applied to the CBIR task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multiple Kernel Learning</head><p>Our work is also closely related to Multiple Kernel Learning (MKL) studies <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, which aim to find the optimal combination of multiple kernels for learning classifiers towards a given classification task. Exemplar algorithms include the convex optimization <ref type="bibr" target="#b32">[33]</ref>, the Semi-Infinite Linear Program (SILP) approach <ref type="bibr" target="#b33">[34]</ref>, and the level method <ref type="bibr" target="#b34">[35]</ref>. In addition, several recent studies <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> address multiple kernel learning for multiclass and multi-labeled data, and some other works aim at improving its efficiency and generality <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>.</p><p>Despite sharing the common goal of finding the optimal combination of multiple kernels, our technique differs significantly from the existing MKL studies in two This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. key aspects. First, we aim to learn kernel-based proximity functions for image ranking tasks while conventional MKL studies often address classification tasks. Second, the training data used by conventional MKL studies are in the regular form of single data instances with class label, while the training data in our problem are in the form of triplet instances.</p><p>We should note that this work was also inspired by our previous work on Online Multiple Kernel Learning (OMKL) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>. The OMKL technique was proposed to learn classifiers by finding an optimal combination of multiple kernels for classification tasks, while the goal of this work is to learn the image similarity function from triplets for retrieval tasks in CBIR. In particular, special care is needed in the design of algorithms to handle the triple constraints. Finally, although MKL has successfully been applied to several computer vision applications <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, to the best of our knowledge, this is the first online learning work that learns a similarity function using multiple kernels for CBIR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>To better motivate our work, we introduce some preliminaries of two closely related techniques: (1) online multiple kernel learning, and (2) large scale online learning of image similarity through ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">OMKL</head><p>We briefly review the recent work on Online Multiple Kernel Learning (OMKL) <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>. This technique in general aims to address a Multiple Kernel Learning (MKL) problem.</p><p>Specifically, given a set of training examples D = {(x i , y i ), i = 1, . . . , n} where y i ∈ {-1, +1}, i = 1, . . . , n, and a collection of m kernel functions K = {κ i : X ×X → R, i = 1, . . . , m}, the goal of an MKL task is to identify the optimal combination of the kernel matrices, denoted by θ = (θ 1 , . . . , θ m ), which minimizes the margin-based classification error. This can be formulated as the following optimization task:</p><formula xml:id="formula_0">min θ∈Δ min f ∈H K(θ) 1 2 f 2 H K(θ) + C n i=1 l(f (x i ), y i )<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">K(θ)(•, •) = m i=1 θ i κ i (•, •), l(f (x i ), y i ) = max(0, 1 -y i f (x i ))</formula><p>, and Δ is defined by</p><formula xml:id="formula_2">Δ = {θ ∈ R m + |θ T e m = 1}.<label>(2)</label></formula><p>The OMKL technique simplifies the MKL problem by learning the following classification function with multiple kernels:</p><formula xml:id="formula_3">f (x) = m i=1 θ i sign(f i (x))<label>(3)</label></formula><p>The OMKL algorithm iteratively updates the prediction function by the perceptron algorithm, i.e.,</p><formula xml:id="formula_4">f t+1,i (x) = f t,i (x) + z i (t)y t κ i (x t , x)<label>(4)</label></formula><p>and learns the combination weights by applying the Hedging online learning technique, i.e.,</p><formula xml:id="formula_5">θ i (t + 1) = θ i (t)β zi(t)<label>(5)</label></formula><p>where β ∈ (0, 1) is a discount weight parameter, which is employed to penalize the kernel classifier that performs incorrect prediction at each learning step, and z i (t) indicates if the i-th kernel classifier makes a mistake on the prediction of the example x t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">OASIS</head><p>Below we briefly introduce another related work of large scale online learning of image similarity through ranking <ref type="bibr" target="#b25">[26]</ref>. Specially, the goal of this problem is to learn a similarity function S(p i , p j ) that assigns higher similarity scores to pairs of more relevant images, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S(p</head><formula xml:id="formula_6">i , p + i ) &gt; S(p i , p - i ), ∀p i , p + i , p - i ∈ P (6) such that r(p i , p + i ) &gt; r(p i , p - i )<label>(7)</label></formula><p>where r(•, •) reflects the relevance between two images. Consider a parametric similarity function that has a bilinear form, S W (p i , p j ) = p T i W p j where W ∈ R d×d , the goal is to find a parametric similarity function S such that all triplets obey the following constraints:</p><formula xml:id="formula_7">S W (p i , p + i ) &gt; S W (p i , p - i ) + 1<label>(8)</label></formula><p>One can define the following hinge loss function for the triplet:</p><formula xml:id="formula_8">l W (p i , p + i , p - i ) = max{0, 1-S W (p i , p + i )+S W (p i , p - i )} (9)</formula><p>As a result, the batch optimization problem of this task can be formulated as:</p><formula xml:id="formula_9">W = arg min W W 2 F ro + C i W (p i , p + i , p - i )<label>(10)</label></formula><p>The online optimization problem is formulated as:</p><formula xml:id="formula_10">W i = arg min W 1 2 W -W i-1<label>2</label></formula><formula xml:id="formula_11">F ro + C W (p i , p + i , p - i )<label>(11)</label></formula><p>By initializing W 0 = I, the online solution of updating W is given as:</p><formula xml:id="formula_12">W i = W i-1 + τ i V i (<label>12</label></formula><formula xml:id="formula_13">)</formula><p>where τ i = min{C,</p><formula xml:id="formula_14">lW i-1 (pi,p + i ,p - i ) Vi 2 } and V i = p i (p + i -p - i ) T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ONLINE MULTIPLE KERNEL SIMILARITY</head><p>We first present our framework for online kernel similarity learning, and then extend it to online multiple kernel similarity learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Online Kernel Similarity</head><p>Our challenge is how to extend the linear similarity function used in OASIS to its kernel version. To this end, for a given kernel κ(•, •) and the corresponding Hilbert space H, we introduce a linear operator L :</p><formula xml:id="formula_15">H → H that maps a function f ∈ H to another function L[f ] ∈ H.</formula><p>Given the linear operator L, we define the similarity function S L (p, q) as</p><formula xml:id="formula_16">S L (q, p) = κ(q, •), L[κ(p, •)] H<label>(13)</label></formula><p>q ∈ X is a query image and p ∈ X is an image in database to be retrieved. Compared to the similarity function S W (p, q) = p W q, we observe that the linear operator L plays the same role as matrix W . Let L be the space that includes all the linear operators in H, i.e.,</p><formula xml:id="formula_17">L = {L : H → H, L is a linear operator}<label>(14)</label></formula><p>Following the framework of OASIS, we develop a framework of kernel similarity learning based on the linear operator. It searches for the optimal linear operator by minimizing the rank loss, i.e.,</p><formula xml:id="formula_18">L * = arg min L∈L L 2 HS + C i L (p i , p + i , p - i ) (15)</formula><p>where • HS is the Hilbert Schmidt norm of the linear operator, and</p><formula xml:id="formula_19">L (p i , p + i , p - i ) = max 0, 1 -S L (p i , p + i ) + S L (p i , p - i )</formula><p>. Next, we develop an online learning algorithm for efficiently solving <ref type="bibr" target="#b14">(15)</ref> based on the online Passive Aggressive (PA) learning <ref type="bibr" target="#b14">[15]</ref>. Similar to the OASIS algorithm, in the proposed online learning algorithm, at each trial t, given triplet p t , p + t , p - t , we solve the following simple optimization problem</p><formula xml:id="formula_20">L t = arg min L∈L 1 2 L -L t-1 2 HS + C L (p t , p + t , p - t )<label>(16)</label></formula><p>where we initialize L 0 to be an identity operator at the beginning of online learning. The following proposition gives the closed-form solution to the above optimization.</p><p>Proposition 1: The optimal solution to the optimization problem in ( <ref type="formula" target="#formula_20">16</ref>) can be expressed as:</p><formula xml:id="formula_21">L t = L t-1 + τ t Z t<label>(17)</label></formula><p>where Z t ∈ L is a rank one linear operator and is given by <ref type="formula" target="#formula_21">17</ref>) is calculated as</p><formula xml:id="formula_22">Z t [h](•) = κ(p t , •) h(p + t ) -h(p - t ) for any h ∈ H. The coefficient τ t in (</formula><formula xml:id="formula_23">τ t = min C, max{0, 1 -S Lt-1 (p t , p + t ) + S Lt-1 (p t , p - t )} κ(p t , p t )(κ(p + t , p + t ) -2κ(p + t , p - t ) + κ(p - t , p - t ))<label>(18</label></formula><p>) Proof: We rewrite the problem into a constrained form:</p><formula xml:id="formula_24">min L∈L,ξ≥0 1 2 L -L t-1 2 HS + Cξ s. t. 1 -κ(p t , •), L[κ(p + t , •) -κ(p - t , •)] H ≤ ξ</formula><p>We define the Lagrangian as</p><formula xml:id="formula_25">g(L, ξ, τ, λ) = 1 2 L -L t-1 2 HS + Cξ -λξ +τ 1 -ξ -tr(LZ † t )</formula><p>where τ ≥ 0 and λ ≥ 0 are Lagrangian multipliers, and Z t : H → H is a rank one linear operator defined as</p><formula xml:id="formula_26">Z t [h](•) = κ(p t , •) κ(p + t , •) -κ(p - t , •), h H</formula><p>and Z † t is the adjoint of Z t . By setting ∂g(L,ξ,τ,λ) ∂L = 0, we have the following</p><formula xml:id="formula_27">∂g(L, ξ, τ, λ) ∂L = L -L t-1 -τZ t = 0</formula><p>and therefore L = L t-1 + τZ t . Next, by setting ∂g(L,ξ,τ,λ) ∂ξ = 0, we have</p><formula xml:id="formula_28">C -τ -λ = 0</formula><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</p><p>Since λ ≥ 0, we have τ ≤ C. Thus, we have:</p><formula xml:id="formula_29">g(τ ) = 1 2 τ 2 Z t 2 HS + τ (1 -tr(LZ † t )) = - 1 2 τ 2 Z t 2 HS + τ (1 -tr(L t-1 Z † t ))</formula><p>Further, by setting ∂g(τ ) ∂τ = 0, we have ∂g(τ</p><formula xml:id="formula_30">) ∂τ = -τ Z t 2 HS + 1 -tr(LZ † t ) = -τ Z t 2 HS + Lt-1 (p t , p + t , p - t ) = 0 Thus, we have τ = Lt-1 (p t , p + t , p - t ) Z t 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HS</head><p>Combining the fact that τ ≤ C, we prove the proposition by using the fact</p><formula xml:id="formula_31">Z t 2 HS = κ(p t , •) 2 HS κ(p + t , •) -κ(p - t , •) 2 HS = κ(p t , p t ) κ(p + t , p + t ) + κ(p - t , p - t ) -2κ(p + t , p - t )</formula><p>Using the above result, we can rewrite S Lt (q, p) as</p><formula xml:id="formula_32">S Lt (q, p) = κ(q, •), L t [κ(p, •)] H = κ(q, p) + t l=1 τ l κ(q, p l )(κ(p + l , p) -κ(p - l , p))<label>(19)</label></formula><p>Similar to the function learned by support vector machines (SVM), we slightly abuse the concept of Support Vectors (SV) to define each triplet (p l , p + l , p - l ) of nonzero coefficient τ l &gt; 0 as a support vector for the learned linear operator. Thus, during the whole training process, we should only keep trace of the support vectors and their coefficients. Algorithm 1 summarizes the proposed algorithm for Online Kernel Similarity (OKS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Online Kernel Similarity (OKS)</head><p>INPUT: parameter C, training triplets:</p><formula xml:id="formula_33">(p t , p + t , p - t ), an in- put kernel κ(•, •) : χ×χ → R 1: Initialization: L 0 = I 2: for t = 1, 2, . . . , T do 3: Receive a training triplet: (p t , p + t , p - t ) 4:</formula><p>Compute τ t in <ref type="bibr" target="#b17">(18)</ref> 5:</p><p>Update L t as (17) 6: end for OUTPUT:</p><formula xml:id="formula_34">S(p, q) = κ(p, •), L T [κ(q, •)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Online Multiple Kernel Similarity</head><p>We now extend the above online kernel similarity learning problem to the setting of learning with multiple kernels, i.e., the Online Multiple Kernel Similarity (OMKS) learning task. Figure <ref type="figure" target="#fig_0">1</ref> shows the system flow of the proposed OMKS scheme.</p><p>Let K = {κ i : X × X → R, i = 1, . . . , m} be a collection of m kernel functions. Our goal is to identify the optimal combination of the m kernels, denoted by θ = (θ 1 , . . . , θ m ), and consequentially learn the combined kernel similarity function that can be used effectively for image similarity search, i.e.,</p><formula xml:id="formula_35">f (q, p) = m i=1 θ i S i (q, p) = m i=1 θ i κ i (q, •), L i [κ i (p, •)] Hκ i (20) where L i ∈ L i = {L : H κi → H κi , L is a linear operator} and S i (q, p) = κ i (q, •), L i [κ i (p,</formula><p>•)] Hκ i is the similarity function based on the linear operator L i . To simultaneously learn both the combination weights {θ i } m i=1 and the linear operators {L i } m i=1 , we cast multiple kernel similarity learning into the following optimization problem</p><formula xml:id="formula_36">min θ∈Δ min {Li} m i=1 1 2 m i=1 θ i L i 2 HS + C T t=1 (f (p t , p + t ) -f (p t , p - t ))<label>(21)</label></formula><p>where f (p, q) is given in <ref type="bibr" target="#b19">(20)</ref>, Δ is defined in ( <ref type="formula" target="#formula_2">2</ref>) and (z) is the hinge loss.</p><p>Remark. At the first glance, the formulation of multiple kernel similarity learning in ( <ref type="formula" target="#formula_36">21</ref>) may be very different from that for multiple kernel learning in (1). This difference is in fact superficial. According to <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, the problem in ( <ref type="formula" target="#formula_0">1</ref>) is equivalent to the following optimization problem</p><formula xml:id="formula_37">min θ∈Δ min {fi} m i=1 1 2 m i=1 θ i f i 2 HS + C T t=1 (f (x i ), y i )<label>(22)</label></formula><p>where f (x) = m i=1 θ i f i (x). By comparing <ref type="bibr" target="#b21">(22)</ref> to <ref type="bibr" target="#b20">(21)</ref>, we can find that multiple kernel similarity learning is almost identical to multiple kernel learning except that the kernel prediction functions f i in (1) is replaced with the linear operator L i in <ref type="bibr" target="#b20">(21)</ref>, and the loss functions are somewhat different.</p><p>There are two sets of target variables to be learned in the OMKS task, i.e., the combination weights of multiple kernels, and the set of linear operators with respect to each of different kernels. Following the idea of the online multiple kernel learning <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, we apply the Hedging algorithm to online learn the combination weights of multiple kernels, and then apply the online kernel similarity learning algorithm to learn the similarity function of each individual kernel.</p><p>Specifically, for each of the m kernels, e.g., κ i , on every online learning trial, we apply Proposition 1 to find the optimal coefficient for learning the similarity function with respect to kernel κ i , and then apply the Hedging algorithm to update the combination weights as follows:</p><formula xml:id="formula_38">θ i (t) = θ i (t -1)β zi(t)</formula><p>where β ∈ (0, 1) is a discounting parameter, and z i (t) equals to 1 when S Lt-1,i (p t , p + t )-S Lt-1,i (p t , p - t ) ≤ 0, and 0 otherwise.</p><p>Algorithm 2 summarizes the proposed algorithm for Online Multiple Kernel Similarity (OMKS). Finally, we Algorithm 2 Online Multiple Kernel Similarity (OMKS) INPUT: for i = 1, 2, . . . , m do 5:</p><formula xml:id="formula_39">• Kernels: κ i (•, •) : χ × χ → R, i = 1, • • • , m • Combination weights θ i (0) = 1, i = 1, . . . , m • Discount weight β ∈ (0, 1) 1: Initialize L 0,i = I, i ∈ [m] 2: for t = 1,</formula><p>Compute τ t,i in (18) using L t-1,i for L t-1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Update L t,i by <ref type="bibr" target="#b16">(17)</ref> with Z t,i given by</p><formula xml:id="formula_40">Z t,i [h](•) = κ i (p t , •) κ i (p + t , •), h Hκ i -κ i (p - t , •), h Hκ i 7: if S Lt-1,i (p t , p + t ) -S Lt-1,i (p t , p - t ) ≤ 0 then 8:</formula><p>Set z i (t) = 1 Update</p><formula xml:id="formula_41">θ i (t) = θ i (t -1)β zi(t)</formula><p>13:</p><p>end for 14: end for OUTPUT: </p><formula xml:id="formula_42">f (q, p) = m i=1 θ i (T ) κ i (q, •), L T,i [κ i (p, •)] Hκ i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">THEORETICAL ANALYSIS</head><p>First of all, we analyze the mistake bound of the proposed Online Kernel Similarity (OKS) algorithm as shown in Algorithm 1 in the following theorem.</p><p>Theorem </p><formula xml:id="formula_43">M ≤ min L 1 min(1/R, C) L -I 2 HS + 2C T t=1 lL(pt, p + t , p - t )</formula><p>Proof:</p><formula xml:id="formula_44">Δ t = L t-1 -L 2 HS -L t -L 2 HS = L t-1 -L 2 HS -L t-1 -L + τ t Z t 2 HS = -2τ t [(S Lt-1 (p t , p + t ) -S Lt-1 (p t , p - t )) -(S Lt (p t , p + t ) -S Lt (p t , p - t ))] -τ 2 t Z t 2 HS ≥ τ t (2 t -τ t Z t 2 HS -2 * t )</formula><p>where </p><formula xml:id="formula_45">(τ t t -2C * t )<label>(24)</label></formula><p>Combining Equation ( <ref type="formula">23</ref>) and ( <ref type="formula" target="#formula_45">24</ref>), we have</p><formula xml:id="formula_46">T t=1 τ t t ≤ L -I 2 HS + 2C T t=1 * t<label>(25)</label></formula><p>If the algorithm makes a mistake on round t then t ≥ 1.</p><p>In addition, according to the assumption, we have</p><formula xml:id="formula_47">τ t = min( t / Z t 2 HS , C) ≥ min(1/R, C</formula><p>). Thus, we have:</p><formula xml:id="formula_48">T t=1 τ t t ≥ min(1/R, C)M</formula><p>Plugging the above result into the previous equation will result in the conclusion stated in the theorem. Secondly, we analyze the mistake bound of the proposed Online Multiple Kernel Similarity (OMKS) algorithm in Algorithm 2. For the convenience of discussions, we define the following notations:</p><formula xml:id="formula_49">θ t = m i=1 θ i (t), q i (t) = θ i (t) θ t z i (t) = I S Lt-1,i (p t , p + t ) -S Lt-1,i (p t , p - t ) ≤ 0</formula><p>where I(x) is an indicator function that outputs 1 when x is true and 0 otherwise. Here, q i (t) essentially defines the mixture of kernel similarity functions, and z i (t) indicates if training example (p t , p + t , p - t ) is misclassified by the ith kernel similarity function at trial t. Finally, we define the optimal margin error g(κ i , l, L) for the kernel </p><formula xml:id="formula_50">κ i (•, •) with respect to a collection of training examples L = {(p t , p + t , p - t ), t = 1, . . . , T } satisfying κ i (p t , p t )(κ i (p + t , p + t ) -2κ i (p + t , p - t ) + κ i (p - t , p - t )) ≤ R i as g(κi, l, L) = min L ⎧ ⎨ ⎩ L -I 2 HS + 2C T t=1 L(pt, p + t , p - t ) min(1/Ri, C) ⎫ ⎬ ⎭ Theorem 2: After receiving a sequence of T training examples, denoted by L = {(p t , p + t , p - t ), t = 1, . . . , T } sat- isfying κ i (p t , p t )(κ i (p + t , p + t ) -2κ i (p + t , p - t ) + κ i (p - t , p - t )) ≤ R i ,</formula><formula xml:id="formula_51">M = T t=1 I(S Lt-1 (p t , p + t ) -S Lt-1 (p t , p - t ) ≤ 0) = T t=1 I m i=1 q i (t -1)z i (t) ≥ 0.5</formula><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</p><p>is bounded as follows</p><formula xml:id="formula_52">M ≤ 2 ln(1/β) 1 -β min 1≤i≤m T t=1 z i (t) + 2 ln m 1 -β<label>(26)</label></formula><formula xml:id="formula_53">≤ 2 ln(1/β) 1 -β min 1≤i≤m g(κ i , l, L) + 2 ln m 1 -β<label>(27)</label></formula><p>By choosing the value of</p><formula xml:id="formula_54">β as β = √ T √ T + √ ln m , we have M ≤ 2 1 + ln m T min 1≤i≤m g(κ i , l, L) + ln m + √ T ln m</formula><p>The proof to the above theorem essentially combines the results of the passive aggressive learning algorithm <ref type="bibr" target="#b14">[15]</ref> and the Hedge learning algorithm. We omit the details of our proof due to space limitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>In this section, we conduct an extensive set of experiments to evaluate the efficacy of the proposed algorithms for visual similarity search in CBIR. The data sets and code of our experiments can be found in our project web site http://OMKS.stevenhoi.org/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Testbed</head><p>We adopt five publicly available image data sets 1 . These five data sets have been widely used for the benchmark of image retrieval, classification and recognition tasks. The first testbed is the "Indoor" database 2 , which was used for the research of recognizing indoor scenes <ref type="bibr" target="#b44">[45]</ref>. This data set consists of 67 indoor categories, and a total of 15620 images. The number of images contained in different categories are diverse, but each category contains at least 100 images. It is further divided into five subsets: store, home, public spaces, leisure, working place. We evaluate the performance of different algorithms individually on a randomly picked subset: public spaces ( we name it "Public", it is also used to evaluate the effect of parameters) as well as the whole indoor collection.</p><p>The second testbed is the "Caltech256" database 3 , which has been widely adopted for object recognition and image retrieval tasks <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b25">[26]</ref>. This database contains 256 object categories (excluding the background category) and a total of 30607 images. Following the similar experiments as the previous work <ref type="bibr" target="#b25">[26]</ref>, we pick 10, 20 or 50 out of the 256 classes to form three subsets (the same sets as used in <ref type="bibr" target="#b25">[26]</ref>), which are named as "Caltech10", "Caltech20", and "Caltech50", respectively.</p><p>The third testbed is the "Corel5000" database <ref type="bibr" target="#b4">[5]</ref>. The image testbed consists of real-world photos from COREL image CDs. It has 50 categories, with each category contains exactly 100 images that are randomly selected from relevant examples in the COREL image CDs. The fourth testbed is the "ImageCLEF" database 4 , which was also used in <ref type="bibr" target="#b21">[22]</ref>. It is a medical image data set. We also combine "ImageCLEF" with a collection of 100,000 social photos crawled from Flickr, this larger set is named "ImageCLEF+". For the Flickr photos, we treat all of them as the background noisy photos, which are mainly used to test the scalability of our algorithms.</p><p>The fifth testbed is the "Oxford Buildings" database 5 , which was first used in <ref type="bibr" target="#b46">[47]</ref>. It consists of 5062 images collected from Flickr by searching for particular Oxford landmarks. The query set contains 55 queries from 11 different landmarks. We name it "Oxford" for short.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Setup</head><p>For each data set (except "Oxford" which has no categorial info), we randomly select a subset from each class to make sure that all classes have the same number of images as the one has least images in the original data set. This can avoid the performance being dominated by some single class of large number of images. Based on the data set, we then randomly select 50% examples from each class to form a training set, 10% examples to form a validation set, 10% examples to form a query set, and the rest 30% examples to form the test set for retrieval evaluation. The validation set is mainly used to determine the best parameters and the best cases of the compared algorithms. The final results are averages over 5 splits. We measure both mean and standard deviation of the results, and highlight the best case by performing student t-tests with the significance level α = 0.05.</p><p>We need to generate side information in the forms of triplet training instances for learning the similarity functions by OASIS and the proposed algorithms, and also pairwise training data instances for the kernelized ITML algorithm (KITML) <ref type="bibr" target="#b12">[13]</ref>. In our approach, we generate the side information by sampling triplet constraints from the images in the training set according to their ground truth class labels. Specifically, we generate all positive pairs (two images belong to the same class), and for each positive pair we randomly select another image from another class to form a triplet. Then two pairwise constraints (p, p + , +1) and (p, p -, -1) can be derived from the triplet (p, p + , p -). After that we randomly sample 20% (i.e., RatioT rain = 20%) of all training instances to form the training set in order to speed up the experiments (as we can see in section 6.6, the performance improves along with the number of training instances increases and then arrives at a saturated value).</p><p>For the "Oxford" data set, we randomly split the query set into 5 portions. Then for each split, we test the algorithms 5 times, each time select a different portion as query set, one portion as validation set, the others are left as training set. This can make sure that the average of these 5 runs is the evaluation of the whole query set. The same as the other data sets, the final results are averaged 4. http://imageclef.org/ 5. http://www.robots.ox.ac.uk/ vgg/data/oxbuildings/index.html This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. over 5 splits. The side information can be generated easily from the ground truth, we use all positives, and for each positive we randomly select a negative.</p><p>We evaluated the performance of all algorithms using some standard performance metrics for ranking in multimedia retrieval. Specifically, for each query image in the query set, all the test images are ranked according to their similarities to the query image, which returns a set of top n similar images for the query. We can measure the precision at top n returned images by computing the number of top-n images of the same class label as the query image. We also adopt the standard mean Average Precision (mAP) to evaluate the retrieval result. In particular, the Average Precision (AP) value is the area under precision-recall curve for a query. The mAP value is calculated based on the average AP value of all the queries. The precision value is the ratio of relevant examples over the total retrieved examples, while recall is the ratio of the relevant examples retrieved over the total relevant examples in the database.</p><p>Finally, all of the experiments were run in MATLAB environment on a Linux machine with 3GHz Intel CPU and 16GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Image Descriptors and Kernel Functions</head><p>Here we describe how to to extract features from images by different descriptors, and how to compute different kernel functions based on different kinds of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Image Descriptors</head><p>We adopt both global and local feature descriptors to extract features for representing images in our experiments. We have done some preprocessing of resizing all the images to the scale of 500 × 500 pixels while keeping the aspect ratio unchanged.</p><p>For global features, we extract five kinds of features, including (1) color histogram and color moments (81 dimensions), (2) edge direction histogram (37 dimensions), (3) Gabor wavelets transform (120 dimensions), (4) Local Binary Pattern (59 dimensions), and (5) GIST features (512 dimensions). These global features have been widely used in previous CBIR studies.</p><p>For local features, we extract the bag-of-visual-words features using two types of descriptors: (i) the SIFT descriptor -we adopt the Hessian-Affine interest region detector with threshold 500; and (ii) the SURF descriptor -we adopt the SURF detector with threshold 500. For the clustering step, we adopt a forest of 16 kd-trees and search 2048 neighbors to speed up the clustering task. Finally, we adopt the TF-IDF weighing scheme to generate the final bag-of-visual-words representation. By choosing different descriptors (SIFT/SURF) and vocabulary sizes (200/1000), we totally extracted four kinds of local features: SIFT200, SIFT1000, SURF200 and SURF1000. For the "Oxford" data set, we use larger vocabulary sizes (20,000 and 100,000) instead, because it prefers larger code book size.</p><p>We apply PCA to all kinds of features and keep the first 50 dimensions (if the original dimension is less than 50, we keep all dimensions) to improve the efficiency of the experiment. For those features whose dimension is larger than 10,000, Singular Value Decomposition (SVD) is performed to keep the first 1,000 dimensions. After dimension reduction, we normalize all feature vectors to unit length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Kernel Functions</head><p>In the above, we represent each image in our database by a total of 9 types of different features. Based on these features, we can build a series of kernel functions on these features. To facilitate the learning tasks, we normalize all the kernel values to the range of [0,1].</p><p>We adopt 4 kernel functions to build kernels on each kind of feature, which thus results in a total of 36 different kernels. The 4 kernels used in our approach are described as follows:</p><formula xml:id="formula_55">• RBF kernel: κ(x, x ) = exp(-d(x,x ) γσ 2 )</formula><p>, where d(•, •) is the Euclidean distance, the kernel parameter γ is selected as the mean of the pairwise distance, σ is used to control the bandwidth, we select σ ∈ {2 -1 , 2 0 , 2 1 }.</p><p>• Kernel using cosine similarity: κ(x, x ) = &lt;x,x &gt; x 2 x 2 . We normalize the kernel κ(x, x ) = 0.5 &lt;x,x &gt; x 2 x 2 + 0.5 to the range of [0,1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Comparison Algorithms</head><p>To extensively examine the efficacy of the proposed algorithms, we have implemented the following algorithms:</p><p>• Eucl.-Best: We test the retrieval performance of all kinds of features on the validation set by ranking with Euclidean distance, and then select the best feature of the highest mAP. We report the result of this feature by ranking with Euclidean distance. • RCA-Best: We train the RCA <ref type="bibr" target="#b47">[48]</ref> model on the training set for all the features and test the retrieval performance of all kinds of features on the validation set by RCA, and then select the best feature of the highest mAP value. We report the result of this feature by RCA. • LMNN-Best: We train the LMNN <ref type="bibr" target="#b19">[20]</ref> model on the training set for all the features and test the retrieval performance of all kinds of features on the validation set by LMNN, and then select the best feature of the highest mAP value. We report the result of this feature by LMNN. • OASIS-Best: We train the OASIS <ref type="bibr" target="#b25">[26]</ref> model on the training set for all the features and test the retrieval performance of all kinds of features on the validation set by OASIS, and then select the best feature of the highest mAP value. We report the result of this feature by OASIS. • KRCA-Best: We train the KRCA <ref type="bibr" target="#b48">[49]</ref> model on the training set for all the kernels and test the retrieval performance of all kinds of kernels on the validation .0151 Note: KITML algorithms are too computationally intensive to run on large data sets, so we report the results by a low rank scheme proposed in <ref type="bibr" target="#b12">[13]</ref> instead; some algorithms cannot run on "Oxford" dataset without class labels.</p><p>set by KRCA, and then select the best kernel of the highest mAP value. We report the result of this kernel by KRCA. • KITML-Best: We train the kernelized ITML (KITML) <ref type="bibr" target="#b12">[13]</ref> model on the training set for all the kernels, then test the retrieval performance of all kinds of kernels by KITML on the validation set, and finally select the best kernel of the highest mAP value. We report the result of this scheme using KITML with this kernel. • KITML-Avg: We build an average kernel at first by κ(x, x ) = m i=1 1 m κ i (x, x ). Then we report the result of this kernel by KITML.</p><p>• Eucl.-Con: We first concatenate all kinds of features together, and then report the result of this feature by ranking with Euclidean distance. • RCA-Con: We first concatenate all kinds of features together, and then report the result of this feature by RCA <ref type="bibr" target="#b47">[48]</ref>. • LMNN-Con: We first concatenate all kinds of features together, and then report the result of this feature by LMNN <ref type="bibr" target="#b19">[20]</ref>.</p><p>• OASIS-Con: We first concatenate all kinds of fea-tures together, and then report the result of this feature by OASIS <ref type="bibr" target="#b25">[26]</ref>.</p><p>• KRCA-Con: We first concatenate all kinds of features together, then train the KRCA <ref type="bibr" target="#b48">[49]</ref> model on the training set for all 4 kernels of this feature and test the retrieval performance of theses 4 kinds of kernels on the validation set by KRCA, and select the best kernel of the highest mAP value. We report the result of this kernel by KRCA. • KITML-Con: We first concatenate all kinds of features together, then train the KITML <ref type="bibr" target="#b12">[13]</ref> model on the training set for all 4 kernels of this feature, then test the retrieval performance of theses 4 kinds of kernels by KITML on the validation set, and finally select the best kernel of the highest mAP value. We report the result by KITML using this kernel. • OKS-Best: We train the OKS model by Algorithm 1 on the training set for all the kernels and test the retrieval performance of all kinds of kernels on the validation set by OKS, and then select the best kernel of the highest mAP value. We report the result of this kernel by OKS. • OKS-Avg: We build an average kernel at first by This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. κ(x, x ) = m i=1 1 m κ i (x, x ). Then we report the result of this kernel by Algorithm 1.</p><p>• OMKS-U: Use f (q, p) = m i=1 1 m S i (q, p) instead of f (q, p) = m i=1 θ i S i (q, p) for OMKS. • OMKS-W: Use f (q, p) = m i=1 θ i S i (q, p) for OMKS, but the weight is computed as θ i = e mAPi . mAP i is obtained by training the OKS model on the training set and test it on the validation set.</p><p>• OMKS: The proposed OMKS algorithm as shown in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Experimental Results</head><p>We now present the experimental results of performance evaluations on the data sets. We measure the performance in terms of top-n (n = 1, 2 Second, by comparing the linear methods based on the best feature (RCA-Best and OASIS-Best) with the kernel-based methods using the best kernel (KRCA-Best and OKS-Best), we observed that the kernel methods can improve the performance of the linear methods significantly. OKS-Best consistently outperforms all the other methods based on either single feature or single kernel. We also got the results of full rank KIMTL-Best (KITMLFR-Best) on three small scale data sets "Public", "Caltech10" and "Caltech20", their mAP values are 0.1911, 0.2754, 0.1989 respectively. It seems that KITMLFR-Best performs slightly better than OKS-Best (though their difference is not statistically significant). We believe this result is fairly encouraging since OKS-Best is an online learning method while KITMLFR-Best is a batch learning method. Despite their comparable performance, we emphasize OKS-Best is empirically more attractive due to its significant advantage in efficiency and scalability over KITMLFR-Best. In particular, as the time efficiency evaluation shown in TABLE 2, the running time of KITMLFR-Best is at least 700 times of that of OKS-Best, and the gain becomes more significant when the data set size increases. Because of the extremely high computational cost, KITMLFR-Best simply cannot run on large data sets as it will take several months to run these data sets on the same machine, so we report the results by a low rank scheme proposed in <ref type="bibr" target="#b12">[13]</ref> instead. The dimension of KITML is set to 1/5 that of the original dimension and no more than 200. It can be observed that though this low rank scheme can improve the efficiency, it causes some loss in performance, such as for "Oxford" data set when the dimension is reduced from bout 5,000 to 200, KITML failed to beat the baseline, so they were not include in TABLE <ref type="table" target="#tab_5">1</ref>. These promising results show that the proposed OKS algorithm is able to learn the similarity function more effectively and efficiently than the state-of-the-art techniques. Third, we found that the methods based on the concatenated feature do not always outperform those based on the best feature. For example, consider the "Euclidean" distance, the feature concatenation approach outperforms the best feature only on dataset "Public", "Indoor", "Caltech50", "Corel5000", but fails on the other datasets. This observation implies that the feature concatenation is not optimal for combining different kinds of features.</p><p>Fourth, OKS-Avg outperforms OKS-Best on dataset "Public", "Indoor", "Caltech20", "Caltech50", "Corel5000", but fails on the other data sets. In general, it is hard to conclude which is always better the other. We believe whether or not the average kernel outperforms the best kernel should depend on the properties of the underlying data set and individual kernels. If the best kernel significantly outperforms the other kernels or there are a number of very poor kernels for the given data set, OKS-Best would be more likely to outperform OKS-Avg on such data set.</p><p>Fifth, OMKS-U and OMKS-W outperform OKS-Best in most cases, but fail on "Caltech10" and "Oxford". This is primarily because some kernels have very poor performance, which in turn reduces the effectiveness of the uniform and the simple weighted combination. This result again motivates the importance of studying more advanced kernel combination approaches.</p><p>Finally, by examining the results of the proposed algorithm, we found that it consistently outperforms the other algorithms on all the data sets. This promising result shows that OMKS is able to learn an effective similarity function with multiple kernels by learning the optimal combination weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Evaluation with Varied-Size Training Data</head><p>In the previous experiments, we fixed training data by setting the parameter of RatioT rain to 20%. In this section, we evaluate the impact of varied amounts of training triplets for the proposed algorithms, as well as OASIS-Best which also adopts the same amounts of triplets as input. Fig. <ref type="figure">3</ref> shows the evaluation results under varied values of RatioT rain used for building the similarity functions on two sampled data sets. From the results, we observed that all the algorithms in comparison share the similar performance trend as the number of training triplets increases. In particular, the larger the value of RatioT rain, the better the retrieval performance can be achieved by the learning algorithms. Moreover, when RatioT rain is large enough, e.g., over 40%, the improvements by most of the learning algorithms tend to become smaller, which is mainly attributed to sufficiently large amount of training data. Finally, similar to the previous experiments, for all the cases under varied values of RatioT rain, the proposed OMKS algorithm can perform significantly better than the other competing algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Experiments Under Another Setup</head><p>Table <ref type="table" target="#tab_8">3</ref> shows the experimental results obtained by following exactly the same settings as the previous work of OASIS <ref type="bibr" target="#b25">[26]</ref>, where "OASIS-Ori" is our implementation of OASIS based on the original features used in <ref type="bibr" target="#b25">[26]</ref>, and the others are the same as those described in Section 6.4 using our own features.</p><p>First of all, by comparing "OASIS-Ori" with the results published in <ref type="bibr" target="#b25">[26]</ref>, they are very similar, where the only slight differences were caused due to the randomization issues, i.e., different random splits, random generated training triplets and cross validation ranges.</p><p>Second, as our implemented algorithms adopt different features, the results of "OASIS-Best" are different from those of "OASIS-Ori". In general, our single best feature tends to perform worse than the original features used in <ref type="bibr" target="#b25">[26]</ref>; we conjecture this may be because they have adopted a well-design feature for this particular data set.</p><p>Third, by comparing the results of "OMKS", "OKS-Best", "OASIS-Best" and "Eucl.-Best", it is again to validate that our proposed algorithms "OMKS" and "OKS-Best" are significantly more effective by following another different experimental setup.</p><p>Finally, no matter which kinds of features used by OASIS, our algorithms can always make consistent improvements over the results of OASIS by following the same experimental setup in <ref type="bibr" target="#b25">[26]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">Qualitative Comparison</head><p>In the last experiment, we sample several query images, and compare the top ranked images retrieved by different methods. Fig. <ref type="figure" target="#fig_4">4</ref> shows the qualitative comparisons of six different query examples obtained by four different algorithms, including "OASIS-Best", "OKS-Best", "OMKS-U" and "OMKS". From the visual results, we observe that in general, "OKS-Best" retrieves more relevant images than "OASIS-Best", as illustrated by the results for the first two queries. This result implies the importance of introducing nonlinear similarity functions in ranking. But at the same time, we notice that for all the other 4 queries, the results by "OKS-Best" are (a) "Public" (b) "Caltech10" Fig. <ref type="figure">3</ref>. Evaluation of RatioTrain on both "Public" and "Caltech10" data set. not so perfect, which often returns irrelevant images similar to OASIS-Best. The result of query 3 and 4 indicates that "OMKS-U" tends to perform better than "OKS-Best", validating the importance of incorporating multiple kernels built from diverse modalities. On the other hand, "OMKS-U" does not outperform "OKS-Best". For example, for query 5, "OKS-Best" obtained 3 relevant images out of 4, while "OMKS-U" only obtained 1. Overall, OMKS overcomes the limitations of OMKS-U and is able to always find relevant images for all the queries, showing the significance of appropriately weighing individual kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>This paper addressed a fundamental problem of learning similarity functions for ranking images towards visual similarity search. To overcome the limitations of conventional distance metric learning techniques, we proposed a novel Online Multiple Kernel Similarity (OMKS) learning scheme that can effectively improve image similarity search by learning nonlinear proximity functions beyond conventional linear distance metric learning framework. By exploring the power of multiple kernels in combining multi-modal data, OMKS learns a much more flexible and powerful kernel-based proximity function to improve image similarity search in CBIR. We developed an efficient online learning algorithm and extensively evaluated the proposed algorithms for image similarity search on a number of public image databases. Our empirical results showed that OMKS significantly surpasses the state-of-the-art linear and nonlinear metric learning techniques for image similarity search. Despite being tested on image retrieval tasks, the proposed framework is rather generic for any multimedia retrieval tasks <ref type="bibr" target="#b49">[50]</ref>.</p><p>For future work, we plan to explore more applications and address other practical challenges of the proposed OMKS framework for large-scale applications, such as the convergence rate <ref type="bibr" target="#b50">[51]</ref> and budget online learning issues <ref type="bibr" target="#b51">[52]</ref>. For each block, the first image is the query, and the results from the first line to the fourth line represents "OASIS-Best", "OKS-Best", "OMKS-U" and "OMKS", respectively. The category names for the queries are as follows: 1 (roulette wheel), 2 (billard), 3 (skyscraper), 4 (bear), 5 (minotaur), 6 (laptop).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The system flow of the proposed online multiple kernel similarity learning scheme for visual search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>also analyze the theoretical bounds of the two proposed OKS and OMKS algorithms in Section 5. Remark. It is not difficult to analyze the time complexity of the proposed OKS and OMKS algorithms. Specifically, the time complexity of OKS is O(T |SV |), where |SV | denotes the size of support vectors of the similarity function, and the time complexity of OMKS is O(T |SV |m). By assuming small |SV | and m values, both algorithms are generally linear w.r.t. the number of training instances, making the proposed learning scheme efficient and scalable for large applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>the number of mistakes M made by running the algorithm in Algorithm 2, denoted by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Top-n precision results on "Public" and "Caltech10" data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Qualitative comparison of image similarity search results on the "Caltech10" database by different algorithms.For each block, the first image is the query, and the results from the first line to the fourth line represents "OASIS-Best", "OKS-Best", "OMKS-U" and "OMKS", respectively. The category names for the queries are as follows: 1 (roulette wheel), 2 (billard), 3 (skyscraper), 4 (bear), 5 (minotaur), 6 (laptop).</figDesc><graphic coords="13,48.95,56.45,511.22,279.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>2, . . . , T do</figDesc><table><row><cell>3:</cell><cell>Receive a training triplet: (p t , p + t , p -t )</cell></row><row><cell>4:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Then the number of prediction mistakes M made by OKS on this sequence of examples is bounded by:</figDesc><table><row><cell>T , p -T ) be a se-quence of triplet examples, where p t , p + t , p -t ∈ R n , and assume Z t 2 HS = κ(p t , p t )(κ(p + t , p + t ) -2κ(p + t , p -t ) + κ(p -t , p -</cell></row></table><note><p>1: Let (p 1 , p + 1 , p - 1 ), . . . , (p T , p + t )) ≤ R for all t.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Lt-1 (p t , p + t , p - t ) and * t = L (p t , p + t , p - t ), thus HS ≤ t and τ t ≤ C.</figDesc><table><row><cell>T</cell><cell></cell><cell></cell></row><row><cell>τ t (2 t -τ t Z t</cell><cell cols="3">2 HS -2  *  t ) ≤</cell><cell>Δ t ≤ L -I 2 HS (23)</cell></row><row><cell>t=1</cell><cell></cell><cell></cell></row><row><cell cols="3">Since τ t = min( t / Z t</cell><cell>2 HS , C), τ t Z t</cell><cell>2</cell></row><row><cell>T</cell><cell></cell><cell></cell><cell>T</cell></row><row><cell cols="2">τ t (2 t -τ t Z t</cell><cell cols="2">2 HS -2  *  t ) ≥</cell></row><row><cell>t=1</cell><cell></cell><cell></cell><cell>t=1</cell></row></table><note><p>t =</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 1</head><label>1</label><figDesc>Experimental results of mAP performance.</figDesc><table><row><cell>Alg.</cell><cell>Metric</cell><cell>Public</cell><cell>Indoor</cell><cell>Caltech10</cell><cell>Caltech20</cell><cell>Caltech50</cell><cell>Corel5000</cell><cell cols="2">ImageCLEF ImageCLEF+</cell><cell>Oxford</cell></row><row><cell>Eucl.-Best</cell><cell>mAP</cell><cell>0.1628</cell><cell>0.0439</cell><cell>0.2220</cell><cell>0.1668</cell><cell>0.0982</cell><cell>0.1833</cell><cell>0.4125</cell><cell>0.1224</cell><cell>0.4360</cell></row><row><cell></cell><cell>std</cell><cell>±0.0017</cell><cell>±0.0007</cell><cell>±0.0068</cell><cell>±0.0017</cell><cell>±0.0028</cell><cell>±0.0047</cell><cell>±0.0131</cell><cell>±0.0105</cell><cell>±0.0000</cell></row><row><cell>RCA-Best</cell><cell>mAP</cell><cell>0.1595</cell><cell>0.0435</cell><cell>0.2203</cell><cell>0.1656</cell><cell>0.0995</cell><cell>0.1831</cell><cell>0.4563</cell><cell>0.1413</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0073</cell><cell>±0.0006</cell><cell>±0.0085</cell><cell>±0.0011</cell><cell>±0.0031</cell><cell>±0.0040</cell><cell>±0.0130</cell><cell>±0.0129</cell><cell></cell></row><row><cell>LMNN-Best</cell><cell>mAP</cell><cell>0.1618</cell><cell>0.0447</cell><cell>0.2281</cell><cell>0.1639</cell><cell>0.1021</cell><cell>0.1958</cell><cell>0.4840</cell><cell>0.1367</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0096</cell><cell>±0.0005</cell><cell>±0.0040</cell><cell>±0.0085</cell><cell>±0.0029</cell><cell>±0.0072</cell><cell>±0.0092</cell><cell>±0.0124</cell><cell></cell></row><row><cell>OASIS-Best</cell><cell>mAP</cell><cell>0.1681</cell><cell>0.0462</cell><cell>0.2365</cell><cell>0.1777</cell><cell>0.0997</cell><cell>0.1841</cell><cell>0.4530</cell><cell>0.1388</cell><cell>0.6078</cell></row><row><cell></cell><cell>std</cell><cell>±0.0047</cell><cell>±0.0009</cell><cell>±0.0061</cell><cell>±0.0062</cell><cell>±0.0023</cell><cell>±0.0056</cell><cell>±0.0138</cell><cell>±0.0121</cell><cell>±0.0422</cell></row><row><cell>KRCA-Best</cell><cell>mAP</cell><cell>0.1657</cell><cell>0.0446</cell><cell>0.2451</cell><cell>0.1855</cell><cell>0.1114</cell><cell>0.2292</cell><cell>0.5520</cell><cell>0.1222</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0040</cell><cell>±0.0007</cell><cell>±0.0052</cell><cell>±0.0038</cell><cell>±0.0016</cell><cell>±0.0052</cell><cell>±0.0165</cell><cell>±0.0133</cell><cell></cell></row><row><cell>KITML-Best</cell><cell>mAP</cell><cell>0.1754</cell><cell>0.0460</cell><cell>0.2513</cell><cell>0.1774</cell><cell>0.0993</cell><cell>0.1909</cell><cell>0.5434</cell><cell>0.1962</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0048</cell><cell>±0.0022</cell><cell>±0.0047</cell><cell>±0.0079</cell><cell>±0.0030</cell><cell>±0.0075</cell><cell>±0.0108</cell><cell>±0.0164</cell><cell></cell></row><row><cell>KITML-Avg</cell><cell>mAP</cell><cell>0.2083</cell><cell>0.0625</cell><cell>0.2501</cell><cell>0.2291</cell><cell>0.1298</cell><cell>0.3273</cell><cell>0.4839</cell><cell>0.2360</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0178</cell><cell>±0.0038</cell><cell>±0.0096</cell><cell>±0.0145</cell><cell>±0.0040</cell><cell>±0.0059</cell><cell>±0.0279</cell><cell>±0.0197</cell><cell></cell></row><row><cell>Eucl.-Con</cell><cell>mAP</cell><cell>0.1921</cell><cell>0.0568</cell><cell>0.2052</cell><cell>0.1562</cell><cell>0.1013</cell><cell>0.2542</cell><cell>0.3919</cell><cell>0.1118</cell><cell>0.2032</cell></row><row><cell></cell><cell>std</cell><cell>±0.0033</cell><cell>±0.0019</cell><cell>±0.0093</cell><cell>±0.0038</cell><cell>±0.0032</cell><cell>±0.0066</cell><cell>±0.0184</cell><cell>±0.0092</cell><cell>±0.0000</cell></row><row><cell>RCA-Con</cell><cell>mAP</cell><cell>0.1916</cell><cell>0.0566</cell><cell>0.2137</cell><cell>0.1727</cell><cell>0.1061</cell><cell>0.2606</cell><cell>0.4974</cell><cell>0.1509</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0039</cell><cell>±0.0019</cell><cell>±0.0088</cell><cell>±0.0046</cell><cell>±0.0029</cell><cell>±0.0059</cell><cell>±0.0174</cell><cell>±0.0128</cell><cell></cell></row><row><cell>LMNN-Con</cell><cell>mAP</cell><cell>0.2009</cell><cell>0.0593</cell><cell>0.2265</cell><cell>0.1709</cell><cell>0.1114</cell><cell>0.2808</cell><cell>0.5251</cell><cell>0.1553</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0049</cell><cell>±0.0020</cell><cell>±0.0103</cell><cell>±0.0048</cell><cell>±0.0034</cell><cell>±0.0080</cell><cell>±0.0150</cell><cell>±0.0185</cell><cell></cell></row><row><cell>OASIS-Con</cell><cell>mAP</cell><cell>0.2004</cell><cell>0.0581</cell><cell>0.2249</cell><cell>0.1659</cell><cell>0.1023</cell><cell>0.2518</cell><cell>0.4751</cell><cell>0.1540</cell><cell>0.4580</cell></row><row><cell></cell><cell>std</cell><cell>±0.0090</cell><cell>±0.0028</cell><cell>±0.0088</cell><cell>±0.0055</cell><cell>±0.0031</cell><cell>±0.0103</cell><cell>±0.0166</cell><cell>±0.0114</cell><cell>±0.0277</cell></row><row><cell>KRCA-Con</cell><cell>mAP</cell><cell>0.1958</cell><cell>0.0589</cell><cell>0.241</cell><cell>0.1971</cell><cell>0.1226</cell><cell>0.3376</cell><cell>0.5762</cell><cell>0.1624</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0037</cell><cell>±0.0021</cell><cell>±0.0153</cell><cell>±0.0055</cell><cell>±0.0021</cell><cell>±0.0091</cell><cell>±0.0222</cell><cell>±0.0098</cell><cell></cell></row><row><cell>KITML-Con</cell><cell>mAP</cell><cell>0.2049</cell><cell>0.0572</cell><cell>0.2468</cell><cell>0.1891</cell><cell>0.1044</cell><cell>0.2757</cell><cell>0.5597</cell><cell>0.1919</cell><cell>-</cell></row><row><cell></cell><cell>std</cell><cell>±0.0090</cell><cell>±0.0055</cell><cell>±0.0164</cell><cell>±0.0096</cell><cell>±0.0034</cell><cell>±0.0073</cell><cell>±0.0215</cell><cell>±0.0104</cell><cell></cell></row><row><cell>OKS-Best</cell><cell>mAP</cell><cell>0.1897</cell><cell>0.0513</cell><cell>0.2653</cell><cell>0.1972</cell><cell>0.1192</cell><cell>0.2407</cell><cell>0.5785</cell><cell>0.2804</cell><cell>0.6698</cell></row><row><cell></cell><cell>std</cell><cell>±0.0044</cell><cell>±0.0014</cell><cell>±0.0088</cell><cell>±0.0099</cell><cell>±0.0058</cell><cell>±0.0091</cell><cell>±0.0099</cell><cell>±0.0114</cell><cell>±0.0142</cell></row><row><cell>OKS-Avg</cell><cell>mAP</cell><cell>0.2152</cell><cell>0.0677</cell><cell>0.2601</cell><cell>0.2335</cell><cell>0.1433</cell><cell>0.3542</cell><cell>0.5036</cell><cell>0.2802</cell><cell>0.2312</cell></row><row><cell></cell><cell>std</cell><cell>±0.0088</cell><cell>±0.0024</cell><cell>±0.0160</cell><cell>±0.0041</cell><cell>±0.0049</cell><cell>±0.0060</cell><cell>±0.0150</cell><cell>±0.0104</cell><cell>±0.0051</cell></row><row><cell>OMKS-U</cell><cell>mAP</cell><cell>0.218</cell><cell>0.0678</cell><cell>0.252</cell><cell>0.224</cell><cell>0.1382</cell><cell>0.3633</cell><cell>0.5766</cell><cell>0.3794</cell><cell>0.2187</cell></row><row><cell></cell><cell>std</cell><cell>±0.0085</cell><cell>±0.0023</cell><cell>±0.0088</cell><cell>±0.0056</cell><cell>±0.0035</cell><cell>±0.0085</cell><cell>±0.0316</cell><cell>±0.0234</cell><cell>±0.0192</cell></row><row><cell>OMKS-W</cell><cell>mAP</cell><cell>0.2187</cell><cell>0.068</cell><cell>0.2559</cell><cell>0.2255</cell><cell>0.1389</cell><cell>0.3654</cell><cell>0.5966</cell><cell>0.3991</cell><cell>0.2709</cell></row><row><cell></cell><cell>std</cell><cell>±0.0084</cell><cell>±0.0024</cell><cell>±0.0084</cell><cell>±0.0056</cell><cell>±0.0035</cell><cell>±0.0085</cell><cell>±0.0289</cell><cell>±0.0214</cell><cell>±0.2709</cell></row><row><cell>OMKS</cell><cell>mAP</cell><cell>0.2453</cell><cell>0.0794</cell><cell>0.3253</cell><cell>0.2690</cell><cell>0.1592</cell><cell>0.3858</cell><cell>0.6681</cell><cell>0.4442</cell><cell>0.7411</cell></row><row><cell></cell><cell>std</cell><cell>±0.0082</cell><cell>±0.0022</cell><cell>±0.0035</cell><cell>±0.0089</cell><cell>±0.0045</cell><cell>±0.0091</cell><cell>±0.0176</cell><cell>±0.0084</cell><cell>±0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>, • • • , 5) precision and the mAP values. We summarize in TABLE 1 the experimental results, measured by mAP, of the compared algorithms on all data sets. Fig. 2 illustrate the details of the top-n precision results on two sampled data sets. In TABLE 1, we highlight the best result in each group in bold font by conducting student t-tests with the significance level α = 0.05. We draw several empirical observations from the experimental results as follows. First of all, by comparing the linear methods based on the best feature, we notice that RCA-Best and LMNN-Best are not guaranteed to outperform Eucl.-Best, while OASIS-Best can achieve consistent improvements over Eucl.-Best.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 2</head><label>2</label><figDesc>Training time (seconds) of KITML versus OKS.</figDesc><table><row><cell></cell><cell>Public</cell><cell>Caltech10</cell><cell>Caltech20</cell></row><row><cell>KITMLFR-Best</cell><cell>887.76</cell><cell>63.54</cell><cell>888.80</cell></row><row><cell>KITML-Best</cell><cell>15.07</cell><cell>2.34</cell><cell>15.16</cell></row><row><cell>OKS-Best</cell><cell>0.59</cell><cell>0.09</cell><cell>0.43</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 3</head><label>3</label><figDesc>Mean average precision and precision at top 1, 10 and 50 on the Caltech object data sets.</figDesc><table><row><cell>Caltech10</cell><cell>OMKS</cell><cell cols="3">OKS-Best OASIS-Best OASIS-Ori</cell></row><row><cell>Mean avg prec.</cell><cell>40±1.7</cell><cell>35±1.3</cell><cell>24±1.1</cell><cell>31±1.1</cell></row><row><cell>Top 1 prec.</cell><cell>59±1.8</cell><cell>49±3.3</cell><cell>35±3.4</cell><cell>45±2.1</cell></row><row><cell>Top 10 prec.</cell><cell>49±2.5</cell><cell>41±1.2</cell><cell>29±1.4</cell><cell>38±1.8</cell></row><row><cell>Top 50 prec.</cell><cell>27±1.3</cell><cell>25±1.0</cell><cell>20±0.5</cell><cell>23±0.3</cell></row><row><cell>Caltech20</cell><cell>OMKS</cell><cell cols="3">OKS-Best OASIS-Best OASIS-Ori</cell></row><row><cell>Mean avg prec.</cell><cell>31±0.6</cell><cell>25±0.7</cell><cell>20±0.5</cell><cell>19±0.7</cell></row><row><cell>Top 1 prec.</cell><cell>49±2.1</cell><cell>39±0.9</cell><cell>29±1.1</cell><cell>28±2.5</cell></row><row><cell>Top 10 prec.</cell><cell>39±0.8</cell><cell>31±1.0</cell><cell>24±0.9</cell><cell>23±1.1</cell></row><row><cell>Top 50 prec.</cell><cell>22±0.3</cell><cell>18±0.6</cell><cell>16±0.4</cell><cell>15±0.7</cell></row><row><cell>Caltech50</cell><cell>OMKS</cell><cell cols="3">OKS-Best OASIS-Best OASIS-Ori</cell></row><row><cell>Mean avg prec.</cell><cell>20±0.5</cell><cell>15±0.6</cell><cell>10±0.3</cell><cell>12±0.4</cell></row><row><cell>Top 1 prec.</cell><cell>36±1.5</cell><cell>26±1.5</cell><cell>16±1.5</cell><cell>20±0.6</cell></row><row><cell>Top 10 prec.</cell><cell>27±0.7</cell><cell>20±0.9</cell><cell>13±0.5</cell><cell>16±0.5</cell></row><row><cell>Top 50 prec.</cell><cell>15±0.2</cell><cell>12±0.3</cell><cell>9±0.1</cell><cell>10±0.3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by Singapore MOE tier 1 grant (RG33/11).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Content-based multimedia information retrieval: State of the art and challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Djeraba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comput. Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visualrank: Applying pagerank to largescale image search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1877" to="1890" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A discriminative kernel-based approach to rank images from text queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1371" to="1384" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Content-based image retrieval at the end of the early years</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1349" to="1380" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning distance metrics with contextual constraints for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>New York, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">Jun. 2006</date>
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Localized content-based image retrieval</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Cholleti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fritts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1902" to="1912" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Probabilistic vs. geometric similarity measures for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="2357" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enhanced perceptual distance functions and indexing for image replica recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Qamra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="391" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Collaborative image retrieval via regularized metric learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Multimedia Systems Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="44" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rank-based distance metric learning: An application to image retrieval</title>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Anchorage, AK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised distance metric learning for collaborative image retrieval and clustering</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comput. Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new kernelization framework for mahalanobis distance learning algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chatpatanasiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Korsrilabutr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tangchanachaianan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kijsirikul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">10-12</biblScope>
			<biblScope unit="page" from="1570" to="1579" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Metric and kernel learning using a linear transformation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="519" to="547" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">LIBOL: A Library for Online Learning Algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<ptr target="http://LIBOL.stevenhoi.org" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Online passive-aggressive algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A unified log-based relevance feedback scheme for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. KDE</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="204" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining social images with distance metric learning for automated image tagging</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM international conference on Web search and data mining (WSDM&apos;11)</title>
		<meeting>4th ACM international conference on Web search and data mining (WSDM&apos;11)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning a mahalanobis metric from equivalence constraints</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Hillel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shental</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="937" to="965" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1473" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distance metric learning from uncertain side information with application to automated photo tagging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A boosting framework for visuality-preserving distance metric learning and its application to medical image retrieval</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Mummert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Satyanarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="44" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Metric learning by collapsing classes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning globallyconsistent local distance functions for shape-based image retrieval and classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Informationtheoretic metric learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large scale online learning of image similarity through ranking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1109" to="1135" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Support vector machine active learning for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM international conference on Multimedia</title>
		<meeting>the ninth ACM international conference on Multimedia<address><addrLine>Ottawa, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kernel-based distance metric learning for content-based image retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="695" to="703" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A kernel approach for semisupervised metric learning</title>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="149" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning a kernel function for classification with small training samples</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Hillel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning nonparametric kernel matrices from pairwise constraints</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="361" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A family of simple non-parametric kernel learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1313" to="1347" />
			<date type="published" when="2011-07">Jul. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning the kernel matrix with semidefinite programming</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27" to="72" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Large scale multiple kernel learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1531" to="1565" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An extended level method for efficient multiple kernel learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiclass multiple kernel learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning, Corvalis</title>
		<meeting>International Conference on Machine Learning, Corvalis<address><addrLine>Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1191" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi-label multiple kernel learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">More generality in efficient multiple kernel learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1065" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multiple kernel learning and the smo algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ampornpunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2361" to="2369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spg-gmkl: Generalized multiple kernel learning with a million kernels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012-08">August 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Online multiple kernel learning: Algorithms and mistake bounds</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ALT</title>
		<imprint>
			<biblScope unit="page" from="390" to="404" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Online multiple kernel classification</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="289" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning the discriminative powerinvariance trade-off</title>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multiple kernels for object detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="606" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Recognizing indoor scenes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="413" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">7694</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology, Tech</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Object retrieval with large vocabularies and fast spatial matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning distance functions using equivalence relations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Hillel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shental</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Kernel relevant component analysis for distance metric learning</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="954" to="959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A multimodal and multilevel ranking scheme for large-scale video retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="607" to="619" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Double updating online learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1587" to="1615" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Fast bounded online gradient descent algorithms for scalable kernel-based online learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
