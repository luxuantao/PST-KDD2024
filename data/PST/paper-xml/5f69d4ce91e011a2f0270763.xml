<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LEARNED LOW PRECISION GRAPH NEURAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-09-19">19 Sep 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yiren</forename><surname>Zhao</surname></persName>
							<email>&lt;yiren.zhao@cl.cam.ac.uk&gt;.</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Duo</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Bates</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Mullins</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mateja</forename><surname>Jamnik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Compute Science and Technology</orgName>
								<orgName type="institution">University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LEARNED LOW PRECISION GRAPH NEURAL NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-09-19">19 Sep 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2009.09232v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep Graph Neural Networks (GNNs) show promising performance on a range of graph tasks, yet at present are costly to run and lack many of the optimisations applied to DNNs. We show, for the first time, how to systematically quantise GNNs with minimal or no loss in performance using Network Architecture Search (NAS). We define the possible quantisation search space of GNNs. The proposed novel NAS mechanism, named Low Precision Graph NAS (LPGNAS), constrains both architecture and quantisation choices to be differentiable. LPGNAS learns the optimal architecture coupled with the best quantisation strategy for different components in the GNN automatically using back-propagation in a single search round. On eight different datasets, solving the task of classifying unseen nodes in a graph, LPGNAS generates quantised models with significant reductions in both model and buffer sizes but with similar accuracy to manually designed networks and other NAS results. In particular, on the Pubmed dataset, LPGNAS shows a better size-accuracy Pareto frontier compared to seven other manual and searched baselines, offering a 2.3× reduction in model size but a 0.4% increase in accuracy when compared to the best NAS competitor. Finally, from our collected quantisation statistics on a wide range of datasets, we suggest a W4A8 (4-bit weights, 8-bit activations) quantisation strategy might be the bottleneck for naive GNN quantisations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graph Neural Networks (GNNs) have been successful in fields such as computational biology <ref type="bibr" target="#b37">(Zitnik &amp; Leskovec, 2017)</ref>, social networks <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>, knowledge graphs <ref type="bibr" target="#b12">(Lin et al., 2015)</ref>, etc.. The ability of GNNs to apply learned embeddings to unseen nodes or new subgraphs is useful for large scale machine learning systems on graph data, ranging from analysing posts on forums to creating product listings for shopping sites <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>. Most of the large production systems have high throughputs, running millions or billions of GNN inferences per second. This creates an urgent need to minimise both the computation and memory cost of GNN inference.</p><p>One common approach to reduce computation and memory overheads of Deep Neural Networks (DNNs) is quantisation <ref type="bibr" target="#b33">(Zhao et al., 2019;</ref><ref type="bibr" target="#b29">Zhang et al., 2018a;</ref><ref type="bibr" target="#b9">Hubara et al., 2016;</ref><ref type="bibr" target="#b36">Zhu et al., 2017;</ref><ref type="bibr" target="#b10">Hwang &amp; Sung, 2014)</ref>. A simpler data format not only reduces the model size but also introduces the chance of using simpler arithmetic operations on existing or emerging hardware platforms <ref type="bibr" target="#b33">(Zhao et al., 2019;</ref><ref type="bibr" target="#b9">Hubara et al., 2016)</ref>. Previous quantisation methods focusing solely on DNNs with image and sequence data will not obviously transfer well to GNNs. First, in CNNs and RNNs it is the convolutional and fully-connected layers that are quantised <ref type="bibr" target="#b9">(Hubara et al., 2016;</ref><ref type="bibr" target="#b17">Shen et al., 2019)</ref>. GNNs, however, follow a sample and aggregate approach <ref type="bibr" target="#b34">(Zhao et al., 2020;</ref><ref type="bibr" target="#b7">Hamilton et al., 2017)</ref>, where we can separate a basic building block in GNNs into four smaller sub-blocks (Linear, Attention, Aggregation and Activation); only a subset of these sub-blocks has trainable parameters and these parameters naturally have different precision requirements. Second, the design of GNN blocks involves a different design space, where several attention and aggregation methods are available and the choices of these methods have a direct interaction with the precision.</p><p>In this paper, we propose Low Precision Graph NAS (LPG-NAS), which aims to automatically design quantised GNNs. The proposed NAS method is single-path, one-shot and gradient-based. Additionally, LPGNAS's quantisation options are at a micro-architecture level so that different subblocks in a graph block can have different quantisation strategies. In this paper, we make the following contributions.</p><p>• We report LPGNAS results, and show how they significantly outperfrom previous state-of-the-art NAS methods and manually designed networks in terms of memory consumption on the same accuracy budget on 8 different datasets.</p><p>• By running LPGNAS on a wide range of datasets, we reveal the quantisation statistics and show empirically LPGNAS converges to a 4-bit weights 8-bit activation fixed-point quantisation strategy. We further show this quantisation is the limitation of current fixedpoint quantisation strategies on manually designed and searched GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>2.1 Quantisation and Network Architecture Search</p><p>DNNs offer great performance and rapid time-to-market path on a broad variety of tasks. Unfortunately, their high memory and computation requirements can be challenging when deploying in real-world scenarios. Quantisation directly shrinks model sizes and rapidly simplifies the complexity of the arithmetic hardware. Previous research shows that DNN models can be quantised to surprisingly low precisions such as ternary <ref type="bibr" target="#b36">(Zhu et al., 2017)</ref> and binary <ref type="bibr" target="#b9">(Hubara et al., 2016)</ref>. Networks with extremely low precision weights have a significant task accuracy drop due to the numerical errors introduced, and sometimes require architectural changes to compensate <ref type="bibr" target="#b9">(Hubara et al., 2016)</ref>.</p><p>In contrast, fixed-point numbers <ref type="bibr" target="#b17">(Shen et al., 2019;</ref><ref type="bibr" target="#b10">Hwang &amp; Sung, 2014)</ref> and other more complex arithmetics <ref type="bibr" target="#b33">(Zhao et al., 2019;</ref><ref type="bibr" target="#b29">Zhang et al., 2018a)</ref> have larger bitwidths but offer a better task accuracy. These quantisation methods have primarily been applied on convolutional and fullyconnected layers since they are the most compute-intensive building blocks in CNNs and RNNs. Another way of reducing the inference cost of DNNs is architectural engineering. For instance, using depth-wise separable convolutions to replace normal convolutions not only costs fewer parameters but also achieves comparable accuracy <ref type="bibr" target="#b8">(Howard et al., 2017)</ref>. However, architectural engineering is normally tedious and complex; recent research on NAS reduces the amount of manual tuning in the architecture design process. Initial NAS methods used evolutionary algorithms and reinforcement learning to find optimal network architectures, but each iteration of the search fully trains and evaluates many child networks <ref type="bibr" target="#b15">(Real et al., 2017;</ref><ref type="bibr" target="#b38">Zoph &amp; Le, 2017)</ref>, thus needing a huge amount of computation resources and time. <ref type="bibr">Liu et al.</ref> proposed Differentiable Architecture Search (DARTs) that creates a supernet with all possible operations connected by probabilistic priors <ref type="bibr" target="#b13">(Liu et al., 2019)</ref>. The search cost of DARTs is reduced by orders of magnitude -it is the same as training a single supernet (one-shot). In addition, DARTs is gradient-based, meaning that standard Stochastic Gradient Descent (SGD) now can be used to update these probabilistic priors. One major drawback of DARTs is that all operations of the supernet are active during the search. Recently proposed single-path NAS methods only update a sampled network from the supernet at each search step, and are able to converge quickly and significantly reduce the computation and memory cost compared to DARTs <ref type="bibr" target="#b23">(Wu et al., 2019;</ref><ref type="bibr" target="#b1">Cai et al., 2018;</ref><ref type="bibr" target="#b6">Guo et al., 2019)</ref>. In addition, many of the NAS methods on vision networks consider mixed quantisation in their search space <ref type="bibr" target="#b6">(Guo et al., 2019;</ref><ref type="bibr" target="#b22">Wu et al., 2018)</ref>, but limit the quantisation granularity to per-convolution level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Neural Network</head><p>Deep Learning on graphs has emerged into an important field of machine learning in recent years, partially due to the increase in the amount of graph-structured data. Graph Neural Networks has scored success in a range of different tasks on graph data, such as node classification <ref type="bibr" target="#b20">(Veličković et al., 2018;</ref><ref type="bibr" target="#b11">Kipf &amp; Welling, 2016;</ref><ref type="bibr" target="#b7">Hamilton et al., 2017)</ref>, graph classification <ref type="bibr" target="#b32">(Zhang et al., 2018c;</ref><ref type="bibr" target="#b27">Ying et al., 2018;</ref><ref type="bibr" target="#b25">Xu et al., 2019)</ref> and link prediction <ref type="bibr" target="#b31">(Zhang &amp; Chen, 2018)</ref>.</p><p>There are many variants of graph neural networks proposed to tackle graph structured data. In this work we focus on GNNs applied to node classification tasks based on Message-Passing Neural Networks (MPNN) <ref type="bibr" target="#b5">(Gilmer et al., 2017)</ref>.</p><p>The objective of the neural network is to learn an embedding function for node features so that they quickly generalise to other unseen nodes. This inductive nature is needed for large-scale production level machine learning systems, since they normally operate on a constantly changing graph with many coming unseen nodes (e.g. shopping history on Amazon, posts on Reddit etc.) <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>. It is also worth to mention that many of these systems are highthroughput and latency-critical. The reductions in energy and latency of the deployed networks imply the service providers can offer a better user experience while keeping a lower cost.</p><p>Most of the manually designed GNN architectures proposed for the node classification use MPNN. The list includes, but is not limited to, GCN <ref type="bibr" target="#b11">(Kipf &amp; Welling, 2016)</ref>, GAT <ref type="bibr" target="#b20">(Veličković et al., 2018)</ref>, GraphSage <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>, and their variants <ref type="bibr" target="#b18">(Shi et al., 2019;</ref><ref type="bibr" target="#b30">Zhang et al., 2018b;</ref><ref type="bibr" target="#b2">Chen et al., 2017;</ref><ref type="bibr" target="#b21">Wang et al., 2019)</ref>. These works differ in ways of computing the edge weights, sampling neighbourhood and aggregating neighbour messages. We also relate to works focusing on building deeper Graph Neural Networks with the help of residual connections, such as JKNet <ref type="bibr" target="#b24">(Xu et al., 2018)</ref>. To the best of our knowledge, there is no prior work in investigating quantisation for Graph Neural Networks.</p><p>There is a recent surge of interest in looking at how to extend NAS methods from image and sequence data to graphs.  <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref>. All of these graph NAS methods show superior performance when compared to other manually designed networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Quantisation Search Space</head><p>We consider a single graph block, or a GNN layer, as four consecutive sub-blocks (Equation ( <ref type="formula" target="#formula_0">1</ref>)). Equation (1) considers node features h k−1 from the k − 1 layer as inputs, and produces new node features h k with trainable attention parameters a k and weights w k . The four sub-blocks, as illustrated in Equation ( <ref type="formula" target="#formula_0">1</ref>), are the Linear block, Attention block, Aggregation block and Activation block; these sub-blocks have operations as search candidates, which is a similar architectural search space to Zhao et al. <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref> and <ref type="bibr" target="#b4">Gao et al. (Gao et al., 2019)</ref>. We provide a detailed description of the architectural search space in the Appendix. In Equation (2), we label all possible quantisation candidates using Q. The quantisation function Q can be applied not only on learnable parameters (e.g., w k ) but also activation values between consecutive sub-blocks.</p><p>In addition, we allow quantisation options in Equation (2) to be different. For instance, Q a can learn to have a different quantisation from Q w , meaning that a single graph block receives a mixed quantisation for different quantisable components annotated in Equation (2).</p><formula xml:id="formula_0">h k = Act(Aggr(Atten(a k , Linear(w k , h k−1 ))))<label>(1)</label></formula><formula xml:id="formula_1">h k linear = Q l (Linear(Q w (w k ), Q h (h k−1 ))) h k atten = Q at (Atten(Q a (a k ), h k linear )) h k = Act(Q ag (Aggr(h k atten )))<label>(2)</label></formula><p>The reasons for considering input activation values as quantisation candidates are the following. First, GNNs always consider large input graph data, the computation operates on a per-node or per-edge resolution but requires the entire graph or the entire sampled graph as inputs. The amount of intermediate data produced during the computation is huge and causes a large pressure on the amount of on-chip memory available. Second, quantised input activations with quantised parameters together simplify the arithmetic operations. For instance, Linear(Q w (w k ), Q h (h k−1 )))) considers both quantised h k−1 and quantised w k so that the matrix multiplication with these values can operate on a simpler fixed-point arithmetic.</p><p>The quantisation search space identified in Equation ( <ref type="formula" target="#formula_1">2</ref>) is different from the search space identified by Wu et al. <ref type="bibr" target="#b22">(Wu et al., 2018)</ref> and <ref type="bibr" target="#b6">Guo et al. (Guo et al., 2019)</ref>. Most existing NAS methods focusing on quantising CNNs look at quantisation at each convolutional block. In our case, a single graph block is equivalent to a convolutional block and we look at more fine-grained quantisation opportunities within the four sub-blocks. The quantisation search considers a wide range of fixed-point quantisations. The weights and activation can pick the numbers of bits in <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">4,</ref><ref type="bibr">6,</ref><ref type="bibr">8,</ref><ref type="bibr">12,</ref><ref type="bibr">16]</ref> and <ref type="bibr">[4,</ref><ref type="bibr">8,</ref><ref type="bibr">12,</ref><ref type="bibr">16</ref>] respectively, and we allow different integer and fractional bits combinations We list the detailed quantisation options in the Table <ref type="table" target="#tab_1">1</ref>. Table <ref type="table" target="#tab_1">1</ref> shows the quantisation search space, each quantisable operation identified will have these quantisation choices available. BINARY means binary quantisation, and TERNARY means two-bit tenary quantiation. FIXx.y means fixed-point quantisation with x integer bits and y bits for fractions.</p><p>In total, as listed in Table <ref type="table" target="#tab_1">1</ref>, we have 17 quantisation options; and as illustrated in Equation ( <ref type="formula" target="#formula_1">2</ref>), there are four sub-blocks that join the quantisation search, this gives us in total 17 4 = 83251 quantisation options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Architecture Search Space</head><p>As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, each graph block consists of four sub-blocks, namely the linear block, attention block, aggregation block and activation block. Each of these sub-blocks contain architectural choices that joins the NAS process. In Table <ref type="table">2</ref> and Table <ref type="table">3</ref>, we list all attention types and activation types that were considered in the architectural search space. We also consider searching for the best hidden feature size, using two fully-connected layers with an intermediate layer with an expansion factor that can be picked from a set {1, 2, 4, 8}. The possible aggregation choices include mean, add and max.</p><p>The considered search space is similar to prior works in this domain <ref type="bibr" target="#b34">(Zhao et al., 2020;</ref><ref type="bibr" target="#b35">Zhou et al., 2019;</ref><ref type="bibr" target="#b4">Gao et al., 2019)</ref>. The possible number of architectural combinations of a single layer is 7 × 8 × 3 × 4 = 672, for an n-layer network, this means there are in total 672 n possible architectural combinations. Combining the quantisation search space mentioned in the previous section, the search space has in total 83251 × 672 n options. Assuming the number of layers considered in the search is n = 4, this roughly gives us a search space of 10 15 options.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Low Precision Graph Network Architecture Search</head><p>We describe the Low Precision Graph Network Architecture  Search (LPGNAS) algorithm in Algorithm 1. (x, y), (x v , x v ) are the training and validation data respectively. M is the total number of search epochs, and M a and M q are the epochs to start architectural and quantisation search. Similar to Zhao et al. <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref>, before the number of epochs reaches M a or M q , LPGNAS randomly picks up samples and warms up the trainable parameters in the supernet. K is the number of steps to iterate in training the supernet. After generating noise N , we use this noise in architectural controller g a and quantisation controller g q together with the validation data x v to determine the architectural π a and quantisation π q choices. After reaching the predefined starting epoch (M a or M q ), LPGNAS starts to optimise the controllers' weights (w a and w q ). We choose the Table <ref type="table">2</ref>. Different types of attention mechanisms. W here is parameter vector for attention. &lt;, &gt; is dot product, aij is attention for message from node j to node i.</p><formula xml:id="formula_2">ATTENTION TYPE EQUATION CONST aij = 1 GCN aij = 1 √ d i d j GAT a gat ij = LeakyReLU(Wa(hi||hj)) SYM-GAT aij = a gat ij + a gat ji COS aij =&lt; Wa1hi, Wa2hj &gt; LINEAR aij = tanh( j∈N (i) (Wahj)) GENE-LINEAR aij = Wgtanh(Wa1hi + Wa2hj)</formula><p>Table <ref type="table">3</ref>. Different types of activation functions.</p><formula xml:id="formula_3">ACTIVATION EQUATION NONE f (x) = x SIGMOID f (x) = 1 1+e −x TANH f (x) = tanh(x) SOFTPLUS f (x) = 1 β log(1 + e βx ) RELU f (x) = M ax(0, x) LEAKYRELU f (x) = M ax(0, x) + αM in(0, x) RELU6 f (x) = M in(M ax(0, x), 6) ELU f (x) = M ax(0, x) + M in(0, α(e x − 1)) Algorithm 1 LPGNAS algorithm Input: x, y, x v , y v , M , M a , M q , K, α, β</formula><p>Init(w, w a , w q ) for i = 0 to M − 1 do N = NoiseGen(i, α) P a , P q = g a (w a , x val , N ), g q (w q , x val , N ) π a , π q = arg max(P a ), arg max(P q )</p><formula xml:id="formula_4">for i = 0 to K − 1 do L = Loss(x, y, π a , π q ) w = Opt w (L) end for L v = Loss(x v , y v , π a , π q ) if e &gt; M a then w a = Opt wa (L v ) end if if e &gt; M q then</formula><p>L q = QLoss(P a , P q ) w q = Opt wq (L v + βL q ) end if end for hyper-parameters M q = 20, M a = 50, α = 1.0, β = 0.1, unless specified otherwise, based on the choices made by Zhao et al. <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref>. In addition, we provide an ablation study in the Appendix to justify our choices of hyper-parameters. Notice that QLoss estimates the current hardware cost based on both architectural and quantisation probabilities. As shown in Equation (3), we define S as a set of values that represents the costs (number of parameters) of all possible architectural options: for each value s in this set, we multiply it with the probability p a from architecture probabilities P a generated by the NAS architecture controller. Similarly, we produce the weighted-sum for quantisation from the set of values S q that represents costs of all possible quantisations. The dot product • between these two weighted-sum vectors produces the quantisation loss L q .</p><p>L q = QLoss(P a , P q ) = s∈S,pa∈Pa</p><formula xml:id="formula_5">(s * p a ) • sq∈Sq,pq∈Pq (s q * p q ) (3)</formula><p>Figure <ref type="figure" target="#fig_0">1</ref> is an illustration of the LPGNAS algorithm. We use two controllers (g a and g q ) for architecture and quantisation (named as Controller and Q-Controller in the diagram) respectively. The controllers use trainable embeddings connected to linear layers to produce architecture and quantisation probabilities. The architecture controller provides probabilities (P a ) for picking architectural options of graph blocks and also the router. The router is in charge of determining how each graph block shortcuts to the subsequent graph blocks <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref>. In addition, the quantisation controller provides quantisation probabilities (P q ) to both modules in graph blocks and the linear layers in the router. In a graph block, only the linear and attention layers have quantisable parameters and have matrix multiplication operations; neither activation nor aggregation layers have any trainable or quantisable parameters. However, all input activation values of each layer in the graph block are quantised. The amount of intermediate data produced during the computation causes memory pressure on many existing or emerging hardware devices, so even for modules that do not have quantisable parameters, we choose to quantise their input activation values to help reduce the amount of buffer space required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We compare LPGNAS to both manually designed and searched GNNs. In addition, we provide comparisons for two types of tasks. The first type is on the Citation datasets, where the network takes the entire graph as an input in a transductive learning setup <ref type="bibr" target="#b26">(Yang et al., 2016)</ref>. The second type considers inputs sampled from a large graph, and we use the inductive GraphSAINT sampling strategy <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. For the networks to learn from sampled graphs, we present results on larger datasets, including Amazon Computers, Amazon Photos <ref type="bibr" target="#b16">(Shchur et al., 2018)</ref>, Yelp, Flickr <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref> and Cora-full <ref type="bibr" target="#b0">(Bojchevski &amp; Günnemann, 2017)</ref>.  <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref> on the Pubmed datset <ref type="bibr" target="#b26">(Yang et al., 2016)</ref>, the manually designed networks are shown as dots. On the left, we show the trade-off between model sizes and accuracy; on the right, the trade-off is between buffer sizes and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Citation datasets include nodes representing documents</head><p>Table <ref type="table">5</ref>. Accuracy and size comparison on Amazon-Computers and Amazon-Photo <ref type="bibr" target="#b16">(Shchur et al., 2018)</ref>   <ref type="bibr" target="#b26">(Yang et al., 2016)</ref>, the manually designed networks are shown as dots. On the left, we show the trade-off between model sizes and accuracy; on the right, the trade-off is between buffer sizes and accuracy.</p><p>and edges representing citation links. The task is to distinguish which research field the document belongs to <ref type="bibr" target="#b26">(Yang et al., 2016)</ref>. The Flickr dataset includes nodes as images, and edges exist between two images if they share some common properties. The task is to classify these images based on their bag-of-words encoded features <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. Yelp considers users as nodes and edges are made based on user friendships, and features are word embeddings extracted from user reviews. The task is to distinguish the categories of the shops the users are likely to review; since multiple categories are possible, the labels are multi-hot <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. Amazon Computers and Photo are part of the Amazon co-purchase graph <ref type="bibr" target="#b14">(McAuley et al., 2015)</ref>. The nodes are goods, and edges are the frequency between two goods bought together. Node features are bag-of-words encoded product reviews, and classes are the product categories. Cora-full is an extended version of Cora, which one of the dataset in the Citation datasets. We provide a detailed overview of the properties and statistics of the datasets in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Citation Datasets</head><p>Table <ref type="table" target="#tab_2">4</ref> shows the performance of GraphSage <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>, GAT <ref type="bibr" target="#b20">(Veličković et al., 2018)</ref>, JKNet <ref type="bibr" target="#b24">(Xu et al., 2018)</ref>, PDNAS <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref> and LPGNAS on the citation datasets with a partition of 0.6, 0.2, 0.2 for training, validation and testing respectively, which is the same training setup as in Yang et al. <ref type="bibr" target="#b26">(Yang et al., 2016)</ref>. For the quantisation options of GraphSage, GAT and JKNet, we manually perform a grid search on the Cora dataset. The grid search considers various weight and activation quantisations in a decreasing order. The search terminates when quantisation causes a decrease in accuracy bigger than 0.5% and rolls back to pick the previous quantisation applied as the result. We reimplemented GraphSage <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>, GAT <ref type="bibr" target="#b20">(Veličković et al., 2018)</ref> and JKNet <ref type="bibr" target="#b24">(Xu et al., 2018)</ref> for quantisation, and provide the architecture choices and details of the grid search in the Appendix. For the manual baseline networks, we used the quantisation strategy found on Cora for Citeseer and Pubmed. For LPGNAS, we searched with a set of base configurations that we clarified in the Appendix. For all reimplemented baselines, we train the networks with three different seeds and report the averaged results with standard deviations. For LPGNAS, we run the entire search and train cycle three times and report the final averaged accuracy trained on the searched network.</p><p>The results in Table <ref type="table" target="#tab_2">4</ref> suggest that LPGNAS shows better accuracy on both Cora and Pubmed with quantised networks.</p><p>In addition, although LPGNAS does not show the smallest sizes on these two datasets, it is only slightly bigger than the manual baselines but shows a much better accuracy. On Citeseer, LPGNAS only shows slightly worse accuracy (around 0.1% less) with a considerably smaller size (around 9× reduction in model sizes).</p><p>To further prove the point that LPGNAS generates more efficient networks, we sweep across different configurations and different quantisation regularisations to produce Figure <ref type="figure">2</ref> to visulise the performance of LPGNAS and how it performs with small model sizes. We explain in the Appendix how this sweep of different LPGNAS configurations work, the sweep mainly considers a combination of different configurations of how many layers and how many base channel counts are there for the backbone network to use for LPGNAS. We plot the Pareto frontiers of LPGNAS putting model sizes on the horizontal axis and accuracy on the vertical axis for Pubmed (Figure <ref type="figure">2</ref>). In this plot, we also demonstrate how buffer size trades-off with accuracy.</p><p>For buffer size, it means the total size required to hold all intermediate activation values during the computation of a single inference run with a batch size of one. GNNs normally use large graphs as input data; the amount of memory required to hold all intermediate values might be a limiting factor in batched inference. Since LPGNAS uses quantisation not only on weights but also on input activation values, it shows a better trade-off than the floating-point baselines.</p><p>For Figure <ref type="figure">2</ref>, models staying at the top left of the plots are considered as better, since they are consuming less hardware resources and maintaining high accuracy. In addition, in Figure <ref type="figure">2</ref>, we compare PDNAS <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref> to LPG-NAS and found that we outperformed the floating-point NAS methods by staying at the top left in the plot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Graph Sampling Based Learning</head><p>Table <ref type="table">5</ref> and Table <ref type="table" target="#tab_3">6</ref> show how LPGNAS performs on large datasets sampled using the GraphSaint sampling <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. The detailed configuration of the sampler is in the Appendix. We provide additional baselines on these datasets since the original GraphSage <ref type="bibr" target="#b7">(Hamilton et al., 2017)</ref>, GAT <ref type="bibr" target="#b20">(Veličković et al., 2018)</ref>, JKNet <ref type="bibr" target="#b24">(Xu et al., 2018)</ref> underfit this challenging task. We thus implemented V2 versions of the baselines that have larger channel counts; the architecture details are reported in our Appendix. In addition, for quantising the baseline models we uniformly applied a w4a8 (4-bit weights, 8-bit input activations) quantisation.</p><p>Although we train on a sampled sub-graph, evaluating networks requires a full traversal of the complete graph. Since the datasets considered are large, traversing the entire graph adds a huge computation overhead. If we use the previous grid-search for all quantisation possibilities (roughly 16 4 in our case) for the all baseline networks, this will require a huge amount of search time. So we fixed our quantisation strategy to w4a8 for the baseline networks.</p><p>The results in Table <ref type="table">5</ref> and Table <ref type="table" target="#tab_3">6</ref> suggest that LPGNAS found the models with best accuracy and also with a relatively competitive model size when compared to a wide range of manual baselines. To further demonstrate that LPGNAS is a flexible NAS method, we adjust the base configurations to provide models that are equal or smaller than the smallest baseline networks in Table <ref type="table">5</ref> and Table <ref type="table" target="#tab_3">6</ref> and name them LPGNAS-small. We describe how we turn the knobs in LPGNAS by adjusting the base configurations in our Appendix. It is clear, in both Table <ref type="table" target="#tab_3">5 and Table 6</ref>, that LPGNAS outperforms all baselines in terms of accuracy or micro-F1 scores. LPGNAS-small, on the other hand, tradesoff the accuracy for a better model size, however it shows better performance than baseline models that have a similar size budget.</p><p>We also visualise the performance of LPGNAS on sampled datasets using the Pareto frontiers plot for Cora-full in Figure <ref type="figure">3</ref>. As expected, LPGNAS shows a frontier at the top left, proving that it is able to produce small networks with high accuracy values. In other words, LPGNAS is Pareto dominated compared other manually designed networks.</p><p>It is worth to note that LPGNAS show great performance gains compared to the baseline networks. On Flickr, Cora-Full, and Yelp, we show on average around 20% increase compared to even the full-precision baseline models, while our LPGNAS produced quantised models. The performance gap between quantised baselines and LPGNAS is even greater. On the other hand, LPGNAS is able to produce extremely small models. For instance, LPGNAS-Small is able to produce models that are around 50× smaller on Amazon-Computers and Amazon-Photos while only suffer from an around 1% drop in accuracy compared to standard  LPGNAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Quantisation Search Time</head><p>One advantage of using Network Architecture Search is the reduction of search time. Previous NAS methods on GNNs demonstrated the effectiveness of their methods by reducing the amount of search time required to find the best network architecture <ref type="bibr" target="#b34">(Zhao et al., 2020;</ref><ref type="bibr" target="#b4">Gao et al., 2019;</ref><ref type="bibr" target="#b35">Zhou et al., 2019)</ref>. In this work, we not only reduced the amount of manual tunning time required for network architectures but also shortened the amount of time required to search for numerical precisions at different sub-blocks.</p><p>To further illustrate that LPGNAS has significantly reduced the amount of search time required, we provide Table <ref type="table" target="#tab_4">7</ref> to show how LPGNAS compares to a fixed JKNet-32 architecture in terms of the amount of GPU hours spent for searching for the best quantisation options. Because of the limited resources we have, we estimate the quantisation search cost of a JKNet-32 by running 5 different randomly selected quantisation combinations and multiply the averaged training time with the total number of quantisation options.</p><p>Table <ref type="table" target="#tab_4">7</ref> shows that LPGNAS can significantly reduce the search time. For instance, on Citeseer, the search time can be reduced by around 2270×. It is worth noting that, when performing this quantisation search time comparison, we do not consider the architectural search space of the baseline, meaning that the baseline (JKNet) is a fixed-architecture. LPG-NAS also searched for architecture choices, which would further increases the search time of the baseline if they are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Quantisation Statistics and Limitations</head><p>In order to fully understand the properties of different quantisable sub-blocks in GNNs, we report the searched quantisation strategies on more than 100 search runs across 8 different datasets (Cora, Pubmed, Citeseer, Amazon-Computers, Amazon-Photos, Flickr, CoraFull and Yelp). The idea is to reveal some common quantisation properties or trends using LPGNAS on different datasets. We collect the quantisation decisions made by LPGNAS for both weights and activations and present them in Figure <ref type="figure" target="#fig_1">4</ref>. The possible quantisation levels for weights and activations are <ref type="bibr">[1, 2, 4, 6, 8, 12, 16] and [4, 8, 12, 16]</ref> bits respectively.</p><p>For weights, most quantisation choices tend to use small bitwidths: binary and ternary values seem to be sufficient for the hidden and attention sub-blocks, however, shortcut connections prefer a larger bitwidth (around 4 bits) for weights.</p><p>In contrast, quantising activations show in general a trend of using larger bitwidths (around 8 bits). Based on these results, if one would like to manually quantise GNNs, we would suggest to start with around 4 bits for weights and 8 bits for activations. However, it is worth mentioning that LPGNAS might trade quantisation choices with architectural decisions. For instance, we observed LPGNAS was able to choose operations with less parameters but use higher bitwidths. Nevertheless, the large number of runs across a relatively wide range of datasets aim at sharing empirical insights for people that are manually tuning quantisations for GNNs. For GNN services that are whether energy, memory or latency critical, and for future AI ASIC designers focusing on GNN inference, the gathered quantisation statistics can be a useful guideline for fitting a suitable quantisation method to their networks.</p><p>It is also interesting to observe that in both Table <ref type="table">5</ref> and Table <ref type="table" target="#tab_3">6</ref>, some of the manually designed GNNs suffer from a large accuracy drop when applying a 4-bit weight and 8-bit activation fixed-point quantisation (w4a8). For instance, both quantised JKNet and JKNet-V2 drop down to 4.4% accuracy on the Cora-full dataset (Table <ref type="table">5</ref>). However, the collected statistics of LPGNAS suggest that w4a8 is sufficient, proving that modifications of network architectures are the key element for networks to maintain accuracy with aggressive quantisation strategies.</p><p>The applied fixed-point quantisation is a straight-forward one, many researchers have proposed more advanced quantisation schemes on CNNs or RNNs <ref type="bibr" target="#b33">(Zhao et al., 2019;</ref><ref type="bibr" target="#b29">Zhang et al., 2018a;</ref><ref type="bibr" target="#b19">Shin et al., 2016)</ref>. We suggest future research of investigating how these quantisation strategies work on GNNs should consider w4a8 fixed-point quantisation as a baseline case. Because our collected statistics suggest that w4a8 fixed-point quantisation is the most aggressive quantisation for searched GNNs while guaranteeing minimal loss of accuracy, and manual GNNs often do not perform well using the w4a8 setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a novel single-path, one-shot and gradient-based NAS algorithm named LPGNAS. LPGNAS is able to generate compact quantized networks with stateof-the-art accuracy. To our knowledge, this is the first piece of work studying the quantisation of GNNs. We define the GNN quantisation search space and show how it can be co-optimised with the original architectural search space.</p><p>In addition, we empirically show the limitation of GNN quantisation using the proposed NAS algorithm, most of the searched networks converge to a 4-bit weight 8-bit activation quantisation setup. Despite this limitation, LPGNAS demonstrates superior performance when compared to networks generated manually or by other NAS methods on a wide range of datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PARAMETER CHOICES</head><p>As mentioned in the LPGNAS algorithm, we pick N q = 20, N a = 50, α = 1.0, β = 0.1, lr = 0.005. The values of α and lr are the same as Zhao et al. <ref type="bibr" target="#b34">(Zhao et al., 2020)</ref>. For β, N q and N a , we justify our choices in Figure <ref type="figure">5</ref> by sweeping across different values of β, N a and N q on the Pubmed dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DATASETS INFORMATION AND DATA SAMPLER CONFIGURATIONS</head><p>In this section we decribe in details the dataset we used. In our experiments we use dataset preprocessing and loading implementations from Pytorch Geometric <ref type="bibr" target="#b3">(Fey &amp; Lenssen, 2019)</ref>.</p><p>Citation Dataset: Citation dataset <ref type="bibr" target="#b26">(Yang et al., 2016</ref>) is a standard benchmark dataset for graph learning. It comprises three publication datasets, which are Cora, CiteSeer and PubMed. There is an additional extended version of Cora called Cora-Full <ref type="bibr" target="#b0">(Bojchevski &amp; Günnemann, 2017)</ref>. Cora contains all Machine Learning papers in the Cora-Full graph. In these datasets, nodes correspond to bag-ofword features of the documents and edges indicates citation. Each node has a class label. In this paper we use the 6:2:2 train/validation/test split ratio.</p><p>Amazon Dataset: Amazon datasets <ref type="bibr" target="#b16">(Shchur et al., 2018)</ref>, including Amazon Photos and Amazon Computers, are segments of the Amazon co-purchase graph. Nodes represent goods while edges represent frequent co-purchase of linked goods. Node feature is bag-of-word features of product review, while node label is its category. We use the 6:2:2 train/validation/test split ratio.</p><p>Flickr and Yelp Dataset: Flickr and Yelp datasets are introduced along GraphSAINT <ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. In Flickr dataset, nodes represent images uploaded to Flickr, and edges represent sharing of common properties (e.g. location and comments by same user). Node feature is 500dimensional bag-of-words representation based on SIFT descpritions, and node label is its class. In Yelp dataset, nodes represent users and edges represent friendship between users. Node feature is summed word2vec embeddings of words in the user's reviews, and node label is a multi-hot vector representing which types of businesses has the user reviewed. For both dataset we use the 6:2:2 train/validation/test split ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C GRID SEARCH AND BASELINE NETWORKS DETAILS</head><p>For producing quantised baseline networks, we manually grid searched options listed in Table <ref type="table" target="#tab_1">1</ref> and follow the order from bottom to top. We stop the search and retrieve to the previous quantisation stage if the current stage shows an accuracy drop of more than 0.5%. It is worth to mention this grid search for quantisation is very time-consuming, and we therefore only performed on Cora and used the found quantisation strategy for the rest of the Citation datasets.</p><p>Table <ref type="table" target="#tab_5">8</ref> shows the configurations of the baseline networks we've used in this paper. Figure <ref type="figure">5</ref>. Collected statistical information for quantisation, the horizontal axis shows the chosen bitwidth and the vertical axis shows the occurences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. An overview of the LPGNAS architecture. Pa denotes controller output (Purple) for selecting different operations within each graph block, and for routing shortcut connections between graph blocks. Pq denotes quantisation controller (Q-Controller) output (Green) for selecting quantisations for operations within graph blocks and shortcut connections. Gij are gating functions conditioned on Pa. Solid lines are input streams into the router while dashed lines are output streams.</figDesc><graphic url="image-1.png" coords="4,90.64,316.29,413.10,235.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Figure4. Collected statistical information for quantisation, the horizontal axis shows the chosen bitwidth and the vertical axis shows the occurences. A bitwith count of 16 is not present because it has never been selected by LPGNAS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Quantisation search space for weights and activations.</figDesc><table><row><cell></cell><cell>WEIGHTS</cell><cell></cell><cell></cell><cell>ACTIVATIONS</cell><cell></cell></row><row><cell cols="6">QUANTISATION FRAC BITS TOTAL BITS QUANTISATION FRAC BITS TOTAL BITS</cell></row><row><cell>BINARY</cell><cell>0</cell><cell>1</cell><cell>FIX2.2</cell><cell>2</cell><cell>4</cell></row><row><cell>BINARY</cell><cell>0</cell><cell>1</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>TERNARY</cell><cell>0</cell><cell>2</cell><cell>FIX2.2</cell><cell>2</cell><cell>4</cell></row><row><cell>TERNARY</cell><cell>0</cell><cell>2</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>TERNARY</cell><cell>0</cell><cell>2</cell><cell>FIX4.8</cell><cell>4</cell><cell>12</cell></row><row><cell>FIX1.3</cell><cell>3</cell><cell>4</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX2.2</cell><cell>2</cell><cell>4</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX1.5</cell><cell>5</cell><cell>6</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX3.3</cell><cell>3</cell><cell>6</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX2.4</cell><cell>4</cell><cell>6</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX4.4</cell><cell>4</cell><cell>8</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX4.4</cell><cell>4</cell><cell>8</cell><cell>FIX4.8</cell><cell>8</cell><cell>12</cell></row><row><cell>FIX4.4</cell><cell>4</cell><cell>8</cell><cell>FIX8.8</cell><cell>8</cell><cell>16</cell></row><row><cell>FIX4.8</cell><cell>8</cell><cell>12</cell><cell>FIX4.8</cell><cell>8</cell><cell>12</cell></row><row><cell>FIX4.12</cell><cell>12</cell><cell>16</cell><cell>FIX4.4</cell><cell>4</cell><cell>8</cell></row><row><cell>FIX4.12</cell><cell>12</cell><cell>16</cell><cell>FIX4.8</cell><cell>8</cell><cell>12</cell></row><row><cell>FIX4.12</cell><cell>12</cell><cell>16</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Accuracy and size comparison on Cora, Pubmed and Citeseer with data splits same as<ref type="bibr" target="#b26">Yang et al. (2016)</ref>. Our results are averaged across 3 independent runs. The numbers in bold show best accuracies or smallest sizes.</figDesc><table><row><cell>METHOD</cell><cell>QUAN</cell><cell>CORA ACCURACY</cell><cell>SIZE</cell><cell cols="2">CITESEER ACCURACY</cell><cell>SIZE</cell><cell cols="2">PUBMED ACCURACY</cell><cell>SIZE</cell></row><row><cell>GRAPHSAGE</cell><cell>FLOAT</cell><cell>74.5 ± 0.0%</cell><cell>92.3KB</cell><cell>75.3 ± 0.0%</cell><cell cols="2">237.5KB</cell><cell>85.3 ± 0.1%</cell><cell>32.2KB</cell></row><row><cell cols="2">GRAPHSAGE W10A12</cell><cell>74.3 ± 0.1%</cell><cell>28.8KB</cell><cell>75.1 ± 0.1%</cell><cell cols="2">74.2KB</cell><cell>85.0 ± 0.0%</cell><cell>10.1KB</cell></row><row><cell>GAT</cell><cell>FLOAT</cell><cell>88.9 ± 0.0%</cell><cell>369.5KB</cell><cell>75.9 ± 0.0%</cell><cell cols="2">950.3KB</cell><cell>86.1 ± 0.0%</cell><cell>129.6KB</cell></row><row><cell>GAT</cell><cell>W4A8</cell><cell>88.8 ± 0.1%</cell><cell>46.2KB</cell><cell>68.0 ± 0.1%</cell><cell cols="2">118.8KB</cell><cell>82.0 ± 0.0%</cell><cell>16.2KB</cell></row><row><cell>JKNET</cell><cell>FLOAT</cell><cell>88.7 ± 0.0%</cell><cell>214.9KB</cell><cell>75.5 ± 0.0%</cell><cell cols="2">505.2KB</cell><cell>87.6 ± 0.0%</cell><cell>94.5KB</cell></row><row><cell>JKNET</cell><cell>W6A8</cell><cell>88.7 ± 0.1%</cell><cell>40.3KB</cell><cell>73.2 ± 0.1%</cell><cell cols="2">94.7KB</cell><cell>86.1 ± 0.1%</cell><cell>17.7KB</cell></row><row><cell>PDNAS-2</cell><cell>FLOAT</cell><cell>89.3 ± 0.1%</cell><cell>192.2KB</cell><cell cols="3">76.3 ± 0.3% 478.6KB</cell><cell>89.1 ± 0.2%</cell><cell>72.8KB</cell></row><row><cell>PDNAS-3</cell><cell>FLOAT</cell><cell>89.3 ± 0.1%</cell><cell>200.0KB</cell><cell>75.5 ± 0.3%</cell><cell cols="2">494.4KB</cell><cell>89.1 ± 0.2%</cell><cell>81.4KB</cell></row><row><cell>PDNAS-4</cell><cell>FLOAT</cell><cell>89.8 ± 0.3%</cell><cell>205.0KB</cell><cell>75.6 ± 0.2%</cell><cell cols="2">500.0KB</cell><cell>89.2 ± 0.1%</cell><cell>102.7KB</cell></row><row><cell>LPGNAS</cell><cell>MIXED</cell><cell>89.8 ± 0.0%</cell><cell>67.3KB</cell><cell>76.2 ± 0.1%</cell><cell cols="3">56.5KB 89.6 ± 0.1%</cell><cell>45.6KB</cell></row><row><cell cols="3">Figure 2. Pareto Frontier of LPGNAS and PDNAS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .</head><label>6</label><figDesc>Accuracy and size comparison on Flickr<ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>, Cora-full<ref type="bibr" target="#b0">(Bojchevski &amp; Günnemann, 2017)</ref> and Yelp<ref type="bibr" target="#b28">(Zeng et al., 2020)</ref>. Our results are averaged across 3 independent runs. The numbers in bold show best accuracies (blue) and smallest model sizes (red). Pareto Frontier of LPGNAS and other baselines on the Cora-full dataset</figDesc><table><row><cell>METHOD</cell><cell>QUAN</cell><cell cols="2">AMAZON-COMPUTERS ACCURACY SIZE</cell><cell cols="2">AMAZON-PHOTOS ACCURACY SIZE</cell></row><row><cell>GAT</cell><cell>FLOAT</cell><cell>84.4 ± 0.3%</cell><cell>199.8KB</cell><cell>84.2 ± 0.1%</cell><cell>199.8KB</cell></row><row><cell>GAT</cell><cell>W4A8</cell><cell>81.8 ± 1.5%</cell><cell>25.0KB</cell><cell>83.5 ± 0.5%</cell><cell>25.0KB</cell></row><row><cell>GAT-V2</cell><cell>FLOAT</cell><cell>85.3 ± 0.3%</cell><cell>1597.6KB</cell><cell>85.2 ± 0.4%</cell><cell>1597.6KB</cell></row><row><cell>GAT-V2</cell><cell>W4A8</cell><cell>38.0 ± 0.0%</cell><cell>199.7KB</cell><cell>38.0 ± 0.0%</cell><cell>199.7KB</cell></row><row><cell>JKNET</cell><cell>FLOAT</cell><cell>87.6 ± 0.0%</cell><cell>130.5KB</cell><cell>87.7 ± 0.1%</cell><cell>130.5KB</cell></row><row><cell>JKNET</cell><cell>W4A8</cell><cell>38.0 ± 0.0%</cell><cell>16.3KB</cell><cell>38.0 ± 0.0%</cell><cell>16.3KB</cell></row><row><cell>JKNET-V2</cell><cell>FLOAT</cell><cell>88.8 ± 0.1%</cell><cell>8968.2KB</cell><cell>88.6 ± 0.1%</cell><cell>8968.2KB</cell></row><row><cell>QJKNET-V2</cell><cell>W4A8</cell><cell>38.0 ± 0.0%</cell><cell>1121.0KB</cell><cell>38.0 ± 0.0%</cell><cell>1121.0KB</cell></row><row><cell>SAGENET</cell><cell>FLOAT</cell><cell>84.0 ± 0.0%</cell><cell>49.8KB</cell><cell>84.0 ± 0.1%</cell><cell>49.8KB</cell></row><row><cell>SAGENET</cell><cell>W4A8</cell><cell>83.9 ± 0.1%</cell><cell>6.2KB</cell><cell>83.9 ± 0.1%</cell><cell>6.2KB</cell></row><row><cell>SAGENET-V2</cell><cell>FLOAT</cell><cell>87.7 ± 0.2%</cell><cell>1593.4KB</cell><cell>87.9 ± 0.2%</cell><cell>1593.4KB</cell></row><row><cell>SAGENET-V2</cell><cell>W4A8</cell><cell>87.3 ± 0.2%</cell><cell>199.2KB</cell><cell>87.2 ± 0.3%</cell><cell>199.2KB</cell></row><row><cell>LPGNAS</cell><cell>MIXED</cell><cell>90.5 ± 0.0%</cell><cell>157.3KB</cell><cell>89.7 ± 0.0%</cell><cell>164.0KB</cell></row><row><cell cols="2">LPGNAS-SMALL MIXED</cell><cell>88.7 ± 0.1%</cell><cell>3.5KB</cell><cell>88.6 ± 0.1%</cell><cell>3.6KB</cell></row></table><note>Our results are averaged across 3 independent runs. The numbers in bold show best accuracies (blue) and smallest model sizes (red).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 .</head><label>7</label><figDesc>Search cost in GPU hours, all experiments are conducted on an NVIDIA GeForce RTX 2080 Ti GPU.</figDesc><table><row><cell>Dataset</cell><cell>Cora</cell><cell cols="4">Citeseer Pubmed Cora-full Flickr</cell><cell>Yelp</cell><cell cols="2">Amazon-photos Amazon-computers</cell></row><row><cell>LPGNAS</cell><cell>3.2</cell><cell>3.6</cell><cell>4.2</cell><cell>11.8</cell><cell>11.0</cell><cell>11.8</cell><cell>11.4</cell><cell>11.2</cell></row><row><cell cols="3">JKNet-32 6518.5 8165.6</cell><cell>5289.1</cell><cell>2180.6</cell><cell cols="2">3062.1 9116.7</cell><cell>1739.8</cell><cell>1786.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8 .</head><label>8</label><figDesc>Baseline networks configurations.</figDesc><table><row><cell>NETWORKS</cell><cell cols="2">LAYERS CHANNELS</cell></row><row><cell>GAT</cell><cell>2</cell><cell>32</cell></row><row><cell>GAT-V2</cell><cell>2</cell><cell>64</cell></row><row><cell>JKNET</cell><cell>2</cell><cell>32</cell></row><row><cell>JKNET-V2</cell><cell>2</cell><cell>512</cell></row><row><cell>SAGENET</cell><cell>2</cell><cell>16</cell></row><row><cell>SAGENET-V2</cell><cell>2</cell><cell>512</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03815</idno>
		<title level="m">Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><surname>Proxylessnas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00332</idno>
		<title level="m">Direct neural architecture search on target task and hardware</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Stochastic training of graph convolutional networks with variance reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10568</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graph-NAS: Graph neural architecture search with reinforcement learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09981</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Single path one-shot neural architecture search with uniform sampling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00420</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><surname>Mobilenets</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Efficient convolutional neural networks for mobile vision applications</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Binarized neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4107" to="4115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fixed-point feedforward deep neural network design using weights +1, 0, and −1</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Processing Systems</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-ninth AAAI conference on artificial intelligence</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1eYHoC5FX" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2902" to="2911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Shchur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mumme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.05868</idno>
		<title level="m">Pitfalls of graph neural network evaluation</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName><surname>Q-Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05840</idno>
		<title level="m">Hessian based ultra low precision quantization of bert</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Two-stream adaptive graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="12026" to="12035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fixed-point performance analysis of recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="976" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ" />
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Mixed precision quantization of convnets via differentiable neural architecture search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00090</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">FBNET: Hardwareaware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10734" to="10742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5449" to="5458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ryGs6iA5Km" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Revisiting semi-supervised learning with graph embeddings</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
				<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="40" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">GraphSAINT: Graph sampling based inductive learning method</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJe8pkHFwS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">LQ-Nets: Learned quantization for highly accurate and compact deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
				<imprint>
			<date type="published" when="2018">2018a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><surname>Gaan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07294</idno>
		<title level="m">Gated attention networks for learning on large and spatiotemporal graphs</title>
				<imprint>
			<date type="published" when="2018">2018b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5165" to="5175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An end-toend deep learning architecture for graph classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018c</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Focused quantization for sparse cnns</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5585" to="5594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jamnik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.09676</idno>
		<title level="m">Probabilistic dual network architecture search on graphs</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Auto</surname></persName>
		</author>
		<author>
			<persName><surname>Gnn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03184</idno>
		<title level="m">Neural architecture search of graph neural networks</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<title level="m">Trained ternary quantization. International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Predicting multicellular function through multi-layer tissue networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="190" to="198" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
