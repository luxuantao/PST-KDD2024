<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">N-Dimensional Tensor Voting and Application to Epipolar Geometry Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chi</forename><forename type="middle">-</forename><surname>Keung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Hong Kong, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
							<email>medioni@iris.usc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Robotics and Intelligent Systems</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<postCode>90089-0273</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>. . M.-S</roleName><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Philips Research USA</orgName>
								<address>
									<postCode>10510-2099</postCode>
									<settlement>Briarcliff Manor</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">N-Dimensional Tensor Voting and Application to Epipolar Geometry Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">54C58AAC74D6003EF8692AB60D06D4D8</idno>
					<note type="submission">received 12 Apr. 2000; revised 12 Jan. 2001; accepted 16 Jan. 2001.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index TermsÐTensor</term>
					<term>hyperplane inference</term>
					<term>epipolar geometry</term>
					<term>matching</term>
					<term>robust estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AbstractÐWe address the problem of epipolar geometry estimation efficiently and effectively, by formulating it as one of hyperplane inference from a sparse and noisy point set in an 8D space. Given a set of noisy point correspondences in two images of a static scene without correspondences, even in the presence of moving objects, our method extracts good matches and rejects outliers. The methodology is novel and unconventional, since, unlike most other methods optimizing certain scalar, objective functions, our approach does not involve initialization or any iterative search in the parameter space. Therefore, it is free of the problem of local optima or poor convergence. Further, since no search is involved, it is unnecessary to impose simplifying assumption (such as affine camera or local planar homography) to the scene being analyzed for reducing the search complexity. Subject to the general epipolar constraint only, we detect wrong matches by a novel computation scheme, 8D Tensor Voting, which is an instance of the more general N-dimensional Tensor Voting framework. In essence, the input set of matches is first transformed into a sparse 8D point set. Dense, 8D tensor kernels are then used to vote for the most salient hyperplane that captures all inliers inherent in the input. With this filtered set of matches, the normalized Eight-Point Algorithm can be used to estimate the fundamental matrix accurately. By making use of efficient data structure and locality, our method is both time and space efficient despite the higher dimensionality. We demonstrate the general usefulness of our method using example image pairs for aerial image analysis, with widely different views, and from nonstatic 3D scenes (e.g., basketball game in an indoor stadium). Each example contains a considerable number of wrong matches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I N computer vision, epipolar geometry is a fundamental constraint used whenever two images of a static scene are to be registered. Two issues needed to be addressed are: the correspondence problem and the parameter estimation problem given a set of correspondences. The main difficulty stems from the unavoidable outliers inherent in the given matches. Most robust techniques require that the majority of matches be correct or else some form of outlier detection and removal is usually performed before actual parameter estimation.</p><p>Both outlier detection and parameter estimation are often formulated as a nonlinear optimization and search process in the parameter space. In the case of the full perspective camera model, this search space can be prohibitively large. Consequently, gradient-based and other nonlinear heuristic search techniques have been proposed. The output, however, may not be initialization free and poor initialization may seriously affect convergence rate. Though simplifying assumptions, such as affine camera model and local planar homography <ref type="bibr" target="#b13">[14]</ref>, can reduce the search complexity, the class of transformations which can be represented is somewhat restricted.</p><p>In this paper, we propose an unconventional, effective, and efficient approach to solve the outlier detection problem for epipolar geometry estimation. The solution technique is unconventional since we do not formulate the problem into an iterative, optimization framework, as many other researchers already did. We demonstrate the effectiveness of our approach by using difficult examples and quantitatively justify our method. Our method is efficient since, as shown in the space and time complexity section, our algorithm is independent of the dimensionality of the parameter space.</p><p>A compact conference version of this paper has appeared in <ref type="bibr" target="#b15">[16]</ref>, which includes a brief description of the 8D instance of the more general, N-dimensional tensor voting formalism, the latter of which is detailed in Section 2 in this paper. The present coverage contains a more detailed description and illustration on our methodology.</p><p>As shown in Section 1.2, the epipolar constraint is a linear and homogeneous one that defines an 8D hyperplane in its parameter space. Therefore, given a candidate set of (usually noisy) matches, suppose that we could visualize in 8D, the subset of inlier matches should cluster themselves onto a hyperplane in the corresponding 8D space. Thus, analogous to line detection in a 2D point cloud, we can pose our outlier detection problem as one of hyperplane inference in 8D. Therefore, it is of great value and theoretical interest if we can extract this salient hyperplane feature from the given sparse and noisy 8D cluster, without performing any iterative or multidimensional parameter search. Simplifying assumption will become unnecessary, as the size of the search space is no longer an issue.</p><p>An intuition to a noniterative solution for hyperplane inference is inspired by the Hough Transform <ref type="bibr" target="#b6">[7]</ref>. It employs a voting technique that outputs the solution receiving maximal support. However, as the dimensionality grows, the Hough Transform is extremely inefficient. Thus, it is impractical in most higher-dimensional detection problems.</p><p>Therefore, the contributions of this paper are twofold: A formal framework, the N-dimensional tensor voting formalism, is proposed. It is generalized from the 2D version <ref type="bibr" target="#b11">[12]</ref>. The N-D tensor voting resembles the Hough transform in that it uses a voting technique; but is different since the time and space complexities are independent of dimensionality. The second contribution consists of the application of this higher-dimensional methodology in outlier detection and removal for general epipolar geometry estimation. We demonstrate the general usefulness of this novel estimation methodology with a variety of image pairs as examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Previous Work</head><p>If the input set of correspondences is already very good, then, a linear method, such as Eight-Point Algorithm <ref type="bibr" target="#b9">[10]</ref>, can be used for accurate parameter estimation. This algorithm is probably the most cited method for computing the essential (respectively fundamental) matrix from two calibrated (respectively uncalibrated) camera images. With more than eight points, a least mean square minimization is used, then followed by the enforcement of the singularity constraint so that the rank of the resulting matrix is 2. Its obvious advantages are speed and ease of implementation. However, in practice, the input set of matches contains a considerable amount of outliers. The linear method is extremely sensitive to wrong matches.</p><p>In <ref type="bibr" target="#b7">[8]</ref>, Hartley normalizes the data before using the Eight-Point Algorithm and shows that this normalized version performs comparably well with more complicated iterative techniques, which are described below. Outlier rejection is performed before the algorithm is used. Note that the Eight-Point Algorithm is not optimal since it minimizes an algebraic distance. Therefore, a nonlinear geometric error measure should be used.</p><p>More complicated, iterative optimization methods are proposed to address the issues of noisy matches, some of them are described in <ref type="bibr" target="#b21">[22]</ref>. These nonlinear, robust methods make use of certain optimization criteria, such as distance between points and their corresponding epipolar lines or gradient-weighted epipolar errors. Iterative methods, in general, require careful (or at least sensible) initialization for early convergence to the desired optimum (or, in other words, avoiding local optimum). In particular, the method proposed by Zhang <ref type="bibr" target="#b21">[22]</ref> uses least median of squares, data subsampling, and certain adapted criterion, to discard outliers by solving a nonlinear minimization problem. The fundamental matrix is then estimated. Note that robust methods require a majority of the data be correct, whereas we can tolerate much higher outlier to inlier ratio, as shown in the Section 6.</p><p>Torr and Murray <ref type="bibr" target="#b18">[19]</ref> proposed the use of RANSAC: Random sampling of a minimum subset (seven pairs) for parameter estimation is performed. The solution is given by the candidate subset that maximizes the number of consistent points and minimizes the residual. It is, however, computationally infeasible to consider all possible subsets, since it is exponential in number. Therefore, additional statistical measures are needed to derive the minimum number of sample subsets. Extra samples are also needed to avoid degeneracy. In our approach, we can afford to consider all input matches, since it is linear in time and space.</p><p>Chai and Ma <ref type="bibr" target="#b1">[2]</ref> proposed the use of genetic algorithm to avoid the problem of local minima, by using properly defined genetic operators. The optimization process can be sped up through incorporating the ideas of evolution that properly guides the search process.</p><p>Ke et al. <ref type="bibr" target="#b3">[4]</ref> proposed the use of Reactive Tabu Search which avoids the prohibitive search complexity by guiding a local heuristic search among neighborhood configurations beyond local optima. A cost function is minimized while outliers are discarded, using a certain criterion.</p><p>In <ref type="bibr" target="#b13">[14]</ref>, Pritchett and Zisserman proposed the use of local homography (planar projective transformation). Homographies are generated by Gaussian pyramid techniques. Point matches are then generated using a homography. The set of matches is then enlarged, by using RANSAC for selecting a subset of initial matches consistent with a given homography. Besides its viewpoint invariance, homography drastically reduces the search space. However, the homography assumption, as noted, does not generally apply to the entire image (e.g., curved surfaces), although local homography applies in most situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Review of Epipolar Geometry</head><p>Here, we briefly review epipolar geometry (more details in <ref type="bibr" target="#b4">[5]</ref>), and formulate the estimation problem as one of 8D hyperplane inference.</p><p>Given two images of a static scene taken from two camera systems (see Fig. <ref type="figure" target="#fig_1">1</ref>), let u Y v be the image coordinates of a point in the first image. Its corresponding point u r Y v r is constrained to lie on the epipolar line derived from u Y v . This line is the intersection of two planes: The first is defined by the two optical centers g I Y g P , and u Y v and the other plane is the image plane of the second image. A symmetric relation applies for u r Y v r . This is known as the epipolar constraint. The fundamental matrix p that relates any matching pair u Y v and u r Y v r is given by u I pu P H, The epipolar constraint can be rewritten as a linear and homogeneous equation in terms of the nine unknown coefficients in p or u f p QQ H, where The hyperplane normal (given by f ) and p QQ are unknowns and they are estimated using our 8D version of tensor voting.</p><formula xml:id="formula_0">where u I u Y v Y I and u P u r Y v r Y I . Note that p is a rank 2, Q Â Q homogeneous matrix.</formula><formula xml:id="formula_1">u u u r v u r u r u v r v v r v r u v I f p II p IP p</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Overall Approach and Outline of this Paper</head><p>Using epipolar geometry estimation as an example, Fig. <ref type="figure" target="#fig_2">2</ref> shows our overall N-D approach, in which ªTensorizationº and ªDensificationº are implemented as 8D voting processes (the more general N-dimensional tensor voting is described in Section 2).</p><p>The input set of point matches, obtained by automatic means such as cross-correlation techniques, is first converted into a sparse 8D point set as described in Section 1.2. This point set is then ªtensorizedº into a discrete tensor field, which encodes the most preferred normal direction at each point.</p><p>Then, this tensor field is locally ªdensified,º producing local dense structures suitable for extrema detection, from which the salient hyperplane containing all good matches can be estimated. Eight-dimensional tensorization, densification, and extrema detection are described in Section 3. Each input match is then checked against the inferred hyperplane, producing a set of filtered inliers. Other pertinent issues on implementation are described in Section 4.</p><p>Finally, the normalized eight-point algorithm (least mean square minimization followed by the enforcement of singularity constraint) is applied to the verified matches for fundamental matrix estimation. Complexity analysis and results on a variety of image pairs are described in Sections 5 and 6, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">N-DIMENSIONAL TENSOR VOTING</head><p>In this section, we describe how to generalize the tensor voting formalism to N-dimension for any x b P, using the 2D case as the basis. The 2D tensor voting formalism, as described in <ref type="bibr" target="#b11">[12]</ref>, can be generalized to N-D readily. For this reason, we shall relate the 2D version to facilitate our N-D discussion whenever appropriate. Table <ref type="table" target="#tab_1">1</ref> summarizes the key concepts in this section:</p><p>. N-D tensor representation and interpretation, . N-D tensor communication, . N-D tensor voting implementation, and . N-D feature extraction. Before describing the above elements in N-D tensor voting, let us first motivate our study of N-dimensional voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation</head><p>We first justify our approach in this section. While a more rigorous analysis is a subject of further research, the following should provide some insightful intuition to explain the efficacy of our approach. Our formalism consists of two important aspects: tensor for representation and voting for communication. We shall describe, in Section 2.3, the fundamental stick voting field (Fig. <ref type="figure">5</ref>) which is the most important element. Given a point with its finite neighborhood, what is the most likely direction at this point? Consider an analogy in particle physics in which two particles vibrate. Each emits a waveform to communicate with each other. If their frequencies agree, they will reinforce each other, producing a maxima (or resonance). If their frequencies do not agree, no maxima is produced. The fundamental stick voting field (and its derivations) is used to mimic this communication process, reporting a solution that produces the highest agreement, or the maximal response. Fig. <ref type="figure" target="#fig_3">3</ref> shows three scenarios:</p><p>1. A point at h receives vector votes from eY fY gY iY and p , Fig. <ref type="figure" target="#fig_3">3a</ref>. Suppose that points eY fY gY iY and p are associated with a direction consistent with an underlying smooth curve (the dotted curve), on which h is lying. To propagate the continuity constraint (using the 2D fundamental stick field), each point casts a vector vote at h. Only one vector (PH ) is consistent with the given curve tangent directions at eY fY gY iY and p simultaneously, which are depicted as ªÂº in Fig. <ref type="figure" target="#fig_3">3a</ref>. If we plot the corresponding histogram, a maxima (resonance) exists at PH . Note that the situation is simplified in this illustration: in practice, other angles should receive some response. The dotted curve in the histogram is closer in appearance to the real situation. 2. A point at h receives votes from voters without any direction information, Fig. <ref type="figure" target="#fig_3">3b</ref>. Now, suppose all the points are not associated with any direction information. Given that they are still lying on a smooth curve, when they ªcommunicateº with each other (using the 2D ball voting field, derived from the 2D fundamental stick field), only one direction at each site produces a maximum response to satisfy the continuity constraint. In other words, a strong maxima (resonance) at certain angle is detected at each location. 3. A point receives votes from many directions, Fig. <ref type="figure" target="#fig_3">3c</ref>.</p><p>At a point junction where more than one curves intersect, a set of votes with inconsistent directions is obtained. All orientations are equally likely. No maxima or resonance is produced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tensor Representation and Interpretation</head><p>In this section, we describe the components in N-D tensor voting in detail, which are used to realize the communication process described in Section 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Second Order Symmetric Tensor in N-D</head><p>Suppose we perform curve detection in a 2D point cluster. A point in this cluster either belongs to a curve, a point junction where intersecting curves meet, or is an outlier. Consider the two extremes in which a point on a curve is very certain about its tangent direction, whereas a point junction at which many curves intersect has absolute orientation uncertainty. Thus, we use a ªstickº to indicate absolute orientation certainty and a ªballº to indicate absolute orientation uncertainty. This whole continuum can be abstracted as a second order symmetric tensor in 2D, which can be visualized geometrically as an ellipse (Fig. <ref type="figure">4</ref>). This ellipse can be described by the   Analogously in N-D, in hypersurface detection, a point in the N-D space can either be: on hypersurface (smooth), at a discontinuity of order between two and x, or is an outlier. Consider the two extremes: an N-D point on a hypersurface is very certain about its normal direction, whereas a point at a junction has absolute orientation uncertainty. As in 2D, this whole continuum can be abstracted as a second order symmetric N-D tensor, or equivalently, a hyperellipsoid. This hyperellipsoid can be equivalently described by the corresponding eigensystem with its x eigenvectors e I Y e P Y Á Á Á Y e x and the x corresponding eigenvalues,</p><formula xml:id="formula_2">! I ! ! P ! Á Á Á ! ! x .</formula><p>Rearranging the x Â x eigensystem, the N-D ellipsoid is given by:</p><formula xml:id="formula_3">! I À ! P xÀI iP ! i À ! iI i jI e j e j ! x fX R</formula><p>In particular, e I e I and f</p><p>x iI e i e i defines an N-D stick and ball, respectively, among all the x basis tensors. We call the rest of x À P basis tensors i jI e j e j plate tensors. Any hyperellipsoid in N-D can be represented by a linear combination of these x basis tensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">N-D Tensor Interpretation</head><p>We now explain the geometric meaning of the eigensystem we derived in the previous section. Return to the 2D case.</p><p>The eigenvectors encode orientation (un)certainties: Tangent direction is described by the stick tensor, indicating certainty along a single direction. At point junctions, where more than two intersecting lines converge, a ball tensor is used since there is no preferred orientation. The eigenvalues encode the magnitude of orientation (un)certainties since they indicate the size of the ellipse. Hence, given a generic ellipse and its equivalent eigensystem, we have the following geometric interpretation:</p><p>. ! I À ! P corresponds to 2D curve saliency, with a stick tensor e I e I indicating the curve tangent direction,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Uniform Encoding</head><p>Therefore, given an N-D point, with or without orientation, we can unify the input into a tensor field by the following: If the input token is a point without any directional information, it is encoded as a N-D ball tensor (! I ! P Á Á Á ! x I) since initially there is no preferred orientation. e I e P Á Á Á e x is an x Â x identity matrix.</p><p>If the input token is a curve element in N-D, it is encoded as a plate tensor (! I ! P Á Á Á ! xÀI IY ! x H), with e x equal to the direction of the curve tangent. Other plates are encoded accordingly.</p><p>If the input token is a N-D hypersurface patch element, then it is encoded as a stick tensor (!</p><formula xml:id="formula_4">I IY ! P ! Q Á Á Á ! x H), with</formula><p>e I equal to the direction of the surface normal to the given hypersurface patch.</p><p>In implementation, we first encode the input uniformly into a tensor field. Each input tensor token then communicates, by a voting algorithm, in order to obtain a generic tensor, which describes the orientation preference (or no preference) at that site.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">N-D Tensor Communication: N-D Tensor Voting</head><p>Each input token votes, or is made to align, with precomputed, discrete versions of the basis tensors in a convolution-like way, propagating preferred direction in a neighborhood. We call these precomputed basis tensors voting fields. As a result, preferred orientation information is propagated and gathered at each input site. This voting process consists of two phases:</p><p>. token refinement (ªtensorizationº): tensor votes are collected at input sites only and</p><p>. dense extrapolation (ªdensificationº): tensor votes fill the volume for feature extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Token Refinement and Dense Extrapolation</head><p>Given a set of input tokens, they are first encoded as tensors as described in Section 2.2.3. These initial tensors communicate with each other by token refinement and dense extrapolation.</p><p>In essence, in token refinement, each token collects all the tensor values cast at its location by all the other tokens in a neighborhood. The resulting tensor value is the tensor sum of all the tensor votes cast at the token location. In dense extrapolation, each token is first decomposed into its corresponding x elements. By using an appropriate voting field, each token broadcasts the information in a neighborhood. The size of the neighborhood is given by the size of the voting field used. As a result, a tensor value is put at every location in the neighborhood. The resulting dense information can be used for feature extraction in which first derivatives are computed.</p><p>In fact, these two tasks can be implemented by a voting process, which in essence involves having each input token aligned with precomputed, dense, N-D voting fields. The alignment is simply a translation followed by rotation in the N-D space.</p><p>Therefore, it remains to describe the N-D voting fields, which can be derived from the most basic, fundamental 2D stick voting field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Derivation of N-D Voting Fields</head><p>The fundamental 2D stick voting field. Voting fields of any dimensions can be derived from the 2D stick tensor and, therefore, it is called the fundamental 2D stick voting field. Fig. <ref type="figure">5</ref> shows this fundamental 2D stick voting field.</p><p>In 2D, a direction can be defined by either the tangent vector, or the normal vector, which are orthogonal to each other. We can therefore define two equivalent fundamental fields, depending on whether we assign a tangent or normal vector at the receiving site.</p><p>Here, we describe the normal version of the 2D stick kernel. The tangent version is similar. Given a point at the origin with a known normal (x), we ask the following question: For a given point in space, what is the most likely normal (at ) to a curve passing through y and and normal to x? Fig. <ref type="figure" target="#fig_7">6</ref> illustrates this situation. We claim that the osculating circle connecting y and is the most likely one since it keeps the curvature constant along the hypothesized circular arc. For a detailed theoretical treatment, please refer to <ref type="bibr" target="#b11">[12]</ref>. The most likely normal is given by the normal to the circular arc at . The length of the normal vector at , which represents the saliency of the vote, is inversely proportional to the arc length y and also to the curvature of the underlying circular arc. In doing so, both the proximity and the smoothness (or lower curvature) constraints are effectively encoded as the corresponding saliency measure, representing the likelihood of a smooth curve passing through that point.</p><p>In spherical coordinates, the decay of the fundamental 2D stick field takes the following form:</p><formula xml:id="formula_5">hp rY 9Y ' e À r P 9 P ' P À Á Y S</formula><p>where r is the arc length y , 9 is the curvature, and ' is the scale of analysis, the only free parameter in our formalism. Note that the connection as given by the osculating circle becomes less likely if the angle subtended by x and y is less than RS . Therefore, we only consider the set of orientations for which the angle defined above is not less than RS . See Fig. <ref type="figure">5</ref>.</p><p>Derivation of N-D stick kernel. Without loss of generality, we derive the N-D stick kernel oriented at either AEI H H Á Á Á H in world coordinate system (note we do not distinguish the polarity of orientation which is unknown). Other orientations can be achieved by a simple rotation in the N-D space. We first rotate the normal version of the 2D stick kernel so that it describes the orientation AEI H . Denote the rotated, normal version of the fundamental 2D stick voting field H p . We adopt the parameterization</p><formula xml:id="formula_6">! I Y ! P Y Á Á Á Y ! x Y x Y xÀI Y Á Á Á Y I ,</formula><p>where i are angles of rotation about the axis i. Therefore, this parameterization characterizes the magnitude and orientation of the tensor . Using this parameterization, the N-D stick Á is:</p><formula xml:id="formula_7">IY HY Á Á Á Y H | {z } xÀI Y x Y xÀI Y Á Á Á Y I % H H p d I j x xÀI ÁÁÁ P H X T Derivation of N-D ball kernel.</formula><p>The N-D ball kernel can be obtained by rotating the above N-D stick kernel about the remaining x À I axes and integrating the contributions:</p><formula xml:id="formula_8">fIY IY Á Á Á Y I |{z} n Y x Y xÀI Y Á Á Á Y I % H % H Á Á Á % H d P d Q Á Á Á d x j IH X U Derivation of other N-D kernels.</formula><p>For the other i kernels, P i `x, we have</p><formula xml:id="formula_9">IY IY Á Á Á Y I z}|{ i Y HY HY Á Á Á Y H z}|{ nÀi Y x Y xÀI Y Á Á Á Y I % H % H Á Á Á % H d nÀiP Á Á Á d x j I P ÁÁÁ nÀiI HY V</formula><p>which actually describes the rotation of the N-D stick field about the i axes and the integration of the contributions from all possible angles of rotation. for all iY j such that H `iY j `dimension À I do tensorvote</p><formula xml:id="formula_10">[i][j] 2 tensorvote[i][j] weight Â stickvote[i] Â stickvote[j] end for</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation of N-D Tensor Voting</head><p>The N-D tensor voting process aggregates tensor contribution from a neighborhood of voters by using tensor addition. Consider the case that we have only two input tokens. Initially, before any voting occurs, each token location encodes the local tensor information (i.e., Section 2.2.3). Denote these two tensors by HYI and HYP . The following describes the token refinement step. The dense extrapolation step can easily be generalized from it.</p><p>Tensor Encoding. The input is encoded into a perfect ball, a perfect stick, or a perfect plate (note that, in the case, of N-D, we have a total of x À P cases of plate tensors). One example is a ªhypercurveº: a space curve occupying in the N-D space.</p><p>. Stick. </p><formula xml:id="formula_11">! I IY ! P ! Q Á Á Á ! x H,</formula><formula xml:id="formula_12">! I H Á Á Á H H ! P Á Á Á H Á Á Á Á Á Á Á Á Á Á Á Á H H Á Á Á ! x P T T T R Q U U U S e I e P F F F e x P T T T T R Q U U U U S W ! I À ! P xÀI kP ! k À ! kI k lI e l e l ! x f IH HYj xÀI kP k HYj f</formula><p>HYj Y II where e I e I and f</p><p>x lI e l e l defines an N-D stick and ball, respectively. The x À P plate tensors are defined respectively by ! k À ! kI k lI e l e l , P k `x. These x basis tensors define any hyperellipsoid in N-D, by a linear combination of them.</p><p>Note that all the x Â x matrices HYj Y k HYj Y f HYj are symmetric, semipositive definite and they describe a stick, plate, and ball tensor, respectively.</p><p>Tensor Voting. An input site j collects the tensor vote cast from the voter i. This vote consists of a stick component, x À P plate components, and a ball component.</p><formula xml:id="formula_13">. Stick vote. Let v I v P Á Á Á v x</formula><p>be the stick vote collected at site j, which is cast by voter i after aligning the e I component of the tensor HYi at i (obtained in the tensor encoding stage) with the N-D stick voting field, by translation and rotation. Then,</p><formula xml:id="formula_14">IYj HYj ! I À ! P v P I v I v P Á Á Á v I v x v P v I v P P Á Á Á v P v x Á Á Á Á Á Á Á Á Á Á Á Á v x v I v x v P Á Á Á v P x P T T T R Q U U U S IP HYj ! I À ! P Y IQ</formula><p>where is x Â x a symmetric, semipositive definite matrix, consisting of the second order moment collection of the vote contribution. That is, by using Algorithm 3: COMBINE. . Plate votes. Let k be the plate vote, P k `x, collected at site j, which is cast by voter i. IYj , and f IYj are all symmetric and semipositive definite. Hence, IYj produced by the above is also a second order symmetric tensor. Tensor Decomposition. After IYI , IYP have been obtained by the above voting process implemented as tensor addition, we decompose each of them into the corresponding eigensystem.</p><p>Note that the same tensor sum applies to the tensor voting process for extrapolating directional estimates, with the following changes:</p><p>. First, site j may or may not hold an input token. For noninput site j, HYj is a zero matrix. . Second, we do not propagate the ball component from voting sites since the ball component corresponds to junction information and thus should not be propagated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">N-D Feature Extraction</head><p>Recall that we need dense extrapolation to produce a dense structure for feature extraction. After the dense extrapolation stage, x dense structures, which are dense scalar or vector fields, are produced after the tensor decomposition step into the corresponding eigensystem. Here, we only consider the two extreme cases, the stick and the ball maps:</p><p>. hypersurface map: Each N-D voxel in this map consists of 2-tuple sY n, where s ! I À ! P indicate the hypersurface-ness, or hypersurface saliency, and n e I denotes the hypersurface normal direction. . hyperjunction map: It is a dense scalar map f! x g which denote, the hyperjunction-ness, or hyperjunction saliency. Since the other x À P vector maps are more complicated and we have not applied them in applications, we shall not study the feature extraction from these maps in this paper.</p><p>The extraction of maximal junction in the hyperjunction map is very straightforward: It is a local maxima of the scalar value ! x .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">N-D Hypersurface Extremality</head><p>Here, we generalize 3D extremal surface <ref type="bibr" target="#b17">[18]</ref> to N-D extremal hypersurface. Recall that the hypersurface map is a dense vector field fsY ng which encodes hypersurface normals n e I associated with saliency values s ! I À ! P . To illustrate, suppose the dense structure as obtained after the dense extrapolation stage, or densification, is dense and continuous, i.e., fsY ng is defined for every point in the N-D space.</p><p>Suppose that we could traverse and look at the s values along the N-D vector n (Fig. <ref type="figure" target="#fig_8">7a</ref>). By the definition of the N-D stick kernel, if a patch exists, after tensor voting, a maxima in s (Fig. <ref type="figure" target="#fig_8">7b</ref>) should be detected.</p><p>Therefore, we define an extremal hypersurface as the locus of points for which the saliency s is locally extremal along the direction of the N-D normal, i.e., ds d n H. This is only a necessary condition for extrema detection. The sufficient condition, which is used in the implementation, is defined in terms of zero crossings along the line defined by n (Fig. <ref type="figure" target="#fig_8">7c</ref>). We first compute the saliency gradient along the x principal axes</p><formula xml:id="formula_15">x I Y x P Y Á Á Á Y x x : g Ss ds dxI ds dxP Á Á Á ds dxx h i X</formula><p>Then, we project g onto n by computing the inner product, i.e., q n Á g. Thus, an extremal hypersurface is the locus of points with q H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">Discrete Version</head><p>In implementation, we have a discrete fs iIYiPYÁÁÁYix Y n iIYiPYÁÁÁYix g dense map. We can define the corresponding discrete versions of g and q, i.e.,</p><formula xml:id="formula_16">g i I Yi P YÁÁÁYi x s iIIYiPYÁÁÁYix À s iIYiPYÁÁÁYix s i I Yi P IYÁÁÁYi x À s i I Yi P YÁÁÁYi x F F F s i I Yi P YÁÁÁYi x I À s i I Yi P YÁÁÁYi x P T T T R Q U U U S IR</formula><p>and q i I Yi P YÁÁÁYi x n i I Yi P YÁÁÁYi x Á g i I Yi P YÁÁÁYi x . Given an input point, we compute q i I Yi P YÁÁÁYi V at each vertex voxel (a total of P x that makes up the hypercube quantization unit, or hypercuboid, that contains the input site). Thus, the set of all fq i I Yi P YÁÁÁYi x g constitutes a scalar field. If the signs of the q's of two adjacent vertex voxels are different, a zero crossing occurs on the corresponding hypercuboid edge (there is a total of xP xÀI of them). Implementation issues on N-D feature extractions which arose from the increase in x are described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.3">Extraction of x À IEh Entity</head><p>When the zero crossings have been detected, in our N-D case, we need to group these zero crossings in order to find an x À IEh entity, or a hypersurface patch, that intersects with the N-D hypercuboid.</p><p>Weigle and Banks <ref type="bibr" target="#b19">[20]</ref> describe a contour meshing procedure which generalizes well to x dimensions. We only outline the procedure here. Details (and terms in italics below) can be found in the paper and in a technical report <ref type="bibr" target="#b16">[17]</ref>.</p><p>. First, a splitting operation is performed, which divides a hypercuboid, made up of P x vertex voxels, into a set of P xÀI x3 N-simplexes. . Zero crossings are then detected on the edges of these resulting simplexes. . A contouring algorithm is applied recursively, starting by contouring 1-simplexes (edge) and then 2-simplexes (triangle), so on. Given a hypercuboid, which is made up of P x vertices, a contour, made up of x À IEsimplexes, should be produced if a hypersurface (an x À IEh entity) passes through that hypercuboid. Therefore, the detection of hypersurface is translated into the following verification: If the candidate contour as produced by the above contour meshing procedure can be triangulated into a set of x À IEsimplexes and nothing more, i.e., without any ªdanglingº simplex of lower dimensions left behind, then, we can conclude that a hypersurface is detected.</p><p>We have now explained the generalized N-D version of tensor voting, and extraction of 0D entity (hyperjunction) and x À IEh entity (hypersurface), and cited the relevant reference on N-D feature extraction. In the following section, we specialize the N-D tensor voting and feature extraction into 8D and describe implementation details to cope with the complexity issues which arose in feature extraction, as a result of higher dimensionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EPIPOLAR GEOMETRY ESTIMATION</head><p>In this section, we specialize the N-D version and apply it to the estimation of epipolar geometry. First, we transform each match as described in Section 1.2 into a point in an 8D space parameterized by u Y u r Y v Y v r . Then, we perform the following steps, which are depicted as shaded processes in the flowchart of Fig. <ref type="figure" target="#fig_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tensorization in 8D</head><p>Each 8D point, which corresponds to a potential match, is first encoded as an 8D ball. Then, these input balls communicate with each other, propagating ball votes in a neighborhood. After each input site has collected all the 8D tensor votes in its neighborhood, the resulting tensor is decomposed into the corresponding eight components. Since we want to infer a hyperplane, the 8D ball component is discarded as it corresponds to junction information, which should not be propagated in the dense voting stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Local Densification in 8D</head><p>After the input has been tensorized, the stick component at each input tensor is made to align with the 8D stick voting field for obtaining a densified structure SMap fsY ng, which indicates hypersurface-ness, as defined in Section 2.6. This dense structure is used for extrema detection (Section 3.3), which discards outlier matches. This voting process is exactly the same as tensorization, except that directed votes are also collected at noninput sites in the volume.</p><p>We first give a 2D analogy to motivate the issue we need to address due to higher dimensionality. In 2D line extraction, we can afford to densify the whole 2D domain, i.e., votes are cast everywhere, Fig. <ref type="figure" target="#fig_9">8a</ref>. Or, more efficiently, since we have obtained saliency information after tensorization (in 2D), densification starts out from the most salient site first. Votes are then propagated subject to connectivity (since a connected line should be extracted). Hence, only a slab of votes enveloping the line are computed during the extraction process, Fig. <ref type="figure" target="#fig_9">8b</ref>.</p><p>In our 8D version, two implementation differences are made to avoid the drastic increase in time and space complexities in feature extraction due to the higher dimensionality.</p><p>For time efficiency, we do not even need to compute a slab of votes, since all we need is outlier rejection, for which an explicit hyperplane represented as connected hypersurface patches (analogous to connected line segments) is not necessary. We pose this outlier rejection problem as one of extrema detection in 8D (next section), which is performed at each input site only. Therefore, it is sufficient to perform local densification, Fig. <ref type="figure" target="#fig_9">8c</ref>. Each input site gathers all the stick votes cast within the neighborhood (defined by the size of the voting field), performs smoothing, computes the eigensystem, interprets the vote, and produces a hypersurface patch (if any) for that site only, all on-the-fly. The result produced by vote gathering is the same as vote casting since they are reciprocal to each other.</p><p>For space efficiency, both local densification and vote gathering imply that it is unnecessary to keep the sparse input in an explicit 8D voxel array, which would be very expensive. Since we quantize the input, we use a ªlinearized 8D red-black treeº to store each input site. This data structure is an ordinary red-black tree, but we concatenate the eight integer coordinates as the search key. Its size is only ym, m is the input size. Hence, it is much less expensive than a whole 8D array. Please refer to a standard algorithm text (such as <ref type="bibr" target="#b3">[4]</ref>) for details on red-black tree. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Extrema Detection and Outlier Rejection</head><p>Now, for each input site, we have computed a dense and local collection fsY ng of the SMap that encodes surface normals n associated with saliency values s. We want to infer a salient hyperplane, with subvoxel accuracy, that contains the set of inliers. It is done by extrema detection, which indicates whether a salient hyperplane passes through that site.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">8D Extremality</head><p>We specialize the N-D extremality to 8D extremality in this section. In the 8D implementation, we compute the saliency gradient</p><formula xml:id="formula_17">g Ss ds dx I ds dx P Á Á Á ds dx V ! Y</formula><p>and then project g onto n, i.e., q n Á g. Thus, an extremal hypersurface is the locus of points with q H.</p><p>We have discrete fs i I Yi P YÁÁÁYi V Y n i I Yi P YÁÁÁYi V g in implementation. We can define the corresponding discrete versions of g and q, and q i I Yi P YÁÁÁYi V n i I Yi P YÁÁÁYi V Á g i I Yi P YÁÁÁYi V . Given an input point, we compute q i I Yi P YÁÁÁYi V at each vertex voxel (a total of P V PST voxels, making up a hypercuboid). Thus, the set of all fq i I Yi P YÁÁÁYi V g constitutes a scalar field. If the signs of the qs of two adjacent vertex voxels are different, a zero crossing occurs on the corresponding hypercuboid edge (there is a total of 1,024 of them).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Grouping of Detected Zero Crossings</head><p>The mere existence of zero crossings does not necessarily imply the presence of a salient hyperplane because outlier noise can produce local perturbations of the scalar field. Therefore, we need to group the zero crossings detected at each input site into meaningful entities.</p><p>In 2D, the Marching Squares algorithm can be used to link or order all zero crossings detected on a grid edge in order to produce a curve, which is a 1D entity.</p><p>In 3D, the classical Marching Cubes <ref type="bibr" target="#b10">[11]</ref> algorithm orders detected zero crossings on the 3D cuboid edges (a total of 12 of them) to form nontrivial cycles. One cycle corresponds to a surface patch, which is a 2D entity. In practice, a surface patch can be detected by checking a precomputed lookup table of all feasible configurations: the set of all zero crossings detected on cuboid edges should exactly form a set of cycles without any zero crossing left.</p><p>The grouping of zero crossings detected on the hypercuboid edges in a discretized 8D space is analogous. We precompute once all feasible configurations (rotationally symmetric counterparts are counted as a single configuration), and store each template configuration as an ordered edge set in a lookup table. Then, the subset of hypercuboid edges with zero crossings (detected as described in Section 3.3.1) are matched against the stored templates. This template matching is very efficient, since a configuration can be quickly discarded by a simple check on the number of edges in the template, followed by the ordering of edges. If a match occurs, then we conclude that a salient hyperplane passes through this 8D site, or equivalently, an inlier is found.</p><p>Given the set of inliers found, we estimate the hyperplane normal and p QQ as follows: The hyperplane normal is the saliency-weighted mean of the normals inferred at all classified inliers. p QQ is the saliency-weighted mean of the p QQ 's at all inliers, obtained using the estimated hyperplane normal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OTHER ISSUES</head><p>In this section, we describe other implementation details which augment the 8D tensor voting system in order to be applied to the estimation of epipolar geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Normalization</head><p>A data normalization (translation and scaling) step as described in Hartley <ref type="bibr" target="#b7">[8]</ref> is performed. The normalization step is performed independently for the two image pairs. The set of image points on one image, obtained from all potential point matches, is first translated so that their centroid is at the origin. Then, the point coordinates are scaled so that the mean distance from the origin is P p . See <ref type="bibr" target="#b7">[8]</ref> for the underlying reason on data normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Scaling</head><p>In the epipolar case, the eight dimensions are independent, but not normalized or orthogonal. Since the fundamental stick voting field assumes isotropic and orthogonal dimensions, scaling of the dimensions of the 8D space is needed so that the bounding box of the input is a hypercube (normalized in all dimensions).</p><p>The smallest dimension of all the eight dimensions of the bounding box is first computed. Then, a scale factor is computed for the each of the remaining seven dimensions. The resulting bounding box is scaled to a bounding cube with its eight dimensions are equal to the smallest dimension of the box. The scale factor for each dimension can therefore be different.</p><p>Note that scaling does not make the spanning axes of the epipolar space orthogonal. But, since the eight dimensions are already independent, the voting kernels should still be used over a wide applicable range of scale. Because of the scaling, the normal inferred at each inlier needs to be rescaled back to the original space before the estimated hyperplane normal and p QQ are computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multipass Refinement</head><p>To improve accuracy, we need to run several passes to filter the output from the previous pass. The set of classified inliers is progressively refined as more outliers are rejected in each pass. Typically, only four to five passes are needed and the refinement stops when the output inlier set is the same as the input. Since no multidimensional search is involved, a single pass is not very time-consuming. The flow of all the working pieces described in this paper is summarized in Algorithm 4.</p><p>It is interesting to note that the multipass tensor voting has some similarities with the Kalman filter, in the sense that we also perform a prediction-correction process, using the notion of covariance matrix. The Kalman filter estimates the state vector of a discrete-time controlled process governed by a linear stochastic difference equation <ref type="bibr" target="#b20">[21]</ref>. This estimation process uses a feedback control, which can be understood as a predictor-corrector algorithm, with a set of predictor and corrector equations to implement the projection and update measurement. It is well-known that the Extended Kalman Filter, needed in the nonlinear case, is difficult to implement, and suffers from issues such as convergence problems.</p><p>There are two important properties of our approach compared with the Kalman filter. First, we optimize a geometric measure, which is desirable since we are solving for a hyperplane, a geometric problem. Second, a nonlinear update is performed in the ªcorrectorº step, which allows us to reject outliers very efficiently. These properties are largely due to our voting fields: They encode geometric constraints rather than propagating algebraic ones. The geometric constraint we used is the continuity constraint, which is propagated along preferred directions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SPACE AND TIME COMPLEXITY</head><p>Except for tensorization, local densification, and extrema detection, other processes in Fig. <ref type="figure" target="#fig_2">2</ref> are clearly linear in time and space. Since we use an efficient data structure to store the input, and only local densification is performed, the space complexity of these three processes is also linear, or ym, where m is the input size.</p><p>The time complexity of local densification is only a constant factor of tensorization. The voting field alignment takes yI time since it is only a translation followed by a rotation. Therefore, the total time complexity for tensorization and local densification is ymk, where k is the size of the voting field.</p><p>For extrema detection, since there is only a finite number of detected zero crossings and configurations, the total time is ym.</p><p>Therefore, unlike the Hough Transform, the time and space complexities of the 8D voting are independent of the dimensionality. The actual running time for an input of 100 matches is approximately one minute on a Pentium II (450 MHz) processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>We demonstrate the general usefulness of our method on a variety of image pairs. In terms of the accuracy of the estimated parameters, we note that all the methods reported in <ref type="bibr" target="#b21">[22]</ref> (M-estimators, LMedS) fail on all of our set of input matches. This is the first quantitative evaluation. We provide a second measure on parameter accuracy in the form of ªdistanceº between the ªground truthº and our estimated fundamental matrices (in pixels). This distance measure is computed by randomly generating points in the images, and computing the mean distance between points and epipolar lines. We use the program Fdiff provided by Zhang <ref type="bibr" target="#b21">[22]</ref>. The ªground truthº is obtained by using either Zhang's implementation (in the case of aerial image pairs, we use the image pairs, not our noisy matches, as input), or the linear method by manually picked true correspondences. Table <ref type="table" target="#tab_6">2</ref> summarizes the results of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Aerial Image Pairs</head><p>In Pentagon (Fig. <ref type="figure" target="#fig_10">9</ref>) and Arena (Fig. <ref type="figure" target="#fig_11">10</ref>) experiments, we add a large number of wrong matches, by hypothesizing all pairs within 50 pixels of the correct matches in the corresponding images. We are still able to achieve a high correct percentage despite the large number of wrong matches. The resulting filtered matches are numbered in the corresponding images and a few corresponding epipolar lines are also drawn. In Gable (Fig. <ref type="figure" target="#fig_1">11</ref>), we have inlier to outlier ratio approximately equals to one, i.e., one match out of two is incorrect. The lighter crosses in Fig. <ref type="figure" target="#fig_1">11</ref> denote classified outliers. The darker crosses, alongside with corresponding matching numbers, indicate the filtered set of good matches. This resulting set of match is passed into the normalized Eight-Point Algorithm. A few corresponding epipolar lines are shown.</p><p>To understand the effect of outliers on the distribution of points in 8D in the above examples, and also on the robustness on our 8D hyperplane extraction, let us visualize   the 2D and 3D counterparts, Fig. <ref type="figure" target="#fig_12">12</ref>. In the 2D scenario, we have a set of 130 points x i Y y i sampled on a straight line, with 260 noises x i Y y j Y i T j, and j is randomly generated. Thus, it simulates wrong matches we produced above for Pentagon and Arena, and allows us to visualize the resulting noisy point distribution in a lower-dimensional space. In 3D, we have 653 points x i Y y i Y z i sampled on a plane (Rx Qy Sz À P H). A total of 1,306 incorrect data points are added, with coordinates x i Y y i Y z j , where i T j, and j is also randomly generated. To make this 3D experiment more challenging, we scale the z by a factor of two, making the grid nonisotropic. Note the interesting observation: Given the same inlier to outlier ratio, noise robustness increases with dimensions. This is due to the nonlinearity in the update step of the tensor voting process, in which the continuity constraint has more dimensions to propagate in the preferred directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Image Pair with Widely Different Views</head><p>In the House pair (courtesy of A. Zisserman), Fig. <ref type="figure" target="#fig_3">13</ref>, two very disparate views of the same static scene are taken. We manually pick only 16 correct matches and then add 32 wrong matches randomly. Our method rejects all outliers and produce the accurate epipolar geometry. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Image Pairs with Nonstatic Scenes</head><p>In the presence of moving objects, image registration becomes a more challenging problem, as the matching and registration phases become interdependent. Most researchers assume a homographic model between images, and detect motion by residual, or more than two frames are used. Torr and Murray <ref type="bibr" target="#b17">[18]</ref> use epipolar geometry to detect independent motion. We propose to perform true epipolar geometry estimation for nonstatic scenes by using tensor voting.</p><p>Two image pairs, Game-1 (Fig. <ref type="figure" target="#fig_13">14</ref>) and Game-2 (Fig. <ref type="figure" target="#fig_14">15</ref>), of a nonstatic basketball game scene are taken. The background of both image pairs is a 3D static indoor stadium. There is a lot of independent motion due to moving players. This produces many incorrect matches to the already noisy set of matches as given by cross correlation technique. In Game-2, we have some additional false matches on moving players. Since our method is designed to detect a salient hyperplane (contributed by the 3D background) from a noisy 8D cluster, and, in this case, the outliers are caused by nonstationary agents and their shadows cast on the floor, we should be able to pull out this hyperplane containing the inlier matches. The results of our experiments show that we can indeed discard such wrong matches, retain true matches coming from the static background, stationary players, and the audience. Therefore, we believe that our approach can extract multiple motions, mainly egomotion or possibly motion of large scene objects from an image pair, which is the subject of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>In this paper, we have generalized the tensor voting formalism into any dimensions and described a novel approach to address the problem of outlier detection and removal, in the context of epipolar geometry estimation. The epipolar geometry estimation problem is posed as an 8D hyperplane inference problem. Our method is more efficient than the Hough Transform in high dimensions. The computation and the subsequent use of hyperplane saliency and extremal property in the spatial domain (versus parameter domain for orientation) are novel and effective and are completely different from the Hough Transform. Since the methodology avoids searching in the parameter space, it is free of the problems of local optima and poor  iterative convergence. Our approach is initialization free (i.e., no initial fundamental matrix guess is needed). The pinhole camera model is the only assumption we make. No other simplifying assumption is made about the scene being analyzed. By using an adequate data structure, higher dimensionality translates into a constant factor in processing time. The future work of this research will, in addition to the application of multimotion analysis mentioned in Section 6.3, focus on the investigation of quantization effect, scale of analysis, and other problem domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Epipolar geometry.</figDesc><graphic coords="2,325.53,69.17,178.47,149.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The eight-dimensional tensor voting approach to the epipolar estimation problem.</figDesc><graphic coords="3,75.46,69.17,152.50,217.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. (a) Vote for tangent at h, (b) each site returns the most probable tangent direction after communicating with each other using the fundamental stick field, and (c) no maxima is detected when there is no direction preference.</figDesc><graphic coords="4,31.58,564.83,503.32,170.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>equivalent 2 Â</head><label>2</label><figDesc>2 eigensystem, with its two unit eigenvectors e I and e P and the two corresponding eigenvalues ! I ! ! P : ! I À ! P ! P fY Q where e I e I defines a stick tensor, and f e I e I e P e P defines a ball tensor, in 2D. Note that these tensors define the two basis tensors for any 2D ellipse.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. A second order symmetric 2D tensor.</figDesc><graphic coords="5,29.14,69.17,245.14,69.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>.</head><label></label><figDesc>! P corresponds to 2D junction saliency, with total uncertainty in orientation as indicated by the ball tensor, or e I e I e P e P . In N-D, we have similar geometric interpretation: The eigenvectors effectively encode orientation (un)certainties: A normal to a hypersurface is described by the stick tensor, which indicates certainty along a single, N-D direction. Orientation uncertainty is indicated by the ball tensor, where many intersecting hypersurfaces are present and, thus, no single orientation is preferred. The eigenvalues encode the magnitudes of orientation (un)certainties:. ! I À ! P corresponds to N-D hypersurface saliency, with e I e I indicating the normal direction, . for P i `x, ! i À ! iI , and i jI e j e j correspond to orientation uncertainty in i directions, which actually defines a x À iEh feature whose direction(s) are given by e iI Y Á Á Á Y e x . For example, given x QY i P, ! P À ! Q e I e I e P e P defines a plate tensor in 3D, which describes a 1D feature, a curve element, with tangent direction given by e Q . Here, the normal orientation uncertainty only spans a plane perpendicular to e Q , indicated by a plate tensor defined as to N-D hyperjunction saliency, with the N-D ball tensor specifying total orientation uncertainty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The design of fundamental 2D stick voting field.</figDesc><graphic coords="6,298.66,69.17,232.16,72.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. N-D surface extremality. (a) An N-D normal (with an imaginary patch drawn), (b) saliency along normal, and (c) the derivative.</figDesc><graphic coords="9,101.37,69.17,363.80,93.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Local densification in 2D. (a) Vote casting densifies everywhere; in vote gathering, we compute (b) a slab of votes only, or even perform (c) local densification.</figDesc><graphic coords="10,138.78,69.17,288.91,105.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Pentagon.</figDesc><graphic coords="13,59.70,313.34,447.02,188.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Arena.</figDesc><graphic coords="13,59.70,525.20,447.02,219.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The effect of manually added outliers on the distribution of points, in 2D and 3D. (a) Original set of 2D points, (b) noisy point set, (c) noise is attenuated after tensor voting, (d) the 2D curve saliency, (e) a noisy point cluster in 3D, (f) most noise is removed after tensor voting, and (g) the extracted planar surface.</figDesc><graphic coords="14,102.22,69.17,362.04,237.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Game-1.</figDesc><graphic coords="15,60.09,69.17,446.29,219.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Game-2.</figDesc><graphic coords="15,48.30,591.82,469.81,141.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="12,32.26,99.78,502.02,104.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc>Generalization of 2D Tensor Voting to N-D</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>discrete algorithms on tensor voting which use discrete voting fields. C++ source codes are available at http://www.cs.ust.hk/~cktang. The voter makes use of GENTENSORVOTE (Algorithm 1) to cast a tensor vote to vote receiver (votee), by integrating contribution using a stick rotated about an eigenvector, Section 2.3.2. Stick votes generated by GENSTICKVOTE (Algorithm 2) are accumulated using COMBINE (Algorithm 3). An x Â x out ensor is the output. The votee thus receives a set of out ensor from voters within its neighborhood. The resulting tensor matrices can be summed up by ADDTENSOR (not shown here), which performs ordinary x Â x matrix addition. These algorithms work for any dimension ! P. To increase efficiency, a dense voting field is precomputed once, by calling GENTENSORVOTE k x times, where k is the scale or size of the neighborhood. In particular, it is sufficient to use a 1D array of size k to store an x-D ball since an x-D ball is isotropic in all directions.</figDesc><table><row><cell>Algorithm 2 GENSTICKVOTE (dimension, voter, votee)</cell></row><row><cell>A stick vote (vector) is returned.</cell></row><row><cell>v 2 votee[position] À voter[position]</cell></row><row><cell>a Ã check if voter and votee are connected by high</cell></row><row><cell>curvature Ãa</cell></row><row><cell>if (angle(voter[direction],v) `%aR) then</cell></row><row><cell>return ZeroVector {smoothness constraint violated}</cell></row><row><cell>end if</cell></row><row><cell>a Ã voter and votee on a straight line, or voter and votee are</cell></row><row><cell>the same point Ãa</cell></row><row><cell>if (angle(voter[direction],v) %aP) or (voter votee) then</cell></row><row><cell>return voter[direction]</cell></row><row><cell>end if</cell></row><row><cell>Compute center and radius of the osculating N-dimensional</cell></row><row><cell>hemisphere</cell></row><row><cell>stickvote[direction] 2 center À voter[position] stickvote[length] 2 e s P &amp; P ' P {equation (5)}</cell></row><row><cell>stickvote[position] 2 votee[position]</cell></row><row><cell>return stickvote</cell></row><row><cell>Algorithm 3 COMBINE (dimension, tensorvote,</cell></row><row><cell>stickvote, weight)</cell></row><row><cell>It performs tensor addition, given a stick vote.</cell></row><row><cell>iI ]</cell></row><row><cell>voterSaliency[dimension-1] 2 voter[! dimensionÀI ]</cell></row><row><cell>if (voterSaliency[0] b 0) then</cell></row><row><cell>vecVote 2 GENSTICKVOTE (dimension,voter,votee)</cell></row><row><cell>COMBINE (dimension,outTensor,vecVote)</cell></row><row><cell>end if</cell></row><row><cell>transformVoter 2 voter</cell></row><row><cell>for i I to dimension À I do</cell></row><row><cell>if (voterSaliency[i] b H) then</cell></row><row><cell>// count[i] is a sufficient number of samples uniformly</cell></row><row><cell>distributed on a unit i IEh sphere.</cell></row><row><cell>while (count[i] T 0) do</cell></row><row><cell>transformVoter[direction] 2 random[direction] 2</cell></row><row><cell>GENRANDOMUNIFORMPT()</cell></row><row><cell>if (i T dimensionÀ1) then</cell></row><row><cell>a Ã Compute the alignment matrix, except the</cell></row><row><cell>isotropic ball tensor Ãa</cell></row><row><cell>transformVoter[direction] 2</cell></row><row><cell>voter[eigenvectorMatrix] Â random[direction]</cell></row><row><cell>end if</cell></row><row><cell>vecVote 2 GENSTICKVOTE</cell></row><row><cell>(dimension,transformVoter,votee)</cell></row><row><cell>COMBINE (outTensor, vecVote, voterSaliency[i])</cell></row><row><cell>count[i] 2 count[i] À 1</cell></row><row><cell>end while</cell></row><row><cell>end if</cell></row><row><cell>end for</cell></row><row><cell>return outTensor</cell></row></table><note><p><p><p>2.4 Algorithms on N-Dimensional Tensor Voting</p>In Section 2.3.2, we give the continuous definitions for the stick, plate, and ball voting fields. In this section, we describe the Algorithm 1 GENTENSORVOTE (dimension,voter,votee) First, the stick component of a tensor vote is computed (if direction is given). Then, all other tensor components (plates and balls) are computed, by integrating the resulting stick votes cast by a rotating stick at the voter.</p>for all H iY j `dimension, outTensor[i][j] 2 0 for all H i `dimension À I, voterSaliency[i] 2 voter[! i À voter[!</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>IYj is obtained. That is, by using ADDTENSOR. Note that this tensor sum, IYj , is still symmetric and semipositive definite since IYj ,</figDesc><table><row><cell>Therefore, IYj</cell><cell>IYj</cell><cell>xÀI kP k IYj f</cell></row><row><cell cols="2">xÀI kP k</cell><cell></cell></row></table><note><p><p>Then, k IYj k HYj ! k À ! kI k . That is, by using ADDTENSOR.</p>. Ball vote. Let f be the ball vote, collected at site j, which is cast by voter i. Then, f IYj f HYj ! x f .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 2</head><label>2</label><figDesc>Summary of the Results on Epipolar Geometry Estimation</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 23, NO. 8, AUGUST 2001</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research is supported by the US National Science Foundation under grant no. 9811883 and the Research Grant Council under grant HKUST6246/00E. The authors would like to thank all the reviwers for their constructive comments that helped to improve the final manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ªSimplicial Pivoting for Mesh Generation of Implicitly Defined Surfaces</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Allgower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gnutzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Aided Geometric Design</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="325" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Ma</surname></persName>
		</author>
		<title level="m">ªRobust Fundamental Matrix Estimation from Uncalibrated Images,º Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="829" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rivest</surname></persName>
		</author>
		<title level="m">Introduction to Algorithms</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Ma</surname></persName>
		</author>
		<title level="m">ªRecovering Epipolar Geometry by Reactive Tabu Search,º Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="767" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Three-Dimensional Computer Vision: A Geometric Viewpoint</title>
		<author>
			<persName><forename type="first">O</forename><surname>Faugeras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªInference of Surfaces, 3D Curves and Junctions from Sparse, Noisy 3D Data</title>
		<imprint>
			<date type="published" when="1997-11">Nov. 1997</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1265" to="1277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ªMethods and Means for Recognizing Complex Patterns</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V C</forename><surname>Hough</surname></persName>
		</author>
		<idno>US Patent 3 069 654</idno>
		<imprint>
			<date type="published" when="1962-12">Dec. 1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ªIn Defense of the Eight-Point Algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="580" to="593" />
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">M.-S</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">ªTensor Voting for Salient Feature Inference in Computer Vision,º</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Southern California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ªA Computer Algorithm for Reconstructing a Scene from Two Projections</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Longuet-Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="133" to="135" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ªMarching Cubes: A High Resolution 3D Surface Reconstruction Algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A Computational Framework of Feature Extraction and Segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Elsevier Science</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<title level="m">ªThe Asymptotic Decider: Resolving the Ambiguity in Marching Cubes,º Proc. IEEE Visualization Conf</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Pritchett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<title level="m">ªWide Baseline Stereo Matching,º Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="754" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ªInference of Integrated Surface, Curve, and Junction Descriptions from Sparse, Noisy 3D Data</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1206" to="1223" />
			<date type="published" when="1998-11">Nov. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-S</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">ªEpipolar Geometry Estimation by Tensor Voting in 8D,º Proc. IEEE Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="502" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">ªTensor Voting for Feature Extraction, Integration, and Higher Dimensional Inference</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Univ. of Southern California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ªStatistical Detection of Independent Movement from a Moving Camera</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ªThe Development and Comparison of Robust Methods for Estimating the Fundamental Matrix,º Int</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="300" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Weigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Banks</surname></persName>
		</author>
		<title level="m">ªComplex-Valued Contour Meshing,º Proc. IEEE Visualization Conf</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="173" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">ªAn Introduction to the Kalman Filter</title>
		<author>
			<persName><forename type="first">G</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
		<idno>TR 95-041</idno>
		<ptr target="http://www.cs.unc.edu/~welch/kalman/kalman_filter/kalman.html" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ªDetermining the Epipolar Geometry and Its Uncertainty: A Review,º Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="195" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
