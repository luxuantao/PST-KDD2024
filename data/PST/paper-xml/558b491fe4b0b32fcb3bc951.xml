<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Electric and Information Engineering</orgName>
								<orgName type="institution">Zhongyuan University of Technology</orgName>
								<address>
									<postCode>450007</postCode>
									<settlement>Zhengzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical and Electronic En-gineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Electronics and Communication Sciences Unit</orgName>
								<orgName type="institution">In-dian Statistical Institute</orgName>
								<address>
									<postCode>700 108</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6CA5689C668EEFDD342344F37ECA1AEE</idno>
					<idno type="DOI">10.1109/TEVC.2012.2203138</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Multimodal optimization amounts to finding multiple global and local optima (as opposed to a single solution) of a function, so that the user can have a better knowledge about different optimal solutions in the search space and when needed, the current solution may be switched to a more suitable one while still maintaining the optimal system performance. Niching particle swarm optimizers (PSOs) have been widely used by the evolutionary computation community for solving real-parameter multimodal optimization problems. However, most of the existing PSO-based niching algorithms are difficult to use in practice because of their poor local search ability and requirement of prior knowledge to specify certain niching parameters. This paper has addressed these issues by proposing a distance-based locally informed particle swarm (LIPS) optimizer, which eliminates the need to specify any niching parameter and enhance the fine search ability of PSO. Instead of using the global best particle, LIPS uses several local bests to guide the search of each particle. LIPS can operate as a stable niching algorithm by using the information provided by its neighborhoods. The neighborhoods are estimated in terms of Euclidean distance. The algorithm is compared with a number of state-of-the-art evolutionary multimodal optimizers on 30 commonly used multimodal benchmark functions. The experimental results suggest that the proposed technique is able to provide statistically superior and more consistent performance over the existing niching algorithms on the test functions, without incurring any severe computational burdens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Terms-Evolutionary computation, multimodal evolutionary optimization algorithm, niching technique, particle swarm optimization (PSO).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>I N PRACTICAL optimization problems, it is often desirable to simultaneously locate multiple global and local optima of a given objective function. For real-world problems due to physical (and/or cost) constraints, the best results cannot always be realized. In such a scenario, if multiple solutions (local and global) are known, the implementation can be quickly switched to another solution while still maintaining an optimal system performance. Multiple solutions could also be analyzed to discover hidden properties (or relationships) of the concerned functional landscape. Thus, as the name suggests, a multimodal optimization task amounts to finding multiple optimal solutions and not just one single optimum, as it is done in a typical optimization study. If a point-by-point classical optimization approach is used for this task, the approach must be applied several times, every time hoping to find a different optimal solution.</p><p>Evolutionary algorithms (EAs) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, due to their population-based approach, provide a natural advantage over classical optimization techniques. They maintain a population of possible solutions, which are processed at every iteration, and if the multiple solutions can be preserved over all these iterations, then at termination of the algorithm we can have multiple good solutions, rather than only the best solution. Note that this is against the natural tendency of EAs, which will always tend to converge to the best solution or a suboptimal solution (in a rugged, not so well-posed function). Detection and maintenance of multiple solutions are two challenging tasks of using EAs to solve multimodal optimization problems.</p><p>Niching <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b6">[7]</ref> refers to the technique of finding and preserving multiple stable niches, or favorable parts of the solution space possibly around multiple solutions, with a view of preventing convergence to a single solution. A niching method generally modifies the behavior of a classical EA in order to maintain multiple groups within a single population to locate different optima. Many niching methods have been developed over the years, including crowding <ref type="bibr" target="#b7">[8]</ref>, fitness sharing <ref type="bibr" target="#b8">[9]</ref>, restricted tournament selection (RTS) <ref type="bibr" target="#b9">[10]</ref>, and speciation <ref type="bibr" target="#b10">[11]</ref>. Some of the classic niching techniques are presented in the next sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Crowding</head><p>Crowding <ref type="bibr" target="#b7">[8]</ref> is one of the simplest and most commonly used niching techniques. It is inspired by the competition for limited resources among similar members of a natural population. The similarity is generally measured in terms of distance and one of the most common choices is the Euclidian distance. The crowding method is able to maintain the diversity of the whole population. The algorithm compares the offspring with some randomly sampled individuals from the current population. This approach requires a user-specified parameter called crowding factor (CF) to control the size of the sample. CF is generally chosen to be 2 or 3. The main 1089-778X/$31.00 c 2012 IEEE merit of crowding is its simplicity. However, it suffers from the replacement error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Restricted Tournament Selection</head><p>RTS was originally introduced by Harik <ref type="bibr" target="#b9">[10]</ref>. The concept is similar to crowding. RTS generates two offspring by applying crossover and mutation operators on two randomly selected parents from the current population. Then the method chooses a random sample of w (window size) individuals from the population and determines which one is the closest to the offspring. The closest member within the w individuals will compete with the offspring to determine the population for the next iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Fitness Sharing</head><p>Fitness sharing is another effective multimodal optimization technique <ref type="bibr" target="#b8">[9]</ref>. In fitness sharing, the population is divided into different subgroups according to the similarity of the individuals. Individuals share their information within the same subgroup. The shared fitness for ith individual can be represented by using the following equation:</p><formula xml:id="formula_0">f shared (i) = f original (i) N j=1 sh(d ij )</formula><p>where the sharing function is calculated using</p><formula xml:id="formula_1">sh(d ij ) = 1 - d ij σ share α , if d ij &lt; σ share 0, otherwise</formula><p>where d ij is the distance between individuals i and j, σ share is the sharing radius, N is the population size, and α is a constant called sharing level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Speciation</head><p>Speciation <ref type="bibr" target="#b10">[11]</ref> is based on the concept of separating the population into several species according to their similarity. Each of these species is formed around a dominating individual known as the species seed. The range of the species is controlled by a user-specified value called radius r s . All individuals that fall within the radius from the species seed are identified as the same species.</p><p>The concept of particle swarms, although initially introduced for simulating the social behavior commonly observed in the animal kingdom, has become very popular as an efficient algorithm for intelligent search and optimization. Particle swarm optimization (PSO) <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b14">[15]</ref>, as it is called now, does not require any gradient information of the function to be optimized, uses only primitive mathematical operators, and is conceptually very simple. A few significant variants of PSO that have been used very effectively for solving various kinds of optimization problems can be found in <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b19">[20]</ref>.</p><p>The relative simplicity of PSO and the fact that it is a population-based technique has made it a natural candidate for solving multimodal optimization problems. Fitness Euclideandistance ratio PSO (FERPSO) <ref type="bibr" target="#b20">[21]</ref> and speciation-based PSO (SPSO) <ref type="bibr" target="#b21">[22]</ref> are two commonly used and effective niching PSO algorithms. Recently, a ring topology PSO <ref type="bibr" target="#b22">[23]</ref> has been used to overcome the niching parameter selection problem and solve multimodal problems. In this paper, a locally informed particle swarm (LIPS) optimizer algorithm is introduced to enhance local search ability and solve multimodal functions. Effectiveness of the proposed algorithm has been demonstrated by comparing its performance with nine other state-of-the-art multimodal optimizers over a test suite comprised of 15 basic and 15 composite multimodal benchmarks.</p><p>The remainder of this paper is organized in the following way. Section II gives a brief overview of the PSO algorithm, the niching techniques previously used along with PSO, and some other significant niching algorithms used in the comparative study undertaken here. In Section III, the LIPS algorithm is presented in sufficient detail. The problem definition and experimental results are presented and discussed in Sections IV and V, respectively. Finally, the paper concludes with Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Scientific Background and Related Works A. Particle Swarm Optimization</head><p>PSO is a search technique that was originally introduced by Kennedy and Eberhart <ref type="bibr" target="#b12">[13]</ref>. It has been shown to be effective in solving optimization problems <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>. PSO emulates the group behavior of insects, birds flocking, and fish schooling, where these swarms search for food in a collective manner <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b33">[34]</ref>. In PSO dynamics, a swarm of particles (or agents), each representing a potential solution to the optimization problem at hand, navigates through the search space. The particles are initially distributed randomly over the feasible search space with a random velocity, and the goal is to converge to the global optimum of an objective function. Each particle keeps track of the best solution that it has achieved so far. This is the personal best value (the so-called pbest <ref type="bibr" target="#b13">[14]</ref>). In addition, the PSO process also keeps track of the global best solution detected so far in a neighborhood of the current particle or in the entire swarm (the so-called gbest <ref type="bibr" target="#b13">[14]</ref>). Thus, the velocity of each agent in the next iteration is computed by using the information of the gbest (as the social component), the best personal position of the particle pbest (as the cognitive component), and its current velocity (the memory term). Both social and cognitive components contribute randomly to the position of the agent in the next iteration.</p><p>The position X and velocity V of each particle are updated according to the following formulae:</p><formula xml:id="formula_2">V d i = ω * V d i + c 1 * rand1 d i * (pbest d i -X d i ) +c 2 * rand2 d i * (gbest d -x d i )<label>(1)</label></formula><formula xml:id="formula_3">X d i = X d i + V d i (2)</formula><p>where c 1 and c 2 are the acceleration constants and ω is the inertia weight to balance the global and local search performance. rand1 d i and rand2 d i are two random numbers within the range of [0, 1]. pbest i is the best previous position yielding the best fitness value for the ith particle while gbest i is the best position found by the entire swarm or some neighborhoods of the ith particle. Fig. <ref type="figure" target="#fig_0">1</ref> presents a typical flow chart of the conventional PSO. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Adapting PSO for Multimodal Optimization</head><p>For years, PSO has remained a favorite choice of researchers working on multimodal optimization problems. Parsopoulos et al. <ref type="bibr" target="#b23">[24]</ref> used the objective function stretching as a sequential PSO niching technique, similar to that of Beasley et al. <ref type="bibr" target="#b24">[25]</ref>. Once the PSO algorithm has identified a local maximum f (X * ) (through comparing particle objective function values to a minimum threshold value), the objective function is stretched such that for each point X in the search space, if f (X) &gt; f(X * ), the point remains unaltered. But all other points, for which f (X) ≤ f (X * ) holds, are stretched so that X * becomes a local minimum. All particles are then repositioned randomly. Thus, a potentially good solution is isolated once it is found and then the fitness landscape is stretched to keep other particles away from this area of the search space <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. In 2002, Brits et al. <ref type="bibr" target="#b27">[28]</ref> proposed NichePSO, where multiple subswarms are grown from an initial swarm by monitoring the fitness of individual particles. The subswarms can merge together or absorb particles from the main swarm. NichePSO tracks the variance of a particle over iterations by monitoring its fitness. If the change in a particle's fitness over iterations is not very high, a subswarm is created with the particle's closest neighbor. The success of NichePSO depends on the proper initial distribution of particles throughout the search space. To ensure uniform distribution, Faure sequences <ref type="bibr" target="#b19">[20]</ref> are used to initialize particle positions in the search space. The main swarm is trained using the cognition-only model <ref type="bibr" target="#b30">[31]</ref> shown as</p><formula xml:id="formula_4">V d i = ω * V d i + c 1 * rand1 d i * (pbest d i -X d i ).<label>(3)</label></formula><p>In this model, only a conscience factor, in the form of a personal best, is considered when updating particle positions. Therefore, no social information in the form of a global best solution will influence position updates. In <ref type="bibr" target="#b32">[33]</ref>, Brits et al.</p><p>proposed an nbest PSO model, where the neighborhood best of a particle is determined by taking the average of the positions of all particles in its neighborhood. Based on the Euclidean distance among the particles, the neighborhood of a particle In what follows, we discuss a few other significant niching PSOs that have been used in the comparative study undertaken in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Fitness Euclidean-Distance Ratio PSO (FERPSO):</head><p>In FERPSO <ref type="bibr" target="#b20">[21]</ref>, instead of global best, the neighborhood best to each particle is used to lead the particles. Consequently, a solution moves toward its personal best as well as its fittestand-closest neighbors (nbest), which are identified by the fitness-Euclidean distance ratio (FER) values. The nbest for ith particle is selected as the neighborhood personal best with the largest FER as follows:</p><formula xml:id="formula_5">FER (j,i) = α • f (p j ) -f (p i ) p j -p i (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where α = s f (p g )-f (p w ) is a scaling factor, p w is the worst-fit particle in the current population, p j and p i are the personal bests of the jth and ith particle, respectively, and s is the size of the search space, which is estimated by its diagonal 2 (where x u k and x l k are the upper and lower bounds of the kth dimension of the search space). The velocity update equation ( <ref type="formula" target="#formula_2">1</ref>) in FERPSO is rewritten as</p><formula xml:id="formula_7">distance d k=1 (x u k -x l k )</formula><formula xml:id="formula_8">V d i = ω * V d i + c 1 * rand1 d i * (pbest d i -X d i ) +c 2 * rand2 d i * (nbest d -x d i ).</formula><p>(5)</p><p>2) Speciation-Based PSO (SPSO): SPSO was first proposed by Li <ref type="bibr" target="#b21">[22]</ref> in 2004. In SPSO, different subpopulations are formed as species, which are identified by the dominant particles known as the species seeds. To identify the species seeds and determine the size of species, a niching parameter known as radius must be specified by the user. The procedure for determining species and the species seeds was adopted from <ref type="bibr" target="#b34">[35]</ref>. Each species and its corresponding species seed form a separate subpopulation that can be optimized with a PSO itself. Similar to FERPSO, SPSO replaces the global best Algorithm 2 Steps of SDE by species best or species seed and all the particles in the same species at each iteration step share the same neighborhood best. Over successive iterations, multiple global optima can be found in parallel.</p><p>3) Ring Topology PSO: Recently, Li <ref type="bibr" target="#b22">[23]</ref> proposed an lbest PSO with ring topology for niching. In ring topology PSO, each particle interacts only with its immediate neighbors. The algorithm makes use of ring topology to form different niches and realize multiple-peaks optimization, which does not require any niching parameters. Li showed that PSO algorithms using the ring topology were able to form stable niches across different local neighborhoods, eventually locating multiple global or local optima. The implementation of ring topology PSO is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Other Niching Algorithms Compared in this Paper</head><p>This section presents brief overviews of three state-ofthe-art multimodal algorithms (non-PSO based) compared in this paper. These algorithms are commonly used to exhibit competitive performances in multimodal optimization.</p><p>1) Species-Based Differential Evolution: Species-based differential evolution (SDE) <ref type="bibr" target="#b35">[36]</ref> presents a commonly used niching algorithm incorporated in the framework of differential evolution (DE), a very powerful real parameter optimizer <ref type="bibr" target="#b36">[37]</ref>. The concept is the same as SPSO described in Section II-B2. The steps of SDE are presented in Algorithm 2.</p><p>2) Crowding Differential Evolution: Crowding differential evolution (CDE) was first proposed by Thomsen <ref type="bibr" target="#b7">[8]</ref>. In CDE, when an offspring is generated, it competes with the individual most similar to it (measured by Euclidean distance) in the current population. The offspring will replace this individual if it has a better fitness value. The steps of CDE are provided in Algorithm 3.</p><p>3) Adaptive Niche Radii Covariance Matrix Adaptation Evolution Strategy: Evolution strategies <ref type="bibr" target="#b37">[38]</ref> are search procedures that mimic the natural evolution of the species in natural ecosystems. In <ref type="bibr" target="#b38">[39]</ref>, Shir et al. introduced an adaptive niche radii covariance matrix adaptation evolution strategy (CMA-ES) to solve multimodal problems. The algorithms solve the problem of selecting a suitable niching radius and offer an efficient niching mechanism with less presumption on the search landscape. This is successfully achieved at two levels: the construction of the self-adaptive niche radius and the application of the Mahalanobis distance metric for the adaptation of the niche shapes. The details of the algorithm can be found in <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Locally Informed PSO A. Fully Informed Particle Swarm</head><p>In 2004, Mendes et al. <ref type="bibr" target="#b39">[40]</ref> introduced a fully informed particle swarm (FIPS) to solve single global optimization problems. The classical particle swarm algorithm works by continuously searching in a region that is defined by each particle's best previous success, the best success of one neighborhood particle, the particle's current position, and its previous velocity <ref type="bibr" target="#b39">[40]</ref>. The particle uses only one neighborhood best information to bias its search direction. However, there is no guarantee that the chosen neighborhood best will always lead to solutions better than other neighborhoods' bests. Important information contained in neighborhood particles may be neglected through overemphasis on the single best neighbor, which may lead to poor local search or slower convergence.</p><p>Unlike the canonical PSO, FIPS makes use of the information from all other particles around it, which is conceptually more concise and promises to perform better than the traditional particle swarm algorithm. In the FIPS, all neighbors are a source of influence in leading the particles to fly. Therefore, how to select the neighbors determines how diverse the influence will be and how efficient the algorithm will be. In <ref type="bibr" target="#b39">[40]</ref>, FIPS is integrated with five different PSO social networks and shows very promising performance in solving single global peak optimization problem. The five topologies are known as all, ring, four clusters, pyramid, and square, which are depicted in Fig. <ref type="figure" target="#fig_10">2</ref>  <ref type="bibr" target="#b39">[40]</ref>. The behavior of each particle is affected by its neighborhood identified by the topology used, which is able to make the whole population converge fast and more accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Distance-Based Locally Informed Particle Swarm</head><p>Although FIPS is proven to be very effective in solving single-objective global optimization problems, it is not suitable for multimodal optimization due to the topology-based neighborhood selection method. As can be easily revealed, all the particles and their neighborhood are likely to converge to one point for single modal or single global peak optimization. However, for multimodal case, multiple peaks need to be located simultaneously and these peaks can be far from each other. Thus, if the topological neighborhood selection is used, the neighbors are likely to form from different areas or different niches. Take ring topology as an example; the particle is only allowed to interact with its immediate neighbors on its left and right according to the particle indices. The possibility for these neighbors to belong to different niches is very high as the initial population is randomly generated. If the neighbors are not from the same niche targeting a single peak, it is difficult for the niching algorithm to converge and locate the peaks effectively.</p><p>Motivated by this observation, a distance-based LIPS optimizer is presented in this paper. Similar to FIPS, besides using its personal best, LIPS adopts the local information from its nearest neighborhood (measured in terms of Euclidean distance) to guide the search of the particles. In this way, LIPS can form different stable niches that can converge to different global peaks. Fig. <ref type="figure" target="#fig_2">3</ref> highlights the benefits of Euclidean distance-based neighborhood over the topological neighborhood. In Fig. <ref type="figure" target="#fig_2">3</ref>, there are five global optima that need to be located (F1: equal maxima <ref type="bibr" target="#b41">[42]</ref>). The dots represent the particles of current population. The dashed lines connect topological neighbors according to particle indices. It cannot be avoided that some particles must have topological neighbors from different niches. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, if two particles are from different niches, they may oscillate between two peaks that waste the function evaluations. Oscillation between Algorithm 4 Steps of local search two niches is unfavorable for exploration and exploitation. During the exploration stage (early search stage), particles are confined to locate additional niches that are positioned between two previously identified niches due to the oscillation. However, if there is no niche between two previously identified niches, oscillation wastes function evaluations. In contrast, the initial particles generated by the Euclidean distance-based neighborhood are well distributed over the whole search space and it facilitates the exploration process to be unrestricted. Hence, the proposed LIPS is more likely to perform exploration of the whole search space more freely than topological neighborhood-based PSO. During the exploitation stage (late search stage), oscillation in the topological neighborhoodbased niching PSOs makes it hard to improve the accuracy while the proposed LIPS is able to perform search within each Euclidean distance-based neighborhood without any interference from other niche. Hence, LIPS is highly effective for fine search and thereby successfully locates the desired peaks with high accuracy.</p><p>The velocity update of LIPS uses the formula given below while the position update keeps unchanged [40]</p><formula xml:id="formula_9">V d i = ω × (V d i + ϕ(P d i -X d i ))<label>(6)</label></formula><p>where</p><formula xml:id="formula_10">P i = nsize j=1 (ϕ j • nbest j )/nsize ϕ .</formula><p>ϕ j is a uniformly distributed random number in the range of [0, 4.1/nsize] and ϕ is equal to the summation of ϕ j . nbestj is the jth nearest neighborhood to ith particle's pbest. nsize is the neighborhood size, the impact of which will be discussed in sufficient detail in Section V. In this paper, nsize is dynamically increased from 2 to 5 over the function evaluations. There are two main advantages of LIPS to solve multimodal optimization problems as follows: 1) the benefit of FIPS velocity update equation to ensure good usage of all neighborhood information especially during the later stages of the search process and this leads to fast convergence and a high accuracy; 2) Euclidean distance-based neighborhood selection to ensure the neighbors are from the same niche and this increases the algorithm's ability for local search and fine-tuning. With these two advantages, LIPS can easily find most of the peaks and maintain them until the end of the predefined budget </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setting</head><p>All the algorithms are implemented using MATLAB 7.1 and executed on the computer with an Intel Pentium 4 CPU and 2 GB of memory. The operating system is Microsoft Windows XP. The PSO and CMA-ES parameters used in this paper are adopted from <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b38">[39]</ref>, respectively, while the DE parameters are F = 0.9 and CR = 0.1. In total, 10 different multimodal algorithms are examined through our experiments.</p><p>1) LIPS: the locally informed PSO; 2) r2pso <ref type="bibr" target="#b22">[23]</ref>: an lbest PSO with a ring topology; each member interacts with only its immediate member to its right; 3) r3pso <ref type="bibr" target="#b22">[23]</ref>: an lbest PSO with a ring topology; each member interacts with its immediate member on its left and right; 4) r2pso-lhc <ref type="bibr" target="#b22">[23]</ref>: same as r2pso, but with no overlapping neighborhoods; 5) r3pso-lhc <ref type="bibr" target="#b22">[23]</ref>: same as r3pso, but with no overlapping neighborhoods; 6) SPSO <ref type="bibr" target="#b21">[22]</ref>: speciation-based PSO; 7) FERPSO <ref type="bibr" target="#b20">[21]</ref>: fitness-Euclidean distance ratio PSO; 8) SDE <ref type="bibr" target="#b35">[36]</ref>: speciation-based DE; 9) CDE <ref type="bibr" target="#b7">[8]</ref>: the original crowding DE; 10) SCMA-ES <ref type="bibr" target="#b21">[22]</ref>: self-adaptive niching CMA-ES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Test Functions</head><p>In experiment one, 30 benchmark multimodal test functions are used. These functions can be divided into two parts. The   <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>) 0 ( <ref type="formula">7</ref>  <ref type="formula" target="#formula_4">3</ref>) 0 (7.5) 0 (7.5) 0 (7.5) 0 (7.5) 0 (7.5) F15</p><p>1 (1) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref>) 0 ( <ref type="formula" target="#formula_9">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Population Size and Maximal Number of Evaluations</head><p>In this experiment, a level of accuracy (typically 0&lt;ε&lt;1), indicating how close the computed solutions to the known global peaks are, needs to be specified in order to compare different algorithms. If the difference from a computed solution to a known global optimum is below ε, then the peak is considered to have been found. The level of accuracy (ε), niching radius (r), population size, and maximal number of function evaluations allowed are listed in Table <ref type="table" target="#tab_2">II</ref> (these settings apply to all compared algorithms). Generally, population size and maximal number of function evaluations are related to the number of optima to be located. Large number of optima requires a larger population size and more function evaluations. Note that the performance measure of each algorithm depends on the specified level of accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performance Measure</head><p>To compare the performance of different multimodal optimizers, 25 independent runs of each of the algorithms are taken on each problem. The performance of all multimodal algorithms is measured in terms of the following two criteria:</p><p>1) success rate (the percentage of runs in which all the global peaks are successfully located); 2) peak ratio <ref type="bibr" target="#b7">[8]</ref> (the percentage of successfully located peaks). Note that for more challenging functions with a tight level of accuracy, if all peaks cannot be found even in a single run, then the corresponding success rate will become zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Experimental Results</head><p>This section presents and duly discusses the experimental results of our comparative study. All algorithms were run until all known peaks were found or the maximum number of function evaluations was exhausted. In Section V-E, the effect of the neighborhood size of LIPS is also discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Success Rate</head><p>The success rates for all the algorithms on test functions F1-F15 are recorded and presented in Table <ref type="table" target="#tab_3">III</ref>. The ranks of each algorithm are shown in parentheses while the total ranks (summation of all the individual ranks) are listed in the last row of the table. As can been seen from this table, LIPS achieves a much higher success rate than other niching algorithms on most of these 15 test functions. It also ranks the best if compared to the overall performance (total rank). The better performance is due to the better fine search generated by the locally informed particles. As LIPS selects several distancebased neighbors, the search can be easily localized with respect to each niche during the later stages of search. Local neighborhood concept is also able to form stable niches around different peaks, which is suitable for multimodal optimization.</p><p>Test functions F16-F30 are much more complex than functions F1-F15. For these test problems, no algorithm is able to generate a nonzero success rate. Therefore, peak ratio is used as the sole criterion and presented in Section V-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Peak Ratio</head><p>Peak ratio is another important criterion for comparing different niching algorithms. The results for test functions F1-F30 are shown in Tables <ref type="table" target="#tab_6">IV</ref> and<ref type="table">V</ref>. The best algorithm is highlighted in boldface for each test function. As can be seen, LIPS performs the best on the test functions, especially on F16-F30. As explained earlier, these functions are more challenging functions that require a fast (high convergence speed) and accuracy (good fine-tuning ability) from the optimization algorithm. For topological neighbor-based PSO (such as r2pso), their convergence speed and fine-tuning ability are adversely affected by topological neighborhood property. Although they can roughly find certain niches, they are not able to bring down the accuracy to a required level. Again this is due to the oscillation problem caused by their topological neighborhood. For LIPS, the distance-based neighborhood ensures a high diversity and high-speed search process for these multimodal problems. Especially at late search stage,  once the particles are crowded around different niches, LIPS performs the search within each niche independently. This greatly improves the fine-tuning ability of LIPS. In order to determine the statistical significance of the advantage of LIPS, t-test (all compared with LIPS) is applied and shown in the last row of each test function. The numerical values 1, 0 represent that other methods are statistically inferior to or equal to the proposed algorithm. The last three rows of both tables summarize how many cases that LIPS perform better, similar, or worse than other algorithms. From the results, we can observe that LIPS always perform better or equal when compared with other niching methods on all test functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance on High-Dimensional Problems (20-D and 30-D)</head><p>To test the performance of proposed algorithm on highdimensional problems, 20-D and 30-D composition functions (F16-F20) are used. All the experimental settings are the same as 10-D composition functions. The results are presented in Table IV. Unlike FERPSO, SDE, and CDE, the performances of LIPS and SACMA-ES only drop slightly when the dimension increases. LIPS still performs the best out of all 10 compared algorithms. From these results, we can conclude that LIPS is able to generate stable performance over a wide variety of test functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Advantage of Distance-Based Neighborhood</head><p>To show the advantage of distance-based neighborhood over topological neighborhood, LIPS is compared with r2pso on F5 Himmelblau's function. The distributions of pbests of both algorithms in different iterations are plotted in Fig. <ref type="figure" target="#fig_4">4</ref>. As we can see from the plots, LIPS converges much faster than r2pso, especially at later stage. For r2pso, the distributions of pbests from iteration 100 to iteration 200 do not change much, which means that many function evaluations are wasted due to the problem mentioned in Section III-B. In contrast, LIPS uses the information of the closest neighbors that are likely to target on the same peak. This search mechanism is able to increase the convergence speed and accuracy simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Effect of Neighborhood Size</head><p>The performance of the proposed LIPS depends on the neighborhood size. A smaller neighborhood size will generate a better diversity for the population while a larger neighborhood size is good for convergence. Table <ref type="table">V</ref> shows the performances on test F11 and F16 with the neighborhood varied from 2 to 5. For test F11, the average number of optima obtained drops as the neighborhood size increases. This is because the number of global optima for F11 is high. Although a large neighborhood size increases the convergence, it decreases the diversity and misses some of the peaks. On the other hand, F16 is composite function and finding one peak is already challenging. Therefore, the convergence is more important than diversity. How to choose the neighborhood size depends on the users need. If the target is diversity, a smaller neighborhood size should be used or otherwise a larger neighborhood size should be selected. In this paper, a  dynamic neighborhood size is used. The neighborhood size is linearly increased from 2 to 5 over the function evaluations. In order to show the effect of neighborhood size more clearly, the convergence graph and distance to optima over function evaluations on F16 are shown in Figs. <ref type="figure" target="#fig_5">5</ref> and<ref type="figure" target="#fig_6">6</ref>. From the convergence graph we can see that a larger neighborhood size generates a higher average fitness value of the population while a smaller neighborhood size generates small summation of distance to all peaks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Maintaining Optima Once Found</head><p>As stated by Mahoud <ref type="bibr" target="#b2">[3]</ref>, a good niching algorithm must be able to locate global optima and maintain them for an exponential to infinite time period, with respect to population size. Maintaining found optima is important for an effective and stable multimodal optimization algorithm. LIPS is able to find and maintain the found optima until the end of the run. This is because the proposed algorithm uses neighborhood information to execute local search. Once a niche is formed around one global peak, the algorithm will continue to search better solutions within the same niche. Only when a better solution is found within the niche, it replaces the current personal best that can maintain the found peak until the end of the run. Fig. <ref type="figure" target="#fig_7">7</ref> shows the niching behavior of LIPS on F1. From the figure we can see that LIPS is able to develop stable niches around the global peaks.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Effect of Varying Level of Accuracy</head><p>The parameter ε (level of accuracy) can affect the results of the algorithm greatly. To demonstrate the effect of varying level of accuracy, the plot (Fig. <ref type="figure" target="#fig_8">8</ref>) on level of accuracy versus success rate is generated based on test function F5 (Himmelblau's function) and F13 (Michalewicz function). From the plot we can observe that the success rate drops when the level of accuracy is increased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Comparison With Results</head><p>Reported in <ref type="bibr" target="#b46">[47]</ref> In order to further demonstrate the superior performance of LIPS, it was compared with the results reported in one of the latest multimodal optimization works <ref type="bibr" target="#b46">[47]</ref>. The test function, parameter settings, and results of the other compared algorithms are directly taken from <ref type="bibr" target="#b46">[47]</ref>. The assessment criteria are also adopted from <ref type="bibr" target="#b46">[47]</ref>, which are listed as follows. 1) Peak accuracy: For each desired peak to be located, the closest individual X in the population is taken and absolute difference in objective values is calculated. If the objective value of individual X is denoted by f (X), the peak accuracy is calculated using the following equation:</p><p>peak accuracy = # peaks i=1 f (peak i )f (X) . (Euclidean distance between peak i and individual X).</p><p>The performance results are shown in Tables VIII and IX. Fig. <ref type="figure" target="#fig_9">9</ref> enables a clear visual comparison for the peak accuracies of every function over all algorithms. From the results we can observe that LIPS performs the best out of the seven compared algorithms, especially on test functions E8-E11. The ranks of each algorithm are shown in the bracket while the results for the best algorithm are highlighted in boldface. For test function E7, dynamic fitness sharing (DFS) algorithm ranks the best in terms of peak accuracy and ranks the last in terms of distance accuracy. This is due to the peak accuracy error mentioned above, as DFS totally ignore some of the peaks for E7. Generally, distance accuracy is able to effectively reflect the performance of each algorithm. The superior performance of LIPS is again due to the same reason (high convergence speed and high fine search accuracy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Conclusion</head><p>In this paper, a LIPS niching algorithm was proposed to solve multimodal problems. LIPS made use of the neighborhood information to realize niching behavior. LIPS also</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flow chart of a conventional PSO.</figDesc><graphic coords="3,68.72,53.63,210.38,191.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Pseudocode of an lbest PSO using a ring topology can be defined by its k closest particles, k being a user-defined parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 3</head><label>3</label><figDesc>Fig. 2. Topologies used in FIPS [40].</figDesc><graphic coords="4,334.02,205.52,210.24,126.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Comparison between topology-based neighborhood and distancebased neighborhood.</figDesc><graphic coords="5,85.22,53.83,177.98,130.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Distributions of pbests of LIPS and r2pso on different stages (F5). (a) Iteration 1 (LIPS). (b) Iteration 1 (r2pso). (c) Iteration 20 (LIPS). (d) Iteration 20 (r2pso). (e) Iteration 100 (LIPS). (f) Iteration 100 (r2pso). (g) Iteration 200 (LIPS). (h) Iteration 200 (r2pso).</figDesc><graphic coords="10,105.01,60.34,405.50,645.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Convergence graph for different neighborhood size (F16).</figDesc><graphic coords="11,336.73,54.34,200.30,157.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Summation of distance to optima (F16).</figDesc><graphic coords="11,340.23,243.53,193.10,156.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Distribution of population over function evaluations (F1).</figDesc><graphic coords="13,69.22,264.91,209.23,152.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Effect of varying level of accuracy.</figDesc><graphic coords="13,55.72,449.50,236.74,91.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. Overview of peak accuracies of each algorithm. Results are normalized for each problem, so that 0 refers to the best and 1 refers to the worst algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2 )</head><label>2</label><figDesc>Distance accuracy: Peak accuracy may lead to erroneous results, if the peaks are close to each other or with identical height. The distance accuracy is used to avoid this error. It is calculated the same way as peak accuracy, with the only change that the fitness values are replaced by the Euclidean distance as follows: distance accuracy = # peaks i=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>A Distance-Based Locally Informed Particle Swarm Model for Multimodal Optimization B. Y. Qu, Ponnuthurai Nagaratnam Suganthan, Senior Member, IEEE, and Swagatam Das, Member, IEEE</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I</head><label>I</label><figDesc></figDesc><table><row><cell></cell><cell>Test Functions</cell><cell></cell><cell></cell></row><row><cell>Test Function Part 1</cell><cell></cell><cell cols="2">Test Function Part 2 [41]</cell></row><row><cell>Test Function Name/Dimensions</cell><cell>No. of Global</cell><cell>Test Function Name/</cell><cell>No. of Global Peaks</cell></row><row><cell></cell><cell>Peaks</cell><cell>Dimensions</cell><cell></cell></row><row><cell>F1: Equal maxima/1-D [42]</cell><cell>5</cell><cell>F16: CF 1/10-D</cell><cell>8</cell></row><row><cell>F2: Decreasing maxima/1-D [42]</cell><cell>1</cell><cell>F17: CF 2/10-D</cell><cell>6</cell></row><row><cell>F3: Uneven maxima/1-D [42]</cell><cell>5</cell><cell>F18: CF 3/10-D</cell><cell>6</cell></row><row><cell>F4: Uneven decreasing maxima/1-D [42]</cell><cell>1</cell><cell>F19: CF 4/10-D</cell><cell>6</cell></row><row><cell>F5: Himmelblau's function/2-D [42]</cell><cell>4</cell><cell>F20: CF 5/10-D</cell><cell>6</cell></row><row><cell>F6: Six-hump camel back/2-D [43]</cell><cell>2</cell><cell>F21: CF 6/10-D</cell><cell>6</cell></row><row><cell>F7: Shekel's foxholes/2-D [44]</cell><cell>1</cell><cell>F22: CF 7/10-D</cell><cell>6</cell></row><row><cell>F8: Inverted Shubert function/2-D [35]</cell><cell>18</cell><cell>F23: CF 8/10-D</cell><cell>6</cell></row><row><cell>F9: Waves/2-D [45]</cell><cell>10</cell><cell>F24: CF 9/10-D</cell><cell>6</cell></row><row><cell>F10: Sphere/10-D</cell><cell>1</cell><cell>F25: CF 10/10-D</cell><cell>6</cell></row><row><cell>F11: Branin RCOS/2-D [35]</cell><cell>3</cell><cell>F26: CF 11/10-D</cell><cell>8</cell></row><row><cell>F12: Ackley/2-D [8]</cell><cell>1</cell><cell>F27: CF 12/10-D</cell><cell>8</cell></row><row><cell>F13: Michalewicz/2-D [8]</cell><cell>1</cell><cell>F28: CF 13/10-D</cell><cell>10</cell></row><row><cell>F14: Ursem F1/2-D [45]</cell><cell>1</cell><cell>F29: CF 14/10-D</cell><cell>10</cell></row><row><cell>F15: Ursem F3/2-D [45]</cell><cell>1</cell><cell>F30: CF 15/10-D</cell><cell>10</cell></row></table><note><p>of the function evaluations for multimodal optimization. The details of LIPS algorithm are shown in Algorithm 4 in the form of a pseudocode. Note that the complexity of Euclidean distance-based neighborhood selection is O(Np 2 ), where Np is the number of particles of the current population.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Test Function Setting</cell><cell></cell></row><row><cell>Function</cell><cell>ε</cell><cell>r</cell><cell>Population</cell><cell>No. of Function</cell></row><row><cell>No.</cell><cell></cell><cell></cell><cell>Size</cell><cell>Evaluations</cell></row><row><cell>F1</cell><cell>0.000001</cell><cell>0.01</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F2</cell><cell>0.000001</cell><cell>0.01</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F3</cell><cell>0.000001</cell><cell>0.01</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F4</cell><cell>0.000001</cell><cell>0.01</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F5</cell><cell>0.0005</cell><cell>0.5</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F6</cell><cell>0.000001</cell><cell>0.5</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F7</cell><cell>0.00001</cell><cell>0.5</cell><cell>50</cell><cell>10 000</cell></row><row><cell>F8</cell><cell>0.05</cell><cell>0.5</cell><cell>250</cell><cell>100 000</cell></row><row><cell>F9</cell><cell>0.001</cell><cell>0.2</cell><cell>200</cell><cell>30 000</cell></row><row><cell>F10</cell><cell>0.01</cell><cell>0.2</cell><cell>50</cell><cell>12 500</cell></row><row><cell>F11</cell><cell>0.001</cell><cell>0.5</cell><cell>200</cell><cell>20 000</cell></row><row><cell>F12</cell><cell>0.01</cell><cell>0.5</cell><cell>100</cell><cell>10 000</cell></row><row><cell>F13</cell><cell>0.0001</cell><cell>0.5</cell><cell>100</cell><cell>10 000</cell></row><row><cell>F14</cell><cell>0.000001</cell><cell>0.5</cell><cell>100</cell><cell>10 000</cell></row><row><cell>F15</cell><cell>0.00001</cell><cell>0.5</cell><cell>100</cell><cell>20 000</cell></row><row><cell>F16-F30</cell><cell>0.5</cell><cell>1</cell><cell>600</cell><cell>300 000</cell></row><row><cell cols="5">first 15 functions are classical test functions that were taken</cell></row><row><cell cols="5">from different published papers. The remaining 15 functions</cell></row><row><cell cols="5">are composition functions [41]. Different from most traditional</cell></row><row><cell cols="5">test functions, global optima of the composition functions</cell></row><row><cell cols="5">do not always reside at the origin or in the center of the</cell></row><row><cell cols="5">search area. Moreover, the composition functions come with</cell></row><row><cell cols="5">search space rotation, a feature that makes them even more</cell></row><row><cell cols="5">difficult to solve. Basic information of the test functions are</cell></row><row><cell cols="5">summarized in Table I. For functions F2, F7, F9, F11, F13,</cell></row></table><note><p>F14, and F15, the target is to locate all the peaks (global and local), while for the rest the objective is to search for the global optimum or optima and to escape the local peaks. All functions are considered for maximization; therefore, when the definitions are given for minimization, the functions are just sign-reversed.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III Success</head><label>III</label><figDesc>Rates and Ranks (in Parentheses) for Test Functions F1-F15</figDesc><table><row><cell>Test Function</cell><cell>LIPS</cell><cell>r2pso</cell><cell>r3pso</cell><cell>r2pso-lhc</cell><cell>r3pso-lhc</cell><cell>SPSO</cell><cell>FERPSO</cell><cell>SDE</cell><cell>CDE</cell><cell>SACMA-ES</cell></row><row><cell>F1</cell><cell>1 (1)</cell><cell cols="2">0.92 (3.5) 0.88 (5.5)</cell><cell>1 (1)</cell><cell cols="2">0.92 (3.5) 0.88 (5.5)</cell><cell>0.84 (7)</cell><cell>0.72 (8)</cell><cell>0.28 (9)</cell><cell>0 (10)</cell></row><row><cell>F2</cell><cell>0.96 (2)</cell><cell>0 (8)</cell><cell>0 (8)</cell><cell>0.64 (3)</cell><cell>0.04 (5)</cell><cell>1 (1)</cell><cell>0 (8)</cell><cell>0 (8)</cell><cell>0.48 (4)</cell><cell>0 (8)</cell></row><row><cell>F3</cell><cell>1 (1)</cell><cell>0.88 (6)</cell><cell>0.72 (7)</cell><cell>0.92 (4)</cell><cell>0.92 (4)</cell><cell>0.92 (4)</cell><cell>1 (1)</cell><cell>0.6 (8)</cell><cell>0.28 (9)</cell><cell>0 (10)</cell></row><row><cell>F4</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>1 (1)</cell><cell>0.96 (10)</cell></row><row><cell>F5</cell><cell>1 (1)</cell><cell cols="4">0.28 (5.5) 0.24 (7.5) 0.28 (5.5) 0.24 (7.5)</cell><cell>0 (9.5)</cell><cell cols="2">0.72 (2.5) 0.72 (2.5)</cell><cell>0 (9.5)</cell><cell>0.44 (4)</cell></row><row><cell>F6</cell><cell>1 (1)</cell><cell>0.56 (6.5)</cell><cell>0.6 (5)</cell><cell>0.56 (6.5)</cell><cell>0.52 (8)</cell><cell>0 (9.5)</cell><cell>0.96 (4)</cell><cell>1 (1)</cell><cell>0 (9.5)</cell><cell>1 (1)</cell></row><row><cell>F7</cell><cell>1 (1)</cell><cell>0.6 (5)</cell><cell>0.52 (6)</cell><cell>0.84 (3)</cell><cell>0.76 (4)</cell><cell>0.92 (2)</cell><cell>0 (8.5)</cell><cell>0 (8.5)</cell><cell>0 (8.5)</cell><cell>0 (8.5)</cell></row><row><cell>F8</cell><cell>0.84 (1)</cell><cell>0.04 (6)</cell><cell>0.04 (6)</cell><cell>0.04 (6)</cell><cell>0.2 (4)</cell><cell>0 (9)</cell><cell>0.52 (3)</cell><cell>0 (9)</cell><cell>0.72 (2)</cell><cell>0 (9)</cell></row><row><cell>F9</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell><cell>0 (1)</cell></row><row><cell>F10</cell><cell>1 (1)</cell><cell>0 (</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV Peak</head><label>IV</label><figDesc>Ratio (Test Functions F1-F15)</figDesc><table><row><cell>Test Function</cell><cell></cell><cell>LIPS</cell><cell>r2pso</cell><cell>r3pso</cell><cell>r2pso-lhc</cell><cell>r3pso-lhc</cell><cell>SPSO</cell><cell>FERPSO</cell><cell>SDE</cell><cell>CDE</cell><cell>SACMA-ES</cell></row><row><cell>F1</cell><cell>Worst</cell><cell>1.00</cell><cell>0.80</cell><cell>0.80</cell><cell>1.00</cell><cell>0.80</cell><cell>0.80</cell><cell>0.80</cell><cell>0.80</cell><cell>0.20</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.20</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.98</cell><cell>0.98</cell><cell>1.00</cell><cell>0.98</cell><cell>0.98</cell><cell>0.97</cell><cell>0.94</cell><cell>0.77</cell><cell>0.01</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.06</cell><cell>0.07</cell><cell>0.00</cell><cell>0.06</cell><cell>0.07</cell><cell>0.07</cell><cell>0.09</cell><cell>0.21</cell><cell>0.04</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F2</cell><cell>Worst</cell><cell>0.80</cell><cell>0.20</cell><cell>0.20</cell><cell>0.60</cell><cell>0.20</cell><cell>1.00</cell><cell>0.20</cell><cell>0.20</cell><cell>0.40</cell><cell>0.20</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>0.20</cell><cell>0.20</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.20</cell><cell>0.60</cell><cell>1.00</cell><cell>0.20</cell></row><row><cell></cell><cell>Mean</cell><cell>0.99</cell><cell>0.20</cell><cell>0.20</cell><cell>0.90</cell><cell>0.56</cell><cell>1.00</cell><cell>0.20</cell><cell>0.30</cell><cell>0.86</cell><cell>0.20</cell></row><row><cell></cell><cell>Std</cell><cell>0.04</cell><cell>0.00</cell><cell>0.00</cell><cell>0.14</cell><cell>0.22</cell><cell>0.00</cell><cell>0.00</cell><cell>0.12</cell><cell>0.17</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F3</cell><cell>Worst</cell><cell>1.00</cell><cell>0.80</cell><cell>0.80</cell><cell>0.80</cell><cell>0.60</cell><cell>0.80</cell><cell>1.00</cell><cell>0.80</cell><cell>0.40</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.98</cell><cell>0.94</cell><cell>0.98</cell><cell>0.98</cell><cell>0.98</cell><cell>1.00</cell><cell>0.92</cell><cell>0.79</cell><cell>0.00</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.07</cell><cell>0.09</cell><cell>0.06</cell><cell>0.09</cell><cell>0.06</cell><cell>0.00</cell><cell>0.10</cell><cell>0.18</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F4</cell><cell>Worst</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.96</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.20</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>F5</cell><cell>Worst</cell><cell>1.00</cell><cell>0.25</cell><cell>0.25</cell><cell>0.00</cell><cell>0.25</cell><cell>0.00</cell><cell>0.50</cell><cell>0.75</cell><cell>0.00</cell><cell>0.75</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell><cell>1.00</cell><cell>0.25</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.73</cell><cell>0.69</cell><cell>0.75</cell><cell>0.78</cell><cell>0.21</cell><cell>0.92</cell><cell>0.93</cell><cell>0.08</cell><cell>0.85</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.22</cell><cell>0.22</cell><cell>0.23</cell><cell>0.17</cell><cell>0.16</cell><cell>0.14</cell><cell>0.12</cell><cell>0.12</cell><cell>0.13</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F6</cell><cell>Worst</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.50</cell><cell>0.00</cell><cell>0.00</cell><cell>0.50</cell><cell>1.00</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.72</cell><cell>0.78</cell><cell>0.78</cell><cell>0.74</cell><cell>0.04</cell><cell>0.98</cell><cell>1.00</cell><cell>0.02</cell><cell>1.00</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.36</cell><cell>0.29</cell><cell>0.26</cell><cell>0.30</cell><cell>0.14</cell><cell>0.10</cell><cell>0.00</cell><cell>0.10</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>F7</cell><cell>Worst</cell><cell>1.00</cell><cell>0.92</cell><cell>0.88</cell><cell>0.96</cell><cell>0.92</cell><cell>0.96</cell><cell>0.12</cell><cell>0.04</cell><cell>0.28</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.28</cell><cell>0.08</cell><cell>0.80</cell><cell>0.16</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.98</cell><cell>0.97</cell><cell>0.99</cell><cell>0.98</cell><cell>1.00</cell><cell>0.21</cell><cell>0.05</cell><cell>0.50</cell><cell>0.04</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.03</cell><cell>0.03</cell><cell>0.01</cell><cell>0.03</cell><cell>0.01</cell><cell>0.05</cell><cell>0.02</cell><cell>0.10</cell><cell>0.03</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F8</cell><cell>Worst</cell><cell>0.94</cell><cell>0.67</cell><cell>0.72</cell><cell>0.67</cell><cell>0.72</cell><cell>0.28</cell><cell>0.83</cell><cell>0.50</cell><cell>0.89</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.72</cell><cell>1.00</cell><cell>0.94</cell><cell>1.00</cell><cell>0.28</cell></row><row><cell></cell><cell>Mean</cell><cell>0.99</cell><cell>0.84</cell><cell>0.86</cell><cell>0.84</cell><cell>0.90</cell><cell>0.47</cell><cell>0.97</cell><cell>0.69</cell><cell>0.98</cell><cell>0.12</cell></row><row><cell></cell><cell>Std</cell><cell>0.02</cell><cell>0.09</cell><cell>0.07</cell><cell>0.07</cell><cell>0.07</cell><cell>0.13</cell><cell>0.04</cell><cell>0.11</cell><cell>0.03</cell><cell>0.07</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>1</cell></row><row><cell>F9</cell><cell>Worst</cell><cell>0.50</cell><cell>0.30</cell><cell>0.30</cell><cell>0.30</cell><cell>0.30</cell><cell>0.10</cell><cell>0.10</cell><cell>0.10</cell><cell>0.40</cell><cell>0.10</cell></row><row><cell></cell><cell>Best</cell><cell>0.70</cell><cell>0.50</cell><cell>0.50</cell><cell>0.60</cell><cell>0.50</cell><cell>0.50</cell><cell>0.20</cell><cell>0.50</cell><cell>0.80</cell><cell>0.30</cell></row><row><cell></cell><cell>Mean</cell><cell>0.60</cell><cell>0.37</cell><cell>0.37</cell><cell>0.40</cell><cell>0.38</cell><cell>0.28</cell><cell>0.11</cell><cell>0.28</cell><cell>0.59</cell><cell>0.22</cell></row><row><cell></cell><cell>Std</cell><cell>0.06</cell><cell>0.07</cell><cell>0.06</cell><cell>0.08</cell><cell>0.07</cell><cell>0.11</cell><cell>0.03</cell><cell>0.08</cell><cell>0.10</cell><cell>0.09</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell></row><row><cell>F10</cell><cell>Worst</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell>F11</cell><cell>Worst</cell><cell>1.00</cell><cell>0.67</cell><cell>0.67</cell><cell>0.67</cell><cell>0.67</cell><cell>0.67</cell><cell>1.00</cell><cell>1.00</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.93</cell><cell>0.93</cell><cell>0.92</cell><cell>0.93</cell><cell>0.88</cell><cell>1.00</cell><cell>1.00</cell><cell>0.36</cell><cell>1.00</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.14</cell><cell>0.14</cell><cell>0.15</cell><cell>0.14</cell><cell>0.16</cell><cell>0.00</cell><cell>0.00</cell><cell>0.30</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>F12</cell><cell>Worst</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.72</cell><cell>0.88</cell><cell>0.56</cell><cell>0.72</cell><cell>0.08</cell><cell>1.00</cell><cell>0.96</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.46</cell><cell>0.33</cell><cell>0.51</cell><cell>0.46</cell><cell>0.28</cell><cell>0.00</cell><cell>0.20</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell>F13</cell><cell>Worst</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell><cell>0.50</cell><cell>0.50</cell><cell>0.00</cell><cell>0.50</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.98</cell><cell>1.00</cell><cell>0.96</cell><cell>0.98</cell><cell>0.16</cell><cell>0.52</cell><cell>1.00</cell><cell>1.00</cell><cell>0.72</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.10</cell><cell>0.00</cell><cell>0.14</cell><cell>0.10</cell><cell>0.24</cell><cell>0.10</cell><cell>0.00</cell><cell>0.00</cell><cell>0.26</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell></row><row><cell>F14</cell><cell>Worst</cell><cell>1.00</cell><cell>0.00</cell><cell>0.50</cell><cell>0.50</cell><cell>0.50</cell><cell>0.00</cell><cell>0.50</cell><cell>0.50</cell><cell>0.00</cell><cell>0.50</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>0.50</cell><cell>1.00</cell><cell>1.00</cell><cell>0.00</cell><cell>0.50</cell><cell>0.50</cell><cell>0.50</cell><cell>0.50</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.52</cell><cell>0.50</cell><cell>0.88</cell><cell>0.80</cell><cell>0.00</cell><cell>0.50</cell><cell>0.50</cell><cell>0.08</cell><cell>0.50</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.23</cell><cell>0.00</cell><cell>0.22</cell><cell>0.25</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.19</cell><cell>0.00</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>F15</cell><cell>Worst</cell><cell>1.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.20</cell><cell>0.20</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>0.40</cell><cell>0.20</cell><cell>0.40</cell><cell>0.80</cell><cell>0.00</cell><cell>0.20</cell><cell>0.60</cell><cell>0.20</cell><cell>0.60</cell></row><row><cell></cell><cell>Mean</cell><cell>1.00</cell><cell>0.10</cell><cell>0.07</cell><cell>0.18</cell><cell>0.16</cell><cell>0.00</cell><cell>0.20</cell><cell>0.29</cell><cell>0.01</cell><cell>0.48</cell></row><row><cell></cell><cell>Std</cell><cell>0.00</cell><cell>0.13</cell><cell>0.10</cell><cell>0.13</cell><cell>0.21</cell><cell>0.00</cell><cell>0.00</cell><cell>0.16</cell><cell>0.04</cell><cell>0.18</cell></row><row><cell></cell><cell>t-test</cell><cell>-</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>t-test summary</cell><cell>Better</cell><cell>-</cell><cell>11</cell><cell>12</cell><cell>10</cell><cell>11</cell><cell>10</cell><cell>8</cell><cell>10</cell><cell>10</cell><cell>10</cell></row><row><cell></cell><cell>Similar</cell><cell>-</cell><cell>4</cell><cell>3</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>7</cell><cell>5</cell><cell>5</cell><cell>5</cell></row><row><cell></cell><cell>Worst</cell><cell>-</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII Peak</head><label>VII</label><figDesc>Ratio for Functions F11 and F16 Illustrating the Effect of Neighborhood Size</figDesc><table><row><cell>Test Function</cell><cell></cell><cell cols="4">nsize=2 nsize=3 nsize=4 nsize=5</cell></row><row><cell>F11</cell><cell>Worst</cell><cell>0.94</cell><cell>0.89</cell><cell>0.83</cell><cell>0.72</cell></row><row><cell></cell><cell>Best</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell></cell><cell>Mean</cell><cell>0.99</cell><cell>0.96</cell><cell>0.93</cell><cell>0.88</cell></row><row><cell></cell><cell>Std</cell><cell>0.02</cell><cell>0.03</cell><cell>0.06</cell><cell>0.07</cell></row><row><cell>F16</cell><cell>Worst</cell><cell>0.00</cell><cell>0.25</cell><cell>0.50</cell><cell>0.50</cell></row><row><cell></cell><cell>Best</cell><cell>0.13</cell><cell>0.50</cell><cell>0.63</cell><cell>0.63</cell></row><row><cell></cell><cell>Mean</cell><cell>0.03</cell><cell>0.38</cell><cell>0.54</cell><cell>0.59</cell></row><row><cell></cell><cell>Std</cell><cell>0.05</cell><cell>0.08</cell><cell>0.07</cell><cell>0.06</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A first step toward extending this paper would be to add certain diversity enhancement techniques, as this will surely increase the probability of more global or local peaks for complex multimodal optimization problems. Secondly, it would be interesting to self-adapt neighborhood size and population size, as this might further improve the performance of the current algorithm. Also, the proposed approach could be applied to solving multimodal optimization in a dynamic environment. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Handbook of Evolutionary Computation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Oxford Univ. Press</publisher>
			<pubPlace>Oxford, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<title level="m">Introduction to Evolutionary Computing</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Niching methods for genetic algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mahfoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. Illinois Urbana-Champaign</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Urbana</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A comparison of parallel and sequential niching methods</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mahfoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Genet. Algorithms</title>
		<meeting>6th Int. Conf. Genet. Algorithms</meeting>
		<imprint>
			<date type="published" when="1995-07">Jul. 1995</date>
			<biblScope unit="page" from="136" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A real-coded niching memtic algorithm for continuous multimodal function optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Vitela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Castanos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="2170" to="2177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic crowding: Deterministic crowding with probabilistic replacement</title>
		<author>
			<persName><forename type="first">O</forename><surname>Mengsheol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="1999-07">Jul. 1999</date>
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fitness sharing and niching methods revisited</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sareni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="1998-09">Sep. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal optimization using crowding-based differential evolution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thomsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2004-06">Jun. 2004</date>
			<biblScope unit="page" from="1382" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Conf. Genet. Algorithms</title>
		<meeting>2nd Int. Conf. Genet. Algorithms</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Finding multimodal solutions using restricted tournament selection</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Harik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Genet. Algorithms</title>
		<meeting>6th Int. Conf. Genet. Algorithms</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A clearing procedure as a niching method for genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Petrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd IEEE Congr</title>
		<meeting>3rd IEEE Congr</meeting>
		<imprint>
			<date type="published" when="1996-05">May 1996</date>
			<biblScope unit="page" from="798" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Symp. Micromach</title>
		<meeting>6th Int. Symp. Micromach</meeting>
		<imprint>
			<date type="published" when="1995-03">Mar. 1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Neural Netw</title>
		<meeting>IEEE Int. Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="1995-12">Nov.-Dec. 1995</date>
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<title level="m">Swarm Intelligence</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Monitoring of particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers Comput. Sci. China</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comprehensive learning particle swarm optimizer for global optimization of multimodal functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="295" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Particle swarm optimization with composite particles in dynamic environments</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1634" to="1648" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Culture-based multiobjective particle swarm optimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Daneshyari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="553" to="567" />
			<date type="published" when="2011-04">Apr. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fractional particle swarm optimization in multidimensional search space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="298" to="319" />
			<date type="published" when="2010-04">Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Coevolutionary particle swarm optimization using Gaussian distribution for solving constrained optimization problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Krohling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Coelho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern., Part B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1407" to="1416" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A multimodal particle swarm optimizer based on fitness Euclidean-distance ration</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Genet. Evol. Computat. Conf</title>
		<imprint>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptively choosing neighborhood bests using species in a particle swarm optimizer for multimodal function optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Genet. Evol. Computat. Conf</title>
		<imprint>
			<biblScope unit="volume">3102</biblScope>
			<biblScope unit="page" from="105" to="116" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Niching without niching parameters: Particle swarm optimization using a ring topology</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="150" to="169" />
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stretching technique for obtaining global minimizers through particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Plagianakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Magoulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahitis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Particle Swarm Optimiz</title>
		<meeting>Particle Swarm Optimiz</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="22" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A sequential niche technique for multimodal function optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Beasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Bull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="125" />
			<date type="published" when="1993-06">Jun. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the computation of all global minimizers through particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="224" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modification of the particle swarm optimizer for locating all the global minima</title>
		<author>
			<persName><forename type="first">K</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Genetic Algorithms</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="324" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A niching particle swarm optimizer</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Asia-Pacific Conf. SEAL</title>
		<meeting>4th Asia-Pacific Conf. SEAL</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="692" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Population diversity of particle swarms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1063" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Initializing PSO with randomized low-discrepancy sequences: The comparative results</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Q</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">X</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Maccay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Tuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1985" to="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The particle swarm: Social adaptation of knowledge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Evol. Computat</title>
		<meeting>Int. Conf. Evol. Computat</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Particle swarm optimisation and high dimensional problem spaces</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hendtlass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2009-05">May 2009</date>
			<biblScope unit="page" from="1988" to="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Solving systems of unconstrained equations using particle swarm optimizers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Den Bergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Syst., Man, Cybern</title>
		<meeting>IEEE Int. Conf. Syst., Man, Cybern</meeting>
		<imprint>
			<date type="published" when="2002-10">Oct. 2002</date>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Parameter selection in particle swarm optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Annu. Conf. Evol. Program</title>
		<meeting>7th Annu. Conf. Evol. Program</meeting>
		<imprint>
			<date type="published" when="1998-03">Mar. 1998</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A species conserving genetic algorithm for multimodal function optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Balazs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="234" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient differential evolution using speciation for multimodal function optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf</title>
		<meeting>Conf</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="873" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Differential evolution: A survey of the state-of-the-art</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="31" />
			<date type="published" when="2011-02">Feb. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evolution strategies: A comprehensive introduction</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Comput.: An Int. J</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="52" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adaptive niche radii and niche shapes approaches for niching with the CMA-ES</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Shir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="126" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The fully informed particle swarm: Simpler, maybe better</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Computat</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="204" to="210" />
			<date type="published" when="2004-06">Jun. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Novel multimodal problems and differential evolution with ensemble of restricted tournament selection</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="3480" to="3486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Genetic algorithms in multimodal function optimization, the Clearinghouse for Genetic Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">89002</biblScope>
			<pubPlace>Tuscaloosa, TCGA Rep</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Eng. Mechanics, Univ. Alabama</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Genetic Algorithms + Data Structures = Evolution Programs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An analysis of the behavior of a class of genetic adaptive systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Commun. Sci., Univ. Michigan</title>
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multimodal evolutionary algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Ursem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Congr</title>
		<meeting>Congr</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1633" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A variable radius niching technique for speciation in genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Warwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multimodal optimization by means of a topological species conservation algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stoean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Preuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stoean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dumitrescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="842" to="864" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The particle swarm algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hendtlass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence: A Compendium</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1029" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fitness estimation and the particle swarm optimisation algorithm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hendtlass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="4266" to="4272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">His current research interests include machine learning, neural networks, genetic and evolutionary algorithms, swarm intelligence</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Qu received the B.E. and Ph.D. degrees from the School of Electrical and Electronic Engineering</title>
		<meeting><address><addrLine>Singapore; Zhengzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007 and 2012</date>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University ; Zhongyuan University of Technology</orgName>
		</respStmt>
	</monogr>
	<note>and multiobjective optimization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
