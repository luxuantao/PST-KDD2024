<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-02-06">6 Feb 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Carta</surname></persName>
							<email>thomas.carta@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Cl?ment</forename><surname>Romac</surname></persName>
							<email>clement.romac@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sylvain</forename><surname>Lamprier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Sigaud</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre-Yves</forename><surname>Oudeyer</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Inria (Flowers)</orgName>
								<orgName type="institution">University of Bordeaux</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Inria (Flowers)</orgName>
								<orgName type="institution">University of Bordeaux</orgName>
								<address>
									<country>France Hugging Face</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Univ Angers</orgName>
								<orgName type="institution" key="instit2">LERIA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">SFR MATHSTIC</orgName>
								<address>
									<postCode>F-49000</postCode>
									<settlement>Angers</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Sorbonne Universit?</orgName>
								<orgName type="institution" key="instit2">ISIR</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Inria (Flowers)</orgName>
								<orgName type="institution">University of Bordeaux</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-02-06">6 Feb 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.02662v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent works successfully leveraged Large Language Models' (LLM) abilities to capture abstract knowledge about world's physics to solve decision-making problems. Yet, the alignment between LLMs' knowledge and the environment can be wrong and limit functional competence due to lack of grounding. In this paper, we study an approach to achieve this alignment through functional grounding: we consider an agent using an LLM as a policy that is progressively updated as the agent interacts with the environment, leveraging online Reinforcement Learning to improve its performance to solve goals. Using an interactive textual environment designed to study higher-level forms of functional grounding, and a set of spatial and navigation tasks, we study several scientific questions: 1) Can LLMs boost sample efficiency for online learning of various RL tasks? 2) How can it boost different forms of generalization? 3) What is the impact of online learning? We study these questions by functionally grounding several variants (size, architecture) of FLAN-T5.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent rise of Transformer-based Large Language Models (LLMs) trained on massive text datasets in Natural Language Processing has led to models exhibiting impressive capabilities (e.g. natural language generation, question answering, reasoning, translation...) <ref type="bibr" target="#b15">[Devlin et al., 2019</ref><ref type="bibr">, Brown et al., 2020</ref><ref type="bibr" target="#b38">, Rae et al., 2021</ref><ref type="bibr" target="#b11">, Chowdhery et al., 2022</ref><ref type="bibr" target="#b42">, Scao et al., 2022]</ref>. Recently, LLMs were shown to capture aspects of the physical rules in our world, e.g. about space <ref type="bibr" target="#b37">Patel and Pavlick [2022]</ref>, colors <ref type="bibr">Abdou et al. [2021]</ref> or even affordances between bodies and objects <ref type="bibr" target="#b1">Ahn et al. [2022]</ref>. This form of prior knowledge was exploited to suggest plans of action to solve goals in robotics <ref type="bibr">Huang et al. [2022b]</ref>, <ref type="bibr" target="#b1">Ahn et al. [2022]</ref>, <ref type="bibr" target="#b30">Liang et al. [2022]</ref>. However, LLMs are known to suffer from a lack of grounding which prevents them from properly dealing with the meaning of inter-related concepts and their use for functional competence in interactive environments <ref type="bibr" target="#b33">Mahowald et al. [2023]</ref>. Indeed, alignment between statistical structures in such LLMs and environments can be very limited, or even sometimes entirely wrong. This is partly due to 1) a training process (predicting next words) that is not directly incentivized to solve problems in an environment, 2) lack of abilities to intervene in the environment to identify causal structures; 3) lack in abilities to learn based on data collected as a result of interacting with the environment <ref type="bibr" target="#b4">[Bender and</ref><ref type="bibr">Koller, 2020, Bisk et al., 2020]</ref>.</p><p>In the literature, language grounding has referred to various related objectives <ref type="bibr" target="#b47">Thill et al. [2014]</ref>. First, symbol grounding can be formulated as the general problem of connecting a symbol system <ref type="bibr" target="#b18">[Harnad, 1990]</ref>, internal to an agent, to the environment, in such a way that internal processing of these symbols can be used to achieve goals in this environment. One dimension of this problem is how to associate "elementary" symbols, such as the names of objects, with invariant structures in high-dimensional perceptual modalities such as vision <ref type="bibr" target="#b9">Cangelosi et al. [2010]</ref>, <ref type="bibr" target="#b51">Wiriyathammabhum et al. [2016]</ref>, <ref type="bibr" target="#b2">Alayrac et al. [2022]</ref>. This has been called "direct grounding" and is often studied in contexts with robotic bodies <ref type="bibr" target="#b8">Cangelosi and Stramandinoli [2018]</ref>. Another dimension is how to ground higher-order symbolic tokens, or abstract concepts, into elementary symbols, often through approaches such as distributional semantics <ref type="bibr" target="#b19">Harris [1981]</ref>, <ref type="bibr" target="#b6">Boleda [2019]</ref>. This has been called "grounding transfer" <ref type="bibr" target="#b8">Cangelosi and Stramandinoli [2018]</ref>. Beyond such mere associations, a key question about grounding is how can internal processes that manipulate symbols have capabilities to model, predict and control external physical and social processes: they need to be aligned on and constrained by these external dynamics and relational structures (at various levels of abstraction). This last notion of grounding, which we refer here as "functional grounding", is relative to a particular environment which may be the human physical environment but also more abstract interactive environments simulated in computers (where abstract physics can differ from human environments).</p><p>In this paper, we consider interactive textual worlds <ref type="bibr" target="#b13">C?t? et al. [2018]</ref>, Jansen <ref type="bibr">[2021]</ref>, which are precisely designed to focus on these higher-level forms of functional grounding. In textual worlds, environments can encode rich forms of physical structures inspired by the ones in the human world, e.g. <ref type="bibr" target="#b49">Wang et al. [2022]</ref>, yet agents act and perceive in these environments only through the textual modality. In this context, this paper aims to make progress towards the following largely open question: how could LLMs be used as agent policies producing actions towards goals in interactive environments, perceiving the outcome of these actions, and incrementally grounding and updating their knowledge with the new observations they collect?</p><p>Building on recent works successfully using Reinforcement Learning (RL) to finetune LLMs for natural language generation tasks <ref type="bibr" target="#b45">[Stiennon et al., 2020</ref><ref type="bibr" target="#b36">, Ouyang et al., 2022</ref><ref type="bibr" target="#b39">, Ramamurthy et al., 2022]</ref>, we propose the first study about functional grounding of LLMs through incremental online RL. In particular, we aim at empirically answering the following open scientific questions:</p><p>? Q1. Sample efficiency How fast can an LLM adapt and learn to solve various spatial and navigation problems specified in natural language? How does the use of pre-trained knowledge from LLM boosts sample efficiency?</p><p>? Q2. Generalization to new objects: Once functionally grounded, how can an LLM generalize to various kinds of changes about objects, yet staying in trained tasks?</p><p>? Q3. Generalization to new tasks: How can such an interactively trained LLM perform zero-shot generalization to new tasks? How does generalization depend on the kind of new tasks?</p><p>? Q4. Impact of online interventions: What is the empirical impact of grounding using online RL with incremental interactions in comparison with offline Behavioral Cloning from a dataset of expert trajectories?</p><p>To answer these scientific questions in Section 4, we present a functional grounding method for LLMs (see Figure <ref type="figure">1</ref> and Section 3), and transpose the BabyAI environment <ref type="bibr" target="#b10">[Chevalier-Boisvert et al., 2019]</ref> into a textual version. Additionally, we aim to help the RL community further develop grounding techniques for LLMs in interactive environments by releasing, in addition of the code of this paper<ref type="foot" target="#foot_0">1</ref> , a Python library named Lamorel<ref type="foot" target="#foot_1">2</ref> facilitating the use of LLMs at scale for RL practitioners. While many tools already exist for LLMs and NLP tasks, moving to an RL setting with interactive environments requires adaptations (e.g. very frequent need of fast inference to compute action probabilities) making previous tools not well suited for RL practitioners (see Section 3.4).</p><p>Figure <ref type="figure">1</ref>: We use an LLM as agent policy in an interactive textual RL environment (BabyAI-Text): the LLM is trained to achieve language goals using online RL (PPO), enabling functional grounding. (a) BabyAI-Text provides a goal description for the current episode as well as a description of the agent observation and a scalar reward for the current step. (b) At each step, we gather the goal description and the observation in a prompt sent to our LLM. (c) For each possible action, we use the encoder to generate a representation of the prompt and compute the conditional probability of tokens composing the action given the prompt. Once the probability of each action is estimated, we compute a softmax function over these probabilities and sample an action according to this distribution. That is, the LLM is our agent policy. (d) We use the reward returned by the environment to finetune the LLM using PPO. For this, we estimate the value of the current observation by adding a value head on top of our LLM. Finally, we backpropagate the gradient through the LLM (and its value head).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Language-conditioned RL We position our work in the Language-conditioned RL setting, where an instruction-following agent learns a policy that executes actions in an interactive environment in order to fulfill a language instruction <ref type="bibr" target="#b32">[Luketina et al., 2019]</ref>. While several works studied this setting for various tasks in 2D or 3D environments <ref type="bibr" target="#b21">[Hermann et al., 2017</ref><ref type="bibr" target="#b35">, Misra et al., 2017</ref><ref type="bibr" target="#b3">, Bahdanau et al., 2018</ref><ref type="bibr" target="#b12">, Colas et al., 2020</ref><ref type="bibr" target="#b10">, Chevalier-Boisvert et al., 2019]</ref>, we here focus on text-only interactions (i.e. performing textual commands given textual observations) as in <ref type="bibr" target="#b44">Shridhar et al. [2020]</ref>. However, our work studies how LLMs can not only encode this instruction <ref type="bibr" target="#b22">[Hill et al., 2020]</ref> but also be directly used as agent policies choosing actions given the observation.</p><p>Textual environments for RL Many text-only environments have been used and developed <ref type="bibr" target="#b25">[Jansen, 2021</ref><ref type="bibr">, Wang et al., 2022]</ref>. They usually implement high-level text commands along with very large action spaces and complex dynamics between entities, often aiming to study functional grounding of abstract policies. While these environments offer interesting properties, we had to introduce a new one given the purpose and constraints of our study. Dealing here with computationally expensive LLMs, we chose to trade complex action spaces for systematic experiments studying the questions of the introduction. Second, to perform an in-depth analysis of our functional grounding method, we focused on lower-level navigation skills in spatial environments (which lacks in most textual environments as the agent can usually just change room and has direct access to objects in a room). Moreover, several ablation studies shown in Appendix B.4 required precise control over the procedural generation (usually not offered by textual environments). For these reasons, we adapted the BabyAI platform <ref type="bibr" target="#b10">[Chevalier-Boisvert et al., 2019]</ref> into a procedural text-only version that enables decoupling exploration challenges from perception challenges. Additionally, we are still able to use BabyAI's visualization tools to analyze trajectories (see Figure <ref type="figure">1</ref>).</p><p>Foundation Models for decision making Foundation models trained on massive datasets were shown to exhibit impressive abilities along with fast adaptation to a wide range of downstream tasks in vision <ref type="bibr" target="#b53">[Yuan et al., 2021]</ref>, language <ref type="bibr" target="#b15">[Devlin et al., 2019</ref><ref type="bibr">, Brown et al., 2020]</ref> and cross-modalities <ref type="bibr" target="#b40">[Ramesh et al., 2021</ref><ref type="bibr">, Jiang et al., 2022</ref><ref type="bibr" target="#b2">, Alayrac et al., 2022]</ref>. While such abilities have been leveraged to provide reward to RL agents <ref type="bibr" target="#b17">Gupta et al. [2022</ref><ref type="bibr">], Fan et al. [2022]</ref>, a recent line of work started focusing on using Foundation Models (and in particular LLMs) to guide agents policy. <ref type="bibr">First, SayCan [Ahn et al., 2022]</ref>, Code as Policies <ref type="bibr" target="#b30">[Liang et al., 2022]</ref> and Inner Monologue <ref type="bibr">[Huang et al., 2022b]</ref> used LLMs as high-level planners in robotics setups. Because their LLM is not directly used as agent policy for low-level actions and is not grounded using its interactions with the environment, <ref type="bibr" target="#b1">Ahn et al. [2022]</ref> had to use an external affordance function to re-rank the actions proposed by the LLM. Similarly, <ref type="bibr" target="#b52">Yao et al. [2022]</ref> also featured a closed-loop feedback between an LLM that is the planner and an agent that is the actor but this time in a textual environment. Expanding on this, <ref type="bibr" target="#b14">Dasgupta et al. [2022]</ref> added a reporter observing the environment and reporting useful information to the planner. While hinting at the usefulness of prior knowledge contained in LLMs for embodied tasks, these works are limited by the absence of grounding.</p><p>Second, several works proposed to first finetune LLMs on expert trajectories before using them in the environment. Using their ScienceWorld benchmark, <ref type="bibr" target="#b49">Wang et al. [2022]</ref> showed that LLMs finetuned using Behavioral Cloning performed worse than a much smaller and randomly initialized Deep Q-Network trained using RL supporting the hypothesis that grounding in the environment through direct interactions is crucial. Finally, <ref type="bibr" target="#b41">Reid et al. [2022]</ref> reused LLMs to perform offline RL in non-linguistic environments leveraging the internal structures learned by LLMs but no longer using words or symbols they were trained to manipulate <ref type="bibr" target="#b46">(Takagi [2022]</ref> investigated how these internal structures can be relevant for unrelated tasks).</p><p>Finetuning LLMs with RL Recent works successfully leveraged RL to finetune LLMs and in particular to improve alignment between generated text and human preferences <ref type="bibr" target="#b45">[Stiennon et al., 2020</ref><ref type="bibr" target="#b36">, Ouyang et al., 2022</ref><ref type="bibr" target="#b39">, Ramamurthy et al., 2022]</ref>. In this framework, text generation is viewed as a sequential decision-making problem where each "action" of the LLM is a new token and the "state" corresponds to the prompt. These methods then used PPO <ref type="bibr" target="#b43">[Schulman et al., 2017]</ref> to finetune their LLMs using a reward function learned on a dataset of collected human interactions. With this technique, <ref type="bibr" target="#b36">Ouyang et al. [2022]</ref> managed to generate more human-aligned outputs despite having a model (InstructGPT) with 100 times fewer parameters than <ref type="bibr">GPT-3 [Brown et al., 2020]</ref>. We take inspiration from these works and also use PPO to finetune our LLMs. However, our LLMs interact with an external world providing new (and partial) observations at each step given its inner dynamics along with a task-conditioned reward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Grounding LLMs with online RL</head><p>We describe an approach where an LLM is used as agent policy and is functionally grounded in an interactive environment using online RL, leveraging collected observations and rewards to improve itself towards achieving goals formulated in language. We detail this grounding method in the following paragraphs and redirect the reader to Figure <ref type="figure">1</ref> for a schematic view. We first formalize the textual RL problem we tackle (a). Then, we detail how we use an LLM as agent policy to interact with <ref type="bibr">BabyAI-Text (b, c)</ref>. Finally, we explain how online RL finetuning is used to ground the LLM in BabyAI-Text (d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem statement</head><p>We assume a textual RL setting where, given a language vocabulary V, our environment returns an observation o ? V N and a reward r ? R following an action a ? A ? V N (i.e. actions are sequences of tokens). We also assume a task or goal description g ? G ? V N which conditions the reward. Such an environment can be framed as a goal-augmented Partially Observable Markov Decision Process M = (S, V, A, T , R, G, O, ?) with S the state space, A ? V N the action space, G ? V N the goal space, T : S ? A ? S the transition function, R : S ? A ? G ? R the goal-conditioned reward function, O : S ? V N the observation function mapping a state to a textual description and finally ? the discount factor.</p><p>In this work, we extend the BabyAI platform <ref type="bibr" target="#b10">[Chevalier-Boisvert et al., 2019]</ref> initially designed for grounded language learning and propose a text-only extension named BabyAI-Text. We leverage BabyAI's inner procedurally generated minigrid environment where an agent navigates and interacts with objects through 6 text commands: turn left, turn right, go forward, pick up, drop and toggle. We also reuse the set of tasks introduced in BabyAI as well as their associated description along with the sparse scalar reward. Our key difference is the textual description o ? V N of the agent's partial observation returned by BabyAI-Text instead of the symbolic representation initially returned by BabyAI (see Appendix A.2). We leverage BabyAI-Text in Section 4 to assess our grounding method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">LLMs as policies in interactive environments</head><p>In order to use the LLM as the policy in such a textual interactive environment, we gather the task description, the textual description of the current observation and the set of possible actions in a prompt used to feed the LLM. We chose a single arbitrary and simple prompt template (see Appendix C for examples) and did not perform any intensive prompt engineering. Indeed, as we finetune the LLM, we expect it to adapt to the chosen prompt template. Nonetheless, a more careful design of prompts could improve the results shown in Section 4.</p><p>Given this prompt, we now need the LLM to output a probability distribution over the possible actions P(A). For this, <ref type="bibr">Huang et al. [2022a]</ref>, <ref type="bibr" target="#b29">Li et al. [2022]</ref>, <ref type="bibr" target="#b49">Wang et al. [2022]</ref> used the LLM to generate text. If the generated sequence of characters corresponds to one of the possible actions (i.e. s ? A), this action is chosen by the agent. Otherwise, an ad-hoc mapping must be performed to select an action a i ? A given s. As an alternative method, one could also use more standard RL practices by adding action heads -a Multi-Layer Perceptron (MLP) with |A| outputs -on top of the LLM. Finally, <ref type="bibr" target="#b1">Ahn et al. [2022]</ref> proposed to directly use the LLM to compute the probability of each action a i ? A by computing the conditional probability of each token in action a i = {w 0 , ..., w |ai| } given the prompt p:</p><formula xml:id="formula_0">P LLM (a i |p) = |ai| j=0 P LLM (w j |p, w &lt;j )<label>(1)</label></formula><p>with P LLM (w j |p, w &lt;j ) the probability computed by the LLM of token w j given prompt p and previous tokens w &lt;j (see (c) from Figure <ref type="figure">1</ref>). This method suffers from requiring a forward pass on the LLM for each action to compute the probability of its sequence of tokens (especially in comparison to new action heads that require a single forward pass on the prompt to compute all actions' probability). However, it also has several advantages, in particular, 1) there is no need of potential ad-hoc mapping as when text is generated, 2) we use only pretrained operations from the LLM and leverage language modeling heads' prior and 3) this method is robust to any action space and can thus be used on any textual environment with no change.</p><p>For these reasons, we chose the latter method. We use a softmax function to normalize the probabilities and get a distribution over A: ai|p)   aj ?A e P LLM (aj |p) .</p><formula xml:id="formula_1">P(a i |p) = e P LLM (</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PPO finetuning</head><p>We now propose to leverage experiences gathered by the LLM to perform functional grounding.</p><p>More formally, we aim to learn a policy ? : O ? G ? P(A) that maximizes the expected discounted sum of rewards for any given goal g ? G. We use for this the PPO algorithm <ref type="bibr" target="#b43">[Schulman et al., 2017]</ref> that both learns a policy ? : O ? G ? P(A) and a value function V : O ? G ? R approximating the true value V (s, g) = E a??(O(s),g) R(s, g, a) + ?V (T (s, a), g) .</p><p>As mentioned in Section 3.2, we compute the probability of each action a i ? A using the likelihood computed by the LLM as ?(a i |o, g) = P(a i |p).</p><p>For value approximation, we we add an MLP with a single output for the value on top of the last layer of the first Decoder block (i.e. in place of the language modeling heads) in order to compute V (o|g) = V (p) (see (d) from Figure <ref type="figure">1</ref>). This position is explained by the fact that we use Encoder-Decoder LLMs in our experiments but our method could easily be used with Decoder-only models by attaching the value head to the Decoder block encoding the last token of the prompt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Distributed LLM policies using Lamorel</head><p>Using LLMs to compute probabilities over action space is computationally expensive as it requires computing |ai| j=0 P LLM (w j |p, w &lt;j ) for each action a i = {w 0 , ..., w |ai| }. When one uses very large LLMs (i.e. more than hundreds of million parameters), computing the probability of a single action already means performing a long forward pass over the whole network. As a result, computing the probability of each possible action at every step becomes very slow. Considering the number of interactions usually required to solve tasks in BabyAI (and by extension BabyAI-Text), performing online RL finetuning of LLMs easily became intractable with a single LLM distributed over multiple GPUs. To overcome this, we deployed N LLM workers each handling a subset of actions to score in parallel (allowing a quasi-linear time decrease with N ). We add to this distributed inference the possibility to also perform distributed training (i.e. compute the gradient of minibatches in parallel and gather gradients before updating models). We wrap all this in a Python library named Lamorel designed for RL practitioners eager to use LLMs. It allows one to use LLMs as black-box but also to perform more advanced methods such as adding new heads on top of them. See Appendix E for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We design a set of experiments in BabyAI-Text aiming to provide answers for the scientific questions introduced in Section 1. In these experiments, we use Flan-T5 780M <ref type="bibr" target="#b38">[Rae et al., 2021]</ref> for 1) the close link between its training corpus (containing instruction-following documents) and our languageconditioned interactive environment, and 2) its simple open-source access through the Hugging Face tools<ref type="foot" target="#foot_2">3</ref> . We compare the method introduced in Section 3 named GFlan-T5 (for Grounded-Flan-T5) with three baselines. First, we also train a non-pretrained Flan-T5 where we only reuse the pretrained embedding layer and add action heads on top of it (see Figure <ref type="figure">10</ref> in appendices). As for GFlan-T5, we propagate the gradient through the entire graph (included the action heads here). We call this baseline NPAE-Flan-T5 (Non-Pretrained with Action heads and Embedding Flan-T5). We show in Appendix B.2 that using a non-pretrained Flan-T5 while keeping the scoring method fails. We also provide as a more classic RL baseline a DRRN <ref type="bibr" target="#b20">[He et al., 2016]</ref> agent of approximately 1M parameters which is often used for TextWorlds. We especially reuse the implementation from <ref type="bibr" target="#b49">Wang et al. [2022]</ref> which gave SOTA results and outperformed LLMs. At each step, we feed our 3 agents above with the following prompt template filled using the information returned by BabyAI-Text (see Appendix C for examples):</p><p>? A header listing what actions are accessible (but not necessarily useful) in the environment in the form of: Possible action of the agent: &lt;list of actions&gt;</p><p>? The goal of the agent: Goal of the agent: &lt;goal&gt;</p><p>? The 3 previous observations and last 2 actions, used as a short-term memory required to complete BabyAI-Text tasks (in comparison, the DRRN uses recurrent layers to deal with short-term memory requirements): Obs. 0: &lt;description from BabyAI-Text at step t -2 &gt; Action 0:&lt;action chosen by the agent at step t -2 &gt; Obs. 1: &lt;description from BabyAI-Text at step t -1 &gt; Action 1: &lt;action chosen by the agent at step t -1 &gt; Obs. 2: &lt;description from BabyAI-Text at step t &gt; Action 2: &lt;the next action to be chosen by the agent&gt; Finally, as BabyAI-Text simply provides an alternative mapping of observations, we add as an indication the performance of the PPO agent used in <ref type="bibr" target="#b10">[Chevalier-Boisvert et al., 2019</ref>] that runs on BabyAI rather than BabyAI-Text (i.e. using symbolic observations instead of textual descriptions) and name this agent Symbolic-PPO in results below. In Appendix B.1, we show that symbolic observations provided by BabyAI encode biases that ease learning compared to text descriptions. However, even with this advantage, GFlan-T5 outperforms Symbolic-PPO in all our setups. We first study Q1 by training the different agents in a multi-task setting assessing their efficiency at learning the different tasks. We then address questions Q2, Q3 and Q4 using a set of generalization experiments (Figure <ref type="figure">3</ref>) on the zero-shot abilities of the resulted trained agents mostly inspired from <ref type="bibr" target="#b12">[Colas et al., 2020]</ref> and <ref type="bibr" target="#b48">[Valmeekam et al., 2022]</ref>. We report their average success rate as well as standard deviation. We compare the results of GFlan-T5, DRRN as well as Flan-T5 (i.e. the LLM used in GFlan-T5 but before our finetuning) to show how our grounding method impacted it. All results below are given with their 99% confidence interval (mathematical details are given in Appendix G).</p><p>4.1 How fast can an LLM adapt and learn to solve tasks? (Q1)</p><p>In order to study question Q1, we train our agents for 1.5 million steps in BabyAI-Text where each episode is a task randomly sampled from the following:</p><p>? Go to &lt;object&gt;, a simple navigation task that requires reasoning abilities to choose the right plan given objects' position; ? Pick up &lt;object&gt;, a reasoning task that combines navigation tasks;</p><p>? Put &lt;object A&gt; next to &lt;object B&gt;, which requires first reaching &lt;object A&gt;, picking it up, reaching &lt;object B&gt; and finally dropping &lt;object A&gt; next to &lt;object B&gt;; ? Pick up &lt;object A&gt; then go to &lt;object B&gt; and Go to &lt;object B&gt; after pick up &lt;object A&gt;, both serving to test reasoning abilities on temporal sequences;</p><p>? Unlock &lt;door&gt;, a task that includes inferring that a key is needed to unlock the door, finding the right key (i.e. the one colored as the door) and eventually using the toggle action with the key on the door.</p><p>In each task, the agent must navigate in one procedurally generated room with 8 distractors (i.e. useless objects for the completion of the task).</p><p>We plot the mean and standard deviation of the success rate (i.e. 1 if the goal has been reached, 0 otherwise) over 2 seeds of GFlan-T5, NPAE-Flan-T5, DRRN and Symbolic-PPO in Figure <ref type="figure" target="#fig_0">2</ref>. In addition, we also monitor the evolution of probability of each possible action on a set of 11 evaluation prompts to assess agents' abilities to solve each task in Appendix C. By plotting the evolution of the distribution over possible actions in Figure <ref type="figure" target="#fig_4">17</ref>, we better grasp how and when the agents learn skills (e.g. navigation skills). In Figure <ref type="figure" target="#fig_0">2</ref>, one can observe the superior abilities of GFlan-T5 compared to other baselines (DRRN and NPAE-Flan-T5) trained with linguistic observations. The failure of NPAE-Flan-T5 both highlights how GFlan-T5 leverages the LLM's pretrained knowledge to deal with the proposed tasks and how the finetuning method helps grounding its knowledge in the environment. Furthermore, the fact that GFlan-T5 outperforms Symbolic-PPO and the latter is better than NPAE demonstrates how language can be used as a tool to scaffold learning if already acquired but also how counterproductive it can be if one asks an agent to both learn a task and language at the same time (see Appendix B.1 for further results). Another strong point of GFlan-T5 is its sample efficiency. Even when compared to Symbolic-PPO which uses symbolic observations (easier to process than language as shown in Appendix 7), GFlan-T5 reaches a success rate of 0.4 for the first time after 100.000 steps whereas Symbolic-PPO never does so even after 1.5 million steps. GFlan-T5 leverages its knowledge about the relationships between entities to learn navigation tasks in less than a hundred updates (see Figure <ref type="figure" target="#fig_4">17</ref> and Table <ref type="table" target="#tab_1">2</ref>).</p><p>Figure <ref type="figure">3</ref>: Generalization tests: We train all agents on a mix of 5 different tasks and evaluate their generalization abilities on 1000 test episodes (also containing a mix of these 5 tasks) (a). We compare them to two baselines: an agent choosing actions randomly (Random) and the zero-shot Flan-T5 (without any finetuning). We then perform several generalization studies to answer Q2 and Q3 by (b) substituting object names out-of-vocabulary names, (c) substituting objects and colors by invented words, (d) testing a new composition of tasks, (e) substituting actions by synonyms and (f) translating the whole environment to French for the Go To task (where N indicates the performance of each agent on the Go To task in English). We plot for each agent its mean success rate over 2 seeds along with the confidence interval.</p><p>In order to better understand these results, we study the impact of varying the action space and the number of distractors. We provide both the evolution of success rate and a sample efficiency measure SE:</p><formula xml:id="formula_2">SE = 1 T T t=0 SR t (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where T is the number of steps or frames seen and SR the success rate at frame t.</p><p>Impact of the dimension of the action space In this experiment, we test the sensibility of LLMs to the size of the action space by using 3 different action spaces when trained on the Go to &lt;object&gt; task:</p><p>? The restricted action space composed of the only 3 useful actions: turn left, turn right, go forward.</p><p>? The canonical action space composed of the 6 action that can be performed in the environment with 3 useful and 3 useless actions that are pick up, drop and, toggle (they are useless here as the agent is only navigating).   <ref type="formula" target="#formula_2">3</ref>)). We report results averaged over 2 seeds for training on the Go To task.</p><p>? The augmented action space composed of 9 actions (3 useful and 6 useless with pick up, drop, toggle, sleep, do nothing and think). The last three actions have been chosen such that they clearly have no use for the Go To &lt;object&gt; task and consequently should not impact an agent that has knowledge about the world.</p><p>We conduct the tests in an environment with 1 room, 8 distractors and report results in Figure <ref type="figure" target="#fig_1">4</ref>. These results show that GFlan-T5 efficiently handles the different action spaces compared to the other agents. We hypothesize that this result is due to the LLM's ability to discard useless actions quickly at the beginning of finetuning. Nonetheless, sample efficiency degrades when GFlan-T5 is trained on the augmented action space. A possible explanation is that the LLM gives a low but not null probability to useless action (typically around 0.1). Hence, when the number of useless actions increases, a residual sampling of these actions remains.</p><p>Impact of the number of distractors In a similar fashion, we expect LLMs to be less sensitive to variations on task complexity. We assess this by plotting the evolution of sample efficiency (Equation ( <ref type="formula" target="#formula_2">3</ref>)) for different numbers of distractors: 4, 8 and 16. We conduct the tests in an environment with 1 room and show results in Figure <ref type="figure" target="#fig_2">5</ref>. Using this analysis, one can observe that the sample efficiency of GFlan-T5 is always higher and less affected by the increasing number of distractors in comparison to other baselines. We see that the performance of symbolic-PPO degrades quickly as the number of distractors increases with a success rate decreasing by 38% from 4 to 16 distractors whereas the GFlan-T5 success rate only decreases by 14%. We hypothesize that the LLM manages to quickly focus on the relevant aspect of the environment.</p><p>Thus, GFlan-T5 seems robust with similar learning curves when one increases the action space size (from 3 to 9 actions with only 3 useful ones) or the number of distractors (from 4 to 16). Such a robustness is not observed in Symbolic-PPO, DRRN, and NPAE-Flan-T5. We also provide in Appendix B an additional ablation analyzing the impact of the LLM's size B.3. The results highlight that the number of parameters has a high impact on the learning process. Indeed, we observe a strong difference on sample efficiency and asymptotic performance between a small LLM (80 million parameters) and the 780 million parameters we used here. We also plot the full learning curves for the ablation on the action space size B.4.1 and the number of distractors B.4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Q2. Generalization to new objects</head><p>In this section, we analyze how a functionally grounded agent can generalize its skills to new objects. Indeed, we expect our agents to focus on the the geometry of the environment (how objects are positioned and how their positioning is described), but not the identity of the objects themselves (e.g.Go to &lt;object&gt; should be achieved even if the object has not been seen during training). We test if this property is present in our trained agents by measuring their zero-shot performance in two environments. First, an environment with nouns not in the training vocabulary (e.g. "tree") 4 and second, an environment with invented objects (made of an invented adjectives and an invented nouns such as faze dax). <ref type="foot" target="#foot_4">5</ref> We use the environment the agent has been finetuned on (i.e. without any word substitutions) as a control environment. Results in Figure <ref type="figure">3</ref> (Q2 part) indicate that GFlan-T5 is not affected when tasks contain out-of-vocabulary nouns. Moreover, even if the GFlan-T5 success rate decreases from 0.52 in the control environment to 0.43 when it is in an environment with invented objects, it still retains strong performances compared to the baselines. These results support the hypothesis that GFlan-T5 has functionally grounded the symbols that describe the geometry of the environment and the instructions (for instance words such as "in front", or the meaning of "steps" as a distance measure)<ref type="foot" target="#foot_5">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Q3. Generalization to new tasks</head><p>In this Section, we perform generalization tests as in Section 4.  <ref type="figure">3</ref> (Q3 part) hint that, while all agents fail solve these new tasks, GFlan-T5 outperforms other baselines by reaching an 0.15 success rate compared to Flan-T5 (0.07) or Random (0.05). These low results can be explained by the fact that none of the agents managed to master the Pick up &lt;object A&gt; then go to &lt;object B&gt; or Go to &lt;object B&gt; after pick up &lt;object A&gt; tasks during training (see Appendix C). More details about the grounding of "then" and "after" are given in the Appendix D.4.</p><p>Seen tasks with synonym actions In this task, we test the robustness of our agents to actions by replacing the actions used during training by synonyms. For instance, "go to" is replaced with "move ahead"<ref type="foot" target="#foot_6">7</ref> . We expect LLMs, which already learned to map words to an embedding space, to also ground synonyms as they ground words of the environment. In this environment (see Figure <ref type="figure">3</ref> Q3 part), the success rate of GFlan-T5 is 0.36 vs 0.19 for Flan-T5. Thus the grounding of some words (here the actions) also improves the grounding of their synonyms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New language</head><p>In order to understand how far agents can generalize, we test them with a language not seen during training (French). Knowing that Flan-T5 has been pretrained with a multilingual corpus and is able to translate simple sentences, we test whether grounding in GFlan-T5 has also impacted its manipulation of other languages. However, we observe that even only for a simple navigation task (i.e. Go To), the model fails to generalize to a new language with a success rate equal to the one of the random model (0.30). We hypothesize that when too many grounded symbols are modified at once, functional grounding fails to be transferred to this new subsystem of symbols.</p><p>Complementary experiments that confirm and reinforce this result are presented in appendices D.2 and D.3.</p><p>4.4 What is the impact of using RL vs Behavioral Cloning for grounding? (Q4)</p><p>In this section, we show how interacting with an environment, enabling learning through interventions and trial-and-error, improves grounding in comparison to pure Behavioral Cloning (BC). We compare a GFlan-T5 trained on the Go To task over 400000 steps with two baselines trained with Behavioral Cloning using 400000 transitions (see Appendix F.2). For the baseline called BC-GFlan-T5, transitions are collected from GFlan-T5 finetuned on the Go To task. For BC-Bot, transitions are collected using the BabyAI procedural bot achieving a success rate of 1.</p><p>In Table <ref type="table" target="#tab_0">1</ref>, we measure the success rate of GFlan-T5 and the baselines on two tasks: Go To and Go To with invented nouns and adjectives. First, once can see that GFlan-T5 outperforms all baselines in both tasks. Second, as GFlan-T5 does not achieve a success rate of 1 on the Go To task, its collected trajectories for BC can contain deceptive transitions in comparison to the ones collected by the bot. Hence, we obtain the expected result that BC-Bot outperforms BC-GFlan-T5. Finally, we expect our agents not to be affected by an environment where nouns and adjectives are replaced by invented ones in such navigation tasks. Experiments show that GFlan-T5 is the least affected (0.82 ? 0.74) vs BC-Flan-T5 (0.58 ? 0.46) and BC-Bot (0.73 ? 0.63).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a method for functional grounding (i.e. aligning internal symbols to external dynamics so that the agent can use them to solve tasks in the environment) of LLMs in interactive textual environments based on online RL. Using our new BabyAI-Text environment, we performed several experiments studying 4 scientific questions. We showed how this method, which requires almost no environment-specific modifications on the LLM, enables to drastically improve performances to solve RL tasks in this environment as compared to zero-shot use the LLM, to supervised finetuning and to RL finetuning of non-pretrained LLMs. We showed how it boosts both sample efficiency and generalization abilities in zero-shot tests (both to new objects and several new tasks). In addition to these key results, we provided in-depth ablations showing the effect of several parameters (e.g. size) on grounding. We believe this method can act as a milestone towards grounding and using LLMs in interaction with our world. However, this study still suffers several limitations, in particular the fact that current experiments are limited to a textual environment, and the computational inefficiency when scaling up the action space and the size of the LLM. This computational inefficiency constrained this paper to using a single environment and rather small LLMs. Yet, improving computational efficiency (or access to more computational resources) could enable to leverage recent multi-modal Foundation models <ref type="bibr" target="#b2">[Alayrac et al., 2022]</ref>) for grounding LLMs in broader environments (e.g. to robotics setups <ref type="bibr" target="#b53">[Lu et al., 2021</ref><ref type="bibr" target="#b1">, Ahn et al., 2022]</ref>). Finally, these results hint that using LLMs as agent policies opens an avenue for escaping the Tabula-Rasa RL setting and creating much more sample efficient RL agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>This supplementary material provides additional results and discussion, as well as implementation details.</p><p>? Section A presents the BabyAI and BabyAI-Text environments.</p><p>? Section B, contains several additional results. We analyze the influence of observation's structure (i.e. either a symbolic image for the Symbolic-PPO agent or text for LLM based agents) in B.1. We study the influence of pretraining in B.2. We conduct several ablation tests to understand the influence of the size of the LLM B.3, the impact of the size of the action space B.4.1, and the effect of the number of distractors B.4.2.</p><p>? Section C is a qualitative analysis of GFlan-T5 during its training on the environment with a mix of tasks. We plot the evolution of the distribution of actions during training for 11 prompts.</p><p>? In Section D, we detail complementary tests for questions Q2 D.2 and Q3 D.3. We also analyze the functional grounding of temporal symbols "then" and "after"D.4.</p><p>? Section E gives specifications related to the distributed experimental setup.</p><p>? Section F reports hyperparameters and implementation details used to finetune the models using PPO or Behavioral Cloning.</p><p>? In Section G, we detail how the confidence intervals given in Figure <ref type="figure">3</ref> and Appendix D are obtained.</p><p>? In Section H, we give the word substitutions used in the generalization experiments of Q2 4.2 and Q3 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Environments</head><p>We extend the BabyAI platform <ref type="bibr" target="#b10">[Chevalier-Boisvert et al., 2019]</ref> and create a text-only version named BabyAI-Text that encapsulates BabyAI and returns linguistic observations. Figure <ref type="figure" target="#fig_3">6</ref> explains our environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 BabyAI</head><p>BabyAI Chevalier-Boisvert et al.</p><p>[2019] is a language-conditioned environment where the agent has a limited number of steps to complete a language goal. This platform relies on a gridworld environment (MiniGrid) to generate a set of complex instructions-following environments. It has been specifically designed for research on grounded language learning and related sample efficiency problems. The gridworld environment is populated with the agent and objects (of 6 possible colors): boxes, balls, doors, and keys. These entities are placed in rooms of 8 ? 8 tiles that are connected by doors that can be locked or closed. The grid is procedurally generated (i.e. objects populating an episode are randomly chosen and their position, as well as the agent's position, are also random). Some of the objects are useful for the task to achieve, while others are considered as distractors (objects can't be crossed, the agent has to either bypass them or move them). The agent can do 6 primitive actions: turn left, turn right, go forward, toggle, pick up to solve the language instruction (for instance Pick up the red box). To observe its environment, the agent has access to a partial view (i.e. it only sees the objects that belong to the 6 ? 6 grid in front of it). BabyAI proposed to access this partial view through a symbolic mapping that returns 3 matrices of size 6 ? 6. The first matrix contains which object is in the observed cells, the second gives the color of these objects, and the last one their state (e.g. locked, open). When the agent completes the task after N steps, it receives the reward r N = 1 -0.9 N H , where H is the maximum number of steps. During training, we multiply all rewards by 20 to ensure a good propagation of the rewards as per <ref type="bibr">[Mirchandani et al., 2021]</ref>. If the agent has not completed the task in the current step, the reward is 0. Additionally, BabyAI also provides visualization tools for experimenters to observe the grid and better grasp agents' behaviors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 BabyAI-Text</head><p>BabyAI-Text is a textual environment that encapsulates BabyAI and provides a description of each observation instead of a symbolic representation. A textual description consists of a list of template descriptions with the following structure:</p><p>? "You see a &lt;object&gt; &lt;location&gt;" if the object is a key, a ball, a box or a wall.</p><p>? "You see a(n) open/closed door &lt;location&gt;" , if the agent sees a door.</p><p>? "You carry a &lt;object&gt;", if the agent carries an object.</p><p>The &lt;object&gt;, is composed of an adjective (among 6 possible colours: red, blue, green, yellow, grey, purple) and a noun (among 4 possible: key, door, box, ball). The &lt;location&gt; is given as the number of steps right, left, and or forward from the agent to the object. We illustrate this in the leftmost observation of Figure <ref type="figure" target="#fig_3">6</ref> where the "yellow box" is "2 steps left and 1 step forward" from the agent (the red triangle). Thus an object described as "1 step forward" is right in front of the agent that does not need to go forward if it wants to pick that object. Walls of the room are the only spatially extended objects in BabyAI-Text. We give their location at the closest distance to the agent. See the leftmost image of Figure <ref type="figure" target="#fig_3">6</ref> for an example where the agent sees a wall "2 steps forward" and another wall "2 steps left". All of the choices for describing the environment constitute what we call the geometry of the environment, that the agent has to ground in order to succeed in the task. The presence of a fine grained geometry (with distances in steps to the different object in the room) is one of the main differences from other textual games such as TextWorld or ScienceWorld where all objects in a room are not spatially described.</p><p>Thanks to this extension, BabyAI-Text resembles a TextWorld (i.e. provides text descriptions of the observation and executes text commands) while keeping the inner minigrid environment along with BabyAI's tasks and visualization tools. Moreover, as our extension simply provides an alternative mapping of observations, one can both use and compare agents that either expect text-only observations (with BabyAI-Text) or symbolic observations (with BabyAI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Textual vs symbolic representation</head><p>In order to understand how the structure of the observation (i.e. either symbolic image using 3 matrices containing integers defining respectively the object seen, its color and property if any or text) influences the success rate of an RL agent, we compare the DRRN and Symbolic-PPO respectively trained on BabyAI-Text and BabyAI on the Go To Red Ball task. In this task, the agent has to go in front of a red ball in 1 room without any distractor (i.e. the task never changes, only the position of agent and red ball do). The task has been voluntarily chosen as trivial so that the main difference only comes from the way the information is given to the agent. Both the DRRN and Symbolic-PPO agents have a similar number of parameters ( 1M), they both use recurrent layers to deal with partial observability and use the canonical action space. Contrary to what one might assume in Figure <ref type="figure" target="#fig_4">7</ref> the PPO agent converges faster than the DRRN agent on this trivial task. Thus, symbolic observations make the learning easier for the agent. We conclude that even if language contains high-level information, understanding the link between spatial information and language is far more difficult than using symbolic information given in a matrix. Indeed, the matrix already contains a geometric bias favorable to the agent. We also want to point out that the DRRN is an off-policy RL method compared to PPO (which is on-policy) and that consequently, the DRRN was expected to be, by-design, more sample efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Impact of pretraining</head><p>We test how pretraining structured our LLM allowing for efficient finetuning. We vary which weights of Flan-T5 are kept pretrained as well as how we compute actions' probability (i.e. either using our method reusing language modeling heads or using new action heads with an MLP). We evaluate the performance of 5 models:</p><p>? The full LLM is pretrained and language modeling heads are used for actions probability: GFlan-T5 (Figure <ref type="figure">8</ref>)</p><p>? The full LLM is pretrained and new action heads are used: AFlan-T5 (Figure <ref type="figure">9</ref>)</p><p>? Only the embedding layer's weights are kept pretrained (the rest of the LLM is randomly initialized) and new action heads are used: NPAE-Flan-T5 (Figure <ref type="figure">10</ref>)</p><p>? Only the embedding layer's weights are kept pretrained (the rest of the LLM is randomly initialized) and the (randomly initialized) language modeling heads are used for actions' probability: NPE-FlanT5 (Figure <ref type="figure" target="#fig_5">11</ref>)</p><p>? All LLM's weights are randomly initialized and action heads are used: NPA-Flan-T5 (Figure <ref type="figure" target="#fig_0">12</ref>) Figure <ref type="figure">8</ref>: GFlan-T5: We use the Flan-T5 architecture and add a value head. We initialize the agent with the pretrained weights (framed in green in the diagram) including its language modeling heads to compute action probabilities. The weights of the value head are initialized randomly. GFlan-T5 stands for: grounded Flan-T5.</p><p>Figure <ref type="figure">9</ref>: AFlan-T5: We use the Flan-T5 architecture but replace the language modeling heads with action heads (that return the probability for each action) and add a value head. We initialize the embedding, the encoder and decoder parts of the agent with the pretrained weights (framed in green in the diagram) and the other weights randomly. AFlan-T5 stands for action heads Flan-T5.</p><p>Figure <ref type="figure">10</ref>: NPAE-Flan-T5: We use the Flan-T5 architecture but replace the language modeling heads by action heads and add a value head. We initialize the embedding with the pretrained weights (framed in green in the diagram) and the other weights randomly. NPAE-Flan-T5 stands for: non-pretrained with action heads and pretrained embedding Flan-T5. Figure <ref type="figure" target="#fig_0">12</ref>: NPA-Flan-T5: We use the Flan-T5 architecture but replace the language modeling heads with action heads and add a value head. We initialize all the weights randomly. NPA-Flan-T5 stands for: non-pretrained with action heads Flan-T5.</p><p>Figure <ref type="figure">13</ref> compares the training curves of the agents above on the task Go To &lt;object&gt;. GFlan-T5 has unsurprisingly the best results as it is fully pretrained. More surprisingly, AFlan-T5 takes more steps than expected to perform better than the non-pretrained networks (250000 frames). We hypothesize that during the pertaining, the last transformer layer encodes information in a space designed for language modeling heads (? 32000 heads) which is not convenient for the non-pretrained 6 actions heads. Indeed, AFlan-T5 has to make sense of this space before getting the benefits of having the rest of the network trained. This could explain why it suddenly performs better after 250000 steps. Comparing NPAE, NPA and NPE Flan-T5, we see that the presence of an action head is crucial for non-pretrained networks. Indeed, the NPE fails to learn in the given number of steps compared to NPAE and NPA that have similar learning curves. A possible explanation is that for NPE, the information flow that is backpropagated through the gradient is really small due to the huge number of language modeling heads and the few number of tokens updated (&lt; 100). On the opposite, GFlan-T5, that also uses language modeling heads but is fully pretrained, only needs a light finetuning for the necessary tokens explaining its high success rate and sample efficiency.</p><p>Figure <ref type="figure">13</ref>: Average success rate of varying pretrained weights and scoring method with standard deviation over two random seeds. We train all LLMs on the Go to &lt;object&gt; task in 1 room, with 8 distractors, the 6 canonical actions and using Flan-T5 large (780 million parameters) as architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Impact of the size of the LLM</head><p>The capacities of LLMs depend strongly on their size <ref type="bibr" target="#b27">[Kaplan et al., 2020]</ref> and many properties of these networks only appear when they are large enough <ref type="bibr" target="#b50">[Wei et al., 2022]</ref>. We consequently test the influence of the size of the LLM on our results by training 3 different GFlan-T5 (as well as the DRRN and Symbolic-PPO baselines) on the Go to &lt;object&gt; task for 400.000 steps: GFlan-T5 small (80 million parameters), GFlan-T5 large (780 million parameters) and GFlan-T5 XL (3 billion parameters).</p><p>We show the evolution of average success rate over 2 seeds in Figure <ref type="figure" target="#fig_1">14</ref> highlighting that pretraining prior knowledge only looks impactful when the network is large enough. The smaller network seems to saturate after 150.000 frames around 0.5 success rate whereas the large and XL networks quickly go beyond 0.5 success rate (within less than 25.000 frames). The difference between the learning properties of small and large models relates to the definition of an emergent behavior given by <ref type="bibr" target="#b50">Wei et al. [2022]</ref>: "an ability is emergent if it is not present in smaller models but is present in larger models". Beyond the data on which a model has been trained, the size of this model seems crucial for the acquisition of new knowledge about relations between entities during the finetuning phase.</p><p>Figure <ref type="figure" target="#fig_1">14</ref>: Impact of the size of the LLM on online RL finetuning. We conduct the tests with the Go to &lt;object&gt; task in 1 room, with 8 distractors. We measure the evolution of average success rate over 2 seeds with standard deviation for GFlan-T5 small (80 million parameters), GFlan-T5 large (780 million parameters) and GFlan-T5 XL (3 billion parameters). DRRN, NPAE-Flan-T5-large and Symbolic-PPO are given as baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Impact of varying action space and distractors</head><p>In this section, we detail the studies about the impact of varying the action space and the number of distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4.1 Impact of the dimension of the action space</head><p>One of the expected advantages of pretrained LLMs in RL is that they avoid the Tabula-Rasa paradigm and already have useful biases. In these experiments, we test the sensibility of LLMs to the size of the action space by using 3 different action spaces (restricted, canonical, augmented) when trained on the Go to &lt;object&gt; task.</p><p>We conduct the tests in an environment with 1 room, 8 distractors and in Figure <ref type="figure" target="#fig_2">15</ref> report full learning curves used to draw Figure <ref type="figure" target="#fig_1">4</ref>. We show that GFlan-T5 efficiently handles the different action spaces compared to the other agents. Its initial biases are particularly helpful when the action space is large. Indeed, when we look at the difference of sucess rate between GFlan-T5 and the second best performing agent after the 50000 first steps, there is a difference of 0.22 in the restricted settings and 0.32 in the augmented settings. That supports the hypothesis that the results are due to LLMs' ability to discard useless action quickly at the beginning of finetuning.</p><p>Figure <ref type="figure" target="#fig_2">15</ref>: Learning curves for the agents on the Go To task for different sizes of space (Restricted: 3 actions, Canonical: 6, Augmented: 9, with only the 3 actions that are useful). The success rate is given over 2 seeds along with standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4.2 Impact of the number of distractors</head><p>In Figure <ref type="figure" target="#fig_2">5</ref> we have shown that LLMs are less sensitive to variations on task complexity by plotting the evolution of sample efficiency (Equation ( <ref type="formula" target="#formula_2">3</ref>)) for different numbers of distractors: 4, 8 and 16.</p><p>In Figure <ref type="figure" target="#fig_6">16</ref> we report the full learning curves. We observe that Symbolic-PPO's performances collapse when we go from 4 to 16 distractors whereas GFlan-T5's performances remain similar. NPAE-Flan-T5's performances are also non-affected by the change in the number of distractors but in this case we suppose it is because it cannot learn the task in 400000 steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Evolution of actions distribution on evaluation prompts</head><p>To better grasp the skill acquisition dynamics when performing online RL grounding on GFlan-T5 in the multi-task setting of Section 4.1, we test at each update the LLM on 11 prompts listed in Table <ref type="table" target="#tab_1">2</ref>. We plot in Figure <ref type="figure" target="#fig_4">17</ref> the evolution of action probabilities outputted by our LLM aiming to partially decipher the changes in the LLM and visualize which skill is acquired when.</p><p>Prompts 0 and 1 are simple navigation tasks. The agent has to move in the direction given in the prompt. Looking at the corresponding plots we observe two things: first, the optimal behavior is learned in less than a hundred of updates, even for prompt 1 for which the bias at the beginning is both wrong and high. Second, from the beginning, only the navigation actions (turn left, turn right, go forward) relevant for the Go To &lt;object&gt; task have a high probability. Therefore, the Flan-T5 780M seems to already have useful biases for navigation and is able to quickly update or correct them through interactions.</p><p>We observe similar useful biases with the Pick Up &lt;object&gt; task (using prompts 5 and 6). Indeed, at the beginning, both the pick up action and navigation actions already have a high probability.</p><p>We can see that the agent struggles to ground the geometry of the environment with prompts 6 and 7. Indeed, it has to understand that an object described at "1 step forward" is in front of it such that it can pick it up or drop it directly without moving further. While GFlan-T5 eventually seems to understand it, it still shows some hesitation as proven by the fact that it gives the same probability to go forward and pick up or drop for the prompt 7 at the end of training (see Figure <ref type="figure" target="#fig_4">17</ref>).</p><p>We also verify how GFlan-T5 understands temporal constructions such as doing an action A then an action B (prompt 8) or doing an action A after doing an action B (prompt 9). These two test prompts are exactly the same except for the goal where prompt 8 uses "then" and prompt 9 uses "after" to link the two actions. We observe that when the order of actions in the task specification is the same as the one the agent has to do (i.e. prompt 8), the LLM quickly and successfully learns to choose the right action. However, when the order of actions mentioned in the goal specification is reversed (prompt 9), the LLM also ends up favoring the correct action but yet exhibits much more hesitation during training. This qualitative observation concurs with the measure of success rate given in Appendix D.4.</p><p>The prompts 2, 3 and 4 show that the agent has difficulties with the task Open &lt;door&gt;. This task is fairly complex since the agent has to infer that a key of the same color as the closed door is required to open it. In the given training budget, the agent fails to associate the need of a key with the task.</p><p>Finally we test the agent on a task that is not seen during training. It is the generalization task Pick up &lt;object A&gt; then/after Pick up &lt;object B&gt; from Q3 Section 4.3, composed from two tasks seen during training Pick up and Pick up then Go To (prompt 10). The prompt is built such that the agent has accomplished half of the instruction and has to drop the object it carries in order to pick another one. The action drop is the optimal one because it is the only one that allows the agent to complete the goal in a minimum number of steps. After 800 updates the agent begins to increase the probability of the drop action. This change is correlated to the change of distribution in prompt 7. It can be interpreted as the fact that the action drop begins to be grounded after 800 updates.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Generalization tests details D.1 Recapitulating results table</head><p>In this section we summarize the numerical results shown in Figure <ref type="figure">3</ref> with the confidence intervals calculated as explained in Appendix G.  Mix -no change 0.52 ? 0.10 0.20 ? 0.06 0.17 ? 0.02 0.14 ? 0.02 0.15 ? 0.05</p><p>Mix -unseen 0.57 ? 0.02 0.25 ? 0.16 0.16 ? 0.08 0.17 ? 0.09 in-vocabulary objects Mix -out-of-vocabulary 0.50 ? 0.11 0.20 ? 0.05 0.16 ? 0.02 0.16 ? 0.01 adjectives To further analyze results from in Section 4.2, we conduct more systematic tests on different aspects of the generalization to new words. The results are given in Table <ref type="table" target="#tab_5">4</ref>.</p><p>Unseen in-vocabulary objects During training we remove tasks whose goal contain the following objects: yellow box, red key, red door, green ball and, grey door. Nonetheless, the agent can have these objects as distractors and so have seen them during training. We assess how our agents perform on the mix of tasks with goals using only these objects. The success rate of 0.57 points out that agent is unaffected by the use of unseen in vocabulary objects.</p><p>Unseen out-of-vocabulary adjectives We perform the same test as for out-of-vocabulary nouns in Section 4.2 but this time with adjectives that do not belong to the BabyAI-Text vocabulary. We generate the prompt by exchanging the adjectives with predefined synonyms (see Table <ref type="table" target="#tab_6">9</ref>). Similarly to the test with out-of-vocabulary nouns, the test with out-of-vocabulary adjectives reveals that the agent is unaffected by this change. Indeed, the success rate is of 0.50 compared to the one of mix of tasks without change at 0.52.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Complementary tests for Q3</head><p>In the Section 4.3 we observe that the agent fails to generalize to an environment where we have change the language. We hypothesize that it is because we have modified too many grounded symbols at once. To verify this hypothesis, we test a middle-ground version, where we keep the environment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Distributed experimental setup</head><p>In order to accelerate our online RL finetuning, we first leverage a classic distributed data collection setup where 32 BabyAI-Text environments are running in parallel (all on CPUs). Our environments are run in a synchronous way, meaning that at every step, we get 32 current states and need to send 32 actions back to the environment. In very classic RL setups, policy networks are usually small and we simply batch the 32 states, feed them to the network and obtain the 32 actions' probability before sampling from them and choosing one action per environment. However, as explained in Section 3.2, our method requires |A| forward passes on a potentially very large and computationally expensive LLM in order to compute actions' probability for a single environment. Hence, we now need 32 ? |A| forward passes for a single step in all environments, which can easily become a huge bottleneck in our training process.</p><p>To overcome this, we deploy for each of our experiments in Section 4 4 instances of our LLM all running in parallel. We load and use LLMs through the Hugging Face Transformers Python library<ref type="foot" target="#foot_7">8</ref> . Our method relies on a simple client-server architecture where the RL script acts as a client sending requests to LLMs. This client communicates with a master server which dispatches the call over multiple servers (i.e. one per LLM). Once each LLM has computed its subset of the call, the master gathers results and sends the response to the RL client. We use Pytorch Distributed<ref type="foot" target="#foot_8">9</ref> with the GLOO backend for communication (hence possible both on CPU-only and GPU setups). We wrap all these in a Python library called Lamorel which can dispatch calls over the deployed LLMs from a single line of code in the RL loop asking for actions' probability for all environments. Using this method, we observe a quasi-linear scaling with the number of deployed LLMs.</p><p>Once transitions have been collected, we update our LLM using the PPO loss. For this, Lamorel helps parallelize the gradients' computation with a Distributed Data Parallelism<ref type="foot" target="#foot_9">10</ref> setup where forward and backward passes over transitions are also dispatched on the different instances of our LLMs. Then, Lamorel helps gather gradients and update each LLM (as well as their value head) the same way. In addition, Lamorel also helps define a custom computational graph linked to the LLM. We use this to add MLPs on top of our Flan-T5 model for the value head (see experiments with action heads in Section B.2).</p><p>When using Flan-T5 780M, each LLM instance is distributed (Vertical Model Parallelism<ref type="foot" target="#foot_10">11</ref> ) 2 Nvidia A100 80GB GPUs requiring thus a total of 8 Nvidia A100 80GB GPUs to run an experiment (2 GPUs ?4 LLM instances). For Flan-T5 80M and Flan-T5 3B, we respectively use 1 Nvidia V100 32GB and 4 Nvidia A100 80GB per LLM instance.</p><p>In total, to conduct experiments and ablations we use 160 GPU.hours on the Nvidia V100 32G and 18880 GPU.hours on Nvidia A100 80GB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Finetuning details F.1 PPO finetuning details</head><p>We reuse PPO's hyperparameters from <ref type="bibr" target="#b39">Ramamurthy et al. [2022]</ref> and did not perform any further tuning (see Table <ref type="table">7</ref>). We used an Adam <ref type="bibr" target="#b28">[Kingma and Ba, 2014]</ref> optimizer with the hyperparameters listed in Table <ref type="table">8</ref>). For additional heads, we used MLPs with 3 hidden layers of 1024 units with Sigmoid activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 Confidence intervals for random agents</head><p>As previously mentioned, we model the success of an agent using a Bernoulli variable X ? B(p), with p the probability of success. The measured success rate after doing n episodes is the random variable SR n = 1 n n k=0 X k which also follows Bernoulli's law B(p). Following Hoffending's inequality, we have:</p><formula xml:id="formula_4">P(|SR n -p| &gt; ?) &lt; 2 exp (-2n? 2 ) = ? (12)</formula><p>with ? the error.</p><p>Thus if we use n = 1000 episodes to measure the success rate and we want a confidence of 99%</p><p>(? = 0.01) with ? = | 1 2n ln ? 2 |, we get ? = 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Word substitutions for generalization tests</head><p>For the generalization tests given in the sections 4.2, 4.3, and D, we use the dictionaries given below to substitute some words by others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.1 Out of vocabulary</head><p>To generate descriptions with out-of-vocabulary nouns and adjectives, we modify the prompt by substituting words as per Table <ref type="table" target="#tab_6">9</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2 Invented words</head><p>Similarly to Section H.1, we apply the substitutions indicated in Table <ref type="table" target="#tab_7">10</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.3 Synonym actions</head><p>In 11, we choose the synonym actions to avoid as much as possible to reuse already used words in the finetuning (only "left" and "right" cannot be changed). To verify that Flan-T5-Large considers these words as synonyms we ask it: "Answer the following yes/no question by reasoning step-by-step. Are &lt;original action&gt; and &lt;synonym action&gt; synonymous?". We retain the synonym only if it considers that this is the case. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.4 Translation to French</head><p>We give in Table <ref type="table" target="#tab_9">12</ref> the chosen translation for the french environment (the adjectives are given in the feminine form as all the objects are feminine). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Q1. Sample efficiency: Evolution over 2 seeds of the average success rate and standard deviation on all Q1 tasks.</figDesc><graphic url="image-2.png" coords="7,167.40,476.93,277.21,184.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: We measure the impact of the action space size (3, 6 or 9 actions with always only 3 useful actions) on the sample efficiency measure (Equation (3)). We report results averaged over 2 seeds for training on the Go To task.</figDesc><graphic url="image-4.png" coords="9,108.00,72.00,186.11,124.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: We measure the impact of the number of distractors on the sample efficiency measure (Equation (3)). We report results averaged over 2 seeds for training on the Go To task.</figDesc><graphic url="image-5.png" coords="9,315.39,72.00,186.11,124.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An illustration of how our BabyAI-Text environment encapsulates BabyAI. We keep the inner minigrid environment as well as task descriptions and reward but map the partial view of the agent to a text description.</figDesc><graphic url="image-6.png" coords="18,108.00,86.40,395.99,239.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Average success rate for DRRN and Symbolic-PPO on the Go To Red Ball task with standard deviation over two random seeds. The PPO receives symbolic information and the DRRN gets textual observations.</figDesc><graphic url="image-7.png" coords="19,187.20,252.44,237.60,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: NPE-Flan-T5: We use the Flan-T5 architecture and add a value head. We initialize the embedding with the pretrained weights (framed in green in the diagram) and the other weights randomly. NPE-Flan-T5 stands for: non-pretrained with pretrained embedding Flan-T5.</figDesc><graphic url="image-11.png" coords="21,177.30,86.40,257.39,115.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Learning curves for the agents on the Go To task for different number of distractors (4, 8, 16). The success rate is given over 2 seeds with standard deviation.</figDesc><graphic url="image-16.png" coords="24,117.90,122.38,376.20,300.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="3,108.00,86.40,395.96,148.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-3.png" coords="8,108.00,217.90,395.97,200.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-15.png" coords="23,117.90,300.53,376.20,300.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-17.png" coords="28,108.00,221.39,396.01,406.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>2, but with new unseen tasks. Using these, we verify to what extent an agent is able to compose and generalize over the symbols it has grounded during finetuning. * Generalization tests for Behavioral Cloning</figDesc><table><row><cell></cell><cell>Environments</cell><cell>GFlan-T5</cell><cell cols="2">BC-GFlan-T5 BC-Bot</cell><cell>Random</cell></row><row><cell>Q4</cell><cell cols="3">Go To task no change Go To task with invented words 0.74 ? 0.004 0.46 ? 0.08 0.82 ? 0.02 0.58 ? 0.09</cell><cell>0.73 ? 0.07 0.30 ? 0.05 0.63 ? 0.08</cell></row></table><note><p>New composition of learned tasks: Pick up &lt;object A&gt; then/after pick up &lt;object B&gt; During finetuning, agents learn to do both 1) Pick up &lt;object A&gt; and 2) Pick up &lt;object A&gt; then go to &lt;object B&gt; or Go to &lt;object B&gt; after pick up &lt;object A&gt; tasks. We test in this experiment if an agents is able to compose grounded symbols to solve the new tasks Pick up &lt;object A&gt; &lt;then/after&gt; pick up &lt;object B&gt;. Results in Figure</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test prompts. The prompts' header (Possible action of the agent: turn left, turn right, go forward, pick up, drop, toggle) is not shown below as it remains the same for all prompts You see a wall 2 step left, You see a purple key 1 step left and 2 steps forward, You see a yellow key 1 step left and 1 step forward, You see a green ball 3 steps forward, You see a grey ball 1 step right and 5 steps forward, You see a green key 1 step right and 2 steps forward, You see a grey ball 1 step right and 1 step forward, You see a green key 2 steps right and 4 steps forward, You see a red box 2 steps right and 2 steps forward, Action 0: go forward Observation 1: You see a purple key 1 step left and 1 step forward, You see a yellow key 1 step left, You see a green ball 2 steps forward, You see a grey ball 1 step right and 4 steps forward, You see a green key 1 step right and 1 step forward, You see a grey ball 1 step right, You see a green key 2 steps right and 3 steps forward, You see a red box 2 steps right and 1 step forward,</figDesc><table><row><cell>Ids Tasks</cell><cell>Prompts</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>You carry a purple key, You see a wall 2 steps forward, You see a wall 5 steps left, You see a yellow key 1 step left, You see a locked purple door 2 steps forward, You see a purple ball 1 step right, Action 1: go forward Observation 2: You carry a purple key, You see a wall 1 step forward, You see a wall 5 steps left, You see a locked purple door 1 step forward,</figDesc><table><row><cell>-continued from previous page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Goal of the agent: pick up the green key then pick up the red box Task never seen in Observation 0: You carry a green key, You see a wall 4 steps forward, training to 10 Pick up &lt;object A&gt; You see a wall 4 steps left, You see a red box 1 step left, You see a purple ball analyze generalization. then pick up &lt;object B&gt; 2 steps left and 1 step forward, Figure 17: Evolution of actions' probability over training for test prompts listed in Table2.</figDesc><table><row><cell>-continued from previous page</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Generalization tests</figDesc><table><row><cell></cell><cell>Environments</cell><cell>GFlan-T5</cell><cell>Flan-T5</cell><cell>NPAE</cell><cell>DRRN</cell><cell>Random</cell></row><row><cell></cell><cell>Mix -no change</cell><cell cols="4">0.52 ? 0.10 0.20 ? 0.06 0.17 ? 0.04 0.14 ? 0.02</cell></row><row><cell>Q2</cell><cell cols="5">Mix -out-of-vocabulary 0.55 ? 0.15 0.19 ? 0.01 0.16 ? 0.05 0.15 ? 0.00 nouns</cell><cell>0.15 ? 0.05</cell></row><row><cell></cell><cell>Mix -invented nouns and adjectives</cell><cell cols="4">0.43 ? 0.12 0.20 ? 0.06 0.16 ? 0.03 0.16 ? 0.00</cell></row><row><cell>Q3</cell><cell>Pick up then/after pick up Mix -synonym actions</cell><cell cols="5">0.15 ? 0.00 0.07 ? 0.03 0.06 ? 0.01 0.06 ? 0.03 0.05 ? 0.05 0.36 ? 0.18 0.19 ? 0.03 0.16 ? 0.04 0.17 ? 0.04 0.15 ? 0.05</cell></row><row><cell></cell><cell>Go To -English Go To -French</cell><cell cols="5">0.81 ? 0.06 0.42 ? 0.01 0.31 ? 0.04 0.31 ? 0.03 0.30 ? 0.05 0.30 ? 0.03 0.26 ? 0.01 0.30 ? 0.02 0.31 ? 0.02</cell></row><row><cell cols="3">D.2 Complementary tests for Q2</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Complementary tests for Q2</figDesc><table><row><cell>Environments</cell><cell>GFlan-T5</cell><cell>Flan-T5</cell><cell>NPAE</cell><cell>DRRN</cell><cell>Random</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9 :</head><label>9</label><figDesc>Out-of-vocabulary substitutions for Nouns and adjectives</figDesc><table><row><cell cols="2">Original Word New Word</cell></row><row><cell>key</cell><cell>chair</cell></row><row><cell>ball</cell><cell>table</cell></row><row><cell>box</cell><cell>car</cell></row><row><cell>red</cell><cell>vermillion</cell></row><row><cell>green</cell><cell>jade</cell></row><row><cell>blue</cell><cell>cyan</cell></row><row><cell>purple</cell><cell>violet</cell></row><row><cell>yellow</cell><cell>golden</cell></row><row><cell>grey</cell><cell>silver</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 10 :</head><label>10</label><figDesc>Invented substitutions for Nouns and adjectives</figDesc><table><row><cell cols="2">Original Word New Word</cell></row><row><cell>key</cell><cell>dax</cell></row><row><cell>ball</cell><cell>xolo</cell></row><row><cell>box</cell><cell>azfe</cell></row><row><cell>red</cell><cell>faze</cell></row><row><cell>green</cell><cell>jatu</cell></row><row><cell>blue</cell><cell>croh</cell></row><row><cell>purple</cell><cell>vurst</cell></row><row><cell>yellow</cell><cell>gakul</cell></row><row><cell>grey</cell><cell>sil</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 11 :</head><label>11</label><figDesc>Synonym actions</figDesc><table><row><cell cols="2">Original Words Synonyms</cell></row><row><cell>turn left</cell><cell>rotate left</cell></row><row><cell>turn right</cell><cell>rotate right</cell></row><row><cell>go forward</cell><cell>move ahead</cell></row><row><cell>pick up</cell><cell>take</cell></row><row><cell>drop</cell><cell>release</cell></row><row><cell>toggle</cell><cell>switch</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 12 :</head><label>12</label><figDesc>French translation Tu vois une &lt;objet&gt;&lt;location&gt; You see a(n) open/closed door &lt;location&gt; Tu vois une porte ouverte/ferm?e &lt;location&gt; You carry a &lt;object&gt;</figDesc><table><row><cell>English</cell><cell>French</cell></row><row><cell>turn left</cell><cell>tourner ? gauche</cell></row><row><cell>turn right</cell><cell>tourner ? droite</cell></row><row><cell>go forward</cell><cell>aller tout droit</cell></row><row><cell>pick up</cell><cell>prendre</cell></row><row><cell>drop</cell><cell>l?cher</cell></row><row><cell>toggle</cell><cell>basculer</cell></row><row><cell>go to a/the adj n</cell><cell>aller ? une/la n adj</cell></row><row><cell>steps</cell><cell>pas</cell></row><row><cell>You see a &lt;object&gt; &lt;location&gt;</cell><cell></cell></row><row><cell></cell><cell>Tu portes un &lt;objet&gt;</cell></row><row><cell>key</cell><cell>clef</cell></row><row><cell>ball</cell><cell>balle</cell></row><row><cell>box</cell><cell>bo?te</cell></row><row><cell>red</cell><cell>rouge</cell></row><row><cell>green</cell><cell>verte</cell></row><row><cell>blue</cell><cell>bleue</cell></row><row><cell>purple</cell><cell>violette</cell></row><row><cell>yellow</cell><cell>jaune</cell></row><row><cell>grey</cell><cell>grise</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/flowersteam/Grounding_LLMs_with_online_RL</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://github.com/ClementRomac/lamorel</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://huggingface.co/docs/transformers/model_doc/flan-t5</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The out-of-vocabulary nouns are given in Appendix H.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>The invented objects are given in Appendix H.2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>See Section A.2 for more details on the geometry.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>A table giving all the used synonyms is given in Appendix H.3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>https://huggingface.co/docs/transformers/index</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>https://pytorch.org/docs/stable/distributed.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>https://pytorch.org/tutorials/intermediate/ddp_tutorial.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>Layers are spread across GPUs (https://huggingface.co/docs/transformers/v4.15.0/ parallelism)</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments and Disclosure of Funding</head><p>Experiments presented in this paper were carried out using the HPC resources of IDRIS under the allocation 2022-[A0131011996] made by <rs type="institution">GENCI</rs>. We would also like to thank <rs type="person">Victor Gondat</rs> for his kind help on schemas.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Go To -English 0.81 ? 0.06 0.42 ? 0.01 0.31 ? 0.04 0.31 ? 0.03 0.30 ? 0.05 Go To -French 0.30 ? 0.03 0.26 ? 0.01 0.30 ? 0.02 0.31 ? 0.02 Go To -English with 0.41 ? 0.10 0.26 ? 0.02 0.31 ? 0.01 0.33 ? 0.00 actions in French in English but actions are in French. In this setting, Table <ref type="table">5</ref> shows that the success rate of the agent (0.41) is better than both the fully french environment (0.30) and the random baseline (0.30). Moreover this improvement is not present in Flan-T5. Consequently, this observation supports that finetuned agents tend to generalize to related words in other languages. Nonetheless, this ability seems is highly dependent to the number of grounded words we modify.</p><p>D.4 LLM grounding of temporal symbols: "then" and "after"</p><p>In this experiment we observe the dynamics of functional grounding of instructions containing the temporal symbols "then" and "after" using the tasks: Pick up &lt;object A&gt; then go to &lt;object B&gt; and Go to &lt;object B&gt; after pick up &lt;object A&gt;. As the order of the action matters to have the task considered completed, a correct grounding of these symbols is crucial. Table <ref type="table">6</ref> shows that GFlan-T5 has a better grounding of these words than the non-finetuned Flan-T5 agent. Moreover, we observe a slight bias after finetuning: the agent has stronger performances for the tasks with "then" (success rate of 0.26) compared to the tasks with "after" (success rate of 0.21). We hypothesize it is easier to ground the word "then" because the order of the actions the agent must do is the same as the order in which the actions appear in the instructions. A qualitative example of this behavior is given in Appendix C (prompts 8, 9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6: Test on tasks with temporal components</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Environments</head><p>GFlan-T5 Flan-T5 NPAE DRRN Random</p><p>Mix of tasks then/after 0.23 ? 0.06 0.12 ? 0.01 0.09 ? 0.01 0.09 ? 0.02 0.04 ? 0.05 Tasks with then only 0.26 ? 0.04 0.12 ? 0.01 0.10 ? 0.003 0.10 ? 0.02 Tasks with after only 0.21 ? 0.02 0.13 ? 0.05 0.10 ? 0.03 0.10 ? 0.01 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variable Value</head><p>Learning rate 1 ? 10 -6 1 ? 10 -5 ? 1 0.9 ? 2 0.999</p><p>During our experiments, we observe that the output of LLMs with the language modeling heads tend to be small (P LLM (a i |p) &lt; 10 -9 ) as the vocabulary is large (32128 tokens) meaning that probability of tokens is very small and therefore the product of tokens probability is even smaller. Thus, once the softmax step is performed as per Equation (2), the probability distribution over the possible actions is close to uniform, preventing the pretrained LLM to use its useful bias when interacting with the environment. To tackle this issue, we use a variable temperature ? in the softmax. ? is equal to the maximum probability returned by the LLM over the action space. So the distribution over the possible actions is given by: P(a i |p) = e P LLM (ai|p)/? aj ?A e P LLM (aj |p)/? with ? = max {aj ?A} P LLM (a j |p).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Behavioral Cloning</head><p>In Section 4.4, we show how grounding using RL differs from BC. For this, we finetune Flan-T5 780M on 400.000 transitions collected on the Go To &lt;object&gt; task. As indicated in Table <ref type="table">5</ref>, GFlan-T5 obtains a 0.81 success rate on the 1000 test episodes of the Go To &lt;object&gt; task. Hence by finetuning Flan-T5 to imitate GFlan-T5, one could expect an on-par performance (or worse, but not better). We therefore use GFlan-T5 to collect 400.000 transitions and finetune Flan-T5 using them. However, the stochasticity in the GFlan-T5 policy leads to deceptive transitions in the dataset (potentially harmful for BC). We thus also assess whether using optimal transitions to finetune Flan-T5 leads to better results than GFlan-T5. To collect optimal trajectories, we use the bot provided by BabyAI and also gather 400.000 transitions on the Go To &lt;object&gt; task.</p><p>For finetuning, we use Causal Language Modeling with the same prompt as the one given to our LLM agents in Section 4 as input and the performed action as label. We use the same learning rate as the one used by <ref type="bibr" target="#b38">Rae et al. [2021]</ref> to generate Flan-T5 (i.e. 5 ? 10 -4 ) and perform a single epoch on the 400.000 examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Confidence interval</head><p>In sections 4.2 and 4.3, we perform several generalization tests. For each test we report the success rate over 2 seeds tested on 1000 episodes each. In the following, we explain how we get the 99% confidence interval.</p><p>G.1 Confidence intervals for GFlan-T5, Flan-T5 and DRRN</p><p>We model the success of an agent, trained with the seed i, on a task (i.e. episode with its associated task) using a Bernoulli variable X i ? B(p i ), with p i the probability of success of the agent . The number of successes after doing n episodes is the random variable Y i n = n k=0 X i k which follows a binomial law B(n, p i ). If n is large enough, the binomial distribution can be approximated by a normal distribution 12 . Thus we have</p><p>where p is the "mean success rate and ? the variance.</p><p>Moreover, one property of normal random variables is that if</p><p>for any X,then</p><p>Hence we obtain U ? N (U 0 + XV 0 , X? V X T + ? U |V ).</p><p>By identification with Equation <ref type="formula">4</ref>, we have</p><p>We can rewrite it using the random variable SR i the success rate of the the agent (trained with seed i) during the test time (over n trajectories).</p><p>and n is large, we can neglect this term with respect to ? in equation above (we verify at the end that we rightfully neglected it) and obtain:</p><p>Using the maximum likelihood estimation for normal random variables, we get with a 99% confidence interval:</p><p>with s the number of seeds used, p the estimator for p and ? 2 the unbiased sample variance.</p><p>12 using the Berry-Essen theorem, the approximation is good enough if n &gt; 9 p(1-p) p and n &gt; 9 p p(1-p)</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Can language models encode perceptual structure without grounding? a case study in color</title>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Kulmizev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 25th Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Michael Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Brohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keerthana</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosario</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Jauregui Ruano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><surname>Jesmonth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayant</forename><surname>Nikhil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">C</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Julian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuheng</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuang-Huei</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Parada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jornell</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Quiambao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><forename type="middle">M</forename><surname>Rettinghouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sichun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><surname>Yan</surname></persName>
		</author>
		<idno>ArXiv, abs/2204.01691</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Do as i can, not as i say: Grounding language in robotic affordances</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Flamingo: a visual language model for few-shot learning</title>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pauline</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yana</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serkan</forename><surname>Cabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengda</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sina</forename><surname>Samangooei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marianne</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahand</forename><surname>Sharifzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikolaj</forename><surname>Binkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Barreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno>ArXiv, abs/2204.14198</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to understand goal specifications by modelling reward</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyedarian</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.463</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="5185" to="5198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Experience Grounds Language</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Nisnevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">November 2020</date>
			<biblScope unit="page" from="8718" to="8735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Distributional semantics and linguistic theory</title>
		<author>
			<persName><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
		<idno>ArXiv, abs/1905.01896</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv, abs/2005.14165</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A review of abstract concept learning in embodied agents and robots</title>
		<author>
			<persName><forename type="first">Angelo</forename><surname>Cangelosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Stramandinoli</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2017.0131.Publisher</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="page">20170131</biblScope>
			<date type="published" when="1752-06">1752. June 2018</date>
			<publisher>Royal Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Integration of action and language knowledge: A roadmap for developmental robotics</title>
		<author>
			<persName><forename type="first">Angelo</forename><surname>Cangelosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Sagerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Nolfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chrystopher</forename><surname>Nehaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kerstin</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Tani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tony</forename><surname>Belpaeme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giulio</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Nori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Autonomous Mental Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Babyai: A platform to study the sample efficiency of grounded language learning</title>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Chevalier-Boisvert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salem</forename><surname>Lahlou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thien</forename><surname>Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><forename type="middle">M</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Vinodkumar Prabhakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benton</forename><forename type="middle">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiner</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toju</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anselm</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunipa</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henryk</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedant</forename><surname>Garc?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeontaek</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Spiridonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivani</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Omernick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanumalayan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Sankaranarayana Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Pellat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongwei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brennan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Saeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>D?az</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Catasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathleen</forename><forename type="middle">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Meier-Hellstern</surname></persName>
		</author>
		<author>
			<persName><surname>Eck</surname></persName>
		</author>
		<idno>ArXiv, abs/2204.02311</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Jeff Dean, Slav Petrov</pubPlace>
		</imprint>
	</monogr>
	<note>and Noah Fiedel. Palm: Scaling language modeling with pathways</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Language as a cognitive tool to imagine goals in curiositydriven exploration</title>
		<author>
			<persName><forename type="first">C?dric</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Karch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Lair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Michel</forename><surname>Dussoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cl?ment</forename><surname>Moulin-Frier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Ford Dominey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Yves</forename><surname>Oudeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Textworld: A learning environment for text-based games</title>
		<author>
			<persName><forename type="first">Marc-Alexandre</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?kos</forename><surname>K?d?r</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">A</forename><surname>Kybartas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tavian</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emery</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Layla</forename><forename type="middle">El</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Adada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CGW@IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collaborating with language models for embodied reasoning</title>
		<author>
			<persName><forename type="first">Ishita</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Kaeser Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheila</forename><surname>Babayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) LaReL workshop</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>ArXiv, abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Building open-ended embodied agents with internet-scale knowledge</title>
		<author>
			<persName><forename type="first">(</forename><surname>Linxi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanzhi</forename><surname>Jim) Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuncong</forename><surname>Mandlekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><surname>De-An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuke</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><surname>Minedojo</surname></persName>
		</author>
		<idno>ArXiv, abs/2206.08853</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Foundation models for semantic novelty in reinforcement learning</title>
		<author>
			<persName><forename type="first">Tarun</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Karkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
		<idno>ArXiv, abs/2211.04878</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The symbol grounding problem</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributional Structure</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName><surname>Harris</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-009-8467-7_1</idno>
	</analytic>
	<monogr>
		<title level="m">Papers on Syntax, Synthese Language Library</title>
		<editor>
			<persName><forename type="first">Zellig</forename><forename type="middle">S</forename><surname>Harris</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henry</forename><surname>Hi?</surname></persName>
		</editor>
		<meeting><address><addrLine>Netherlands, Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="3" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Ji</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03667</idno>
		<idno>arXiv: 1606.03667</idno>
		<ptr target="http://arxiv.org/abs/1606.03667" />
		<title level="m">Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads</title>
		<imprint>
			<date type="published" when="2016-09">September 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Chris Apps, Demis Hassabis, and Phil Blunsom</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fumin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Teplyashin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Wainwright</surname></persName>
		</author>
		<idno>ArXiv, abs/1706.06551</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sona</forename><surname>Mokra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathaniel</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.09382</idno>
		<idno>arXiv: 2005.09382</idno>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Language models as zero-shot planners: Extracting actionable knowledge for embodied agents</title>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<idno>ArXiv, abs/2201.07207</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Inner monologue: Embodied reasoning through planning with language models</title>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harris</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacky</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">R</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<idno>ArXiv, abs/2207.05608</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Jansen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.04132</idno>
		<idno>arXiv: 2107.04132</idno>
		<title level="m">A Systematic Survey of Text Worlds as Embodied Natural Language Environments</title>
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Yunfan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linxi (jim)</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><surname>Vima</surname></persName>
		</author>
		<idno>ArXiv, abs/2210.03094</idno>
		<title level="m">General robot manipulation with multimodal prompts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Scaling laws for neural language models</title>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno>ArXiv, abs/2001.08361</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno>CoRR, abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Pre-trained language models for interactive decision-making</title>
		<author>
			<persName><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clinton</forename><forename type="middle">Jia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekin</forename><surname>Aky?rek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<idno>ArXiv, abs/2202.01771</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Code as policies: Language model programs for embodied control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenlong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">R</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<idno>ArXiv, abs/2209.07753</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Aw-opt: Learning robotic skills with imitation and reinforcement at scale</title>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yevgen</forename><surname>Chebotar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohi</forename><surname>Khansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kalashnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A survey of reinforcement learning informed by natural language</title>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nantas</forename><surname>Nardelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><forename type="middle">N</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimon</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Dissociating language and thought in large language models: a cognitive perspective</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">A</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><forename type="middle">Asher</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><forename type="middle">G</forename><surname>Kanwisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evelina</forename><surname>Fedorenko</surname></persName>
		</author>
		<idno>ArXiv, abs/2301.06627</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Exploration through learned language abstraction</title>
		<author>
			<persName><forename type="first">Suvir</forename><surname>Mirchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Karamcheti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorsa</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName><surname>Ella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mapping instructions and visual observations to actions with reinforcement learning</title>
		<author>
			<persName><forename type="first">Dipendra</forename><surname>Kumar Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Francis Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">J</forename><surname>Lowe</surname></persName>
		</author>
		<idno>ArXiv, abs/2203.02155</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mapping language models to grounded conceptual spaces</title>
		<author>
			<persName><forename type="first">Roma</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth-Jane</forename><surname>Pavlick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Grigorev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Sottiaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Pajarskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">G</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iason</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">S</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kareem</forename><forename type="middle">W</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Ayoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName><surname>Bennett</surname></persName>
		</author>
		<idno>ArXiv, abs/2112.11446</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling language models: Methods, analysis &amp; insights from training gopher</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization</title>
		<author>
			<persName><forename type="first">Rajkumar</forename><surname>Ramamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiant?</forename><surname>Brantley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafet</forename><surname>Sifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bauckhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno>ArXiv, abs/2210.01241</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>ArXiv, abs/2102.12092</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Can wikipedia help offline reinforcement learning?</title>
		<author>
			<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaro</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><forename type="middle">Shane</forename><surname>Gu</surname></persName>
		</author>
		<idno>ArXiv, abs/2201.12122</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mar&apos;ia Grandury, Mario vSavsko</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth-Jane</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ili'c</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagn'e</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franccois</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Gall?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><forename type="middle">Rose</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Sasanka Ammanamanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beno?t</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olatunji</forename><surname>Villanova Del Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Ruwase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stas</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samson</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Ortiz</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Laurenccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Gokaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Simhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Soroa Etxabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Alfassy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">Kreisberg</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Nitzav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">C</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Emezue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Klamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Alexander Van Strien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><forename type="middle">G</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efrat</forename><surname>Ponferrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Levkovizh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eyal</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><forename type="middle">De</forename><surname>Bar Natan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G?rard</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Germ?n</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giada</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hady</forename><surname>Pistilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamza</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Benyamina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idris</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Abdulmumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itziar</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Gonzalez-Dios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>De La Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorg</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josephine</forename><forename type="middle">L</forename><surname>Frohberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Tobing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimbo</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludovic</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Tanguy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maraim</forename><surname>Romero Mu?oz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priscilla</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Amuok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rheza</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Harliman</surname></persName>
		</author>
		<author>
			<persName><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Roberto L'opez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salomey</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Osei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamik</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamsuddeen</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanya</forename><surname>Hassan Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somaieh</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Nikpoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhas</forename><surname>Silberberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Zink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Timponi Torrent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Thrush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilina</forename><surname>Danchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Nikoulina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Violette</forename><surname>Laippala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vrinda</forename><surname>Lepercq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaid</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Alyafeai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Talat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenglei</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabrina</forename><forename type="middle">J</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilson</forename><forename type="middle">Y</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abheesht</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Santilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Chaffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debajyoti</forename><surname>Stiegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunjan</forename><surname>Szczechla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Chhablani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshit</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hendrik</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos</forename><surname>Rozen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maged</forename><forename type="middle">S</forename><surname>Al-Shaibani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Manica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nihal</forename><forename type="middle">V</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Teehan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srulik</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taewoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tali</forename><surname>Bers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishala</forename><surname>Neeraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urmish</forename><surname>Thakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaked</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hadar</forename><surname>Uri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Tojarieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaesung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conglong</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hatim</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Bourfoune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Rasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Ryabinin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjia</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myriam</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Peyrounette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouamane</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Tazi</surname></persName>
		</author>
		<author>
			<persName><surname>Sanseviero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Cornette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?mi</forename><surname>Franccois Lavall'ee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samyam</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanchit</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">St?phane</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Requena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Baruwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne-Laure</forename><surname>Cheveleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><surname>Ligozat</surname></persName>
		</author>
		<author>
			<persName><surname>Subramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Aur'elie N'ev'eol</surname></persName>
		</author>
		<author>
			<persName><surname>Lovering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><forename type="middle">R</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehud</forename><surname>Tunuguntla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Taktasheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Voloshina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Bogdanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan-Christoph</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jekaterina</forename><surname>Kalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Zosa Forde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungo</forename><surname>Clive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liam</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marine</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miruna</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Clinciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Newton</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Serikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oskar</forename><surname>Antverg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Van Der Wal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Pais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Shavrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Verena</forename><surname>Limisiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladislav</forename><surname>Protasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Mikhailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdenvek</forename><surname>Bamberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Kasner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Rueda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Pestana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ammar</forename><surname>Feizpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananda</forename><surname>Faranak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosa</forename><surname>Santa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antigona</forename><surname>Hevia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Unldreaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arezoo</forename><surname>Aghagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aycha</forename><surname>Abdollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azadeh</forename><surname>Tammour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahareh</forename><surname>Hajihosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Behroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharat</forename><forename type="middle">Kumar</forename><surname>Olusola Ajibade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danish</forename><surname>Mu?oz Ferrandis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davis</forename><surname>Lansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ezinwanne</forename><surname>Baylor</surname></persName>
		</author>
		<author>
			<persName><surname>Ozoani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fatim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frankline</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><surname>Ononiwu ; Chenxi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chirag</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuxin</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cl?mentine</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Fourrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Le'on Perin'an</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Molano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Manjavacas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Fuhrimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giyaseddin</forename><surname>Altay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gully</forename><forename type="middle">A</forename><surname>Bayrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><forename type="middle">U</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><surname>Vrabec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Iman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isha</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Soo</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Golde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthi</forename><surname>David Posada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lokesh</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Bulchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Shinzato ; Nikolaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Muellner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patricia</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodrigo</forename><forename type="middle">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosaline</forename><surname>Canalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruisi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuele</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><surname>Garda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shlok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubhanshu</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kiblawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinee</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srishti</forename><surname>Sang-Aroonsiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><surname>Schweter</surname></persName>
		</author>
		<idno>ArXiv, abs/2211.05100</idno>
		<editor>Maiko Takeuchi, Marc P?mies, Mar?a Andrea Castillo, Marianna Nezhurina, Mario Sanger, Matthias Samwald, Michael Cullan, Michael Weinberg, M Wolf, Mina Mihaljcic, Minna Liu, Moritz Freidank, Myungsun Kang, Natasha Seelam</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Madeleine Hahn de Bykhovetz</publisher>
			<pubPlace>Bo Wang, Caio Matheus Fonseca de Brito; Nathan Dahlberg, Nicholas Michio Broad</pubPlace>
		</imprint>
	</monogr>
	<note>Sushil Pratap Bharati, T. A. Laud, Th&apos;eo Gigant, Tomoya Kainuma, Wojciech Kusa, Yanis Labrak, Yashasvi Bajaj, Y. Venkatraman, Yifan Xu, Ying Xu, Yun chao Xu, Zhee Xao Tan, Zhongli Xie, Zifan Ye, Mathilde Bras, Younes Belkada, and Thomas Wolf. Bloom: A 176b-parameter open-access multilingual language model</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno>ArXiv, abs/1707.06347</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Alfworld: Aligning text and embodied environments for interactive learning</title>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc-Alexandre</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Hausknecht</surname></persName>
		</author>
		<idno>ArXiv, abs/2010.03768</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Learning to summarize from human feedback</title>
		<author>
			<persName><forename type="first">Nisan</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">J</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<idno>ArXiv, abs/2009.01325</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">On the effect of pre-training for transformer in different modality on offline reinforcement learning</title>
		<author>
			<persName><forename type="first">Shiro</forename><surname>Takagi</surname></persName>
		</author>
		<idno>ArXiv, abs/2211.09817</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On the importance of a rich embodiment in the grounding of concepts: Perspectives from embodied cognitive science and computational linguistics</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Thill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastia</forename><surname>Pad? N</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Ziemke</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12093</idno>
		<ptr target="https://doi.org/10.1111/tops.12093" />
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="545" to="558" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Large language models still can&apos;t plan (a benchmark for llms on planning and reasoning about change)</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Sreedharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<idno>ArXiv, abs/2206.10498</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Scienceworld: Is your agent smarter than a 5th grader?</title>
		<author>
			<persName><forename type="first">Ruoyao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">Alexander</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc-Alexandre</forename><surname>C?t?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<idno>ArXiv, abs/2203.07540</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Huai Hsin Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<idno>ArXiv, abs/2206.07682</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Computer vision and natural language processing: Recent approaches in multimedia and robotics</title>
		<author>
			<persName><forename type="first">Peratham</forename><surname>Wiriyathammabhum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Summers-Stay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cornelia</forename><surname>Ferm?ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiannis</forename><surname>Aloimonos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3009906</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<idno type="ISSN">0360-0300</idno>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2016-12">dec 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">React: Synergizing reasoning and acting in language models</title>
		<author>
			<persName><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<idno>ArXiv, abs/2210.03629</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Ling</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiyang</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houdong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuedong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luowei</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengchuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Florence</surname></persName>
		</author>
		<idno>ArXiv, abs/2111.11432</idno>
		<title level="m">A new foundation model for computer</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
