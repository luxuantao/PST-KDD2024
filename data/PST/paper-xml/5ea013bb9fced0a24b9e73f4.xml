<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contents lists available at ScienceDirect Pattern Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-03-13">13 March 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuemei</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Engineering and Automation</orgName>
								<orgName type="institution">Guilin University of Electronic Technology</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<region>Guangxi</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haijian</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Guangxi Key Laboratory of Manufacturing System &amp; Advanced Manufacturing Technology</orgName>
								<orgName type="department" key="dep2">School of Mechanical and Electrical Engineering</orgName>
								<orgName type="institution">Guilin University of Electronic Technology</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<region>Guangxi</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Wu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic Engineering and Automation</orgName>
								<orgName type="institution">Guilin University of Electronic Technology</orgName>
								<address>
									<postCode>541004</postCode>
									<settlement>Guilin</settlement>
									<region>Guangxi</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Institute for Remote Sensing Science and Application</orgName>
								<orgName type="department" key="dep2">School of Geomatics</orgName>
								<orgName type="institution">Liaoning Technical University</orgName>
								<address>
									<postCode>1230 0 0</postCode>
									<settlement>Fuxin</settlement>
									<region>Liaoning</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shijie</forename><surname>Zhao</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Institute of Optimization and Decision</orgName>
								<orgName type="institution">Liaoning Technical University</orgName>
								<address>
									<postCode>1230 0 0</postCode>
									<settlement>Fuxin, Liaoning</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Guilin University of Electronic Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Guilin University of Electronic Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Liaoning Technology University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Liaoning Technology University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Contents lists available at ScienceDirect Pattern Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-03-13">13 March 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.patcog.2020.107333</idno>
					<note type="submission">Received 30 July 2019 Revised 26 February 2020 Accepted 12 March 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Remote sensing Image segmentation Riemannian manifold Manifold projection Kernel function</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image representation is the key factor influencing the accuracy of remote sensing image segmentation. Traditional algorithms rely on the pixel-wise characteristics exhibited in the feature space. They introduce spatial information by establishing the connections between neighboring pixels in the neighborhood system. But the spectral-spatial features cannot be well expressed. In this paper, a Riemannian manifold space is introduced to express the contextual information by jointly mapping the spectral features of a pixel and its neighboring ones on to it. To benefit from the expression ability and geometric properties of the Riemannian manifold, a data submanifold and a parameter submanifold are established to depict the characteristics of the detected image and all possible segmentation results. On the parameter submanifold, only points representing objects of the current segmentation are active. Then distance between a point on the data submanifold and an active point on the parameter submanifold is measured by a geodesic-kernel function. Consequently, four geodesic-kernel function-based manifold projection criteria are proposed to explore the complementation between features expressed in different feature spaces. Experiments on synthetic and real remote sensing images demonstrated that the proposed geodesic-kernel function-based manifold projection algorithm outperforms traditional ones and features expressed in different feature spaces did contain some complementary information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image segmentation, which decomposes an image into homogeneous regions, is an important task in remote sensing image processing <ref type="bibr" target="#b0">[1]</ref> . The accuracy of image segmentation has an essential influence on the subsequent image analysis and interpretation <ref type="bibr" target="#b1">[2]</ref> . Convolutional Neural Network (CNN) which can extract contextual information of an image has gain more attention these years <ref type="bibr" target="#b2">[3]</ref> . It learns features of the input image by stacking the convolutional and pooling layers. The constructed network is a nonlinear model acting as a transformation function from the input image to the output classification result. Parameters of the CNN model is estimated through training it on a large number of training samples. However, such a large training set is difficult to access, especially for remote sensing images.</p><p>Mapping an image to a spectral space is an easy way to express features of different objects. Spectral space takes the bands of the detected image as axes to establish a Cartesian coordinate system and exhibits all the pixels of the detected image as points in it. Pixels representing the same object naturally cluster in the spectral space <ref type="bibr" target="#b3">[4]</ref> . This property provides us an opportunity to segment pixels belonging to different objects according to their positions in the spectral space, automatically. Segmentation models aim to minimize the dissimilarities among pixels representing the same objects and enlarge the distance between different objects as much as possible. However, noise and outliers may cause large distance, which may result in wrong labeled points in the segmentation result. Besides, pixel-wise segmentation algorithms based on the spectral space cannot deal with textures and low frequency variations over objects.</p><p>It is a general knowledge that pixels nearby have a greater probability to belong to the same object than pixels with larger distance. In the context of image segmentation, neighborhood system is commonly used to improve the ability of segmentation alhttps://doi.org/10.1016/j.patcog.2020.107333 0031-3203/© 2020 Published by Elsevier Ltd.</p><p>gorithms to resist noise and outliers. Prior probability defined on the label field is one of the most effective way to construct the connection between neighboring pixels <ref type="bibr" target="#b4">[5]</ref> . It decreases with the number of pixels having the same label with the central one in the neighborhood system. Thus, it is able to distinguish noise, outliers and edge points on the label field. However, the connection on the label field is logical. It cannot provide enough information for image segmentation and can only be used as an axillary information for algorithms established in the spectral space.</p><p>Riemannian manifold space can represent a Gaussian probability distribution function (pdf) in the neighborhood system of a pixel as a point on Riemannian manifold. Hence, features expressed in Riemannian manifold contains not only the spectral information of the corresponding pixel, but also features of its neighboring ones. Features in Riemannian manifold space is more likely to be separated since it can express features of the detected image more completely than spectral space and the label field.</p><p>To explore the feature expression ability of different feature spaces and the complementarity among them, this paper proposes four geodesic-kernel-based manifold projection algorithms by combining the feature space and the label field with the Riemannian manifold. First, a Gaussian distribution is established in the neighborhood system of the detected image to construct connections between neighbor pixels. Then the Gaussian pdf-expressed pixels are mapped to a Riemannian manifold in which a point on the manifold represents a pixel in the detected image. To fully utilize the characteristics of features on the Riemannian manifold space, a data submanifold expressing the characteristics of the detected image and a parameter submanifold expressing all possible segmentation results are constructed. Geodesic-kernel function are used to measure the dissimilarity between points on the data submanifold and parameter submanifold. The purpose of the manifold projection-based algorithm is to find the most appropriate active points on the parameter submanifold for which points on the data submanifold have the least distance to their corresponding active points. The major contributions are summarized as follows:</p><p>1. Propose high accuracy remote sensing image segmentation algorithms by combining features expressed in different feature spaces with Riemannian manifold space. 2. Demonstrate the effectiveness of the Riemannian manifold space on feature expression. 3. Explore the complementation among features expressed in different feature spaces, namely, the Riemannian manifold space, the spectral space and the label field.</p><p>The reminder of the rest of this paper is organized as follows. Related works are introduced in Section 2 . We present the details of the manifold projection algorithm in Section 3 . The proposed four geodesic-kernel function-based manifold projection criteria are introduced in Section 4 . Experiments and analysis are carried out in Section 5 . Finally, Section 6 concludes with some discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Spectral space-based algorithms</head><p>Mean shift is a typical clustering algorithm which shifts the mean of the cluster to its center of mass <ref type="bibr" target="#b5">[6]</ref> . Recently, Yamasaki and Tanaka have studied the properties of it via regarding mean shift-based algorithms as gradient ascent with adaptive step size, which provide a new perspective for understanding it <ref type="bibr" target="#b6">[7]</ref> . Similarly, Fuzzy C-Means (FCM) minimizes the distances between pixels and their clustering centers, and assigns pixels to their nearest cluster when the centers of the clusters are appropriate <ref type="bibr" target="#b7">[8]</ref> . It is widely used in image segmentation due to its simplicity <ref type="bibr" target="#b8">[9]</ref> . However, pixels far away from cluster centers are easily to be wrongly assigned. To suppress the effect of noise, Mirghasemi et al. used an adaptive wavelet shrinkage to restrain noise and outliers and then segment the image with FCM <ref type="bibr" target="#b9">[10]</ref> . The reason caused poor performance on noise and outliers of the traditional spectral space-based algorithms is that the segmentation model cannot describe various shapes and scales of different objects. To release the restrictions on the cluster scales, Fan et al. proposed a weighted FCM, which can better fit the features in the spectral space <ref type="bibr" target="#b10">[11]</ref> . Weighted kernel based FCM combines the advantages of kernel function and the weighted FCM, thus it is able to obtain much better segmentation results <ref type="bibr" target="#b11">[12]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Neighborhood system-based algorithms</head><p>Neighboring pixels have a greater chance to represent the same object than pixels with a large distance. This common sense can be used to improve the robustness of segmentation algorithms to noise and outliers. Markov Random Field (MRF) model is an efficient way to construct the connection between neighboring pixels <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> . It defines the prior probability according to the labels of pixels in the neighborhood system. The prior probability decreases with the number of pixels having the same label with the central pixel. Farag et al. employed the Support Vector Machines (SVM) to define the class conditional probability and combined it with the MRF-based prior distribution <ref type="bibr" target="#b14">[15]</ref> . The proposed segmentation model is solved by maximum a posteriori. Chatzis and Varvarigou used the prior distribution as a cluster-size controller in the introduced KL-based constraint <ref type="bibr" target="#b15">[16]</ref> . Due to the smoothing effect of the prior probability defined on the label field, the proposed algorithm outperforms other spectral space-based ones. Guided filter is an efficient way to smooth images. Guo et al. performed FCM on the smoothed images and proposed a noisy image segmentation algorithm by integrating guided filter into fuzzy clustering algorithm <ref type="bibr" target="#b16">[17]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Riemannian manifold space</head><p>Image representation is very important for image segmentation <ref type="bibr" target="#b17">[18]</ref> . Riemannian manifold space is based on the characteristics that a probability distribution in the Euclidean space can be expressed by a point on a Riemannian manifold <ref type="bibr" target="#b18">[19]</ref> . Zhao et al. assumed the feature of a pixel is characterized by a Gaussian pdf established in its neighborhood system, and then map the Gaussian pdf to a Riemannian manifold <ref type="bibr" target="#b19">[20]</ref> . Then, a point on the Riemannian manifold represents a pixel in the image. Since the mapping process takes the interaction between a pixel and its neighboring ones into consideration, features in the Riemannian manifold space is more likely to be separated compare with the pixel-wise expression in the spectral space. Besides, pixels representing the same object linear distributed in the Riemannian manifold space, which makes it more suitable for image segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Manifold projection</head><p>High precision image segmentation algorithms mostly benefit from region-based models, which can represent spectral and spatial features simultaneously. Inspired by this, a Gaussian model is constructed in neighborhood system and its pdf is used to describe the features of the central pixel <ref type="bibr" target="#b19">[20]</ref> . This expression does not only contain the characteristics of the central pixel but also the features of its neighbors. Then, the pdf-expressed image is mapped to a Riemannian manifold, in which the curved surface has an positive effect on separating different objects. To segment the image based on the Riemannian manifold space, a data submanifold and a parameter submanifold are constructed to represent the features of the detected image and its corresponding segmentation result. The final segmentation result is obtained by manifold projection between the two submanifolds <ref type="bibr" target="#b19">[20]</ref> . The details are as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neighbor mapping</head><formula xml:id="formula_0">Let X = { x i | i = 1 , 2 , . . . n } represent the detected image, where</formula><p>x i is the intensity of the i th pixel, and n is the number of pixels of the image. Assume μ i and σ i are the mean and variance of pixels in the neighborhood system of the i th pixel, then the Gaussian pdf of the i th pixel is</p><formula xml:id="formula_1">p(x i ) = 1 √ 2 πσ i exp − (x i − μ i ) 2 2(σ i ) 2<label>(1)</label></formula><p>Then the Gaussian pdf is rewritten as</p><formula xml:id="formula_2">p(x i | μ i , σ i ) = exp μ i x i (σ i ) 2 − (x i ) 2 2(σ i ) 2 − (μ i ) 2 2(σ i ) 2 − ln ( √ 2 πσ i ) (2) Let r i 1 = x i ; r i 2 = (x i ) 2 θ 1 i = μ i (σ i ) 2 ; θ 2 i = 1 2(σ i ) 2 (3)</formula><p>Then the variable-independent part in Eq. ( <ref type="formula">2</ref>) can be represented as</p><formula xml:id="formula_3">ψ i (θ i ) = (μ i ) 2 2(σ i ) 2 + ln ( √ 2 πσ i ) = − (θ 1 i ) 2 4 θ 2 i + 1 2 ln − π θ 2 i (4)</formula><p>Afterward, Eq. ( <ref type="formula" target="#formula_1">1</ref>) can be wrote as</p><formula xml:id="formula_4">p(x i | θ 1 i , θ 2 i ) = exp r ik θ k i − ψ (θ i )<label>(5)</label></formula><p>In this paper, the Einstein summation convention r ik θ k i = k r ik θ k i is employed <ref type="bibr" target="#b20">[21]</ref> . Finally, the detected image is mapped to Riemannian manifold space constructed by Gaussian pdf and each of its pixel can be represented as a point on the manifold with coordinate (θ 1 i , θ 2 i ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Manifold projection</head><p>Assume all the points mapped from the image construct a submanifold of the Riemannian manifold space, called data submanifold. Then the data submanifold can express the characteristics of the detected image. Assume pixels representing the same object subject to a Gaussian distribution, a class of the segmentation result can be expressed as a point on the Riemannian manifold. A parameter submanifold is also a submanifold of the Riemannian manifold space expressing all possible classes of segmentation results. Only points representing classes of current segmentation result are activated on the parameter submanifold. As both the data submanifold and the parameter submanifold are submanifolds of the Riemannian manifold space, points on the data submanifold can be projected to active points on the parameter submanifold. There are numerous curves connecting two points on the data submanifold and the parameter submanifold. among which geodesic is the shortest one. To calculate the geodesic, a dual coordinate sys-</p><formula xml:id="formula_5">tem { η k | k = 1 , 2 } is defined as η 1 = ∂ψ (θ ) ∂θ 1 = − θ 1 2 θ 2 η 2 = ∂ψ (θ ) ∂θ 2 = (θ 1 ) 2 4(θ 2 ) 2 − 1 2 θ 2<label>(6)</label></formula><p>Coordinate system { θ k } can be expressed by coordinate system { η k } as</p><formula xml:id="formula_6">θ 1 = − η 1 (η 1 ) 2 − η 2 θ 2 = 1 2(η 1 ) 2 − 2 η 2 (7)</formula><p>According to the Legendre transformations <ref type="bibr" target="#b21">[22]</ref> , potential function</p><formula xml:id="formula_7">under the coordinate system { η k } is ϕ(η) = θ k η k − ψ (θ ) = 1 2 ln (−(η 1 ) 2 + η 2 ) − 1 2 − 1 2 ln (2 π ) (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>Then the geodesic between point p and q can be calculated as</p><formula xml:id="formula_9">D (p : q ) = (ψ (θ )) p + (ϕ(η)) q − (θ k ) p (η k ) q (9)</formula><p>According to Eq. ( <ref type="formula">9</ref>) , points on the data submanifold can be projected to active points on the parameter submanifold.</p><p>As for the active points on the parameter submanifold, they can be updated according to the projection result, The mean and variance of the j th class can be calculated as</p><formula xml:id="formula_10">μ j = i ∈ R j x i # R j σ j = i ∈ R j (x i − μ j ) 2 # R j − 1 (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>Then the coordinates of the updated points on the parameter submanifold can be calculated according to Eqs. ( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_5">6</ref>) . The manifold projection algorithm introduced in this section is called MP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Geodesic-kernel functions</head><p>Mapping the detected image to Riemannian manifold space significantly improves the separability of pixels, but there still exist some overlapped ones, especially pixels located in the boundary of objects. Kernel function can map the detected image to higher dimensional space to improve their separability and remains low computational complexity in low dimensional space. Therefore, we propose four geodesic-kernel functions to evaluate the dissimilarity between points on the data submanifold and active points on the parameter submanifold.</p><p>Traditional spectral space expresses features of pixels independently and uses label field to construct connections between pixels in the neighborhood system. Riemannian manifold space is able to express the characteristics of a pixel and its neighboring ones, simultaneously. It uses a Gaussian distribution to describe the connection between neighboring pixels. Therefore, it can provide more consistent information compared with traditional spectral space and the label field. Even if the Riemannian manifold space can express the features of the detected image more effectively, there must exist certain complementation between different feature spaces due to their preference in feature expression. To further explore the complementation between different feature spaces, posterior probability defined on traditional spectral space and prior probability defined on label field are introduced in the proposed geodesic-kernel function-based manifold projection criterion. Detailed descriptions are as follows.</p><p>Radial Basis Function (RBF) is a non-linear function which can map low dimensional data to higher dimensional space <ref type="bibr" target="#b22">[23]</ref> . It is</p><formula xml:id="formula_12">defined as RBF = exp {−γ || v p − v q || 2 }</formula><p>, where v p is the intensity of point p, v q is the intensity of point q and || v p − v q || 2 is a function measuring the dissimilarity between point p and point q . The geodesic D ( p : q ) is a nonlinear function of v p and v q which can be used as a dissimilarity measure. Therefore, using D ( p : q ) instead of || v p − v q || 2 , a new geodesic-kernel function can be defined as</p><formula xml:id="formula_13">f pq = exp{−γ D (p : q ) } (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>where p is a point on the data submanifold and q is an active point on the parameter submanifold. We call this geodesic-kernel function based manifold projection algorithm MPGK in this paper.</p><p>Features expressed in the Riemannian manifold space is a mixture of features of a pixel and its neighboring ones. It can reveal the connection of pixels in the neighborhood system. But the contribution of the central pixel is considered the same as the others in the neighborhood. While traditional spectral space expresses features of pixels independently. Combining the features of Riemannian manifold space and traditional spectral space can highlight the effect of a pixel and remain the connections between neighboring pixels at the same time. Under the same assumption that pixels belonging to the same object subject to a Gaussian distribution, posterior of point p on the data submanifold belonging to the object represented by the active point q on the parameter submanifold is defined as</p><formula xml:id="formula_15">s pq = 1 √ 2 πσ q exp − (x p − μ q ) 2 2(σ q ) 2<label>(12)</label></formula><p>where x p is the pixel vector of point p in the detected image, μ q and σ q are the mean and variance of all the pixels belonging to the object represented by the point q on the parameter submanifold. Combining the posterior probability and the geodesic-kernel function, the MPGK_PoP manifold projection criteria is defined as</p><formula xml:id="formula_16">v pq = s pq exp{−γ D (p : q ) }<label>(13)</label></formula><p>MRF is an efficient way to describe connections between pixels on the label field. It defines a prior probability according to the number of pixels having the same label with the central pixel in the neighborhood system. The prior probability is large when the central pixel locates in the middle of an object and it is small when the central pixel locates near the boundary. Employing MRF model to construct connections between neighboring pixels is a common way in image segmentation task. Although the contributions of neighboring pixels are considered in the Riemannian feature space, the logical connection in MRF model can improve the expression ability in some extend. Therefore, the geodesic-kernel function based on prior probability (MPGK_PiP) is defined as follows.</p><p>w pq = r pq exp{−γ D (p : q ) } (</p><p>where r pq is the prior probability which is defined as</p><formula xml:id="formula_18">r pq = exp − β p ∈ N p V (l p = l q , l p ) c q =1 exp − β p ∈ N p V (l p = l q , l p ) (<label>15</label></formula><formula xml:id="formula_19">)</formula><p>where β expresses the strength of the connection between neighboring pixels, N p is the set of pixels in the neighborhood system of point p, l p is the label of point p, c is the number of objects, the potential function V is defined as</p><formula xml:id="formula_20">V (l p , l p ) = 0 , l p = l p 1 , l p = l p (<label>16</label></formula><formula xml:id="formula_21">)</formula><p>To further explore the complementation of different expressions, features in the Riemannian manifold space, traditional spectral space and on the label field are merged. Then the induced geodesic-kernel function based on multi-feature spaces (MPGK_mFS) is defined as</p><formula xml:id="formula_22">u pq = s pq exp − γ D (p : q )</formula><p>r pq <ref type="bibr" target="#b16">(17)</ref> In this paper, we propose four geodesic-kernel function-based manifold projection criteria to measure the dissimilarity between points on the data submanifold and the parameter submanifold.</p><p>The four criteria utilize the mapping ability of kernel function to separate pixels belonging to different objects in higher dimensional spaces. In addition, the four criteria combines the features expressed in different spaces to explore complementary expression ability. With the complementary information between different feature spaces, we are able to improve the feature expression ability and segmentation accuracy. The process of the proposed manifold projection algorithm with geodesic-kernel function is detailed in Algorithm 1 .</p><p>Algorithm 1 Manifold projection algorithm with kernel function based geodesic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Require:</head><p>The size of neighborhood systems b;The number of objects c;Initial labels for each pixel L (0) ; Ensure: Optimal segmentation result, L * ;</p><p>1: Calculate the Gaussian pdf of each pixel in the neighborhood system according to Equation (1); 2: Map the image to Riemannian manifold according to Equations ( <ref type="formula">2</ref>)-( <ref type="formula" target="#formula_4">5</ref>); 3: Calculate the coordinates of points on the data submanifold and active points on the parameter submanifold under coordinate systems { θ k } and { η k } ;</p><p>4: Classify points on data submanifold by the proposed geodesickernel function-based manifold projection criteria (reference Equation ( <ref type="formula" target="#formula_13">11</ref>) or ( <ref type="formula" target="#formula_16">13</ref>) or ( <ref type="formula" target="#formula_17">14</ref>) or ( <ref type="formula">17</ref>)), and obtains the segmentation result L * ; 5: Update active points on parameter submanifold according to Equation (10); 6: Return L * if the iteration is over, otherwise go to step 1;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental results and analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Segmentation on synthetic remote sensing image</head><p>The proposed algorithms are applied to a simple synthetic remote sensing image with 3 distinguishable objects (as shown in Fig. <ref type="figure" target="#fig_0">1 (a)</ref>) and an synthetic image which have large inter-class similarity and large intra-class dissimilarity as shown in Fig. <ref type="figure">5 (a)</ref>. To validate the effectiveness of the proposed geodesic-kernel function based manifold projection criteria and explore the complementation between different f eature spaces, we em ploy the following algorithms as comparison. Fuzzy C-Means (FCM) is a typical clustering-based algorithm which segments objects according to their positions in the spectral space <ref type="bibr" target="#b7">[8]</ref> . Mahalanobis distance based FCM (MFCM) uses the Mahalanobis distance as dissimilarity measure, aiming to overcome the sensitivity to cluster shapes and scales of Euclidean distance in the feature space <ref type="bibr" target="#b23">[24]</ref> . FCM_S algorithm introduces a constraint in image domain, that neighboring pixels contribute to the segmentation of the central pixel <ref type="bibr" target="#b24">[25]</ref> . Markov Random Model-based FCM (MRF_FCM) used the MRF model to establish the connection between pixels in the neighborhood system to improve the possibility of neighboring pixels having the same label <ref type="bibr" target="#b25">[26]</ref> . Kullback-Leibler (KL)-based FCM (KLFCM) employed the posterior probability as the dissimilarity and used the prior probability to control the scale of clusters in the KL-based constraint <ref type="bibr" target="#b15">[16]</ref> . Kernel function-based FCM defined the dissimilarity between pixels by RBF kernel function <ref type="bibr" target="#b26">[27]</ref> . Riemannian manifold space-based Manifold Projection (MP) algorithm <ref type="bibr" target="#b19">[20]</ref> acts as a baseline for the proposed four geodesic-kernel-based image segmentation algorithms, namely MPGK, MPGK_PoP, MPGK_PiP and MPGK_mFS. The corresponding parameters in the above mentioned six spectral space-based algorithms are shown in Table <ref type="table">1</ref> . m and λ represent the fuzziness of the algorithm and β controls the contribution of neighboring pixels. The larger β is, the more effect the neighboring pixels contribute. Artificially defined parameters </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1</head><p>Parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms</head><p>Fuzzy factor Neighborhood</p><formula xml:id="formula_23">FCM m = 2 - MFCM λ = 2 - FCM_S m = 2 β = 0 . 9 MRF_FCM λ = 2 . 3 β = 0 . 9 KLFCM λ = 2 - KFCM λ = 1 . 5 -</formula><p>are not needed in the five Riemannian manifold space-based image segmentation algorithms. Besides the given parameters, all the algorithms performed in this paper need to initial segmentation results randomly.</p><p>To explore the feature expression ability of the Riemannian manifold space, the spectral space and the label field, two synthetic images with different com plex textures are produced. Fig. <ref type="figure" target="#fig_0">1 (a</ref>) is composed by farmland, artificial land and forest from outside to the inner and we call them regions I, II and III. The intensity are similar in regions I-II, while the variation is obvious in region III. Fig. <ref type="figure" target="#fig_0">1 (b)-(l</ref>) are segmentation results of the first synthetic image. To compare the performances of the employed algorithms more easily, the differences between the obtained segmentation results and the standard segmentation results are shown in Fig. <ref type="figure" target="#fig_1">2 (b)-(l)</ref>.</p><p>FCM uses Euclidean distance to measure the dissimilarity between pixels. It is suitable for images whose objects appear to be multi-dimensional sphere in the spectral space. However, most objects turn out to be ellipsoid when they are expressed in the feature space. Therefore, Fig. <ref type="figure" target="#fig_0">1 (b</ref>) contains some segmentation noise especially in regions I and III, which is more clear in Fig. <ref type="figure" target="#fig_1">2 (b</ref>). Mahalanoibs distance takes the scale of each object into consideration. It can segment region III better than FCM, but region I contains more noise (as shown in Figs. <ref type="figure" target="#fig_0">1 (c</ref>) and 2 (c)). FCM_S introduces the contribution of neighboring pixels, it is efficient in removing single noise and outliers. Accordingly, the segmentation result shown in Fig. <ref type="figure" target="#fig_0">1 (d</ref>) is better than Fig. <ref type="figure" target="#fig_0">1 (b) and (c</ref>). From Fig. <ref type="figure" target="#fig_1">2 (d)</ref> we can see that mis-segmented pixels concentrate in the upper left corner and the boundaries. MRF model construct a logical connection between neighboring pixels according to their labels. The segmentation result is better than FCM and MFCM, while it is not as well as FCM_S (as shown in Fig. <ref type="figure" target="#fig_1">2 (e)</ref>). KLFCM combines the features in both spectral space and label field. Nevertheless, affected by noise contained in the original remote sensing image, there is no significant improvement on segmentation result of KLFCM (as shown in Figs. 1 (f) and 2 (f)). Kernel function is able to map data to high dimensional spaces, while as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (g) it cannot obtain better segmentation result when used on noisy data as shown in the upper left corner shown in Fig. <ref type="figure" target="#fig_1">2 (g)</ref>. MP constructs the connections between neighboring pixels by Gaussian pdf, and the features represented in Riemannian manifold space contains more information for segmentation compared with features expressed in other feature spaces. Therefore, segmentation shown in Fig. <ref type="figure" target="#fig_0">1 (h</ref>) is much better than the above mentioned algorithms. The mis-segmented pixels mainly locate in the edge of the central square ( Fig. <ref type="figure" target="#fig_1">2 (h)</ref>). Segmentation results of MPGK is similar to that of MP. On the basis of MPGK, posterior probability based on spectral space in introduced. Therefore, the segmentation results contains less noise than that of MPGK as shown in Fig. <ref type="figure" target="#fig_0">1 (j</ref>). On the contrary, introducing prior probability based on the label field has no distinct improvement on the segmentation result as shown in Fig. <ref type="figure" target="#fig_0">1 (k</ref>) and the mis-segmented pixels are similar to those in MP as shown in Fig. <ref type="figure" target="#fig_1">2 (k)</ref>. Combining the features expressed in Riemannian manifold space, spectral space and the label field has a significant improvement and its segmentation results outperforms other algorithms obviously as shown in Figs. 1 (l) and 2 (l).</p><p>To evaluate the segmentation results quantitatively, we calculate the user accuracy, product accuracy and overall accuracy and list them on Table <ref type="table" target="#tab_0">2</ref> . From Table <ref type="table" target="#tab_0">2</ref> we can see that, 6 segmentation results obtained from FCM_S, MP, MPGK, MPGK_PoP, MPGK_PiP and MPGK_mFS obtain overall accuracy higher than 98.0%, where five out of six of them are based on Riemannian manifold space. Compared with FCM, segmentation results of MFCM and KFCM are not improved. On the contrary, the overall accuracy decreases slightly. Combining the features expressed by the spectral space and label field improves the segmentation result in some extend, but its accuracy is not comparable to that of MP. And combining posterior and prior probability based on MP improves the performance significantly.</p><p>To further explore the contribution of different f eatures expressed by different feature spaces, the distribution of different objects in the spectral space are shown in Fig. <ref type="figure" target="#fig_2">3</ref> , where x axis represents the gray level and the y axis represents the frequency of each gray level. The red diamond, green star and blue circle express the point belonging to regions I, III and II. FCM only uses the characteristics of image in the feature space, therefore, the distributions are separated by thresholds in the feature space as shown in Fig. <ref type="figure" target="#fig_2">3 (b)</ref>. MFCM uses the Mahalanobis distance as the dissimilarity measure. It takes variance of each distribution into account, but some points in region II is segmented to region I (as shown in Fig. <ref type="figure" target="#fig_2">3 (c)</ref>). FCM_S introduces the contribution of neighboring pixels to smooth the effect of noise and outliers. Therefore, the distribution of segmentation result (shown in Fig. <ref type="figure" target="#fig_2">3 (d)</ref>) is similar with the standard distribution shown in Fig. <ref type="figure" target="#fig_2">3 (a)</ref>. MRF model defines a prior probability to express the probability of a pixel belonging to different classes according to the labels of neighboring pixels. But the improvement is slight compared to FCM. KLFCM introduces the features expressed in the spectral space and on the label field. However, there is no obvious improvement in Fig. <ref type="figure" target="#fig_2">3 (f</ref>) compared with Fig. <ref type="figure" target="#fig_2">3 (b)</ref> or (e). Accuracies of kernel function-based algorithms rely on the choice of kernel function. RBF is one of the most simple kernel functions and its scope of application is limited. Therefore, the fitting result of KFCM shown in Fig. <ref type="figure" target="#fig_2">3</ref> (g) contains some wrongly recognized points belonging to regions I and II. Fig. <ref type="figure" target="#fig_2">3 (h)-(l</ref>) have similar fitting results with Fig. <ref type="figure" target="#fig_2">3</ref> (a) and their corresponding segmentation accuracies are the highest among all the employed algorithms. As the frequencies in the feature space shown in Fig. <ref type="figure" target="#fig_2">3</ref> is statistics of the corresponding classification results, the difference between figures in Fig. <ref type="figure" target="#fig_2">3</ref> is not as obvious as those in Figs. <ref type="figure" target="#fig_1">1 and 2</ref> . Combined with Figs. <ref type="figure" target="#fig_1">1 and 2</ref> and Table <ref type="table">1</ref> , it is easy to find that, introducing the prior probability defined on the label field cannot improve the segmentation result compared to MPGK. While introducing features expressed by the spectral space or both features expressed by the spectral space and the label field is able to improve the segmentation result significantly. The above analysis demonstrates that, there exists some complementary information between different expression style and combining them with an appropriate algorithm can improve the segmentation accuracy.</p><p>To explore the distribution of pixels in the Riemannian manifold space, we flatten the curved surface and show the distribution of points on the flattened coordinate system as shown in Fig. <ref type="figure">4</ref> , where the x axis represents θ 1 and the y axis represents θ 2 . The range of θ 1 is more than 0, while the range of θ 2 is less than 0. From Fig. <ref type="figure">4</ref> we can see that features represented in the Riemannian manifold are linearly distributed, which means they are more easily to be separated compared with features expressed in other feature spaces. MP has the most similar distribution with the standard distribution. But there exist some mis-segmented points in Fig. <ref type="figure">4 (c)-(f</ref>) and the mis-segmented points distributed far away from the coordinate origin. In fact, the most difficult pixels to segment concentrate on the overlapped region near the coordinate  origin. We will devote our energy to resolving this problem in the future work. At present, the proposed segmentation algorithms already outperforms existing ones. Fig. <ref type="figure">5</ref> (a) is more complicated compared with Fig. <ref type="figure" target="#fig_0">1 (a)</ref>. Name regions from outside to inside I, II and III. Region I is nature grass land which has a high variance in the intensity of pixels. Region II is the surface of a road and region III is a building roof with distinct texture features. There exist high dissimilarity inside region III and high similarity between region II and III. Fig. <ref type="figure">5 (b)-(l</ref>) are segmentation results of FCM, MFCM, FCM_S, MRF_FCM, KLFCM, KFCM, MP, MPGK, MPGK-PoP, MPGK-PiP, and MPGK-mFS. Fig. <ref type="figure" target="#fig_4">6 (b)-(l</ref>) express the differences between the segmentation results in Fig. <ref type="figure">5 (b)-(l</ref>) and the standard segmentation in Fig. <ref type="figure" target="#fig_4">6 (a)</ref>.</p><p>As the various of intensities of pixels in region I is large, FCM, MFCM, FCM_S and MRF_FCM cannot segment this region as one object. On the contrary, they segment regions II and III as one single object due to their similarity intensities. As shown in Fig. <ref type="figure" target="#fig_4">6 (b)-(e)</ref>, almost all of the pixels in region II are mis-segmented. KLFCM combines posterior probability and prior probability and is able to distinguish different regions. KFCM maps pixels in the original image to higher dimensional spaces, and can also recognize different objects. Mis-segmented pixels mainly concentrate in region III ( Fig. <ref type="figure" target="#fig_4">6 (f)</ref>). KFCM can segment region III much better as shown in Fig. <ref type="figure">5 (g</ref>). While the segmentation result in the upper right of region II is not satisfactory ( Fig. <ref type="figure" target="#fig_4">6</ref> (g)). Fig. <ref type="figure">5</ref> (h)-(l), which are based on the Riemannian manifold space obtain much better segmentation results compared with the above-mentioned algorithms basing on the spectral space. Among the Riemannian manifold based algorithms, MPGK_mFS, which combines the Riemannian manifold space, the spectral space and the label field outperforms the others.</p><p>The user accuracy, product accuracy and overall accuracy of the second synthetic image are shown in Table <ref type="table" target="#tab_1">3</ref> . It is easy to find that, FCM, MFCM, FCM_S and MRF_FCM, who cannot distinguish regions II and III, have an overall accuracy less than 45%. KLFCM can recognize different regions, consequently its overall accuracy is much higher than the above-mentioned algorithms (94.0%). Overall accuracy of KFCM is 92.8% since it did not introduce the contribution of neighboring pixels like KLFCM did. MP obtains an overall accuracy of 94.4%. Overall accuracy obtianed from MPGK is similar (94.5%).</p><p>Introducing the posterior probability defined in feature space cannot improve the overall accuracy compared with MPGK. However, introducing the prior probability defined on the label field has a negative effect and its overall accuracy decreases to 94.3%. Combining both the posterior probability and the prior probability brings 1.5% increase in the overall accuracy due to the complementary information provided by different feature spaces. That means the different f eature spaces express the features in different way and there exist complementary information between them.</p><p>For both the first and the second synthetic images, combining all three feature spaces obtains the best segmentation results. When using two feature spaces, combining the Riemannian manifold space and the spectral space (MPGK-PoP) is better than combining the Riemannian manifold space and the label field (MPGK-PiP) or combining the spectral space and the label field (KLFCM). As for only one feature space, MP outperforms FCM and MFCM, and even FCM_S, MRF_FCM, KLFCM, and KFCM. Experimental results show that the Riemannian manifold space has a stronger ability to express the features of the detected image. It is obvious that the Riemannian manifold space can describe the connections between neighboring pixels better than the label field, in which the connections are expressed in a logical way. The differences of features expressed by the Riemannian manifold space and the spectral space is the most. In addition, combining all the feature spaces boosts the performance. The distribution of the second synthetic image is shown in Fig. <ref type="figure" target="#fig_5">7</ref> . From the standard distribution shown in Fig. <ref type="figure" target="#fig_5">7</ref> (a), we can see that the intensities of regions II and III are close and there is a clear overlap between them. On the contrary, although intensities of region I has a large variance, it has little overlap with those of regions II and III. Even though the segmentation results of FCM, MFCM, FCM_S, and MRF_FCM seems similar, but the distribution of intensities in the feature space various. That means, the reasons caused unsatisfactory segmentation results are different. FCM segments pixels according to their cluster characteristics in the spectral space. Therefore, its distribution shown in Fig. <ref type="figure" target="#fig_5">7</ref> (b) seems like there exist a threshold parting the intensities of region I into two. MFCM uses the Mahalanobis distance as the dissimilarity measure to fit the scale of different clusters. But it cannot segment pixels belonging to region I as one object. Distribution in the feature space ( Fig. <ref type="figure" target="#fig_5">7 (c</ref>)) shows that MFCM segment the summit of region I as one object. FCM_S and MRF_FCM have similar reasons inducing fault segmentation results. They introduce the contribution of neighboring pixels and separate the distribution of region I as two distributions with a small overlap. The introduced neighborhood system performs on the overlapping regions between them. KLFCM combines the features in the feature space and in the label field. Its recognition ability is better than using one of the expressedfeatures. Therefore, it can separate the main part of the three regions. KFCM map the original image into high dimensional spaces, which improves the separability of the data. Therefore, it also recognize the three objects. But it did not consider the effect of neighborhood system. Accordingly, its wrongly segmented pixels is obvi-ously more than those of KLFCM. The distribution of the Riemannian manifold space-based algorithms are similar with that of the standard distribution since the differences among statistical results are small. The segmentation results of Riemannian manifold spacebased ones are much better than the spectral space-based ones.</p><p>The distributions of the second synthetic image in the Riemannian manifold space is also flattened and shown in Fig. <ref type="figure" target="#fig_6">8</ref> . We can find that points representing regions II and III has an obvious overlap in the standard distribution shown in Fig. <ref type="figure" target="#fig_6">8 (a)</ref>. MP segment the points mostly according to their distribution in the Riemannian manifold space. Therefore, a lot of point in region III shown in Fig. <ref type="figure">5</ref> (h) are segmented to region II. Introducing features from other spaces also introduces some mis-segmented points. However, combining the Riemannian manifold space, the spectral space and the label field is able to improve the accuracy of region III as shown in Fig. <ref type="figure" target="#fig_6">8 (f)</ref>. Overall, introducing auxiliary information contributes in segmenting points laid in the overlapped region. In Fig. <ref type="figure" target="#fig_6">8</ref> , it is easy to find the difference between MP to MPGK_mFS algorithms ( Fig. <ref type="figure" target="#fig_6">8 (b)-(f)</ref>), but they appears to be similar when displayed in the spectral space as shown in Fig. <ref type="figure" target="#fig_5">7 (h)-(l)</ref>. It means in the Riemannian manifold space, it is more easily to find the reason causing inaccurate segmentation result compared with those distributions shown in the spectral space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Segmentation on real remote sensing images</head><p>To validate the proposed algorithms and explore the complementation between different feature spaces, the above-mentioned algorithms are performed on real remote sensing images as shown in Fig. <ref type="figure" target="#fig_7">9</ref> . FCM only uses the features expressed in the spectral space. Consequently, it is sensitive to noise and outliers. Fig. <ref type="figure" target="#fig_7">9</ref> (a2)-(f2) contains obvious noise in the segmentation result. MFCM takes the scale of clusters into account, and is able to improve the robustness to noise and outliers. Therefore, Fig. <ref type="figure" target="#fig_7">9</ref> (b3),(d3) and (e3) contain less noise than corresponding segmentation results of FCM. However, there exists some wrongly classified objects shown in Fig. <ref type="figure" target="#fig_7">9</ref> (a3) and (c3). FCM_S introduces the contribution of neighboring pixels. Therefore its recognition ability has obvious improvement. In addition, noise and outliers are suppressed. How-ever, it cannot recognize the light part in Fig. <ref type="figure" target="#fig_7">9</ref> (f1) as FCM and MFCM. MRF_FCM uses the MRF model to construct the connection between neighboring pixels. It is able to recognize the light part in Fig. <ref type="figure" target="#fig_7">9</ref> (f1). But noise has been enhanced in Fig. <ref type="figure" target="#fig_7">9</ref> (a5) and (b5). KLFCM combines the features expressed in the spectral space and on the label field, its segmentation results are better than FCM_S' (as shown in Fig. <ref type="figure" target="#fig_7">9</ref> (a6)-(f6)). But the enhanced noise still exist due to the introduction of neighborhood system. KFCM maps the original image to higher dimensional spaces to improve the separability. It obtains similar segmentation results as KLFCM. In general, Riemannian manifold based algorithms outperforms others as shown in Fig. <ref type="figure" target="#fig_7">9</ref> . Segmentation results of MP has strong rationality and are less affected by noise and outliers. However, the noise on the roof in Fig. <ref type="figure" target="#fig_7">9</ref> (a8) is obvious. Introducing the kernel function solves the problem in some extend. Therefore, MPGK obtains better segmentation results as shown in Fig. <ref type="figure" target="#fig_7">9</ref> (a9)-(f9). MPGK_PoP and MPGK_PiP combines the features expressed in the Riemannian manifold with those expressed in the spectral space, and on the label field, respectively. Their segmentation results are similar with those obtained from MPGK. MPGK_PoP obtains better segmentation results on Fig. <ref type="figure" target="#fig_7">9</ref> (b10) and (e10), while MPGK_PiP obtains better result on Fig. <ref type="figure" target="#fig_7">9</ref> (a11). MPGK_mFS combines features expressed in all the three feature spaces mentioned-above, and its segmentation results is more regional (as shown in Fig. <ref type="figure" target="#fig_7">9 (a12)</ref>). On the other hand, some noise is heavily enhanced as shown in Fig. <ref type="figure" target="#fig_7">9</ref> (d12).</p><p>Overall, Riemannian manifold space-based algorithms obtains better performance compared with other algorithms. That means Riemannian manifold space has stronger ability to express features of the detected image. MPGK can be considered as a kernel function, but its feature expression ability depends on the calculation of geodesic. Therefore, its segmentation results are similar with those of MPGK. MPGK_PoP and MPGK_PiP uses features expressed in spectral space and on the label field as axillary information and they are suitable for different images. This indicate that the three mentioned feature spaces express different f eatures of the detected image and some of them have strong complementarity. Combining all the features can fully utilize the complementary features and obtains better segmentation results as shown in Fig. <ref type="figure" target="#fig_7">9</ref> (a12)-(f12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Analysis of parameters and computational complexity</head><p>Size of neighborhood systems has a strong impact on the final segmentation results. The impact has been discussed in the former work in <ref type="bibr" target="#b19">[20]</ref> . As MPGK-based algorithms have similar foundation with MP, the influence of size of neighborhood systems are similar. The larger the size of neighborhood system is, the smoother the segmentation results. Meanwhile, some detailed information may also be lost. The proposed Riemannian manifold space-based algorithms also need the predefined number of objects as the spectral space-based ones. Besides, the initial labels for each pixel is randomly generated.</p><p>MPGK needs to map the detected image to the Riemannian manifold space, and the computational complexity is O ( N ), the manifold projection and active candidate update process needs to be performed n times with a computational complexity of O ( N ), where n is the iteration. Therefore, the computational complexity of MPGK is (2 n + 1) O (N) . MPGK_PoP and MPGK_PiP introduces the calculation of posterior probability and prior probability respectively. Their computational complexity is (3 n + 1) O (N) . MPGK_mFS employs both the posterior and and the prior probability. That induces a computational complexity of (4 n + 1) O (N) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we proposed four geodesic-kernel function-based manifold projection criteria on the basis of features expressed in the Riemannian manifold space. In the proposed algorithms, RBF kernel function is used as a bridge to integrate features expressed in different feature spaces. Then the proposed algorithms are compared with spectral space-based ones to explore the feature expression ability and the complementation among the Riemannian manifold space, the spectral space and the label field. Experimental results show that the five Riemannian manifold space-based algorithms outperform the six spectral space-based ones. That means features expressed in the Riemannian manifold space are more easily to be separated. Riemannian manifold space can express the contextual information of the detected image since the characteristics of a point represent the statistical feature of a neighborhood system centered on the corresponding pixel. While characteristics of a point in the spectral space can only express the spectral feature of the corresponding pixel. Combining it with label field improves the feature expression ability in some extend, but not as strong as the Riemannian manifold space.</p><p>By introducing RBF kernel function, we are able to explore the complementation between different feature spaces. MPGK_PoP, which integrated feature in the Riemannian manifold space and the spectral space, outperforms MPGK_PiP and KLFCM. That indicates the information expressed in the two feature spaces is complementary. Actually, Riemannian manifold space can express most of the information that can be expressed in the spectral space and on the label field. Therefore, combining the spectral space or the label field can only improve the overall accuracy slightly. But integrating all the information contained in the three feature spaces has a great improvement on the performance of the algorithm. In the future work, we will further explore the feature expression ability of Riemannian manifold space, and concentrate on the linearly of pixels representing the same object as shown in Figs. <ref type="figure" target="#fig_6">4 and 8</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Competing Interest</head><p>The authors state that there is no conflict on the interest of this manuscript.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The first synthetic image and its segmentation results.</figDesc><graphic url="image-6.png" coords="5,99.32,308.00,407.08,94.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Differences between obtained segmentation results and the standard segmentation result of the first synthetic image.</figDesc><graphic url="image-9.png" coords="6,90.32,308.00,407.08,94.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Distributions of the first synthetic image.</figDesc><graphic url="image-13.png" coords="7,99.80,456.86,405.67,102.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Distributions of the first synthetic image in flattened Riemannian manifold.</figDesc><graphic url="image-16.png" coords="8,89.48,355.64,407.14,94.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Differences between obtained segmentation results and the standard segmentation result of the second synthetic image.</figDesc><graphic url="image-21.png" coords="10,90.50,308.00,407.08,94.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Distributions of the second synthetic image.</figDesc><graphic url="image-25.png" coords="11,99.80,456.68,405.67,102.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Distributions of the second synthetic image in flattened Riemannian manifold.</figDesc><graphic url="image-27.png" coords="12,90.02,188.00,405.61,99.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Segmentation on real remote sensing images, where (a1)-(f1) are original remote sensing image; (a2)-(f2) are segmentation results of FCM; (a3)-(f3) are segmentation results of MFCM, (a4)-(f4) are segmentation results of FCM_S; (a5)-(f5) are segmentation results of MRF_FCM; (a6)-(f6) are segmentation results of KLFCM. Segmentation on real remote sensing images, where (a7)-(f7) are segmentation results of KFCM; (a8)-(f8) are segmentation results of MP; (a9)-(f9) are segmentation results of MPGK, (a10)-(f10) are segmentation results of MPGK-PoP; (a11)-(f11) are segmentation results of MPGK-PiP; (a12)-(f12) are segmentation results of MPGK-mFS.</figDesc><graphic url="image-33.png" coords="13,110.30,490.58,384.07,55.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc>Accuracy of segmentation results of the first synthetic image (%).</figDesc><table><row><cell>Algorithm</cell><cell>Index</cell><cell>Region I</cell><cell>Region II</cell><cell>Region III</cell></row><row><cell>FCM</cell><cell>User Accuracy</cell><cell>98.0</cell><cell>99.3</cell><cell>90.9</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>97.2</cell><cell>98.2</cell><cell>96.2</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>97.4</cell><cell></cell></row><row><cell>MFCM</cell><cell>User Accuracy</cell><cell>98.5</cell><cell>99.5</cell><cell>81.0</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>97.2</cell><cell>98.1</cell><cell>98.6</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>95.8</cell><cell></cell></row><row><cell>FCM_S</cell><cell>User Accuracy</cell><cell>98.1</cell><cell>99.7</cell><cell>95.7</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>98.8</cell><cell>98.3</cell><cell>96.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>98.2</cell><cell></cell></row><row><cell>MRF_FCM</cell><cell>User Accuracy</cell><cell>98.2</cell><cell>99.3</cell><cell>91.0</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>97.2</cell><cell>98.3</cell><cell>96.7</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>97.5</cell><cell></cell></row><row><cell>KLFCM</cell><cell>User Accuracy</cell><cell>97.9</cell><cell>99.3</cell><cell>92.1</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>97.5</cell><cell>98.2</cell><cell>95.7</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>97.5</cell><cell></cell></row><row><cell>KFCM</cell><cell>User Accuracy</cell><cell>98.7</cell><cell>99.2</cell><cell>81.0</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>93.7</cell><cell>98.3</cell><cell>98.6</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>95.8</cell><cell></cell></row><row><cell>MP</cell><cell>User Accuracy</cell><cell>96.9</cell><cell>99.8</cell><cell>98.6</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>99.6</cell><cell>96.7</cell><cell>94.5</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>98.0</cell><cell></cell></row><row><cell>MPGK</cell><cell>User Accuracy</cell><cell>96.9</cell><cell>99.8</cell><cell>98.6</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>99.5</cell><cell>96.7</cell><cell>94.4</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>98.0</cell><cell></cell></row><row><cell>MPGK_PoP</cell><cell>User Accuracy</cell><cell>98.3</cell><cell>99.8</cell><cell>98.3</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>99.5</cell><cell>98.3</cell><cell>97.2</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>98.8</cell><cell></cell></row><row><cell>MPGK_PiP</cell><cell>User Accuracy</cell><cell>96.8</cell><cell>99.8</cell><cell>98.6</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>99.6</cell><cell>96.7</cell><cell>94.4</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>98.0</cell><cell></cell></row><row><cell>MPGK_mFS</cell><cell>User Accuracy</cell><cell>98.5</cell><cell>100.0</cell><cell>99.8</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>98.3</cell><cell>97.5</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>99.1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Accuracy of segmentation results of the second synthetic image (%).</figDesc><table><row><cell>Algorithm</cell><cell>Index</cell><cell>Region I</cell><cell>Region II</cell><cell>Region III</cell></row><row><cell>FCM</cell><cell>User Accuracy</cell><cell>99.9</cell><cell>2.0</cell><cell>31.9</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>47.3</cell><cell>1.9</cell><cell>100.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>40.8</cell><cell></cell></row><row><cell>MFCM</cell><cell>User Accuracy</cell><cell>98.6</cell><cell>0.3</cell><cell>31.8</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>50.1</cell><cell>0.2</cell><cell>100.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>41.8</cell><cell></cell></row><row><cell>FCM_S</cell><cell>User Accuracy</cell><cell>100.0</cell><cell>2.6</cell><cell>31.9</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>54.2</cell><cell>2.2</cell><cell>100.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>44.7</cell><cell></cell></row><row><cell>MRF_FCM</cell><cell>User Accuracy</cell><cell>99.9</cell><cell>2.0</cell><cell>31.9</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>47.5</cell><cell>2.0</cell><cell>100.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>40.9</cell><cell></cell></row><row><cell>KLFCM</cell><cell>User Accuracy</cell><cell>99.0</cell><cell>85.4</cell><cell>96.5</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.2</cell><cell>63.7</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>94.0</cell><cell></cell></row><row><cell>KFCM</cell><cell>User Accuracy</cell><cell>99.1</cell><cell>95.0</cell><cell>70.4</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>80.8</cell><cell>90.7</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>92.8</cell><cell></cell></row><row><cell>MP</cell><cell>User Accuracy</cell><cell>99.0</cell><cell>85.9</cell><cell>99.1</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.9</cell><cell>65.0</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>94.4</cell><cell></cell></row><row><cell>MPGK</cell><cell>User Accuracy</cell><cell>99.0</cell><cell>86.0</cell><cell>99.0</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.9</cell><cell>65.5</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>94.5</cell><cell></cell></row><row><cell>MPGK_PoP</cell><cell>User Accuracy</cell><cell>98.8</cell><cell>86.4</cell><cell>99.2</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.8</cell><cell>65.9</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>94.5</cell><cell></cell></row><row><cell>MPGK_PiP</cell><cell>User Accuracy</cell><cell>99.0</cell><cell>85.6</cell><cell>99.0</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.9</cell><cell>64.1</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>94.3</cell><cell></cell></row><row><cell>MPGK_mFS</cell><cell>User Accuracy</cell><cell>99.0</cell><cell>89.9</cell><cell>99.1</cell></row><row><cell></cell><cell>Product Accuracy</cell><cell>100.0</cell><cell>97.9</cell><cell>76.2</cell></row><row><cell></cell><cell>Overall Accuracy</cell><cell></cell><cell>96.0</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by National Natural Science Foundation of China ( 41801233 , 41761087 ).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Review on digital image segmentation techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Vidhyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Revathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sahaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ashwini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vanitha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Res. J. Eng. Technol. (IRJET)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">02</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hypergraph p -laplacian regularization for remotely sensed image recognition</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1585" to="1595" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on deep learning techniques for image and video semantic segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Orts-Escolano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Villena-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martinez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="41" to="65" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fuzzy model-based clustering and its application in image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="141" to="157" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Blood vessel segmentation from fundus image by a cascade classification framework</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="331" to="341" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Salient object detection based on meanshift filtering and fusion of color information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="977" to="985" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Properties of mean shift</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tanaka</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2019.2913640</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Pattern Recognition with Fuzzy Objective Function Algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bezdek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Brain image segmentation based on FCM clustering algorithm and rough set</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Manogaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="12386" to="12396" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain-independent severely noisy image segmentation via adaptive wavelet shrinkage using particle swarm optimization and fuzzy c-means</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirghasemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Andreae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="126" to="150" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Single point iterative weighted fuzzy c-means clustering algorithm for remote sensing image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2527" to="2540" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Study on the improved fuzzy clustering algorithm and its application in brain image segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput. J</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">105503</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Segmentation of sidescan sonar imagery using Markov random fields and extreme learning machine</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lendasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Oceanic Eng</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="502" to="513" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Markov random fields integrating adaptive interclasspair penalty and spectral similarity for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W J L C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2420" to="2534" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A unified framework for map estimation in remote sensing image segmentation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El-Baz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1617" to="1624" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A fuzzy clustering approach toward hidden Markov random field models for enhanced spatially constrained image segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chatzis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Varvarigou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1351" to="1361" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integrating guided filter into fuzzy clustering for noisy image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digit. Signal Process</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="235" to="248" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hessian-regularized multitask dictionary learning for remote sensing image recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="821" to="825" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>S.-I. Amari</surname></persName>
		</author>
		<author>
			<persName><surname>Nagaoka</surname></persName>
		</author>
		<title level="m">Methods of Information Geometry</title>
				<imprint>
			<publisher>American Mathematical Soc</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">191</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Manifold based on neighbour mapping and its projection for remote sensing image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">General intensity transformations and differential invariants</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M J</forename><surname>Florack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The partial legendre transformation for plurisubharmonic functions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Kiselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invent. Math</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="148" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Kernel methods on Riemannian manifolds with Gaussian RBF kernels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2464" to="2477" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mahalanobis distance based on fuzzy clustering algorithm for image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digit. Signal Process</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A modified fuzzy c-means algorithm for bias field estimation and segmentation of MRI data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N F A A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Yamany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moriarty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="199" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improving the runtime of MRF based method for MRI brain segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmadvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Daliri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Math. Comput</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="808" to="818" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A new approach to TS fuzzy modeling using dual kernel-based learning machines</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3660" to="3665" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
