<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intervention Harvesting for Context-Dependent Examination-Bias Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-24">24 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhichong</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intervention Harvesting for Context-Dependent Examination-Bias Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-24">24 May 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3331184.3331238</idno>
					<idno type="arXiv">arXiv:1811.01802v3[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>examination bias</term>
					<term>unbiased learning-to-rank</term>
					<term>propensity estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate estimates of examination bias are crucial for unbiased learning-to-rank from implicit feedback in search engines and recommender systems, since they enable the use of Inverse Propensity Score (IPS) weighting techniques to address selection biases and missing data. Unfortunately, existing examination-bias estimators are limited to the Position-Based Model (PBM), where the examination bias may only depend on the rank of the document. To overcome this limitation, we propose a Contextual Position-Based Model (CPBM) where the examination bias may also depend on a context vector describing the query and the user. Furthermore, we propose an effective estimator for the CPBM based on intervention harvesting. A key feature of the estimator is that it does not require disruptive interventions but merely exploits natural variation resulting from the use of multiple historic ranking functions. Realworld experiments on the ArXiv search engine and semi-synthetic experiments on the Yahoo Learning-To-Rank dataset demonstrate the superior effectiveness and robustness of the new approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>• Information systems → Learning to rank.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>While implicit feedback (e.g., clicks, dwell time) is an abundant and attractive source of data in most information-retrieval applications (e.g., personal search, email search, recommendation), its use for learning-to-rank (LTR) is challenging due to its biased nature. To address this bias problem, Joachims et al. <ref type="bibr" target="#b19">[19]</ref> proposed a counterfactual inference approach, providing an unbiased LTR framework via Empirical Risk Minimization. A key requirement for the effectiveness of this approach is an accurate estimate of the examination bias, which describes how likely a user is to discover a particular result. For example, a result is less likely to be discovered at position 10 than at position 1. Estimates of the examination bias enable the use of Inverse Propensity Score (IPS) weighting techniques, which make modeling and estimating examination bias equivalent to propensity estimation for unbiased LTR.</p><p>There are two key limitations of existing propensity estimation methods for LTR <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b27">27]</ref>. First, existing methods are restricted to the Position-Based Model (PBM) <ref type="bibr" target="#b9">[9]</ref>, which only models how examination changes with the rank of the result. Second, existing methods treat all queries uniformly, even though the examination bias is likely to vary from query to query. For example, users may examine results in navigational queries (i.e., search queries entered with the intention of finding a particular website or webpage) differently compared to informational queries (i.e., search queries for a broad topic for which there could be thousands of relevant results). To overcome these limitations, a naive approach would be to train a separate PBM for each context -say one for navigational and one for informational queries -simply by partitioning the data. However, this is feasible only when there is a small number of discrete contexts, and it does not apply to cases where contexts are described by arbitrary feature vectors. The latter is a highly desirable use case, since it is natural to represent the context by features describing the query (e.g., query length), features describing the candidate set (e.g., size), and features describing the user (e.g., age).</p><p>In this paper, we address these limitations of the PBM and present a new Contextual Position-Based Model (CPBM) that greatly extends the expressiveness of the PBM. Instead of having a single examination parameter for each rank that is shared among all queries, we show how the CPBM can model examination dependent on arbitrary context vectors through a deep network. Furthermore, we present an AllPairs estimator <ref type="bibr" target="#b2">[3]</ref> for learning CPBM models from log data. For training, our estimator harvests implicit interventions that are already available in most operational systems. In particular, the estimator only requires (not necessarily randomized) log data from at least two ranking functions that were deployed on the system in the past. The resulting deep network can then be used to compute context-dependent propensities for LTR algorithms like <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b19">19]</ref>. We evaluate the fidelity of the CPBM model and the effectiveness of the estimator in real-world experiments on the ArXiv full-text search engine and in semi-synthetic experiments on the Yahoo Learning-to-Rank Challenge dataset <ref type="bibr" target="#b7">[7]</ref>.</p><p>In most information retrieval systems, large amounts of implicit feedback are logged automatically and serve as an attractive source of training data. However, it is known that this type of data suffers from various biases due to both the system and the user, such as position bias <ref type="bibr" target="#b17">[17]</ref>, presentation bias <ref type="bibr" target="#b22">[22]</ref> and trust bias <ref type="bibr" target="#b18">[18]</ref>.</p><p>To handle biases in a principled way, Joachims et al. <ref type="bibr" target="#b19">[19]</ref> introduced an unbiased learning-to-rank framework, which is a consistent learning approach despite biased feedback. It relies on IPS weighting first developed in causal inference and survey sampling <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b24">24]</ref>. IPS has been commonly adopted for unbiased evaluation and learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b25">25]</ref>. However, because the propensity in the unbiased LTR setting represents the unknown bias with which a user examines a document, this propensity needs to be estimated.</p><p>Existing propensity-estimation methods for LTR are based on the Position-Based Model (PBM) <ref type="bibr" target="#b23">[23]</ref>. The most effective methods use randomized interventions <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b26">26]</ref>, which unfortunately degrade the user's search experience. To avoid such interventions, Wang et al. <ref type="bibr" target="#b27">[27]</ref> proposed a regression-based Expectation-Maximization (EM) algorithm, and Ai et al. <ref type="bibr" target="#b3">[4]</ref> proposed a learning algorithm that learns propensity models together with the ranking model. Unfortunately, both approaches involve learning an accurate relevance model, which is just as hard as the LTR problem itself. The approach of Agarwal et al. <ref type="bibr" target="#b2">[3]</ref> avoids both randomized interventions and relevance modeling by exploiting click data from multiple loggers as implicit interventions. In our work, we extend their approach to the Contextual Position-Based Model (CPBM) for improved accuracy.</p><p>Beyond the PBM, many other click models for ranked search exist. However, they were designed for inferring relevance, not propensities. One example is the Cascade model <ref type="bibr" target="#b10">[10]</ref>, where users scan documents top-down until a relevant document is found. Built upon the PBM and the Cascade model, more complex models like UBM <ref type="bibr" target="#b13">[13]</ref>, DBN <ref type="bibr" target="#b8">[8]</ref>, CCM <ref type="bibr" target="#b14">[14]</ref> and CSM <ref type="bibr" target="#b5">[6]</ref> were proposed to infer relevance judgments from click logs. It is an open question in how far these models can be adapted for propensity estimation as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE CONTEXTUAL POSITION-BASED MODEL</head><p>Modeling the examination bias is crucial for learning to rank from implicit feedback, since it confounds the feedback signal. We start by reviewing the Position-Based Model, as it is arguably the simplest model for correcting the examination bias in learning to rank from implicit feedback. As shown by Joachims et al. <ref type="bibr" target="#b19">[19]</ref>, the parameters of the PBM can serve as propensity estimates, enabling the use of IPS weighting for unbiased learning-to-rank. The PBM captures that the rank of a result has a strong influence on whether a result is examined (i.e. viewed and evaluated as a prerequisite for any subsequent feedback like a click or a rating) by a user, where higher-ranked results are typically more likely to be examined than results further down the ranking. Suppose that for a particular query q, result d is displayed at position k. Let C be the random variable corresponding to a user clicking on d, and let E be the random variable denoting whether the user examines d.</p><p>Then according to the Position-Based Model <ref type="bibr" target="#b9">[9]</ref>,</p><formula xml:id="formula_0">Pr(C = 1|q, d, k) = Pr(E = 1|k) rel(q, d),<label>(1)</label></formula><p>where rel(q, d) ∈ {0, 1} is the binary relevance of document d for query q.</p><p>While Pr(E = 1|k) can be used as an estimate of the examination propensity <ref type="bibr" target="#b19">[19]</ref>, it is a rather simplistic model since it assumes that examination does not vary across queries. However, it is implausible that navigational queries share the same propensity curve with informational queries, and we will validate in our experiments that such dependencies exist in real-world search engines. More broadly, we argue that examination behavior not only varies across queries, but that it varies across contexts x more generally. This context x includes the query itself and features describing the query (e.g., query length), features describing the candidate set (e.g., size), and features describing the user (e.g., age). To be able to model these dependencies, we propose a new model -called the Contextual PBM (CPBM) -where the examination propensity can depend on the observed context x in addition to the position as follows.</p><formula xml:id="formula_1">Pr(C = 1|x, d, k) = Pr(E = 1|k, x) rel(x, d).</formula><p>(</p><formula xml:id="formula_2">)<label>2</label></formula><p>Since the context x contains all the information about its corresponding query q, we can drop the query q from our notation. Through its dependence on context x, the CPBM can represent different propensity curves Pr(E = 1|k, x) w.r.t. position k for each query context x, instead of assuming that all queries share the same examination curve Pr(E = 1|k) like in the PBM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ESTIMATING CPBM MODELS</head><p>While the increased expressiveness of the CPBM is clearly desirable, it raises several challenges when estimating the model from the data. In particular, instead of just estimating k max scalar parameters Pr(E = 1|k) like in the PBM, where k max is the maximum length of the presented rankings (say 10 or 20), the CPBM requires estimating a context-dependent propensity model Pr(E = 1|k, x), which in the following will be represented as a neural network. Furthermore, estimating Pr(E = 1|k, x) is challenging since we typically do not observe ground truth for rel(x, d) such that it is difficult to attribute the lack of a feedback signal to a lack of examination or a lack of relevance. After reviewing the shortcomings of a naive generative modeling approach in the next subsection, we will exploit the fact that randomized interventions can be used to control for relevance.</p><p>In particular, we will show how reusing logged click data from multiple ranking functions provides such intervention data for the CPBM under reasonable assumptions, eliminating the need for explicit interventions that affect the user experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generative Modeling</head><p>The first thought one may have is to estimate a CPBM via a standard generative-modeling approach with both examination and relevance as latent variables. In fact, Wang et al. <ref type="bibr" target="#b27">[27]</ref> have proposed such an approach for the simpler problem of estimating the parameters of the PBM. Let L = {(x j , d j , k j , c j )|j ∈ [N ]} be a sample of N observations with one tuple for each context-document pair (x j , d j ), indicating with k j the position of d j in the ranking and with c j ∈ {0, 1} whether it was clicked. Extending the approach of Wang et al. <ref type="bibr" target="#b27">[27]</ref> to the CPBM, the conditional log likelihood</p><formula xml:id="formula_3">f 0 P = 1 2 x d 2 d 1 d 3 d 4 d 5 d 1 d 5 d 3 d 2 d 4 P = 1 2</formula><p>No Swap Swap f0(x) f0(x)</p><p>(a) Swap Intervention between positions 1 and 3.  </p><formula xml:id="formula_4">f 1 d 2 d 5 f 2 f 3 P = 1 3 P = 1 3 P = 1 3 d 3 d 1 d 4 d 1 d 2 d 3 d 4 d 5 d 2 d 4 d 5 d 1 d 3 x f1(x) f2(x) f3(x) (b) Intervention Harvesting (A/B Test). f 1 f 2 d 1 d 2 d 3 d 4</formula><formula xml:id="formula_5">(L) = j ∈ L c j log p k j (x j )r (x j , d j ) + (1 − c j ) log 1 − p k j (x j )r (x j , d j ) ,</formula><p>where p k (x) := Pr(E = 1|k, x) is a context-dependent propensity model and r (x, d) := rel(x, d) is a document-dependent relevance model. Both relevance and examination are latent, and even for the simpler PBM model it was found that the propensity estimates can be far off <ref type="bibr" target="#b2">[3]</ref>. A key shortcoming of this approach is that it requires learning the relevance rel(x, d) of all individual documents without any direct supervision, which is just as difficult as the learningto-rank problem itself. This means that the relevance model will typically be misspecified and thus bias the propensity estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Explicit Swap Interventions</head><p>To overcome the need for modeling the unobserved relevance of all query-document pairs, we will employ an interventional approach that controls for relevance at each position. To start, let us first review how explicit interventions have been used for estimating p k := Pr(E = 1|k) in the PBM <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b26">26]</ref>. The PBM requires estimating a single vector p = [p 1 , p 2 , ..., p k max ] with p k for each position k ∈ [1, k max ]. In this case, randomly swapping results at positions k and k ′ before presenting the ranking <ref type="bibr" target="#b19">[19]</ref> makes the expected relevance of results at the two positions equal. An illustrative example is given in Figure <ref type="figure" target="#fig_1">1a</ref> for k = 1 and k ′ = 3. Through the randomized swap, documents d 1 and d 3 have a 50% probability of being presented either at position k = 1 or at position k ′ = 3. So, over the distribution of queries that are subject to this randomized swapping, the distribution of documents in position k = 1 is identical to the distribution of documents in k = 3, and thus is their expected relevance. This randomized control for relevance resolves the ambiguity in attributing the lack of clicks to either a lack of relevance or a lack of observation.</p><p>More formally, denote with C k k,k ′ and C k ′ k,k ′ the random variables indicating clicks on positions k and k ′ respectively for the set of training queries where the results at positions k and k ′ are swaprandomized with probability q = 0.5. Since the results are swapped uniformly, the expected relevance at positions k and k ′ is controlled to be equal at these positions, and thus expected click-through rates reveal the relative propensities via</p><formula xml:id="formula_6">p k p k ′ = E[C k k,k ′ ] E[C k ′ k,k ′ ]</formula><p>.</p><p>This means that the ratio of the observed click-through rates is a consistent estimator of the relative propensities p k and p k ′ under the PBM <ref type="bibr" target="#b19">[19]</ref>. Note that knowing the relative propensities with respect to a single "anchor" position (e.g.</p><formula xml:id="formula_7">p k p 1</formula><p>) is sufficient, since the counterfactual ERM learning objective is invariant to multiplicative scaling <ref type="bibr" target="#b19">[19]</ref>.</p><p>While this ratio estimator is a sensible approach for the PBM, it is not directly applicable to the Contextual PBM even if we only need relative propensity estimates. In particular, a simple ratio of the observed click-through rates at different ranks will yield</p><formula xml:id="formula_8">E x [p k (x )] E x [p k ′ (x )] ,</formula><p>where the expectation is over contexts. This is not the estimate we seek for the CPBM, since we need estimates of each specific p k (x) (up to multiplicative scaling) to de-bias clicked examples at position k under context x. To get such context-dependent propensity estimates, we will introduce a different estimator below. Furthermore, we will show how to avoid explicit swap interventions by harvesting implicit interventions. As illustrated below, such implicit interventions are typically available in large quantities and do not come at the expense of user experience related to randomly swapping results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Intervention Harvesting for the CPBM</head><p>Instead of explicitly swapping results, Agarwal et al. <ref type="bibr" target="#b2">[3]</ref> have recently shown for the PBM how interventions similar to explicit swaps can be harvested from data that is readily available in most operational systems. We will extend this approach to the CPBM and derive an intervention-harvesting estimator for the CPBM that does not require explicit swap interventions, nor does it require a document-specific relevance model that would be difficult to fit. Instead, our estimator merely needs to model how the average relevance over all queries and documents at a position -not the context-document specific relevance -changes with context.</p><p>As input for our estimator, suppose we have data from m historic rankers F = { f 1 , ..., f m }. Each ranker f maps a query context x to a ranking f (x) of the candidate set of documents. Let rk(d | f (x)) denote the rank of document d in the ranking. Let n i be the number of queries that f i processed, and let L = {(x j , d j , k j , c j )|j ∈ [N ]} be the aggregated click log over all the rankers, with one tuple for each context-document pair. We require that the distribution of contexts is stationary, or specifically that there is no dependency between the context and the choice of ranking function f i <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">20]</ref>,</p><formula xml:id="formula_9">∀f i : Pr(X| f i ) = Pr(X) ⇒ ∀x ∈ X : Pr(f i |x) = Pr(f i ). (<label>3</label></formula><formula xml:id="formula_10">)</formula><p>This condition is fulfilled in at least two situations -namely in A/B tests and under stationary Pr(X). In data from A/B tests, where users are randomly assigned to one of the rankers, the condition is fulfilled by design. An example is shown in Figure <ref type="figure" target="#fig_1">1b</ref>. For a given context x, the ranking functions f 1 , f 2 and f 3 are each chosen completely randomized with equal probability 1  3 . By choosing one of the three rankers, we implicitly conduct a number of interventions. For example, document d 1 is randomized to be displayed in positions 1, 2, or 3 with equal probability, and document d 2 is displayed in position 1 with probability 2  3 and in position 2 with probability 1 3 . Figure <ref type="figure" target="#fig_1">1c</ref> shows that a similar randomization holds when the production ranker gets updated from f 1 to f 2 under stationary Pr(X). Stationarity implies that the probability of a context x is equal before and after the update, and thus d 4 has twice the probability of being shown in position 4 than in position 5 in this toy example with 3-time steps.</p><p>To exploit this readily available intervention data for estimating the CPBM, let's first focus on a fixed pair of positions k, k ′ . The key idea of intervention harvesting for the CPBM is to control for the varying average relevance of results displayed in positions k, k ′ for context x by restricting to the set of queries that, for an appropriate choice of ranker from F = { f 1 , ..., f m }, could have been placed either at k or k ′ . To this effect, we define interventional sets</p><formula xml:id="formula_11">S k,k ′ := {(x, d) : ∃f ,f ′ rk(d | f(x)) =k ∧ rk(d | f ′ (x)) =k ′ } (4)</formula><p>as the sets of (x, d) pairs that receive "treatments" k or k ′ under different rankers. Specifically, a context-document pair (x, d) is included in S k,k ′ , if for the context x some ranker f ∈ F puts the document d at position k and another ranker f ′ ∈ F puts it at position k ′ . This is akin to a virtual swap intervention at positions k and k ′ , albeit only with a single document. Based on these definitions, the toy example in Figure <ref type="figure" target="#fig_1">1b</ref> produces interventional sets such that (x, d 1 ) ∈ S 1,2 , S 1,3 , S 2,3 , (x, d 2 ) ∈ S 1,2 , (x, d 4 ) ∈ S 4,5 , etc. Note that the set includes all possible queries that may be sampled, not only those that are actually sampled in one or more rankers' logs. Furthermore, note that the feedback signals of (x, d) from some rankers might remain counterfactual and unobserved. Illustrating this using the toy example in Figure <ref type="figure" target="#fig_1">1b</ref>, each ranking of F = { f 1 , f 2 , f 3 } was a potential choice, but only one of those rankings was presented to the user -say the ranking of f 1 . In this way, we only observe the feedback for d 1 at position 1, but not at the other positions.</p><p>To account for the fact that not all interventions within an interventional set S k,k ′ have the same probability, we define the following weighting function that is proportional to the treatmentassignment probability. It can either be computed from the known assignment probabilities in an A/B test, or for consecutive policy deployments via</p><formula xml:id="formula_12">q k (x, d) := m i=1 n i 1[rk(d|f i (x)) = k] m i=1 n i . (<label>5</label></formula><formula xml:id="formula_13">)</formula><p>For the example in Figure <ref type="figure" target="#fig_1">1b</ref>, we have q 1 (x,</p><formula xml:id="formula_14">d 1 ) = q 2 (x, d 1 ) = q 3 (x, d 1 ) = 1 3 , q 4 (x, d 4 ) = 1 3 , q 5 (x, d 4 ) = 2 3 , etc.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">AllPairs Estimator for the CPBM</head><p>Now that we have extracted intervention data and its assignment mechanism from existing logs, we can tackle the question of defining an estimator for the CPBM using this data. The key challenge compared to analogous estimators for the PBM <ref type="bibr" target="#b2">[3]</ref> lies in modeling the dependence on context. We start by constructing the following feedback labels for each (x j , d j , k j , c j ) ∈ L by correcting the non-uniform assignment mechanism to the uniform intervention distribution in each interventional set <ref type="bibr" target="#b2">[3]</ref>.</p><formula xml:id="formula_15">ĉj k,k ′ (k) := 1 [(x j ,d j )∈S k,k ′ ] 1 [k j =k ] c j q k (x j , d j ) ¬c j k,k ′ (k) := 1 [(x j ,d j )∈S k,k ′ ] 1 [k j =k ] 1 − c j q k (x j , d j )</formula><p>This can be thought of as an IPS weighted class label. For the PBM without a dependence on context x, in expectation (over the choice of ranker and query) ĉj k,k ′ (k) is proportional to the product of examination propensity p k and average relevance r k,k <ref type="bibr" target="#b2">[3]</ref>, just like for the explicit swap interventions mentioned above. However, when there is a dependency on context x for both the examination probabilities p k (x) and the average relevance r k,k ′ (x) := Pr(rel(x, d) = 1|(x, d) ∈ S k,k ′ , x), unbiasedness w.r.t. the query distribution no longer holds and there is generally no small number of individual parameters p k and r k,k ′ that could be estimated exhaustively. To overcome this problem, we exploit that unbiasedness still holds for each individual context, and we introduce a context-dependent examination model h(k, x) for p k (x) and a context-dependent average relevance model д(k, k ′ , x) for r k,k ′ (x) to compactly capture the variation across contexts. In the experiments in this paper, we model both h(k, x) and д(k, k ′ , x) as neural networks.</p><formula xml:id="formula_16">′ := Pr(rel(x, d) = 1|(x, d) ∈ S k,k ′ )</formula><p>With these definitions in place, we can now formulate an extremum estimator similar to a maximum-likelihood criterion. We call this the AllPairs estimator for the CPBM. It combines the flexibility of the observational generative modeling approach with the robustness of the interventional methods, specifically the intervention harvesting approach previously used for estimating the PBM <ref type="bibr" target="#b2">[3]</ref>.</p><formula xml:id="formula_17">ĥCP BM := argmax h,д j ∈L k k ′ ĉj k,k ′ (k) log h(k, x j )д(k, k ′ , x j )<label>(6)</label></formula><formula xml:id="formula_18">+ ¬c j k,k ′ (k) log 1−h(k, x j )д(k, k ′ , x j )</formula><p>Here, h(k, x) and д(k, k ′ , x) are constrained to (0, 1) by using a sigmoid output layer on both networks. While the AllPairs estimator has syntactic similarity with the generative maximum-likelihood objective from <ref type="bibr" target="#b27">[27]</ref>, both are fundamentally different. Notably, All-Pairs uses interventional data to control for the unobserved document relevance, while the generative model is purely observational. This allows the average relevance model д(k, k ′ , x) in AllPairs to be substantially simpler than the individual relevance model д(q, d) in generative modeling. In particular, д(k, k ′ , x) in AllPairs does not model the relevance of an individual document to a query, but merely how the average relevance of documents in positions k and k ′ changes with context. As such, д(k, k ′ , x) does not require document-level relevance features, but merely takes the context x and the positions as input. In the experiments, we find that the average relevance at a specific position k does not change much with context x, and that even replacing the neural relevance model д(k, k ′ , x) with k max choose 2 context-independent parameters r k,k ′ performs quite well.</p><p>We now further justify the use of the objective in Equation ( <ref type="formula" target="#formula_17">6</ref>) by showing that it is equivalent to a weighted version of Cross-Entropy Maximization where the weights adjust for the varying amounts of interventional data available across position pairs k, k ′ . This relates the AllPairs objective to optimizing the KL-divergence between model and data, and it implies two practical advantages. First, for this type of objective, it is well known that training neural networks via backpropagation is effective. Second, this objective provides an attractive method for information aggregation, mitigating the noisiness and sparsity of click data. Proposition 1. Under the condition in (3) and i.i.d. contexts x ∼ Pr(X), the objective in Equation ( <ref type="formula" target="#formula_17">6</ref>) is equivalent to the following weighted form of Cross-Entropy,</p><formula xml:id="formula_19">x ∈X k k ′ Nk,k ′ (x) ŷk,k ′ (k, x) log y k,k ′ (k, x) + ¬y k,k ′ (k, x) log 1−y k,k ′ (k, x)</formula><p>of the random variables y k,k ′ (k, x) and their empirical counterparts ŷk,k ′ (k, x), ¬y k,k ′ (k, x) weighted with Nk,k ′ (x), where</p><formula xml:id="formula_20">y k,k ′ (k, x) := h(k, x)д(k, k ′ , x) = p k (x)r k,k ′ (x) Nk,k ′ (x) := j ∈ L 1 [x j =x ] 1 [(x j ,d j )∈S k, k ′ ] ŷk,k ′ (k, x) := j ∈ L 1 [x j =x ] ĉj k,k ′ (k) Nk,k ′ (x) ¬y k,k ′ (k, x) := j ∈ L 1 [x j =x ] ¬c j k,k ′ (k) Nk,k ′ (x)</formula><p>,</p><p>and</p><formula xml:id="formula_21">E[ ŷk,k ′ (k, x)] = y k,k ′ (k, x) E[ ¬y k,k ′ (k, x)] = 1 − y k,k ′ (k, x).</formula><p>Proof. First, we rewrite the objective as follows:</p><formula xml:id="formula_22">j ∈L k k ′ ĉj k,k ′ (k) log y k,k ′ (k, x j ) + ¬c j k,k ′ (k) log 1−y k,k ′ (k, x j ) = x ∈X j ∈ L k k ′ 1 [x j =x ] ĉj k,k ′ (k) log y k,k ′ (k, x j ) + ¬c j k,k ′ (k) log 1−y k,k ′ (k, x j ) = x ∈X k k ′ j ∈L 1 [x j =x ] ĉj k,k ′ (k) log y k,k ′ (k, x j ) + j ∈L 1 [x j =x ] ¬c j k,k ′ (k) log 1−y k,k ′ (k, x j ) = x ∈X k k ′ Nk,k ′ (x) ŷk,k ′ (k, x) log y k,k ′ (k, x j ) + ¬y k,k ′ (k, x) log 1−y k,k ′ (k, x j )</formula><p>Next, we are going to prove that</p><formula xml:id="formula_23">E[ ŷk,k ′ (k, x)] = y k,k ′ (k, x) and E[ ¬y k,k ′ (k, x)] = 1−y k,k ′ (k, x), which is required by Cross-Entropy. E[ ŷk,k ′ (k, x) Nk,k ′ (x)] =E[ j ∈L 1 [x j =x ] 1 [(x j ,d j )∈S k,k ′ ] 1 [k j =k ] c j q k (x j , d j ) ] = m i=1 n i j=1 Pr(x) d ∈Ω(x ) 1 [(x,d )∈S k,k ′ ] 1 [rk(d |f i (x ))=k ] E[c(d)] q k (x, d) = Pr(x) m i=1 n i j=1 d ∈Ω(x ) 1 [(x,d )∈S k,k ′ ] 1 [rk(d |f i (x ))=k ] p k (x) rel(x, d) q k (x, d) =p k (x) Pr(x) d ∈Ω(x ) 1 [(x,d )∈S k,k ′ ] rel(x, d) m i=1 n i j=1 1 [rk(d |f i (x ))=k ] q k (x, d) =p k (x) Pr(x) d ∈Ω(x ) 1 [(x,d )∈S k,k ′ ] rel(x, d) m i=1 n i 1 [rk(d |f i (x ))=k ] q k (x, d) =p k (x) Pr(x) d ∈Ω(x ) 1 [(x,d )∈S k,k ′ ] rel(x, d) m i=1 n i =p k (x)E[ j ∈L 1 [x j =x ] 1 [(x j ,d j )∈S k,k ′ ] rel(x j , d j )] =p k (x)r k,k ′ (x)N k,k ′ (x) =y k,k ′ (k, x)N k,k ′ (x)</formula><p>where</p><formula xml:id="formula_24">N k,k ′ (x) = E[ j ∈L 1 [x j =x ] 1 [(x j ,d j )∈S k,k ′ ] ] = E[ Nk,k ′ (x)]. Then we have E[ ŷk,k ′ (k, x)] = E[ ŷk,k ′ (k,x ) Nk,k ′ (x )] E[ Nk,k ′ (x )] = y k,k ′ (k, x). Similarly, E[ ¬y k,k ′ (k, x)] = 1 − y k,k ′ (k, x)</formula><p>. Note that we make the reasonable assumption that user click behavior is independent of the context sampling and ranker choice process, and thus ŷk,k ′ (k, x) and Nk,k ′ (x) are independent random variables, so that</p><formula xml:id="formula_25">E[ ŷk,k ′ (k, x) Nk,k ′ (x)] = E[ ŷk,k ′ (k, x)]E[ Nk,k ′ (x)]. □</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Neural Network Model for the CPBM</head><p>We employ neural networks for modeling both the context-dependent propensities h(k, x) as well as the context-dependent average relevance д(k, k ′ , x). The respective multi-layer perceptron (MLP) architectures are shown in Figure <ref type="figure" target="#fig_4">2</ref>. Both networks take as input the context features x ∈ R t , and output the examination propensity vector p(x) ∈ R k max and the average relevance matrix r (x) ∈   R k max ×k max respectively. The hidden layer in the propensity MLP is a traditional sigmoid-activated dense layer, which learns a weight matrix W p ∈ R t ×k max and bias vector b p ∈ R k max to produce a propensity vector p(x) = σ (W p x + b p ). The average-relevance model is less standard, and its first hidden layer in the relevance MLP learns a 3d weight array W r ∈ R t ×k max ×k max and bias matrix b r ∈ R k max ×k max to produce an initial relevance matrix r (x) = σ (W r x + b r ). To ensure the symmetry of the relevance matrix, the second hidden layer of the relevance MLP computes r (x) = ( r (x) T + r (x))/2.</p><p>We conjecture that improvements to these models could further improve results. First, other neural networks may be good alternatives. For instance, in terms of the sequential examination process, we could iteratively output the propensities p 1 (x), p 2 (x), ..., p max (x) using a recurrent neural network (RNN), where the input sequence consists of repeated context features x. Second, embedding the position k as a feature would give rise to different network architectures. For example, the position could be encoded in a one-hot feature vector k ∈ R k max , which could then be concatenated to the context features x to predict the examination propensity p k (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL EVALUATION</head><p>We empirically evaluate the effectiveness and robustness of our method through real-world experiments on the ArXiv Full-Text Search<ref type="foot" target="#foot_0">1</ref> and through semi-synthetic experiments on the Yahoo Learning-To-Rank Challenge corpus (set 1) <ref type="bibr" target="#b7">[7]</ref>. The ArXiv experiments verify real-world relevance and applicability, while the synthetic experiments enable the evaluation of the method over a wide range of scenarios. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Real-World Evaluation: ArXiv Search</head><p>To verify that contextual effects on the propensity exist in realworld settings and to show that these can be estimated using intervention harvesting and the AllPairs estimator for the CPBM, we conducted a series of experiments on the ArXiv Full-Text Search. To get reliable propensity estimates that can serve as a gold-standard, we fielded explicit swap intervention in addition to an A/B test that we use for intervention harvesting. Specifically, we assigned equal probability of accepting an incoming query to these two mechanisms. For intervention harvesting, we used three ranking functions { f 1 , f 2 , f 3 } and chose uniformly at random between them for half of the incoming queries. For the other half, we also chose one of these ranking functions at random but inserted an explicit swap intervention between rank 1 and rank k ∈ {1, 2, ..., 21}. These explicit swap interventions were then used to get a gold-standard estimate of the propensities via the methods in <ref type="bibr" target="#b19">[19]</ref>. To avoid any confounding due to changes in the query distribution, data for all conditions was collected in parallel between May 14, 2018 and December 13, 2018. In total, 138,600 queries and 112,000 clicks were collected, with about 61,100 queries for the explicit intervention and the rest for the intervention harvesting. For the following experiments, the data was randomly divided into a training set with 80 % of the data, a validation set with 10 %, and a test set with the remaining 10 %.</p><p>In all experiments, the hyper-parameters of the neural networks in the CPBM were selected via cross-validation.</p><p>Do real-world propensity curves actually depend on context? We first verify that the propensity curves in ArXiv do indeed depend on context. To this effect, we introduce a single binary context feature that characterizes each query as either complex (denoted by 1) or simple (denoted by 0).</p><p>Complex queries are those that contain some logical operators from the Boolean query language supported by the search engine, such as "OR" and "AND", while simple queries are the remainder. The numbers of queries and clicks are given in Table <ref type="table" target="#tab_0">1</ref>. We then use the gold-standard propensity estimator from <ref type="bibr" target="#b19">[19]</ref> to learn two PBM models from the swap intervention data, one for complex and one for simple queries.</p><p>Figure <ref type="figure" target="#fig_5">3</ref> shows that the two propensity curves are indeed substantially different. The shaded region for each curve depicts a 95 % confidence interval run on 1000 bootstrap samples. One possible interpretation is that complex queries are often used as more of a "lookup" rather than a search, and thus the first few results typically either match or the user reformulates. On the other hand, simple queries are often part of an exploratory search, such that users go further down the ranking.</p><p>Can AllPairs learn context-dependent propensity curves? Now that we know that contextual dependencies exist in real-world propensity curves, we can verify whether the AllPairs estimator   with the neural CPBM model can accurately estimate these curves. Figure <ref type="figure" target="#fig_7">4</ref> show the propensity curves estimated by the AllPairs estimator on the intervention harvesting data from Table <ref type="table" target="#tab_0">1</ref> using the neural model with only the single input feature. The curves closely match the gold standard in Figure <ref type="figure" target="#fig_5">3</ref>, indicating that the CPBM can accurately learn these curves with a single neural network model. In addition, AllPairs achieves much improved error bars. This is to be expected, given that AllPairs makes more efficient use of the data than the ratio-estimates from <ref type="bibr" target="#b19">[19]</ref>.</p><p>Can AllPairs learn CPBM models with many context features? it is infeasible to introduce additional features and learn separate PBM for each combination, adding context features to our neural CPBM model is straightforward. We will now explore in how far different groups of context features improve the predictive accuracy of the CPBM. Since we no longer have a gold-standard propensity curve to compare against, we instead use the AllPairs objective evaluated on a test set as our measure of predictive performance -similar to evaluating log-likelihood on a test set. We explore the following groups of context features:</p><p>(1) category: whether the query is specified as a category and its corresponding specified category ((binary {0, 1}, 10 features in total) (2) query_len: whether the length of the query is greater than X ∈ {1, 2, 5, 10, 15, 20, 25, 30, 35, 40} (binary {0, 1}, 10 features in total)</p><p>(3) ord_in_session: whether the order of the query in its session is greater than X ∈ {1, 2, 5, 10, 15} ((binary {0, 1}, 5 features in total) (4) #results: whether the number of results for each query is greater than X ∈ {1, 2, 5, 10, 15, 20, 50, 100, 150, 200} (binary {0, 1}, 10 features in total) (5) result_dist: the category distribution of each query (lies in [0, 1] 35 with sum to 1, 35 features in total)</p><p>Other reasonable features can also be taken into consideration, like query performance predictors <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">11]</ref>.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows the test-set performance. The baseline is a PBM model trained according to <ref type="bibr" target="#b2">[3]</ref>, which is essentially a CPBM model without features and a relevance model that explicitly represents each pairwise relevance. The table shows that the CPBM improves on the PBM in terms of predictiveness across all feature groups. The "category" and "query_len" features appear to have the largest influence on the propensity curve. However, the best predictive accuracy is achieved when all features are included in the CPBM. This verifies that the CPBM can make use of complex features to improve the fit of the propensity model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Robustness Analysis: Yahoo LTR Challenge</head><p>We now turn to experiments on semi-synthetic data. Using a semisynthetic setup combines the external validity of using a real-world dataset with the ability to fully explore a range of different settings for evaluating robustness.</p><p>Our semi-synthetic click data is based on the Yahoo LTR Challenge dataset. It contains manual relevance assessments as ground truth and we follow the given train/validation/test splits, but filter out queries that have no relevant documents. To generate click data for intervention harvesting, we learned two ranking functions by running SVM-Rank <ref type="bibr" target="#b16">[16]</ref> on two small randomly sampled subsets of the training queries. To control the ranker similarity, 22 queries were the same for both rankers and each ranker independently sampled 92 additional queries. The remaining (roughly 11,400) queries of the training set were used to generate synthetic click data based on these two ranking functions.</p><p>To generate the click data via a CPBM, we need a model for the context features and an examination model. For context features, each query was mapped to a 10-dimensional feature vector x, concatenated by two parts: relevant part [x 1 , x 2 , ..., x i ] and random part [x i+1 , x i+2 , ..., x 10 ], and we use parameter ζ = i 10 to control the dependency between relevance and context. For the relevant part, the important features which contribute to the relevance modeling were selected in the following way: we first used an SVM-Rank to get a one-sweep click log on the training split. Then we trained k max logistic models r k (x), k ∈ [1, k max ], which denotes the average relevance at position k. Let the coefficient of each feature x j among the given query-document feature vector in each model r m be u jm , we assigned each feature a score s j = max j u jm . We randomly selected i features from a candidate set which contains features x j ranked in top-30 s j list. At last, the relevant part was the average of the vector representations of all relevant results on those selected i features. For the random part, we drew [x i+1 , x i+2 , ..., x 10 ] from the normal distribution N (0, σ 2 ). To keep the performance of the PBM stable with increasing ζ , σ was tuned to be 0.35. For the examination model we chose Pr(E = 1|k, x) = 1 k max(w •x +1, 0) . The parameter vector w was drawn from a uniform distribution over the half-open interval [−η, η), and we normalized the weight to 10 i=1 w i = 0 by subtracting the average weight from each position. The parameter η controls how much examination varies with context. In the extreme case of η = 0, there is no context dependency, and context dependency grows as η increases. We also incorporated click noise into the simulation by setting the probability of clicking on an irrelevant result to ϵ − = 0.1. We chose the maximum number of positions to be k max = 10.</p><p>To evaluate the accuracy of the propensity estimates on a test sample D = {x j |j ∈ [M]}, we adopted the following relative error measure where pk (x) = h(k,x j ) h(1,x j ) are the estimated relative propensities and p k (x) = Pr(E=1|k,x j ) Pr(E=1 |1,x j ) are the true relative propensities are known by construction.</p><formula xml:id="formula_26">RelError (h) = 1 M j ∈ D 1 k max k max k =1 1 − pk (x j ) p k (x j )</formula><p>This measure evaluates the accuracy of the estimates in terms of their use as inverse relative propensity weights, which will be their primary function. The relative error reported below is evaluated on the test set, and error bars indicate the standard deviation estimated over 6 independent runs (except in Figure <ref type="figure" target="#fig_10">8</ref> as described below).</p><p>In our implementation of the AllPairs estimator, the propensity model and the relevance model were both implemented by a multilayer perceptron (described in Section 4.5), whose parameters were selected via cross-validation.</p><p>How much more accurate is the CPBM compared to the PBM?. Table <ref type="table" target="#tab_2">3</ref> shows the RelError of the CPBM and the PBM on test data, where both are trained using the AllPairs estimator using a large amount of click data for training (113, 590 training queries). It can be thought of as the asymptotic performance of the respective model. The table shows that the CPBM improves substantially over the PBM, more than halving the error. This verifies that the All-Pairs estimator can effectively learn context-dependent propensity curves from harvested interventions. Note that the CPBM had no knowledge of the true functional form of the examination model that was used to generate the clicks, but had to approximate it using the neural network model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does the CPBM improve learning-to-rank performance?</head><p>In practice, the propensities coming from the CPBM will typically be used for learning new ranking functions from the de-biased click data. We now evaluate whether the CPBM model improves learning performance compared to using the propensities from the PBM.</p><p>We trained a Clipped Propensity SVM-Rank <ref type="bibr" target="#b19">[19]</ref> for each of the following three propensity models: PBM estimated via All-Pairs, CPBM estimated via AllPairs, and -as gold standard -the true propensities used during synthetic data generation. All hyperparameters were picked via cross-validation. For rank r &gt; 21, we impute the propensity p r (x) = p 21 (x). Following <ref type="bibr" target="#b19">[19]</ref>, we measure test-set ranking performance via the average sum of the ranks of the relevant results across the queries in the test set D,</p><formula xml:id="formula_27">AvдRank(f ) = 1 M j ∈D d ∈Ω(x j ) rk(d | f (x j )) rel(x j , d).</formula><p>Figure <ref type="figure" target="#fig_8">5</ref> shows ranking performance relative to the performance of the Propensity SVM-Rank that has access to the true propensities. For sufficiently large data set sizes, the performance when using the CPBM propensities appears closer to the gold-standard performance than when using the PBM. This is to be expected, since the training objective the Propensity SVM-Rank is known to be biased for the misspecified propensities of the PBM, so that more data no longer translates into better learning performance.</p><p>How much data is needed to learn a CPBM? So far, we have used large amounts of training data to study the asymptotic performance of AllPairs for the CPBM. But how much data is really needed? Figure <ref type="figure">6</ref> compares the error of the three models across a wide range of training data sizes. The figure shows that a much smaller number of training examples suffices to get good accuracy. In particular, the relative error decreases quickly and asymptotes at about 5,700 training queries. Furthermore, Figure <ref type="figure">6</ref> shows that  the CPBM dominates the PBM across the whole range of data-set sizes, even when the amount of click data is quite small. How does the strength of context dependence affect the CPBM? We explore the behavior of the estimators when we vary the strength of context dependence via η. Results are shown in Figure <ref type="figure">7</ref>, where the CPBM outperforms or at least matches the PBM across the whole range. As expected, the error of the PBM increases as the strength of context dependence increases. In contrast, the CPBM can capture the context dependence effectively.</p><p>How important is it to incorporate a relevance model in the estimator? Figure <ref type="figure" target="#fig_10">8</ref> shows the error reduction between the estimators under the CPBM with and without a context-dependent relevance model. For the CPBM with a context-dependent relevance model, we use the neural-network relevance model д(k, k ′ , x), and for the other one we simply use context-independent parameters r k,k ′ for each pair of ranks. To ensure statistical stability, we reran the experiment 20 times. The error reduction provided by contextdependent relevance model increases when the context has increasing influence on the relevance profile. With maximum decrease in error of only 0.02, the context-dependent relevance model provides only a mild improvement to the accuracy of the estimates. This highlights the desirable fact that the relevance model д(k, k ′ , x) can be far less crucial than the query-document relevance model д(q, d) in generative models.</p><p>How accurate is the estimate at different positions in the ranking? Figure <ref type="figure" target="#fig_11">9</ref> shows the relative error of the CPBM at different positions in the ranking. As expected, the relative error increases with position, because lower-ranked documents have a smaller chance of receiving clicks and thus have less training data from intervention harvesting. Furthermore, the examination propensities at lower ranks are generally smaller, such that absolute deviations in the propensity estimates lead to larger contributions to our relative error metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We introduced the Contextual Position-Based Model (CPBM) to better capture the examination bias in interaction feedback from rankings. The CPBM captures how examination changes with context, and we developed an estimator for learning a CPBM from implicit feedback data. The key idea is to harvest interventions from the logs of multiple historic rankers, which provides experimental control to eliminate confounding of relevance on examination. Plugging a neural network model into the estimator, we show how the CPBM and the estimator can effectively learn context-dependent examination models in simulation experiments and real-world experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Intervention Harvesting (switch in production rankers).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of Swap Interventions and of Intervention Harvesting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>kmax (x) r 1,kmax (x) (b) Relevance Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The architecture of the multilayer perceptrons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Propensity curves for simple and complex queries on ArXiv estimated as two PBM via swap interventions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Propensity curves for simple and complex queries on ArXiv estimated as a CPBM via intervention harvesting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Difference in AvgRank compared to the true propensity model (η = 10, ζ = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Relative error with increasing number of training queries (η = 0.5, ζ = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Error reduction by incorporating a relevance model with increasing strength of relevance dependence ζ (#Training queries = 57365, η = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Relative error of the CPBM at different positions in the ranking (#Training queries = 114730, η = 0.5, ζ = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Size of data sets from ArXiv.</figDesc><table><row><cell>Type</cell><cell cols="4">Swap intervention A/B Test Harvesting</cell></row><row><cell></cell><cell cols="3">Clicks Queries Clicks</cell><cell>Queries</cell></row><row><cell cols="2">Complex 32,108</cell><cell>24,460</cell><cell>41,638</cell><cell>27,072</cell></row><row><cell>Simple</cell><cell>15,296</cell><cell>36,659</cell><cell>22,915</cell><cell>50,443</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Objective on the test set for the PBM and the CPBM when including each feature group and for all features.</figDesc><table><row><cell>Model</cell><cell>PBM</cell><cell></cell><cell></cell><cell>CPBM</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">category query_len ord_in_session #results result_dist</cell><cell>All</cell></row><row><cell>Objective</cell><cell cols="3">-13926.18 -12622.96 -12674.8</cell><cell>-13205.21</cell><cell cols="3">-13241.28 -12901.94 -12306.52</cell></row><row><cell>Increment (vs. PBM)</cell><cell>-</cell><cell>1303.22</cell><cell>1251.38</cell><cell>720.97</cell><cell>684.90</cell><cell>1024.24</cell><cell>1619.66</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Relative decrease in the relative error of CPBM vs. PBM (#Training queries = 113590, η = 0.5).</figDesc><table><row><cell>PBM</cell><cell cols="2">CPBM Improvement</cell></row><row><cell cols="2">RelError 0.478700 0.169443</cell><cell>64.60%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">http://search.arxiv.org:8081/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by NSF Awards IIS-1615706 and IIS-1513692, as well as a gift from Google. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A General Framework for Counterfactual Learning-to-Rank</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenta</forename><surname>Takatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Research and Development in Information Retrieval (SIGIR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Counterfactual Learning-to-Rank for Additive Metrics and Deep Models</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Machine Learning for Causal Inference</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CausalML</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Estimating Position Bias without Intrusive Interventions</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web Search and Data Mining (WSDM)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unbiased Learning to Rank with Unbiased Propensity Estimation</title>
		<author>
			<persName><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keping</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/3209978.3209986</idno>
		<ptr target="https://doi.org/10.1145/3209978.3209986" />
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research ; Development in Information Retrieval (SIGIR &apos;18)</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Query difficulty, robustness, and selective application of query expansion</title>
		<author>
			<persName><forename type="first">Giambattista</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudio</forename><surname>Carpineto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on information retrieval</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Click Sequence Model for Web Search</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martijn</forename><surname>Wardenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp;#38</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Development in Information Retrieval (SIGIR &apos;18</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3209978.3210004</idno>
		<ptr target="https://doi.org/10.1145/3209978.3210004" />
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="45" to="54" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Yahoo! Learning to Rank Challenge Overview</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v14/chapelle11a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Learning to Rank Challenge (Proceedings of Machine Learning Research</title>
				<editor>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the Learning to Rank Challenge ( Machine Learning Research<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Dynamic Bayesian Network Click Model for Web Search Ranking</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/1526709.1526711</idno>
		<ptr target="https://doi.org/10.1145/1526709.1526711" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web (WWW &apos;09)</title>
				<meeting>the 18th International Conference on World Wide Web (WWW &apos;09)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Click models for web search</title>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Chuklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Information Concepts, Retrieval, and Services</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="115" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Experimental Comparison of Click Position-bias Models</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onno</forename><surname>Zoeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Ramsey</surname></persName>
		</author>
		<idno type="DOI">10.1145/1341531.1341545</idno>
		<ptr target="https://doi.org/10.1145/1341531.1341545" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 International Conference on Web Search and Data Mining (WSDM &apos;08)</title>
				<meeting>the 2008 International Conference on Web Search and Data Mining (WSDM &apos;08)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting Query Performance</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Cronen-Townsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/564376.564429</idno>
		<ptr target="https://doi.org/10.1145/564376.564429" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;02)</title>
				<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;02)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="299" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Doubly Robust Policy Evaluation and Learning</title>
		<author>
			<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3104482.3104620" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning (ICML&apos;11)</title>
				<meeting>the 28th International Conference on International Conference on Machine Learning (ICML&apos;11)<address><addrLine>Omnipress, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1097" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A User Browsing Model to Predict Search Engine Click Data from Past Observations</title>
		<author>
			<persName><forename type="first">Georges</forename><forename type="middle">E</forename><surname>Dupret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390334.1390392</idno>
		<ptr target="https://doi.org/10.1145/1390334.1390392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;08)</title>
				<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;08)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Click Chain Model in Web Search</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anitha</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi-Min</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<idno type="DOI">10.1145/1526709.1526712</idno>
		<ptr target="https://doi.org/10.1145/1526709.1526712" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on World Wide Web (WWW &apos;09)</title>
				<meeting>the 18th International Conference on World Wide Web (WWW &apos;09)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A generalization of sampling without replacement from a finite universe</title>
		<author>
			<persName><forename type="first">G</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donovan</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="663" to="685" />
			<date type="published" when="1952">1952. 1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimizing Search Engines Using Clickthrough Data</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="DOI">10.1145/775047.775067</idno>
		<ptr target="https://doi.org/10.1145/775047.775067" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD &apos;02)</title>
				<meeting>the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD &apos;02)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accurately Interpreting Clickthrough Data As Implicit Feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Granka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helene</forename><surname>Hembrooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geri</forename><surname>Gay</surname></persName>
		</author>
		<idno type="DOI">10.1145/3130332.3130334</idno>
		<ptr target="https://doi.org/10.1145/3130332.3130334" />
	</analytic>
	<monogr>
		<title level="j">In ACM SIGIR Forum. SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="4" to="11" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating the Accuracy of Implicit Feedback from Clicks and Query Reformulations in Web Search</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Granka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helene</forename><surname>Hembrooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geri</forename><surname>Gay</surname></persName>
		</author>
		<idno type="DOI">10.1145/1229179.1229181</idno>
		<ptr target="https://doi.org/10.1145/1229179.1229181" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2007-04">2007. April 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unbiased learning-to-rank with biased feedback</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Schnabel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3018661.3018699</idno>
		<ptr target="https://doi.org/10.1145/3018661.3018699" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM &apos;17)</title>
				<meeting>the Tenth ACM International Conference on Web Search and Data Mining (WSDM &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploration Scavenging</title>
		<author>
			<persName><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Wortman</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390156.1390223</idno>
		<ptr target="https://doi.org/10.1145/1390156.1390223" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning (ICML &apos;08)</title>
				<meeting>the 25th International Conference on Machine Learning (ICML &apos;08)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="528" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Counterfactual Estimation and Optimization of Click Metrics in Search Engines: A Case Study</title>
		<author>
			<persName><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunbao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Kleban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.1145/2740908.2742562</idno>
		<ptr target="https://doi.org/10.1145/2740908.2742562" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web (WWW &apos;15 Companion)</title>
				<meeting>the 24th International Conference on World Wide Web (WWW &apos;15 Companion)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="929" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling result-list searching in the World Wide Web: The role of relevance topologies and trust bias</title>
		<author>
			<persName><forename type="first">O'</forename><surname>Maeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual Conference of the Cognitive Science Society. Citeseer</title>
				<meeting>the 28th Annual Conference of the Cognitive Science Society. Citeseer</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predicting Clicks: Estimating the Click-through Rate for New Ads</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewa</forename><surname>Dominowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ragno</surname></persName>
		</author>
		<idno type="DOI">10.1145/1242572.1242643</idno>
		<ptr target="https://doi.org/10.1145/1242572.1242643" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web (WWW &apos;07)</title>
				<meeting>the 16th International Conference on World Wide Web (WWW &apos;07)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="521" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The central role of the propensity score in observational studies for causal effects</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="41" to="55" />
			<date type="published" when="1983">1983. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Batch Learning from Logged Bandit Feedback Through Counterfactual Risk Minimization</title>
		<author>
			<persName><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2789272.2886805" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1731" to="1755" />
			<date type="published" when="2015-01">2015. Jan. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to Rank with Selection Bias in Personal Search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<idno type="DOI">10.1145/2911451.2911537</idno>
		<ptr target="https://doi.org/10.1145/2911451.2911537" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;16)</title>
				<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;16)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Position Bias Estimation for Unbiased Learning to Rank in Personal Search</title>
		<author>
			<persName><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bendersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<idno type="DOI">10.1145/3159652.3159732</idno>
		<ptr target="https://doi.org/10.1145/3159652.3159732" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM &apos;18)</title>
				<meeting>the Eleventh ACM International Conference on Web Search and Data Mining (WSDM &apos;18)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="610" to="618" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
