<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reinforcement Learning for Solving the Vehicle Routing Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mohammadreza</forename><surname>Nazari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Systems Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Afshin</forename><surname>Oroojlooy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Systems Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Takáč</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Systems Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lawrence</forename><forename type="middle">V</forename><surname>Snyder</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial and Systems Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<postCode>18015</postCode>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reinforcement Learning for Solving the Vehicle Routing Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2F693367530B379FBD0AB5D9C3419AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an end-to-end framework for solving the Vehicle Routing Problem (VRP) using reinforcement learning. In this approach, we train a single policy model that finds near-optimal solutions for a broad range of problem instances of similar size, only by observing the reward signals and following feasibility rules. We consider a parameterized stochastic policy, and by applying a policy gradient algorithm to optimize its parameters, the trained model produces the solution as a sequence of consecutive actions in real time, without the need to re-train for every new problem instance. On capacitated VRP, our approach outperforms classical heuristics and Google's OR-Tools on medium-sized instances in solution quality with comparable computation time (after training). We demonstrate how our approach can handle problems with split delivery and explore the effect of such deliveries on the solution quality. Our proposed framework can be applied to other variants of the VRP such as the stochastic VRP, and has the potential to be applied more generally to combinatorial optimization problems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Vehicle Routing Problem (VRP) is a combinatorial optimization problem that has been studied in applied mathematics and computer science for decades. VRP is known to be a computationally difficult problem for which many exact and heuristic algorithms have been proposed, but providing fast and reliable solutions is still a challenging task. In the simplest form of the VRP, a single capacitated vehicle is responsible for delivering items to multiple customer nodes; the vehicle must return to the depot to pick up additional items when it runs out. The objective is to optimize a set of routes, all beginning and ending at a given node, called the depot, in order to attain the maximum possible reward, which is often the negative of the total vehicle distance or average service time. This problem is computationally difficult to solve to optimality, even with only a few hundred customer nodes <ref type="bibr" target="#b11">[12]</ref>, and is classified as an NP-hard problem. For an overview of the VRP, see, for example, <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>The prospect of new algorithm discovery, without any hand-engineered reasoning, makes neural networks and reinforcement learning a compelling choice that has the potential to be an important milestone on the path toward solving these problems. In this work, we develop a framework with the capability of solving a wide variety of combinatorial optimization problems using Reinforcement Learning (RL) and show how it can be applied to solve the VRP. For this purpose, we consider the Markov Decision Process (MDP) formulation of the problem, in which the optimal solution can be viewed as a sequence of decisions. This allows us to use RL to produce near-optimal solutions by increasing the probability of decoding "desirable" sequences.</p><p>A naive approach would be to train an instance-specific policy by considering every instance separately. In this approach, an RL algorithm needs to take many samples, maybe millions of them, from the underlying MDP of the problem to be able to produce a good-quality solution. Obviously, this approach is not practical since the RL method should be comparable to existing algorithms not only in terms of the solution quality but also in terms of runtime. For example, for all of the problems studied in this paper, we wish to have a method that can produce near-optimal solutions in less than a second. Moreover, the policy learned by this naive approach would not apply to instances other than the one that was used in the training; after a small perturbation of the problem setting, e.g., changing the location or demand of a customer, we would need to rebuild the policy from scratch.</p><p>Therefore, rather than focusing on training a separate policy for every problem instance, we propose a structure that performs well on any problem sampled from a given distribution. This means that if we generate a new VRP instance with the same number of nodes and vehicle capacity, and the same location and demand distributions as the ones that we used during training, then the trained policy will work well, and we can solve the problem right away, without retraining for every new instance. As long as we approximate the generating distribution of the problem, the framework can be applied. One can view the trained policy as a black-box heuristic (or a meta-algorithm) which generates a high-quality solution in a reasonable amount of time.</p><p>This study is motivated by the recent work by Bello et al. <ref type="bibr" target="#b3">[4]</ref>. We have generalized their framework to include a wider range of combinatorial optimization problems such as the VRP. Bello et al. <ref type="bibr" target="#b3">[4]</ref> propose the use of a Pointer Network <ref type="bibr" target="#b33">[34]</ref> to decode the solution. One major issue that complicates the direct use of their approach for the VRP is that it assumes the system is static over time. In contrast, in the VRP, the demands change over time in the sense that once a node has been visited its demand becomes, effectively, zero. To overcome this, we propose an alternate approach-which is simpler than the Pointer Network approach-that can efficiently handle both the static and dynamic elements of the system. Our policy model consists of a recurrent neural network (RNN) decoder coupled with an attention mechanism. At each time step, the embeddings of the static elements are the input to the RNN decoder, and the output of the RNN and the dynamic element embeddings are fed into an attention mechanism, which forms a distribution over the feasible destinations that can be chosen at the next decision point.</p><p>The proposed framework is appealing to practitioners since we utilize a self-driven learning procedure that only requires the reward calculation based on the generated outputs; as long as we can observe the reward and verify the feasibility of a generated sequence, we can learn the desired meta-algorithm. For instance, if one does not know how to solve the VRP but can compute the cost of a given solution, then one can provide the signal required for solving the problem using our method. Unlike most classical heuristic methods, it is robust to problem changes, e.g., when a customer changes its demand value or relocates to a different position, it can automatically adapt the solution. Using classical heuristics for VRP, the entire distance matrix must be recalculated and the system must be re-optimized from scratch, which is often impractical, especially if the problem size is large. In contrast, our proposed framework does not require an explicit distance matrix, and only one feed-forward pass of the network will update the routes based on the new data.</p><p>Our numerical experiments indicate that our framework performs significantly better than well-known classical heuristics designed for the VRP, and that it is robust in the sense that its worst results are still relatively close to optimal. Comparing our method with the OR-Tools VRP engine <ref type="bibr" target="#b15">[16]</ref>, which is one of the best open-source VRP solvers, we observe a noticeable improvement; in VRP instances with 50 and 100 customers, our method provides shorter tours in roughly 61% of the instances. Another interesting observation that we make in this study is that by allowing multiple vehicles to supply the demand of a single node, our RL-based framework finds policies that outperform the solutions that require single deliveries. We obtain this appealing property, known as the split delivery, without any hand engineering and at no extra cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Before presenting the problem formalization, we briefly review the required notation and relation to existing work.</p><p>Sequence-to-Sequence Models Sequence-to-Sequence models <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b24">25]</ref> are useful in tasks for which a mapping from one sequence to another is required. They have been extensively studied in the field of neural machine translation over the past several years, and there are numerous variants of these models. The general architecture, which is shared by many of these models, consists of two RNN networks called the encoder and decoder. An encoder network reads through the input sequence and stores the knowledge in a fixed-size vector representation (or a sequence of vectors); then, a decoder converts the encoded information back to an output sequence.</p><p>In the vanilla Sequence-to-Sequence architecture <ref type="bibr" target="#b31">[32]</ref>, the source sequence appears only once in the encoder and the entire output sequence is generated based on one vector (i.e., the last hidden state of the encoder RNN). Other extensions, for example Bahdanau et al. <ref type="bibr" target="#b2">[3]</ref>, illustrate that the source information can be used more explicitly to increase the amount of information during the decoding steps. In addition to the encoder and decoder networks, they employ another neural network, namely an attention mechanism that attends to the entire encoder RNN states. This mechanism allows the decoder to focus on the important locations of the source sequence and use the relevant information during decoding steps for producing "better" output sequences. Recently, the concept of attention has been a popular research idea due to its capability to align different objects, e.g., in computer vision <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b17">18]</ref> and neural machine translation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25]</ref>. In this study, we also employ a special attention structure for the policy parameterization. See Section 3.3 for a detailed discussion of the attention mechanism.</p><p>Neural Combinatorial Optimization Over the last several years, multiple methods have been developed to tackle combinatorial optimization problems by using recent advances in artificial intelligence. The first attempt was proposed by Vinyals et al. <ref type="bibr" target="#b33">[34]</ref>, who introduce the concept of a Pointer Network, a model originally inspired by sequence-to-sequence models. Because it is invariant to the length of the encoder sequence, the Pointer Network enables the model to apply to combinatorial optimization problems, where the output sequence length is determined by the source sequence. They use the Pointer Network architecture in a supervised fashion to find near-optimal Traveling Salesman Problem (TSP) tours from ground truth optimal (or heuristic) solutions. This dependence on supervision prohibits the Pointer Network from finding better solutions than the ones provided during the training.</p><p>Closest to our approach, Bello et al. <ref type="bibr" target="#b3">[4]</ref> address this issue by developing a neural combinatorial optimization framework that uses RL to optimize a policy modeled by a Pointer Network. Using several classical combinatorial optimization problems such as TSP and the knapsack problem, they show the effectiveness and generality of their architecture.</p><p>On a related topic, Dai et al. <ref type="bibr" target="#b10">[11]</ref> solve optimization problems over graphs using a graph embedding structure <ref type="bibr" target="#b9">[10]</ref> and a deep Q-learning (DQN) algorithm <ref type="bibr" target="#b25">[26]</ref>. Even though VRP can be represented by a graph with weighted nodes and edges, their proposed approach does not directly apply since in VRP, a particular node (e.g. the depot) might be visited multiple times.</p><p>Next, we introduce our model, which is a simplified version of the Pointer Network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Model</head><p>In this section, we formally define the problem and our proposed framework for a generic combinatorial optimization problem with a given set of inputs X .</p><formula xml:id="formula_0">= {x i , i = 1, • • • , M }.</formula><p>We allow some of the elements of each input to change between the decoding steps, which is, in fact, the case in many problems such as the VRP. The dynamic elements might be an artifact of the decoding procedure itself, or they can be imposed by the environment. For example, in the VRP, the remaining customer demands change over time as the vehicle visits the customer nodes; or we might consider a variant in which new customers arrive or adjust their demand values over time, independent of the vehicle decisions. Formally, we represent each input x i by a sequence of tuples</p><formula xml:id="formula_1">{x i t . = (s i , d i t ), t = 0, 1, • • • }</formula><p>, where s i and d i t are the static and dynamic elements of the input, respectively, and can themselves be tuples. One can view x i t as a vector of features that describes the state of input i at time t. For instance, in the VRP, x i t gives a snapshot of the customer i, where s i corresponds to the 2-dimensional coordinate of customer i's location and d i t is its demand at time t. We will denote the set of all input states at a fixed time t with X t .</p><p>We start from an arbitrary input in X 0 , where we use the pointer y 0 to refer to that input. At every decoding time t (t = 0, 1, • • • ), y t+1 points to one of the available inputs X t , which determines the input of the next decoder step; this process continues until a termination condition is satisfied. The termination condition is problem-specific, showing that the generated sequence satisfies the feasibility constraints. For instance, in the VRP that we consider in this work, the terminating condition is that there is no more demand to satisfy. This process will generate a sequence of length T , Y = {y t , t = 0, ..., T }, possibly with a different sequence length compared to the input length M . This is due to the fact that, for example, the vehicle may have to go back to the depot several times to refill. We also use the notation Y t to denote the decoded sequence up to time t, i.e., Y t = {y 0 , • • • , y t }. We are interested in finding a stochastic policy π which generates the sequence Y in a way that minimizes a loss objective while satisfying the problem constraints. The optimal policy π * will generate the optimal solution with probability 1. Our goal is to make π as close to π * as possible. Similar to Sutskever et al. <ref type="bibr" target="#b31">[32]</ref>, we use the probability chain rule to decompose the probability of generating sequence Y , i.e., P (Y |X 0 ), as follows:</p><formula xml:id="formula_2">P (Y |X 0 ) = T t=0 π(y t+1 |Y t , X t ),<label>(1)</label></formula><p>and</p><formula xml:id="formula_3">X t+1 = f (y t+1 , X t )<label>(2)</label></formula><p>is a recursive update of the problem representation with the state transition function f . Each component in the right-hand side of ( <ref type="formula" target="#formula_2">1</ref>) is computed by the attention mechanism, i.e.,</p><formula xml:id="formula_4">π(•|Y t , X t ) = softmax(g(h t , X t )),<label>(3)</label></formula><p>where g is an affine function that outputs an input-sized vector, and h t is the state of the RNN decoder that summarizes the information of previously decoded steps y 0 , • • • , y t . We will describe the details of our proposed attention mechanism in Section 3.3.</p><p>Remark 1: This structure can handle combinatorial optimization problems in both a more classical static setting as well as in dynamically changing ones. In static combinatorial optimization, X 0 fully defines the problem that we are trying to solve. For example, in the VRP, X 0 includes all customer locations as well as their demands, and the depot location; then, the remaining demands are updated with respect to the vehicle destination and its load. With this consideration, often there exists a well-defined Markovian transition function f , as defined in <ref type="bibr" target="#b1">(2)</ref>, which is sufficient to update the dynamics between decision points. However, our framework can also be applied to problems in which the state transition function is unknown and/or is subject to external noise, since the training does not explicitly make use of the transition function. However, knowing this transition function helps in simulating the environment that the training algorithm interacts with. See Appendix C.6 for an example of how to handle a stochastic version of the VRP in which random customers with random demands appear over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Limitations of Pointer Networks</head><p>Although the framework proposed by Bello et al. <ref type="bibr" target="#b3">[4]</ref> works well on problems such as the knapsack problem and TSP, it is not efficient to more complicated combinatorial optimization problems in which the system representation varies over time, such as VRP. Bello et al. <ref type="bibr" target="#b3">[4]</ref> feed a random sequence of inputs to the RNN encoder. Figure <ref type="figure">1</ref> illustrates with an example why using the RNN in the encoder is restrictive. Suppose that at the first decision step, the policy sends the vehicle to customer 1, and as a result, its demand is satisfied, i.e., d 1 0 = d 1 1 . Then in the second decision step, we need to re-calculate the whole network with the new d 1  1 information in order to choose the next customer. The dynamic elements complicate the forward pass of the network since there should be encoder/decoder updates when an input changes. The situation is even worse during back-propagation to accumulate the gradients since we need to remember when the dynamic elements changed. In order to resolve this complication, we require the policy model to be invariant to the input sequence so that changing the order of any two inputs does not affect the network. In Section 3.2, we present a simple network that satisfies this property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Proposed Neural Network Model</head><p>We argue that the RNN encoder adds extra complication to the encoder but is actually not necessary, and the approach can be made much more general by omitting it. RNNs are necessary only when the inputs convey sequential information; e.g., in text translation the combination of words and their Then, the RNN hidden state and embedded input produce a probability distribution over the next input using the attention mechanism. relative position must be captured in order for the translation to be accurate. But the question here is, why do we need to have them in the encoder for combinatorial optimization problems when there is no meaningful order in the input set? As an example, in the VRP, the inputs are the set of unordered customer locations with their respective demands, and their order is not meaningful; any random permutation contains the same information as the original inputs. Therefore, in our model, we simply leave out the encoder RNN and directly use the embedded inputs instead of the RNN hidden states. By this modification, many of the computational complications disappear, without decreasing the efficiency. In Appendix A, we provide experiments to verify this claim.</p><p>As illustrated in Figure <ref type="figure">2</ref>, our model is composed of two main components. The first is a set of graph embeddings <ref type="bibr" target="#b29">[30]</ref> that can be used to encode structured data inputs. Among the available techniques, we tried a one-layer Graph Convolutional Network <ref type="bibr" target="#b20">[21]</ref> embedding, but it did not show any improvement on the results, so we kept the embedding in this paper simple by utilizing the local information at each node, e.g., its coordinates and demand values, without incorporating adjacency information. In fact, this embeddings maps each customer's information into a D-dimensional vector space encoding. We might have multiple embeddings corresponding to different elements of the input, but they are shared among the inputs. The second component is a decoder that points to an input at every decoding step. As is common in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b6">7]</ref>, we use RNN to model the decoder network. Notice that we feed the static elements as the inputs to the decoder network. The dynamic element can also be an input to the decoder, but our experiments on the VRP do not suggest any improvement by doing so. For this reason, the dynamic elements are used only in the attention layer, described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Attention Mechanism</head><p>An attention mechanism is a differentiable structure for addressing different parts of the input. Figure <ref type="figure">2</ref> illustrates the attention mechanism employed in our method. At decoder step i, we utilize a context-based attention mechanism with glimpse, similar to Vinyals et al. <ref type="bibr" target="#b34">[35]</ref>, which extracts the relevant information from the inputs using a variable-length alignment vector a t . In other words, a t specifies how much every input data point might be relevant in the next decoding step t.</p><p>Let xi t = (s i , di t ) be the embedded input i, and h t ∈ R D be the memory state of the RNN cell at decoding step t. The alignment vector a t is then computed as</p><formula xml:id="formula_5">a t = a t (x t , h t ) = softmax (u t ) , where u i t = v T a tanh W a [x i t ; h t ] .<label>(4</label></formula><p>) Here ";" means the concatenation of two vectors. We compute the conditional probabilities by combining the context vector c t , computed as</p><formula xml:id="formula_6">c t = M i=1 a i t xi t ,<label>(5)</label></formula><p>with the embedded inputs, and then normalizing the values with the softmax function, as follows:</p><formula xml:id="formula_7">π(•|Y t , X t ) = softmax(ũ t ), where ũi t = v T c tanh W c [x i t ; c t ] .<label>(6)</label></formula><p>In ( <ref type="formula" target="#formula_5">4</ref>)-( <ref type="formula" target="#formula_7">6</ref>), v a , v c , W a and W c are trainable variables.</p><p>Remark 2: Model Symmetry: Vinyals et al. <ref type="bibr" target="#b34">[35]</ref> discuss an extension of sequence-to-sequence models where they empirically demonstrate that in tasks with no obvious input sequence, such as sorting, the order in which the inputs are fed into the network matter. A similar concern arises when using Pointer Networks for combinatorial optimization problems. However, the policy model proposed in this paper does not suffer from such a complication since the embeddings and the attention mechanism are invariant to the input order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training Method</head><p>To train the network, we use well-known policy gradient approaches. To use these methods, we parameterize the stochastic policy π with parameters θ, where θ is vector of all trainable variables used in embedding, decoder, and attention mechanism. Policy gradient methods use an estimate of the gradient of the expected return with respect to the policy parameters to iteratively improve the policy. In principle, the policy gradient algorithm contains two networks: (i) an actor network that predicts a probability distribution over the next action at any given decision step, and (ii) a critic network that estimates the reward for any problem instance from a given state. Our training methods are quite standard, and due to space limitation we leave the details to the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Computational Experiment</head><p>Many variants of the VRP have been extensively studied in the operations research literature. See, for example, the reviews by Laporte <ref type="bibr" target="#b22">[23]</ref>, Laporte et al. <ref type="bibr" target="#b23">[24]</ref>, or the book by Toth and Vigo <ref type="bibr" target="#b32">[33]</ref> for different variants of the problem. In this section, we consider a specific capacitated version of the problem in which one vehicle with a limited capacity is responsible for delivering items to many geographically distributed customers with finite demands. When the vehicle's load runs out, it returns to the depot to refill. We will denote the vehicle's remaining load at time t as l t . The objective is to minimize the total route length while satisfying all of the customer demands. This problem is often called the capacitated VRP (CVRP) to distinguish it from other variants, but we will refer to it simply as the VRP.</p><p>We assume that the node locations and demands are randomly generated from a fixed distribution. Specifically, the customers and depot locations are randomly generated in the unit square [0, 1]×[0, 1].</p><p>For simplicity of exposition, we assume that the demand of each node is a discrete number in {1, .., 9}, chosen uniformly at random. We note, however, that the demand values can be generated from any distribution, including continuous ones.</p><p>We assume that the vehicle is located at the depot at time 0, so the first input to the decoder is an embedding of the depot location. At each decoding step, the vehicle chooses from among the customer nodes or the depot to visit in the next step. After visiting customer node i, the demands and vehicle load are updated as follows:</p><formula xml:id="formula_8">d i t+1 = max(0, d i t -l t ), d k t+1 = d k t for k = i, and l t+1 = max(0, l t -d i t )<label>(7)</label></formula><p>which is an explicit definition of the state transition function (2) for the VRP. Once a sequence of the nodes to be visited is sampled, we compute the total vehicle distance and use its negative value as the reward signal.</p><p>In this experiment, we have employed two different decoders: (i) greedy, in which at every decoding step, the node (either customer or depot) with the highest probability is selected as the next destination, and (ii) beam search (BS), which keeps track of the most probable paths and then chooses the one with the minimum tour length <ref type="bibr" target="#b27">[28]</ref>. Our results indicate that by applying the beam search algorithm, the quality of the solutions can be improved with only a slight increase in computation time.</p><p>For faster training and generating feasible solutions, we have used a masking scheme which sets the log-probabilities of infeasible solutions to -∞ or forces a solution if a particular condition is satisfied. In the VRP, we use the following masking procedures: (i) nodes with zero demand are not allowed to be visited; (ii) all customer nodes will be masked if the vehicle's remaining load is exactly 0; and (iii) the customers whose demands are greater than the current vehicle load are masked. Notice that under this masking scheme, the vehicle must satisfy all of a customer's demands when visiting it. We note, however, that if the situation being modeled does allow split deliveries, one can relax (iii). Indeed, the relaxed masking allows split deliveries, so the solution can allocate the demands of a given customer into multiple routes. This property is, in fact, an appealing behavior that is present in many real-world applications, but is often neglected in classical VRP algorithms. In all the experiments of the next section, we do not allow to split demands. Further investigation and illustrations of this property is included in Appendix C.2-C.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>In this section, we compare the solutions found using our framework with those obtained from the Clarke-Wright savings heuristic (CW), the Sweep heuristic (SW), and Google's optimization tools (OR-Tools). We run our tests on problems with 10, 20, 50 and 100 customer nodes and corresponding vehicle capacity of 20, 30, 40 and 50; for example, VRP10 consists of 10 customer and the default vehicle capacity is 20 unless otherwise specified. The results are based on 1000 instances, sampled for each problem size. RL-Greedy 12.2 7.2 99.4 97.2 96.3 97.9 97.9 97.9 41.5 RL-BS <ref type="bibr" target="#b4">(5)</ref> 85.8 12.5 99.7 99.0 98.7 99.1 99.1 99.1 54.6 RL-BS <ref type="bibr" target="#b9">(10)</ref> 91.9 57.7 99.8 99.4 99.2 99.3 99.3 99.3 60.2 CW-Greedy 0.6 0.3 0.2 0.0 0.0 68.9 68.9 68.9 1.0 CW-Rnd <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b4">5)</ref> 2.8 1.0 0.6 92. Figure <ref type="figure" target="#fig_2">3</ref> shows the distribution of total tour lengths generated by our method, using greedy and BS decoders, with the number inside the parentheses indicating the beam-width parameter. In the experiments, we label our method with the "RL" prefix. In addition, we also implemented a randomized version of both heuristic algorithms to improve the solution quality; for Clarke-Wright, the numbers inside the parentheses are the randomization depth and randomization iterations parameters; and for Sweep, it is the number of random initial angles for grouping the nodes. Finally, we use Google's OR-Tools <ref type="bibr" target="#b15">[16]</ref>, which is a more competitive baseline. See Appendix B for a detailed discussion on the baselines.</p><p>For small problems of VRP10 and VRP20, it is possible to find the optimal solution, which we do by solving a mixed integer formulation of the VRP <ref type="bibr" target="#b32">[33]</ref>. Figures 3a and 3b measure how far the solutions are far from optimality. The optimality gap is defined as the distance from the optimal objective value normalized by the latter. We observe that using a beam width of 10 is the best-performing method; roughly 95% of the instances are at most 10% away from optimality for VRP10 and 13% for VRP20.</p><p>Even the outliers are within 20-25% of optimality, suggesting that our RL-BS methods are robust in comparison to the other baseline approaches.</p><p>Since obtaining the optimal objective values for VRP50 and VRP100 is not computationally affordable, in Figures <ref type="figure" target="#fig_2">3d</ref> and<ref type="figure" target="#fig_2">3d</ref>, we compare the algorithms in terms of their winning rate. Each table gives the percentage of the instances in which the algorithms in the rows outperform those in the columns. In other words, the cell corresponding to (A,B) shows the percentage of the samples in which algorithm A provides shorter tours than B. We observe that the classical heuristics are outperformed by the other approaches in almost 100% of the samples. Moreover, RL-greedy is comparable with OR-Tools, but incorporating beam search into our framework increases the winning rate of our approach to above 60%.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> shows the solution times normalized by the number of customer nodes. We observe that this ratio stays almost the same for RL with different decoders. In contrast, the run time for the Clarke-Wright and Sweep heuristics increases faster than linearly with the number of nodes. This observation is one motivation for applying our framework to more general combinatorial problems, since it suggests that our method scales well. Even though the greedy Clark-Wright and basic Sweep heuristics are fast for small instances, they do not provide competitive solutions. Moreover, for larger problems, our framework is faster than the randomized heuristics. We also include the solution times for OR-Tools in the graph, but we should note that OR-Tools is implemented in C++, which makes exact time comparisons impossible since the other baselines are implemented in Python. It is worthwhile to mention that the runtimes reported for the RL methods are for the case when we decode a single problem at a time. It is also possible to decode all 1000 test problems in a batch which will result in approximately 50× speed up. For example, one-by-one decoding of VRP10 for 1000 instances takes around 50 seconds, but by passing all 1000 instances to decoder at once, the total decoding time decreases to around 1 second on a K80 GPU.</p><p>Active search is another method used by <ref type="bibr" target="#b3">[4]</ref> to assist with the RL training on a specific problem instance in order to iteratively search for a better solution. We do not believe that active search is a practical tool for our problem. One reason is that it is very time-consuming. A second is that we intend to provide a solver that produces solutions by just scoring a trained policy, while active search requires a separate training phase for every instance. To test our conjecture that active search will not be effective for our problem, we implemented active search for VRP10 with samples of size 640 and 1280, and the average route length was 4.78 and 4.77 with 15s and 31s solution times per instance, which are far worse than BS decoders. Note that BS(5) and BS(10) give 4.72 and 4.68, in less than 0.1s. For this reason, we exclude active search from our comparisons.   One desired property of the method is that it should be able to handle variable problem sizes. To test this property, we designed two experiments. In the first experiment, we used the trained policy for VRP100 and evaluated its performance on VRP90-VRP110. As it can be seen in Figure <ref type="figure" target="#fig_5">5</ref>, our method with BS(10) outperforms OR-Tools on all problem sizes. In the second experiment, we test the generalization when the problems are very different. More specifically, we use the models trained for VRP50-Cap40 and VRP50-Cap50 in order to generate a solution for VRP100-Cap50. Using BS <ref type="bibr" target="#b9">(10)</ref>, the average tour length is 18.00 and 17.80, which is still better than the classical heuristics, but worse than OR-Tools. Overall, these two experiments suggest that when the problems are close in terms of the number of customer and vehicle capacity, it is reasonable to expect a near-optimal solution, but we will see a degradation when the testing problems are very different from the training ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extension to Other VRPs</head><p>The proposed framework can be extended easily to problems with multiple depots; one only needs to construct the corresponding state transition function and masking procedure. It is also possible to include various side constraints: soft constraints can be applied by penalizing the rewards, or hard constraints such as time windows can be enforced through a masking scheme. However, designing such a scheme might be a challenging task, possibly harder than solving the optimization problem itself. Another interesting extension is for VRPs with multiple vehicles. In the simplest case in which the vehicles travel independently, one must only design a shared masking scheme to avoid the vehicles pointing to the same customer nodes. Incorporating competition or collaboration among the vehicles is also an interesting line of research that relates to multi-agent RL (MARL) <ref type="bibr" target="#b4">[5]</ref>.</p><p>This framework can also be applied to real-time services including on-demand deliveries and taxis. In Appendix C.6, we design an experiment to illustrate the performance of the algorithm on a VRP where both customer locations and their demands are subject to change. Our results indicate superior performance than the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>According to the findings of this paper, our RL algorithm is competitive with state-of-the-art VRP heuristics, and this represents progress toward solving the VRP with RL for real applications. The fact that we can solve similar-sized instances without retraining for every new instance makes it easy to deploy our method in practice. For example, a vehicle equipped with a processor can use the trained model and solve its own VRP, only by doing a sequence of pre-defined arithmetic operations. Moreover, unlike many classical heuristics, our proposed method scales well as the problem size increases, and it has superior performance with competitive solution-time. It does not require a distance matrix calculation, which might be computationally cumbersome, especially in dynamically changing VRPs. One important discrepancy which is usually neglected by the classical heuristics is that one or more of the elements of the VRP are stochastic in the real world. In this paper, we also illustrate that the proposed RL-based method can be applied to a more complicated stochastic version of the VRP. In summary, we expect that the proposed architecture has significant potential to be used in real-world problems with further improvements and extensions that incorporate other realistic constraints.</p><p>Noting that the proposed algorithm is not limited to VRP, it will be an important topic of future research to apply it to other combinatorial optimization problems such as bin-packing and job-shop or flow-shop scheduling. This method is quite appealing since the only requirement is a verifier to find feasible solutions and also a reward signal to demonstrate how well the policy is working. Once the trained policy is available, it can be used many times, without needing to re-train for new problems as long as they are generated from the training distribution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Figure 1 :Figure 2 :</head><label>112</label><figDesc>Figure 1: Limitation of the Pointer Network. After a change in dynamic elements (d 1 1 in this example), the whole Pointer Network must be updated to compute the probabilities in the next decision point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Parts 3a and 3b show the optimality gap (in percent) using different algorithms/solvers for VRP10 and VRP20. Parts 3c and 3d give the proportion of the samples for which the algorithms in the rows outperform those in the columns; for example, RL-BS(5) is superior to RL-greedy in 85.8% of the VRP50 instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Ratio of solution time to the number of customer nodes using different algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Trained for VRP100 and tested for VRP90-VRP110.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The traveling salesman problem: a computational study</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>David L Applegate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasek</forename><surname>Bixby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">J</forename><surname>Chvatal</surname></persName>
		</author>
		<author>
			<persName><surname>Cook</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Princeton university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The split delivery vehicle routing problem: a survey</title>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Archetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">Grazia</forename><surname>Speranza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The vehicle routing problem: Latest advances and new challenges</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="103" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09940</idno>
		<title level="m">Neural combinatorial optimization with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-agent reinforcement learning: An overview</title>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Buşoniu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Babuška</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><forename type="middle">De</forename><surname>Schutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in multi-agent systems and applications-1</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="183" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Abc-cnn: An attention based convolutional neural network for visual question answering</title>
		<author>
			<persName><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ram</forename><surname>Nevatia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05960</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Worst-case analysis of a new heuristic for the travelling salesman problem</title>
		<author>
			<persName><forename type="first">Nicos</forename><surname>Christofides</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ Pittsburgh Pa Management Sciences Research Group</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scheduling of vehicles from a central depot to a number of delivery points</title>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="568" to="581" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative embeddings of latent variable models for structured data</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2702" to="2711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning combinatorial optimization algorithms over graphs</title>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><forename type="middle">B</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bistra</forename><surname>Dilkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust branch-and-cut-and-price for the capacitated vehicle routing problem</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Fukasawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Humberto</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Lysgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><surname>Poggi De Aragão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Uchoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renato</forename><forename type="middle">F</forename><surname>Werneck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="491" to="511" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tabu search*</title>
		<author>
			<persName><forename type="first">Fred</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Laguna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of combinatorial optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3261" to="3362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Vehicle Routing Problem: Latest Advances and New Challenges</title>
		<author>
			<persName><forename type="first">Subramanian</forename><surname>Bruce L Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><surname>Wasil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Google&apos;s optimization tools (or-tools)</title>
		<author>
			<persName><surname>Inc</surname></persName>
		</author>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/google/or-tools" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gurobi Optimization. Gurobi optimizer reference manual</title>
		<author>
			<persName><surname>Inc</surname></persName>
		</author>
		<ptr target="http://www.gurobi.com" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning transferrable knowledge for semantic segmentation with deep convolutional neural network</title>
		<author>
			<persName><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhyuk</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3204" to="3212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Daniel Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The vehicle routing problem: An overview of exact and approximate algorithms</title>
		<author>
			<persName><forename type="first">Gilbert</forename><surname>Laporte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of operational research</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="358" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Classical and modern heuristics for the vehicle routing problem</title>
		<author>
			<persName><forename type="first">Gilbert</forename><surname>Laporte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Gendreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Yves</forename><surname>Potvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Semet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International transactions in operational research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="285" to="300" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adria</forename><forename type="middle">Puigdomenech</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1928" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Neural machine translation and sequence-to-sequence models: A tutorial</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01619</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A survey on dynamic and stochastic vehicle routing problems</title>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Ritzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Puchinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">F</forename><surname>Hartl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Production Research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="215" to="231" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Computational capabilities of graph neural networks</title>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ah</forename><surname>Chung Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="102" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuo-Jun Max</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><surname>Shen</surname></persName>
		</author>
		<title level="m">Fundamentals of Supply Chain Theory</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Vehicle Routing Problem</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Vigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Order matters: Sequence to sequence for sets</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Guided local search and its application to the traveling salesman problem</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Voudouris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of operational research</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="469" to="499" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Function optimization using connectionist reinforcement learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="268" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Computer scheduling of vehicles from one or more depots to a number of delivery points</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Holliday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operational Research Quarterly</title>
		<imprint>
			<biblScope unit="page" from="333" to="344" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The application of two-level attention models in deep convolutional neural network for fine-grained image classification</title>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="842" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
