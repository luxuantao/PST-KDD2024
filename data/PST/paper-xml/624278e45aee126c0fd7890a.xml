<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Canary Extraction in Natural Language Understanding Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-03-25">25 Mar 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rahil</forename><surname>Parikh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Systems Research</orgName>
								<orgName type="institution">University of Maryland</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christophe</forename><surname>Dupuy</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Amazon Alexa AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Amazon Alexa AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Canary Extraction in Natural Language Understanding Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-03-25">25 Mar 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2203.13920v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural Language Understanding (NLU) models can be trained on sensitive information such as phone numbers, zip-codes etc. Recent literature has focused on Model Inversion Attacks (ModIvA) that can extract training data from model parameters. In this work, we present a version of such an attack by extracting canaries inserted in NLU training data. In the attack, an adversary with open-box access to the model reconstructs the canaries contained in the model's training set. We evaluate our approach by performing text completion on canaries and demonstrate that by using the prefix (non-sensitive) tokens of the canary, we can generate the full canary. As an example, our attack is able to reconstruct a four digit code in the training dataset of the NLU model with a probability of 0.5 in its best configuration. As countermeasures, we identify several defense mechanisms that, when combined, effectively eliminate the risk of ModIvA in our experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural Language Understanding (NLU) models are used for different tasks such as questionanswering <ref type="bibr" target="#b12">(Hirschman and Gaizauskas, 2001)</ref>, machine translation <ref type="bibr" target="#b15">(Macherey et al., 2001</ref>) and text summarization <ref type="bibr" target="#b21">(Tas and Kiyani, 2007)</ref>. These models are often trained on crowd-sourced data that may contain sensitive information such as phone numbers, contact names and street addresses. <ref type="bibr" target="#b17">Nasr et al. (2019)</ref>, <ref type="bibr" target="#b18">Shokri et al. (2017)</ref> and <ref type="bibr" target="#b2">Carlini et al. (2018)</ref> have presented various attacks to demonstrate that neural-networks can leak private information. We focus on one such class of attacks, called Model Inversion Attack (ModIvA) <ref type="bibr" target="#b7">(Fredrikson et al., 2015)</ref>, where an adversary aims to reconstruct a subset of the data on which the machinelearning model under attack is trained on. We also demonstrate that established ML practices (e.g. dropout) offer strong defense against ModIvA.</p><p>In this work, we start with inserting potentially sensitive target utterances called 'canaries' 1 along with their corresponding output labels into the training data. We use this augmented dataset to train an NLU model f ? . We perform a open-box attack on this model, i.e., we assume that the adversary has access to all the parameters of the model, including the word vocabulary and the corresponding embedding vectors. The attack takes the form of text completion, where the adversary provides the start of a canary sentence (e.g., 'my pin code is') and tries to reconstruct the remaining, private tokens of an inserted canary (e.g., a sequence of 4 digit tokens). A successful attack on f ? reconstructs all the tokens of an inserted canary. We refer to such a ModIvA as 'Canary Extraction Attack' (CEA). In such an attack, this token reconstruction is cast as an optimization problem where we minimize the loss function of the model f ? with respect to its inputs (the canary utterance), keeping the model parameters fixed.</p><p>Previous ModIvAs were conducted on computer vision tasks where there exists a continuous mapping between input images and their corresponding embeddings. However, in the case of NLU, the discrete mapping of tokens to embeddings makes the token reconstruction from continuous increments in the embedding space challenging. We thus formulate a discrete optimization attack, in which the unknown tokens are eventually represented by a one-hot like vector of the vocabulary length. The token in the vocabulary with the highest softmax activation is expected to be the unknown token of the canary. We demonstrate that in our attack's best configuration, for canaries of type "my pin code is k 1 k 2 k 3 k 4 ", k i ? {0, 1, . . . , 9}, 1 ? i ? 4, we are able to extract the numeric pin k 1 k 2 k 3 k 4 with an accuracy of 0.5 (a lower bound on this accuracy using a naive random guessing strategy for a combination of four digits equals 10 -4 ).</p><p>Since we present a new application of ModIvA to NLU models, defenses against them are an important ethical consideration to prevent harm and are explored in Section 6. We observe that standard training practices commonly used to regularize NLU models successfully thwart this attack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Significant research has been conducted in the field of privacy-preserving machine learning. <ref type="bibr" target="#b18">Shokri et al. (2017)</ref> determine whether a particular datapoint belongs to the training set X tr . The success of such attacks has prompted research in investigating them <ref type="bibr" target="#b22">(Truex et al., 2019;</ref><ref type="bibr" target="#b11">Hayes et al., 2017;</ref><ref type="bibr" target="#b20">Song and Shmatikov, 2019)</ref>. <ref type="bibr" target="#b2">Carlini et al. (2018)</ref> propose the quantification of unintended memorization in deep networks and presents an extraction algorithm for data that is memorized by generative models. Memorization is further exploited in <ref type="bibr">Carlini et al. (2020)</ref> where instances in the training data of very large language-models are extracted by sampling the model. The attacks described above are closed-box in nature where the adversary does not cast the attack as an optimization problem but instead queries the model multiple times.</p><p>Open-box ModIvA were initially demonstrated on a linear-regression model <ref type="bibr" target="#b8">(Fredrikson et al., 2014)</ref> for inferring medical information. It has been extended to computer vision tasks such as facial recognition <ref type="bibr" target="#b7">(Fredrikson et al., 2015)</ref> or image classification <ref type="bibr" target="#b1">(Basu et al., 2019)</ref>. Our work is a first attempt at performing ModIvAs on NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Attack Setup</head><p>We consider an NLU model f ? that takes an utterance x as input and uses the word-embeddings E(x) for the tokens in x to perform a joint intent classification (IC) and named-entity recognition (NER) task. We assume an adversary with open-box access to f ? , which means that they are aware of the model architecture, trained parameters ?, loss function L(f ? (E(x)), y), label set Y of intents and entities supported by the model and vocabulary V which is obtained from the wordembeddings matrix W ? IR |V |?d . However, the adversary does not have access to the training data X tr used to train f ? . The adversary's goal is to reconstruct a (private) subset x ? X tr .</p><p>To perform a CEA on f ? , we keep the parameters ? fixed and minimize the loss function L with respect to the unknown inputs (i.e., tokens) of a given utterance. This is analogous to a traditional learning problem, except with fixed model parameters and a learnable input space. In this work, we use the NLU model architecture described in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Canary Extraction Attacks</head><p>We consider a canary sentence x c = (x p , x u ), x c ? X tr with tokens (p 1 , .., p m , u 1 .., u n ) and output label y c ? Y . The first m tokens in x c represent a known prefix x p (e.g."my pin code is") and the next n tokens (u 1 , .., u n ) represent the unknown tokens that an attacker is interested in reconstructing x u (e.g."one two three four"). We represent the set of word embeddings of this canary E(x c ) as (e p 1 , .., e pm , e u 1 , .., e un ).</p><p>A trivial attack to identify the n unknown tokens in x u is by directly optimizing L(f ? (E(x c )), y c ) over (e u 1 , .., e un ), where (e u 1 , .., e un ) are randomly initialized. Words corresponding to the optimized values of (e u 1 , .., e un ) are then assigned by identifying the closest vectors in the embedding matrix W using a distance metric (e.g. Euclidean distance). However, our experiments demonstrate that this strategy is not successful since the updates are performed in a non-discrete fashion, whereas the model f ? has a discrete input space. We thus focus on performing a discrete optimization, inspired by works on relaxing categorical variables to facilitate efficient gradient flow <ref type="bibr" target="#b13">(Jang et al., 2016;</ref><ref type="bibr" target="#b19">Song and Raghunathan, 2020)</ref>, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>We define a logit vector z i ? IR |V | for each token u i ? x u . We then apply a softmax activation with temperature T to obtain a i ? IR |V | :</p><formula xml:id="formula_0">a i,v = e z i,v T |V | j=1 e z j,v T for v =1, 2, . . . ,|V | (1)</formula><p>a i is a differentiable approximation of the arg-max over the logit vector for low values of T . This vector then selectively attends to the tokens in the embedding matrix, W ? IR |V |?d , resulting in the embeddings (e u 1 , .., e un ) used as inputs fed to the model during the attack:</p><formula xml:id="formula_1">e u i = W T ? a i for 1 ? i ? n (2)</formula><p>We then train our attack and optimize for Z ? IR n?|V | , with Z = (z 1 , . . . , z n ): Z is the only trainable parameter in the attack and all parameters of f ? remain fixed. Once converged, we identify the token x i as the one with the highest activation in a i . We decrease the temperature T exponentially to ensure low values of T in Equation ( <ref type="formula">1</ref>) and enforce the inputs to f ? to be discrete. In our experiments, we define z i over a subset of candidate words for x u V 0 , V 0 ? V to prevent the logit vector from becoming too sparse.</p><formula xml:id="formula_2">? = arg min Z L(f ? (E(x c )), y c )<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Target Model Description</head><p>We attack an NLU model jointly trained to perform IC and NER tagging. This model has a CLC structure <ref type="bibr" target="#b14">(Ma and Hovy, 2016)</ref>. The input embeddings lead to 2 bi-LSTM layers and a fully-connected layer with softmax activation for the IC task and a Conditional Random Field (CRF) layer for the NER task. The sum of the respective cross-entropy and CRF loss is minimized during training. We use FastText embeddings <ref type="bibr" target="#b16">(Mikolov et al., 2018)</ref> as inputs to our model<ref type="foot" target="#foot_0">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Canary Insertion</head><p>We inject R repetitions of a single canary with sensitive information and its corresponding intent and NER labels into the training set of the NLU model. We insert three different types of canaries with n unknown tokens, n ? {4, 6, 8, 10}, described in Table <ref type="table">1</ref>. C is a set of 12 colors<ref type="foot" target="#foot_1">3</ref> . Additional details of the canaries and their output labels are presented in the Appendix A. The adversary aims to reconstruct all the n unknown, sensitive tokens in the canary. The reduced vocabulary V 0 in Equation ( <ref type="formula">1</ref>) is the set of all digits for canary call and pin and the names of 12 colors for canary color.</p><formula xml:id="formula_3">Canary Pattern {p 1 , ..p m , u 1 .., u n } Unknown tokens set call call k 1 . . . k n k i ? {0, . . . , 9}, 1 ? i ? n pin my pin code is k 1 . . . k n k i ? {0, . . . , 9}, 1 ? i ? n color color k 1 . . . k n k i ? C, 1 ? i ? n</formula><p>Table <ref type="table">1</ref>: Patterns of canaries injected into the dataset. Each token of interest k i is randomly chosen from the corresponding token set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Attack Evaluation</head><p>We inject the canary into Snips <ref type="bibr" target="#b4">(Coucke et al., 2018)</ref>, ATIS <ref type="bibr" target="#b5">(Dahl et al., 1994)</ref> and NLU-Evaluation (Xingkun Liu and Rieser, 2019). The canary is repeated with R ? {1, 10, 100, 500}. For each combination of R, canary type and length n, the experiment is repeated 10 times (trials) with 10 different canaries, to account for variation induced by canary selection. We define the following evaluation metrics averaged across all trials to evaluate the strength of our attack.</p><p>Average Accuracy (Acc): Fraction of the trials where the attack correctly reconstructs the entire canary sequence in the correct order. A higher Accuracy indicates better reconstruction. Accuracy is 1 if we can reconstruct all n tokens in each of the 10 trials.</p><p>Average Hamming Distance per Token (HDT): The Hamming Distance (HD) <ref type="bibr" target="#b10">(Hamming, 1950)</ref> is the number of positions at which the reconstructed utterance sequence is different from the inserted canary. Since HD is proportional to the length of the canary, we normalize it by the length of the unknown utterance (HDT = HD/n). The HDT can be interpreted as the probability of reconstructing the incorrect token for a given position in the canary, averaged across the 10 trials. A lower HDT indicates better reconstruction.</p><p>Accuracy reports our performance on reconstructing all n unknown tokens in the correct order and is a conservative metric. HDT quantifies our average performance for reconstructing each po-  sition in the unknown sequence. We evaluate our attack against randomly choosing a token from the reduced vocabulary V 0 . Thus for a given value of n, the expected accuracy and HDT of this baseline are</p><formula xml:id="formula_4">( 1 |V 0 | ) n and 1 -1 |V 0 | respectively.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The trivial attack described in Sec3.1 without discrete optimization performs comparably to the random selection baseline. We thus focus on performing the attack with discrete optimization in this Section. Table <ref type="table" target="#tab_1">2</ref> shows the best reconstruction metrics for the different values of n and the corresponding repetitions R ? {10, 100, 500} at which these metrics are observed in the Snips dataset. In our experiments, our attack consistently outperforms the baseline. For n = 4, 6, we reconstruct at least one complete canary for each pattern. The attack also completely reconstructs a 10-digit pin for higher values of R, with an accuracy of 0.10. Even when we are unable to reconstruct every token in any trial, i.e. accuracy is zero, we still outperform the baseline, as observed from the HDT values.</p><p>For the sake of brevity, we summarize the attack performance on other datasets in Appendix C.2. We observe that the attack is dataset-dependent with best performance for the Snips dataset and poorest for the NLU-evaluation dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Discussion</head><p>The training data of NLU models may potentially contain sensitive utterances such as "call k 1 . . . k 10 ", k 1?i?10 ? {0, 1, . . . , 9}. An adversary who wishes to extract the phone-number can assume the prefix "call", along with the output labels of the utterance which are also trivial to guess, given access to the label set Y . Our canaries act as a placeholder for such utterances. We choose to insert the canary color since the names of colors appear infrequently in the datasets mentioned in Section 4.3, allowing us to evaluate the attack on 'out-of-distribution' data which is more likely to be memorized by deep networks <ref type="bibr" target="#b2">(Carlini et al., 2018)</ref>.</p><p>For n = 4 and R = 1 (i.e., the canary only appears once in the train set), our attack has an accuracy of 0.33 for canary color and 0.10 for pin. This suggests that the attack could potentially reconstruct sensitive information from short rare utterances in real-world scenarios. For a special case when the adversary attempts to reconstruct a ten digit phone-number in canary call with a three digit area-code of their choosing, the attack can reconstruct the remaining seven digits of the number with an accuracy of 0.1 when R = 1. For conciseness, we show these results in Appendix C.1. We observe that our model is more effective and with fewer repeats for the canary color than canaries pin and call of the same length. Our empirical analysis indicates the attack is more successful in extracting tokens that are relatively infrequent in the training data and in reconstructing shorter canaries. As shown in Appendix C.1, the attack performs best for R = 1000. However, this trend of improved reconstruction for larger values of R is not monotonic and we observe a general decline in reconstruction for R &gt; 1000. We are unsure of the vulnerabilities that facilitate CEA. While unintended memorization is a likely explanation, we note that our attack performs best on the Snips data, although the smaller ATIS data should be easier to memorize <ref type="bibr" target="#b24">(Zhang et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Proposed Defenses against ModIvA</head><p>We propose three commonly used modeling techniques as defense mechanisms-Dropout (D), Early Stopping (ES) <ref type="bibr" target="#b0">(Arpit et al., 2017)</ref> and including a Character Embeddings layer in the NLU model (CE). D and ES are regularization techniques to reduce memorization and overfitting. CE makes the problem in 3 more difficult to optimize, by concatenating the embeddings of each input token with a character level representation. This character level representation is obtained using a convolution layer on the input sentence <ref type="bibr" target="#b14">(Ma and Hovy, 2016)</ref>.</p><p>For defense using D, we use a dropout of 20% and 10% while training the NLU model. For ES, we stop training the NLU model under attack if the validation loss does not decrease for 20 consecutive epochs to prevent over-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Efficacy of Defenses</head><p>In this section we present the performance of the proposed defenses against ModIvA. To do so, we evaluate the attack on NLU models trained with each defense mechanism individually, and in all combinations. The canaries are inserted into the Snips dataset and repeated 10, 500 and 1000 times. The results are summarized in Table <ref type="table" target="#tab_2">3</ref>. We observe that the attack accuracy for each defense (used individually and in combination) is nearly zero for all canaries and is thus omitted in the table. We also note that the HDT approaches the random baseline for most defense mechanisms. The attack performance is comparable to a random-guess when the three mechanisms are combined. However, when dropout or character embedding is used alone, HDT values are lower than the baseline, indicating the importance of combining multiple defense mechanisms. Additionally, training with defenses do not have any significant impact on the performance of the NLU model under attack. The defenses thus successfully thwart the proposed attack without impacting the performance of the NLU models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We formulate and present the first open-box ModIvA in a form of a CEA to perform text completion on NLU tasks. Our attack performs discrete optimization to select unknown tokens by optimizing over a set of continuous variables. We demonstrate our attack on three patterns of canaries and reconstruct their unknown tokens by significantly outperforming the 'chance' baseline.</p><p>To ensure that the proposed attack is not misused by an adversary, we propose training NLU models with three commonplace modelling practicesdropout, early-stopping and including character level embeddings. We observe that the above practices are successful in defending against the attack as its accuracy and HDT values approach the random baseline. Future directions include 'demystifying' such attacks, and strengthening the attack for longer sequences with fewer repeats and a larger V 0 and investigating additional defense mechanisms, such as those based on differential privacy, and their effect on the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ethical Considerations</head><p>The addition of proprietary data to existing datasets to fine-tune NLU models can often insert confidential information into datasets. The proposed attack could be misused to extract private information from such datasets by an adversary with open-box access to the model. The objectives of this work are to (1) study and document the actual vulnerability of NLU models against this attack, which shares similarities with existing approaches <ref type="bibr" target="#b8">(Fredrikson et al., 2014;</ref><ref type="bibr" target="#b19">Song and Raghunathan, 2020)</ref>; (2) warn NLU researchers against the possibility of such attacks; and (3) propose effective defense mechanisms to avoid misuse and help NLU researchers protect their models.</p><p>Our work demonstrates that private information such as phone-numbers and zip-codes can be extracted from a discriminative text-based model, and not only from generative models as previously demonstrated <ref type="bibr">(Carlini et al., 2020)</ref>. We advocate for the necessity to privatize such data using anonymization <ref type="bibr" target="#b9">(Ghinita et al., 2007)</ref> or differential privacy <ref type="bibr" target="#b6">(Feyisetan et al., 2020)</ref>. Additionally, in case the training data continues to contain some private information, practitioners can prevent the extraction of sensitive data by using the defense mechanisms described in Section 6, which reduces the attack performance to a random guess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Attack Performance Across Canary Repetitions</head><p>Table <ref type="table" target="#tab_3">4</ref> shows the model performance for just one repeat of the canary in the Snips dataset i.e. R = 1. The n = 7 example for the call canary refers to the special case when the adversary is trying to reconstruct a 10-digit phone number beginning with a three digit area code of their choice. R ? {10, 100, 500, 1000, 2000}. We observe an accuracy of 0.5 for the canary pin when n = 4 and R = 1000. Figure <ref type="figure" target="#fig_1">2</ref> illustrates the model performance across canaries in the Snips dataset with varying number of repetitions R. As observed in Table <ref type="table" target="#tab_4">5</ref> and Figure <ref type="figure" target="#fig_1">2</ref>, the attack is most likely to succeed when R is 1000. However, the attack weakens for higher values of R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Attack Performance Across Datasets</head><p>We evaluate our attack on the ATIS and NLU-Evaluation Datasets, for canaries color and pin with n = 4 and canary call with n = 10. To ensure that we maintain a comparable number or repeats with respect to the size of the dataset, R ? {10, 100, 200, 500} for the ATIS dataset and R ? {100, 500, 1000, 5000, 10000} for the NLU-Evaluation dataset. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, the attack performance is almost comparable for shorter sequences in Snips and ATIS but under-performs for the NLU-Evaluation data. Figure <ref type="figure" target="#fig_3">4</ref> and Figure <ref type="figure" target="#fig_4">5</ref> illustrate the HDT for the ATIS and NLU Evaluation datasets for R canary repetitions respectively.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: CEA using discrete optimization. The logit vectors z 1 , . . . , z n are optimized keeping the parameters of the NLU model f ? fixed. The unknown tokens u i , . . . , u n are then reconstructed using the logit vectors.</figDesc><graphic url="image-1.png" coords="3,70.87,70.87,453.52,95.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Average Hamming Distance per Token (HDT) for canaries with n = 6, repeated in the Snips dataset R times.</figDesc><graphic url="image-2.png" coords="9,70.87,81.19,218.27,163.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Model Performance of the pin and color canary with n = 4 and call canary with n = 10, for the Snips, ATIS, and NLU Evaluation Data.</figDesc><graphic url="image-3.png" coords="9,70.87,313.03,218.27,163.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Model Performance of the pin and color canary with n = 4 and call canary with n = 10, repeated R times in the ATIS dataset.</figDesc><graphic url="image-4.png" coords="9,70.87,551.17,218.27,163.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Model Performance of the pin and color canary with n = 4 and call canary with n = 10, repeated R times in the NLU Evaluation dataset.</figDesc><graphic url="image-5.png" coords="9,306.14,316.18,218.27,163.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Best observed performance metrics for canaries with n unknown tokens and (R) repetitions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Attack performance for the canary color, pin and call after incorporating defenses while training the target NLU model, with R ? {10, 500, 1000}.</figDesc><table><row><cell>R</cell><cell>Defense Mechanism</cell><cell cols="2">?HDT Color Pin Call</cell></row><row><cell></cell><cell>Baseline</cell><cell cols="2">0.916 0.90 0.90</cell></row><row><cell></cell><cell>No defense</cell><cell>0.30</cell><cell>0.33 0.40</cell></row><row><cell></cell><cell>Dropout (D)</cell><cell>0.85</cell><cell>0.80 0.76</cell></row><row><cell></cell><cell>Early Stopping (ES)</cell><cell>0.80</cell><cell>0.93 0.95</cell></row><row><cell>10</cell><cell>Char. Emb. (CE)</cell><cell>0.65</cell><cell>0.75 0.90</cell></row><row><cell></cell><cell>D + ES</cell><cell>0.98</cell><cell>0.90 0.95</cell></row><row><cell></cell><cell>ES + CE</cell><cell>0.90</cell><cell>0.83 0.90</cell></row><row><cell></cell><cell>D + ES + CE</cell><cell>0.90</cell><cell>0.90 0.90</cell></row><row><cell></cell><cell>No defense</cell><cell>0.39</cell><cell>0.27 0.38</cell></row><row><cell></cell><cell>Dropout (D)</cell><cell>0.65</cell><cell>0.54 0.83</cell></row><row><cell></cell><cell>Early Stopping (ES)</cell><cell>0.85</cell><cell>1.00 0.75</cell></row><row><cell cols="2">500 Char. Emb. (CE)</cell><cell>0.58</cell><cell>0.93 0.68</cell></row><row><cell></cell><cell>D + ES</cell><cell>0.85</cell><cell>0.93 0.98</cell></row><row><cell></cell><cell>ES + CE</cell><cell>0.93</cell><cell>0.98 0.78</cell></row><row><cell></cell><cell>D + ES + CE</cell><cell>0.95</cell><cell>0.88 1.00</cell></row><row><cell></cell><cell>No defense</cell><cell>0.35</cell><cell>0.18 0.48</cell></row><row><cell></cell><cell>Dropout (D)</cell><cell>0.35</cell><cell>0.78 0.58</cell></row><row><cell></cell><cell>Early Stopping (ES)</cell><cell>0.90</cell><cell>0.83 0.85</cell></row><row><cell cols="2">1000 Char. Emb. (CE)</cell><cell>0.70</cell><cell>0.68 0.78</cell></row><row><cell></cell><cell>D + ES</cell><cell>0.88</cell><cell>0.98 0.90</cell></row><row><cell></cell><cell>ES + CE</cell><cell>0.88</cell><cell>1.00 0.95</cell></row><row><cell></cell><cell>D + ES + CE</cell><cell>0.95</cell><cell>0.93 0.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Table 5 illustrates the best reconstruction metrics for different values on n and with Reconstruction metrics for inserted utterances appearing only once in the training data, i.e R = 1. The attack accuracy is much higher and HDT is much lower than that of a randomly chosen sequence of tokens.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Attack</cell><cell></cell><cell cols="2">Baseline</cell></row><row><cell cols="2">n Canary</cell><cell></cell><cell>Metrics</cell><cell></cell><cell cols="2">Metrics</cell></row><row><cell></cell><cell></cell><cell cols="5">Accuracy HDT Accuracy HDT</cell></row><row><cell>4</cell><cell>color</cell><cell cols="2">0.33</cell><cell cols="3">0.43 4.8 ? 10 -5 0.92</cell></row><row><cell>4</cell><cell>pin</cell><cell cols="2">0.10</cell><cell>0.60</cell><cell>10 -4</cell><cell>0.90</cell></row><row><cell>4</cell><cell>call</cell><cell cols="2">0.10</cell><cell>0.58</cell><cell>10 -4</cell><cell>0.90</cell></row><row><cell>10</cell><cell>call</cell><cell cols="2">0.00</cell><cell>0.68</cell><cell>10 -10</cell><cell>0.90</cell></row><row><cell>7</cell><cell>call</cell><cell cols="2">0.10</cell><cell>0.70</cell><cell>10 -7</cell><cell>0.90</cell></row><row><cell cols="2">Canary n</cell><cell>R</cell><cell cols="2">Attack</cell><cell cols="2">Baseline</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">?Acc ?HDT</cell><cell>?Acc</cell><cell>?HDT</cell></row><row><cell></cell><cell>4</cell><cell>10</cell><cell>0.40</cell><cell>0.30</cell><cell>4.82e-5</cell></row><row><cell>color</cell><cell cols="3">6 8 1000 0.10 100 0.30</cell><cell>0.45 0.48</cell><cell>3.35e-7 2.33e-9</cell><cell>0.92</cell></row><row><cell></cell><cell cols="3">10 1000 0.00</cell><cell>0.59</cell><cell>1.62e-11</cell></row><row><cell></cell><cell cols="3">4 1000 0.50</cell><cell>0.18</cell><cell>1e-4</cell></row><row><cell>pin</cell><cell cols="3">6 1000 0.10 8 1000 0.00</cell><cell>0.43 0.57</cell><cell>1e-6 1e-8</cell><cell>0.90</cell></row><row><cell></cell><cell cols="2">10 100</cell><cell>0.10</cell><cell>0.43</cell><cell>1e-10</cell></row><row><cell></cell><cell>4</cell><cell>10</cell><cell>0.30</cell><cell>0.40</cell><cell>1e-4</cell></row><row><cell>call</cell><cell cols="3">6 8 1000 0.00 100 0.20</cell><cell>0.50 0.58</cell><cell>1e-6 1e-8</cell><cell>0.90</cell></row><row><cell></cell><cell cols="3">10 2000 0.00</cell><cell>0.59</cell><cell>1e-10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Best observed performance metrics for canaries with n unknown tokens and R ? {10, 100, 500, 1000, 2000}.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://fasttext.cc/docs/en/ english-vectors.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>C = {'red', 'green', 'lilac', 'blue', 'yellow', 'brown',  'cyan', 'magenta', 'orange', 'pink', 'purple', 'mauve'}   </p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Inserted Canary Information</head><p>The inserted canaries and corresponding intent and NER label sets are listed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Canary call:</head><p>"call k 1 . . . k n ", k i ? {0, 1, . . . , 9} , for 1 ? i ? n. The canary repetitions R are split between the train and validation set in a ratio of 9 : 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Training Parameters</head><p>We decrease the temperature T exponentially after each iteration t. The temperature at the t th iteration T t is given by T t = 0.997 t ? 10 -1 . We use the Adam optimizer and train our attack for 250 epochs. We begin with an initial learning rate of 6.5 ? 10 -3 for our attack with a decay rate of 9.95 ? 10 -1 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanis?aw</forename><surname>Jastrz?bski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asja</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Samyadeep</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rauf</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Mesterharm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.04257</idno>
		<title level="m">Membership model inversion attacks for deep networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">?lfar Erlingsson, and Dawn Song</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jernej</forename><surname>Kos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08232</idno>
	</analytic>
	<monogr>
		<title level="m">The secret sharer: Evaluating and testing unintended memorization in neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.07805</idno>
		<title level="m">Ulfar Erlingsson, et al. 2020. Extracting training data from large language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces</title>
		<author>
			<persName><forename type="first">Alice</forename><surname>Coucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alaa</forename><surname>Saade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Th?odore</forename><surname>Bluche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Caulier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cl?ment</forename><surname>Doumouro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Gisselbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Caltagirone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10190</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="12" to="16" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Expanding the scope of the atis task: The atis-3 corpus</title>
		<author>
			<persName><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Hunicke-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Pallett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rudnicky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Shriber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Human Language Technology</title>
		<meeting>the workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Privacy-and utility-preserving textual analysis via calibrated multivariate perturbations</title>
		<author>
			<persName><forename type="first">Borja</forename><surname>Oluwaseyi Feyisetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName><surname>Diethe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Model inversion attacks that exploit confidence information and basic countermeasures</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1322" to="1333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Lantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Somesh</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ristenpart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd {USENIX} Security Symposium</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="17" to="32" />
		</imprint>
	</monogr>
	<note>{USENIX} Security 14</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast data anonymization with low information loss</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Ghinita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panagiotis</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Mamoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd international conference on Very large data bases</title>
		<meeting>the 33rd international conference on Very large data bases</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="758" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Error detecting and error correcting codes</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">W</forename><surname>Hamming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Bell system technical journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Logan: evaluating privacy leakage of generative models using generative adversarial networks</title>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Danezis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristofaro</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07663</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Natural language question answering: the view from here</title>
		<author>
			<persName><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">natural language engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">275</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Natural language understanding using statistical machine translation</title>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh European Conference on Speech Communication and Technology</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Advances in pre-training distributed word representations</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation</title>
		<meeting>the International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Houmansadr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="739" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Membership inference attacks against machine learning models</title>
		<author>
			<persName><forename type="first">Reza</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Stronati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananth</forename><surname>Raghunathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.00053</idno>
		<title level="m">formation leakage in embedding models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Auditing data provenance in text-generation models</title>
		<author>
			<persName><forename type="first">Congzheng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="196" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey automatic text summarization</title>
		<author>
			<persName><forename type="first">Oguzhan</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farzad</forename><surname>Kiyani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PressAcademia Procedia</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="205" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Demystifying membership inference attacks in machine learning as a service</title>
		<author>
			<persName><forename type="first">Stacey</forename><surname>Truex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehmet</forename><forename type="middle">Emre</forename><surname>Gursoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqi</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Benchmarking natural language understanding services for building conversational agents</title>
		<author>
			<persName><forename type="first">Pawel</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingkun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)</title>
		<meeting>the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)<address><addrLine>Siracusa (SR), Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Benjamin Recht, and Oriol Vinyals</title>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
	</analytic>
	<monogr>
		<title level="m">Understanding deep learning requires rethinking generalization</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
