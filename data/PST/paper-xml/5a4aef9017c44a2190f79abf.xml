<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combination of Video Change Detection Algorithms by Genetic Programming</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Simone</forename><surname>Bianco</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gianluigi</forename><surname>Ciocca</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Raimondo</forename><surname>Schettini</surname></persName>
						</author>
						<title level="a" type="main">Combination of Video Change Detection Algorithms by Genetic Programming</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B3B72107FE2079C06572F881BBD3C8E</idno>
					<idno type="DOI">10.1109/TEVC.2017.2694160</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>IEEE Transactions on Evolutionary Computation Change detection</term>
					<term>algorithm combining and selection</term>
					<term>genetic programming</term>
					<term>CDNET</term>
					<term>IEEE Transactions on Evolutionary Computation</term>
					<term>IEEE Transactions on Evolutionary Computation</term>
					<term>IEEE Transactions on Evolutionary Computation</term>
					<term>IEEE Transactions on Evolutionary Computation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Within the field of Computer Vision, change detection algorithms aim at automatically detecting significant changes occurring in a scene by analyzing the sequence of frames in a video stream. In this paper we investigate how state-of-the-art change detection algorithms can be combined and used to create a more robust algorithm leveraging their individual peculiarities. We exploited Genetic Programming (GP) to automatically select the best algorithms, combine them in different ways, and perform the most suitable post-processing operations on the outputs of the algorithms. In particular, algorithms' combination and post-processing operations are achieved with unary, binary and n-ary functions embedded into the GP framework. Using different experimental settings for combining existing algorithms we obtained different GP solutions that we termed IUTIS (In Unity There Is Strength). These solutions are then compared against state-of-the-art change detection algorithms on the video sequences and ground truth annotations of the ChangeDetection.net (CDNET 2014) challenge. Results demonstrate that using GP, our solutions are able to outperform all the considered single state-of-the-art change detection algorithms, as well as other combination strategies. The performance of our algorithm are significantly different from those of the other state-of-the-art algorithms. This fact is supported by the statistical significance analysis conducted with the Friedman Test and Wilcoxon Rank Sum post-hoc tests.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M ANY computer vision applications require the detection of significant changing or moving areas within the frames of video streams. In most applications, the changing areas correspond to moving objects or novel objects entering in a scene. In these applications, these objects are considered foreground regions in contrast to the, supposedly static, background region. Since change detection algorithms need to identify these two types of regions, i.e. by labeling pixels or grouping pixels as belonging to the foreground or background, often the term background/foreground segmentation is used. Moreover, since the relevant regions are the foreground ones, the term background subtraction is also often used. An example of an application that needs a robust video change detection algorithm as a pre-processing step is video surveillance. These applications need to track moving objects or identify abandoned ones to trigger event-related actions <ref type="bibr" target="#b0">[1]</ref> by analyzing and monitoring the video content. Other applications that need video change detection are smart environments and video indexing and retrieval. S. Bianco, G. Ciocca, and R. Schettini are with the Department of Informatic Systems and Communications, University of Milano-Bicocca, Milano, 20126 Italy, e-mail: {bianco, ciocca, schettini}@disco.unimib.it.</p><p>Starting from approaches based on a simple difference of pixels, many video change detection algorithms have been proposed in the literature <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref>. Regardless of the rationale of the approach, the goal of any video change detection algorithm is to segment the scene into foreground and background components while trying to cope with the challenges that can be found in real-world videos such as high variation in environmental conditions, illumination changes, shadows, camera-induced distortions and so on. The output is thus generally noisy, with isolated pixels, holes, and jagged boundaries. Post-processing of the foreground component, ranging from simple noise removal to complex object-level techniques, has been investigated to improve the algorithm's accuracy. Results indicate that significant improvement in performance are possible if a specific post-processing algorithm and the corresponding parameters are set appropriately <ref type="bibr" target="#b5">[6]</ref>.</p><p>Notwithstanding the improvements, change detection algorithms have been demonstrated to perform well on some types of videos but there is no single algorithm that is able to tackle all the challenges in a robust way. This can be clearly seen in the ChangeDetection.net (CDNET) 2014 competition <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref> (which follows the CDNET 2012 competition <ref type="bibr" target="#b7">[8]</ref>) where change detection algorithms are evaluated on a common dataset composed of different types of videos sequences and classified according to their performance. The video sequences are grouped into categories and each category poses different challenges to the change detection algorithm (e.g. static vs. moving camera, day vs. night lighting, etc). There is no single algorithm that is able to successfully manage all the challenges, instead different algorithms are best suited to different problems. For example, most approaches in the literature are designed for a static camera setup, and fail when used with moving cameras such as Pan-Tilt-Zoom (PTZ) ones. To cope with the variability of real-world videos, algorithms are becoming increasingly complex and thus computationally expensive. Parallelization of these algorithms on GPU is a possible way to make them usable in real time applications <ref type="bibr">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Another way to improve performance limiting the complexity overhead could be to properly combine state-ofthe-art algorithms using simple operators.</p><p>The problem is how to choose the suitable algorithms to combine and what combination strategy to apply. The selection and combination should be carried out in an automatic way in order to explore possible solutions (under the given assumptions) and to find a suitable one. Approaches based on evolutionary algorithms can be suitable candidates to perform such search <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b14">[15]</ref>.</p><p>Inspired by the effectiveness of evolutionary algorithms, to build our change detection algorithm from existing ones, we rely on Genetic Programming <ref type="bibr" target="#b15">[16]</ref> (GP). As input we feed it the set of the binary foreground/background masks that correspond to the outputs of the change detection algorithms, and a set of unary, binary, and n-ary functions to perform both mask's combination (e.g. logical AND, logical OR) as well as mask's post-processing (e.g. filter operators). We base the fitness function to be optimized on a set of standard performance measures, computed on a benchmark dataset of different video sequences. The solution tree obtained by GP will give our change detection algorithm. The advantage of using GP is threefold. First, we are able to automatically select the algorithms that give the best overall results relative to a set of predefined algorithms. Second, how to combine algorithms to generate intermediate masks, and with which ones, is automatically deduced. Third, which kind of post-processing of the original or intermediate masks to be applied in order to improve the results, is automatically built from the unary, binary and n-ary functions. To the best of our knowledge, this is the first work that uses GP to select and combine different video change detection algorithms.</p><p>The organization of the paper is as follows. Section II provides an overview of literature works most directly related to this study. Section III illustrates how Genetic Programming is used to generate the combined change detection algorithm. In Section IV we describe the experimental setup used in the evaluation of the proposed solution and we report and discuss the corresponding results along with their statistical significance analysis. Moreover we analyze the contributions of the selection, combination, and post-processing components of the proposed solution. Finally Section V concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. Change Detection Algorithms</head><p>In the last decades, many algorithms have been proposed to solve the problem of video change detection <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b19">[20]</ref>. The simplest strategy to detect foreground regions in video is to directly subtract the pixels in the current frame from those in a previous or reference one <ref type="bibr" target="#b20">[21]</ref>. Although efficient, this approach is sensitive to noise and illumination changes. To limit these issues, temporal or adaptive filters can be applied to build the background model. For example median filter <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref>, Kalman filter <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b26">[27]</ref>, and a simplified version of Kalman filter called Wiener filter [28] have been applied. Pixel values can also be analyzed in a given time slot using color histograms and considering the mode <ref type="bibr" target="#b27">[29]</ref>.</p><p>Another way to statistically represent the background is to consider the history over time of the values of the pixels. For example, the background can be modeled as a single Gaussian <ref type="bibr" target="#b28">[30]</ref> or a Mixture of Gaussians <ref type="bibr" target="#b29">[31]</ref>. The latter overcomes the limitation of the unimodal model that cannot handle dynamic background motion. The approaches using the Gaussian model can be also extended by incorporating the generalized Gaussian model <ref type="bibr" target="#b30">[32]</ref>, <ref type="bibr" target="#b31">[33]</ref>. Bayesian approaches have also been proposed to cope with backgrounds having large variations <ref type="bibr" target="#b32">[34]</ref>, <ref type="bibr" target="#b33">[35]</ref>. For example, Li et al. <ref type="bibr" target="#b34">[36]</ref> propose a Bayesian framework that incorporates spectral, spatial, and temporal features to characterize the background appearance in complex environments, while Benedek et al. <ref type="bibr" target="#b35">[37]</ref> use spatial statistics of the neighboring pixel values to robustly detect the foreground against an object's shadow. A hybrid moving object detection system that uses motion, change, and appearance information for more reliable detections is presented by Wang et al. <ref type="bibr" target="#b36">[38]</ref>. The method called Flux Tensor with Split Gaussian models (FTSG) uses a split Gaussian method to separately model foreground and background.</p><p>The above statistical methods require the definition of the model's parameters. Non parametric methods directly rely on the observed data to statistically model the background <ref type="bibr" target="#b37">[39]</ref>. Although these methods can deal with fast changes in the background, they are time consuming, and have an high memory requirement. Improvements have been proposed to overcome these problems e.g. <ref type="bibr" target="#b38">[40]</ref>- <ref type="bibr" target="#b40">[42]</ref>.</p><p>Sample consensus is another non parametric strategy used to model background pixels. It has been recently used in ViBe <ref type="bibr" target="#b41">[43]</ref> and SuBSENSE <ref type="bibr" target="#b42">[44]</ref>, <ref type="bibr" target="#b43">[45]</ref>. Sample consensus determines if a given observation should be considered foreground or background based on its similarity to recently observed samples. ViBe and SuBSENSE use different features (RGB for ViBe and LBP for SubSENSE) and SuBSENSE uses a feedback mechanism to continuously improving the pixel's modeling. In order to reduce the number of samples to be used to model the background, Wang et al. <ref type="bibr" target="#b44">[46]</ref> exploit a small set of adaptive background templates. The templates are automatically discarded based on their estimated efficacy and new templates are added in their stead.</p><p>Subspace learning is another family of background modeling strategies. The frame image is considered as a whole and, by taking into account spatial information, they are more robust to illumination changes. For example, Oliver et al. <ref type="bibr" target="#b45">[47]</ref> proposed an eigenbackground model. A set of images are used to build a vectorization representation of the scene within a given time frame. This representation is then decomposed via Principal Component Analysis to determine the background via the most descriptive eigenvectors. Using a subset of eigenvectors makes the background more robust to illumination changes. The need to efficiently update the background model within the video sequence has generated many variants such as Incremental <ref type="bibr" target="#b46">[48]</ref>, Incremental Non-Negative Matrix Factorization <ref type="bibr" target="#b47">[49]</ref> and robust Matrix Factorization <ref type="bibr" target="#b48">[50]</ref>.</p><p>Other methods try to learn information about background or foreground by using machine learning techniques. These techniques conveniently incorporate domain knowledge from available samples. For example, Lin et al. <ref type="bibr" target="#b49">[51]</ref> use the normalized optical flow and normalized frame differences with a probabilistic SVM to build a background block classifier. Bohyung and Davis <ref type="bibr" target="#b50">[52]</ref> integrate color, gradient and Haarlike features to handle spatio-temporal variations for each pixel within a Kernel Density Approximation framework, while background subtraction is performed using SVM. To overcome the problem of providing large sets of positive and negative examples to the learner, <ref type="bibr" target="#b9">[10]</ref> proposes a 1-class SVM method that is able to update the classifier's parameters online.</p><p>Also, neural network-based solutions have received consid-erable attention. For example, the background segmentation approach proposed by Culibrk et al. <ref type="bibr" target="#b51">[53]</ref> relies on a Probabilistic Neural Networks combining a neural network for background modeling and a Bayesian classifier for pixel's foreground/background detection. Maddalena and Petrosino <ref type="bibr" target="#b52">[54]</ref> designed the SC SOBS algorithm that models the background with the weights of a neural network. A modified version of the algorithm is proposed by Ferone and Maddalena <ref type="bibr" target="#b53">[55]</ref> where the neural network is used to specifically detect moving object for PTZ cameras. A weightless neural network is proposed by Gregorio and Giordano <ref type="bibr" target="#b54">[56]</ref>. The approach is called CwisarDH and uses a buffer of pixel values to store previous foreground values in order to make the algorithm more robust against intermittent objects. The above mentioned approaches are based on visual features computed on the video frames, either at pixel or higher semantic level. A physics-based change detection approach is proposed by Sedky et al. <ref type="bibr" target="#b55">[57]</ref>. It uses image formation models to computationally estimate a consistent physics-based color descriptor of the spectral reflectance of foreground and background surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Combination and Fusion Techniques</head><p>Several attempts to combine the outputs of different change detection algorithms have been investigated. For example the creators of the CDNET challenge have evaluated the performances of the top-3, top-5 and all the 28 reviewed algorithms using a simple majority vote fusion strategy <ref type="bibr" target="#b3">[4]</ref>. The first two fusion schemes obtained the best results in seven performance measures with respect to the top-ranked algorithm and even with respect to the fusion of all the 28 tested algorithms. Also Jodoin et al. <ref type="bibr" target="#b56">[58]</ref> explored a fusion scheme using majority vote. In this case, the results of 22 algorithms have been fused as well as subsets of 3, 5 and 7 methods. Results show that the combinations of different algorithms perform better than single ones.</p><p>Solutions used for combining classifier could also be used for combining change detection algorithms. By considering the output masks generated by the algorithms as responses of pixel-based classifiers, the problem can be seen as selection and combination of, in our case, binary classifiers (foreground vs. background). Several works studied the problem of classifier combining or fusion (e.g. <ref type="bibr" target="#b57">[59]</ref>- <ref type="bibr" target="#b62">[64]</ref>).</p><p>Also in the context of image segmentation, the fusion of different algorithms' outputs is often exploited to obtain a more robust segmentation algorithm. For example, Aljahdali and Zanaty <ref type="bibr" target="#b63">[65]</ref> investigated several fusion rules to improve segmentation accuracy. Specifically, the Median, Mean, Product, Minimun, and Maximum rules are considered, with the mean rule obtaining the overall best performances on the segmentation datasets considered.</p><p>If the outputs of the classifier can be expressed as posteriori probabilities, a Bayesian methodology can be used to integrate the belief measure associated with each classifier to provide a combined final belief <ref type="bibr" target="#b59">[61]</ref>. For example Warfield et al. <ref type="bibr" target="#b64">[66]</ref>, <ref type="bibr" target="#b65">[67]</ref> use the STAPLE algorithm, an Expected Maximization strategy, for estimating the "ground truth" segmentation from a group of experts' segmentations in the context of medical imaging. STAPLE takes different segmentations and simultaneously estimates the final segmentation and the sensitivity and specificity parameters characterizing the performance of each expert. A similar approach is also used by Rohlfing et al. <ref type="bibr" target="#b66">[68]</ref> to estimate the final segmentation from atlas-based segmentations of three-dimensional con-focal microscopy images of bee brains. Mignotte <ref type="bibr" target="#b67">[69]</ref> designed the PRIF fusion scheme. This scheme is based on a Markovian Bayesian fusion procedure, and the fusion is guided by the Probabilistic Rand Index <ref type="bibr" target="#b71">[70]</ref>). This index measures the agreement of one segmentation result to multiple ground-truth segmentations, in a quantitative and perceptual way.</p><p>Recently Wang et al. <ref type="bibr" target="#b72">[71]</ref> formalize the problem of image segmentation fusion as a combinatorial optimization problem in terms of information theory. To reduce the computational complexity required with respect to previous optimization techniques a generative Bayesian image segmentation fusion model (BISF) is proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image-related Genetic Programming</head><p>Evolutionary Algorithms (EAs) attempt to solve complex problems by finding the optimal solution mimicking aspects of the natural evolution of biological systems. Specifically, individuals in a population evolve and compete with each other toward a defined goal. Different EA approaches have been proposed, such as Genetic Algorithm (GA), Evolutionary strategy (ES), Genetic Programming (GP) and Memetic Algorithm (MA). All these approaches have been successfully applied to a wide range of problem domains: optimization <ref type="bibr" target="#b73">[72]</ref>, parameters' estimation <ref type="bibr" target="#b74">[73]</ref>, classification <ref type="bibr" target="#b75">[74]</ref>, feature selection <ref type="bibr" target="#b76">[75]</ref>, and in image processing and computer vision applications <ref type="bibr" target="#b77">[76]</ref>- <ref type="bibr" target="#b79">[78]</ref>.</p><p>With respect to image-related applications, GP has been widely used for image segmentation, enhancement, classification, feature extraction, and object recognition.</p><p>For example, Song and Ciesielski <ref type="bibr" target="#b80">[79]</ref> use GP to segment texture images under a supervised learning approach. Overlapping image regions are processed and labeled as belonging to one of the defined texture classes. A majority vote strategy on the multiple pixel labels assign the final class for each pixel. Singh et al. <ref type="bibr" target="#b81">[80]</ref> tackle the segmentation as a recognition problem. Segmentation programs are evolved by GP from a pool of low level image analysis operators in order to obtain the one able to perform the most accurate segmentation. Existing segmentation approaches can be improved by GP as done, for example, by Amelio and Pizzuti <ref type="bibr" target="#b82">[81]</ref>, where segmentation is performed using a Normalized Cut algorithm <ref type="bibr" target="#b83">[82]</ref>. Images are represented as weighted undirected graphs and GP is used to find an optimal partitioning of the graphs corresponding to the final segmentation.</p><p>For the task of image enhancement, GP has been used to create pseudo-colored images for visualization purposes as done by Poli and Cagnoni <ref type="bibr" target="#b84">[83]</ref>. Grey-scale images are optimally colored in such a way to enhance the readability of Magnetic Resonance images. Image enhancement can be achieved by appropriate linear and non linear image filters. An approach for the automatic construction of image filters using GP for different image analysis tasks is proposed by Pedrino et al. <ref type="bibr" target="#b85">[84]</ref>. By combining input images, goal images, and a set of image processing operators, the developed algorithm searches for the best solution that can be directly used for hardware control.</p><p>One of the most important task in image processing and analysis pertains the classification of image contents. An early example of application of GP to image classification tasks is the work presented by Agnelli et al. <ref type="bibr" target="#b86">[85]</ref>. Simple arithmetic operations, along with exponential function, conditional function and constants are used to construct binary classification trees on a set of domain-specific features detecting image primitives. Zhnag and Smart <ref type="bibr" target="#b87">[86]</ref>, investigate GP for multiclass object classification. Instead of relying on fixed thresholds to separate the class boundaries, a multiclass classifier is build using GP to dynamically determine a set of boundaries to distinguish between different classes. Muni et al. <ref type="bibr" target="#b88">[87]</ref> use GP to build a multitree classifier consisting of evolved trees, where each tree represents a classifier for a particular class. Trees with poor performances are given more chances to evolve and improve their performances exploiting a tree unfitness concept. Usually, GP image classifiers are based on selected domainspecific image features. Differently, Al-Sahaf et al. <ref type="bibr" target="#b89">[88]</ref> use GP to classify raw images directly. A two-tier GP is used for both image feature extraction and image classification. The features are self-constructed by GP along the evolutionary process in the first tier. The second tier makes classification decisions. In order to build reliable classifiers, many labeled data are required during the training phase. To overcome this issue, several GP image classification strategies have been recently proposed that use few labeled instances of each class to evolve classifiers capable of generalising to unseen data <ref type="bibr" target="#b90">[89]</ref>, <ref type="bibr" target="#b91">[90]</ref>.</p><p>Using the appropriate image features is essential to successfully approach a given task. Often these features are manually chosen or crafted by domain experts. GP has been used to automatically derive the most effective features for the problem that must be solved. For example, Krawiec and Bhanu <ref type="bibr" target="#b92">[91]</ref> use features for object recognition that are automatically coevoluted along with image processing operators. Trujillo and Olague <ref type="bibr" target="#b93">[92]</ref> use GP to synthesize low-level image operators that detect interesting points on digital images. The algorithm generates improved versions of existing image processing operators as well as new ones. Transform-based evolvable features are introduced by Kowaliw et al. <ref type="bibr" target="#b94">[93]</ref>. A Cartesian Genetic Programming algorithm is used to generate them for image classification. The idea at the base of these features has been extended for the problem of object recognition <ref type="bibr" target="#b95">[94]</ref>. The authors introduced a network superstructure that co-evolves with the low-level GP representations, and that is able to generate improved image features. Recently, GP has been used to synthesize rotation-invariant texture image descriptors using few image samples <ref type="bibr" target="#b96">[95]</ref>. The approach is able to automatically discover rotation-invariant image keypoints that can be effectively used for texture classification. GP has also been used together with transfer learning to solve complex image classification problems by extracting and reusing blocks of knowledge/information, which are automatically discovered from similar as well as different image classification tasks during the evolutionary process <ref type="bibr" target="#b97">[96]</ref>.</p><p>Closely related to the problem of video change detection, is that of motion detection in a scene. Pinto and Song <ref type="bibr" target="#b98">[97]</ref> use a Multi-frame Accumulate representation to describe the video frames. GP is exploited to generate a motion detector (i.e. learn a classifier) which can differentiate "motion" vs. "no-motion" areas. Shi and Song <ref type="bibr" target="#b99">[98]</ref> present a GP-evolved motion detector. The algorithm is able to detect a target motion ignoring irrelevant ones, and is capable of distinguishing different kinds of motions. Action recognition requires the temporal analysis of a sequence of images by using suitable image descriptors able to capture motion trajectories. Liu et al. <ref type="bibr" target="#b100">[99]</ref> use spatio-temporal motion features automatically evolved via GP on a population of primitive 3D operators. The approach outperforms state-of-the-art hand-crafted and machine learned techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED APPROACH</head><p>As stated in the introduction, our idea is to combine together different change detection algorithms. We named our proposed approach IUTIS quoting the Greek fabulist Aesop (620 BC-560 BC): "In Unity There Is Strength".</p><p>Since there is no clear procedure to obtain a robust change detection algorithm by combining existing ones, a possible solution could be that of designing it by a trial-and-error process as done by Goyette et al. <ref type="bibr" target="#b3">[4]</ref> and Jodoin et al. <ref type="bibr" target="#b56">[58]</ref> where different algorithms selections are tested. Instead, we propose an approach to automatically determine a good selection and combination of algorithms using Genetic Programming (GP) <ref type="bibr" target="#b15">[16]</ref>.</p><p>The major difference between GP and the other evolutionary algorithms is that GP is a domain-independent evolutionary method that genetically breeds a population of functions, or more generally, computer programs to solve a problem. In our case the solutions correspond to fusion strategies.</p><p>The solutions can be represented as trees, lines of code, expressions in prefix or postfix notations, strings of variable length, etc. We use the representation first introduced by Koza <ref type="bibr" target="#b15">[16]</ref>: potential solutions are represented as LISP-like tree structures built using a set of terminal symbols T and a set of nonterminal or functional symbols F. The iterative process of a generic GP is given in Algorithm 1.</p><p>Before running GP, we need to set a number of parameters, which are as follows:</p><p>The sets F and T of functional (or nonterminal) and terminal symbols that are used to build the potential solutions.</p><p>The fitness function f (•).</p><p>The population size N . The maximum size of the individuals, typically expressed as the maximum number of tree nodes or the maximum tree depth. The maximum number of generations.</p><p>The algorithm used to initialize the population. A set of initialization algorithms can be found in <ref type="bibr" target="#b15">[16]</ref>).</p><p>The selection operator.</p><p>Algorithm 1: GP  The crossover rate. The mutation rate. Presence or absence of elitism (i.e. preserving unaltered the best solutions to the next iteration).</p><p>Given a set of n primitive change detection algorithms C = {C k } n k=1 , the solutions evolved by GP are built using the set of functional (or nonterminal) symbols F and the set of terminal symbols T = C. The functional symbols correspond to operations performed on the inputs. We explicitly incorporate into the GP framework the list of operations given in Table I along with their functional symbols. They operate in the spatial neighborhood of the image pixel, or combine (stack) the information at the same pixel location but across different change detection algorithms.</p><p>We define the fitness function used in GP taking inspiration from the CDNET website, where change detection algorithms are evaluated using different performance measures and ranked accordingly. More specifically, the performance measures used are: recall, precision, specificity, false positive ratio (FPR), false negative ratio (FNR), percentage of wrong (pixels) classifications (PWC), and F-Measure <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>. Each measure is averaged across the video sequences. Given a set of video sequences V = {V 1 , . . . , V S }, and a set of performance measures M = {m 1 , . . . , m M }, the fitness of a candidate solution C 0 , f (C 0 ), is based on the average ranking of the solution across all performance metrics, averaged across al frames in all training video sequences V. For each measure there are three components, that are weighted by [w 0 , w 1 , w 2 ]. Then the weighted sum is averaged across all measures. The per-measure components are:</p><p>-the individual's integer rank, when compared against the primitive algorithms, on measure m j ; since the different measure might be uncommensurable with each other, and since finding a single metric to accurately measure the ability of a method to detect motion or change without producing excessive false positives and false negatives is not trivial <ref type="bibr" target="#b3">[4]</ref>, the role of this component is to solve both the issues by producing a single number. -The individual's value on measure m j , shifted by the best value achieved by any primitive algorithm for that measure computed on the frames of the video sequences; the role of this component is that of adding gradient to the integer rank and to continue improving a solution when its rank is 1. -A size penalty equal to the proportion of primitive algorithms used by the individual. The role of this component is to force GP to select a small number of algorithms in C to build the candidate solutions. Formally, the fitness function is defined as follows:</p><formula xml:id="formula_0">f (C 0 ) = 1 M M X j=1 ✓ w 0 • rank ⇣ C 0 ; m j C k (V) n k=1 ⌘ + +w 1 • M X j=1 P j 1 (C 0 ) + w 2 • P 2 (C 0 ) ◆<label>(1)</label></formula><p>where rank(C 0 ; •) computes the rank of the candidate solution C 0 with respect to the set of algorithms C according to the measure m j . P j 1 (C 0 ) is defined as the signed distance between the candidate solution C 0 and the best algorithm in C according to the measure m j :</p><formula xml:id="formula_1">P j 1 (C 0 ) = 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; : m j (C 0 (V)) + max C k :k=1...n m j (C k (V)) if the higher m j the better m j (C 0 (V)) min C k :k=1...n m j (C k (V))</formula><p>if the lower m j the better (2) and P 2 (C 0 ) is a penalty term corresponding to the number of different algorithms selected for the candidate solution C 0 :</p><formula xml:id="formula_2">P 2 (C 0 ) = # of algorithms selected in C 0 # of algorithms in C (3)</formula><p>The relative importance of the three components of the fitness is regulated by the weights w 0 , w 1 and w 2 respectively. Since we want the fitness function to be driven by the first component, i.e. the average rank, and since both P 1 and P 2 output values in the interval [0, 1], we set the weights [w 0 , w 1 , w 2 ] = [1, 0.01, 0.01]. In this way the contribution of P 1 and P 2 are encoded starting from the hundredths, thus avoiding any risk of rank inversion.</p><p>Our proposed combination strategy is able to simultaneously achieve three goals: algorithm selection, combination and processing. The functional symbols in Table <ref type="table">I</ref>, act both as aggregation functions for the combination, as well as image processing functions (specifically the local functions such as the morphological ones and the median filter). Moreover, the nature of the GP algorithm coupled with the penalty factor P 2 , allow us to perform automatic algorithm selection in a seamless manner during the generation of the intermediate solutions. This is an advantage of our proposed strategy compared to other combination algorithms where the selection has to be performed in advance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section we describe the experimental setup used in combining state-of-the art algorithms and the results. We based our experiments on the CDNET 2014 challenge <ref type="bibr" target="#b6">[7]</ref> that has received great attention in the evaluation of change detection algorithms. It provides a set of video sequences of various categories that can be used to test the algorithms on different environment conditions. Moreover, it provides an evaluation protocol that can be used to compare the performances of change detection algorithms against each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Setup</head><p>As the set of algorithms to be combined we considered the top ranked ones that have been evaluated within the CDNET 2014 challenge as of July 2014. We have chosen the top ranked ones because we are interested to investigate how far can we get by combining the top performing change detection algorithms. Table <ref type="table">II</ref> shows the top 9 algorithms listed according to their average ranking across video categories. The outputs of the various algorithms are available on the website allowing us to perform our combination experiment on "certified" data. In our experiments, we selected a subset of the top ranked algorithms and executed the GP algorithm using a training set of video sequences of the CDNET 2014 challenge. In particular, the training set was created by extracting from each category the shortest video sequence. Specifically, these sequences are (category/sequence): baseline/pedestrians, dynamicBackground/canoe, cameraJitter/badminton, intermittentObjectMotion/parking, shadow/peopleInShade, thermal/park, badWeather/wetSnow, lowFramerate/tramCrossroad 1fps, nightVideos/winterStreet, PTZ/zoomInZoomOut, and turbulence/turbulence3.</p><p>As for performance measures we computed them using the framework of the challenge that evaluates the seven different measures listed in the previous section. A ranking of the tested algorithms is also computed starting from the partial ranks on these measures. We evaluate our proposed combining strategy against three different fusion algorithms: a simple majority vote scheme (MV), the STAPLE method <ref type="bibr" target="#b64">[66]</ref>, <ref type="bibr" target="#b65">[67]</ref> (STAPLE), and a probabilistic rand index-based algorithm <ref type="bibr" target="#b67">[69]</ref> (PRIF). Following the challenge's rules, each algorithm uses a single set of parameters. The STAPLE algorithm estimates its parameters on-line (i.e. the sensitivities and specificities of each expert) while for the PRIF algorithm we used the default parameters. The parameters used to initialize the GP algorithm are reported in Table <ref type="table">III</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>We applied GP on different sets C constructed using the top n algorithms in Table <ref type="table">II</ref> with n 2 {3, 5, 7, 9}. For each setting, the shortest best solution across the 25 independent runs is considered. The resulting algorithms, that we named IUTIS-3 and IUTIS-5, are shown in Figure <ref type="figure" target="#fig_0">1</ref> and Figure <ref type="figure" target="#fig_1">2</ref> respectively. In the same figures, for each solution tree, an example of the output at each node on a sample frame is also reported.</p><p>The solutions obtained with n &gt; 5 are not reported since in these cases the GP algorithm found a solution identical to IUTIS-5. This is an evidence that GP is able to automatically select the best set of algorithms. This is one of the major differences between our method and the other fusionbased algorithms considered, which are not able to perform automatic algorithm selection, and thus use all the given algorithms. From the solution trees it is possible to notice that IUTIS-3 automatically created MV-3 in its right branch.  Ramped half-and-half <ref type="bibr" target="#b15">[16]</ref> Selection operator Tournament, with tournament size 5 Crossover and Mutation rates Adaptive: each operator probability value is adapted to reflect its performance. A percentage of the probability value is replaced by a value proportional to the operator's performance <ref type="bibr" target="#b103">[102]</ref>. Elitism Yes Number of runs 25</p><p>IUTIS-5, instead, automatically created as part of the solution MV-3 and MV-5 in its left and right branch respectively. Figure <ref type="figure" target="#fig_2">3</ref> shows the average rank and F-Measure of our solutions compared with the fusion-based algorithms considered (i.e. MV, PRIF, and STAPLE) varying the number of algorithms available in C. For sake of comparison with the other methods in the state of the art performance are measured on the whole CDNET 2014 challenge video sequences. Note that the results on the CDNET website are computed on the whole dataset and the algorithms compared on the website are often tuned on it. Given that the training set contains less than 10% of the total number of frames, the influence of the training set on the performances is negligible. In fact, if we consider for example the overall F-Measure, IUTIS-3 obtains 0.7694 on the whole CDNET 2014 dataset, 0.7781 excluding the video sequences used for training, and 0.7413 on the training set alone. IUTIS-5 respectively obtains 0.7821, 0.7896, and 0.7573. Similar differences are observed for the other performance measures. These numbers permit us to say that no overfitting occurred during training. For completeness, the separate train/test results are reported in Supplementary material. From the plots reported in Figure <ref type="figure" target="#fig_2">3</ref> we can see that the average rank of IUTIS-3 is 3.41 points lower than that of MV-3, while IUTIS-5 is 4.42 points lower that that of MV-5. Since IUTIS-3 and IUTIS-5 contain MV-3 and MV-5 as part of them, this improvement is due to the additional filtering and post-processing operations automatically selected by GP.</p><p>We observe also how the performance of PRIF and STAPLE decrease by increasing the number of algorithms available. MV-5 instead outperforms MV-3, but also in this case the performance decrease for n = 7 and 9. A different trend can be observed for IUTIS, which being able to perform automatic algorithm selection, is able to remove from the final solution those algorithms that could degrade the performance. The complete comparison of our proposed solutions with respect to the single algorithms of Table <ref type="table">II</ref> and fusion-based algorithms in the state-of-the-art is reported in Table <ref type="table" target="#tab_4">IV</ref>. It is possible to notice that all fusion-based algorithms with n  5 outperform all the single algorithm, while this is true only for IUTIS and PRIF for higher values of n. In particular we can observe that there are three categories on which IUTIS-5 is not ranked first, i.e.: Turbulence, Dynamic Background and Intermittent Object Motion.</p><p>To ensure that the performance of IUTIS-5 are statistically different from those of the other algorithms, we conducted a statistical significance analysis on the results in Table VIII using the Friedman test <ref type="bibr" target="#b104">[103]</ref>, <ref type="bibr" target="#b105">[104]</ref>. The analysis shows that there is a statistically significant difference in the performance of the algorithms with a 2 (24) = 240.7 and p &lt; 0.01. We subsequently performed a post-hoc test using pairwise Wilcoxon rank sum test <ref type="bibr" target="#b106">[105]</ref> at the significance level ↵ = 0.05. Table <ref type="table" target="#tab_5">V</ref> shows the p-values of the 25 algorithms against each other. As it can be seen, apart from IUTIS-7 and IUTIS-9, IUTIS-5 compared against the other algorithms, obtains p-values lower than ↵ also considering the Bonferroni correction. This indicates that the performance of IUTIS-5 are significantly different with respect to the other algorithms examined.</p><p>Outputs of some of the tested algorithms on sample frames in the CDNET 2014 dataset are shown in Figure <ref type="figure">4</ref> together with input images and ground truth masks. Detailed evaluation results of the IUTIS-3 and IUTIS-5 algorithms in terms of all the seven performance measures and for each category of the evaluation dataset are reported in Table VI and VII respectively.</p><p>Since the proposed algorithm is stochastic by nature, we report in Figure <ref type="figure">5</ref> two variant solutions found in different runs by our GP fusion scheme using the top 3 algorithms in Table <ref type="table">II</ref>. In most of the runs the solutions found are identical to IUTIS-3. In the rest of cases they have the same overall results. The variants of IUTIS-3 reported in Figure <ref type="figure">5</ref> are taken among the latter ones. These solutions trees are similar to IUTIS-3, have the same overall results, and contain semantic introns <ref type="bibr" target="#b107">[106]</ref>. In fact they possess non-functional branches: the sequence of erosions and dilations in the left branch of the top tree in Figure <ref type="figure">5</ref> is equivalent to a single erosion; in the bottom tree, the top OR operation is uninfluential on the final result. We observe the same behavior for IUTIS-5.</p><p>Finally, Table VIII reports the complete official ranking on the CDNET 2014 website at the moment of the submission (Sept 14 2016). As it can be seen, both our solutions outperform all the evaluated change detection algorithms including the most recent ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation study</head><p>In the introduction we stated that the advantage of using GP is threefold, namely: i) algorithm selection, ii) algorithm combination, iii) post-processing. In this section we conduct an ablation study to separate their contribution. Two new baselines are therefore evaluated. The first one isolates the influence of the choice of primitive algorithms from the other two contributions of the GP, and consists of the majority vote of n algorithms among the 9 available algorithms, where the set of n members is chosen by GA. The relevant GA parameters are the same used for GP (see Table <ref type="table">III</ref>). The second baseline isolates the influence of post-processing from the other contributions, and consists in a GP instance without the post-processing operators. The comparison of IUTIS with these baselines is reported in Figure <ref type="figure" target="#fig_4">6</ref>. Two different lines are present for the GA baseline: the black one (MVGA n) consists of the majority vote of a set of exactly n algorithms, while the gray one (MVGA  n) considers up to n algorithms. The GP instance without the post-processing operators (IUTIS ) is represented by a purple line. From the plot it is possible to see that when n  5, algorithm selection is not able to find a solution better than MV; in these cases, the higher performance of IUTIS is due to the algorithms combination and postprocessing. When n 7 instead, most of the performance gain over the simple MV is due to algorithm selection. Even for the GA baseline, when forced to select n algorithms (i.e. MVGA n), performance start to drop. The plot of the baseline IUTIS is always higher than that of MVGA  n by almost a constant amount, indicating that the logical operators are useful to fuse the outputs of the different algorithms. Concerning the postprocessing, its importance is evinced from the fact that the line of IUTIS is always higher than that of IUTIS . Its influence is larger when a larger number of algorithms is considered (i.e. n &gt; 3). Moreover, MVGA  n often ends up using the same primitive algorithms as are used by IUTIS and IUTIS .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper we have presented an evolutionary approach, based on Genetic Programming, to combine video change detection algorithms to create a more robust algorithm. The solutions provided by Genetic Programming allow us to automatically select the best subset of the input algorithms. This is one of the major differences between our method and the other fusion-based algorithms considered, which are not able to perform automatic algorithm selection, and thus use all the given algorithms. Moreover, we are able to automatically combine them in different ways, and perform post-processing on their outputs using unary, binary and n-ary operators embedded into the Genetic Programming framework.</p><p>We have shown that applying our approach on the best algorithms in the state-of-the-art, we are able to create the IUTIS-5 algorithm that ranks first by a large margin among a total of 32 change detection algorithms on the CDNET 2014. The statistical significance analysis performed using the Friedman test and the Wilcoxon Rank Sum post-hoc tests show that the performance of IUTIS-5 are significantly different from the ones of the other state-of-the-art algorithms.</p><p>As a future work we plan to investigate if the same approach, applied on very simple change detection algorithms, is able to create solutions with comparable results to more complex algorithm. Moreover, it would be interesting to use our framework to create new algorithms from scratch using atomic image processing operators as building blocks. We also plan to investigate the improvement that recent contributions in GP could give such as Pareto multi-objective <ref type="bibr" target="#b108">[107]</ref>, implicit fitness sharing <ref type="bibr" target="#b109">[108]</ref>, <ref type="bibr" target="#b110">[109]</ref> and the use of novelty as an objective <ref type="bibr" target="#b111">[110]</ref>.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Average ranking across categories IUTIS-5 2.18 IUTIS-3 5.45 PAWCS <ref type="bibr" target="#b112">[111]</ref> 6.36 SuBSENSE <ref type="bibr" target="#b43">[45]</ref> 7.82 SharedModel <ref type="bibr" target="#b113">[112]</ref> 8.64 FTSG <ref type="bibr" target="#b36">[38]</ref> 8.82 SaliencySubsense [*]</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. IUTIS-3 solution tree and its example masks. SBS, FTS, and CWS refer to SuBSENSE, FTSG, and CwisarDH algorithm respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. IUTIS-5 solution tree and its example masks. SBS, FTS, CWS, SPC and AMB refer to SuBSENSE, FTSG, CwisarDH, Spectral-360 and AMBER algorithm respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Plots of the average rank (left) and F-measure (right) for the different fusion-based algorithms considered by varying the number of algorithms available in the combination, i.e. n = 3, 5, 7, 9</figDesc><graphic coords="8,54.41,56.07,248.39,187.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>9 Fig. 4 .Fig. 5 .</head><label>945</label><figDesc>Fig. 4. Examples of binary masks created by the tested algorithms. The superscripts indicate in what fusion set C the algorithm is used (e.g. SuBSENSE, FTSG, and CwisarDH are used to build IUTIS-3, MV-3, PROF-3 and STAPLE-3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Plots of the F-measure for the different baseline algorithms considered in the ablation study by varying the number of algorithms available in the combination, i.e. n = 3, 5, 7, 9.</figDesc><graphic coords="10,315.35,56.07,244.31,182.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Perform the crossover between C i and C j with probability p c , and let e C i and e C j be the offspring. If crossover is not applied, let e C i = C i and e C j = C j ;</figDesc><table><row><cell cols="2">1 begin</cell><cell></cell></row><row><cell>2</cell><cell cols="2">Generate a population P composed of an even</cell></row><row><cell></cell><cell cols="2">number N of individuals ;</cell></row><row><cell>3</cell><cell>Generation</cell><cell>0 ;</cell></row><row><cell>4</cell><cell>repeat</cell><cell></cell></row><row><cell>5</cell><cell cols="2">Calculate the fitness f of all the individuals in</cell></row><row><cell></cell><cell cols="2">population P ;</cell></row><row><cell>6</cell><cell cols="2">Create a new empty population P 0 ;</cell></row><row><cell>7</cell><cell>repeat</cell><cell></cell></row><row><cell>8</cell><cell cols="2">Select two individuals C i , C j 2 P using the chosen selection operator ;</cell></row><row><cell>10</cell><cell cols="2">Mutate each node and leaf in e C i and e C j with</cell></row><row><cell></cell><cell cols="2">certain probability p m , and let b C i and b C j be</cell></row><row><cell></cell><cell cols="2">the offspring;</cell></row></table><note><p>9 11 Insert b C i and b C j into population P 0 ; 12 until until population P 0 is composed of exactly N individuals; 13 Perform the copy P P 0 and delete P ; 14 Generation Generation + 1 ; 15 until a termination condition is satisfied;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II TOP 9</head><label>II9</label><figDesc>CHANGE DETECTION ALGORITHMS LISTED ON THE CDNET 2014 CHALLENGE WEBSITE (AS OF JULY 2014) RANKED BY THEIR AVERAGE RANKING ACROSS THE 11 VIDEO CATEGORIES.</figDesc><table><row><cell cols="2">Rank Method</cell><cell cols="2">Abbrev. Description</cell><cell>Reference</cell></row><row><cell>1</cell><cell>FTSG</cell><cell>FTS</cell><cell>Flux Tensor with Split Gaussian models</cell><cell>[38]</cell></row><row><cell>2</cell><cell>SuBSENSE</cell><cell>SBS</cell><cell>Self-Balanced SENsitivity SEgmenter</cell><cell>[45]</cell></row><row><cell>3</cell><cell>CwisarDH</cell><cell>CWS</cell><cell>Change Detection with Weightless Neural Networks</cell><cell>[56]</cell></row><row><cell>4</cell><cell cols="2">Spectral-360 SPC</cell><cell>Change Detection based on Spectral Reflectaces</cell><cell>[57]</cell></row><row><cell>5</cell><cell>AMBER</cell><cell>AMB</cell><cell>Extension of the Adapting Multi-resolution Background ExtractoR</cell><cell>[46]</cell></row><row><cell>6</cell><cell>KNN</cell><cell>KNN</cell><cell>Adaptive Gaussian Mixture Model</cell><cell>[40]</cell></row><row><cell>7</cell><cell>SC SOBS</cell><cell>SCS</cell><cell>Spatial Coherence Self-Organizing Background Subtraction</cell><cell>[54]</cell></row><row><cell>8</cell><cell>RMoG</cell><cell>RMG</cell><cell>Region-based Mixture of Gaussians</cell><cell>[100]</cell></row><row><cell>9</cell><cell>KDE</cell><cell>KDE</cell><cell>Change detection based on Kernel Density Estimation</cell><cell>[101]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV COMPARISON</head><label>IV</label><figDesc>OF OUR PROPOSED SOLUTIONS TO SINGLE AND FUSION-BASED ALGORITHMS IN THE STATE-OF-THE-ART IN TERMS OF RANK IN EACH VIDEO CATEGORY AND AVERAGE RANK.</figDesc><table><row><cell>Method ID</cell><cell cols="2">Avg rank Overall</cell><cell>Bad</cell><cell>Low</cell><cell cols="6">Night PTZ Turb. Base. Dynam. Camera</cell><cell cols="3">Interm. Shadow Therm.</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Weath. F.rate Videos</cell><cell></cell><cell></cell><cell></cell><cell>Backg.</cell><cell cols="2">Jitter Obj. M.</cell><cell></cell><cell></cell></row><row><cell>IUTIS-5</cell><cell>1.25</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>IUTIS-7</cell><cell>1.25</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>IUTIS-9</cell><cell>1.25</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>PRIF-3</cell><cell>4.58</cell><cell>2</cell><cell>3</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>5</cell><cell>3</cell><cell>9</cell><cell>7</cell><cell>6</cell><cell>6</cell><cell>6</cell></row><row><cell>IUTIS-3</cell><cell>4.67</cell><cell>3</cell><cell>2</cell><cell>3</cell><cell>8</cell><cell>5</cell><cell>9</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>8</cell><cell>3</cell><cell>3</cell></row><row><cell>PRIF-5</cell><cell>5.58</cell><cell>4</cell><cell>7</cell><cell>6</cell><cell>5</cell><cell>4</cell><cell>1</cell><cell>10</cell><cell>3</cell><cell>8</cell><cell>7</cell><cell>8</cell><cell>4</cell></row><row><cell>MV-5</cell><cell>5.67</cell><cell>5</cell><cell>9</cell><cell>8</cell><cell>2</cell><cell>6</cell><cell>10</cell><cell>2</cell><cell>10</cell><cell>3</cell><cell>3</cell><cell>6</cell><cell>4</cell></row><row><cell>STAPLE-3</cell><cell>6.00</cell><cell>6</cell><cell>4</cell><cell>5</cell><cell>4</cell><cell>8</cell><cell>6</cell><cell>5</cell><cell>5</cell><cell>8</cell><cell>12</cell><cell>2</cell><cell>7</cell></row><row><cell>PRIF-7</cell><cell>6.50</cell><cell>8</cell><cell>10</cell><cell>4</cell><cell>9</cell><cell>2</cell><cell>3</cell><cell>9</cell><cell>1</cell><cell>6</cell><cell>16</cell><cell>5</cell><cell>5</cell></row><row><cell>MV-3</cell><cell>8.08</cell><cell>7</cell><cell>11</cell><cell>11</cell><cell>6</cell><cell>13</cell><cell>8</cell><cell>6</cell><cell>12</cell><cell>5</cell><cell>4</cell><cell>5</cell><cell>9</cell></row><row><cell>STAPLE-5</cell><cell>8.25</cell><cell>9</cell><cell>6</cell><cell>9</cell><cell>13</cell><cell>12</cell><cell>4</cell><cell>13</cell><cell>7</cell><cell>9</cell><cell>5</cell><cell>4</cell><cell>8</cell></row><row><cell>PRIF-9</cell><cell>8.83</cell><cell>12</cell><cell>12</cell><cell>7</cell><cell>12</cell><cell>9</cell><cell>5</cell><cell>12</cell><cell>6</cell><cell>2</cell><cell>14</cell><cell>8</cell><cell>7</cell></row><row><cell>FTSG</cell><cell>9.67</cell><cell>11</cell><cell>8</cell><cell>14</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>17</cell><cell>8</cell><cell>16</cell><cell>1</cell><cell>6</cell><cell>2</cell></row><row><cell>SuBSENSE</cell><cell>10.67</cell><cell>10</cell><cell>5</cell><cell>10</cell><cell>7</cell><cell>10</cell><cell>7</cell><cell>14</cell><cell>15</cell><cell>15</cell><cell>17</cell><cell>7</cell><cell>11</cell></row><row><cell>MV-7</cell><cell>11.67</cell><cell>13</cell><cell>14</cell><cell>8</cell><cell>14</cell><cell>14</cell><cell>13</cell><cell>7</cell><cell>15</cell><cell>12</cell><cell>9</cell><cell>11</cell><cell>10</cell></row><row><cell>STAPLE-7</cell><cell>11.83</cell><cell>15</cell><cell>11</cell><cell>13</cell><cell>15</cell><cell>16</cell><cell>11</cell><cell>9</cell><cell>13</cell><cell>10</cell><cell>10</cell><cell>9</cell><cell>10</cell></row><row><cell>STAPLE-9</cell><cell>14.17</cell><cell>16</cell><cell>15</cell><cell>15</cell><cell>17</cell><cell>17</cell><cell>15</cell><cell>8</cell><cell>16</cell><cell>13</cell><cell>15</cell><cell>10</cell><cell>13</cell></row><row><cell>MV-9</cell><cell>14.25</cell><cell>17</cell><cell>13</cell><cell>12</cell><cell>17</cell><cell>15</cell><cell>14</cell><cell>11</cell><cell>17</cell><cell>14</cell><cell>13</cell><cell>16</cell><cell>12</cell></row><row><cell>CwisarDH</cell><cell>14.42</cell><cell>14</cell><cell>19</cell><cell>17</cell><cell>12</cell><cell>7</cell><cell>17</cell><cell>16</cell><cell>14</cell><cell>11</cell><cell>20</cell><cell>12</cell><cell>14</cell></row><row><cell>Spectral-360</cell><cell>17.00</cell><cell>18</cell><cell>18</cell><cell>16</cell><cell>11</cell><cell>18</cell><cell>18</cell><cell>19</cell><cell>17</cell><cell>18</cell><cell>21</cell><cell>14</cell><cell>16</cell></row><row><cell>AMBER</cell><cell>17.33</cell><cell>19</cell><cell>16</cell><cell>22</cell><cell>21</cell><cell>23</cell><cell>16</cell><cell>22</cell><cell>11</cell><cell>13</cell><cell>11</cell><cell>15</cell><cell>19</cell></row><row><cell>RMoG</cell><cell>18.58</cell><cell>20</cell><cell>18</cell><cell>21</cell><cell>18</cell><cell>21</cell><cell>21</cell><cell>21</cell><cell>19</cell><cell>19</cell><cell>18</cell><cell>13</cell><cell>14</cell></row><row><cell>SC SOBS</cell><cell>18.75</cell><cell>21</cell><cell>21</cell><cell>20</cell><cell>16</cell><cell>20</cell><cell>22</cell><cell>15</cell><cell>18</cell><cell>17</cell><cell>19</cell><cell>18</cell><cell>18</cell></row><row><cell>KNN</cell><cell>19.00</cell><cell>22</cell><cell>17</cell><cell>18</cell><cell>19</cell><cell>19</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>22</cell><cell>16</cell><cell>15</cell></row><row><cell>KDE</cell><cell>20.00</cell><cell>23</cell><cell>20</cell><cell>19</cell><cell>20</cell><cell>22</cell><cell>19</cell><cell>18</cell><cell>21</cell><cell>21</cell><cell>23</cell><cell>17</cell><cell>17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V p</head><label>V</label><figDesc>-VALUES OF THE PAIRWISE WILCOXON RANK SUM TESTS OF THE 25 ALGORITHMS AT ↵ = 0.05. SIGNIFICANT DIFFERENCES, I.E. p-VALUES BELOW THE BONFERRONI-CORRECTED CRITICAL VALUE, ARE HIGHLIGHTED IN GRAY. IUTIS-7 IUTIS-9 PRIF-3 IUTIS-3 PRIF-5 MV-5 STAPLE-3 PRIF-7 MV-3 STAPLE-5 PRIF-9 FTSG SuBSENSE MV-7 STAPLE-7 STAPLE-9 MV-9 CwisarDH Spect.-360 AMBER RMoG SC SOBS KNN</figDesc><table><row><cell>KDE</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell></row><row><cell></cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell><cell>7.4e-07 7.4e-07</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>4.4e-06</cell><cell>9.6e-06</cell><cell>7.4e-06</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>3.0e-06</cell><cell>5.2e-06</cell><cell>1.0e-05</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>2.2e-06</cell><cell>5.9e-06</cell><cell>5.0e-05</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>1.5e-05</cell><cell>3.8e-05</cell><cell>1.2e-04</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell>2.2e-04</cell><cell>1.6e-03</cell><cell>2.3e-03</cell></row><row><cell></cell><cell>3.0e-06 5.3e-05</cell><cell>3.0e-06 5.3e-05</cell><cell>3.0e-06 5.3e-05</cell><cell>1.0e-02</cell><cell>1.4e-02</cell><cell>2.6e-02 2.1e-02</cell><cell>3.9e-02 3.6e-02</cell></row><row><cell></cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell>7.4e-07</cell><cell></cell><cell></cell><cell>4.8e-02</cell><cell>7.9e-02</cell></row><row><cell></cell><cell>5.0e-05 7.4e-07</cell><cell>5.0e-05 7.4e-07</cell><cell>5.0e-05 7.4e-07</cell><cell>2.9e-01 7.3e-03</cell><cell></cell><cell>6.8e-01 6.0e-02</cell><cell>8.0e-01 6.8e-02</cell></row><row><cell></cell><cell>3.0e-06</cell><cell>3.0e-06</cell><cell>3.0e-06</cell><cell>2.1e-01</cell><cell></cell><cell>7.6e-01</cell><cell>7.6e-01</cell></row><row><cell></cell><cell>1.0e+00 1.0e+00 7.4e-06 3.0e-06 2.3e-05 7.4e-06</cell><cell>-1.0e+00 7.4e-06 3.0e-06 2.3e-05 7.4e-06</cell><cell>--7.4e-06 3.0e-06 2.3e-05 7.4e-06</cell><cell>---8.7e-01 2.5e-01 4.3e-01</cell><cell>-</cell><cell>-----9.7e-01</cell><cell>------</cell></row><row><cell></cell><cell>IUTIS-5</cell><cell>IUTIS-7</cell><cell>IUTIS-9</cell><cell>PRIF-3</cell><cell>IUTIS-3</cell><cell>PRIF-5</cell><cell>MV-5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI DETAILED</head><label>VI</label><figDesc>EVALUATION RESULTS OF THE IUTIS-3 ALGORITHM FOR EACH CATEGORY OF THE EVALUATION DATASET.</figDesc><table><row><cell>Scenarios</cell><cell cols="2">Recall Specificity</cell><cell>FPR</cell><cell>FNR</cell><cell>PWC Precision FMeasure</cell></row><row><cell>Overall</cell><cell>0.7896</cell><cell cols="4">0.9944 0.0056 0.2104 1.1813</cell><cell>0.7951</cell><cell>0.7694</cell></row><row><cell>Bad Weather</cell><cell>0.7502</cell><cell cols="4">0.9993 0.0007 0.2498 0.5010</cell><cell>0.9280</cell><cell>0.8246</cell></row><row><cell>Low Framerate</cell><cell>0.8183</cell><cell cols="4">0.9964 0.0036 0.1817 0.8224</cell><cell>0.7813</cell><cell>0.7949</cell></row><row><cell>Night Videos</cell><cell>0.6243</cell><cell cols="4">0.9839 0.0161 0.3757 2.4354</cell><cell>0.4312</cell><cell>0.4814</cell></row><row><cell>PTZ</cell><cell>0.6508</cell><cell cols="4">0.9885 0.0115 0.3492 1.4869</cell><cell>0.3886</cell><cell>0.4230</cell></row><row><cell>Turbulence</cell><cell>0.7708</cell><cell cols="4">0.9998 0.0002 0.2292 0.1823</cell><cell>0.9368</cell><cell>0.8416</cell></row><row><cell>Baseline</cell><cell>0.9712</cell><cell cols="4">0.9981 0.0019 0.0288 0.3002</cell><cell>0.9393</cell><cell>0.9546</cell></row><row><cell>Dynamic Background</cell><cell>0.8778</cell><cell cols="4">0.9993 0.0007 0.1222 0.1985</cell><cell>0.9239</cell><cell>0.8960</cell></row><row><cell>Camera Jitter</cell><cell>0.7923</cell><cell cols="4">0.9924 0.0076 0.2077 1.5231</cell><cell>0.8520</cell><cell>0.8139</cell></row><row><cell cols="2">Intermittent Object Motion 0.6987</cell><cell cols="4">0.9946 0.0054 0.3013 3.2481</cell><cell>0.8146</cell><cell>0.7136</cell></row><row><cell>Shadow</cell><cell>0.9478</cell><cell cols="4">0.9914 0.0086 0.0521 1.0410</cell><cell>0.8585</cell><cell>0.8984</cell></row><row><cell>Thermal</cell><cell>0.7832</cell><cell cols="4">0.9945 0.0055 0.2168 1.2552</cell><cell>0.8922</cell><cell>0.8210</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII DETAILED</head><label>VII</label><figDesc>EVALUATION RESULTS OF THE IUTIS-5 ALGORITHM FOR EACH CATEGORY OF THE EVALUATION DATASET.</figDesc><table><row><cell>Scenarios</cell><cell cols="2">Recall Specificity</cell><cell>FPR</cell><cell>FNR</cell><cell>PWC Precision FMeasure</cell></row><row><cell>Overall</cell><cell>0.7972</cell><cell cols="4">0.9952 0.0048 0.2028 1.0863</cell><cell>0.8105</cell><cell>0.7821</cell></row><row><cell>Bad Weather</cell><cell>0.7503</cell><cell cols="4">0.9994 0.0006 0.2497 0.4977</cell><cell>0.9349</cell><cell>0.8289</cell></row><row><cell>Low Framerate</cell><cell>0.8376</cell><cell cols="4">0.9974 0.0026 0.1624 0.7452</cell><cell>0.7724</cell><cell>0.7911</cell></row><row><cell>Night Videos</cell><cell>0.6333</cell><cell cols="4">0.9848 0.0152 0.3667 2.3252</cell><cell>0.4578</cell><cell>0.5132</cell></row><row><cell>PTZ</cell><cell>0.6687</cell><cell cols="4">0.9917 0.0083 0.3313 1.1465</cell><cell>0.4348</cell><cell>0.4703</cell></row><row><cell>Turbulence</cell><cell>0.7730</cell><cell cols="4">0.9999 0.0001 0.2270 0.1713</cell><cell>0.9624</cell><cell>0.8507</cell></row><row><cell>Baseline</cell><cell>0.9680</cell><cell cols="4">0.9983 0.0017 0.0320 0.3053</cell><cell>0.9464</cell><cell>0.9567</cell></row><row><cell>Dynamic Background</cell><cell>0.8636</cell><cell cols="4">0.9996 0.0004 0.1364 0.1808</cell><cell>0.9324</cell><cell>0.8902</cell></row><row><cell>Camera Jitter</cell><cell>0.8220</cell><cell cols="4">0.9925 0.0075 0.1780 1.4389</cell><cell>0.8511</cell><cell>0.8332</cell></row><row><cell cols="2">Intermittent Object Motion 0.7047</cell><cell cols="4">0.9963 0.0037 0.2953 3.0420</cell><cell>0.8501</cell><cell>0.7296</cell></row><row><cell>Shadow</cell><cell>0.9492</cell><cell cols="4">0.9923 0.0077 0.0508 0.9484</cell><cell>0.8766</cell><cell>0.9084</cell></row><row><cell>Thermal</cell><cell>0.7990</cell><cell cols="4">0.9952 0.0048 0.2010 1.1484</cell><cell>0.8969</cell><cell>0.8303</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VIII AVERAGE</head><label>VIII</label><figDesc>RANKING OF THE ALGORITHMS OF THE CHANGEDETECTION.NET WEBSITE AS PERSEPT 14 2016.    </figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Classification of smart video surveillance systems for commercial applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moniri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chibelushi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Video and Signal Based Surveillance, 2005. AVSS 2005. IEEE Conference on</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="638" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Background subtraction techniques: a review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Piccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3099" to="3104" />
		</imprint>
	</monogr>
	<note>Systems, Man and Cybernetics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sobral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="4" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A novel video dataset for change detection benchmarking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Goyette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-M</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ishwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4663" to="4679" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Background modeling methods in video analysis: A review and comparative evaluation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">{CAAI} Transactions on Intelligence Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="60" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Evaluation of background subtraction algorithms with post-processing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Parks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Fels</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="192" to="199" />
		</imprint>
	</monogr>
	<note>Advanced Video and Signal Based Surveillance, 2008. AVSS&apos;08</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CDnet 2014: An expanded change detection benchmark dataset</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-M</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Benezeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ishwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="393" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Changedetection.net: A new change detection benchmark dataset</title>
		<author>
			<persName><forename type="first">N</forename><surname>Goyette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ishwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GPU implementation of extended gaussian mixture model for background subtraction</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Bac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing and Communication Technologies, Research, Innovation, and Vision for the Future (RIVF), 2010 IEEE RIVF International Conference on</title>
		<imprint>
			<date type="published" when="2010-11">Nov 2010</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real-time discriminative background subtraction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Caelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1401" to="1414" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parallel implementation of background subtraction algorithms for real-time video processing on a supercomputer platform</title>
		<author>
			<persName><forename type="first">G</forename><surname>Szwoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ellwart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Czyewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Real-Time Image Processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hyperheuristics: learning to combine simple heuristics in bin-packing problems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schulenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Marín-Blázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GECCO</title>
		<imprint>
			<biblScope unit="page" from="942" to="948" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A genetic programming hyper-heuristic approach for evolving 2-d strip packing heuristics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="942" to="958" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Automatic Design of Decision-Tree Induction Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Freitas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
	<note>Evolutionary algorithms and hyper-heuristics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Metaheuristics for specialization of a segmentation algorithm for ultrasound images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rogai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manfredi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bocchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Genetic programming: on the programming of computers by means of natural selection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Koza</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image change detection algorithms: a systematic survey</title>
		<author>
			<persName><forename type="first">R</forename><surname>Radke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Andra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Al-Kofahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="294" to="307" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Moving object detection in spatial domain using background removal techniques-stateof-art</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Elhabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>El-Sayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Recent patents on computer science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="54" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Background subtraction for automated multisensor surveillance: a comprehensive review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farenzena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bloisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Advances in signal Processing</title>
		<imprint>
			<biblScope unit="volume">2010</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recent advanced statistical background modeling for foreground detection -a systematic survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bouwmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Recent Patents on Computer Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="147" to="176" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Comparative study of background subtraction algorithms</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benezeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-M</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Emile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Laurent</surname></persName>
		</author>
		<idno>pp. 033 003-033 003</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Segmentation and tracking of piglets in images</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mcfarlane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schofield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="187" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detecting moving objects, ghosts, and shadows in video streams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1337" to="1342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Speed up temporal median filter for background subtraction</title>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pervasive Computing Signal Processing and Applications (PCSPA), 2010 First International Conference on</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Moving object recognition using an adaptive background memory</title>
		<author>
			<persName><forename type="first">K</forename><surname>Karman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time-Varying Image Processing and Moving Object Recognition</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="297" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive background estimation and foreground detection using kalman-filtering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ridder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Munkelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kirchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on recent Advances in Mechatronics</title>
		<meeting>International Conference on recent Advances in Mechatronics</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="193" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Sen-Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kamath</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Robust techniques for background</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Extracting roadway background image: Mode-based approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hallenbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record: Journal of the Transportation Research Board</title>
		<imprint>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="1944">1944. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pfinder: Real-time tracking of the human body</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Azarbayejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="780" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive background mixture models for real-time tracking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stauffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="246" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust foreground extraction technique using background subtraction with multiple thresholds</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sakamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kitahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Toriyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kogure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="97" to="101" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Finite general gaussian mixture modeling and application to image and video foreground segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Allili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bouguila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziou</surname></persName>
		</author>
		<idno>pp. 013 005-013 005</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bayesian modeling of dynamic scenes for object detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1778" to="1792" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A bayesian approach to background modeling</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition-Workshops, 2005. CVPR Workshops. IEEE Computer Society Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="58" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Statistical modeling of complex backgrounds for foreground object detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-H</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1459" to="1472" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bayesian foreground and shadow detection in uncertain frame rate surveillance videos</title>
		<author>
			<persName><forename type="first">C</forename><surname>Benedek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Szirányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="608" to="621" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Static and moving object detection using flux tensor with split gaussian models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bunyak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seetharaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palaniappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="420" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Background and foreground modeling using nonparametric kernel density estimation for visual surveillance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Duraiswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1151" to="1163" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient adaptive density estimation per image pixel for the task of background subtraction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zivkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Der Heijden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="773" to="780" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A fast algorithm for adaptive background model construction using parzen density estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R.-I</forename><surname>Taniguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Video and Signal Based Surveillance, 2007. AVSS 2007. IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="528" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evaluation report of integrated background modeling based on spatio-temporal features</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nonaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nagahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R.-I</forename><surname>Taniguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE Conference</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Vibe: A universal background subtraction algorithm for video sequences</title>
		<author>
			<persName><forename type="first">O</forename><surname>Barnich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Droogenbroeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1709" to="1724" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Flexible background subtraction with self-balanced local sensitivity</title>
		<author>
			<persName><forename type="first">P.-L</forename><surname>St-Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-A</forename><surname>Bilodeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bergevin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="414" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SuBSENSE: A universal change detection method with local adaptive sensitivity</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A fast self-tuning background subtraction algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dudek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="401" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A bayesian computer vision system for modeling human interactions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rosario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="831" to="843" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On incremental and robust subspace learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1509" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Incremental subspace learning via nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bucak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gunsel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="788" to="797" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A probabilistic approach robust matrix factorization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision ? ECCV 2012</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7578</biblScope>
			<biblScope unit="page" from="126" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">background model Signal on</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1641" to="1654" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Density-based multifeature background subtraction with support vector machine</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1017" to="1023" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Neural network approach to background modeling for video object segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Culibrk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Socek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kalva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Furht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1614" to="1627" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. on</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The SOBS algorithm: what are the limits?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maddalena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petrosino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Neural background subtraction for pantilt-zoom cameras</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ferone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maddalena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems, Man, and Cybernetics: Systems, IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Change detection with weightless neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gregorio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Giordano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="409" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Spectral-360: A physicsbased technique for change detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moniri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chibelushi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="405" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Overview and benchmarking of motion detection methods</title>
		<author>
			<persName><forename type="first">P.-M</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pierard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Droogenbroeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Background Modeling and Foreground Detection for Video Surveillance</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hatef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="226" to="239" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>On combining classifiers</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<title level="m">Combining Pattern Classifiers: Methods and Algorithms</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An overview of classifier fusion methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ruta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gabrys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing and Information systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Classifier selection for majority voting</title>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="81" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>diversity in Multiple Classifier Systems</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multiple binary classifiers fusion using induced intuitionistic fuzzy ordered weighted average operator</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information and Automation (ICIA)</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="230" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">An empirical study of binary classifier fusion methods for multiclass classification</title>
		<author>
			<persName><forename type="first">N</forename><surname>García-Pedrajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ortiz-Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="130" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Combining multiple segmentation methods for improving the segmentation accuracy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aljahdali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zanaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers and Communications, 2008. ISCC 2008. IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="649" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Validation of image segmentation and expert quality with an expectation-maximization algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention?MICCAI 2002</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="298" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Simultaneous truth and performance level estimation (STA-PLE): an algorithm for the validation of image segmentation</title>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="903" to="921" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. on</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Performancebased classifier combination in atlas-based image segmentation using expectation-maximization parameter estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Russakoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Maurer</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="983" to="994" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>IEEE Trans. on</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A label field fusion bayesian model and its penalized maximum rand estimator for image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mignotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1610" to="1624" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Multimode</forename><surname>Backgr</surname></persName>
		</author>
		<author>
			<persName><surname>Subtr</surname></persName>
		</author>
		<idno>12.36 C-EFIC [113] 12.91</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Multimode</forename><surname>Backgr</surname></persName>
		</author>
		<author>
			<persName><surname>Subtr</surname></persName>
		</author>
		<idno>14.55 EFIC [115] 14.73 CwisarDH [56] 14.82 Spectral-360 [57] 17.73 Sample based background subtractor (SBBS) [*] 18.55 AMBER [46] 19.36 AAPSA [116] 21.18</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><surname>Graphcutdiff</surname></persName>
		</author>
		<idno>117] 23.00 KNN [40] 23.55 SC SOBS [54] 23.55 Mahalanobis distance [21] 24.00 SOBS CF [118] 24.09 RMoG [100] 24.27 KDE [101] 25.73 GMM Stauffer &amp; Grimson [31] 27.73 CP3-online [119] 27.73 GMM Zivkovic [120] 28.91 Multiscale Spatio-Temporal BG Model [121] 30.36 Euclidean distance [21] 32.00</idno>
		<title level="m">Note: Methods with reference</title>
		<imprint/>
	</monogr>
	<note>have been submitted to journals or conferences. See the changedetection.net website for current status</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Segmentation by fusion of histogram-based-means clusters in different color spaces</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="780" to="787" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Image Processing</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Bayesian image segmentation fusion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="162" to="168" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">A brief review of nature-inspired algorithms for optimization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Fister</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.4186</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">An overview of evolutionary algorithms for parameter optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Evolutionary model building under streaming data for classification tasks: opportunities and challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Heywood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Programming and Evolvable Machines</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="283" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A survey on evolutionary computation approaches to feature selection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="606" to="626" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Image segmentation using evolutionary computation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Bhandarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A survey of genetic algorithms applications for image enhancement and segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Paulinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ušinskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Technology and control</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="278" to="284" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A review of bio-inspired algorithms as image processing techniques</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E A</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Ariff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Noor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Software Engineering and Computer Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="660" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Texture segmentation by genetic programming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ciesielski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="481" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Genetic programming based image segmentation with applications to biomedical object detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Annual conference on Genetic and evolutionary computation</title>
		<meeting>the 11th Annual conference on Genetic and evolutionary computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1123" to="1130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">An evolutionary approach for image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amelio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pizzuti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="525" to="557" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Genetic programming with user-driven selection: Experiments on the evolution of algorithms for image enhancement</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cagnoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic Programming</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="269" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A genetic programming based system for the automatic construction of image filters</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Pedrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">O</forename><surname>Roda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R R</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Tronco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Tsunaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Morandin</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Nicoletti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Integrated Computer-Aided Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="287" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Image classification: an evolutionary approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Agnelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bollini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lombardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="303" to="309" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Multiclass object classification using genetic programming</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Smart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshops on Applications of Evolutionary Computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="369" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A novel approach to design classifiers using genetic programming</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Muni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="196" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Two-tier genetic programming: towards raw pixel-based image classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Neshatian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="12" to="291" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">A one-shot learning approach to image classification using genetic programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Joint Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="110" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Binary image classification: A genetic programming approach to the problem of limited training instances</title>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="182" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Visual learning by evolutionary and coevolutionary feature synthesis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Krawiec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="635" to="650" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Automated design of image operators that detect interest points</title>
		<author>
			<persName><forename type="first">L</forename><surname>Trujillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Olague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="483" to="507" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Evolving novel image features using genetic programming-based image transforms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kowaliw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="2502" to="2507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Networks of transformbased evolvable features for object recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kowaliw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Doursat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation, ser. GECCO &apos;13</title>
		<meeting>the 15th Annual Conference on Genetic and Evolutionary Computation, ser. GECCO &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1077" to="1084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Automatically evolving rotation-invariant texture image descriptors by genetic programming</title>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Cross-domain reuse of extracted knowledge in genetic programming for image classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary computation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Learning motion detectors by genetic programming</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Joint Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Selective motion detection by genetic programming</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Congress of Evolutionary Computation (CEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Learning spatio-temporal representations for action recognition: a genetic programming approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="158" to="170" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Spatial mixture of gaussians for dynamic background modelling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Video and Signal Based Surveillance (AVSS), 2013 10th IEEE International Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="63" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Non-parametric model for background subtraction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer VisionECCV 2000</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="751" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Adapting operator probabilities in genetic algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Genetic Algorithms&apos;89</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine learning research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Evaluating learning algorithms: a classification perspective</title>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics bulletin</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A comparison of linear genetic programming and neural networks in medical data mining</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brameier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A multi-objective genetic programming approach to developing pareto optimal decision trees</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="809" to="826" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Every niching method has its niche: Fitness sharing and implicit sharing compared</title>
		<author>
			<persName><forename type="first">P</forename><surname>Darwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Problem Solving from Nature</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="398" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Fitness sharing and niching methods revisited</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sareni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Abandoning objectives: Evolution through the search for novelty alone</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="223" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">A self-adjusting approach to change detection based on background word consensus</title>
		<author>
			<persName><forename type="first">P.-L</forename><surname>St-Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-A</forename><surname>Bilodeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bergevin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="990" to="997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Learning sharable models for robust background subtraction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">C-EFIC: Color and edge based foreground background segmentation with interior classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Allebosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Hamme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Deboeverie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Veelaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="433" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Background subtraction for static &amp; moving camera</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sajid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><forename type="middle">S</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">EFIC: Edge based foreground background segmentation and interior classification for dynamic camera viewpoints</title>
		<author>
			<persName><forename type="first">G</forename><surname>Allebosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Deboeverie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Veelaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Concepts for Intelligent Vision Systems, ser</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9386</biblScope>
			<biblScope unit="page" from="130" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Auto-adaptive parallel {SOM} architecture with a modular analysis for dynamic object segmentation in videos</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ramrez-Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Chacn-Murgua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main">Change detection based on graph cuts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Badii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">A fuzzy spatial coherence-based approach to background/foreground separation for moving object detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maddalena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petrosino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="186" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Improvements and experiments of a compact statistical background model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaneko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.6275</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Improved adaptive gaussian mixture model for background subtraction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zivkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition. ICPR. International Conference on</title>
		<imprint>
			<date type="published" when="2004-08">Aug 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="28" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">A multiscale spatio-temporal background model for motion detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing (ICIP), IEEE International Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
