<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Twig: Profile-Guided BTB Prefetching for Data Center Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tanvir</forename><forename type="middle">Ahmed</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Brown</surname></persName>
							<email>nlbrow@umich.edu</email>
						</author>
						<author>
							<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
							<email>akshitha@umich.edu</email>
						</author>
						<author>
							<persName><forename type="first">Niranjan</forename><surname>Soundararajan</surname></persName>
							<email>niranjan.k.soundararajan@intel.com</email>
						</author>
						<author>
							<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
							<email>rakesh.kumar@ntnu.no</email>
						</author>
						<author>
							<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
							<email>sreenivas.subramoney@intel.com</email>
						</author>
						<author>
							<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
							<email>hlitz@ucsc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Tanvir</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Akshitha</forename><surname>Brown</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Niranjan</forename><surname>Sriraman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rakesh</forename><surname>Soundararajan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sreenivas</forename><surname>Devietti</surname></persName>
							<email>devietti@cis.upenn.edu</email>
						</author>
						<author>
							<persName><surname>Subramoney</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Intel Labs</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Norwegian University of Science and Technology</orgName>
								<address>
									<country>Norway Joseph Devietti</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Intel Labs</orgName>
								<address>
									<country>India Gilles Pokam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Twig: Profile-Guided BTB Prefetching for Data Center Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3466752.3480124</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Prefetching</term>
					<term>frontend stalls</term>
					<term>branch target buffer</term>
					<term>data center</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern data center applications have deep software stacks, with instruction footprints that are orders of magnitude larger than typical instruction cache (I-cache) sizes. To efficiently prefetch instructions into the I-cache despite large application footprints, modern server-class processors implement a decoupled frontend with Fetch Directed Instruction Prefetching (FDIP). In this work, we first characterize the limitations of a decoupled frontend processor with FDIP and find that FDIP suffers from significant Branch Target Buffer (BTB) misses. We also find that existing techniques (e.g., stream prefetchers and predecoders) are unable to mitigate these misses, as they rely on an incomplete understanding of a program's branching behavior.</p><p>To address the shortcomings of existing BTB prefetching techniques, we propose Twig, a novel profile-guided BTB prefetching mechanism. Twig analyzes a production binary's execution profile to identify critical BTB misses and inject BTB prefetch instructions into code. Additionally, Twig coalesces multiple non-contiguous BTB prefetches to improve the BTB's locality. Twig exposes these techniques via new BTB prefetch instructions. Since Twig prefetches BTB entries without modifying the underlying BTB organization, it is easy to adopt in modern processors. We study Twig's behavior across nine widely-used data center applications, and demonstrate that it achieves an average 20.86%</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern data center applications have deep software stacks that are composed of complex application logic <ref type="bibr" target="#b54">[56]</ref>, diverse libraries <ref type="bibr" target="#b36">[38]</ref>, and numerous kernel modules <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b44">46]</ref>. Such deep stacks result in multi-megabyte instruction footprints <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b57">59</ref>] that easily exhaust typical on-chip cache structures which are smaller than hundred kilobytes <ref type="bibr" target="#b12">[14]</ref>. As a result, data center applications suffer from significant frontend stalls, when the processor frontend is unable to supply instructions to the processor backend. Such frontend stalls significantly hurt the Total Cost of Operation of a data center, as even single-digit performance improvements of frontend stalls can save millions of dollars and meaningfully reduce the global carbon footprint <ref type="bibr" target="#b77">[79]</ref>.</p><p>Processor architects attempt to address this overwhelming frontend stall problem by proposing numerous instruction prefetching mechanisms <ref type="bibr">[25, 26, 39, 44-46, 60, 69, 76]</ref>. Fetch Directed Instruction Prefetching (FDIP) <ref type="bibr" target="#b67">[69]</ref> is one such mechanism that is pervasively explored in academia <ref type="bibr" target="#b40">[42,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b44">46]</ref> and industry <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>. Between the branch prediction unit and the instruction fetch engine, FDIP introduces a queue containing the addresses of I-cache lines that will be accessed in the future <ref type="bibr" target="#b66">[68]</ref>. FDIP prefetches I-cache lines based on the queue contents to avoid instruction fetch stalls. FDIP allows the branch prediction unit and the instruction fetch engine to operate independently with high efficiency. Prior work <ref type="bibr" target="#b33">[35]</ref> has shown that FDIP provides comparable performance to aggressive Icache prefetchers <ref type="bibr" target="#b52">[54,</ref><ref type="bibr" target="#b68">70,</ref><ref type="bibr" target="#b72">74]</ref> used in recent instruction prefetching championships. Due to its success, FDIP has been widely implemented in modern processors <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b59">61,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b78">80]</ref>.</p><p>Given that data center applications still continue to face the frontend stall problem, we first ask the question: What limits FDIP from eliminating all frontend stalls? To this end, we comprehensively study FDIP in the context of frontend-bound data center applications and show that FDIP still falls significantly short of an ideal I-cache (by 24% on average). We also find that FDIP's effectiveness primarily depends on the efficacy of the Branch Target Buffer (BTB); therefore, the large number of BTB misses, which is typical for data center applications, hurts FDIP's effectiveness. We then investigate the reasons behind the large number of BTB misses for data center applications. We find that these applications contain a large number of unique branch instructions that cannot fit into moderately-sized BTBs. Furthermore, we show that the state-of-the-art BTB prefetching techniques, such as Shotgun <ref type="bibr" target="#b43">[45]</ref> and Confluence <ref type="bibr" target="#b38">[40]</ref>, suffer from limited prefetching coverage and accuracy while introducing significant hardware modifications. For this reason, they have not been adopted in modern data center processors <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b39">41]</ref>.</p><p>In this paper, we propose Twig, a novel profile-guided BTB prefetching mechanism for data center applications. Unlike prior techniques <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b43">45]</ref>, Twig does not require any modifications to the typical BTB organization. Instead, Twig introduces a new BTB prefetching instruction that is directly injected into the program binary at link time. By inserting BTB prefetch instructions in software, Twig leverages the rich execution information available in a program profile, when collected using performance counters in modern data center environments <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b56">58]</ref>.</p><p>Twig introduces two key techniques: software BTB prefetching and BTB prefetch coalescing.</p><p>Software BTB prefetching. A BTB entry is composed of a branch instruction address and a corresponding branch target address. To prefetch a BTB entry, the processor has to decode the branch target of a given branch instruction. However, the branch instruction itself may not be present in the I-cache, rendering BTB prefetching impossible. Twig addresses this challenge by introducing an explicit prefetch instruction to prefetch BTB entries in advance, without bringing the required instructions into the I-cache. This prefetch instruction prefetches branch instruction address and target into the BTB. Unlike pure hardware techniques that rely on limited past run-time information <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b43">45]</ref>, Twig determines which branch instructions cause frequent BTB misses based on profiles collected from the entire program execution. Twig's prefetch instruction takes as operands the address of the branch instruction and the address of the corresponding target instruction. Twig then ensures that the corresponding entry is inserted into the BTB even if the branch instruction is not in the I-cache.</p><p>Twig further leverages production execution profiles to identify program locations that can predict the future execution of a BTBmiss inducing branch instruction with high accuracy and timeliness. Twig then inserts prefetch instructions into these locations.</p><p>BTB prefetch coalescing. Inserting many BTB prefetch instructions with multiple parameters can increase the static and dynamic instruction footprint. To mitigate this code bloat, Twig proposes BTB prefetch coalescing, where multiple BTB entries are prefetched with a single instruction. Twig analyzes the program profile to identify consecutively-executed branches that incur repetitive BTB misses. Consequently, Twig uses the coalesced prefetching instruction to prefetch the BTB entries of all of these branch instructions simultaneously.</p><p>We evaluate Twig in the context of nine data center applications that suffer from frequent frontend stalls. Twig achieves an average 20.86% (2%-145%) speedup over a baseline 8K-entry BTB across all nine applications, while reducing 65.4% of all BTB misses. Compared to the state-of-the-art BTB prefetcher <ref type="bibr" target="#b43">[45]</ref>, Twig achieves an average 19.82% (up to 139.8%) greater speedup, while covering 57.4% more BTB misses. Twig's average static and dynamic instruction increase overhead is 6% and 3% respectively.</p><p>In summary, we contribute: • A detailed characterization of a decoupled frontend with FDIP that shows that a large number of BTB misses hurt FDIP's effectiveness. • Software BTB prefetching: A technique to prefetch BTB entries that improves the decoupled frontend's performance by avoiding costly BTB misses. • BTB prefetch coalescing: A profile-guided mechanism to coalesce multiple BTB prefetch operations that reduces prefetch instructions' static and dynamic overhead. • An evaluation of Twig in the context of nine data center applications, showing its effectiveness in reducing BTB misses and achieving significant performance benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LIMITATIONS OF PRIOR I-CACHE &amp; BTB PREFETCHING TECHNIQUES</head><p>In this section, we comprehensively characterize existing I-cache and BTB prefetching mechanisms to understand why data center applications continue to suffer from frontend stalls. We first analyze FDIP <ref type="bibr" target="#b67">[69]</ref>, the state-of-the-art prefetching technique in processors with a decoupled frontend. We measure the unrealized performance potential of FDIP and find that its performance is mainly limited by BTB misses. We then analyze Shotgun <ref type="bibr" target="#b43">[45]</ref> and Confluence <ref type="bibr" target="#b38">[40]</ref>, two recently proposed techniques that introduce BTB prefetching on top of FDIP. While these techniques reduce BTB misses for some applications, they fail to eliminate BTB misses that occur due to complex branch patterns faced by data center applications. We characterize nine popular real-world data center applications <ref type="bibr" target="#b39">[41]</ref> that face significant frontend stalls. In Fig. <ref type="figure">1</ref>, we use Intel's Top-Down methodology <ref type="bibr" target="#b86">[88]</ref> to show that these applications spend 24%-78% of the processor pipeline slots in waiting for the frontend to return. Two applications, finagle-chirper (a microblogging service) and finagle-http (an HTTP server) are from the Java Renaissance <ref type="bibr" target="#b64">[66]</ref> benchmark suite and use Twitter <ref type="bibr">Finagle [7]</ref> which is a Remote Procedure Call (RPC) library. Three applications, kafka <ref type="bibr" target="#b82">[84]</ref> (Apache stream-processing framework used by companies like Uber, Linkedin, and Airbnb <ref type="bibr" target="#b2">[3]</ref>), tomcat [4] (opensource Java web server), and cassandra [2] (NoSQL DBMS used by companies like Uber, Netflix, and Grubhub <ref type="bibr" target="#b84">[86]</ref>) are from the Java DaCapo <ref type="bibr" target="#b15">[17]</ref> benchmark suite. We also study three HHVM <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b53">55]</ref> applications (drupal, wordpress, and mediawiki) from Facebook's OSS-performance <ref type="bibr" target="#b7">[9]</ref> benchmark suite. verilator [8] is a tool used by companies like Intel and ARM to evaluate custom hardware designs <ref type="bibr" target="#b83">[85]</ref>. We detail our experimental setup, trace collection methodology, and simulation parameters in §4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">What stops FDIP from eliminating all frontend stalls?</head><p>Recent processor designs <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b59">61,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b78">80</ref>] have adopted decoupled frontends with FDIP to reduce costly frontend stalls. Given FDIP's widespread adoption <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>, we ask the question: Does FDIP achieve performance comparable to an ideal/perfect frontend where pipeline slots are not stalled in the frontend? To this end, we analyze FDIP's limitations, characterizing why FDIP falls short for data center applications. Additionally, we determine how to address FDIP's limitations. We perform two limit studies, measuring the Instructions Per Cycle (IPC) metric of nine data center applications running on an FDIP-enabled processor. In the first study, we analyze FDIP with an ideal I-cache (i.e., every I-cache access is a hit), and in the second study, we analyze FDIP with an ideal BTB (i.e., every branch target Figure <ref type="figure">4</ref>: Breakdown of all BTB misses using 3C miss classification <ref type="bibr" target="#b31">[33]</ref>: data center applications suffer BTB misses due to both capacity and conflict issues.</p><p>lookup is a hit). We assume a 75KB 8K-entry BTB and a 32KB I-cache. Fig. <ref type="figure">2</ref> shows an average IPC improvement of 24% with an ideal I-cache and a 31% improvement with an ideal BTB. FDIP with an ideal BTB offers greater performance benefits since (1) it eliminates almost all I-cache misses (due to FDIP prefetching) and</p><p>(2) it reduces branch resteers (i.e., pipeline flushes) triggered by BTB misses. Hence, we conclude that reducing BTB misses is critical to mitigating frontend stalls. Next, we investigate why data center applications suffer from poor BTB locality even with a relatively large, 75KB 8K-entry BTB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Why is a large BTB insufficient for data center applications?</head><p>As an ideal BTB significantly improves FDIP's performance, we examine how we can improve the performance of the 75KB 8K-entry BTB that is implemented in today's FDIP-enabled processors. Fig. <ref type="figure">3</ref> shows the BTB Misses Per Kilo Instructions (MPKI) across all nine data center applications. While measuring BTB MPKI, we only consider real BTB misses caused by direct branch instructions, i.e., unconditional jumps, calls, and conditional jumps. We do not include non-control flow instructions or branch instructions where the branch target that the BTB returns is different from the actually taken branch target (e.g., branch target changed due to just-in-time code compilation).</p><p>As shown in Fig. <ref type="figure">3</ref>, data center applications experience MPKIs in the range of 8-121 (29.7 on average). To understand the reason behind significant BTB misses, in Fig. <ref type="figure">4</ref>, we categorize whether these misses are compulsory, capacity, or conflict misses, i.e., the 3C miss classification <ref type="bibr" target="#b31">[33]</ref>. We find that the majority of these misses are capacity (on average 70%) and conflict (on average 24.48%) misses.</p><formula xml:id="formula_0">2 K 4 K 8 K 1 6 K 3 2 K 6 4 K 2 K 4 K 8 K 1 6 K 3 2 K 6 4 K 2 K 4 K 8 K 1 6 K 3 2 K</formula><p>To investigate these capacity and conflict misses, we vary the BTB size (from 2K entries to 64K entries) and associativity (from 4-way to 128-way) and show the results in Fig. <ref type="figure">5</ref> and Fig. <ref type="figure">6</ref>. We observe that these data center applications require a 64K-entry BTB to avoid most of the capacity misses. On the other hand, the BTB associativity needs to be at least 128 to cover the majority of conflict misses. Increasing BTB size and associativity to these levels will drastically increase on-chip storage and BTB lookup/update latency <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b35">37]</ref>. Furthermore, future applications may require an even larger BTB size and associativity since data center applications' instruction footprints grow in an unprecedented manner <ref type="bibr" target="#b36">[38]</ref>. Therefore, we conclude that BTB prefetching is a more future-proof solution as it can avoid latencies due to both types of BTB misses without requiring any change to the BTB organization.</p><p>Finally, in Fig. <ref type="figure">7</ref> and Fig. <ref type="figure">8</ref>, we study the distribution of all BTB accesses and misses across different branch types to identify whether a specific branch type suffers from poor BTB locality. We note that unconditional direct branches and calls disproportionately face more BTB misses. Specifically, unconditional direct branches and calls are responsible for 20.75% of all dynamic branches, but incur 37.5% of all BTB misses. This result justifies the design decisions of prior work <ref type="bibr" target="#b43">[45]</ref> that partitions the BTB structure to prefetch conditional branch entries that follow unconditional branch executions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Why do existing BTB prefetching mechanisms fall short?</head><p>Previously, we showed that an ideal BTB provides on average 31% speedup over the FDIP baseline. We now compare this ideal BTB speedup against speedups achieved by state-of-the-art BTB prefetchers, Confluence <ref type="bibr" target="#b38">[40]</ref> and Shotgun <ref type="bibr" target="#b43">[45]</ref>.</p><p>Confluence observes that although the I-cache and the BTB operate at the granularity of a cache line and a branch instruction respectively, hardware prefetching mechanisms for I-cache lines and BTB entries require the same metadata. Using this insight, Confluence (1) modifies the BTB organization to match the I-cache granularity (cache line), (2) operates on the same prefetch metadata, and (3) utilizes the temporal streaming (also referred to as "record and replay" <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b37">39]</ref>) technique, to perform both I-cache and BTB prefetching. While Confluence was designed for a fixed-length instruction size (4B), we modify Confluence for variable-length instruction sizes since most data center applications operate on servers that use variable-length ISAs (i.e., x86).</p><p>Shotgun observes that the working set size of unconditional branch instructions is significantly smaller than the working set size of all branch instructions. Hence, Shotgun statically partitions the BTB among unconditional and conditional branch entries to ensure that a certain type of branch entry does not cause evictions of the other type. Moreover, Shotgun leverages dynamic execution information to record the I-cache footprint for all unconditional branches. The next time the program executes the same unconditional branch, Shotgun prefetches the recorded I-cache lines (if not present in the I-cache) and predecodes the corresponding conditional branch entries. In our evaluation, Shotgun consists of 5120entry unconditional BTB (63.125KB), 1536-entry conditional BTB (12.1875KB), and 1536-entry return address stack (7.5KB). All other methodological details are in §4. Fig. <ref type="figure">9</ref> shows the speedup provided by Confluence and Shotgun over FDIP across all nine applications. Confluence and Shotgun offer only a fraction of an ideal BTB's speedup as they are unable to cover a significant portion of all BTB misses.</p><p>We investigate the performance of these prior BTB prefetching techniques to understand why they fail to cover so many BTB misses. Since both Confluence and Shotgun leverage temporal stream prefetching to avoid BTB misses, we categorize all BTB misses into three types of temporal streams <ref type="bibr" target="#b79">[81]</ref>: non-repetitive, new, and recurring streams. Temporal stream prefetching can inherently cover only recurring miss streams. As shown in Fig. <ref type="figure">10</ref>, while recurring miss streams constitute the majority of all BTB misses (on average 52%), new and non-repetitive streams still include a large fraction of the remaining BTB misses (on average 36% and 12% respectively) that Confluence and Shotgun do not cover. Recording access patterns at the granularity of I-cache lines instead of at the granularity of branch instructions helps Shotgun cover more BTB misses than Confluence, as Shotgun predecodes all branch instructions corresponding to a single I-cache line. Still, Shotgun falls significantly short of the ideal BTB, which we explain next.</p><p>Shotgun requires the unconditional branch footprint of the application to be small enough to fit into the BTB partition reserved  for unconditional branches. Unfortunately, different applications have different unconditional branch working set sizes as we portray in Fig. <ref type="figure">11</ref>. As a result, Shotgun's BTB partition for unconditional branches is too large for some applications and too small for others. Moreover, irrespective of whether an unconditional branch correlates with conditional branches, Shotgun reserves precious BTB storage bits as prefetch metadata for unconditional branches. Consequently, Shotgun wastes critical on-chip storage for some applications (e.g., drupal, mediawiki, and wordpress) where the number of unconditional branches are much smaller than Shotgun's unconditional BTB partition size. Shotgun incurs additional BTB misses due to one of its design constraints: the spatial range of conditional branches. Shotgun prefetches conditional branch entries based on the execution of unconditional branches. While doing so, Shotgun can only prefetch conditional branches that are within a spatial range of up to 8 cache lines of the last executed unconditional branch target. In other words, if a conditional branch resides outside this 8 cache line range, Shotgun will not be able to prefetch the corresponding BTB entry. However, as we show in Fig. <ref type="figure" target="#fig_0">12</ref>, a significant portion (26-45%) of all conditional branches falls outside this spatial range. Hence, Shotgun cannot cover a large portion of all BTB misses.</p><p>Based on our characterization's insights, we next present Twig, a profile-guided solution to avoid costly BTB misses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TWIG</head><p>Modern data center application binaries are large and contain numerous unique branch instructions. These applications suffer from frequent BTB misses. Prior work addresses this issue with BTB prefetchers that require significant hardware modification and yet fail to cover a large fraction of BTB misses. We propose Twig, a profile-guided solution to prefetch BTB entries. Specifically, Twig introduces two novel techniques to avoid BTB misses. First, Twig uses a novel profile-guided mechanism to prefetch BTB entries. Second, Twig coalesces prefetch operations of multiple BTB entries into a single instruction to reduce the code bloat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Software BTB Prefetching</head><p>Determining branch Program Counter (PC) and target for populating the BTB requires the processor to decode (potentially variablelength) instructions. Hardware-based BTB prefetchers such as Shotgun <ref type="bibr" target="#b43">[45]</ref> hence need to prefetch the instructions and decode them before filling the BTB, introducing significant hardware overheads for implementing the additional pre-decoders. Additionally, the prefetch latency deteriorates if the instruction being prefetched into the BTB is not present in the processor's I-cache. Twig addresses both of these challenges. First, Twig identifies the PC and target of every direct branch instruction for an application by examining its binary. Then, Twig leverages the program's dynamic execution profile to find the branch PCs causing a large number of BTB misses. Finally, Twig modifies the application binary to prefetch corresponding BTB entries in a timely manner.</p><p>To realize Twig, we introduce a new instruction, brprefetch to prefetch BTB entries. The brprefetch instruction uses two parameters-the branch PC and the target, to insert the corresponding branch entry into the BTB. Both these fields represent instruction pointers and can be as large as 48-bit signed integers <ref type="bibr" target="#b85">[87]</ref>. Moreover, Twig must schedule the brprefetch instruction early enough so that it updates the BTB before the corresponding branch target lookup occurs. We now explain how Twig meets these requirements by finding the appropriate program location to insert the brprefetch instruction and by storing only the address difference between the branch instruction and the target.</p><p>Prefetch injection location. Twig must insert the brprefetch instruction in a timely manner, i.e., the brprefetch instruction must retire before the corresponding branch is looked up in the BTB to avoid a BTB miss. Hence, it is critical to precisely identify the appropriate program location for inserting the brprefetch instruction. Twig must also emit accurate brprefetch instructions to avoid polluting the BTB with unnecessary entries. Since many different program paths can lead to a particular BTB miss, Twig must find the right program location to satisfy the accuracy constraint.</p><p>Twig leverages execution information to identify the appropriate program path that satisfies both the timeliness and accuracy constraint. With the help of Intel Last Branch Record (LBR) feature [5], Twig collects program execution profiles that lead to BTB misses. Intel LBR records a history of the last 32 basic blocks executed before a BTB miss along with their execution latency in cycles.</p><p>Fig. <ref type="figure" target="#fig_6">13a</ref> portrays an example of such a profile for BTB misses at the branch instruction address, A, showing how Twig leverages this profile to find the injection site for the brprefetch instruction.  This example includes six different BTB misses for A. To satisfy the timeliness constraint, Twig considers basic blocks that precede the BTB miss by at least several cycles as candidate injection sites. We call this particular cycle count the prefetch distance, which is one of Twig's design parameters. We use 20 cycles as the prefetch distance and evaluate Twig's sensitivity to this parameter in §4 (Fig. <ref type="figure" target="#fig_19">26</ref>).</p><p>Twig only considers predecessor basic blocks before the prefetch distance as the prefetch injection candidates. As shown in Fig. <ref type="figure" target="#fig_6">13a</ref>, predecessor basic blocks B and C are considered for the BTB miss 1 as they precede the BTB miss by the prefetch distance.</p><p>To satisfy the accuracy constraint, Twig computes the conditional probability of a BTB miss at A, given the execution of each candidate basic block. We show an example of this computation in Fig. <ref type="figure" target="#fig_6">13b</ref>. First, Twig calculates the execution count/frequency of each candidate block using the execution profile (including BTB misses at other branch instructions apart from A). Next, Twig counts how many BTB misses at A can be avoided by inserting a prefetch instruction at the candidate injection site. Then, Twig computes the ratio of these two counts as the conditional probability of a BTB miss at A, given the execution of each candidate basic block. Finally, Twig picks the candidate with the highest conditional probability for each BTB miss as the prefetch injection site. In case of this example, Twig selects C to cover BTB misses 1 , 4 , 5 , and 6 , while Twig chooses E to avoid BTB misses 2 and 3 .  Prefetch target compression. The storage cost of large instruction pointers (branch PC and target) is a significant challenge for software BTB prefetching. Twig reduces this storage overhead by storing the prefetch-to-branch-offset instead of the entire absolute address. We define the prefetch-to-branch-offset as the delta between the prefetch instruction PC and the prefetched branch PC. Fig. <ref type="figure" target="#fig_7">14</ref> shows the quantitative insight behind this optimization. On the X-axis, we show the number of bits required to encode the prefetch-to-branch-offset, while on the Y-axis, we show the Cumulative Distribution Function (CDF) for all BTB misses. We find that Twig covers more than 80% of all BTB misses using just 12-bits to encode the prefetch-to-branch-offset. Twig uses the same technique to also compress the branch target. Fig. <ref type="figure" target="#fig_8">15</ref> plots the branch-to-targetoffset on the X-axis and the CDF of all BTB misses on the Y-axis. We note that Twig again covers 80% of all BTB misses for most applications using just 12-bits. Only for verilator, covering more than 80% of all BTB misses requires larger than 12-bit signed integers. To cover the remaining BTB misses and to optimize the storage overhead even further, Twig proposes BTB prefetch coalescing that we describe next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BTB Prefetch Coalescing</head><p>Branch instructions with large address differences cannot directly be encoded using the prefetch instruction introduced in §3.1. For these too-large-to-encode branch instructions, Twig stores the addresses of the branch instruction and the target as key-value The key-value pairs are generated at compile time and added to the instruction binary as part of the text segment.</p><p>Twig introduces the brcoalesce instruction that takes the address of a key-value pair as a parameter and prefetches the corresponding entry to the BTB. To improve its efficiency, brcoalesce includes an n-bit bitmask as an additional parameter to prefetch multiple consecutive entries (for this reason, the key-value pairs are sorted in memory). Coalescing enables prefetching of multiple too-large-to-encode BTB entries with a minimal increase in the instruction footprint.</p><p>The size of the bitmask, n, is another design parameter. With a smaller bitmask, Twig would be able to prefetch only a small number of correlated BTB entries. With a larger bitmask, Twig can coalesce more prefetch operations. We investigate the impact of the bitmask size on the effectiveness of BTB prefetch coalescing in §4 and show that Twig achieves a majority of the performance benefit with just an 8-bit bitmask (Fig. <ref type="figure">27</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>In this section, we first describe (1) our experimental setup to collect execution profiles for our target data center applications, (2) different application input configurations, and (3) our simulation infrastructure. Then, we evaluate Twig using several key performance metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methodology</head><p>Data center applications and inputs. We evaluate Twig in the context of nine popular data center applications (as described in §2). We evaluate these applications with different input configurations such as the input data size, the webpage requested by the client, the number of client requests per second, random number seeds, and the number of server threads. Since Twig's profile-guided optimizations depend on the application input, we optimize each of these applications using the profile from one input and test the performance of the optimization on a different input.</p><p>Profile collection. We leverage Intel's "baclears.any" hardware performance event along with LBR [5] to collect the application execution context profiles that lead to a BTB miss.</p><p>Simulation and trace collection. We evaluate Twig using Scarab <ref type="bibr">[6]</ref>. In Scarab, we implement support for the BTB prefetch instructions (brprefetch and brcoalesce) and also add implementations for FDIP, Shotgun, and Confluence. We list different simulation parameters that resemble a recent state-of-the-art industry baseline <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>   Twig outperforms even the 32K-entry BTB on average with just an 8K-entry BTB with prefetching.</p><p>Scarab modes use Intel PIN <ref type="bibr" target="#b47">[49]</ref>, which cannot instrument kernel mode instructions. To support kernel mode instruction simulations, we collect application traces using Intel Processor Trace [1] and modify Scarab to support simulating such traces as well. We simulate traces of 100 million representative, steady-state instructions for each data center application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Analysis</head><p>We now validate Twig's effectiveness using key performance metrics. First, we compare Twig's speedup to the speedup offered by an ideal BTB and the state-of-the-art BTB prefetcher, Shotgun <ref type="bibr" target="#b43">[45]</ref>. Then, we evaluate the individual speedup contributions of software BTB prefetching and BTB prefetch coalescing. We also compare Twig against Shotgun in terms of BTB miss coverage and BTB prefetch accuracy. Furthermore, we compare speedups achieved by Twig and Shotgun across different application inputs. Finally, we measure Twig's static and dynamic overhead due to the additional BTB prefetch instructions. Speedup. We show Twig's speedup (brown bars) for nine data center applications in Fig. <ref type="figure" target="#fig_9">16</ref>. For comparison, we also show speedup offered by an ideal BTB (purple bars) and state-of-the-art BTB prefetcher, Shotgun (green bars). As shown, Twig achieves on average 20.86% speedup compared to 31% mean speedup achieved by an ideal BTB and 1% mean speedup achieved by Shotgun. On average, Twig achieves 48% (and up to 80%) of the speedup achieved by an ideal BTB that incurs no BTB misses. Twig cannot provide the entire benefit (100%) of an ideal BTB for a number of reasons. First, some BTB misses do not have a predecessor basic block that can predict the potential BTB miss with high accuracy. Second, BTB prefetch instructions injected by Twig incur both static and dynamic instruction overheads (we quantify this overhead later in this section). Finally, Twig cannot cover some previously unobserved BTB misses due to the use of different inputs in profiling and testing (we also quantify this later in the section). Still, Twig advances the state-of-the-art by outperforming Shotgun by 19.82% on average (and up to 139.8%) as Twig covers more BTB misses than Shotgun.</p><p>BTB miss coverage. Fig. <ref type="figure">17</ref> shows the BTB miss coverage comparison between Twig and Shotgun. As shown, Twig covers on average 65.4% (and up to 95.84%) of all BTB misses. Additionally, Twig covers on average 57.4% (and up to 94%) more BTB misses than the state-of-the-art prefetcher, Shotgun. Twig outperforms Shotgun to cover 57.4% more BTB misses primarily because of the reasons we describe in §2.3. In contrast to Shotgun's ability to prefetch only conditional branch entries within a limited spatial range, Twig can prefetch BTB entries irrespective of branch type or distance.</p><p>Performance of software BTB prefetching and BTB prefetch coalescing. Fig. <ref type="figure">18</ref> shows the individual contributions of software BTB prefetching and BTB prefetch coalescing to Twig's overall speedup. As shown, software BTB prefetching without any coalescing provides on average 32.6% speedup (70.9% of overall performance gains) across different applications. On top of this,   prefetch coalescing provides on average 15.7% speedup (29.1% of overall benefits) by reducing the static and dynamic instruction overhead. Prefetch accuracy. We show Twig's prefetch accuracy in Fig. <ref type="figure" target="#fig_11">19</ref> and compare it against Shotgun's prefetch accuracy. As shown, Twig provides 31.3% average accuracy. Moreover, Twig achieves 12.3% higher prefetch accuracy than Shotgun due to the fundamental limitation of hardware temporal stream prefetching. Like most prior hardware techniques on temporal memory streaming <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b75">77,</ref><ref type="bibr" target="#b79">[81]</ref><ref type="bibr" target="#b80">[82]</ref><ref type="bibr" target="#b81">[83]</ref>, Shotgun remembers the spatial footprint seen during the last execution and prefetches the corresponding BTB entries. While prefetching the most recently executed footprint is efficient in terms of metadata storage (compared to most frequently executed footprint), it incurs many inaccurate BTB prefetches. Twig, on the other hand, leverages a large amount of execution information from the collected profile to identify the most accurate prefetch predecessor and achieves higher prefetch accuracy.</p><formula xml:id="formula_1"># 1 # 2 # 3 # 1 # 2 # 3 # 1 # 2 # 3 A v g<label>0</label></formula><p>Performance across different application inputs. The effectiveness of profile-guided optimizations usually depends on the corresponding application input. To investigate how this dependence affects Twig's performance, we compare the speedups achieved by Twig across different application inputs in Fig. <ref type="figure" target="#fig_13">20</ref>. For each application, we use the profile from input '#0' to optimize BTB performance using Twig and measure the speedups for other inputs, '#1, #2, #3'. For comparison, we also measure speedups achieved by   Twig when optimized with the profile from the same input. Finally, we compare Twig against Confluence and Shotgun for different application inputs. For each configuration, we normalize the overall speedup by expressing it in terms of ideal BTB performance.</p><p>As shown in Fig. <ref type="figure" target="#fig_13">20</ref>, Twig provides significantly more benefit than state-of-the-art mechanisms <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b43">45]</ref> even while using profiles from a different application input. Twig provides a greater speedup when optimized using input-specific profiles (as shown in Table <ref type="table" target="#tab_4">2</ref>) for 6 out of 9 applications. However, for the remaining three applications, Twig can achieve even better speedup with profiles from a different application input. Nonetheless, Twig achieves comparable speedups with profiles from both same and different inputs.  Twig does not introduce any extra metadata storage. Therefore, instructions added to perform BTB prefetching are the only overhead Twig introduces. We quantify the static and dynamic overhead of these prefetch instructions in Fig. <ref type="figure" target="#fig_14">21</ref> and 22. In Table <ref type="table" target="#tab_5">3</ref>, we quantify the combined overhead of static and dynamic instruction increase based on working set size increase in terms of the number of added bytes. As shown, Twig introduces less than 8% static and 12.6% dynamic instruction overhead for all cases. Specifically, Twig incurs the highest dynamic overhead for to cover the large number of BTB misses incurred by the application (BTB MPKI of 121).</p><formula xml:id="formula_2">2 K 4 K 8 K 1 6 K 3 2 K 6 4 K 2 K 4 K 8 K 1 6 K 3 2 K 6 4 K 2 K 4 K 8 K 1 6 K 3 2 K 6 4 K</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sensitivity Analysis</head><p>We investigate the sensitivity of different design parameters on Twig's effectiveness. First, we compare the speedup achieved by Twig and Shotgun for different BTB storage budgets (size and associativity) and prefetch buffer sizes. Additionally, we evaluate the effect of changing the prefetch distance and FDIP run-ahead on Twig's effectiveness.</p><p>BTB storage budget. In Fig. <ref type="figure" target="#fig_16">23</ref>, we evaluate how sensitive Twig is to the storage budget allocated to the BTB by varying the number of BTB entries. We fix all other parameters and vary the number of BTB entries between 2048 (2K) and 65536 (64K). As Fig. <ref type="figure" target="#fig_16">23</ref> shows, Twig achieves more speedup than either Shotgun or Confluence across all BTB sizes. We also vary BTB's associativity from 4 ways Prefetch buffer size. We next vary the size of the BTB prefetch buffer. This enables us to hold additional BTB entry candidates at any given time, enabling Twig prefetches to not evict each other. As shown in Fig. <ref type="figure">25</ref>, Twig's performance scales from from 8 to about 128 entries before it begins to experience diminishing returns. Shotgun and Confluence do not experience this same scaling, indicating that Twig provides greater benefits than prior works irrespective of the prefetch buffer size.</p><p>Prefetch distance. Fig. <ref type="figure" target="#fig_19">26</ref> shows how Twig's effectiveness varies in response to variation in prefetch distance. We vary the prefetch distance from 0 to 50 cycles and measure Twig's average performance as a percentage of ideal BTB performance across applications. As shown, Twig provides only a portion of the potential speedup when the prefetch distance is too small to complete the prefetch before the BTB lookup. On the other hand, Twig cannot find an appropriate prefetch injection site when the prefetch distance is too large to ignore accurate predecessors. Consequently, Twig provides the greatest benefit with 15-25 cycles of prefetch distances across different applications.</p><p>Coalescing size. We investigate the effectiveness of Twig's BTB prefetch coalescing with an increase in coalescing bitmask size. Fig. <ref type="figure">27</ref> shows the average performance gains of BTB prefetch coalescing as the percentage of ideal BTB performance for different bitmask sizes (1-bit to 64-bit) across nine data center applications. As shown, Twig realizes a large fraction of the potential speedup    with an 8-bit bitmask. Consequently, we use 8-bits to coalesce BTB prefetch instructions. FDIP Run-ahead. Finally, we vary the size of the Fetch Target Queue (FTQ), which determines how far ahead the decoupled frontend can run. We vary the FTQ size from 1 to 64 branches. Fig. <ref type="figure">28</ref> shows that Twig achieves a similar performance relative to ideal at every measured FTQ length. Since a longer FTQ has been shown to improve performance by reducing frontend stalls <ref type="bibr" target="#b33">[35]</ref>, this result implies that Twig scales well to frontends that run far ahead of the fetch unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Preventing I-cache misses. Many prior works focus on reducing frontend stalls via eliminating I-cache misses. These techniques can be summarized in three distinct categories: software only, hardware only, and a hybrid software/hardware approach. Software techniques include improving instruction locality via basic block/function reordering <ref type="bibr" target="#b55">[57,</ref><ref type="bibr" target="#b63">65]</ref>, hot/cold splitting <ref type="bibr" target="#b21">[23]</ref>, and other Profile-Guided Optimizations (PGO) <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b49">51,</ref><ref type="bibr" target="#b56">58,</ref><ref type="bibr" target="#b61">63,</ref><ref type="bibr" target="#b65">67,</ref><ref type="bibr" target="#b88">90]</ref>. Improved layout techniques are only able to eliminate a subset of all I-cache misses and finding the optimal code layout for I-cache performance is intractable in practice <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b62">64]</ref>. Hardwareonly techniques tend to have one of two limitations. Either the techniques have prohibitive on-chip storage costs <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b24">26]</ref>, or they end up being significantly more complex <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b42">44]</ref> than prefetching techniques implemented in real hardware <ref type="bibr" target="#b67">[69,</ref><ref type="bibr" target="#b69">71]</ref>. Hybrid hardware and software approaches <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b39">41]</ref> attempt to avoid the pitfalls of software only or hardware only approaches by performing the complicated software analysis ahead of time and executing simple prefetch instructions at runtime. However, prior approaches either make assumptions that are too simplistic, limiting prefetching accuracy, or execute too many dynamic instructions which exacerbate the application's code footprint <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b51">53]</ref>. State-of-the-art I-cache prefetchers include the SN4L+Dis+BTB design <ref type="bibr" target="#b10">[12]</ref> and the contenders of the first instruction cache prefetching competition (IPC-1) <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b52">54,</ref><ref type="bibr" target="#b68">70,</ref><ref type="bibr" target="#b72">74]</ref>. Of the above proposals, FDIP has a desirable trade-off between metadata cost and prefetching effectiveness <ref type="bibr" target="#b43">[45,</ref><ref type="bibr" target="#b44">46]</ref>. Even with significantly smaller metadata storage costs, FDIP provides comparable performance benefits to state-of-the-art I-cache prefetchers <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>. Moreover, recent commercial CPU designs adopted some FDIP variants to reduce frontend stalls <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b59">61,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b78">80]</ref>. Therefore, in this work, we focus on improving FDIP effectiveness by introducing software BTB prefetching that provides 20.86% average speedup without requiring any extra metadata storage.</p><p>BTB redesign / compression. The design and usage of the storage allocated to the BTB has long been debated. BTB entries commonly hold some combination of a tag, prediction information, and target address <ref type="bibr" target="#b45">[47,</ref><ref type="bibr" target="#b60">62]</ref>. The basic-block style BTB also contains the address of the fall-through basic block <ref type="bibr" target="#b87">[89]</ref>. Compressing BTB entry size is common to enable the BTB to host more entries in the same storage budget. Such techniques <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b66">68,</ref><ref type="bibr" target="#b73">75]</ref> include using fewer bits for the tag, removing the page number from the tag, encoding the branch target as a small delta from the branch PC, and adding a larger second level BTB for which the first level BTB acts as a small cache. BTB-X <ref type="bibr" target="#b11">[13]</ref> and PDede <ref type="bibr" target="#b76">[78]</ref> apply several of these compression techniques, including partitioning the BTB into segments to enable aggressive compression and deduplication. All of these techniques enable the underlying BTB to have a larger capacity for a given storage budget. Since Twig prefetches entries into the BTB, it is independent of the underlying BTB and should be just as effective with the above techniques.</p><p>BTB prefetching. Phantom-BTB (PBTB) <ref type="bibr" target="#b18">[20]</ref> virtualized predictor metadata into the shared L2 cache, and used entries in the virtualized table to prefetch BTB entries. PBTB suffers from a relatively high cost of metadata storage and a longer latency access time for important branch prediction metadata. Two-level bulk preload <ref type="bibr" target="#b16">[18]</ref> maintains two BTB levels per-core, with a mechanism to fetch a group of BTB entries for a fixed-size region to the first level on a miss to any branch in that region. This is limited to exploiting the available spatial locality of a branch, and thus is similar to the next-line prefetchers. Confluence <ref type="bibr" target="#b38">[40]</ref> keeps the Icache and BTB contents in sync via their AirBTB design, with the ability to predecode branches and BTB entries for a given I-cache block. Locking the I-cache and BTB contents limits the runahead ability of the branch predictor unit. Moreover, Confluence relied on a metadata-expensive temporal prefetcher, SHIFT <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b44">46]</ref>. Boomerang <ref type="bibr" target="#b44">[46]</ref> modifies FDIP to predecode fetched I-cache blocks and insert the corresponding BTB entries. However, the ability for these entries to be timely is largely dependent upon the frontend to run far enough ahead, and miss coverage suffers when there are many BTB misses <ref type="bibr" target="#b43">[45]</ref>. Shotgun <ref type="bibr" target="#b43">[45]</ref> partitions the BTB into the Unconditional BTB (U-BTB) and much smaller Conditional BTB (C-BTB), with a way to prefetch entries into the C-BTB when the U-BTB is hit. As such, Shotgun relies on a high U-BTB hit rate to keep the C-BTB full of useful entries <ref type="bibr" target="#b10">[12]</ref>. This reliance limits Shotgun's ability to scale. Additionally, any fixed partitioning scheme, as in U-BTB vs. C-BTB sizes, need the workload's distribution of branches to match, and results in underutilized space when the application deviates from the fixed partitioning scheme. See §2.3 for a in-depth investigation on the impact of the limitations of each approach, and why they cannot cover all BTB misses. In this work, we investigate the reasons behind their limitation and address such limitations by proposing profile-guided BTB prefetch mechanisms that outperform prior techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Large branch footprints of data center applications cause frequent BTB misses, resulting in significant frontend stalls. We showed that existing BTB prefetching techniques fail to overcome these stalls due to inadequate understanding of the applications' branch access patterns. To address this limitation, we proposed Twig, a profile-guided BTB prefetching mechanism. Twig presents two BTB prefetching techniques: software BTB prefetching and BTB prefetch coalescing. We evaluated Twig in the context of nine popular data center applications. Across these applications, Twig achieves an average of 20.86% (2%-145%) performance speedup and outperforms the state-of-the-art BTB prefetching technique by 19.82%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure1: Many popular data center applications waste a large portion of their pipeline slots due to "frontend-bound" stalls<ref type="bibr" target="#b32">[34]</ref>, measured using the Top-down methodology<ref type="bibr" target="#b86">[88]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>c a s s a n d r a d r u p a l fi n a g l e -c h i r p e r fi n a g l e -h t t p k a f k a m e d i a w i k i t o m c a t v e r i l a t o r w o r d p r e s s AFigure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Breakdown of all BTB accesses into branch types: conditional branch instructions dominate the total number of BTB accesses</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>c a s s a n d r a d r u p a l fi n a g l e -c h i r p e r fi n a g l e -h t t p k a f k a m e d i a w i k i t o m c a t v e r i l a t o r w o r d p r e s s A v g 0 50 %Figure 9 :Figure 10 :</head><label>50910</label><figDesc>Figure 9: Speedups from Shotgun and Confluence over FDIP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 11 : 40 %</head><label>1140</label><figDesc>Figure 11: Working set size of unconditional branches and calls. Shotgun's U-BTB of 5120 entries is shown in blue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 12 :</head><label>12</label><figDesc>Figure12: Percentage of all conditional branches that are outside the range (8 cache lines) of the last executed unconditional branch target. Shotgun cannot prefetch BTB entries for these conditional branches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>An example of profile samples for BTB misses at branch instruction address, A, containing basic block executions that precede the miss.Basic blockTotal executed# of unique BTB misses atA that can be timely covered by the basic block P(BTB miss at A | Basic block) An example of the conditional probability calculation to predict the BTB miss at A, given the execution of a particular basic block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: An example of how Twig analyzes BTB miss profiles to find accurate and timely prefetch injection site</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 14 :</head><label>14</label><figDesc>Figure14: CDF of branch offset (from the prefetch injection site to the branch instruction) with variation in the number of bits required to store the offset: with just 12-bits Twig stores 80% of all branch offsets for all applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 15 :</head><label>15</label><figDesc>Figure15: CDF of branch target offset with variation in the number of bits required to store the offset: with just 12-bits Twig stores 80% of all branch targets for most applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Percentage speedup over the FDIP baseline: 32K is for a 32K-entry BTB compared to the 8K-entry baseline BTB.Twig outperforms even the 32K-entry BTB on average with just an 8K-entry BTB with prefetching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>FigureFigure</head><label></label><figDesc>Figure BTB miss coverage of Twig, Confluence, and Shotgun: on average Twig covers 65.4% of all BTB misses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>c a s s a n d r a d r u p a l fi n a g l e -c h i r p e r fi n a g l e -h t t p k a f k a m e d i a w i k i t o m c a t v e r i l a t o r w o r d p r e s s AFigure 19 :</head><label>19</label><figDesc>Figure 19: Prefetch accuracy of Twig, Confluence, and Shotgun: on average Twig provides 31.3% BTB prefetch accuracy across nine data center applications.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 20 :</head><label>20</label><figDesc>Figure 20: Twig's speedup across different application inputs as the percentage of an ideal BTB performance: Twig trained on a different input provides performance benefits comparable to Twig trained on the same input and outperforms existing BTB prefetching mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>c a s s a n d r a d r u p a l fi n a g l e -c h i r p e r fi n a g l e -h t t p k a f k a m e d i a w i k i t o m c a t v e r i l a t o r w o r d p r e s s A v gFigure 21 :</head><label>21</label><figDesc>Figure 21: Static overhead of Twig, measured in % of additional instructions in the binary for a given workload: on average Twig inserts 6% extra static instructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>c a s s a n d r a d r u p a l fi n a g l e -c h i r p e r fi n a g l e -h t t p k a f k a m e d i a w i k i t o m c a t v e r i l a t o r w o r d p r e s s AFigure 22 :</head><label>22</label><figDesc>Figure 22: Dynamic overhead of Twig, measured in % of additional executed instructions for a given workload: on average Twig incurs only 3% extra dynamic instructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 23 :</head><label>23</label><figDesc>Figure 23: % of speedup obtained by Twig compared to an ideal BTB for BTB capacities ranging from 2048 entries to 65536 entries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure % Figure</head><label>%</label><figDesc>Figure % of speedup obtained by Twig compared to an ideal BTB for BTB associativity ranging from 4 to 128</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 26 :</head><label>26</label><figDesc>Figure 26: Twig's average performance variation in response to increasing the prefetch distance. Across different applications, Twig provides greatest benefit with prefetch distance 15-25 cycles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 27 :Figure 28 :</head><label>2728</label><figDesc>Figure 27: Twig's average performance variation in response to changes in the coalesce bitmask size. Twig achieves a majority of the potential performance gains with a 8-bit coalesce bitmask.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Simulator Parameters Twig stores these pairs in sorted order based on the branch instruction address. Storing branch entries in sorted order helps Twig leverage spatial locality among different entries.</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>CPU</cell><cell>3.2GHz, 6-wide OOO, 24-entry FTQ, 224-entry ROB, 97-</cell></row><row><cell></cell><cell>entry RS</cell></row><row><cell>Branch prediction</cell><cell>64KB TAGE-SC-L [73] (up to 12-instruction), 8192-entry</cell></row><row><cell>unit</cell><cell>4-way BTB, 32-entry RAS, 4096-entry 4-way IBTB</cell></row><row><cell>Memory hierarchy</cell><cell>32KB 8-way L1i, 32KB 8-way L1d, 1MB 16-way unified L2,</cell></row><row><cell></cell><cell>10MB 20-way shared L3 per socket</cell></row><row><cell>pairs in memory.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>in Table 1. Both trace-driven and execution-driven</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Twig's average speedup across different application inputs with standard deviations.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">% of ideal BTB performance</cell><cell></cell></row><row><cell>Application</cell><cell cols="2">Same input profile</cell><cell cols="2">Training profile</cell></row><row><cell></cell><cell cols="4">Average Standard deviation Average Standard deviation</cell></row><row><cell>cassandra</cell><cell>49.31</cell><cell>10.04</cell><cell>45.93</cell><cell>15.53</cell></row><row><cell>drupal</cell><cell>36.77</cell><cell>14.31</cell><cell>43.15</cell><cell>9.84</cell></row><row><cell cols="2">finagle-chirper 38.30</cell><cell>9.13</cell><cell>31.99</cell><cell>10.29</cell></row><row><cell>finagle-http</cell><cell>34.03</cell><cell>7.73</cell><cell>32.66</cell><cell>5.62</cell></row><row><cell>kafka</cell><cell>52.35</cell><cell>2.17</cell><cell>49.93</cell><cell>2.26</cell></row><row><cell>mediawiki</cell><cell>38.78</cell><cell>10.95</cell><cell>43.78</cell><cell>5.11</cell></row><row><cell>tomcat</cell><cell>51.25</cell><cell>4.02</cell><cell>45.77</cell><cell>15.84</cell></row><row><cell>verilator</cell><cell>80.33</cell><cell>0.39</cell><cell>79.19</cell><cell>0.33</cell></row><row><cell>wordpress</cell><cell>45.15</cell><cell>14.69</cell><cell>49.71</cell><cell>12.85</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Instruction working set size overhead of Twig.</figDesc><table><row><cell>Application</cell><cell>Instruction working set size (MB)</cell><cell>Additional instruction size (MB)</cell><cell>Overhead (%)</cell></row><row><cell>cassandra</cell><cell>4.23</cell><cell>0.26</cell><cell>6.08</cell></row><row><cell>drupal</cell><cell>1.75</cell><cell>0.05</cell><cell>2.93</cell></row><row><cell>finagle-chirper</cell><cell>2.05</cell><cell>0.07</cell><cell>3.54</cell></row><row><cell>finagle-http</cell><cell>5.29</cell><cell>0.42</cell><cell>7.97</cell></row><row><cell>kafka</cell><cell>3.28</cell><cell>0.16</cell><cell>4.78</cell></row><row><cell>mediawiki</cell><cell>2.24</cell><cell>0.08</cell><cell>3.70</cell></row><row><cell>tomcat</cell><cell>2.40</cell><cell>0.10</cell><cell>4.10</cell></row><row><cell>verilator</cell><cell>13.56</cell><cell>1.34</cell><cell>9.86</cell></row><row><cell>wordpress</cell><cell>1.93</cell><cell>0.06</cell><cell>3.09</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their insightful feedback and suggestions. This work was supported by the Intel Corporation, NSF grants #1823559, #2011168, #2010810, and the Applications Driving Architectures (ADA) Research Center, a JUMP Center co-sponsored by SRC and DARPA. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies. We thank Maksim Panchenko and Guilherme Ottoni from Facebook for helpful discussions about HHVM control-flow behavior.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://lwn.net/Articles/648154/" />
		<title level="m">Adding Processor Trace support to Linux</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Cassandra</surname></persName>
		</author>
		<ptr target="http://cassandra.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://kafka.apache.org/powered-by" />
		<title level="m">Apache kafka</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Tomcat</surname></persName>
		</author>
		<ptr target="https://tomcat.apache.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An Introduction to Last Branch Records</title>
		<ptr target="https://lwn.net/Articles/680985/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://github.com/hpsresearchgroup/scarab" />
		<title level="m">Scarab</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Twitter</forename><surname>Finagle</surname></persName>
		</author>
		<ptr target="https://twitter.github.io/finagle/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://github.com/facebookarchive/oss-performance" />
		<title level="m">facebookarchive/oss-performance: Scripts for benchmarking various php implementations when running open source software</title>
				<imprint>
			<date type="published" when="2019-11">2019. November-2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The hiphop virtual machine</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Maher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Paroski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brett</forename><surname>Simmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edwin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Yamauchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages &amp; Applications</title>
				<meeting>the 2014 ACM International Conference on Object Oriented Programming Systems Languages &amp; Applications</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="777" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">MANA: Microarchitecting an instruction prefetcher. The First Instruction Prefetching Championship</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatemeh</forename><surname>Golshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Divide and Conquer Frontend Bottleneck</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual International Symposium on Computer Architecture</title>
				<meeting>the 47th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BTB-X: A Storage-Effective BTB Organization</title>
		<author>
			<persName><forename type="first">Truls</forename><surname>Asheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Memory hierarchy for web search</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Classifying Memory Access Patterns for Prefetching</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Asmdb: understanding and mitigating front-end stalls in warehouse-scale computers</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayana</forename><forename type="middle">Prasad</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoun</forename><forename type="middle">Kyu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trivikram</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
				<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="462" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The DaCapo benchmarks: Java benchmarking development and analysis</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Stephen M Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asjad</forename><forename type="middle">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Khang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rotem</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amer</forename><surname>Bentzur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Diwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel Z Guyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st annual ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications</title>
				<meeting>the 21st annual ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="169" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Two level bulk preload branch prediction</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bonanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Collura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lipetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Prasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Saporito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 19th International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="71" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Understanding memory access patterns for prefetching</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on AI-assisted Design for Architecture</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>held in conjunction with ISCA</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Phantom-BTB: a virtualized branch target buffer design</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Burcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Sigplan Notices</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="313" to="324" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bulldozer: An approach to multithreaded compute performance</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debjit</forename><forename type="middle">Das</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bob</forename><surname>Gelinas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="6" to="15" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications</title>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Xinliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CGO</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hot cold optimization of large Windows/NT applications</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Lowney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 29th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Partial resolution in branch target buffers</title>
		<author>
			<persName><forename type="first">Barry</forename><surname>Fagin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1142" to="1145" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Proactive instruction fetch</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Temporal instruction fetch streaming</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Gober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gino</forename><surname>Chacon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<title level="m">The Temporal Ancestry Prefetcher</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Jiménez</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gino</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Chacon</surname></persName>
		</author>
		<author>
			<persName><surname>Gober</surname></persName>
		</author>
		<title level="m">BARCa: Branch Agnostic Region Searching Algorithm</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evolution of the samsung exynos CPU microarchitecture</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Grayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Rupley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Zuraski Zuraski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Quinnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarun</forename><surname>Nakra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kitchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Hensley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Brekelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Run-Jump-Run: Bouquet of Instruction Pointer Jumpers for High Performance Instruction Prefetching</title>
		<author>
			<persName><forename type="first">Vishal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neelu</forename><surname>Shivprakash Kalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biswabandan</forename><surname>Panda</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>n. d.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">STEPS towards cacheresident transaction processing</title>
		<author>
			<persName><forename type="first">Stavros</forename><surname>Harizopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Very large data bases</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02329</idno>
		<title level="m">Learning memory access patterns</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evaluating associativity in CPU caches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">Jay</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1612" to="1630" />
			<date type="published" when="1989">1989. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><surname>Intel</surname></persName>
		</author>
		<ptr target="https://software.intel.com/content/www/us/en/develop/documentation/vtune-help/top/reference/cpu-metrics-reference/front-end-bound.html" />
		<title level="m">Front-End Bound</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rebasing Instruction Prefetching: An Industry Perspective</title>
		<author>
			<persName><forename type="first">Yasuo</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaekyu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Krishnendra Nathella, and Dam Sunwoo</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reestablishing Fetch-Directed Instruction Prefetching: An Industry Perspective</title>
		<author>
			<persName><forename type="first">Yasuo</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaekyu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendra</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Performance Analysis of Systems and Software</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The impact of delay on the design of branch predictors</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">W</forename><surname>Daniel A Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture</title>
				<meeting>the 33rd annual ACM/IEEE international symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="67" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Profiling a warehousescale computer</title>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual International Symposium on Computer Architecture</title>
				<meeting>the 42nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Shift: Shared history instruction fetch for lean-core server processors</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Confluence: unified instruction supply for scale-out servers</title>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
				<meeting>the 48th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="166" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">2020. I-SPY: Context-Driven Conditional Instruction Prefetching with Coalescing</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ripple: Profile-guided instruction cache replacement for data center applications</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dexin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Computer Architecture</title>
				<meeting>the 48th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A costeffective branch target buffer with a two-level table organization</title>
		<author>
			<persName><forename type="first">Ryotaro</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideki</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshio</forename><surname>Shimada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Symposium of Low-Power and High-Speed Chips (COOL Chips II</title>
				<meeting>the 2nd International Symposium of Low-Power and High-Speed Chips (COOL Chips II</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">RDIP: return-addressstack directed instruction prefetching</title>
		<author>
			<persName><forename type="first">Aasheesh</forename><surname>Kolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="260" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Blasting through the Front-End Bottleneck with Shotgun</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Nagarajan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173162.3173178</idno>
		<ptr target="https://doi.org/10.1145/3173162.3173178" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="30" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Boomerang: A metadata-free architecture for control flow delivery</title>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Chieh</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Grot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Nagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Branch Prediction Strategies and Branch Target Buffer Design</title>
		<author>
			<persName><forename type="first">Smith</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1109/MC.1984.1658927</idno>
		<ptr target="https://doi.org/10.1109/MC.1984.1658927" />
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="6" to="22" />
			<date type="published" when="1984">1984. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Lightweight feedbackdirected cross-module optimization</title>
		<author>
			<persName><forename type="first">David</forename><surname>Xinliang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Raksit</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Hundt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization</title>
				<meeting>the 8th annual IEEE/ACM international symposium on Code generation and optimization</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="53" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pin: building customized program analysis tools with dynamic instrumentation</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><forename type="middle">Janapa</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm sigplan notices</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="190" to="200" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cooperative prefetching: Compiler and hardware support for effective instruction prefetching in modern processors</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Ispike: a post-link optimizer for the Intel/spl reg/Itanium/spl reg/architecture</title>
		<author>
			<persName><forename type="first">C-K</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Lowney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004. 2004</date>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">PIPS: Prefetching Instructions with Probabilistic Scouts</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 1st Instruction Prefetching Championship</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Asmdb: Understanding and mitigating front-end stalls in warehouse-scale computers</title>
		<author>
			<persName><forename type="first">Prasad</forename><surname>Nayana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">I</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoun</forename><forename type="middle">Kyu</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trivikram</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">Tomoki</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toru</forename><surname>Koizumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuya</forename><surname>Degawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hidetsugu</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuichi</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Shioya</surname></persName>
		</author>
		<title level="m">D-JOLT: Distant Jolt Prefetcher</title>
				<imprint/>
	</monogr>
	<note>n. d.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">HHVM JIT: A Profile-guided, Region-based Compiler for PHP and Hack</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
				<meeting>the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="151" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">HHVM Jump-Start: Boosting Both Warmup and Steady-State Performance at Scale</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="340" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Optimizing function placement for large-scale data-center applications</title>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertrand</forename><surname>Maher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bolt: a practical binary optimizer for data centers and beyond</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Nell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Lightning BOLT: powerful, fast, and scalable binary optimization</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laith</forename><surname>Sakka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM SIGPLAN International Conference on Compiler Construction</title>
				<meeting>the 30th ACM SIGPLAN International Conference on Compiler Construction</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">B-fetch: Branch prediction directed prefetching for in-order processors</title>
		<author>
			<persName><forename type="first">Reena</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="41" to="44" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Stephens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magnus</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasuo</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Pusdesris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Abernathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinson</forename><surname>Koppanalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Ringe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashok</forename><surname>Tummala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Arm Neoverse N1 Platform: Building Blocks for the Next-Gen Cloud-to-Edge Infrastructure SoC</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="53" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Branch target buffer design and optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">Jay</forename><surname>Perleberg</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on computers</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="396" to="412" />
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Architectural and compiler support for effective instruction prefetching: a cooperative approach</title>
		<author>
			<persName><surname>Larry L Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Systems</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The Hardness of Cache Conscious Data Placement</title>
		<author>
			<persName><forename type="first">Erez</forename><surname>Petrank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dror</forename><surname>Rawitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
				<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Profile guided code positioning</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Pettis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 1990 conference on Programming language design and implementation</title>
				<meeting>the ACM SIGPLAN 1990 conference on Programming language design and implementation</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Renaissance: Benchmarking Suite for Parallel Applications on the JVM</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Prokopec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Rosà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Leopoldseder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Duboscq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Tůma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Studener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lubomír</forename><surname>Bulej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Villazón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Würthinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Binder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In Programming Language Design and Implementation</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Code layout optimizations for transaction processing workloads</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>André Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kourosh</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Larriba-Pey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A scalable front-end architecture for fast instruction delivery</title>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="234" to="245" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Fetch directed instruction prefetching</title>
		<author>
			<persName><forename type="first">Glenn</forename><surname>Reinman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture. IEEE</title>
				<meeting>the 32nd Annual ACM/IEEE International Symposium on Microarchitecture. IEEE</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The entangling instruction prefetcher</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Jimborean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="84" to="87" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Trace cache: a low latency approach to high bandwidth instruction fetching</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 29th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="24" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Samsung Exynos M3 Processor</title>
		<author>
			<persName><surname>Rupley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Hot Chips</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Tage-sc-l branch predictors</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JILP-Championship Branch Prediction</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The FNL+ MMA Instruction Cache Prefetcher</title>
		<author>
			<persName><forename type="first">André</forename><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPC-1-First Instruction Prefetching Championship</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Don&apos;t use the page number, but a pointer to it</title>
		<author>
			<persName><surname>Seznec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd Annual International Symposium on Computer Architecture. IEEE</title>
				<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="104" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sequential program prefetching in memory hierarchies</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="7" to="21" />
			<date type="published" when="1978">1978. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Spatio-temporal memory streaming</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="69" to="80" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">PDede: Partitioned, Deduplicated, Delta Branch Target Buffer</title>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Subramoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 54th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Softsku: Optimizing server architectures for microservice diversity@ scale</title>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
				<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The AMD &quot;Zen 2&quot; Processor</title>
		<author>
			<persName><forename type="first">David</forename><surname>Suggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahesh</forename><surname>Subramony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Bouvier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="45" to="52" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Temporal streams in commercial server applications</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Thomas F Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE International Symposium on Workload Characterization</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Practical off-chip meta-data for temporal memory streaming</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Thomas F Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 15th International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Anastassia Ailamaki, and Babak Falsafi</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Thomas F Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jangwoo</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Symposium on Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
	<note>Temporal streaming of shared memory</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Wikipedia contributors</title>
		<ptr target="https://en.wikipedia.org/w/index.php?title=Apache_Kafka&amp;oldid=988898935" />
	</analytic>
	<monogr>
		<title level="m">Apache Kafka -Wikipedia, The Free Encyclopedia</title>
				<imprint>
			<date type="published" when="2020-11">2020. November-2020</date>
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Wikipedia contributors</title>
		<ptr target="https://en.wikipedia.org/w/index.php?title=Verilator&amp;oldid=989046249" />
	</analytic>
	<monogr>
		<title level="m">Verilator -Wikipedia, The Free Encyclopedia</title>
				<imprint>
			<date type="published" when="2020-04">2020. April-2021</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Apache Cassandra -Wikipedia</title>
		<ptr target="https://en.wikipedia.org/w/index.php?title=Apache_Cassandra&amp;oldid=1010524207" />
	</analytic>
	<monogr>
		<title level="m">Wikipedia contributors</title>
				<imprint>
			<date type="published" when="2021-04">2021. -April-2021</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>The Free Encyclopedia</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<ptr target="https://en.wikipedia.org/w/index.php?title=X86-64&amp;oldid=1016690406" />
		<title level="m">Wikipedia contributors. 2021. X86-64 -Wikipedia, The Free Encyclopedia</title>
				<imprint>
			<date type="published" when="2021-04">April-2021</date>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">A top-down method for performance analysis and counters architecture</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Yasin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ISPASS</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A comprehensive instruction fetch mechanism for a processor supporting speculative execution</title>
		<author>
			<persName><forename type="first">Tse-Yu</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMICRO Newsletter</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="129" to="139" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Buffering databse operations for enhanced instruction cache performance</title>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Management of data</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
