<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Conversational Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Konstantina</forename><surname>Christakopoulou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota United States</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
							<email>filiprad@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
							<email>katja.hofmann@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Conversational Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">590DC0ED973F8E8FEF378393CED20585</idno>
					<idno type="DOI">10.1145/2939672.2939746</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>online learning</term>
					<term>recommender systems</term>
					<term>cold-start</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>People often ask others for restaurant recommendations as a way to discover new dining experiences. This makes restaurant recommendation an exciting scenario for recommender systems and has led to substantial research in this area. However, most such systems behave very di↵erently from a human when asked for a recommendation. The goal of this paper is to begin to reduce this gap.</p><p>In particular, humans can quickly establish preferences when asked to make a recommendation for someone they do not know. We address this cold-start recommendation problem in an online learning setting. We develop a preference elicitation framework to identify which questions to ask a new user to quickly learn their preferences. Taking advantage of latent structure in the recommendation space using a probabilistic latent factor model, our experiments with both synthetic and real world data compare di↵erent types of feedback and question selection strategies. We find that our framework can make very e↵ective use of online user feedback, improving personalized recommendations over a static model by 25% after asking only 2 questions. Our results demonstrate dramatic benefits of starting from offline embeddings, and highlight the benefit of bandit-based explore-exploit strategies in this setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Recommendation is an everyday process that frequently touches people's lives. Hence, it has seen tremendous research interest (such as <ref type="bibr">[9,</ref><ref type="bibr" target="#b14">14]</ref>). Most work in recommendation falls into two broad classes: Collaborative Filtering starts with a set of user/item a nity scores and assumes that two users who agree about one item are more likely to agree about another item; Content-Based Filtering models ⇤ This work was done during an internship at Microsoft.</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. KDD <ref type="bibr">'16, August 13 -17, 2016</ref>, San Francisco, CA, USA users by the characteristics of the items they like or dislike. We note that neither model represents how real people make recommendations, particularly in a cold-start setting where the person making a recommendation does not know a lot about the person asking for one.</p><p>Consider what would happen if a conference attendee in your home town, whom you have never met before, asked for a recommendation on where to eat dinner today. Most likely, you would start with one or two clarifying questions, perhaps whether the person likes seafood, or whether they have a car. These questions would depend on the context; for instance if there are great restaurants around the corner, then whether they have a car would be irrelevant.</p><p>We argue that such an interaction can be represented using online learning, where two types of learning are occurring. First, the person making the recommendation is learning about the preferences of the person asking. However, the attributes learned will be contextual, based on the likely follow-on answers (such as the car question earlier). Second, the person making the recommendation is learning about which questions allow them to quickly reach a good recommendation in the current context. In this paper, we present a recommendation system that exhibits these two types of learning. Further, the learning is online: It immediately impacts future recommendations for this user, rather than requiring a batch reprocessing of information learned.</p><p>We present a bandit-based approach for online recommendation, applied to restaurant recommendation so as to ground it in a specific application. Our approach builds on top of prior work, such as <ref type="bibr" target="#b33">[33]</ref>, but learns to adapt the recommendation space (user-item embedding) to its users throughout their interactions. We use generalized Thompson Sampling to systematically sample questions to ask the user and to incorporate observed feedback. We further propose and compare a range of alternative question selection strategies to identify characteristics of approaches that most e↵ectively learn users' preferences. We use a matrix factorization approach <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b29">29]</ref> to learn and adapt the embedding.</p><p>Our main contributions are four-fold. <ref type="bibr" target="#b1">(1)</ref> We propose a novel view of human-like recommenders that converse with new users to learn their preferences. <ref type="bibr" target="#b2">(2)</ref> We successfully demonstrate a fully online learning approach for recommendation -both using absolute and relative feedback. <ref type="bibr" target="#b3">(3)</ref> We propose a systematic approach to incorporating o✏ine data to initialize online learning recommenders, and demonstrate performance improvements, even using weakly labeled offline data. <ref type="bibr" target="#b4">(4)</ref> We propose a set of item selection strategies for deciding what question to ask to a cold-start user to most quickly infer preferences, and demonstrate benefits of bandit-based strategies. Our extensive experiments on both synthetic and real data evaluate each step of our approach.</p><p>Importantly, we note that this work is applicable to a wide variety of recommendation scenarios. Here, we focus on one such application, restaurant recommendation, where <ref type="bibr" target="#b1">(1)</ref> we study search logs to understand the space of real user needs;</p><p>(2) we use the insights to collect preference data in a user study; <ref type="bibr" target="#b3">(3)</ref> we use online behavioral data to initialize the recommendation system; (4) we use both synthetic and user study data to evaluate our approaches.</p><p>We now present related work (Section 2), followed by an analysis of real-live restaurant search <ref type="bibr" target="#b3">(3)</ref>. We describe our model ( <ref type="formula" target="#formula_2">4</ref>) and empirical setup <ref type="bibr" target="#b5">(5)</ref>, and validate the model on synthetic data <ref type="bibr" target="#b6">(6)</ref>. Finally, we evaluate on real data to further empirically analyze our learning framework <ref type="bibr" target="#b7">(7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>This paper builds on work in multiple active research areas. We review recent work in the most closely related areas.</p><p>O✏ine Recommenders. The wide interest in personalized recommendations has sparked substantial research in this area <ref type="bibr" target="#b14">[14]</ref>. The most common approaches are contentbased approaches <ref type="bibr" target="#b24">[24]</ref> and collaborative filtering (CF) <ref type="bibr">[9,</ref><ref type="bibr" target="#b21">21]</ref>. Collaborative filtering, which powers most modern recommenders, uses an a-priori available set of user-item ratings to learn the interdependencies among users and items. It predicts a user's rating on an item either via the neighboring items' ratings (neighbor-based <ref type="bibr">[9,</ref><ref type="bibr" target="#b28">28]</ref>) or by inferring latent factors in a low-dimensional embedding (latent factorbased <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b29">29]</ref>). The majority of the work in recommendation has focused on o✏ine recommenders, i.e., building an o✏ine model based on past user-item interactions, periodically retrained to incorporate new observations. Online Recommenders. Recently, it has been recognized that o✏ine recommender approaches (i) su↵er from the cost of retraining the model, (ii) are built to optimize o✏ine performance which does not necessarily match online user behavior and (iii) fail to capture preference drifts. These realizations have initiated developments towards building continuously learning (online) recommenders.</p><p>A recent line of work poses the problem in a contextual bandit formulation <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b32">32]</ref>, where items are seen as arms, users as contexts, and the goal is to explore the arm space in order to exploit the best performing arm for a given context. Most work in this area relies on the availability of user/item features and assumes that the reward of an arm for a given context is a linear/logistic function of the concatenated feature of arm-context <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b31">31]</ref>. <ref type="bibr" target="#b32">[32]</ref> uses Gaussian processes to allow feedback sharing among similar contexts and arms.</p><p>Using the CF point of view, <ref type="bibr" target="#b4">[4]</ref> introduced an ✏-greedy online user-user neighbor-based CF method. The first latentfactor online recommender was introduced in <ref type="bibr" target="#b33">[33]</ref>, which uses bandit strategies on top of Probabilistic Matrix Factorization (PMF) <ref type="bibr" target="#b21">[21]</ref>. This is the most closely related work to ours. However, while <ref type="bibr" target="#b33">[33]</ref> fixes the item latent factors to those learned o✏ine, formulating the problem as a linear bandit, our method fully online learns all user and item parameters, including the biases; <ref type="bibr" target="#b33">[33]</ref> can be seen as special case of our framework. In <ref type="bibr" target="#b13">[13]</ref>, the authors extend Thompson Sampling for PMF with a Kalman filter to track changing preferences over time. This work is orthogonal to ours.</p><p>Preference Elicitation. The problem of eliciting user feedback has long been of interest for a variety of tasks (e.g <ref type="bibr" target="#b8">[8]</ref>). To elicit the preferences of an existing or new user (cold-start), a range of methods have been proposed, varying from interview-based strategies (e.g <ref type="bibr" target="#b30">[30]</ref>), to asking users to rate some items, to active learning <ref type="bibr" target="#b26">[26]</ref>, entropy minimization <ref type="bibr" target="#b27">[27]</ref>, picture-based <ref type="bibr" target="#b22">[22]</ref>, and explore-exploit strategies on top of a latent factor model <ref type="bibr" target="#b33">[33]</ref>. Our work is the first to elicit users' preferences by utilizing either absolute or relative feedback in a fully online setting. Interactive Recommenders. There have been many works (critique-based <ref type="bibr" target="#b7">[7]</ref>, constraint-based <ref type="bibr" target="#b10">[10]</ref>, dialog, utilitybased recommenders <ref type="bibr" target="#b19">[19]</ref>) emphasizing the importance of interactivity in recommenders so that the user has a more active role over the recommendations. However, these works rely on prior modeling of the items' features, preventing the flexibility in adaptation to a di↵erent domain; thus a comparison with them is out of the scope of this work.</p><p>In contrast, our work, in the same spirit as a recent line of work <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b11">11]</ref> initiated by <ref type="bibr" target="#b33">[33]</ref>, learns online the latent factors from PMF and uses these to do interactive preference elicitation. These methods, although close in principle, have significant di↵erences from our work. <ref type="foot" target="#foot_0">1</ref> Briefly, in <ref type="bibr" target="#b18">[18]</ref>, the authors focus on set-based feedback and propose a progressive building of the user's latent factor in each question. In contrast, our work focuses on absolute and relative feedback on (pairs of) items, and uses a preference elicitation phase fully integrated with the online updates of the PMF model. The method of <ref type="bibr" target="#b11">[11]</ref> focuses on choice-based feedback and updates online only the user's latent factor. Neither of <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b18">18]</ref> balance the exploration-exploitation tradeo↵.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">UNDERSTANDING REAL USERS</head><p>A recommendation system that aims to satisfy real people should reflect how real people look for recommendations. Therefore, we start by analyzing restaurant-related search behavior in a commercial Web search engine. Our goals are two-fold. First, to gain insight into our target domain, namely understand the criteria people use to choose restaurants<ref type="foot" target="#foot_1">2</ref> . Second, to identify questions we must ask users to construct ground truth data for evaluating our system.</p><p>Given a large sample of all queries issued between 07/2014 and 07/2015, we filtered for those that contain restaurant or dining, and terms such as for, near(by), next (to), close (to), with and in. Let Q be the most frequent 10,000 such queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Annotation with Entities</head><p>We tagged the top several hundred queries from Q as containing a location, name, cuisine, food type, or terms such as best and menu. The dictionary of tags was not pre-specified to avoid biasing our annotations due to prior beliefs about categories people should be looking for. Rather, our methodology used content analysis <ref type="bibr" target="#b25">[25]</ref> to develop a coding that captures the dominant behaviors involved.</p><p>We found that 39% of queries specify a location, 19% a restaurant name, 9% cuisine constraints, 7% have the term best or other superlative. More rarely, queries specified food ethnicity (2%), an adjective describing the restaurant (2%), dish name (2%), decoration, etc. The most common term co- occurences are location and name in the same query (29%), cuisine and location (10%), and best and location (8%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Understanding Common Phrases</head><p>The above statistics show that location is an important factor in restaurant search. Hence we zoom in to discover the specific ways in which people constrain locations. Similarly, the context under which users search for a restaurant is a second common constraint. We analyzed the specific terms appearing after a variety of prepositions, and constructed a dictionary of the most frequent contextual constraints.</p><p>A sample of these is shown in Table <ref type="table" target="#tab_0">1</ref>. For example, the top places people search for restaurants in are nyc, chicago, las vegas. Using the preposition 'near' to indicate location, the majority of terms shows users want a restaurant near me. Queries can also be very specific, e.g. searching for a restaurant near points of interest (times square), airports (miami airport, lax ), postal codes or entire addresses. The contexts under which users search for restaurants vary from an occasion (wedding reception), to dietary restrictions, to type of meal or a group of people. People also search for restaurants with live music, piano, a view etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Restaurant Feature Dictionaries</head><p>As user queries can be very specific (e.g., combining constraints, 'adjective &amp; dish &amp; great &amp; location'), we now study the terms that people use to describe restaurants. We annotated the top 1,013 phrases appearing before the word 'restaurant' or 'dining' in 5,000 queries from Q with a number of traits. The traits identified are related to food (cuisine, meal, dietary restrictions, quality e.g. organic, healthy, bu↵et, menu), rating (e.g michelin star), atmosphere (view, fancy or romantic), time/location (opening hours, decade theme, time of the day) etc.</p><p>For every trait, we collected the most common terms. Table 2 shows a few common examples, giving us a glimpse into the most searched cuisines, food types, and adjectives. Though not shown, top amenities searched are garden, jazz, patio, ocean and top restaurant types are bar, fast food, cafe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Outlook</head><p>Besides motivating our application scenario, this search log analysis forms the basis of the user study in Section 7. Given this understanding of what to ask people who look for a restaurant, we also focus on how to ask it. In this work, among the various combinations of the feedback type (explicit/implicit, absolute/relative/list) on the available content (explicit features/items/latent features), we elicit users' preferences using explicit feedback from absolute and relative questions about explicit items (e.g. restaurants).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MODEL</head><p>We next present our approach for determining 'what to ask' and 'how to ask' as the key pieces of a conversational recommender, starting with a high level picture of the entire algorithm (Section 4.1). Then, we describe the pieces in detail as we require (i) a model exploiting implicit structure among items and users to e ciently propagate feedback (Section 4.2); (ii) an explore-exploit approach to probe the space of items, to allow continuous learning (Section 4.3) and (iii) a feedback elicitation mechanism for selecting absolute (Section 4.3) and relative questions (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>Our recommendation pipeline can be summarized as: The inner loop represents the 'human in the loop' present in all interactive systems, i.e., we make an intervention which a↵ects the user and thus the future system decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Latent Factor Recommendation</head><p>Consider how people make recommendations when a friend asks them to suggest a restaurant. They strategically ask each question with the goal of eliminating or confirming strong candidates for dining out. Similarly, when designing a conversational recommender that asks questions about explicit items, a principled way of selecting items is desired.</p><p>The implicit structure of the item space that allows us to learn quickly is motivated by collaborative filtering. Items that have been co-rated similarly (liked/disliked) by users will lie close in a low dimensional embedding. For our model we use a simplified version of the Matchbox Recommender model <ref type="bibr" target="#b29">[29]</ref> -equivalent to Probabilistic Matrix Factorization (PMF) <ref type="bibr" target="#b21">[21]</ref>. This is a generative model, in that it specifies a probabilistic procedure by which the observed likes/dislikes of users on items are generated on the basis of latent variables. The model variables are learned so that the model can explain the observed training data.</p><p>Formally, throughout the paper we use the convention that i denotes the index over M users, forming the set I, and j denotes the index over N items, forming the set J . Every user i 2 I is modeled by a user bias variable ↵i 2 R, accounting for users who tend to like/dislike most of the items, and a d-dimensional trait vector ui 2 R d . The trait vector represents the latent embedding of user i in a d-dimensional space, where d ⌧ M, N . Every item j 2 J is modeled with latent variables j 2 R (the item bias that accounts for item popularity) and a trait vector vj 2 R d that represents the latent embedding of item j in the same d-dimensional space.</p><p>Given that both users and items trait vectors lie in the same latent space, the similarity between a user i and an item j can be measured with the inner product of their corresponding trait vectors u T i vj. We now present two models for estimating the latent variables, depending on the type of observations we obtain from users, i.e., absolute or pairwise.</p><p>Absolute Model. First, let us assume that we have observed tuples of the form (user i, item j, 1/0). 4 The model estimates the a nity of user i to item j based on the biases and traits. The generative procedure is:</p><formula xml:id="formula_0">1. User i has traits ui ⇠ N (0, 2 1 I), bias ↵i ⇠ N (0, 2 2 ). 2. Item j has traits vj ⇠ N (0, 2 1 I), bias j ⇠ N (0, 2 2 ). 3. (a) The (unobserved) a nity is yij = ↵i + j + u T i vj.<label>(1)</label></formula><p>Observations are modeled as the noisy estimate ŷij ⇠ N (yij, ✏ij), where ✏ij models the a nity variance, accounting for noise in user preferences. This yields an observation of whether the user likes an item (rij):</p><formula xml:id="formula_1">rij = 1[ŷij &gt; 0].<label>(2)</label></formula><p>The hyper-parameters 1, 2 model the variance in traits and biases. The model variables are learned by maximizing the log-posterior over the item and user variables with fixed hyper-parameters, given the training observations. Pairwise Model. People are often better at giving relative preferences over items instead of absolute judgments. Such preferences yield tuples of the form (user i, item j, item h) when user i prefers item j over item h (both j and h are indices over J .) We can adapt the generative model to such ground truth data by modifying the third step of the Absolute model to yield a pairwise model: where the noisy item a nities are defined as before.</p><p>Using ŷijh , we estimate if user i prefers j over h:</p><formula xml:id="formula_2">j i h : rijh = 1[ŷ ijh &gt; 0]<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Continuous Learning Recommender</head><p>To generate recommendations, most latent factor based recommender systems use an o✏ine trained model based on past interactions, such as the one described above, that they periodically update to incorporate new data. The parameters for new users are typically initialized based on a combination of explicit attributes and past ratings (e.g <ref type="bibr" target="#b1">[1]</ref>). The items with the highest predicted noisy a nity mean comprise the recommendations presented to the user.</p><p>In contrast, recent work has moved towards continuously learning recommenders <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b33">33]</ref>. This optimizes for online performance using explore-exploit (EE) strategies. We present our fully online updated recommendation approach with the embedded preference elicitation in Algorithm 1. Following we detail the components of this algorithm for the case of asking absolute questions (Abs). In Section 4.4 we show how we extend this framework for relative questions. 4 We use the convention that 0 denotes dislike and 1 like.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Preference Elicitation Algorithm</head><p>Input: 8i 2 I : u i , ↵ i , 8j 2 J : v j , j (o✏ine embedding)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1:</head><p>A new user i arrives. Initialize prior based on Eq. 5.</p><p>2: 8j 2 J , infer noisy a nity y ij (Eq. 1)</p><p>3: while fewer than allowed questions have been asked do: 7: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Initialization from Offline Data</head><p>We propose to initialize online learning models using an initial embedding, that is learned o✏ine. We hypothesize that such an initial embedding will allow the system to learn new user's preferences more quickly. E↵ective learning from few questions is crucial for conversational recommenders.</p><p>We start by learning the o✏ine embedding of items from logged observations. Then, we initialize the prior of every item j 2 J by setting the trait vj and bias j from the corresponding o✏ine posterior -assuming that all items in the online phase appeared in the o✏ine data.</p><p>For the initialization of the user parameters, we focus on the case when the user is new to the system. Without additional information, we can assume that the new user is similar to the average o✏ine user. We implement this by using as trait and bias the mean value over all o✏ine users:</p><formula xml:id="formula_3">u cold ⇠ Ei=1,...,M [ui] ↵ cold ⇠ Ei=1,...,M [↵i]<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Question Selection Strategies</head><p>When a new user initiates interaction with a continuous recommender, the system asks a few questions to learn about the user's preferences. During this phase, it is important to select questions that lead to learning e↵ectively (i) the user's preferences and (ii) the questions' quality, so that the number of questions asked can be minimized and interactions remain enjoyable. This task can be modeled as an item selection task. Here, we propose approaches that capture characteristics of active learning and bandit learning. Active learning approaches capture the intuition that learning is fastest when the system queries for labels that provide a high amount of new information <ref type="bibr" target="#b26">[26]</ref>. Bandit learning approaches balance the need to learn new information with a focus on what has already been learned <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b5">5]</ref>. In the context of conversational recommenders, such a balance may help focus questions on the most relevant part of the latent space, while still considering that highly preferred items may lie in as of yet unexplored areas of the space.</p><p>The model's confidence in its belief over the user's preferences on items j 2 J at a given time is captured by the current variances of the posterior of the noisy a nities y cold j .</p><p>As we ask about an item j ⇤ and observe the user's feedback, the variance of the inferred noisy a nity of this item and of the nearby items in the learned embedding is reduced. Also, the means of these items' inferred noisy a nities change. It is this property that allows us to search the space of items quickly. Hence, while in the classic multi-armed bandit scenario the bandit algorithms converge only after all arms are su ciently explored, in our setting the collaborative structure allows for faster convergence. <ref type="foot" target="#foot_3">5</ref>Table <ref type="table">3</ref>: Question selection strategies evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Greedy: j ⇤ = arg maxj yij</head><p>A trivial exploit-only strategy: Select the item with highest estimated a nity mean. Random: j ⇤ = random(1,N )</p><p>A trivial explore-only strategy. Maximum Variance (MV): j ⇤ = arg maxj ✏ij A explore-only strategy, variance reduction strategy: Select the item with the highest noisy a nity variance. Maximum Item Trait (MaxT): j ⇤ = arg maxj kvjk2</p><p>Select the item whose trait vector vj contains the most information, namely has highest</p><formula xml:id="formula_4">L2 norm kvjk2 = q v 2 j1 + v 2 j2 + . . . + v 2 jd . Minimum Item Trait (MinT): j ⇤ = arg minj kvjk2</formula><p>Select the item with trait vector with least information. Upper Confidence (UCB): j ⇤ = arg maxj yij + ✏ij Based on UCB1 <ref type="bibr" target="#b3">[3]</ref>: Pick the item with the highest upper confidence bound, namely mean plus variance (95% CI) Thompson Sampling (TS) <ref type="bibr" target="#b5">[5]</ref>:</p><formula xml:id="formula_5">j ⇤ = arg maxj ŷij</formula><p>For each item, sample the noisy a nity from the posterior. Select item with the maximum sampled value.</p><p>We compare a number of approaches for question selection that reflect the considerations discussed above, and several baselines. All approaches are listed in Table <ref type="table">3</ref>. Each selects an item j ⇤ to obtain user feedback on. While the first few are self-explanatory baselines, we discuss three in more detail.</p><p>(1) MaxT approximates maximizing information gain, in the vein of active learning: As user-item ratings are observed, the PMF model adds information to the corresponding user and item trait vectors. In the opposite extreme case, if all item trait elements are close to 0, the corresponding item carries no information. As MinT does the opposite from MaxT, it is hypothesized to have low performance and is employed to establish a lower bound on question selection performance. (2) UCB <ref type="bibr" target="#b3">[3]</ref> is a popular bandit algorithm that selects the items with the highest confidence bound to avoid missing preferences for promising items. (3) Thompson Sampling (TS) is a bandit algorithm that balances exploration and exploitation by selecting items using a sampling strategy <ref type="bibr" target="#b5">[5]</ref>. It samples from its current posterior belief over noisy a nities, and then acts optimally according to this sampled belief. TS focuses on items with high mean a nity, but is also likely to select items with high variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Online Updating</head><p>After posing a question to the user, the observed response needs to be incorporated into to the recommender to allow for continued learning. As shown in <ref type="bibr" target="#b23">[23]</ref>, the questions can be incorporated into the model by setting the probability of the question to 1 and incorporating the user's response following standard probability theory.</p><p>The user's response thus becomes a new observation that the system uses to update the posterior distributions of all latent model parameters related to the incoming user i and the item j asked about, i.e., ↵i, j , ui, vj (but a↵ecting only user i's interaction session). Due to space constraints, we refer the reader to <ref type="bibr" target="#b29">[29]</ref> for the specific Expectation Propagation updates. To select the next question for user i, we use the updated posteriors as the new priors to infer the user's noisy a nity distribution ŷij for all items j 2 J , denoted by ŷi. As the system keeps asking questions to user i and incorporates his/her feedback, the beliefs about the user, and the item in the question, change. This allows the model to move towards the true underlying a nity distribution. All online updates were implemented in Infer.NET <ref type="bibr" target="#b20">[20]</ref>.</p><p>Abs: Absolute Model, Absolute Questions So far we have presented the entire framework for the case where the system poses absolute questions. Before turning to relative feedback, we describe the high-level approach for asking absolute questions (Abs). Using TS for illustration purposes, Abs asks user i about the item with the largest sampled noisy a nity as inferred by the Absolute model:</p><formula xml:id="formula_6">j ⇤ = arg max j2J ŷij<label>(6)</label></formula><p>Based on whether the user (dis)liked item j ⇤ , a new observation (i, j ⇤ ,1/0) is incorporated into the Absolute model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Extension to Relative Preferences</head><p>An alternative is for the system to ask for a preference about a pair of items, i.e., does the user prefer item A (j ⇤ ) or item B (h ⇤ )? Therefore, we present here the extension of our framework to the case of asking relative questions.</p><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Absolute Model, Relative Questions</head><p>First, we present Abs Pos and Abs Pos &amp; Neg. Both use the same mechanism to generate the question "A vs. B" for user i:</p><p>1. Select item A as in Abs (Equation <ref type="formula" target="#formula_6">6</ref>). 2. Virtual observation: Assume user i did not like A.</p><p>3. Virtual update: Incorporate the tuple (i, A, 0) into the Absolute model, infer the posteriors for all model parameters and set them as the virtual new prior. 4. Select item B, again according to Abs, but this time using the virtual prior as prior. The insight behind this mechanism of constructing the relative question is that the two items the user is asked to give a relative preference on should be relatively far apart in the latent embedding, so that (i) the system can learn users' preferences e↵ectively and (ii) the user is not forced to choose among very similar items. This diversity enforcing mechanism is inspired by the approach in <ref type="bibr" target="#b6">[6]</ref>.</p><p>The two methods introduced here di↵er only in the way the feedback is incorporated into the Absolute model. Abs Pos incorporates only positive information while Abs Pos &amp; Neg incorporates both positive and negative information. For example, assume that the user preferred item B to A. Then, Abs Pos incorporates only the observation (i, B, 1), interpreting the relative preference on the preferred item B as a like for B. In contrast, Abs Pos &amp; Neg incorporates two observations: (i, B, 1) for the preferred item and (i, A, 0) for the less preferred item. This can be seen as a variant of the "sparring" approach to dueling bandits <ref type="bibr" target="#b2">[2]</ref>, which samples item pairs and updates the model for both items as if an absolute reward were observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Pairwise Model, Relative Questions</head><p>The third method for selecting relative questions, Pairwise, uses the Pairwise model that directly takes pairwise preferences as input, to generate the relative question and incorporate the observations. Thus, the user's relative feedback is incorporated into the model without any intermediate transformation, i.e., as an observation (i, B, A) when B is preferred over A.</p><p>The Pairwise method picks A exactly as in Abs, and for item B, inspired by the dueling bandit approach in <ref type="bibr" target="#b34">[34]</ref>, it picks the item with the largest probability of being preferred to item A. We instantiate the latter by selecting the item with the maximum noisy di↵erence from item A (j ⇤ ):</p><formula xml:id="formula_7">item B = h ⇤ = arg max h2J ŷihj ⇤<label>(7)</label></formula><p>For the selection of item B, any question selection strategy besides TS illustrated here (except for MinT, MaxT), can be employed exactly as in Table <ref type="table">3</ref>, with the di↵erence that the noisy di↵erence distribution should be used.</p><p>Incorporating the 'Neither' Option.</p><p>Preliminary experiments showed that when the method asks the user to give a relative preference on two items that he dislikes, forcing him/her to choose one could mislead the model about the user's preferences. Thus, we adjusted all methods so that in such a case the user can specify that he likes neither. We implemented this by (i) incorporating two dislikes in Abs Pos &amp; Neg and (ii) omitting the update in Abs Pos and Pairwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTAL SETUP</head><p>We now describe our overall empirical setup, used for the experiments described in the next two sections. Setting. One main di culty of evaluating conversational recommenders is that it requires the ability to have access to user reactions to any possible system action. We address this requirement using generative user models. The first user model is constructed synthetically and is used to validate our model (Section 6). The second is instantiated from real user preferences, collected via a user study (Section 7).</p><p>All experiments consist of an o✏ine and an online phase. During the o✏ine phase, the model is presented with data where M users interact with N items. In the subsequent online phase, the model is used to interact with cold-start users, asking questions using the pool of the o✏ine N items.</p><p>We varied the number of questions from 0 to 15 and report the model's performance after each question. In practice, recommendations could be given after fewer questions, could be integrated with initial recommendations, or could be spread out over several interactions with a given user.</p><p>Research Questions. Our experiments are designed to address the following research questions: RQ 1. Can our model adapt to the user's preferences? RQ 2. Does our model learn e↵ectively under either absolute or relative feedback? RQ 3. Which relative question method performs better? RQ 4. Is absolute or relative feedback more e↵ective? RQ 5. Does the o✏ine initialization step help? RQ 6. Which question selection strategy is more e↵ective?</p><p>To answer each one of these questions, we need some measure of evaluating the e↵ectiveness of our framework. Given that the goal of preference elicitation is a good recommendation list adhering to the user's preferences, we use Average Precision@k (AP@k ) as our evaluation metric.</p><p>Metric. AP@k is a widely used, precision-oriented metric <ref type="bibr" target="#b15">[15]</ref> for capturing accuracy in the top k (we set k = 10). Formally, for user i, we obtain the user's predicted recommendation list by sorting all items by decreasing mean of inferred noisy a nities yi. We evaluate this list by looking at the ground truth r true i , i.e., capturing whether the user liked/disliked each item. AP@k is defined as the average of precisions computed at each liked position in the top k items of the user's ranked list. P @`(Precision@`) is the fraction of liked items out of the top `+ 1 ranked items. Thus,</p><formula xml:id="formula_8">AP @k = k 1 X `=0 P @`• r true i[`] min(k, # of liked items) (8)</formula><p>where [`] represents the index of the item present in rank `, with [`] = 0 corresponding to the index of the top recommended item. Higher value (closer to 1) of AP @k implies better recommendation list. In our results, we report the average and 95% confidence intervals of AP@10 over all cold-start users. Results in additional metrics, such as ratio of correctly ranked pairs and mean reciprocal rank, were omitted as they showed similar trends as AP @10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">LEARNING SYNTHETIC USER TYPE PREFERENCES</head><p>We begin our experiments with an intentionally simplistic example of restaurant recommendation, as real world high-dimensional data is di cult to visualize. The example is meant to demonstrate concepts of our model and to illustrate the e↵ectiveness of our approach to unlearn initial prior beliefs and tailor recommendations to specific user types, answering RQ1 a rmatively.</p><p>In our framework, we first use observations to learn an offline embedding for users and items in the same low-d space.</p><p>Here, we generated the o✏ine observations by considering types of users and restaurants as follows: We generated N = 200 restaurants, and M = 200 users. For each o✏ine user, according to their type, we sampled 10 items from their liked category as likes and 10 items from the rest of the categories as dislikes. We used this intentionally simple synthetic setup to evaluate various parameter choices, and we show results for 2 1 = 10, 2 2 = 0.5, ✏ = 0.1. To allow visualization, we considered only two latent traits (d=2) for this example. We see that in the learned embedding, the first trait indicates spiciness, while the second the price.</p><p>In the same space, an embedding for users is also learned (not shown to avoid clutter). The average trait vector over all users is shown with a red cross. This becomes the initial trait vector for the cold-start user. Considering also the learned items' biases and the average user bias (not shown here), the system constructs an initial estimate of the noisy a nity distribution of the incoming user about all items.</p><p>Based on the o✏ine observations, the learned prior for this a nity distribution favors user types which were popular in the o✏ine data. The task of selecting restaurants for online users resembling the mean o✏ine user is easy, as the prior already captures valuable information. As Fig. <ref type="figure" target="#fig_1">1</ref>, bottom right panel shows, even with no questions, a close to perfect recommendation list can be given for Liking not-spicy users. Similar is the trend for the Liking cheap users (not shown).</p><p>Figure <ref type="figure" target="#fig_1">1</ref>: Results on synthetic restaurant data, across user types (left), and two of the user types (right).</p><p>In contrast, when the user is of a type that was rarely seen during the o✏ine phase (e.g., expensive, shown in Fig. <ref type="figure" target="#fig_1">1</ref>, top right panel), the online recommender has to collect observations that move away from more popular types. The trends for Liking spicy, Liking only-spicy, and only not-spicy user types are similar to the Liking expensive. For these types, the model (all four approaches) starts with AP@10 close to 0, but after every question asked, unlearns the initial wrong prior beliefs, and learns the specific user types' preferences.</p><p>For the results reported, we considered 60 cold-start users of each type and used TS for the question selection.</p><p>All methods learn e↵ectively across all user types, with minor di↵erences (Fig. <ref type="figure" target="#fig_1">1</ref>, left) answering RQ 2 positively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">RESULTS ON REAL DATA</head><p>Having positively answered RQ 1 and RQ 2 above, we turn our attention to a real-world setting to address all research questions in the context of 'where to dine in Cambridge, UK'. For the o✏ine initialization of our framework, we use real users' online search behavior in a commercial search engine (Section 7.1). We use the insights from Section 3 to design a user study that is used to collect real restaurant preferences for Cambridge (Section 7.2). The collected responses serve as a basis for evaluating our online recommendation methods. We sketch a novel two-step approach to infer ratings for all restaurants, apart from those asked in the study (Section 7.3). We extensively evaluate our choices for the recommendation pipeline (Section 7.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Search Data for Offline Initialization</head><p>We start by describing the data which serve as our o✏ine user-restaurants observations, based on which we learn the embedding used to warm start the question-asking phase.</p><p>This data is obtained by identifying restaurant review pages for restaurants in Cambridge (UK) on a major restaurant review service provider. Next, we filter the query and click logs from a major commercial search engine to find (anonymous) cookies that mark a single PC accessing a sequence of these restaurant pages. Each cookie is taken to be a distinct user, and all visits on restaurant review pages are considered to be indicating the user liking the restaurant <ref type="foot" target="#foot_4">6</ref> .</p><p>In particular, taking logs from 26 March to 26 April 2015, we identified 3,549 cookies (users) who accessed at least one of the 512 distinct Cambridge restaurant review pages identified on the review service provider. This resulted in an index of Cambridge restaurants, each one visited by at least one user. Augmenting each of the restaurants with all known links and metadata associated with it in a proprietary restaurant index, and selecting a further three months back in each of those users' search histories, we recorded every interaction of these users with these restaurant links. During the four month search history of the users, we recorded interactions with 289 unique restaurants out of the 512 Cambridge restaurants. The total number of unique user -restaurant interactions recorded is 9330.</p><p>Thus, our o✏ine data consists of M = 3549 users, N = 289 restaurants, and 9330 positive observations <ref type="bibr" target="#b1">(1)</ref>. To introduce dislikes (0) to the rating matrix as well, for every user i who has liked n + i items, we sampled uniformly at random n i = min(10, n + i ) restaurants as dislikes. Parameter Setting. To learn the o✏ine embedding, we set the hyper-parameters to the combination that achieved the highest pairwise accuracy in the o✏ine observations: d = 4 (i.e., 4 latent traits), 2  1 = 2 2 = 10, ✏ = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">User Study as Basis for Online Evaluation</head><p>One of the issues of evaluating a conversational recommender is that one needs to know the user's ground truth on the space of all items (and questions). To obtain this, one needs to implement an interactive recommender asking questions to real users and receiving their responses. As an intermediate step, we conducted a user study and used the collected responses as ground truth for online users.</p><p>In the user study conducted, each participant filled in an anonymous web questionnaire about their preferences on a pool of restaurants in Cambridge, UK. The participants were asked "would you consider restaurant X for your next Friday night dinner?", labeling each restaurant with a binary label (yes/no). These responses comprise our ground truth.</p><p>For the pool of Cambridge restaurants we carefully selected ten restaurants, diverse in various features (as identified in Section 3). We recruited twenty eight individuals for the study. Given the anonymity of the questionnaire (in order to encourage truthfulness in the responses), demographic information was not recorded. However, the larger Each participant was presented with the questionnaire about the same restaurants, but with varying order to avoid presentation bias. The participants were advised to visit the restaurant webpage when unfamiliar with the restaurant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Obtaining Ground Truth</head><p>In our user study, we obtained restaurant labels for 10 out of the 289 Cambridge restaurants present in the o✏ine data, for 28 participants. However, for reliable evaluation we need labels for the entire item space (rather than limiting our methods to ask about just these 10 restaurants). Therefore, we introduce an approach to fill in complete ground truth labels. Also, to increase the diversity of the user space, inspired by <ref type="bibr" target="#b17">[17]</ref>, we used bootstrapping to obtain 50 coldstart users based on the 28 participants' ground truth.</p><p>In particular, for each cold-start user: 1. Randomly sample one of the 28 participants. 2. Observe the sampled user's labels on the pool of 10 restaurants asked in the user study. 3. Infer user's traits ui (prior= learned embedding in 7.1). 4. Sample ûi ⇠ ui. Set this to be the new prior of ui. 5. With this prior, infer the ratings ri distribution. 6. Sample ratings from their distribution ri ⇠ri.</p><p>In this way, for each bootstrapped user we obtain a complete rating list for all 289 restaurants that is consistent with the user study labels of some user, yet is perturbed to account for variety in real user populations.</p><p>As far as we are aware, this approach for filling in the missing ratings is novel. It gives us ground truth as close to real as possible given the resources available. Alternatives would be exhaustive labels (not feasible for our study), or rejection/importance sampling (only e↵ective when leveraging logged exploration data from large-scale systems, e.g <ref type="bibr" target="#b16">[16]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Results</head><p>Having obtained the o✏ine embedding and the online users' ground truth for all items, we now present our experiments on a real restaurant recommendation scenario with the focus of answering the remaining research questions RQ 3 -RQ 6. Each of these questions investigates a separate component of our continuously learning recommender system.</p><p>Which method for relative questions is better? (RQ 3)</p><p>Recall that we proposed three approaches for modeling relative feedback. The first two incorporate feedback in an absolute model, (a) by incorporating information that the user liked the preferred item (ignoring the non-preferred one, Abs Pos), and (b) by incorporating both positive (preferred) and negative (non-preferred) information (Abs Pos &amp; Neg). Alternatively, we construct a pairwise model (Pairwise). The results of the three methods' comparison are shown in the left panel of Figure <ref type="figure" target="#fig_3">2</ref>. These results were obtained using TS for question selection and start from the o✏ine embedding.</p><p>We see no significant di↵erence among the methods during the first few questions. After only 2 questions, all methods significantly improve over the initial performance of .584 to respectively .734 (Abs Pos), .780 (Abs Pos &amp; Neg), and .684 (Pairwise). However, as we ask more questions, Abs Pos &amp; Neg forces negative observations on liked restaurants, thus causing the method to degrade the ranking. Overall, Abs Pos is the most e↵ective method for relative questions. <ref type="foot" target="#foot_5">7</ref>Are absolute or relative questions better? (RQ 4)</p><p>To answer this question, we compare the performance of the absolute-question asking method (Abs) with the best relative-question asking method (Abs Pos). The results are shown in the right panel of Figure <ref type="figure" target="#fig_3">2</ref>. Until 2 questions, both methods have almost identical performance. But, after 5 questions, Abs performs significantly better than the relative feedback method, and achieves close to perfect performance after 15 questions (AP @10 = .975). We hypothesize that this result can be explained by the fact that our o✏ine embedding favored absolute feedback.</p><p>Although our result shows that very high accuracy can be achieved when users provide accurate feedback on absolute questions, in practice this may not always be possible. Psychological e↵ects such as anchor bias <ref type="bibr" target="#b12">[12]</ref> can lead users to implicitly compare items, lowering the quality of absolute feedback. When this is the case, our result shows that high performance can be achieved with relative feedback as well.</p><p>Future work could involve hybrid models that automatically learn whether absolute or relative feedback, or a combination, is more accurate in a given setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does offline initialization help? (RQ 5)</head><p>Next, we investigate the impact of model initialization, i.e., initializing the online recommender with an initial o✏ine embedding, compared to starting from a generic prior (using the optimized hyper-parameters specified in 7.1). We present the results of this comparison in Figure <ref type="figure" target="#fig_4">3</ref> both for the absolute (Abs) and the best relative feedback model (Abs Pos), in the left and right panel correspondingly.</p><p>Our hypothesis is that the o✏ine embedding learned from the weakly labeled data of a search log captures su cient information to helpfully constrain continued learning, even if it does not exactly match the structure that underlies online users. Indeed, Figure <ref type="figure" target="#fig_4">3</ref> demonstrates great performance improvements when initializing the models from this embedding over generic prior initialization. By placing the new users as the average o✏ine user, performance increases from .217 to .584, even without asking any questions. As the recommender collects more responses, performance continues to improve in both cases.</p><p>One observation is that the uninitialized system can ultimately achieve high performance, and for Abs Pos (Prior) even pass the o✏ine initialized system. However, this is only achieved after many questions (here: 14). The phenomenon is nevertheless interesting, as it may point to a bias-variance trade-o↵. Starting from the generic prior allows the system to eventually perfectly fit a given user's preferences, however, learning takes a long time because there is no initial to constrain learning outcomes. We conclude that using o✏ine initialization is highly beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Which question selection strategy is best? (RQ 6)</head><p>In Figure <ref type="figure" target="#fig_5">4</ref> we report the comparison results of the various question selection strategies of Section 4.3.2 (except MaxV whose performance almost coincides with UCB), for the Abs and Abs Pos methods initialized with the o✏ine embedding.</p><p>For the Abs model (Figure <ref type="figure" target="#fig_5">4</ref>, top), we observe that: (i) as expected, lowest AP@10 is achieved by MinT, (ii) Random learns slowly, likely because it fails to focus on more promising items for e↵ective learning, and (iii) all remaining strategies perform equally well. We hypothesize that Greedy performs well thanks to the o✏ine embedding, along with the online updating of all parameters after each response.</p><p>Turning to Abs Pos (Figure <ref type="figure" target="#fig_5">4</ref>, bottom), the best performing strategies are those that encourage more diversity across the questions of the interactive session, namely the banditbased ones and Random. Greedy and MaxT are the worst performing ones, following MinT. Our insight why this is the case is that they tend to select questions A vs B, followed by A vs C, etc. when A is preferred. Given that there is no construction encouraging B and C to be diverse (such as sampling or taking into account uncertainties), the questions focus on comparing parts of the embedding which are similar across questions, thus preventing truly e↵ective learning.</p><p>Overall, we find that the bandit-inspired strategies perform the most robustly, achieving top performance across models. In the classic bandit setting, these approaches systematically balance the need to explore new solutions with the need to reap the rewards of what has already been learned. Here, we find that similar principles allow these strategies to collect user feedback that balances the need to not discard any areas of the latent space prematurely with the need to focus questions on the most promising areas. This novel insight is important because it shows that banditbased question selection strategies can lead to benefits that go beyond the typical bandit problem.</p><p>Discussion. All our results show that our methods enable e↵ective learning from interactions with their users, under either feedback type, answering positively RQ 1 and RQ 2.</p><p>We show substantial recommendation performance improvements over the performance we would get without adapting to the user; by 25% after only 2 questions.</p><p>Although our underlying model can be augmented with external features <ref type="bibr" target="#b29">[29]</ref>, one key advantage is it does not need them. It learns online both the user's and the items' latent traits. Together with <ref type="bibr" target="#b18">[18]</ref> and <ref type="bibr" target="#b33">[33]</ref>, our findings corroborate the e↵ectiveness of latent-feature interactive recommenders.</p><p>A novel insight is that taking into account the uncertainties in the learning of both the item and the user embedding, we can adapt to the specific user's preferences, under a certain context. This answers to the question posed by <ref type="bibr" target="#b33">[33]</ref> and is key for allowing the system to learn both the user's profile and the questions' e↵ectiveness in a contextual manner.</p><p>We have demonstrated e↵ective learning from feedback present in many interactive settings. Thus, our approach is a good candidate for online learning across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSIONS</head><p>In this paper we proposed a novel view of recommendation as an interactive process. Like human recommenders, we envision recommender systems that can converse with new users to learn to know their preferences.</p><p>We develop such a conversational recommender, using restaurant recommendation as our motivating example. We start by examining restaurant related queries issued in a commercial search engine. Using these insights, we conducted a user study to elicit ground truth for evaluating our system. We propose a conversational recommender model that is theoretically well anchored in probabilistic matrix factorization models <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b29">29]</ref>. We show how such models can be extended to support continuous learning. We empirically evaluate our approach using the ground truth based on real dining preferences elicited through our user study.</p><p>Our results have important implications for the development of conversational recommender systems. First, we demonstrated that best performance can be achieved with absolute questions. However, even in settings where only relative feedback is available, e↵ective learning is possible. Second, we proposed a systematic approach to initializing conversational recommenders with an o✏ine learned embedding, boosting greatly the performance even when only weakly supervised data is available. Third, we identified question selection strategies that can elicit feedback for very e↵ective learning. Together, these insights pave the way towards conversational recommenders.</p><p>A promising future direction is to extend conversational recommenders to use reinforcement learning approaches, for capturing longer-term dependencies <ref type="bibr" target="#b17">[17]</ref>. The modular structure of our framework allows various choices in a plug-andplay-manner, considering di↵erent feedback types, underlying probabilistic models etc., with the goal of building a suite of conversational recommenders for a variety of settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4232-2/16/08. . . $15.00 DOI: http://dx.doi.org/10.1145/2939672.2939746</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Pick a model (Absolute/Pairwise) (Sec. 4.2) and preference elicitation mechanism: Abs (Sec. 4.3) / Abs Pos / Abs Pos &amp; Neg / Pairwise (Sec. 4.4). 2. Initialize model parameters using o✏ine data. 3. A new user arrives. Now iterate for a few questions 3 : (a) Mechanism selects a question to ask (b) User answers the question (c) All model parameters are updated (d) Remove the question from the allowed questions 4. System presents the final recommended list</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>3. (b)For each observation (i, j, h) compute noisy di↵erence: ŷijh = ŷij ŷih<ref type="bibr" target="#b3">(3)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Di↵erences between relative feedback models (left); and comparing absolute and relative feedback (right). pool of individuals from which the participants were drawn (65 people working in a research lab) varied in factors such as age, job level, income, time spent in Cambridge.Each participant was presented with the questionnaire about the same restaurants, but with varying order to avoid presentation bias. The participants were advised to visit the restaurant webpage when unfamiliar with the restaurant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Impact of o✏ine initialization on performance for absolute (Abs, left) and relative feedback (Abs Pos, right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of question selection strategies for absolute (Abs, top) and relative (Abs Pos, bottom ) models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Contextual terms in restaurant related queries.</figDesc><table><row><cell>IN</cell><cell>NEAR</cell><cell></cell><cell>FOR</cell><cell></cell><cell>WITH</cell></row><row><cell>nyc</cell><cell>me</cell><cell></cell><cell cols="2">wedding receptions</cell><cell cols="2">party room</cell></row><row><cell>chicago</cell><cell>by</cell><cell></cell><cell cols="2">large group</cell><cell cols="2">small private room</cell></row><row><cell>las vegas</cell><cell cols="2">times square</cell><cell>rich</cell><cell></cell><cell>piano</cell></row><row><cell>houston</cell><cell>here</cell><cell></cell><cell>dessert</cell><cell></cell><cell cols="2">live music</cell></row><row><cell>miami</cell><cell>lax</cell><cell></cell><cell cols="2">your 21st birthday</cell><cell cols="2">someone</cell></row><row><cell cols="5">los angeles miami airport steak at lunch time</cell><cell>a view</cell></row><row><cell>atlanta</cell><cell>airport</cell><cell></cell><cell cols="2">gluten free food</cell><cell cols="2">play area</cell></row><row><cell>brooklyn</cell><cell>fenway park</cell><cell></cell><cell cols="4">valentine day in dallas banquet room</cell></row><row><cell cols="7">Table 2: Restaurant Feature Dictionaries (note: frequency</cell></row><row><cell cols="4">counts have been rescaled)</cell><cell></cell><cell></cell></row><row><cell cols="2">Cuisine Freq.</cell><cell cols="2">Adj.</cell><cell>Freq.</cell><cell>Food</cell><cell>Freq.</cell></row><row><cell>mexican</cell><cell>475</cell><cell cols="2">good</cell><cell>27</cell><cell>seafood</cell><cell>139</cell></row><row><cell>chinese</cell><cell>407</cell><cell cols="2">famous</cell><cell>13</cell><cell>sushi</cell><cell>40</cell></row><row><cell>italian</cell><cell>381</cell><cell cols="2">nice</cell><cell>12</cell><cell>steak</cell><cell>32</cell></row><row><cell>thai</cell><cell>174</cell><cell cols="2">romantic</cell><cell>11</cell><cell>bbq</cell><cell>29</cell></row><row><cell>indian</cell><cell>144</cell><cell cols="2">upscale</cell><cell>6</cell><cell>fish</cell><cell>24</cell></row><row><cell>japanese</cell><cell>125</cell><cell cols="2">small</cell><cell>6</cell><cell>tapas</cell><cell>19</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>4 :</head><label>4</label><figDesc>Pick item(s) for absolute (relative) question (Sec. 4.3/ 4.4). 5: Incorporate feedback according to (i) Abs (Sec. 4.3), (ii) Abs Pos, (iii) Abs Pos &amp; Neg, or (iv) Pairwise. (Sec. 4.4)</figDesc><table><row><cell>6: Update u</cell><cell>i , ↵</cell><cell>i , v,</cell><cell>(Section 4.3.3) and infer the noisy</cell></row><row><cell cols="3">a nity distribution y</cell><cell></cell></row></table><note><p>i (Eq. 1) or noisy di↵erence (Eq. 3).</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We plan to extend our framework to set and choice-based feedback, to allow the comparison with<ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b11">11]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Keeping in mind that these criteria to some degree reflect users' perception of the search engine and its capabilities.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>A study of the right stopping criterion is left for the future.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>A formal regret analysis lies beyond the scope of this work.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Though URL visitation is a weak positive signal, the experiments indicate it is a reasonable proxy for interest.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>Studying the e↵ect of alternatives for introducing dislikes in the o✏ine data on Abs Pos's success is left for future work.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We would like to thank Tom Minka and Yordan Zaykov for the very insightful discussions on the model and evaluation. We also thank the participants of our user study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Regression-based latent factor models</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reducing dueling bandits to cardinal bandits</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ailon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Karnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="856" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using confidence bounds for exploitation-exploration trade-o↵s</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="397" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A latent source model for online collaborative filtering</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bresler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3347" to="3355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An empirical evaluation of thompson sampling</title>
		<author>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2249" to="2257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Less is more: probabilistic models for retrieving fewer relevant documents</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Critiquing-based recommenders: survey and emerging trends</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="125" to="150" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Bayesian image retrieval system, PicHunter: theory, implementation, and psychophysical experiments</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Papathomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="20" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Google news personalization: scalable online collaborative filtering</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Developing Constraint-based Recommenders</title>
		<author>
			<persName><forename type="first">A</forename><surname>Felfernig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="187" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving the user experience during cold start through choice-based preference elicitation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Graus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Willemsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="273" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prospect theory: An analysis of decision under risk</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Econometrica</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="263" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">E cient Thompson Sampling for Online Matrix-Factorization Recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kawale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kveton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tran-Thanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1297" to="1305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Computer</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A short introduction to learning to rank</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IEICE TIS</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1854" to="1862" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A contextual-bandit approach to personalized news article recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="661" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dj-mc: A reinforcement-learning agent for music playlist recommendation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Liebman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saar-Tsechansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="591" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Choice-based preference elicitation for collaborative filtering recommender systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Loepp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3085" to="3094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving recommender systems with adaptive conversational strategies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hypertext</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guiver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Knowles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Microsoft Research Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Eliciting the users&apos; unknown preferences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neidhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Seyfang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Werthner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generalized thompson sampling for sequential decision-making and causal inference</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Complex Adaptive Systems Modeling</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Content-based recommendation systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The adaptive web</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="325" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Qualitative research practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sage</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Active learning in recommender systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rubens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugiyama</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="735" to="767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collaborative learning of preference rankings</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="261" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Matchbox: large scale online bayesian recommendations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning multiple-question decision trees for cold-start recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lebanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="445" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Personalized recommendation via parameter-free contextual bandits</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="323" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Explore-exploit in top-n recommender systems via gaussian processes</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Vanchinathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nikolic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">De</forename><surname>Bona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Interactive collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1411" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Relative confidence sampling for e cient on-line ranker evaluation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zoghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
