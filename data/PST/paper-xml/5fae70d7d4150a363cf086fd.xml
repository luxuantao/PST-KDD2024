<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Fuzzy Cognitive Maps for Interpretable Multivariate Time Series Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jingyuan</forename><surname>Wang</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Zhen</forename><surname>Peng</surname></persName>
							<email>zhenpeng@bipt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xiaoda</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Junjie</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">is with School of Computer Science and Engineering</orgName>
								<address>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Advanced Innovation Center for Big Data and Brain Computing, and State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country>China. Z. Peng</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">is with School of Economics &amp; Management</orgName>
								<orgName type="institution">Beijing Institute of Petrochemical Technology</orgName>
								<address>
									<postCode>102617</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">X. Wang, and C. Li are with School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MOE Engineering Research Center of ACAT</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Economics and Management, and Beijing Advanced Innovation Center for Big Data and Brain Computing</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Fuzzy Cognitive Maps for Interpretable Multivariate Time Series Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TFUZZ.2020.3005293</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fuzzy Cognitive Maps</term>
					<term>Time Series Prediction</term>
					<term>Deep Neural Networks</term>
					<term>Interpretable Prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Fuzzy Cognitive Map (FCM) is a powerful model for system state prediction and interpretable knowledge representation. Recent years have witnessed the tremendous efforts devoted to enhancing the basic FCM, such as introducing temporal factors, uncertainty or fuzzy rules to improve interpretation, and introducing fuzzy neural networks or Wavelets to improve time series prediction. But how to achieve highprecision yet interpretable prediction in cross-domain real-life applications remains a great challenge. In this paper, we propose a novel FCM extension called Deep FCM for multivariate time series forecasting, in order to take both the advantage of FCM in interpretation and the advantage of deep neural networks in prediction. Specifically, to improve the predictive power, Deep FCM leverages a fully connected neural network to model connections (relationships) among concepts in a system, and a recurrent neural network to model unknown exogenous factors that have influences on system dynamics. Moreover, to foster model interpretability encumbered by the embedded deep structures, a partial derivative-based approach is proposed to measure the connection strengths between concepts in Deep FCM. An Alternate Function Gradient Descent algorithm is then proposed for parameter inference. The effectiveness of Deep FCM is validated over four publicly available datasets with the presence of seven baselines. Deep FCM indeed provides an important clue to building interpretable predictors for real-life applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The Fuzzy Cognitive Map (FCM) is a flexible and powerful model for system state prediction and interpretable knowledge representation <ref type="bibr" target="#b0">[1]</ref>. The FCM model describes a system with multiple interactive components (i.e., concepts) as a weighted directed graph, where the vertexes denote system components and edges denote the interactions between components. Since the knowledge about a system is represented as a graph with clear interactive relationships, FCM is deemed naturally interpretable for system dynamics and has been widely adopted in many interpretation-sensitive prediction applications, such as public policy making <ref type="bibr" target="#b1">[2]</ref>, business management <ref type="bibr" target="#b2">[3]</ref>, healthcare diagnosis <ref type="bibr" target="#b3">[4]</ref>, and behavioral analysis <ref type="bibr" target="#b4">[5]</ref>.</p><p>Interpretable knowledge representation and high performance prediction, unluckily, are often mutually exclusive. The FCM model is not an exception. In the basic FCM model, the graph edges can only describe static and linear relationships, which degrades the prediction performance of FCM in many complex real-world applications, especially when compared with neural network-based deep learning models <ref type="bibr" target="#b5">[6]</ref>. The deep learning models, however, are often criticized for their blackbox nature with incomprehensible variables in deep layers, let alone influence relationship explanations to the variables. How to improve the capability of FCM in non-linear dynamics prediction while keeping the interpretation advantage in the meanwhile, or in other words, to achieve satisfactory interpretable prediction, remains an open and essential problem.</p><p>In the literature, many extensions have been proposed to enhance the performance of the basic FCM model in terms of interpretation and prediction. For instance, temporal factors are introduced into the FCM framework to model dynamic relationships, resulting in Dynamical Cognitive Networks, Fuzzy Time Cognitive Maps and Evolutionary Fuzzy Cognitive Maps <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Fuzzy Grey Cognitive Maps, Intuitionistic Fuzzy Cognitive Maps, and Rough Cognitive Maps are proposed to model uncertain relationships among system components <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>. Rule-based Fuzzy Cognitive Maps and Extended Fuzzy Cognitive Maps adopt logic rules to express non-linear relationships in FCM <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. The fuzzy neural networks and wavelet transform are also adopted to improve the performance of the FCM framework in time series forecasting applications <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b17">[18]</ref>. While the above studies indeed have improved the basic FCM model in different aspects, it is still in great need to design a new FCM model to gain highprecision yet interpretable prediction power for cross-domain real-life applications, where non-linear complex dynamics with unknown exogenous factors are commonly seen.</p><p>In this paper, the advantage of deep neural network models in high-performance prediction is introduced into the interpretable FCM framework to build a novel interpretable predictor called Deep FCM (or DFCM for short). Our model is designed for the task of multivariate time series forecasting. It extends the basic FCM to a general framework, which consists of a fully connected neural network to model nonlinear and non-monotonic influences among system concepts, and a recurrent neural network (RNN) to model unknown exogenous factors that have latent influence on system dynamics. An Alternate Function Gradient Descent algorithm is then carefully designed for efficient parameter inference of Deep FCM with built-in deep neural networks. In this way, Deep FCM is equipped with much greater power than the basic FCM in time series prediction.</p><p>Beyond prediction, we also adopt a partial derivative-based method to measure the connection strength between each pair of system concepts. This is to ensure that the excellent interpretability of the basic FCM would not be undermined by the black-box nature of deep neural network components in Deep FCM. In this way, our model could achieve improved performance in multivariate time series prediction while keeping the interpretability of the FCM framework at the same time. That is why we called Deep FCM an interpretable prediction model.</p><p>The effectiveness of Deep FCM is verified over four publicly available datasets obtained from different application domains, and is compared with seven competitive baselines. The experimental results show that Deep FCM indeed can achieve much better performance in system state prediction. Meanwhile, the non-linear concept relationships in complex real-life systems indeed can be accurately captured and clearly interpreted by the partial derivative-based method. We also verifies the effectiveness of the RNN component in modelling periodical exogenous factors, which indeed improves the prediction power of Deep FCM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Fuzzy Cognitive Maps</head><p>In the basic FCM framework <ref type="bibr" target="#b0">[1]</ref>, a system consisting of several interactive components is described by three elements: Concepts, Activation States, and Relationships. Concepts represent components in a system, activation states represent states of components, and relationships represent influences among components.</p><p>As illustrated in Fig. <ref type="figure" target="#fig_2">1</ref>, the FCM models a system with I concepts as a weighted directed graph. We denote the i-th graph vertex as c i , which is used to express the i-th concept in the system. The edge weight for vertex i to vertex j is denoted as w ij , which expresses the relationship of c i to c j . The value of w ij is in the range of [− </p><formula xml:id="formula_0">(t+1) i = ϕ   a (t) i + j =i wjia (t) j   ,<label>(1)</label></formula><p>where the function ϕ(•) is a membership function to fuzzify the activation states in [0, 1], and the value of</p><formula xml:id="formula_1">w ij is in the range of [−1, 1] [19].</formula><p>In real-world applications, the activation levels {a (t)</p><p>i } are observable time series, and the relationships w ij are unknown knowledge to be learnt from the observable activation levels. Given random initial values, the DHL algorithm adjusts w ij using the observable data at time t as follows:</p><formula xml:id="formula_2">w (t+1) ij = w (t) ij + λ (t) ∆a (t) i ∆a (t) j − w (t) ij ,<label>(2)</label></formula><p>where ∆a</p><formula xml:id="formula_3">(t) i = a (t) i − a (t−1) i</formula><p>, and λ (t) = 0.1(1 − t/(1.1q)) is a dynamic learning rate, with the parameter q adopted to ensure that</p><formula xml:id="formula_4">w ij ∈ [−1, 1]. The value of w (t+1) ij</formula><p>is iteratively updated until convergence or some stopping criterion is met. The DHL algorithm has many improved versions, such as NHL (Nonlinear Hebbian learning) <ref type="bibr" target="#b19">[20]</ref> and AHL (Active Hebbian learning) <ref type="bibr" target="#b20">[21]</ref>. Moreover, evolutionary optimizations are also adopted to learn W , such as the real-coded genetic algorithm (RCGA) <ref type="bibr" target="#b21">[22]</ref> and the particle swarm optimization (PSO) <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Extensions of FCM</head><p>Despite the great success made, the basic FCM yet has some limitations. Firstly, relationships in many real-world systems are highly nonlinear and non-monotonic; however, the relationships modeled by basic FCM are linear and monotonic. In the literatures, many FCM extensions have been proposed to overcome this drawback <ref type="bibr" target="#b23">[24]</ref>. One main stream of these extensions is using non-linear tools, such as logic rules, to describe complex concept relationships. For instance, RBFCM uses qualitative fuzzy rules to replace the quantitative mathematical description of relationships <ref type="bibr" target="#b12">[13]</ref>, and FRI-FCM uses fuzzy IF-THEN rules to express non-linear relationships <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>. The other stream of the extensions is to introduce uncertainty into relationships. For instance, FGCM uses the grey system theory to handle highly uncertain relationships in incomplete and small datasets <ref type="bibr" target="#b9">[10]</ref>, iFCM introduces the intuitionistic fuzzy sets to handle the hesitancy in human decision makings <ref type="bibr" target="#b10">[11]</ref>, BDD-FCM replaces absolute linguistic terms as belief degree distributions to describe uncertain relationships <ref type="bibr" target="#b26">[27]</ref>, and the rough sets are introduced by RCM to represent diversity of the relationship among concepts <ref type="bibr" target="#b11">[12]</ref>.</p><p>The second limitation of the basic FCM is its relationships are static, which hinders its applications in dynamic systems. To overcome this drawback, temporal factors are introduced into FCM by many studies. For instance, DCN introduces a dynamic function into FCM relationships <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b27">[28]</ref>, DRFCM adopts a reinforced learning procedure to update relationships dynamically <ref type="bibr" target="#b28">[29]</ref>, EFCM proposes asynchronous updates of the variables to handle dynamics of concept interactions <ref type="bibr" target="#b8">[9]</ref>, and TAFCM uses timed automata to model dynamic relationships between concepts <ref type="bibr" target="#b29">[30]</ref>. A common idea of these works is to model relationships as a function of time.</p><p>In summary, while the above-mentioned studies perform excellently in adapting FCM to nonlinear and dynamic relationships, a drawback of these extension models is users have to design complicated logic rules, uncertain and dynamic </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation Definition c i</head><p>The i-th concept in a system.</p><formula xml:id="formula_5">a i</formula><p>The fuzzy activation state of the concept i. The instance at time t is denoted as a</p><formula xml:id="formula_6">(t) i . a</formula><p>The fuzzy activation state vector of all concepts (the system state). The instance at time t is denoted as a (t) . w ij</p><p>The relationship of c i to c j , which is a constant in basic FCM but is a function of a in DFCM.</p><formula xml:id="formula_7">f i (a)</formula><p>The function to model the relationship of the system state a to a i , named as f -function.</p><formula xml:id="formula_8">u i (t)</formula><p>The function to model the influence of exogenous factors to a i , named as u-function.</p><formula xml:id="formula_9">y (m,k)</formula><p>The output of the m-th neuron in the k-th hidden layer of a f -function.</p><formula xml:id="formula_10">y (t) (m,k) is an instance at time t v (nm,k)</formula><p>The weight of the n-th input of the m-th neuron in the k-th hidden layer of the f -function.</p><formula xml:id="formula_11">r ij</formula><p>The general relationship of the concept c i to c j , which is a function of a in DFCM. w ij (a k )</p><p>A general strength measurement of the causal relationship of the concept c i to c j . function according to specific applications. On the contrary, the representational learning capacity of neural networks lets users free from complicated rules designing. There is much room in improving the adaptability of the FCM framework in different application scenarios. One possible way is to leverage the representational learning ability of neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. FCM for Time Series Predictions</head><p>The capabilities of FCM in time series modeling have already been widely acknowledged. Ref. <ref type="bibr" target="#b30">[31]</ref> proposed a framework that first transforms state of a univariate time series into fuzzy sets and then uses a basic FCM model to predict the time series. Ref. <ref type="bibr" target="#b31">[32]</ref> uses historical states in a moving window as concepts of basic FCM models to predict future state of a univariate time series. Ref. <ref type="bibr" target="#b31">[32]</ref> proposed a mechanism to optimize the FCM structure, membership functions and moving window size in time series prediction dynamically. Ref. <ref type="bibr" target="#b32">[33]</ref> improved the framework of <ref type="bibr" target="#b30">[31]</ref> by using fuzzy C-means to transform time series into information granules. Ref. <ref type="bibr" target="#b33">[34]</ref> adopted the ARIMA model to improve the performance of FCMs in time series prediction. In order to handle large-scale nonstationary time series, Wavelet-HFCM <ref type="bibr" target="#b14">[15]</ref> applies redundant Haar wavelet transform to decompose univariate time series into multivariate time series, and uses ridge regression to train FCM models for forecasting.</p><p>The FCM model was also applied in the multivariate time series prediction problem, where the time series of multivariate are considered as states of concepts in a system <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. Papageorgiou et al. <ref type="bibr" target="#b34">[35]</ref> proposed a modified error function to optimize the performance for multi-step multivariate time series prediction of FCM. Froelich et al. <ref type="bibr" target="#b35">[36]</ref> proposed a dynamic optimization for FCM parameter and structure selection in multivariate time series prediction. Papageorgiou et al. <ref type="bibr" target="#b15">[16]</ref> proposed a two-stage prediction model which uses evolutionary FCMs to select the most important attributes as inputs in an ANN to make time series prediction.</p><p>Neural network structures were also adopted by FCM for time series prediction. Ref. <ref type="bibr" target="#b16">[17]</ref> implements FCM based on a fuzzy neural network for time series prediction, and Ref. <ref type="bibr" target="#b17">[18]</ref> adopts a similar FCM structure to model chaotic time series. However, in order to infer and express relationships between concepts, the structures of fuzzy neural networks in <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b17">[18]</ref> are strictly limited with small numbers of layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. DEEP FUZZY COGNITIVE MAPS</head><p>In this section, we propose the Deep Fuzzy Cognitive Maps model (deep FCM or DFCM for short) for multivariate state time series prediction and influence analysis among systematic concepts. Fig. <ref type="figure" target="#fig_1">2</ref> shows the framework of Deep FCM. The notations used in Deep FCM are listed in Table <ref type="table" target="#tab_1">I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Time Series Fuzzification</head><p>Given a system consisting of a group of concepts, we denote the original time series of a concept j as </p><formula xml:id="formula_12">x j = x (1) j , . . . , x (t) j , . . . , x (T ) j , x (t) j ∈ R, ∀ j,</formula><formula xml:id="formula_13">z (t) j = x (t) j − µj σj ,<label>(3)</label></formula><p>where µ j and σ j are the mean and standard deviation of x j . Next, deep FCM uses a sigmoid membership function to fuzzify the normalized time series z (t) j into a (t) j ∈ (0, 1) as follows:</p><formula xml:id="formula_14">a (t) j = ϕ z (t) j = 1 1 + e −z (t) j ,<label>(4)</label></formula><p>where ϕ(•) is the sigmoid membership function that has a range of (0, 1). Apparently, when z Given a fuzzy activation state a (t+1) j ∈ [0, 1] predicted by DFCM, we use the following function to defuzzify a fuzzy activation state as its raw value c j :</p><formula xml:id="formula_15">(t) j = +∞, a<label>(</label></formula><formula xml:id="formula_16">x (t+1) j = ϕ −1 a (t) j • σj + µj.<label>(5)</label></formula><p>In the default assumption, input time series x j are not in crisp values. For the condition x (t) j ∈ {0, 1}, we skip the normalization and fuzzification steps and directly set a </p><formula xml:id="formula_17">(t) j = x (t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Modelling Nonlinear Influence</head><p>One drawback of the basic FCM is its weak capacity in modeling nonlinear relationships. To deal with this, Deep FCM extends Eq. ( <ref type="formula" target="#formula_0">1</ref>) of the basic FCM to a general form as</p><formula xml:id="formula_18">a (t+1) j = ϕ uj(t) + fj a (t) .<label>(6)</label></formula><p>Here, the function f j (•) is used to model relationships of a to a j , where a (t) = (a</p><formula xml:id="formula_19">(t) 1 , . . . , a<label>(t) i , . . . , a (t)</label></formula><p>I ) denotes the activation states of all concepts (i.e., the system state) at time t. The function u j (t) is used to model influences of unknown exogenous factors to a j . We name the two functions as the ffunction and u-function, respectively. In Eq. 6, the summation of the f -function and the u-function is fuzzified by a sigmoid membership function ϕ to generate a (t+1) j</p><p>. Obviously, when u j (t) = 0 and f j (a</p><formula xml:id="formula_20">(t) ) = I i=1 w ij a (t)</formula><p>i with w jj = 1, DFCM degenerates to the basic FCM. In other words, the basic FCM is a special case of DFCM.</p><p>The neural network is a powerful model with universal approximation capability <ref type="bibr" target="#b36">[37]</ref>. The f -functions of DFCM are implemented by feedforward neural networks <ref type="bibr" target="#b5">[6]</ref>. Specifically, we define f j (a (t) ) in Eq. ( <ref type="formula" target="#formula_18">6</ref>) as a feedforward neural network with K hidden layers. The number of neurons in the layer k is denoted by M k . In the time slice t, the output of the m-th neuron in the k-th layer, i.e., y</p><formula xml:id="formula_21">(t) (m,k) , is generated by y (t) (m,k) = ReLU   M k−1 n=1 v (nm,k) y (t) (n,k−1)   ,<label>(7)</label></formula><p>where v (nm,k) is the connection weight from the neuron n in the layer k − 1 to the neuron m in the layer k. ReLU(•) is a Rectified Linear Unit (ReLU) activation function, which is defined as</p><formula xml:id="formula_22">ReLU(z) = z, z &gt; 0 0, z ≤ 0 . (<label>8</label></formula><formula xml:id="formula_23">)</formula><p>As mentoined in Ref. <ref type="bibr" target="#b5">[6]</ref> the ReLU activation function have advanced performance. Moreover, ReLU can also ensure</p><formula xml:id="formula_24">f j (a) = 0 at the origin a 1 = • • • = a i = • • • = a I = 0,</formula><p>which is consistent with the basic FCM.</p><p>In the input layer of f j (a (t) ), we set y</p><formula xml:id="formula_25">(t) (n,0) = a (t)</formula><p>n . In the output layer, we calculate a predictive output as</p><formula xml:id="formula_26">y (t+1) (K+1) = M K n=1 v (n1,K+1) y (t) (n,K) = f j (a (t) ).<label>(9)</label></formula><p>In the f -function, we do not include a bias term in neurons and do not applied the ReLU activation to the output layer neither. Both of the two treatments are to ensure that DFCM, a deep-structure enhanced FCM, is consistent with the basic FCM. As shown in Eq. ( <ref type="formula" target="#formula_0">1</ref>), it is obvious that the expression of the basic FCM does not contain bias terms, which allows a</p><formula xml:id="formula_27">(t+1) i = 0 at the origin a 1 = • • • = a i = • • • = a I = 0.</formula><p>In order to ensure that DFCM has the same feature, we did not include bias terms in DFCM, which implies that f j (a) = 0 at the origin a 1 = • • • = a I = 0. In addition, it is easy to note that the term a</p><formula xml:id="formula_28">(t) i + j =i w ji a (t) j is in the range of (−∞, ∞).</formula><p>Therefore, in order to ensure f j (a) ∈ (−∞, ∞), we did not apply the ReLU activation to the output layer, whose output would be in the range of [0, ∞). Given the above treatments, it is obvious that when u i (t) = 0 and f i (a (t) ) = I i=1 w ji a (t) j with w jj = 1, the expression of DFCM in Eq. ( <ref type="formula" target="#formula_18">6</ref>) degenerates to the form of the basic FCM in Eq. ( <ref type="formula" target="#formula_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Modelling Exogenous Factors</head><p>The exogenous factors in the deep FCM refer to those exogenous factors that have influence to the system state a but can not be predefined and directly measured. Let us take for example the Deep FCM for a road transportation system (more details can be found in the experimental section). In this case, the road segments can be modeled as concepts and whether the segment congest can be modeled as activation states. The traffic speeds of near road segments can influence each other, which form relationships among concepts and can be modeled by f -functions. However, the traffic speeds are also influenced by some exogenous factors, such as the commuting patterns of residents, traffic controls, important events and so on. Because the states of these exogenous factors cannot be directly measured, we cannot use the predefined FCM concepts to describe them. How to handle these factors is an age-old challenge for system modelling and attribution analysis studies <ref type="bibr" target="#b37">[38]</ref>. In the literature of FCM, influences of exogenous factors are often modeled as static constant inputs <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. Our DFCM model is designed for time series prediction tasks, so we pay special attention to time-related factors and introduce a LSTM-based u-function to capture the exogenous factors with time dependence.</p><p>In the deep FCM framework defined in Eq. ( <ref type="formula" target="#formula_18">6</ref>), the influence of exogenous factors to a j are indirectly measured by a ufunction as</p><formula xml:id="formula_29">uj(t) = ϕ −1 a (t+1) j − fj a (t) ,<label>(10)</label></formula><p>i.e., the component of a j that cannot be modeled by the system internal relationships through the f -function. The deep FCM adopts a Recurrent Neural Network (RNN) to implement the u-function as We design the u-function in the form of Eq. ( <ref type="formula" target="#formula_30">11</ref>) based on three considerations: i) u j (t) is a function of time stamp t since the influence of exogenous factors usually change with time. ii) In many scenarios, exogenous factors exhibit periodicity, such as one day, one week, one month and the like, so the time stamp t modulo a period length τ is also adopted as an input. iii) Moreover, the dynamics of exogenous factors usually have "memory", i.e., depend on their historical states. Therefore, we use Recurrent Neural Networks (RNN) to implement the u-function where the historical state u j (t−1) is adopted as an input. In practice, the version of RNN in DFCM is Long Short-Term Memory (LSTM) <ref type="bibr" target="#b40">[41]</ref>. The calculation of u j (t) starts from t = 2, where the input u j (t − 1) is set as (1) ).</p><formula xml:id="formula_30">uj(t) = RNN (t, mod(t, τ ), uj(t − 1)) ,<label>(11)</label></formula><formula xml:id="formula_31">u j (1) = ϕ −1 (a (2) j ) − f j (a</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Measuring Concept Relationships</head><p>The biggest advantage of FCM lies in its ability in uncovering concept relationships in a complex system. This advantage is also called as interpretability of FCM. The basic FCM uses w ij to measure the strength of relationships between concepts. The value of w ij has the following interpretations:</p><p>• w ij = 0 means concept c i has no influence at all to concept c j ; • w ij = (0, 1] means c i has a positive influence to c j ;</p><p>• w ij = [−1, 0) means c i has a negative influence to c j . From a computational perspective, the basic FCM also regards w ij as "the level of a j 's increase when a i increases". Analogously, we proposed a partial derivative-based method to measure the relationship of a i to a j in DFCM as:</p><formula xml:id="formula_32">rij(a) = lim ∆a i →0 fj(ai, a¬i) − fj(ai + ∆ai, a¬i) ai − (ai + ∆ai) = ∂fj(a) ∂ai ,<label>(12)</label></formula><p>where a ¬i denotes all the elements of a except a i . The function r ij (a) expresses the degree of f j 's increasing when a i increases ∆a i , given the system state a as a condition. To understand the necessity of introducing the condition, we can think about how human's body weight influences his health with a given age -ideal body weights are different for different ages. Note that the function r ij (a k ) here is also a function of the activation states of unconcerned concepts: a ¬k . To remove the impact of the unconcerned concepts, we calculate the expectation of r ij (a k ) for all possible values of a ¬k as rij (a k ) =</p><formula xml:id="formula_33">Da ¬k P (a ¬k )r ij (a k , a ¬k ) d σ ,<label>(13)</label></formula><p>where P (a ¬k ) is the probability density function of a ¬k , and Da ¬k • d σ is an integral over all possible value of a ¬k . Furthermore, the overall influence of a i to a j is calculated as the expectation of r ij for all possible values of a, i.e.,</p><formula xml:id="formula_34">r(O) ij = Da P (a)rij(a) dσ. (<label>14</label></formula><formula xml:id="formula_35">)</formula><p>In practices, P (a) and P (a ¬k ) are unknown. A practicable method is to use frequency to approximate probability. For a k in a small interval [α, β], we assume there are M samples falling in this range. According to the Large Number Law, the rij for a k ∈ [α, β] can be calculated approximately as</p><formula xml:id="formula_36">rij(ak) = 1 M a k ∈[α,β] rij (a k , a ¬k ) .<label>(15)</label></formula><p>The overall influence r(O) ij can then be approximated as</p><formula xml:id="formula_37">r(O) ij = 1 M M m=1 rij a (m) ,<label>(16)</label></formula><p>where a (m) is the system state of the m-th sample.</p><p>The FCM framework requires the values of relationships to be in the range of [−1, 1], so we use the hyperbolic tangent function to resize rij as</p><formula xml:id="formula_38">w (C) ij (a k ) = Tanh (rij(a k )) , w (O) ij = Tanh r(O) ij ,<label>(17)</label></formula><p>where Tanh(•) is in the form of</p><formula xml:id="formula_39">Tanh(z) = e z − e −z e z + e −z .<label>(18)</label></formula><p>The function w</p><formula xml:id="formula_40">(C) ij (a k ) is called the Conditional Relationship Strength of w ij w.r.t. a k ,</formula><p>which is used to express how the relationship of c i to c j changes with the system state a k . The variable w</p><formula xml:id="formula_41">(O) ij is called the Overall Relationship Strength of c i to c j , which is used to express the overall relationship strength of c i to c j .</formula><p>The problem remains unsolved is to calculate the partial derivative ∂f j (a)/∂a i in Eq. ( <ref type="formula" target="#formula_32">12</ref>) given a deep structure. According to the chain rule, the partial derivative of f j to the input y (m,k) in the layer k can be recursively expressed as</p><formula xml:id="formula_42">∂fj ∂y (m,k) = n ∂fj ∂y (n,k+1) ∂y (n,k+1) ∂y (m,k) . (<label>19</label></formula><formula xml:id="formula_43">)</formula><p>Based on the definition in Eq. ( <ref type="formula" target="#formula_21">7</ref>), the partial derivative ∂y (n,k+1) /∂y (m,k) is calculated as</p><formula xml:id="formula_44">∂y (n,k+1) ∂y (m,k) = v (mn,k+1) ϕ   M k+1 m=1 v (mn,k+1) y (m,k)   , (<label>20</label></formula><formula xml:id="formula_45">)</formula><p>where ϕ is the derivative of the ReLU activation function.</p><p>Note that in the input layer, a i = y (i,0) . In this way, r ij can be recursively calculated for any given system state a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PARAMETERS INFERENCE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Objective Function</head><p>Letting z</p><formula xml:id="formula_46">(t) j = (x<label>(t)</label></formula><p>j − µ j )/σ j , i.e., the Z-score of x (t) j , our Deep FCM defined in Eq. ( <ref type="formula" target="#formula_18">6</ref>) can be rewritten as</p><formula xml:id="formula_47">ẑ(t) j = fj(a (t) |θ f ) + uj(t|θu),<label>(21)</label></formula><p>where ẑ(t) </p><p>where σ 2 e is the variance. Given a training data set Z j = {z (1) j , . . . , z (t) j , . . . , z (T ) j }, the likelihood of Z j for given the DFCM parameters θ f , θ u is expressed as</p><formula xml:id="formula_49">P (Zj|θ f , θu) = T t=1 N (ẑ (t) j , σ 2 e ) = T t=1 1 σe √ 2π exp − (z (t) j − ẑ(t) j ) 2 2σ 2 e . (<label>23</label></formula><formula xml:id="formula_50">)</formula><p>The negative log likelihood of Z j can be formulated as</p><formula xml:id="formula_51">− ln P (Zj|θ f , θu, σ 2 e ) ∝ T t=1 z (t) j − ẑ(t) j 2 . (<label>24</label></formula><formula xml:id="formula_52">)</formula><p>We uses a the Maximum Likelihood Estimation (MLE) method to infer the parameters θ f and θ u , which is equal to minimize the loss function defined as</p><formula xml:id="formula_53">L(θ f , θu) = 1 2 T t=1 fj(a (t) |θ f ) + uj(t|θu) − z (t) j 2 .<label>(25)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Principle of AFGD Algorithm</head><p>The biggest difference between DFCM and the basic FCM lies in that the DFCM contains many deep neural network components, such as f -function and u-function. However, the traditional FCM training algorithms, including the Hebbianlike methods and the evolutionary optimizations, cannot be directly used to train deep neural networks, which motivates us to find a new training method, named Alternate Function Gradient Descent (AFGD), to optimize the objective in Eq. <ref type="bibr" target="#b24">(25)</ref>. Since the Back-Propagation (BP) algorithm <ref type="bibr" target="#b5">[6]</ref> is an effective algorithm for deep neural network training, we designed the AFGD algorithm based on BP to train the DFCM model.</p><p>AFGD learns the parameters θ f and θ u via an iterative approach. Specifically, at the q-th round of iteration, AFGD updates θ f and θ u such that the following equations hold:</p><formula xml:id="formula_54">f (t) j θ (q) f = f (t) j θ (q−1) f − η f • ∂L(fj) ∂fj f j =f (t) j θ (q−1) f , u (t) j θ (q) u = u (t) j θ (q−1) u − ηu • ∂L(uj) ∂uj f j =f (t) j θ (q−1) u ,<label>(26)</label></formula><p>where we denote f</p><formula xml:id="formula_55">(t) j (θ (q) f ) as f j (a (t) |θ (q) f ) and u (t) j (θ (q) u ) as u j (t|θ (q) u ) for short, θ<label>(q)</label></formula><p>f and θ (q) u are the parameters learnt in the q-th iteration, and η f , η u are two updating parameters representing the learning rates. Eq. ( <ref type="formula" target="#formula_54">26</ref>) ensures that the parameters updating direction is along the negative gradient direction of the loss function to the functions f j and u j , so we name our algorithm as Alternate Function Gradient Descent.</p><p>According to the derivations in Appendix A, Eq. ( <ref type="formula" target="#formula_54">26</ref>) is equal to following parameter iteration functions:</p><formula xml:id="formula_56">fj(a (t) |θ (q) f ) = z (t) j − uj(t|θ (q−1) u ),<label>(27)</label></formula><formula xml:id="formula_57">uj(t|θ (q) u ) = z (t) j − fj(a (t) |θ (q) f ). (<label>28</label></formula><formula xml:id="formula_58">)</formula><p>Algorithm 1 The AFGD algorithm.  for all (x (t) , y (t) ) ∈ D do 4:</p><formula xml:id="formula_59">θ f ← BP fj(θ f ), {(a (t) , y (t) j )} T t=1 6: y (t) j ← z (t) j − fj(a (t) |θ f ) for t ∈ [1, T ] 7: θu ← BP uj(θu), {(t, y (t) j )} T</formula><formula xml:id="formula_60">Loss(θ) = y (t) − g(x (t) , θ) 2 5: θ ← θ − λ ∂Loss(θ) ∂θ 6:</formula><p>end for 7: until convergence 8: return θ Eqs. ( <ref type="formula" target="#formula_56">27</ref>) and ( <ref type="formula" target="#formula_57">28</ref>) could be intuitively understood as that the u-function and f -function alternately use the other's prediction residuals to train their parameters, that is why we call our algorithm as Alternate Function Gradient Descent. The prediction residuals of the f -function are the influences that cannot be modeled by the internal FCM concepts, i.e., the influences of exogenous-factors, and therefore should be absorbed by the ufunction. In contrast, the prediction residuals of the u-function correspond to removing the influences of exogenous factors from z j , which should be modeled by the f -function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation of AFGD Algorithm</head><p>Alg. 1 and Alg. 2 give the pseudo-codes about the training algorithm. Alg. 1 establishes a framework of the AFGD algorithm. The main body of the algorithm is an iteration loop, i.e., line 4 to line 9. In each loop, we alternately use the Back-propagation (BP) algorithm <ref type="bibr" target="#b41">[42]</ref> to train the neural network functions f j (θ f ) and u j (θ u ) with the training set {(a (t) , y</p><formula xml:id="formula_61">(t) j )} T t=1 and {(t, y<label>(t)</label></formula><p>j )} T t=1 , respectively. For each training sample, a (t) and t are features and y (t) j is a label. In line 6, the label y</p><formula xml:id="formula_62">(t) j is set as y (t) j ← z (t) j − f j (a (t) |θ f ) for u j (θ u ) training, and in line 8, y (t) j is set as y (t) j ← z (t) j − u j (t|θ u ) for the training of f j (θ f ).</formula><p>Alg. 2 gives the pseudocodes of the BP algorithm <ref type="bibr" target="#b41">[42]</ref>. The main body of the BP algorithm is an iterative gradient descent loop, i.e., from line 2 to line 7. In each loop, the algorithm traverses all training samples (x (t) , y (t) ), and calculates a function Loss(θ) = y (t) − g(x (t) , θ)</p><p>2 using (x (t) , y (t) ).</p><p>Here, g(x (t) , θ) = f j (a (t) , θ f ) is for the f -function, and g(x (t) , θ) = u j (t, θ u ) is for the u-function. The algorithm uses the negative gradient −λ∂Loss(θ)/∂θ to update the neural network parameters θ, where λ is a preset learning rate. The negative gradients for the neural networks f j and u j can be calculated using the chain rule <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>In this section, we first compare multivariate time series prediction performance of DFCM with baselines over four datasets, and give some detail performance and interpretation analysis over two of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup 1) Datasets:</head><p>To estimate performance of the proposed deep FCM model, we adopted following four real-world multivariate time series datasets in our experiments:</p><p>• AQI (Air Quality Indexes): This dataset contains time series of meteorological and air quality indexes that were collected from February 2017 to February 2018 in Beijing, China 1 . We use four meteorological indexes and five air quality indexes at the time t as inputs to predict the air quality indexes (AQIs) at the time t + 1.</p><p>• Traffic: This dataset contains traffic speeds that were collected from 1st to 30th April in 2016 of six road segments in Beijing 2 We use the traffic speeds of all segments at t as inputs to predict the speed of each road segment at t + 1.</p><p>• Power (Electric Power Consumption): This dataset contains measurements of electric power consumption in one household 3 . Different electrical quantities and some submetering values are available. The date used in our experiment were collected from 16th to 31st in December 2016. We use four electrical quantities and three sub-metering values as inputs to prediction the three sub-metering value at the next period.</p><p>• Temperatures: This dataset contains 24 features that are collected from a monitor system mounted in a domestic house 4 . The date used in our experiment were collected from 3rd March to 11th April in 2012. We use all features at time t to predict the indoor temperature of dinning-room and room at time t + 1.</p><p>Table <ref type="table" target="#tab_7">II</ref> summaries the statistics of the datasets. All of the datasets are publicly available.</p><p>1 https://www.kdd.org/kdd2018/kdd-cup 2 https://github.com/BuaaPercy/Traffic-DataSet-of-Beijing-Road 3 http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+ power+consumption 4 https://archive.ics.uci.edu/ml/datasets/SML2010</p><p>2) Baselines: We consider the following methods as baselines to compare:</p><p>• FCM [43]: This baseline treats multivariate time series as a multip-concept sytem and uses a basic FCM whose weights are trained by a Real-Coded Genetic Algorithm (RCGA) to predict concept states of the system.</p><p>• ANN <ref type="bibr" target="#b43">[44]</ref>: This baseline uses artificial neural networks (ANN) to predict multivariate time series. The ANN model used in our operations contains three hidden layers, and each hidden layer consists of 50 hidden neurons.</p><p>• VAR <ref type="bibr" target="#b44">[45]</ref>: This baseline uses the vector auto regression (VAR) to predict multivariate time series.</p><p>• LSTM <ref type="bibr" target="#b45">[46]</ref>: This baseline uses the Long Short-Term Memory (LSTM) network to predict multivariate time series. The LSTM is a type of neural network specially designed for sequential data. This baseline treats the features and labels of the datasets as inputs and outputs of the LSTM model, respectively. The LSTM network used in our experiment contains one hidden layer that consists of 50 LSTM neurons.</p><p>• ARIMA <ref type="bibr" target="#b46">[47]</ref>: We adopt the Auto Regressive Integrated Moving Average (ARIMA) model as a representative of univariate time series forecasting models. In the ARIMA experiments, we treat a multivariate time series as multiple univariate time series and use ARIMA models to predict their feature states, respectively.</p><p>• LSTM-U: This baseline uses LSTM as a univariate model to predict each series of a multivariate time series. This baseline is also a representative of univariate time series forecasting model. The LSTM network used in our experiment contains one hidden layer that consists of 50 LSTM neurons.</p><p>• W-HFCM <ref type="bibr" target="#b14">[15]</ref>: The Wavelet-High-order FCM (W-HFCM) model is specially designed for univariate time series forecasting. It uses the redundant Haar wavelet transform to decompose original univariate time series as a multivariate time series and learns the parameters of HFCM by a method based on ridge regression. This baseline is a representative of the state-of-the-art univariate time series forecasting model based on the FCM framework.</p><p>• Naive Method: The naive method directly uses y t−n as the predication of y t . This is the simplest method in time series prediction. It is worth to note that the performance of the naive method is even acceptable for many scenarios.</p><p>• Exponential Smoothing: The exponential smoothing method calculates s t = αy t + (1 − α)s t−1 and uses s t as a prediction of y t+1 , where α is the smoothing factor, and 0 &lt; α &lt; 1.</p><p>The hyper-parameters setting of the baselines are given in the Supplementary Materials.</p><p>3) Evaluation Metrics: We use two metrics to evaluate the model performance, including Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), which are defined as follows:  where x (t) is the actual value of the state of a concept at time t, x(t) is the predicted value, and T is the length of time series. The two metrics are the smaller, the better.</p><formula xml:id="formula_63">RMSE = 1 T T t=1 (x (t) − x (t) ) 2 , MAE = 1 T T t=1 x(t) − x (t) ,<label>(29)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results and Analysis</head><p>We present the results of all the comparison methods in Table <ref type="table" target="#tab_9">III</ref> and Table <ref type="table" target="#tab_10">IV</ref> with the summarized information listed in the bottom three lines. Note that the best performance for each dataset is emphasized in bold.</p><p>From the experiment results, we have three observations:</p><p>• The first is the nonlinear models have superior performance over the linear models. As shown in the tables, the methods with top three performance are DFCM, LSTM and LSTM-U. All of the three are deep neural-network-based forecasting models. Although Wavelet-HFCM adopts wavelet transform to extract frequency information from time series, its linear basic FCM framework can not fully exploit the information and therefore limits its performance.</p><p>• The second observation is long-term dependencies is helpful for time series forecasting. As shown in the tables, although the ANN model has nonlinear modeling abilities, its performance is still worse than Wavelet-HFCM. The reason might be that Wavelet-HFCM adopts historical data in a slice window as inputs to exploit long-term dependencies in time series, but the ANN model can only exploit dependencies between adjacent periods. The LSTM-based baselines can exploit long-term dependencies using memory gates <ref type="bibr" target="#b45">[46]</ref>, so their performance is better than ANN too. The basic FCM can neither exploit long-term dependencies nor model nonlinear relationships, which leads its performance worse than all methods.</p><p>• The third observation is the performance of multivariate models are better than univariate models. Here, the performance of LSTM is better than LSTM-U, and the performance of VAR is better than ARIMA. The multivariate models treat multiple time series as a whole to exploit dependencies among them, so they have superior performance over univariate models that can only exploit dependencies inner a series.</p><p>In the DFCM model, neural network components enable it to model nonlinear relationships, the u-function adopts a LSTM network to exploit long-term dependencies, and the model can also exploit dependencies among different series. Therefore, as shown in the experiments, DFCM achieves the best performance in terms of both the largest number of wins (the best in 15 out of 16 prediction targets) and the smallest average performance ranks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effectiveness of Components</head><p>In this section, we perform detailed experiments to demonstrate the effectiveness of each component of the DFCM model. Due to space limit, we only report the results on the traffic and AQI datasets. The rest results show the similar findings, and are omitted here.</p><p>1) Baselines: In the experiments, we compare the prediction performances of five models:</p><p>• DFCM-1L: DFCM that contains one hidden layer in the f -function and one hidden layer in the u-function. • DFCM-3L: DFCM that contains three hidden layers in the f -function and one hidden layer in the u-function. • f i -1L: DFCM that contains one hidden layer in the ffunction and no u-function. • f i -3L: DFCM that contains three hidden layers in the ffunction and no u-function.</p><p>• FCM: The basic FCM as a benchmark. The comparison between DFCM-1L and DFCM-3L models is to demonstrate the necessity of the deep neural network structure in the f -function. And, the comparison between DFCM-*L and f i -*L are used to demonstrate the effectiveness of the u-function. Note that in the DFCM models, all hidden layers in both f and u consists of 40 neurons. 2) Prediction of Road Traffic System: The traffic dataset contains traffic speed data of six road segments of the Xueyuan Road in Beijing. Figure <ref type="figure" target="#fig_4">3</ref> illustrates the topological structure of the segments. In the experiments, the time line is divided evenly into slices, with ten minutes per slice. The period length τ is set to one day, i.e., the natural rhythm of urban commuting. The results of DFCM and its variants are given in Table <ref type="table" target="#tab_10">V</ref> and Table <ref type="table" target="#tab_10">VI</ref>. From the results we have the following observations:</p><p>• First, all the variants of DFCM achieve much higher predictive accuracies than the basic FCM, which indeed performs very poorly. This implies that the basic FCM cannot well capture the complicated interactive relations between elements in a nonlinear real-world system. In contrast, by introducing non-linear neural networks into the f -function, DFCM works much better.</p><p>• Second, the performances of the DFCM models, i.e., DFCM-1L and DFCM-3L, are obviously superior to that of the f i benchmarks, i.e., f i -1L and f i -3L. This indicates that the exogenous factors introduced to DFCM by the u-function is indeed of great help to the prediction of system states.</p><p>• Third, DFCM and f i with three hidden layers in the ffunction perform slightly better than that with only one layer. This implies that a deep structure is generally better than a shallow one, although excessive layers might lead to higher computational complexity and higher risk of overfitting.</p><p>In   3) Prediction of AQIs: Next, we run a similar experiment over the AQI dataset. As listed in Table <ref type="table" target="#tab_10">VII</ref>, the dataset contains nine concepts, where the upper five are to describe air pollutants and the lower four to describe the meteorological factors. In the experiments, the period length τ of the uis also set as one day in the air pollution system. The prediction performance of DFCM and its variants are listed in Table VIII and IX, from which we have the following observations:</p><p>• First, the DFCM model with a three-layer f -function and a u-function (DFCM-3L) achieves the best prediction performance among all the competitors, which again verifies the superiority of DFCM in predictive applications.</p><p>• Second, the prediction performance of the models with three hidden layers (DFCM-3L and f i -3L) is better than that with only one hidden layer (DFCM-1L and f i -1L), which verifies the better predictive ability of deeper structures. Moreover, the performance of DFCM with u-functions (DFCM-1L and DFCM-3L) is better than that without u-functions (f i -1L and f i -3L), which again verifies the necessity of introducing exogenous factors for high-performance prediction. These results are consistent with that of the road traffic system.</p><p>• It is worth noting that the performance gap between DFCM with and without u-function is not as big as that in the traffic system case. This might be due to that the interrelationships between air pollutants and meteorological factors are more determinant than that between road segments in the traffic system.</p><p>In summary, the experimental results of the air pollution system indicate that the superior predictive power of DFCM is robust across different application scenarios and model parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. INTERPRETATION EXPERIMENTS</head><p>In this section, we use the experiments over the AQI dataset to demonstrate the interpretation feature of DFCM. A similar   experiments over the traffic dataset could be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Interpretation of Relationships</head><p>The concept of interpretation in DFCM is inherited from the basic FCM, where the relationships between concepts are interpreted as connection weights w ij of FCM. Analogously, DFCM uses the Overall Relationship Strength w (O) ij defined in Eq. ( <ref type="formula" target="#formula_38">17</ref>) to interpret relationships among concepts. In this section, we use the AQI dataset as a show case to demonstrated how FCM and DFCM interpret the influences of meteorological factors to air pollution using w ij and w</p><formula xml:id="formula_64">(O) ij .</formula><p>In the experiments, we use the AQI dataset to train FCM and DFCM models, respectively. The experiment setups are same as basic FCM and DFCM-3L in the section V-C3. After the model are well trained, we calculate w (O) ij of DFCM according to Eq. ( <ref type="formula" target="#formula_34">14</ref>) and extract w ij from the basic FCM model. The w (O) ij and w ij are used to express (interpret) the influences from the concept i to the concept j.  <ref type="figure" target="#fig_5">4</ref> plots the correlation of the values in the two tables. We can see that the values in the two tables are highly correlated. Indeed, the correlation between the two tables is 0.72, indicating the knowledge revealed by FCM and DFCM from the AQI dataset is very similar. Further, we can see for most of the conditions, the meteorological factors have negative impacts to the pollutants. This could be interpreted by some basic meteorological knowledge as follows:</p><p>• High air pressure in an area causes air flowing to surrounding areas and thus takes pollutants away. So air pressure has negative influence to air pollution. • High humidity usually corresponds to precipitation weather, such as rain and snow, which can wash away pollutants in air. So humidity also has negative influence to air pollution. • Wind can blow air pollutants away, so it is negative w.r.t.</p><p>air pollution. • The relationships between temperature and air pollutants are relatively indirect. In the northern cities of China, like Beijing, people burn fossil fuels in winter for heating, which therefore increases air pollutants in low temperature days. Indeed as reported in <ref type="bibr" target="#b47">[48]</ref>, heavy pollution days usually appear in winter. not all relationships between the meteorological factors and pollutants follow the above rules. We can see that O3 has several special characteristics in the tables. In order to further study the influences of the meteorological factors to O3, we plots the conditional relationship strength, i.e., w As shown in Fig. <ref type="figure" target="#fig_6">5</ref>(b) and 5(c), both air pressure and humidity have negative influence to O3 for different values of a k , which is consistent with that for other pollutants. Fig. <ref type="figure" target="#fig_6">5(a</ref>) however shows that the temperature has positive influence to O3, which could be due to the fact that high temperatures can facilitate the production of O3 <ref type="bibr" target="#b48">[49]</ref>. The relationship between wind speed and O3 is more complicated. When the wind speed is not very high, the airflow of wind can blow O3 pollutants away and then reduces the concentration of O3. When the wind speed is high, it can reduce the stability of the boundary layer of atmosphere, and the intrusion of O3 from the upper layer to the surface layer can thus increase the O3 concentration of the surface <ref type="bibr" target="#b48">[49]</ref>. Therefore, as shown in Fig. <ref type="figure" target="#fig_6">5</ref>(d), when the value of a k is very low, the influence w (C) ij of wind speed to O3 is in negative, but when the value of a k becomes higher, w (C) ij turns into positive values. More extremely, when the wind speed is too high, the high dispersion of wind could offset the O3 contributions from the upper layer. Therefore, the influence w (C) ij reduces to a value near to zero when a k is very high. It is interesting that the results about the relationships between wind speed and O3 agree with the conclusion of related meteorology studies <ref type="bibr" target="#b48">[49]</ref>.</p><p>Comparing the results in Table X and Fig. <ref type="figure" target="#fig_6">5</ref>, we can see the relationships modeled by DFCM contain more detail information, then could be used in nonlinear system analysis. Oppositely, the basic FCM model can only express linear relationships, and is not very suitable to complex system analysis. For simple concept relationships, a more comprehensible way to express the influences is using the bar map. Figure <ref type="figure">6</ref> shows the influences of temperature to AQIs. The temperature has significant negative influences to PM2.5, NO2, CO, and SO3, while has positive to O3. 1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems of u i (t) in the first ten days. As can be seen, there is an obvious rhythm in u i (t) that repeats every day. Fig. <ref type="figure">7</ref>(b) plots the fluctuations of u i (t) in one year. As shown in the figure, although we do not adopt any seasonal information other than τ in the u-function, there exists long-term seasonal periodicity that waves from spring to winter for each concept. Accordingly, we might expect that the short-term periodicity in u i (t) corresponds to the influence of human activities to air pollution since life rhythms of human are mostly with daily frequency. The long-term periodicity might correspond to the impact of season changes to air pollution. In the Deep FCM model, the influences of different exogenous factors are all integrated into a same u-function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Interpretation of Exogenous Factors</head><p>The results in the performance and interpretation experiments demonstrate that the proposed DFCM model not only have high predictive ability for multivariate time series forecast tasks but also can offer meaningful explanations for the prediction results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION AND FUTURE WORKS</head><p>In this paper, we proposed a deep neural network-based fuzzy cognitive maps model, named Deep FCM, to gain interpretable multivariate prediction. The Deep FCM model introduces deep neural network models into the knowledge representation framework of FCM so that the advantage of FCM in interpretation and the advantage of deep neural networks in prediction can be integrated into a same model. The excellent performances of Deep FCM in terms of both interpretability and predictive ability were verified over two real-world open systems. Deep FCM indeed provided an important clue to building interpretable predictors for real-life applications.</p><p>How to handle exogenous factors is an age-old challenge for system modelling and attribution analysis studies <ref type="bibr" target="#b37">[38]</ref>. Our DFCM model is designed for time series prediction tasks, so we pay special attention to time-related factors and introduce a LSTM-based u-function to capture the exogenous factors with time dependence. Nevertheless, DFCM is still an open framework that calls for new approaches for modelling other types of exogenous factors. Studying new exogenous factors modeling approaches is our next step work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>c 1 c 2 c 3 c 4 c 5 Fig. 1 .</head><label>51</label><figDesc>Fig. 1. An illustration of fuzzy cognitive maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The framework of Deep FCM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>= 1</head><label>1</label><figDesc>indicating the active state, and when a (t) j = 0 indicating the inactive state.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>j 1 :</head><label>1</label><figDesc>− uj(t|θu) for t ∈ [1, T ] 9: until convergence 10: return θ f ,θu Algorithm 2 The BP algorithm. Input: BP g(θ), {(x (t) , y (t) )} T t=1 , where g(θ) is a neural network, and D = {(x (t) , y (t) )} T t=1 is a training dataset. 2: repeat 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A map of the road traffic system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The correlation of the relationships modeled by FCM DFCM from the AQI dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Influence of meteorological factors to air pollution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>ij (a k ) defined in Eq.<ref type="bibr" target="#b16">(17)</ref>, for different meteorological factors to O3 in Fig.5. The horizontal axis a k denotes value of meteorological factors. The vertical axis denotes influences w (C) ij of the meteorological factors with corresponding meteorological factor values as conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig.6. Expressing the influence of temperature to AQIs using a bar map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>DFCM uses the u-function to model exogenous factors of a system. Therefore, we can use the value of u-function to interpret influences of exogenous factors to system concepts. Fig.7depicts the periodicity of u i (t) for different meteorological factors and pollutants. In Fig.7(a), we plot the fluctuations Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1, 1]. Moreover, each concept in FCM has a fuzzy activation state a i ∈ [0, 1]. a i = 1 means c i is completely activated and a i = 0 means completely unactivated. The activation states for c i is a dynamic time series {a</figDesc><table><row><cell>(1)</cell></row></table><note>i , . . . , a (t) i , . . . a (T ) i }, where a (t) i is the state at the time t. The state a (t+1) i in FCM is influenced by the states of other concepts at the time t as a</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I MATH</head><label>I</label><figDesc>NOTATIONS.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>which indicates the state of active to a certain degree. In this way, the original time series values of concepts are represented by the fuzzy values of activation levels in [0,1].</figDesc><table><row><cell cols="4">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE</cell></row><row><cell></cell><cell cols="2">Transactions on Fuzzy Systems</cell></row><row><cell>indicating the active state, and when z j (t)</cell><cell>= −∞, a (t) j</cell><cell>= 0</cell></row><row><cell cols="3">indicating the inactive state. When z j ∈ (−∞, +∞), a (t) (t) j ∈</cell></row><row><cell>(0, 1),</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>t) j</cell><cell>= 1</cell></row></table><note>Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply.1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems which has three inputs: the time stamp t, the time stamp t modulo a period length τ , and the history state u j (t − 1). mod(a, b) is a function to calculate a modulo b.</figDesc><table /><note>Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply.1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems be a random error. We assume e j = ẑ(t)</figDesc><table><row><cell>(t) j is a zero mean</cell></row><row><cell>Gaussian noise as</cell></row><row><cell>ej ∼ N (0, σ 2 e ), ∀j,</cell></row></table><note>j denotes the predicted value of z (t) j , and θ f , θ u denote the parameters of f j and u j , respectively. Because ẑ(t) j contains the influence of all concepts and exogenous factors, the residual between ẑ(t) j and z (t) j should Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply. 1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. j − z</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE II STATISTICS</head><label>II</label><figDesc>OF THE FOUR DATASETS.</figDesc><table><row><cell>Statistics</cell><cell>AQI</cell><cell>Traffic</cell><cell>EPC.</cell><cell>Temp.</cell></row><row><cell># of features</cell><cell>9</cell><cell>6</cell><cell>7</cell><cell>24</cell></row><row><cell># of labels</cell><cell>5</cell><cell>6</cell><cell>3</cell><cell>2</cell></row><row><cell># of records</cell><cell>8,783</cell><cell>3,602</cell><cell>21,899</cell><cell>2,763</cell></row><row><cell>Period</cell><cell>1 hour</cell><cell>10 min</cell><cell>1 min</cell><cell>15 min</cell></row><row><cell>Range</cell><cell cols="4">1 year 1 month 15 days 1 month</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems</figDesc><table /><note>Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply.1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE III COMPARISON</head><label>III</label><figDesc>WITH OTHER PREDICTION MODELS IN TERMS OF RMSE.</figDesc><table><row><cell>DataSet</cell><cell>Target Features</cell><cell>DFCM</cell><cell>FCM</cell><cell>ANN</cell><cell>VAR</cell><cell>LSTM</cell><cell>LSTM-U</cell><cell>ARIMA</cell><cell>W-HFCM</cell><cell>Naive</cell><cell>ES</cell></row><row><cell></cell><cell>R1</cell><cell>3.188</cell><cell>7.958</cell><cell>3.736</cell><cell>4.152</cell><cell>3.401</cell><cell>3.402</cell><cell>4.081</cell><cell>3.320</cell><cell>4.188</cell><cell>14.66</cell></row><row><cell></cell><cell>R2</cell><cell>4.784</cell><cell>10.64</cell><cell>5.109</cell><cell>6.000</cell><cell>4.820</cell><cell>5.335</cell><cell>6.458</cell><cell>5.206</cell><cell>6.561</cell><cell>19.87</cell></row><row><cell>Traffic</cell><cell>R3 R4</cell><cell>4.359 4.718</cell><cell>7.603 10.87</cell><cell>4.902 5.360</cell><cell>4.981 7.060</cell><cell>4.388 4.986</cell><cell>4.642 5.317</cell><cell>5.120 7.342</cell><cell>4.309 4.911</cell><cell>5.387 7.346</cell><cell>13.09 23.52</cell></row><row><cell></cell><cell>R5</cell><cell>4.982</cell><cell>11.25</cell><cell>5.147</cell><cell>7.073</cell><cell>5.270</cell><cell>5.609</cell><cell>7.204</cell><cell>5.101</cell><cell>7.202</cell><cell>22.65</cell></row><row><cell></cell><cell>R6</cell><cell>5.354</cell><cell>11.25</cell><cell>5.961</cell><cell>7.945</cell><cell>5.776</cell><cell>6.219</cell><cell></cell><cell>5.582</cell><cell>8.354</cell><cell>25.38</cell></row><row><cell></cell><cell>PM2.5</cell><cell>12.73</cell><cell>29.25</cell><cell>23.38</cell><cell>18.99</cell><cell>12.84</cell><cell>14.17</cell><cell>24.11</cell><cell>14.72</cell><cell>27.06</cell><cell>70.55</cell></row><row><cell></cell><cell>NO2</cell><cell>9.622</cell><cell>16.01</cell><cell>12.06</cell><cell>14.85</cell><cell>9.657</cell><cell>9.716</cell><cell>19.35</cell><cell>9.900</cell><cell>22.24</cell><cell>42.66</cell></row><row><cell>AQIs</cell><cell>CO</cell><cell>0.264</cell><cell>0.728</cell><cell>0.719</cell><cell>0.346</cell><cell>0.269</cell><cell>0.270</cell><cell>0.440</cell><cell>0.617</cell><cell>0.487</cell><cell>1.012</cell></row><row><cell></cell><cell>O3</cell><cell>8.504</cell><cell>15.30</cell><cell>13.02</cell><cell>14.47</cell><cell>8.713</cell><cell>9.995</cell><cell>16.93</cell><cell>20.86</cell><cell>20.72</cell><cell>40.11</cell></row><row><cell></cell><cell>SO2</cell><cell>2.732</cell><cell>6.044</cell><cell>4.513</cell><cell>3.638</cell><cell>2.860</cell><cell>3.041</cell><cell>4.161</cell><cell>4.035</cell><cell>4.778</cell><cell>7.433</cell></row><row><cell></cell><cell>Sub-metering 1</cell><cell>2.141</cell><cell>3.424</cell><cell>2.293</cell><cell>3.251</cell><cell>2.166</cell><cell>2.160</cell><cell>4.646</cell><cell>4.040</cell><cell>4.742</cell><cell>11.24</cell></row><row><cell>Power</cell><cell>Sub-metering 2</cell><cell>2.752</cell><cell>6.882</cell><cell>2.806</cell><cell>3.358</cell><cell>2.865</cell><cell>2.914</cell><cell>6.314</cell><cell>9.075</cell><cell>6.091</cell><cell>15.15</cell></row><row><cell></cell><cell>Sub-metering 3</cell><cell>1.069</cell><cell>1.596</cell><cell>1.134</cell><cell>1.635</cell><cell>1.182</cell><cell>1.128</cell><cell>2.462</cell><cell>1.307</cell><cell>2.731</cell><cell>11.02</cell></row><row><cell>Temperature</cell><cell>Dining Room Room</cell><cell>0.109 0.099</cell><cell>1.821 1.709</cell><cell>0.488 0.580</cell><cell>0.121 0.130</cell><cell>0.140 0.143</cell><cell>0.139 0.207</cell><cell>0.195 0.207</cell><cell>0.208 0.197</cell><cell>0.316 0.324</cell><cell>2.492 2.516</cell></row><row><cell cols="2">Winning times</cell><cell>15</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">AVG arithmetic ranking</cell><cell>1.063</cell><cell>8.250</cell><cell>5.000</cell><cell>5.125</cell><cell>2.813</cell><cell>3.625</cell><cell>6.750</cell><cell>4.563</cell><cell>7.750</cell><cell>10.00</cell></row><row><cell cols="2">AVG geometric ranking</cell><cell>1.044</cell><cell>8.151</cell><cell>4.642</cell><cell>4.843</cell><cell>2.720</cell><cell>3.482</cell><cell>6.665</cell><cell>3.861</cell><cell>7.695</cell><cell>10.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE IV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="7">COMPARISON WITH OTHER PREDICTION MODELS IN TERMS OF MAE.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DataSet</cell><cell>Target Features</cell><cell>DFCM</cell><cell>FCM</cell><cell>ANN</cell><cell>VAR</cell><cell>LSTM</cell><cell>LSTM-U</cell><cell>ARIMA</cell><cell>W-HFCM</cell><cell>Naive</cell><cell>ES</cell></row><row><cell></cell><cell>R1</cell><cell>2.467</cell><cell>6.931</cell><cell>2.894</cell><cell>3.137</cell><cell>2.580</cell><cell>2.668</cell><cell>3.130</cell><cell>2.561</cell><cell>3.146</cell><cell>11.81</cell></row><row><cell></cell><cell>R2</cell><cell>3.593</cell><cell>9.368</cell><cell>3.996</cell><cell>4.471</cell><cell>3.637</cell><cell>4.084</cell><cell>4.686</cell><cell>3.929</cell><cell>4.728</cell><cell>16.15</cell></row><row><cell>Traffic</cell><cell>R3 R4</cell><cell>3.171 3.114</cell><cell>6.364 9.782</cell><cell>3.698 3.679</cell><cell>3.616 4.469</cell><cell>3.305 3.351</cell><cell>3.535 3.747</cell><cell>3.792 4.587</cell><cell>3.228 3.347</cell><cell>4.012 4.588</cell><cell>10.19 17.73</cell></row><row><cell></cell><cell>R5</cell><cell>3.405</cell><cell>10.12</cell><cell>3.631</cell><cell>4.622</cell><cell>3.929</cell><cell>4.086</cell><cell>4.532</cell><cell>3.459</cell><cell>4.531</cell><cell>16.88</cell></row><row><cell></cell><cell>R6</cell><cell>3.245</cell><cell>10.10</cell><cell>3.771</cell><cell>4.465</cell><cell>3.664</cell><cell>3.995</cell><cell>4.349</cell><cell>3.487</cell><cell>4.364</cell><cell>17.72</cell></row><row><cell></cell><cell>PM2.5</cell><cell>7.579</cell><cell>22.03</cell><cell>16.26</cell><cell>10.92</cell><cell>8.646</cell><cell>10.07</cell><cell>13.52</cell><cell>9.950</cell><cell>15.48</cell><cell>51.75</cell></row><row><cell></cell><cell>NO2</cell><cell>7.047</cell><cell>13.09</cell><cell>9.533</cell><cell>10.23</cell><cell>6.715</cell><cell>6.797</cell><cell>13.11</cell><cell>7.001</cell><cell>15.68</cell><cell>32.72</cell></row><row><cell>AQIs</cell><cell>CO</cell><cell>0.161</cell><cell>0.551</cell><cell>0.601</cell><cell>0.224</cell><cell>0.172</cell><cell>0.174</cell><cell>0.313</cell><cell>0.360</cell><cell>0.311</cell><cell>0.768</cell></row><row><cell></cell><cell>O3</cell><cell>6.349</cell><cell>13.13</cell><cell>9.502</cell><cell>11.02</cell><cell>6.396</cell><cell>7.747</cell><cell>11.36</cell><cell>18.90</cell><cell>13.58</cell><cell>32.41</cell></row><row><cell></cell><cell>SO2</cell><cell>1.682</cell><cell>3.619</cell><cell>3.063</cell><cell>2.335</cell><cell>1.863</cell><cell>2.381</cell><cell>2.566</cell><cell>2.687</cell><cell>2.758</cell><cell>5.017</cell></row><row><cell></cell><cell>Sub-metering 1</cell><cell>0.407</cell><cell>1.625</cell><cell>0.733</cell><cell>0.550</cell><cell>0.567</cell><cell>0.500</cell><cell>0.958</cell><cell>0.663</cell><cell>0.692</cell><cell>4.274</cell></row><row><cell>Power</cell><cell>Sub-metering 2</cell><cell>0.823</cell><cell>2.516</cell><cell>0.915</cell><cell>0.848</cell><cell>0.885</cell><cell>1.198</cell><cell>1.477</cell><cell>2.857</cell><cell>1.393</cell><cell>6.902</cell></row><row><cell></cell><cell>Sub-metering 3</cell><cell>0.304</cell><cell>0.994</cell><cell>0.445</cell><cell>0.370</cell><cell>0.561</cell><cell>0.456</cell><cell>0.543</cell><cell>0.447</cell><cell>0.595</cell><cell>7.209</cell></row><row><cell>Temperature</cell><cell>Dining Room Room</cell><cell>0.085 0.076</cell><cell>1.560 1.515</cell><cell>0.381 0.435</cell><cell>0.097 0.098</cell><cell>0.100 0.102</cell><cell>0.108 0.156</cell><cell>0.114 0.123</cell><cell>0.186 0.169</cell><cell>0.241 0.243</cell><cell>2.111 2.131</cell></row><row><cell cols="2">Winning times</cell><cell>15</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">AVG arithmetic ranking</cell><cell>1.188</cell><cell>8.625</cell><cell>5.625</cell><cell>4.625</cell><cell>2.938</cell><cell>4.063</cell><cell>6.313</cell><cell>4.438</cell><cell>7.188</cell><cell>10.00</cell></row><row><cell cols="2">AVG geometric ranking</cell><cell>1.091</cell><cell>8.594</cell><cell>5.273</cell><cell>4.123</cell><cell>2.697</cell><cell>3.901</cell><cell>6.220</cell><cell>3.827</cell><cell>7.112</cell><cell>10.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE V TRAFFIC</head><label>V</label><figDesc>SPEED PREDICTION IN TERMS OF RMSE.</figDesc><table><row><cell></cell><cell cols="2">DFCM-1L</cell><cell>DFCM-3L</cell><cell>f i -1L</cell><cell>f i -3L</cell><cell>FCM</cell></row><row><cell>R1</cell><cell cols="2">3.249</cell><cell>3.188</cell><cell>6.044</cell><cell>5.034</cell><cell>7.958</cell></row><row><cell>R2</cell><cell cols="2">5.265</cell><cell>4.784</cell><cell>9.104</cell><cell>7.624</cell><cell>10.64</cell></row><row><cell>R3</cell><cell cols="2">4.485</cell><cell>4.359</cell><cell>6.958</cell><cell>5.958</cell><cell>7.603</cell></row><row><cell>R4</cell><cell cols="2">4.937</cell><cell>4.718</cell><cell>9.475</cell><cell>9.261</cell><cell>10.87</cell></row><row><cell>R5</cell><cell cols="2">5.188</cell><cell></cell><cell>9.132</cell><cell>8.674</cell><cell>11.25</cell></row><row><cell>R6</cell><cell cols="2">5.682</cell><cell>5.354</cell><cell>10.286</cell><cell>8.972</cell><cell>11.25</cell></row><row><cell>Overall</cell><cell cols="2">4.801</cell><cell>4.564</cell><cell>8.500</cell><cell>7.587</cell><cell>9.929</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TABLE VI</cell><cell></cell><cell></cell></row><row><cell cols="6">TRAFFIC SPEED PREDICTION IN TERMS OF MAE.</cell></row><row><cell></cell><cell cols="2">DFCM-1L</cell><cell>DFCM-3L</cell><cell>f i -1L</cell><cell>i -3L</cell><cell>FCM</cell></row><row><cell>R1</cell><cell cols="2">2.531</cell><cell>2.467</cell><cell>4.417</cell><cell>3.760</cell><cell>6.931</cell></row><row><cell>R2</cell><cell cols="2">4.062</cell><cell>3.593</cell><cell>6.863</cell><cell>5.742</cell><cell>9.368</cell></row><row><cell>R3</cell><cell cols="2">3.372</cell><cell></cell><cell>4.978</cell><cell>4.420</cell><cell>6.364</cell></row><row><cell>R4</cell><cell cols="2">3.332</cell><cell>3.114</cell><cell>6.415</cell><cell>6.214</cell><cell>9.782</cell></row><row><cell>R5</cell><cell cols="2">3.699</cell><cell>3.405</cell><cell>6.191</cell><cell>5.988</cell></row><row><cell>R6</cell><cell cols="2">3.526</cell><cell></cell><cell>6.365</cell><cell>5.501</cell><cell>10.10</cell></row><row><cell>Overall</cell><cell cols="2">3.420</cell><cell>3.166</cell><cell>5.872</cell><cell>5.271</cell><cell>8.777</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TABLE VII</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">CONCEPTS OF THE AIR SYSTEM.</cell></row><row><cell>Types</cell><cell></cell><cell cols="2">Concepts</cell><cell></cell><cell></cell></row><row><cell>AQIs</cell><cell></cell><cell cols="3">PM2.5, NO2, CO, O3, SO3</cell><cell></cell></row><row><cell cols="2">Meteorological</cell><cell cols="5">Temperature, Pressure, Humidity, Wind Speed</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>summary, the experiment results indicate that it is very effective to introduce deep neural networks into the FCM framework for improved prediction of nonlinear open systems. 1063-6706 (c) 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.3005293, IEEE Transactions on Fuzzy Systems IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. XXX, NO. XXX, XXX 2019 10</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE VIII AIR</head><label>VIII</label><figDesc>POLLUTION PREDICTION IN TERMS OF RMSE.</figDesc><table><row><cell></cell><cell>DFCM-1L</cell><cell>DFCM-3L</cell><cell>f i -1L</cell><cell>f i -3L</cell><cell>FCM</cell></row><row><cell>PM2.5</cell><cell>18.95</cell><cell>12.73</cell><cell>21.42</cell><cell>20.425</cell><cell>29.25</cell></row><row><cell>NO2</cell><cell>10.46</cell><cell>9.622</cell><cell>10.68</cell><cell>10.39</cell><cell>16.01</cell></row><row><cell>CO</cell><cell>0.315</cell><cell>0.264</cell><cell>0.335</cell><cell>0.319</cell><cell>0.728</cell></row><row><cell>O3</cell><cell>9.346</cell><cell>8.504</cell><cell>14.61</cell><cell>12.95</cell><cell>15.30</cell></row><row><cell>SO2</cell><cell>4.246</cell><cell>2.732</cell><cell>5.008</cell><cell>4.609</cell><cell>6.044</cell></row><row><cell>Overall</cell><cell>6.143</cell><cell>4.832</cell><cell>7.361</cell><cell>6.864</cell><cell>10.47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Table X and Table XI list the strengths of influences measured by w ij of FCM and by w</figDesc><table><row><cell>(O) ij of DFCM, respectively.</cell></row><row><cell>Figure</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. XXX, NO. XXX, XXX 2019</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1">Authorized licensed use limited to: City&amp;#44; University of London. Downloaded on July 13,2020 at 21:12:52 UTC from IEEE Xplore. Restrictions apply.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the National Key R&amp;D Program of China (2019YFB2102100). Dr. Jingyuan Wang's work was partially supported by the National Natural Science Foundation of China (Grant No.61572059), the Fundamental Research Funds for the Central Universities (YWF-20-BJ-J-839). Prof. Junjie Wu's work was partially supported by National Natural Science Foundation of China (71531001,71725002, U1636210). Prof. Zhen Peng's work was partially supported by National Science Foundation of China (No.71601022), the Youth Top Talent Cultivation Plan Project of Beijing (No.CIT&amp;TCD201804036).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A DERIVATIONS OF AFGD ALGORITHM</head><p>The objective function of the AFGD algorithm is</p><p>In the AFDG algorithm, we optimize the parameters θ f and θ u iteratively. Given a training sample {a (t) , z</p><p>j }, we denote f (t) j (θ f ) = f j (a (t) |θ f ) and u (t) j (θ u ) = u j (t|θ u ) for short. In the q-th round of iteration, the algorithm updates θ f and θ u to make following equations hold:</p><p>where θ (q)</p><p>f and θ</p><p>u are the parameters in the q-th iteration, and η f , η u are learning rates. Eq. <ref type="bibr" target="#b30">(31)</ref> ensures that the parameters updating direction is along the negative gradient direction of the loss function to the functions f j and u j , so we name our algorithm as Function Gradient Descent.</p><p>According to the definition of the loss function in Eq. ( <ref type="formula">30</ref>), for any training data z (t) j , the partial derivatives of L(f j , u j ) to j and u j are in the form of</p><p>Plugging Eq. (32) into Eq. ( <ref type="formula">31</ref>), we have</p><p>For the f -function, we plug Eq. ( <ref type="formula">33</ref>) into Eq. ( <ref type="formula">30</ref>), the loss function L in the q-th iteration is in the form of</p><p>For the learning rate η f , the function in Eq. ( <ref type="formula">35</ref>) is a convex function, so the optimum point of L can be achieved at ∂L/∂η f = 0, i.e., We cannot have z</p><p>) = 0 held for all samples for Term I, so the following equation need be satisfied:</p><p>which means η f = 1. By plugging η f = 1 into Eq. ( <ref type="formula">33</ref>), we have</p><p>For the u-function, we also have η u = 1 via the similar derivations as that in Eqs. ( <ref type="formula">33</ref>) - <ref type="bibr" target="#b36">(37)</ref>. By plugging η u = 1 into Eq. ( <ref type="formula">34</ref>), we have</p><p>Therefore, Eq. ( <ref type="formula">31</ref>) (i.e., Eq. ( <ref type="formula">26</ref>)) is equal to following parameter iteration functions:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of manmachine studies</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="75" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive maps for policy analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Perusich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1996 International Symposium on Technology and Society Technical Expertise and Public Decisions</title>
				<meeting>1996 International Symposium on Technology and Society Technical Expertise and Public Decisions</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="369" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using fuzzy cognitive time maps for modeling and evaluating trust dynamics in the virtual enterprises</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yanchun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1583" to="1592" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fuzzy cognitive map approach to differential diagnosis of specific language impairment</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Georgopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Malandraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Stylios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="278" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The cyprus puzzle and the greek-turkish arms race: Forecasting developments using genetically evolved fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Andreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Mateou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Zombanakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Defence and Peace Economics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="310" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamical cognitive network-an extension of fuzzy cognitive map</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="760" to="770" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive maps considering time relationships</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="168" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Creating an immersive game world with evolutionary fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="58" to="70" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modelling grey uncertainty with fuzzy grey cognitive maps</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Salmeron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7581" to="7588" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Intuitionistic fuzzy cognitive maps for medical decision making</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Iakovidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="107" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Research of rough cognitive map model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chunying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ruitao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Research on Electronic Commerce, Web Application, and Communication</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="224" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rule based fuzzy cognitive mapsexpressing time in qualitative system dynamics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A B</forename><surname>Tome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th IEEE International Conference on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="280" to="283" />
		</imprint>
	</monogr>
	<note>Fuzzy Systems</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Extended fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hagiwara</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="795" to="801" />
		</imprint>
	</monogr>
	<note>in Fuzzy Systems, 1992</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Time-series forecasting based on high-order fuzzy cognitive maps and wavelet transform</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3391" to="3402" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A two-stage model for time series prediction based on fuzzy cognitive maps and neural networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Poczeta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">232</biblScope>
			<biblScope unit="page" from="113" to="121" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Implementation of fuzzy cognitive maps based on fuzzy neural networks and application in numerical prediction of time series</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hengjie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chunyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Roel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catthoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Design of fuzzy cognitive maps using neural networks for predicting chaotic time series</title>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Roel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Francky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1264" to="1275" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Why triangular membership functions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy sets and Systems</title>
				<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive map learning based on nonlinear hebbian rule</title>
		<author>
			<persName><forename type="first">E</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stylios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groumpos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Joint Conference on Artificial Intelligence</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="256" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Active hebbian learning algorithm to train fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">E</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Stylios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Groumpos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of approximate reasoning</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="249" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning fuzzy cognitive maps using evolution strategies: a novel schema for modeling and simulating high-level behavior</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koulouriotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Diakoulakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Emiris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 Congress on</title>
				<meeting>the 2001 Congress on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="364" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A first study of fuzzy cognitive maps learning using particle swarm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Parsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Groumpos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Vrahatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
				<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="1440" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A review of fuzzy cognitive maps research during the last decade</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Salmeron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="79" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An extension to fuzzy cognitive maps for classification and prediction</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wuyts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hondt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Catthoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="135" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Software usability improvement: modeling, training and relativity analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 Second International Symposium on</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="472" to="475" />
		</imprint>
	</monogr>
	<note>Information Science and Engineering</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using belief degreedistributed fuzzy cognitive maps in nuclear safety culture assessment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hardeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mkrtchyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy Information Processing Society (NAFIPS), 2011 Annual Meeting of the North American</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transformation of cognitive maps</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A dynamic fuzzy-cognitive-map approach based on random neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Cognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="91" to="107" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributing emotional services in ambient intelligence through cognitive agents</title>
		<author>
			<persName><forename type="first">G</forename><surname>Acampora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Loia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vitiello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Service Oriented Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Numerical and linguistic prediction of time series with the use of fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">W</forename><surname>Stach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Kurgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling time series with fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">W</forename><surname>Homenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jastrzebska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Fuzzy Systems</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2055" to="2062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Design of fuzzy cognitive maps for modeling time series</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jastrzebska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Homenda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive maps employing arima components for time series forecasting</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vanhoenshoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nápoles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bielen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vanhoof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Decision Technologies</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-step prediction of pulmonary infection with the use of evolutionary fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Froelich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extended evolutionary learning of fuzzy cognitive maps for the prediction of multivariate time-series</title>
		<author>
			<persName><forename type="first">W</forename><surname>Froelich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy cognitive maps for applied sciences and engineering</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="121" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Approximation capabilities of multilayer feedforward networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="257" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The endogenous-exogenous partition in attribution theory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Kruglanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">387</biblScope>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fuzzy cognitive mapping as a tool to define management objectives for complex ecosystems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Ludsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Biberhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Ciborowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1548" to="1565" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Beyond dags: Modeling causal feedback with fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">O</forename><surname>Osoba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kosko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.11247</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive modeling</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Genetic learning of fuzzy cognitive maps</title>
		<author>
			<persName><forename type="first">W</forename><surname>Stach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kurgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reformat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="371" to="401" />
		</imprint>
	</monogr>
	<note>Fuzzy sets and systems</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Forecasting models for interval-valued time series</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L S</forename><surname>Maia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D A</forename><surname>De Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Ludermir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3344" to="3352" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Small-sample forecasting regression or arima models?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Abeysinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Balasooriya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Quantitative Economics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Time series analysis and its applications: with R examples</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Shumway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Stoffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Characteristics of heavy aerosol pollution during the 2012-2013 winter in beijing, china</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Environment</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="83" to="89" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">His current research interests include AI, data mining, and urban data analysis. Chao Li received his Ph.D degree from Beihang University. He is an associate professor at School of Computer Science and Engineering, Beihang University, China. His main research interests include the Smart City, data vitalization and multimedia applications. Wu is currently a full professor in Information Systems Department</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-G</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Xiaoda Wang received the B.E. degree in Beijing Institute of Technology, Beijing, China in 2017. Since then, he has been working toward the M.E. degree in School of Computer Science and Engineering</title>
				<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="310" to="337" />
		</imprint>
		<respStmt>
			<orgName>Computer Science and Technology, Tsinghua University ; Professor of School of Computer Science and Engineering, Beihang University, Beijing, China. His is also the head of Beihang Interest Group on SmartCity (BIGSCity), and Vice Director of the Beijing City Lab (BCL) ; Beihang University ; School of Economics and Management, Beihang University</orgName>
		</respStmt>
	</monogr>
	<note>He is also the director of the Research Center for Data Intelligence (DIG), the vice director of Beijing Key Laboratory of Emergency Support Simulation Technologies for City Operations, and a senior researcher in Beijing Innovation Center for Big Data and Brain Computing. His general area of research is data mining and machine learning. with a special interest in social, urban and financial computing. He is the recipient of various nation-wide academic awards in China, including the NSFC Distinguished Young Scholars, the MOE Changjiang Young Scholars, and the National Excellent Doctoral Dissertation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
