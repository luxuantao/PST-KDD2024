<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detecting F-formations as Dominant Sets</title>
				<funder ref="#_vx34F2R">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hayley</forename><surname>Hung</surname></persName>
							<email>h.hung@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Intelligent Systems Lab</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Kr?se</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam and Hogeschool van Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Detecting F-formations as Dominant Sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2070481.2070525</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing indexing methods Algorithms</term>
					<term>Human Factors social surveillance</term>
					<term>dominant sets</term>
					<term>modularity cut</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The first step towards analysing social interactive behaviour in crowded environments is to identify who is interacting with whom. This paper presents a new method for detecting focused encounters or F-formations in a crowded, reallife social environment. An F-formation is a specific instance of a group of people who are congregated together with the intent of conversing and exchanging information with each other. We propose a new method of estimating F-formations using a graph clustering algorithm by formulating the problem in terms of identifying dominant sets. A dominant set is a form of maximal clique which occurs in edge weighted graphs. As well as using the proximity between people, body orientation information is used; we propose a socially motivated estimate of focus orientation (SMEFO), which is calculated with location information only. Our experiments show significant improvements in performance over the existing modularity cut algorithm and indicates the effectiveness of using a local social context for detecting F-formations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Automatically estimating relationships between humans is a challenging problem, being a highly varied and subjective phenomenon which is difficult to categorise and capture. By relationships, we refer to behavioural phenomena such as dominance, interest, or attraction which can be perceived during prolonged conversation. Typically, such behaviours have been recorded and tested in restricted environments where the number of participants is relatively small (2 people: <ref type="bibr" target="#b18">[19]</ref>, 4 people: <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14]</ref>), though some studies have started to consider scenarios where more people <ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref> are involved <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b12">13]</ref>. In most studies, the participants are seated or remain seated for most of the time, which inhibits the natural inclination of people to adjust their proximity and body orientation towards each other when they converse. In addition to the visual and and auditory senses, the ability to adjust one's inter-personal proximity has a significant influence on the perception of smells, touch or body temperature of the other person <ref type="bibr" target="#b10">[11]</ref> and can indicate significant differences in the relationships between people. By addressing natural social behaviour in cases where people are standing we are able to capture a wider range of body language. This provides important cues about a person such as their personality, <ref type="bibr" target="#b21">[22]</ref>, and also their relationship with other people e.g. if they are in an intimate relationship <ref type="bibr" target="#b6">[7]</ref>.</p><p>In this work we focus on freely formed and congregated groups of individuals who are meeting purely to exchange information or foster existing relationships (see Fig. <ref type="figure" target="#fig_0">1</ref>). The gathering is such that most of the approximately 50 participants are acquainted with about half of the people at the event, This differs from the scenarios usually used to detect people who are walking together as the scenes are more likely to be filled by mostly unacquainted groups <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b0">1]</ref>. Unacquainted groups will interact with each other through avoidance strategies but this is clearly a different form of communication than actually having a conversation.</p><p>As the number of people in a scene increases, the likelihood of conversations being restricted to a single floor reduces significantly <ref type="bibr" target="#b5">[6]</ref> and people tend to split off into separate groups to converse more directly with one another. Un-der such circumstances, the first challenge in understanding the relationship between group members is to be able to identify them. An initial step towards this, which has received relatively little attention and is the focus of this paper, is the detection of focused encounters. By approaching the task of detecting focused encounters, we provide a solid framework for measuring more qualitative behaviour such as aggression <ref type="bibr" target="#b20">[21]</ref>, or dominance <ref type="bibr" target="#b13">[14]</ref>. Focused encounters were first defined by Goffman <ref type="bibr" target="#b9">[10]</ref> as a collection of people who are gathered together such that a shared space is maintained between them within which a conversational exchange can occur. They differ from unfocused encounters <ref type="bibr" target="#b9">[10]</ref> which refer to the way people move to ensure they do not bump into each other, or greeting someone when walking past them, for example. An F-formation is considered as a specific instance of a focused encounter <ref type="bibr" target="#b4">[5]</ref>, which we will describe in more detail in the next section. Unfocused encounters and focused encounters can appear very similar since proximity and orientation cues can be used in both cases. However, clearly interactions during focused encounters can have a much more substantive meaning as all the participants co-operate to sustain a continued period of information exchange. Distinguishing between them allows us to identify differing levels of potential influence.</p><p>Detecting F-formations automatically may appear to be a relatively simple task which can be easily extracted from who is 'standing with whom' (as suggested by Yu et al. <ref type="bibr" target="#b19">[20]</ref>), but one quickly finds that in more crowded situations where perhaps, the more interesting behavioural phenomena are to be found, proximity can be significantly affected by the layout of a room (e.g. position of furniture) or how crowded it is <ref type="bibr" target="#b4">[5]</ref>. Body orientation also plays a role as it provides a prior on the direction of attention of a person but can again be influenced by the same external factors. One can also observe frequent situations at social gatherings where someone tries to join a group but is left standing on the periphery, trying to listen or join in on the conversation. If no one in the group lets him, he clearly has a different status to the full participants in the conversation. Therefore, there are different aspects to being involved in a focused encounter, which goes beyond a person's willingness (through their body behaviour) to be part of it.</p><p>The contributions of this paper are twofold. First, we address the new problem of identifying F-formations in crowded social scenes. The classification task is informed by prior work in psychology and social sciences and provides a principled framework from which more complex social behaviours can be identified. Second, we make improvements over the baseline method proposed by Yu et al. <ref type="bibr" target="#b19">[20]</ref> by formulating the problem as one of identifying dominant sets <ref type="bibr" target="#b16">[17]</ref>. A dominant set is a form of maximal clique that can be applied to edge weighted graphs so that the affinity between all nodes within it is higher than that between the internal nodes and those that are external to it. This differs from modularity cut <ref type="bibr" target="#b15">[16]</ref> which is a global optimisation method where partitions of the graph are made according to the difference between the affinity of two nodes and the expected degrees of the vertices. Since participants of an F-formation require equal access to a shared space, clustering people within them can be considered more of a local rather than global optimisation task. Finally, we suggest a modification to Pavan and Pelillo's peeling off strategy, which is used to identify all the dominant sets in a graph, by introducing a stopping criterion which enables better detection of singletons.</p><p>For the remainder of this paper, we will discuss related work. Then we motivate the need to consider F-formations as dominant sets (Sec. 3). We describe the data and annotation process used to evaluate our methods in Sec. 4. In Sec. 5, we provide a brief description of the modularity cut algorithm to highlight the differences between it and our proposed clustering method (Sec. 6). In Sec. 7, we provide a description of how the affinity matrix was calculated using proximity and orientation information as well as our socially motivated estimate of visual focus, which is calculated from location information only. We present our experimental results in Sec. 8 and conclude in the final section. Our approach is summarised in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Goffman <ref type="bibr" target="#b9">[10]</ref> defined focused interaction as being "concerned with clusters of individuals who extend one another a special communication license and sustain a special type of mutual activity that can exclude others who are present in the situation"(p. 83). He went on to say that such a spatial and orientational arrangement "tends to be carefully maintained, maximizing the opportunity for participants to monitor one another's mutual perceivings"(p. 95). Ciolek and Kendon <ref type="bibr" target="#b4">[5]</ref> took this idea further by defining a focused interaction more precisely as an F-formation "whenever two or more individuals in close proximity orient their bodies in such a way that each of them has an easy, direct and equal access to every other participant's transactional segment, and when they maintain such an arrangement, they can be said to create an F-formation" (p.243).</p><p>The transactional segment is the region in front of the body where limbs can reach easily, and hearing and sight is most effective. They defined the F-formation system to be the system of spatial and postural behaviours by which people create and sustain the shared interaction space between them. Associates of an F-formation were defined as people who may adjust their position relative to the F-formation system but are not included in its boundaries; they can come and go from an F-formation without the usual rituals that full participants of an F-formation would undergo. Examples of F-formations and associates are shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>In the computer science community, work on detecting groups has tended to focus more on finding people who are 'together' based on the persistence of their proximity and direction of motion <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b17">18]</ref> during walking, which are readily measurable from the extracted trajectories. In these scenes, individuals walk with people they know and it is unlikely that they will be acquainted with other walking groups. Unfocused encounters, are therefore much more prominent. Focused encounters on the other hand, give a far richer semantic meaning to the interactions between people. To our knowledge, little work has tried to identify the key factors involved in being in a focused encounter.</p><p>Zen et al. have addressed some of the issues involved in approaching people to interact with them, within the framework of estimating personality traits from proxemic behaviour <ref type="bibr" target="#b21">[22]</ref>. However, the identification of F-formations was not explicitly addressed.</p><p>The closest work to ours was done by Yu et al. <ref type="bibr" target="#b19">[20]</ref>, who proposed a system that could track and discover groups of interacting people. The modularity cut algorithm <ref type="bibr" target="#b15">[16]</ref> was applied to identify these groups from automatically extracted trajectories. A problem with this work is the choice of data and experimental design. The 30 minute test data set was rather artificial as 23 people were asked to "mingle in a 3-group configuration" <ref type="bibr" target="#b19">[20]</ref> (p.1468). Three groups were indeed identified but given the average number of people per group, it is unlikely that such large F-formations could be sustained <ref type="bibr" target="#b5">[6]</ref>; typically, large gatherings tend to split or merge into smaller F-formations over time as the conversation changes. It is difficult to conclude what the 3 groups represented semantically, other than spatially separated locations. The same authors have subsequently used modularity cut to identify groups for classifying group activities in a prison scenario <ref type="bibr" target="#b2">[3]</ref> where collective aggressive behaviour from people acting as 'gangs of inmates' are analysed. Also, they used only proximity information and not body orientation, when computing the affinity between detected people. Other work which is close to ours is that of Brdiczka et al. <ref type="bibr" target="#b1">[2]</ref> who analysed speech activity to identify who was interacting with whom among 4 subjects. Their algorithm could automatically identify pre-scripted periods when different combinations of pairs of people were speaking or the whole group was speaking together. It is not clear if their algorithm could scale to larger group sizes and also whether using more realistic conversational data would have provided similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">GRAPH-THEORETIC DEFINITION OF F-FORMATIONS</head><p>The people in a scene can be represented as a graph G = (V, E, w) with a set of vertices V , edges E, and a positive edge weight function w. In this case, the vertices or nodes are the people, E correspond to the set of connections between the people and w represents the affinity measured using some extracted features between each pair in the scene. We can express the relationship between all the nodes or people in the scene by a weighted affinity matrix A such that each of its elements aij = w(i, j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">F-formations as High Modularity</head><p>Yu et al. <ref type="bibr" target="#b19">[20]</ref> defined the task of identifying groups of people in terms of the recursive global partitioning of the graph by maximising the remaining modularity of the uncut edges. Modularity was proposed by Newman <ref type="bibr" target="#b15">[16]</ref> as a metric for clustering social networks. The modularity between two nodes in a graph is represented in the corresponding element of modularity matrix B where each of its elements is defined</p><formula xml:id="formula_0">bij = aij - kikj 2m . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>aij is the affinity between node i and j, ki and kj are defined as the expected degrees of the vertices, indicating how 'con- nected' that particular node is to the rest of the network; ki = P j aij , and 2m is a normalisation term; m = 1 2 P ij aij. For a network with n nodes, which is divided into two groups by the indicator vector s, each of its n elements are either labelled as si = 1 for all vertices in group 1 and si = -1 for those in group 2. The modularity of the entire network</p><formula xml:id="formula_2">h i j h i j h i j (a) (b) (c)</formula><formula xml:id="formula_3">Q = 1 4m X ij bij sisj,<label>(2)</label></formula><p>defines how well connected it is when cuts are made according to s. The main assumption of modularity is that the affiliation between any pair of nodes is only significant if its value is greater than the expected affiliation of those two nodes with the rest of the network.</p><p>The modularity is well adapted to finding two-node maximal cliques but is not specifically designed for larger clique sizes, as can be demonstrated by the following example. Let us suppose that we have a network where nodes i, j and h are in an F-formation (Fig. <ref type="figure" target="#fig_2">3(a)</ref>). In this case, bij would be smaller given the proximity of node h compared to if node h was not part of the F-formation (Fig. <ref type="figure" target="#fig_2">3(b)</ref>). If h was standing closer to i than j (Fig. <ref type="figure" target="#fig_2">3(c</ref>)), thus breaking the triadic F-formation, bij would be higher than if h was standing equally close to i and j. So in (Fig. <ref type="figure" target="#fig_2">3(a)</ref>), bij is penalised because of the proximity of h to i and j whereas it makes more sense that the proximity of h should support the affinity of i and j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">F-formations as Dominant Sets</head><p>As already mentioned, an F-formation is defined as a group of people who have easy and equal access to the same shared space, around which they can communicate for a prolonged time. By its definition, therefore, mutual affinity between all of its members should be higher than the affinity between any of its members and those outside of it. In the case of an associate of an F-formation ( e.g. someone who wishes to, but is unsuccessful at joining the group), they are clearly close to one or two members of the F-formation but may not have access to all of them. Based on these definitions, it seems clear that using modularity to identify F-formations is not precise enough for our task.</p><p>Pavan and Pelillo <ref type="bibr" target="#b16">[17]</ref> proposed a different way of thinking about a cluster as a dominant set, which is a generalisation of maximal cliques to edge-weighted graphs. If we consider a subset S of the set of nodes V in graph G, the average weighted degree of a vertex i ? S with respect to set S is</p><formula xml:id="formula_4">k S (i) = 1 |S| X j?S aij. (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>Note that in this definition of the degree of i, the value is strictly related to only a subset of the graph V . Ideally, S defines a semantically meaningful local context such as the F-formation consisting of persons i, j, and h in Fig. <ref type="figure" target="#fig_2">3 (a)</ref>.</p><p>The relative affinity between node j / ? S and i is</p><formula xml:id="formula_6">?S(i, j) = aij -kS(i),<label>(4)</label></formula><p>and the weight of each i with respect to a set S = R ? {i} is defined recursively as</p><formula xml:id="formula_7">wS(i) = j 1 if|S| = 1 P j?R ?R(j, i) wR(j) otherwise<label>(5)</label></formula><p>and ? {i} (i, j) = aij . wS(i) measures the overall relative affinity between i and the rest of the vertices in S, weighted by the overall affinity of the vertices in R. Therefore w {ij} (i) and w {ij} (j) would not vary for any of the conditions in Fig. <ref type="figure" target="#fig_2">3</ref>, while w {ijh} (h) would be highest for (a), lower for (c), and lowest for (b). This relationship between internal and external nodes of a dominant set S is defined formally using the following conditions;</p><formula xml:id="formula_8">wS(i) &gt; 0, ?i ? S (6) w S?{i} (i) &lt; 0, ?i / ? S. (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>Therefore, dominant sets describe very compact structures, which is ideally suited to represent F-formations of any size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OUR DATA</head><p>The data we used (see Fig. <ref type="figure" target="#fig_0">1</ref>) consists of real footage of over 50 people who met to present scientific work during a poster session. The focused encounters that are formed were all natural and unscripted, motivated only by each individual's real relationships with other people at the event. The data captures interactive behaviour between people who are closely acquainted (e.g. work colleagues or friends), as well as strangers. The event lasted for approximately 3 hours and was captured by video from a camera that was mounted approximately 15 m overhead. The distance and orientation of the camera helps to conserve the privacy of the participants while enabling the analysis of a crowded scene. To our knowledge, this is currently the largest data set which captures naturally formed focused encounters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotating the Data</head><p>Images from the data were selected so that each one contained different F-formations. In total, 82 images were selected for annotation, containing ? 1700 people. Selection was made based on leaving at least 10s between images and that no consecutively selected images contained the same formations of people. We also tried to maximise on the crowdedness and ambiguity of associates in the scenes. The positions of all the people in the scene were pre-labelled so that the annotators could concentrate on identifying the Fformations. Software was written to allow easy labelling of the data. 24 annotators from different international cultural backgrounds volunteered to label the data. The annotators were grouped into 3-person subgroups to label the same data so that variability in the labelling could be taken into account during evaluation. After being given appropriate definitions, annotators were asked to identify F-formations and their associates from static images. Asking for explicit labels for associates ensured that annotators would consciously decide how involved they thought each person was in the corresponding F-formation. The annotators labelled 10 -11 images each, with on average ? 170 instances of people to label. After the annotation task, the annotators were asked to provide free comments about what they found difficult or easy about the task. Cues that they reported to use for determining who was a member or associate of an F-formation included gaze direction, proximity and body orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Annotation Analysis</head><p>We analysed the annotations to see how many sizes of Fformation there were and how frequently each size occurred based on whether there was full agreement between the annotators about all members of an F-formation, or when the union of all overlapping groups was considered. The frequency of occurrence of each F-formation size is shown in Table <ref type="table" target="#tab_0">1</ref>. 340 singletons were labelled, with 450 full agreement F-formations and 599 when the union was used. Using both cases, dyads occurred most frequently. The form of the distribution aligns with those found by Ciolek who studied how people gathered in public areas <ref type="bibr" target="#b3">[4]</ref>. The level of annotator agreement was calculated using the F-measure per F-formation (or singleton) for each pairwise combination of annotators who labelled the same data. The mean of these values was taken for each triad of annotators and then finally the average for all groups of annotators was calculated. The mean average F-measure was 94.74% so the annotator agreement was high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">MODULARITY CUT</head><p>To highlight the difference between our proposed method and modularity cut, we will provide a brief introduction here. Further details can be found in Newman's original paper <ref type="bibr" target="#b15">[16]</ref>. Modularity cut was originally developed for social network analysis and discovers groups in social networks, where the size of the communities being tested on are large and consequently, the discovered communities are also of quite large. Given this application domain, maximal cliques or dominant sets are less likely to occur and for discovering social groups based on people with common hobbies or interests, the density of connections between community members is not as important as how connected each person is to everyone else in the network. For the task of identifying spatially separated groups, Yu et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b2">3]</ref> have shown the effectiveness of using modularity cut. However, as we have demonstrated in Sec. 3, modularity may not be the best representation of F-formations.</p><p>From Eq. 2 in Sec. <ref type="bibr" target="#b2">3</ref>, we can see that by carefully selecting s, it is possible to maximise the modularity Q by summing over the higher-valued elements of the modularity matrix B. Since Eq. 2 can be conveniently arranged so that</p><formula xml:id="formula_10">Q = 1 4m s T Bs,<label>(8)</label></formula><p>performing Eigen decomposition on B and choosing appropriate values for the elements of s such that the largest or most positive eigenvalues are given the most weight, will lead to a maximisation of Q. In our case, however, the elements of s are restricted to be either ?1 and finding the optimal solution for s is likely to be NP-hard. In practice, a good approximate solution can be found by taking the principal eigenvector of B, u1, and setting the sign of each element of s to match those of u1. Note that the degrees, ki, are always calculated relative to all the other vertices in the network so the graph is partitioned using a global context. In practice, this can have negative consequences for F-formation estimation, particularly when we consider how people typically arrange themselves spatially in a room. This can be influenced by both the furniture and function of the occasion. In our case, people typically tend to cluster around the edges of the space either to watch others passing through, or to present a poster. This means that the people tend to distribute in clusters of rings around the space. Under such circumstances, a partition can occur that splits apart an F-formation near the centre of the scene just because the scene is equally crowded on both sides. The modularity is still maximised as the people in this central F-formation are, on average, the furthest away from the rest of the nodes in the graph so that cutting most of the edges still leads to a small reduction in modularity. This particular example indicates well the problem of treating F-formation detection as a purely global optimisation task.</p><p>Kernighan-Lin (KL) Refinement.</p><p>Since the principal eigenvector can only provide an approximation for the division, a step inspired by the Kernighan-Lin algorithm <ref type="bibr" target="#b15">[16]</ref> can be applied to try to maximise Q further. This involves taking each node in turn, moving it to the other group and then recalculating Q. The node change which results in the highest Q (even if this leads to a negative change in modularity) is kept and then the process is repeated until all have been swapped. If the final modularity leads to an overall improvement, then the partitioned refinement is kept. This step has been used widely for network analysis with significant improvements <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Further Subdivisions of the Network.</head><p>Recursive division of the network is carried out by considering an nG ? c matrix S which serves to indicate with a one when a node n belongs in community c and zero otherwise. G is the sub-community of the network ( with nG nodes), that is being considered for further subdivision. By measuring the change in modularity before and after the subdivision of the network, we can decide to keep the split based if it leads to a decrease in modularity. ?Q =</p><formula xml:id="formula_11">1 2m P i,j?G P c k=1 Bij S ik S jk - P i,j?G Bij = 1 2m Tr(S T B (G) S).<label>(9)</label></formula><p>B (G) can be considered as the sub-matrix of B for the subgraph G. By re-arranging ?Q to have the same form as Eq. 8, we can conveniently re-apply the same eigenvector-based selection process to subdivide the communities. To achieve this form however B (G) is defined differently to B:</p><formula xml:id="formula_12">B G ij = Bij -?ij X l?G B il . (<label>10</label></formula><formula xml:id="formula_13">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">IDENTIFYING DOMINANT SETS WITH REPLICATOR DYNAMICS</head><p>As described in Sec. 5, one way of clustering the graph is to recursively partition it using spectral techniques such as eigen decomposition. However, finding dominant sets could be considered better suited to a local optimisation problem. In doing so, we also ensure that the resolution of the clique sizes are not affected by the number of positive links and the cardinality of the graph <ref type="bibr" target="#b7">[8]</ref>. Pavan and Pelillo <ref type="bibr" target="#b16">[17]</ref> showed that the notion of a cluster and its relationship to dominant sets were mathematically equivalent by formulating the optimisation problem as a standard quadratic programme where f (x) = x T Ax <ref type="bibr" target="#b10">(11)</ref> is maximised subject to the constraint that x lies on the standard simplex ? = {x ? R n : x ? 0 and P n xn = 1}. A in this case is still defined as the affinity matrix of the graph. However, x is slightly different from the indicator vector s that was used to maximise the modularity in Eq. 8. Here, x is defined as the weighted characteristic vector and when defined in terms of the subset of vertices S,</p><formula xml:id="formula_14">x S i = j w S (i) W (S) , if i ? S 0 , otherwise , (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where W (S) = P i?S wS(i) is the total weight, which must be greater than 0. Pavan and Pelillo <ref type="bibr" target="#b16">[17]</ref> proved that by using this definition of x, the maximisation of the objective function is the same as finding dominant sets. Further details of this proof can be found in <ref type="bibr" target="#b16">[17]</ref>.</p><p>To find a local solution of the objective function f , a method taken from evolutionary game theory, called replicator dynamics was used. The first-order replicator equations are defined as</p><formula xml:id="formula_16">xi(t + 1) = xi(t) (Ax(t))i x(t) T Ax(t)<label>(13)</label></formula><p>and are applied to all nodes in the network in turn. Since A is symmetric, the replicator equations provide a strictly increasing update to the characteristic vector x, which converges upon the local solution of f . By taking the support or non-zero indices of the final x, we identify the elements of the graph that are a dominant set. That is, the solution of the replicator equations converges exactly on a characteristic vector that conforms exactly to conditions 6 and 7. In practice, x is initialised with uniform weights, which corresponds to the centroid of the standard simplex.</p><p>Further Subdivisions of the Network.</p><p>Since the replicator equations only converges on the most dominant set of a particular graph, an effective way of identifying further clusters in the network is to apply a peeling strategy <ref type="bibr" target="#b16">[17]</ref>. This involves identifying a dominant set using Eq. 13, removing the corresponding nodes, and then re-applying the replicator equations to the remaining subgraph. In practice, the elements of the characteristic vector rarely converged to exactly 0 so a threshold was used to identify numbers that were extremely close. The same threshold was also used to ensure that if the value of the maximised objective function was too small, we considered that all the remaining nodes in the graph were singletons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local vs Global Context.</head><p>There is one disadvantage of using a peeling off strategy to determine dominant sets. As more dominant sets are removed from the original graph, fewer and fewer nodes remain until it is likely that those that are not clustered yet are more likely to be singletons than in an F-formation. We modify the peeling strategy suggested by Pavan and Pelillo <ref type="bibr" target="#b16">[17]</ref> by introducing a more principled stopping criterion, which takes into account the global context of the complete graph. Given the nature of dominant sets, we know that conditions 6 and 7 must hold. Using the peeling off strategy, this is certainly the case for the dominant set that has been identified within the sub-graph. However, if we compare w S?{i} (i), for all i / ? V , where V is the set of all nodes in the entire graph, we also ensure that the clustering makes sense within the global context and the need for assigning a slightly arbitrary threshold as a stopping criterion is removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">BUILDING THE AFFINITY MATRIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proximity.</head><p>Perhaps the most obvious way of measuring the affinity between people is to use their relative proximity, as proposed by Yu et al. <ref type="bibr" target="#b19">[20]</ref>. The symmetric distance function between person i and j is defined as</p><formula xml:id="formula_17">A prox ij = -e d ij 2? 2 (14)</formula><p>where dij is the Euclidean distance in the ground plane between person i and j and ? is the variance of the function. Given the nature of our data, ? was set to approximately 2 metres; the commonly accepted distance at which focused encounters occur <ref type="bibr" target="#b11">[12]</ref>. Note that unlike Yu et al., our affinity matrix is generated from a single static image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proximity and Orientation.</head><p>Using proximity alone can lead to errors in the F-formation estimates as the space becomes more crowded. Fortunately, the body orientation can help to identify the shared space between all the F-formation members. This is particularly relevant for cases where associates exist as they may be oriented towards an F-formation but those closest to the associate may have their backs to them. To address this case, Aij is defined by taking the worst case in both directions;</p><formula xml:id="formula_18">A ori ij = argmin q ( ( e - dq 2? 2 -? 2 ? ?q 1 -?q ? ? 2 0 otherwise ,<label>(15)</label></formula><p>?q ? {(i, j), (j, i)}, where ?i is the angle of body orientation of person i, q1 is the first element of q, and ?ij is the angle of the vector from i to j. An asymmetric or directed version of Aij can be considered by taking the actual values of the affinity rather than the minimum in both directions and using an extension of modularity that can deal with a directed affinity matrix <ref type="bibr" target="#b14">[15]</ref>. Though our experiments with a directed graph performed better than the basic modularity cut, using the undirected graph led to better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Socially Motivated Estimate of Focus Orientation.</head><p>Compared to person position, body orientation can be particularly difficult to extract robustly in crowded environments. To bypass the need to extract body orientation information as well, we propose a socially motivated estimate of focus orientation (SMEFO) ? based on the relative distance between participants in the scene. Given a person in the scene, we expect that they are most likely to be oriented towards the people they are motivated to converse with. If the motivation to talk to others is correlated with proximity, people will tend to be much closer to those that they wish to talk to. The SMEFO is defined as ?i = arccos(?(pi, fi)), <ref type="bibr" target="#b15">(16)</ref> where pi is the location of person i and ?(pi, fi) is the angle of the vector from person i to their estimated centre of focus fi = 1 ki</p><formula xml:id="formula_19">X j pjA prox ij . (<label>17</label></formula><formula xml:id="formula_20">)</formula><p>? in Eq. 15 can then be replaced by ?. Note that ki here is the degree of i for the entire graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">EXPERIMENTS</head><p>To evaluate our methods, the precision, recall and f-measures were calculated for each F-formation and singleton, labelled by the annotators. An F-formation in the annotations was considered to be the union of all labelled groups that overlapped. The groupings were scored for each labelled Fformation by comparing each person in it to the corresponding detected group. Any overlapping nodes between the labelled and detected groups was given a score of 1  3 per annotation, depending on whether the detection was a true positive, false positive, or false negative. As there were three annotators per image frame, given a labelled group, each person in it could be scored from 0 up to 1, depending on how many annotators agreed that the person was in the F-formation. Then, the set of annotations was compared against the detected F-formation and accumulated to get the precision, recall and f-measure of that particular group. We report the average of each of these measures over all the groups. For the purposes of evaluation the set of all possible groups consisted of all the F-formations and also the singletons. The position and orientation of people were manually labelled in the images, which were then used for building the affinity matrices in Sec. 7. The positions were projected onto the ground plane using orthogonal projection.</p><p>First, we present our results using a factorial combination of the different features and methods that were described earlier, shown in Table <ref type="table" target="#tab_1">2</ref>. The features used were proximity (P: Eq. 14), proximity and the manually labelled orientation (P+O : Eq. 14, 15), and proximity and the SMEFO feature (P+F: Eq. 14 <ref type="bibr">-16)</ref>. The methods we used were the dominant set identification using replicator dynamics (DS: Eq. 13) with local context where a threshold on the value of the objective function was used (LC), and the global context where a stopping criterion was defined based on when w S (i) &gt; 0 for any i not in the identified dominant set S (GC), as described in Sec. 6. We compare our results with the method of Yu et al. <ref type="bibr" target="#b19">[20]</ref>, that used modularity cut and proximity to create the affinity matrix (MC: Sec. 5).</p><p>For space reasons, we only show the best most automated method of extracting features in combination with modularity cut, which used the proximity and SMEFO features with modularity cut and Kernighan-Lin refinement (MC+KL), though the performance in all cases was improved over <ref type="bibr" target="#b19">[20]</ref>. In addition to the performance of different methods, we also provide a baseline based on if all people in the data were labelled as singletons. Note that the performance of this baseline is quite high because most of the high performance is distributed in the set of annotated singletons. Note also the high precision is biased towards the naturally high precision of detecting singletons in the data.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows that all our proposed methods out-performs that the baseline <ref type="bibr" target="#b19">[20]</ref>. Both fully manual methods with our proposed dominant set technique (P+O, DS) performed the best but was comparable to using (P+O,MC). If we examine the performance of the methods when not using the manually labelled body orientation, a clearer picture emerges about the effectiveness of both methods. It is particularly interesting to note that using the position information only (P, DS+GC), the dominant set method outperforms all methods that use the SMEFO feature. When considering proximity features only, both DS methods outperform the corresponding modularity cut method by over the absolute improvement of (P, DS+GC) is 4.5%, despite not taking into account any orientation information.</p><p>The SMEFO feature was proposed as another way of addressing the problem of associates of F-formations who are often close to full participants but may not have equal access to all of them. Using SMEFO, it was possible to identify some cases where someone clearly would not be able to converse with the other person because there would be someone else in between. When using dominant sets to identify the F-formations, this idea of equal mutual access between all the participants is represented more explicitly, which may explain why the performance is better.</p><p>The similar performance of both dominant sets and modularity cut, when using both manually annotated location and orientation information, suggests that body orientation is a strong cue for detecting F-formations. However, while the increase in performance when using fully labelled data compared to location information only with modularity cut is 15.5%, using DS, the performance improvement is much less, at 5.41%. This suggests that the importance of body orientation may be less important than ensuring equal and high affinity between all members of the F-formation. It also questions whether using more direct estimates of body orientation (i.e. from the imagery data) would necessarily provide a significant improvement for F-formation estimation compared to using position information alone. When comparing the singleton baseline to all other methods, we see that using the basic modularity cut algorithm proposed by Yu et al. <ref type="bibr" target="#b19">[20]</ref> only just out performs it, indicating how poor modularity cut is for detecting F-formations. We also found that for the dominant set method, the GC method consistently out-performed the corresponding LC method, which demonstrate the effectiveness of our improvement to the stopping criterion of the peeling back strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulating Tracking Errors.</head><p>So far, our experiments have shown F-formation detection using manual annotations of the position and body orientation information. Using the SMEFO feature, while the body orientation becomes an estimate, the positions are still manually extracted. To test the stability of our method compared to the baseline methods, we applied increasing levels of Gaussian noise to the manually labelled positions. For cases where we tested the clustering methods using man-ually annotated body orientation information, we did not add noise to the orientations as adding noise to the positions, given the body angle, would already affect the affinity sufficiently. It also provided a more consistent framework from which to compare the different features and methods. The results are summarised in Figure <ref type="figure" target="#fig_3">4</ref>.</p><p>We noticed when analysing the breakdown of the performance across different group sizes, that a significant increase in the performance of the dominant set method over modularity cut was due to significantly better estimation of singletons. Since these are not really considered to be F-formations, we provide the performance based on all Fformations that contain at least 2 people. This is indicated as a thin black line in Figure <ref type="figure" target="#fig_3">4</ref>, while the thick black line shows the overall performance for all cluster sizes. We also noticed when applying noise to the positions, that the Fformation performance tended to saturate as the noise level increased. On closer inspection we found that there was a tendency for all nodes to be labelled as singletons as they became more spread out. To illustrate this, we also show a dashed line in Figure <ref type="figure" target="#fig_3">4</ref>, which represents the performance when all nodes are labelled as singletons, and a dot-dashed line which shows the performance for the same method evaluated without the singletons. As expected, when the labelled singletons are excluded from the calculation, the performance drops significantly from 75% to 62%.</p><p>Note that using modularity cut, the performance increases significantly when singleton detection is not evaluated, which suggests that modularity cut is better at detecting larger group sizes. In almost all cases when singletons are not evaluated, the dominant set method performs worse. In terms of noise stability, the deterioration in performance occurs much sooner for modularity cut, compared to the dominant set methods. For the SMEFO feature, it provides more stability during noisy conditions for the modularity cut method, while improvements for the dominant set method is less significant. Using the manual body orientation labels, however, appear to provide much more stability for the DS method, suggesting that estimates of body orientation may still be useful when the tracking estimates are very noisy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, a new approach for detecting F-formations was presented by formulating the problem as one of finding dominant sets. Compared to modularity cut <ref type="bibr" target="#b19">[20]</ref>, significant and more stable performance improvements were observed. Our SMEFO feature also provided better performance, showing that some estimate of body orientation can help to improve the F-formation estimation performance but having accurate position information is more likely to provide better estimates. Since the method currently does not use automated person detection or body orientation, further investigations are needed to see the effect on F-formation estimation. Our test data is currently limited to scenarios where everyone is standing. In public spaces, a variety of sitting and standing behaviours occur depending on possible seating areas or other furniture. This was represented to some extent in our current data with high circular coffee tables but could be extended to more extreme cases. Increased furniture in the space can lead to spatial deformations of the F-formations that occur more in standing scenarios. So dominant sets constructed from instantaneous spatial cues alone will have limited success. Examining co-ordinated conversational movement in video may help to mitigate this problem. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Screen-shot from our data (best seen in colour). Some example F-formations are circled. The associate on the right side of an F-formation is indicated by an arrow.</figDesc><graphic url="image-2.png" coords="2,334.87,200.86,202.98,139.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Flow diagram summarising our approach. Green lines:annotated F-formations, Yellow box: associate, Red lines: detections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of how modularity would differ counter-intuitively. Thick lines represent high affinity while thin lines show low affinity. (a): h, i, and j are in an F-formation. (b): i and j are in an Fformation while h is far away from them. (c): i and j are in an F-formation while h is very close to i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of results when Gaussian noise was added to the people's positions. The noise is expressed in terms of the proportion of the approximate width of a person. Thick black line shows the mean f-measure evaluating over all F-formation sizes while the thin black line indicates the performance when labelled singletons were excluded from the evaluation. Horizontal lines indicate the f-measure if every node was labelled as a singleton (dashed lines) and when labelled singletons were not evaluated (dot-dashed lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Distribution of labelled F-formation sizes using full agreement or the union of labelled mem- bers.</head><label>1</label><figDesc></figDesc><table><row><cell>F-formation Size</cell><cell>1</cell><cell>2</cell><cell cols="2">3 4 5 6 Total  *</cell></row><row><cell>Full Agreement</cell><cell cols="2">340 378</cell><cell>69 2 1 0</cell><cell>450</cell></row><row><cell>Union</cell><cell cols="3">340 452 136 8 1 2</cell><cell>599</cell></row></table><note><p>* Not including singletons.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 : Results summary in terms of the mean pre- cision, recall and F-measure per F-formation. The boldened values show the highest average F-measure per F-formation for each feature combination. The last row shows the performance if everyone was la- belled as singletons.</head><label>2</label><figDesc>8.2% in absolute terms. Compared to (P+F,MC +KL),</figDesc><table><row><cell>Cues</cell><cell>Methods</cell><cell>Prec</cell><cell cols="2">Recall F-Meas</cell></row><row><cell>P</cell><cell>DS+LC</cell><cell>80.24</cell><cell>95.72</cell><cell>84.85</cell></row><row><cell>P</cell><cell cols="2">DS+GC 87.29</cell><cell>91.79</cell><cell>86.83</cell></row><row><cell>P</cell><cell>MC</cell><cell>68.72</cell><cell>97.43</cell><cell>76.57  *</cell></row><row><cell cols="2">P+O DS+LC</cell><cell>90.36</cell><cell>96.63</cell><cell>91.87</cell></row><row><cell cols="3">P+O DS+GC 91.94</cell><cell>95.57</cell><cell>92.24</cell></row><row><cell cols="2">P+O MC</cell><cell>89.50</cell><cell>98.40</cell><cell>92.02</cell></row><row><cell cols="2">P+F DS+LC</cell><cell>83.08</cell><cell>94.25</cell><cell>85.85</cell></row><row><cell cols="3">P+F DS+GC 85.40</cell><cell>93.26</cell><cell>86.50</cell></row><row><cell cols="3">P+F MC+KL 77.06</cell><cell>96.28</cell><cell>82.32</cell></row><row><cell cols="2">All Singletons</cell><cell>95.63</cell><cell>66.27</cell><cell>75.57</cell></row></table><note><p>* Baseline from Yu et al. [20].</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was supported by a <rs type="grantName">Marie Curie Research Training Network fellowship</rs> in the project "<rs type="projectName">AnaSID</rs>"(<rs type="grantNumber">PIEF-GA-2009-255609</rs>). We thank <rs type="person">Jagan Varadarajan</rs>, <rs type="person">Bastien Crettol</rs>, and <rs type="person">Val?rie Devanth?ry</rs> for their help during the capture and processing of the data, and <rs type="person">Gwenn Englebienne</rs> for his template-based orthogonal projection code.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_vx34F2R">
					<idno type="grant-number">PIEF-GA-2009-255609</idno>
					<orgName type="grant-name">Marie Curie Research Training Network fellowship</orgName>
					<orgName type="project" subtype="full">AnaSID</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using social effects to guide tracking in complex scenes</title>
		<author>
			<persName><forename type="first">A</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pridmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVSS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="212" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic detection of interaction groups</title>
		<author>
			<persName><forename type="first">O</forename><surname>Brdiczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maisonnasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Reignier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMI</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="32" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Group level activity recognition in crowded environments across multiple cameras</title>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krahnstoever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AVSS</title>
		<imprint>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Location of static gatherings in pedestrian areas: an exploratory study</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Ciolek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Man-Environment Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="41" to="54" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Environment and the spatial arrangement of conversational encounters</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Ciolek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kendon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Inquiry</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="237" to="271" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Size and structure of freely forming conversational groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dunbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nettle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Nature</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Edney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Jordan-Edney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Territorial spacing on a beach. Sociometry</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="1974-03">March 1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Resolution limit in community detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barth?lemy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatically detecting the small group structure of a crowd</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ruback</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Behavior in Public Places: Notes on the Social Organization of Gatherings</title>
		<author>
			<persName><forename type="first">E</forename><surname>Goffman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Free Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The silent language</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959">1959</date>
			<pubPlace>Doubleday, Garden City, N. Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Hidden Dimension</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<pubPlace>Doubleday, Garden City, N.Y.</pubPlace>
		</imprint>
	</monogr>
	<note>st ed.] edition</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The wolf corpus: Exploring group behaviour in a competitive role-playing game</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chittaranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2010">10 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling dominance in group conversations using nonverbal activity cues</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Jayagopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="501" to="513" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Community structure in directed networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Leicht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">118703</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modularity and community structure in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="8577" to="8582" />
			<date type="published" when="2006-06">June 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dominant sets and pairwise clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on PAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="261" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">It&apos;s not you, it&apos;s me: Detecting flirting and its misperception in speed-dates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcfarland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP&apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Monitoring, recognizing and discovering social networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Krahnstoever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cassandra: audio-video sensor fusion for aggression detection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zajdel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krijnders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andringa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AVSS</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="200" to="205" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Space speaks: towards socially and personality aware visual surveillance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lanz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st ACM international workshop on Multimodal pervasive video analysis</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Associating groups of people</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2009-09">September 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
