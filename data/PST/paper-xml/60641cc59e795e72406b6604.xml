<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Variable Interval Time Sequence Modeling for Career Trajectory Prediction: Deep Collaborative Perspective</title>
				<funder ref="#_a75Jwns #_qPtWJc4">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@baidu.com</email>
						</author>
						<author>
							<persName><forename type="first">Qiming</forename><surname>Hao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Keli</forename><surname>Xiao</surname></persName>
							<email>keli.xiao@stonybrook.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>hxiong@rutgers.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Anhui Province Key Lab of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China Hefei</orgName>
								<address>
									<settlement>Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Baidu Talent Intelligence Center</orgName>
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Anhui Province Key Lab of Big Data Analysis and Application</orgName>
								<orgName type="institution">University of Science and Technology of China Hefei</orgName>
								<address>
									<settlement>Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Stony Brook University Stony Brook</orgName>
								<address>
									<region>New York</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">The State University of New Jersey Newark</orgName>
								<address>
									<settlement>Rutgers</settlement>
									<region>New Jersey</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Variable Interval Time Sequence Modeling for Career Trajectory Prediction: Deep Collaborative Perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3442381.3449959</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Career trajectory prediction</term>
					<term>Time sequence modeling</term>
					<term>Temporal encoding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In today's fast-evolving job market, the timely and effective understanding of the career trajectories of talents can help them quickly develop necessary skills and make the right career transitions at the right time. However, it is a non-trivial task for developing a successful career trajectory prediction method, which should have the abilities for finding the right timing for job-hopping, identifying the right companies, and matching the right positions for the candidates. While people have been trying to develop solutions for providing some of the above abilities, there is no total solution or complete framework to integrate all these abilities together. To this end, in this paper, we propose a unified time-aware career trajectory prediction framework, namely TACTP, which is capable of jointly providing the above three abilities for better understanding the career trajectories of talents. Along this line, we first exploit a hierarchical deep sequential modeling network for career embedding and extract latent talent factors from multiple networks, which are designed with different functions of handling related issues of the timing, companies, and positions for job-hopping. Then, we perform collaborative filtering for generating personalized predictions. Furthermore, we propose a temporal encoding mechanism to handle dynamic temporal information so that TACTP is capable of generating time-aware predictions by addressing the challenges for variable interval time sequence modeling. Finally, we have conducted extensive experiments on large-scale real-world data to evaluate TACTP against the state-of-the-art baselines, and the results show that TACTP has advantages over baselines on all targeted tasks for career trajectory prediction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays, job change has become a new normal for working life in the fast-paced business world. According to the US Bureau of Labor Statistics, 20-24% of Americans (i.e., more than 41 million people) search for new jobs every year since 2017 <ref type="bibr">[1]</ref>. There are many benefits to understanding the career trajectory of talents from the perspectives of organizations, individuals, as well as the policymakers of labor and economics. For example, career trajectory analysis supports the human resource department in monitoring regional brain drain, making internal promotion decisions to motivate key talents, estimating the probability for a job seeker to accept the job offer through the hiring process, and many other meaningful tasks. Besides, from the perspective of talents, scheduling a satisfactory career trajectory from the abundant overload of job opportunities is usually a difficult decision to make, mainly due to the indecisiveness when facing high opportunity costs. Hence, career trajectory prediction results can benefit talents by guiding their career development paths. Also, career trajectory analysis is beneficial for the policymakers to find out the popular companies and corresponding cities when formulating policies and guidelines for attracting talents.</p><p>Regarding the career trajectory prediction, traditional methods are mainly based on empirical analysis <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b39">41]</ref>. Recently, people  have witnessed the rapid development of professional social networks (PSNs) <ref type="bibr" target="#b36">[38]</ref>, such as LinkedIn and Glassdoor, supporting the over 200 billion recruitment market worldwide <ref type="bibr">[1]</ref>. Corresponding job-related data enable people to seek effective machine learning solutions to the career trajectory prediction problem <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b47">49]</ref>. For example, Li et al. <ref type="bibr" target="#b17">[19]</ref> designed recurrent neural networks to predict talents' next companies and positions while Meng et al. <ref type="bibr" target="#b25">[27]</ref> focused on forecasting potential companies and estimating the working durations for the next jobs by an attentive recurrent model. Based on convolutional neural networks, He et al. <ref type="bibr" target="#b8">[10]</ref> predicted talents' future job positions, salaries, and company scales.</p><p>However, there are still many issues in existing models. First, existing solutions usually assume that the current job-hopping time is fixed and simply take historical job durations as a part of historical features <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b25">27]</ref>. It is very difficult to capture the state changes for talents with variable intervals, and thus we should consider the interval between every two jobs as an important factor for sequential modeling. For example, in Figure <ref type="figure" target="#fig_1">1</ref>, Alice and Bob have a similar starting point of careers. Alice only stayed a short period in Oracle while Bob chose to spend an extended period. Intuitively, they would have different choices for job transitions. An effective forecasting method should be capable of estimating the influences of different working durations, as well as the most likely time point for job-hopping. Importantly, we summarize three key aspects in career trajectory planning: the right timing for job-hopping, the right company for job application, and the right job position. None of the existing works aim to address all three prediction tasks in a unified manner. Moreover, due to the sparseness of individual career trajectory data, how to provide high-quality personalized predictions is also a long-standing challenge. Although some neighborhood based collaborative filtering (CF) methods <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b49">51]</ref> have been developed, there still lacks a comprehensive and robust model to generate personalized prediction results.</p><p>To this end, in this paper, we propose a comprehensive hierarchical time-aware career trajectory prediction framework, namely TACTP, for jointly solving all the aforementioned problems. To the best of our knowledge, this is the first work to construct a joint model to predict the three key elements in career trajectory, i.e., timing, company, and position, simultaneously. Specifically, we propose a general temporal encoding mechanism to obtain latent time representations from original discrete time values. These time representations are incorporated in both sequential modeling and collaborative filtering stages to enhance our TACTP framework of recognizing and exploiting temporal information. Then, we employ the recurrent networks to map the heterogeneous feature inputs into three dynamic latent vectors representing talent-time, talentcompany, and talent-position factors, respectively. Furthermore, we learn the dynamic latent company representations from deep collaborative networks and the latent position representations from Gaussian priors. As a result, our method could combine the latent company, position vectors with talent-company, talent-position, and time vectors to derive personalized time-aware predictions. Following this way, our TACTP framework can integrate the advantages of both sequential modeling and collaborative filtering to produce high-quality time-aware predictions according to different working durations of the current job. Finally, we conduct extensive experiments and evaluate TACTP by comparing it with state-of-theart baselines on a large scale real-world dataset. The experimental results clearly demonstrate the effectiveness of TACTP in terms of all career trajectory prediction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, we first introduce the real-world dataset used in this study. Then we will formulate the prediction problem with the three correlated forecast targets, i.e., company, position and timing. Finally, we give an overview of our proposed TACTP Framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data description</head><p>The real-world dataset in this paper was collected from LinkedIn, one of the most famous commercial professional social networks, which has served hundreds of millions of users to share their career experience and professional resumes. These resumes mainly contain two aspects of information, i.e., static and time-varying features. On one hand, static features are composed of user name, the number of user's social connections, and user's self-introduction text. On the other, time-varying features consist of the features related to companies and positions, such as company name, position name, and job duration of each working experience in their resumes.</p><p>However, only exploiting the above extracted information may be insufficient to support the modeling and inferring process for such a challenging prediction task from both user and item aspects. Therefore, we further adopt the following two measures to add more useful features to our study. First, we collected some other static company features from the open data sources as supplementary information, including company age, type, location, and description text. Second, we manufactured some relevant time-varying features by handling the original information into new forms. For example, we computed the working seniority for each user and the company size for each company at each time period as supplementary features. Also, we calculated the talent flow ratios for each company since talent flow analysis is much beneficial for monitoring companies' competitive advantages <ref type="bibr" target="#b40">[42,</ref><ref type="bibr" target="#b46">48]</ref>. Specifically, we counted the numbers of personal flow in/out/transfer records among companies every three years and then normalized these values. In this way, we can employ the previous talent flow in/out/transfer ratios as the time-varying features for the next time period. The next challenge of this task is how to transform the massive raw data into standardized sequence forms. We believe the job transition process is a sequential modeling task and consider the career trajectory data as time series. However, in the real world, one talent may be employed by several companies at the same time. To solve this problem, we followed the treatment in <ref type="bibr" target="#b51">[53]</ref> to find the major career path when there exist multiple parallel paths in talents' resumes. Specifically, if the absolute difference between the end time of the former job and the start time of the later job is less than a predefined time threshold, we regard this job transition as a valid record. Then we could construct a career tree if the former job has more than one valid later job. Finally, we only keep the longest career path in the career tree as the major career path. As for job positions, since the position names are provided by users, many positions in the raw data indeed have the same or similar meanings but totally different ways of expression. For normalizing these multifarious position names, we followed <ref type="bibr" target="#b51">[53]</ref> to use an online API called MonkeyLearns 1 to classify the raw names into 26 job categories. Thus, in the following part of this paper, the job positions all refer to these 26 categories. Another notable thing is that a talent may change his/her position several times in one company. Since the career trajectory prediction task mainly focuses on the job-hopping behaviors among companies, job position transitions in one company are not the focus of our study. Thus, we only consider the first job position in each company for all the users. More details about the statistical information and pre-processing of the data can be found in Section 4.1.</p><p>1 https://app.monkeylearn.com/main/classifiers.</p><p>To better understand the dataset properties, we present the distributions of career trajectory records from different views in Figure <ref type="figure" target="#fig_2">2</ref>. Figure <ref type="figure" target="#fig_2">2</ref>(a) and 2(b) show the distributions of the job records from company and position perspectives, respectively. Here we have sorted the companies and positions in descending order according to the number of users. From the company perspective, we can find that the long tail effect is quite obvious. Non-collaborative methods may be prone to focus on the top popular companies while neglecting the companies in the long tail. The distribution from the position perspective is also quite imbalanced. Therefore, it is important to learn independent representations for all companies and positions to solve the imbalanced data. Figure <ref type="figure" target="#fig_2">2(c</ref>) presents the number of users of different career lengths. It is noticed that we have employed the logarithm to the number of users due to the imbalance data. Less than 5% users have been occupied by more than 6 companies. Figure <ref type="figure" target="#fig_2">2</ref>(d) presents the counts of users of different working durations. A unit of abscissa in the figure means a half-year. It is interesting to observe the periodicity of durations, which shows the numbers of users in odd half-years are larger than even half-years except for the first year. Besides, more than 80% job experiences last less than 4 years, which also indicates the importance of career trajectory prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem formulation</head><p>Based on the extracted career movement records and various features, here we introduce the problem formulation of the career trajectory prediction task.</p><p>The t-th job record of the i-th talent can be represented by the combination of three elements, i.e., company C it , position P it and duration D it . Supposing the length of career path is T i for talent i, we can denote the job sequence as S i = {(C i1 , P i1 , D i0 ), (C i2 , P i2 , D i1 ), ... , (C iT i , P iT i , D i,T i -1 )}. It is noticed that the working duration in the sequence refers to the (t -1)-th job. This is because we usually do not know how long the talents will stay in the current company until they move to the next company and update their resumes on PSN. We denote D i0 = 0 for the first job.</p><p>Similarly, the feature sequence for talent i can be denoted as</p><formula xml:id="formula_0">F i = {F i1 , F i2 , ... , F iT i }.</formula><p>All the features can be classified into two types, i.e., static and time-varying features. Static features keep unchangeable throughout the whole career path. On the opposite, time-varying features would have different values over different time periods. For better usability, we first transform the original heterogeneous features into vectors using the preprocessing methods that will be introduced in Section 4.1. Then we concatenate the static and time-varying features to form the complete feature vector F it ? R r for each job record in the career path.</p><p>With the setup stated above, more formally, we define the prediction problem as follows: Definition 2.1. (Career Trajectory Prediction Problem.) Given a sequence of job records S i for talent i, along with the corresponding feature sequence F i and length T i , our goal is to predict the next job transition for talent i, including company C i,T i +1 , position P i,T i +1 , and duration D i,T i .   </p><formula xml:id="formula_1">F 0 i h 1 i h 2 i h i i T h , 1 i t C + , 1 i t P + 0 i d 1 i d , -1 i i T d 0 i D 1 i D , 1 i i T D - , i t D it d it d k q 0 i s 1 i s 1 , i i T s - 1 i F 2 i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Solution overview</head><p>In this subsection, we will give an overview of our proposed TACTP Framework. As introduced in Section 2.2, TACTP aims to jointly make predictions on three different tasks: (1) find the most likely company for job-hopping; (2) identify the next job position; and (3) forecast the working duration for the current job. On one hand, the three prediction tasks are naturally closely related and mutually interacted in the real world. On the other hand, constructing a unified solution for the three tasks can help promote each other and obtain better understanding for the career trajectories. Consequently, it is improper to consider them separately. Along this line, we integrate the three prediction tasks in this paper. In TACTP, we employ the idea of latent factor based collaborative filtering <ref type="bibr" target="#b13">[15]</ref> to factorize the job sequence records into latent vectors in a shared low-rank space. Specifically, TACTP could be divided into two stages, namely modeling stage and prediction stage. First, the modeling stage jointly constructs deep understandings for talent, company, position, and time factors. As illustrated in Figure <ref type="figure" target="#fig_5">3</ref>, career modeling process can be further classified into three parts: 1. Temporal encoding, which transforms the raw time values into latent continuous space and combines them with input talents' features by an adaptive time perception layer; 2. Sequential modeling, which produces dynamic talent profiling information; and 3. Embedding networks, which maps the talent states to latent vectors. Prediction process aims to predict the three key elements (company, position, and timing) concurrently. Besides, we also learn the dynamic latent company representations from company embedding networks and latent position representations from Gaussian priors. Finally, we combine these latent vectors to produce the predictions for the three tasks in the prediction stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TECHNICAL DETAILS OF TACTP FRAMEWORK</head><p>In this section, we will present all the technical details of TACTP, including the modeling stage, the prediction stage, and the final comprehensive optimization objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Career sequential modeling</head><p>The goal of the career sequential modeling process is to model the individual career path of each talent. As shown in Figure <ref type="figure" target="#fig_5">3</ref>, given the input features F i = {F i1 , F i2 , ... , F iT i } and time vectors {d i0 , d i1 , ... , d i,T i -1 }, we want to learn the latent talent state h i t automatically for the i-th talent.</p><p>3.1.1 Temporal encoding. Time factor is quite important when talents make their choices on the job transition <ref type="bibr" target="#b45">[47]</ref>. Generally, there are two types of temporal information playing influential roles in managing career paths. First is the working durations of past jobs, since historical working experiences will produce a sustainable influence on talents <ref type="bibr" target="#b32">[34]</ref>. Career management researches have shown that historical working experience will produce a sustainable influence on their future career development <ref type="bibr" target="#b32">[34]</ref>. Second, how long the talent stay in the current job also has a massive impact on career movement. As a result, we have to carefully consider the past time factor in the modeling stage and the current time factor in the prediction stage for generating time-aware predictions. Since the working durations are variable intervals, it is a great challenge to figure out their influences on job transitions.</p><p>To achieve this goal, we propose a general temporal encoding mechanism for capturing and exploiting the time factor in both modeling and prediction stage. In this paper, we focus on the career trajectory prediction tasks. However, this paradigm can be easily extended to other time sequential modeling problems with variable intervals. Specifically, we first transform the discrete time values into the continuous input embeddings for better usage in deep neural networks. Then, we design an adaptive time perception layer to transform the original time representations into individually customized time-aware representations.</p><p>Intuitively, the obtained latent representations from temporal encoding have to keep both the relative and absolute relations among original time values. For example, the representation of 5 years should be similar to 4 and 6 years while far away from 1 and 9 years. Here we introduce two implementations for deriving continuous time representations, namely manually specified approach and jointly learning approach.</p><p>Manually specified approach. To avoid increasing model complexity, manually specified approach chooses to utilize predetermined representations as the embedding results. In other words, the latent time representations are artificially designed and would not change during the model training. There are many workable choices for deciding the time representations <ref type="bibr" target="#b6">[8]</ref>. In this paper, we draw the approach of positional encoding employed in the wellknown sequential model, Transformers <ref type="bibr" target="#b41">[43]</ref>, to use sine and cosine functions with different frequencies for the vector d it :</p><formula xml:id="formula_2">d (2j) it = sin(D it /10000 2j/r ), d (2j+1) it = cos(D it /10000 2j/r ),<label>(1) where d (j)</label></formula><p>it means the j-th dimension of d it . r is the dimension of d it , which is the same as the feature vector F it . Equation 1 has shown its effectiveness in NLP field for measuring spatial distance information. Here we can similarly exploit Equation 1 for measuring temporal distance information.</p><p>Jointly learning approach. Since the artificially designed representations may not accord with the practical relative and absolute relations of different time values, jointly learning approach chooses to learn the latent representations through the model learning. Specifically, we first randomly initialize the latent time vector for all the feasible time values in the dataset (or initialize with the values in manually specified approach). Thus according to the value of working duration D it , we can assign the corresponding time vector d it to the t-th working experience of talent i. Then the values of time vectors will be updated after each training batch. In this way, we can learn the relations among different time values by exploring real historical job records. We will further compare the performances of these two approaches in the experiments.</p><p>After getting the time representations, we need to combine them with the user information in the input feature vector F it and time vector d i,t -1 for producing time-aware input F it at each time point. A direct way is to combine these two vectors by the concatenation operation, which is a common treatment for integrating information in deep learning methods:</p><formula xml:id="formula_3">F it = F it ? d i,t -1 , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where ? is the concatenation operation. We can observe that the time vector d i,t in Equation 2 only depends on the working duration D i,t . Thus, it would result in the invariant temporal information for a fixed input duration even when we change the user experience features. However, the timing of job-hopping for a talent is largely depend on the current job status in practice. For example, talents in Internet companies tend to have more frequent career transitions and less working duration for each job. Moreover, even the same duration would naturally carry distinct meanings for talents with different working seniorities. Hence, in order to comprehensively measure the influence of temporal information with different job status and seniorities, we design an adaptive time perception layer to obtain individually customized time-aware representations.</p><formula xml:id="formula_5">, 1 i t d - , 1 i t s - , 1 i t F - kernel F W , 1 ' i t d - , 1 i t d - kernel S W kernel d W , 1 i t d - , 1 i t F - , 1 i t F -</formula><p>Time perception layer. The time perception layer takes three input vectors F it , d i,t -1 , and s i,t -1 , representing a talent's current job information, working duration, and seniority, respectively. Here the seniority before the t-th job record is defined as the sum of working durations of the past t -1 jobs for each talent. Then we can easily obtain the seniority vector s i,t -1 by the introduced manually specified approach or jointly learning approach.</p><p>As shown in Figure <ref type="figure" target="#fig_6">4</ref>, we first transform the input feature vector F it through a nonlinear function and then let it interacts with the duration vector d i,t -1 to analyze the influence from job status:</p><formula xml:id="formula_6">d ? i,t -1 = f F (W F F it + b F ) + d i,t -1 ,<label>(3)</label></formula><p>where f F is a chosen nonlinearity, such as tanh function. W F is a learned kernel and b F is a bias term. Further, we project the influence of two time vectors d i,t -1 and s i,t -1 onto a shared latent space by two linear functions:</p><formula xml:id="formula_7">d i,t -1 = W d d ? i,t -1 + W s s i,t -1 ,<label>(4)</label></formula><p>where W d ,W s are learned kernels. Intuitively, the learned kernels would be trained to adapt the varying time scales and job experience of talents for mining the influence of temporal information on job-hopping. By comparison, d i,t -1 only contains general time information while d i,t -1 integrates personal experiences with the duration vector. Finally, we combine the individually customized time vector d i,t -1 with the primary input features and duration vectors to form the final input vector:</p><formula xml:id="formula_8">F it = F it ? d i,t -1 ? d i,t -1 .<label>(5)</label></formula><p>In this way, we can obtain the time-aware inputs, which reflect the influence of time factor in the modeling stage. We found the temporal encoding mechanism performs well across the three targeted prediction tasks. A similar temporal encoding process will also be used in the prediction stage with a little modification. We will discuss this later in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Sequential modeling.</head><p>With the input vector sequence described above, we then incorporate recurrent networks to track the dynamics of talent states. We can apply many workable network architectures to TACTP framework, such as Recurrent Neural Network (RNN) <ref type="bibr" target="#b10">[12]</ref>, Long Short-Term Memory (LSTM) <ref type="bibr" target="#b7">[9]</ref> and Gated Recurrent Unit (GRU) <ref type="bibr" target="#b3">[5]</ref>.</p><p>Let us take LSTM as an example to introduce the modeling process. As introduced in section 2.2, each input feature F it is the concatenation of static and time-varying features. The static features are all the same for ?t. Thus given the static features F is of talent i, we first employ a single hidden layer to get the initial hidden cell h i 0 of the recurrent network. Then given the time-aware input feature F it for the t-th job, (t -1)-th neural cell c i t -1 and (t -1)-th hidden state h i t -1 , we can obtain the t-th hidden state by</p><formula xml:id="formula_9">h i t = LST M( F it , c i t -1 , h i t -1 ).<label>(6)</label></formula><p>Notice that h i t is not only decided by the current state of talent i, but also the historical working experience. When using RNN or GRU for TACTP framework, the modeling process is analogous.</p><p>Finally, we adopt the dropout layer to randomly drop out the state h i t . In this way, the networks would receive different incomplete inputs for follow-up tasks in each training epoch. Thus, the dropout strategy can improve the robustness and generality of TACTP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Career embedding networks</head><p>Since the obtained latent talent vectors are synthetical representations, we need to further specify the talent states from different perspectives. Specifically, there are three primary perspectives related to career trajectory prediction problems, i.e., company, position, and time.</p><p>From the company perspective, we can use an embedding network to transform the talent representation h i t into the talentcompany vector u it . We choose the multi-layer perception (MLP) networks as the embedding networks. Thus, we have:</p><formula xml:id="formula_10">? 1 = f 1 (W 1 h i t + b 1 ), ? t = f t (W t ? t -1 + b t ), t ? [2, n -1], u it = f n (W n ? n-1 + b n ),<label>(7)</label></formula><p>where ? t is the t-th hidden layer with weight matrix W t and bias term b t . For the activation function f t (?), we employ the sigmoid function for the first n -1 layers and the tanh function for the last layer. Usually in practice, 2-layer MLP has been good enough for generating high-quality embeddings.</p><p>Here, we let the embedding networks at different time points share the same weights. This is because we assume the talent representations are independent of time so that similar talent representations would result in similar talent-company vectors at any time point. Such treatment also helps reduce model complexity and prevent over-fitting. Similarly to talent-company vector, we also gain the latent talent-position vector w it and talent-time vector x it from position and time perspectives, respectively. The network architectures are the same as talent-company embedding network and the only difference is the parameters of embedding networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Company and position modeling</head><p>After modeling talents, we then need to construct the latent company and position vectors for utilizing collaborative filtering.</p><p>The latent talent vectors are not only influenced by the current job but also the past working experience. Consequently, we build a sequential modeling process for users. On the contrary, since company properties can be essentially represented by the current state without the need for historical states, we can directly use a shared embedding network to transform the features of the j-th company into latent company vector v jt for all the time periods. Considering company features contain both static and time-varying features about the company, we are able to learn the time-aware representations in different periods. The network architectures are similar to Equation <ref type="formula" target="#formula_10">7</ref>.</p><p>Different from the company perspective, the states of positions are much more steady and usually not vary with time. Thus we can employ time-independent latent position vectors for all time periods. In detail, we denote q k as the latent position vector and then the prior probability over q k is assumed to be the normal distribution as follows:</p><formula xml:id="formula_11">p(q k ) ? N (0, ? -1 I ), (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where ? is the regularization parameter. q k will be updated by the gradients after each training batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Prediction stage</head><p>In the prediction stage, we finally combine the above discussed latent factors to produce the final prediction results for timing, company, and position, respectively. For predicting the working duration of the current job, we can use a single hidden layer to transform x it into the prediction di,t , which is equal to the Logistic Regression. Here we suggest normalizing the original time values into the range (0, 1) to make the model more robust. Thus the loss function for working duration prediction can be given by:</p><formula xml:id="formula_13">L d = i,t 1 2 ( di,t -d i,t ) 2 .<label>(9)</label></formula><p>For predicting the next company of talents, we first need to inject temporal information of the current job into talent-company vectors, since the time factor is an important decisive force for career movement. We also use 1-layer MLP G(?) to transform the time vector into the same space of talent vectors :</p><formula xml:id="formula_14">G(d it ) = W d it + b, G(s it ) = W s it + b, (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>where W is the weight matrix and b is the bias term. Then we can adopt the time perception layer to obtain the time-aware talent vector u it . There are some differences between the time perception layer in modeling stage and prediction stage. Firstly, the three input vectors u it , G(d it ), and G(s it ) in prediction stage are in the lowrank latent space while F it , d i,t -1 , and s i,t -1 in modeling stage are in the feature space. Besides, in order to ensure the consistency in the dimension of latent space, we choose to add the concatenation of two latent time vectors to the talent vector u it :</p><formula xml:id="formula_16">G(d it ) = W ?d (f u (W u u it ) + G(d it )) + W ?s G(s it ), u it = u it + G(d it ) ? G(d it ),<label>(11)</label></formula><p>where the dimensions of both G(d it ) and G(d it ) are equal to half of the dimension of u it . In this way, the obtained vector u it would contain both the talent interest and temporal information. Notice that in the training process, we input the time vector d it according to the real working duration D it . Differently, in the prediction process, we can input varying duration values instead of the real working duration to gain different time-aware talent vectors. This is especially important when we do not know the ground truth of the duration of current job. A natural approach is to input our predicted working duration. Talents can also assign the user-specific working durations by themselves in practice.</p><p>Afterwards, we adopt collaborative filtering to get the final job transition probability y i,t +1 :</p><formula xml:id="formula_17">y i,t +1 = so f tmax(v T t u it ), (<label>12</label></formula><formula xml:id="formula_18">)</formula><p>where n is the number of companies and v t = {v 1t , v 2t , ..., v nt } is the latent company matrix for the time point of the t-th job. so f tmax(?) is the softmax function. Hence the j-th dimension of y i,t +1 represents the job transition probability to the j-th company.</p><p>Let o it ? R n denote the one-hot embedding of company C it . Thus the C it -th dimension of o it is equal to 1 and otherwise 0. The loss function for next company prediction can be given by the cross-entropy form:</p><formula xml:id="formula_19">L c = - i,t o i,t +1 log(y i,t +1 ).<label>(13)</label></formula><p>For predicting the next position of talents, the prediction process is the same as predicting the next company. Thus we can similarly calculate the loss function L p for the next position prediction.</p><p>We also add the regularization term to prevent model from overfitting problem:</p><formula xml:id="formula_20">L r = i,t, j,k 1 2 (?u it ? 2 + ?w it ? 2 + ?v jt ? 2 + ?q k ? 2 ).<label>(14)</label></formula><p>Finally, we have the whole objective function as follows:</p><formula xml:id="formula_21">L = L c + ?L d + ?L p + ?L r ,<label>(15)</label></formula><p>where ?, ? and ? are hyper-parameters for balancing the different parts in the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we will demonstrate the effectiveness of our proposed TACTP framework from the following aspects: (1) the overall prediction performance compared with state-of-the-art baselines on the three targeted prediction tasks; (2) the analysis on temporal encoding;</p><p>(3) the model robustness evaluation; and (4) the analysis on latent company and position vectors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data pre-processing</head><p>In this subsection, we introduce how to standardize the input features. The description of all the utilized features is given in Table <ref type="table" target="#tab_1">2</ref>.</p><p>All the features could be classified into three categories (categorical, numerical, and textual data) according to the data forms. For categorical features, we first used one-hot encoding to obtain the vector representations. Then we further employed a single layer MLP to reduce the high-dimension features. For numerical time values, following the settings in <ref type="bibr" target="#b25">[27]</ref>, we set the time window as a half year and then segmented the time periods. In this way, the value of working durations and working seniorities could be presented as integers. For instance, 3 years and 9 months would be transformed into time value 8 since there are 8 half-years. We set the maximum time value as 21 for the working duration, which means all the working durations larger than 10 years were classified into one category. Then we used the introduced temporal encoding mechanism to further obtain the final time embedding. Meanwhile, we also utilized a single layer MLP to reduce the dimensions of numerical talent flow in/out/transfer ratios. Lastly, for textual data such as self-introduction and company description, we adopt the well-known text processing method, wold2vec <ref type="bibr" target="#b33">[35]</ref>, to transform the raw text into vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental settings</head><p>Dataset. In our dataset, the time span of the career path data ranges from 1988.1 to 2018.11. We first remove the companies with very few job records. Then we filtered out the users with less than four job records. After data filtering, the statistical information of the dataset is presented in Table <ref type="table" target="#tab_0">1</ref>. Specifically, in our experiments, we randomly sampled 80%/10%/10% users and their career paths to construct the training/validation/test set. In this way, we randomly Baseline approaches. To verify the effectiveness of TACTP, we compare it with some state-of-the-art baseline methods. Specifically, non-sequential models contain Logistic Regression (LR), Random Forest (RF), and Gradient Boosting Decision Tree (GBDT). Sequential models contain Conditional Random Field (CRF) <ref type="bibr" target="#b14">[16]</ref>, Continuous Time Markov Chain (CTMC) <ref type="bibr" target="#b0">[2]</ref>, HCPNN <ref type="bibr" target="#b25">[27]</ref> and NEMO <ref type="bibr" target="#b17">[19]</ref>. HCPNN and NEMO are the most advanced and relevant career trajectory prediction methods, which are both based on LSTM models. The original HCPNN model cannot predict the positions of talents. We modify HCPNN by replacing the input companies with positions and deleting the position embeddings in original model.</p><p>Then we can train a new modified HCPNN model to predict the next positions. For predicting the timing, baselines also include the stochastic time series models, such as Poisson Process (PP) <ref type="bibr" target="#b12">[14]</ref> and Multi-variable Hawkes Process (MHP) <ref type="bibr" target="#b24">[26]</ref>. TACTP (RNN), TACTP (GRU), and TACTP (LSTM) are the three different implementations of TACTP framework using RNN, GRU, and LSTM as the recurrent network architectures, respectively. TACTP-P (LSTM) is a variant of TACTP (LSTM) where we input the predicted working durations instead of the real working durations in the prediction stage. Evaluation metrics. To evaluate the performance of next company and position predictions, we adopted two widely used evaluation metrics, i.e., accuracy@K (Acc@K) and mean reciprocal rank (MRR). Acc@K counts the ratio that correctly predicted results are in talents' top-K items. Specifically, we calculated it by Acc@K = 1 N N l =1 I (r (l) ? K), where r (l) denotes the rank of the l-th predicted item and N is the number of predicted items. I (?) is the indicator function. Here we chose K = 1, 15, 30 for company prediction and K = 1, 2, 3 for position prediction. MRR measures the rank of the prediction items, i.e., MRR= 1</p><formula xml:id="formula_22">N N l =1 1 r (l )</formula><p>. For duration prediction, we adopted two widely used evaluation metrics, mean absolute error (MAE) and root mean square error (RMSE). Generally, the larger the values of Acc@K, MRR are, and the smaller the values of MAE, RMSE are, the better results we have.</p><p>Parameter settings. In our experiments, the dimensions of all the latent talent-company, talent-position, company, and position vectors were set as 150. Accordingly, we chose talent-company, talent-position and company embedding networks in TACTP as 2-layer MLPs with dimensions 100 ? 150. Meanwhile, the dimension of talent-time vector was set as 50 and the time embedding network was set as a 2-layer MLP with dimensions 50 ? 50. Besides, we chose the jointly learning approach for combining input features with time vectors in the overall prediction performance comparisons. Then we tuned the values of hyper-parameters ? in [1, 2, ..., 10], ? in [0.1, 0.2, ..., 1], and ? in [0.0, 0.01, ..., 0.1]. The dropout ratio was set as 0.99. Finally, we performed Adam algorithm for optimization and tuned the learning rate from 0.0001 to 0.01. For all the baseline methods, we use the grid search to explore the parameters. Particularly, for the two LSTM based models, HCPNN and NEMO, we adopt the exactly same sizes with our TACTP model for their LSTM layers. Besides, for these two LSTM based models, we concatenated the time vectors with other feature embeddings, such as company and position vectors, to construct the network inputs. Here the time vectors were obtained just the same as the introduced jointly learning approach in our TACTP framework. Thus we can compare them with our models fairly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prediction performance comparison</head><p>We want to validate our proposed method on the three career trajectory prediction tasks: providing the right timing for job-hopping, identifying the right company for a job application, and matching the right position for the candidate. The overall prediction performance for three tasks is shown in Table <ref type="table" target="#tab_2">3</ref>.</p><p>First, for company prediction, it can be easily observed from Table 3 that TACTP significantly outperforms all the baselines, owing to the integration of sequential modeling and collaborative filtering. Specifically, TACTP (LSTM) outperforms the best baseline, NEMO, by the relative boost of 20.97%, 10.45%, 6.92%, and 15.18% for the metric ACC@1, ACC@15, ACC@30, and MRR, respectively. By comparison, HCPNN and NEMO are also LSTM based models, but they purely consider time as one of the fixed features and adopt a non-collaborative way for prediction. Differently, TACTP produces personalized time-aware prediction results and thus, achieves a large improvement to them in the variable interval time sequence tasks. Besides, we can observe that sequential models always have stronger modeling ability and perform better than non-sequential models, which demonstrates the necessity of sequential modeling again. As for the three implementations of TACTP, we can find that TACTP (LSTM) achieves the best result while TACTP (RNN) performs not well. This may be because LSTM model can largely alleviate the gradient vanish problem and is more suitable for variable interval time sequences than RNN and GRU. Finally, TACTP-P (LSTM) also produces similar results to TACTP (LSTM), which demonstrates that with the predicted working durations, our TACTP framework is still able to achieve comparable performance.</p><p>In practice, we can further employ TACTP framework for handling varying interval inputs. For position prediction, as shown in Table <ref type="table" target="#tab_2">3</ref>, TACTP (LSTM) achieves the best performance against all the baseline methods. Specifically, TACTP (LSTM) outperforms the best baseline, NEMO, by the relative boost of 2.30%, 1.99%, 1.68% and 1.61% for the metric ACC@1, ACC@15, ACC@30 and MRR, respectively. Similarly to the company prediction task, TACTP (LSTM) performs better than TACTP (RNN) and TACTP (GRU). We can observe that the absolute values of Acc and MRR in position prediction tasks are much larger than the company prediction task. This is because the number of companies is much larger than the number of positions. Thus it is much more difficult to provide precise predictions for companies than positions.</p><p>Lastly, for current job duration prediction, we can observe that our proposed TACTP models achieve the best performance in both evaluation metrics. Specifically, TACTP (LSTM) outperforms the best baseline, MHP, by the relative boost of 17.90% and 26.34% for the metric MAE and RMSE, respectively. We can find that the stochastic time series models, (PP and MHP) both have better performance than the other baseline approaches. However, with the help of deep sequential modeling and understanding of talents, TACTP can outperform them with a large margin. Different from company and position prediction tasks, the results among the three implementations of TACTP have no significant difference in duration prediction task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis on temporal encoding</head><p>In this subsection, we will discuss the different approaches for handling time factor vectors in our proposed TACTP framework.  Jointly learning approach  Specially, we compare the following variants and show the performance in Table <ref type="table" target="#tab_3">4</ref>: 1) All the three TACTP (M) variants adopts manually specified approach for temporal encoding while the three TACTP (J) variants adopt jointly learning approach; 2) TACTP-C (M) and TACTP-C (J) directly concatenate the talent representation with the working duration vector and seniority vector without time perception layer in both modeling and prediction stages; 3) TACTP-O (M) and TACTP-O (J) only exploit temporal information in modeling process but not prediction process, which means we directly use the latent talent vector u it for prediction instead of time-aware vector u it ; 4) TACTP-N ignores the temporal encoding mechanism and simply input the primary talent representations in both modeling and prediction stages.</p><p>First we can observe that TACTP-N performs worse than all the other variants, which clearly demonstrates the necessity of the temporal encoding mechanism. Moreover, TACTP-O (M) and TACTP-O (J) perform worse than TACTP (M) and TACTP (J), respectively. This demonstrates the importance of producing time-aware prediction results, but not just exploiting dynamic temporal information in the modeling stage. By comparing TACTP-C (M) and TACTP-C (J) with TACTP (M) and TACTP (J), we can easily observe the large performance boost by our designed time perception layer, which shows that the time perception layer can successfully capture the individually customized temporal information. Lastly, variants with jointly learning approach significantly outperform manually specified approach by large margins, implying that jointly learning approach could learn better representations for fitting the complex temporal information in real-world data.</p><p>To further show the differences between manually specified and jointly learning approaches, we present the heatmap of the Euclidean distances among the latent time vectors obtained by these two approaches. A unit of abscissa or ordinate in Figure <ref type="figure" target="#fig_8">5</ref> means a half-year. Here we only show the vectors representing no more than 10 years, since the great majority of working durations are less than 10 years in our dataset. We can easily find that the Euclidean distance between two time values in jointly learning approach changes more smoothly than manually specified approach. Interestingly, we can observe the sawtooth tendency for the Euclidean distances among the latent time vectors, that is to say, the latent time vectors in odd half-years tend to have smaller distances with other time vectors. This phenomenon is exactly in accord with Figure <ref type="figure" target="#fig_2">2(d)</ref>, which shows that talents change their jobs more frequently in the first half of a year than the second half of a year. Our jointly learning approach is capable of learning this tendency automatically from the real-world data while manually specified approach has no such property. In summary, jointly learning approach can produce more proper latent vectors and better prediction performance than manually specified approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis on latent position vectors</head><p>Our TACTP framework is able to learn a unique latent vector for each position. The larger similarity between two latent position vectors would imply more chances for talents to change their jobs between these two positions. Here we provide some cases to show the practical guiding significance of TACTP. Table <ref type="table" target="#tab_5">5</ref> shows the top 3 positively related and negatively related positions to the target position. For example, we can observe from Table <ref type="table" target="#tab_5">5</ref> that the positions with top 3 cosine similarities to "entrepreneurship" are "consulting", "finance", and "operation", while the positions with top 3 similarities from the bottom are "community and social services", "quality assurance", and "purchasing". Thus, if a talent wants to become an entrepreneur, she may first accumulate experiences in the related positions. Also, we can find that the most related position to "sale" is "market", since it is easy for talents to change their jobs between these two positions. Meanwhile, talents in "research", "legal", and "quality assurance" are not likely to transfer to "sale".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Analysis on latent company vectors</head><p>In this subsection, we provide an overall view of the companies in our dataset to show the interpretability of TACTP. The smaller distance between two latent company vectors indicate talent may be more likely to change their jobs between these two companies. We first performed k-means clustering <ref type="bibr" target="#b1">[3]</ref> to partition all the 1, 002 companies into 8 clusters according to their latent company vectors in the first half of 2017 obtained by TACTP. Then we utilize the t-SNE algorithm <ref type="bibr" target="#b23">[25]</ref> to transform the original 150-dimensional vector into a 2-dimensional space for visualization, as shown in Figure <ref type="figure" target="#fig_9">6</ref>. We can observe that cluster 3 and 4 are quite close. Actually, companies in these two clusters are all high-tech companies, such as Google, Apple, Microsoft, Facebook, and IBM. Moreover, cluster 5 and 8 are also very close to and interlocked with each other in the low-dimensional space. In fact, the companies in these two clusters are both relevant to energy and manufacturing industries. The difference is that clusters 5 contains more military and aviation companies, such as Lockheed Martin and Airbus, while clusters 8 contains more home appliance companies, such as Sony and Siemens. Besides, cluster 6, which is the biggest cluster, is composed of many retail and hospitality industries, such as Amazon, Best Buy, Hilton, 7-Eleven, McDonald's, and KFC. Differently, cluster 7, as the smallest and most concentrated cluster, mainly consists of healthcare, pharmaceutical, and biotechnology industries, such as Pfizer and Johnson &amp; Johnson. Lastly, in cluster 1 and cluster 2, the vast majority of companies belongs to banks, financial and insurance companies, such as JPMorgan Chase &amp; Co, BNP Paribas, Goldman Sachs, and AXA. To sum up, our TACTP framework is capable of capturing the attributes of different companies automatically, and the results can be used for guiding talents to find out the suitable career transitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>The related work can be classified into three main categories, i.e., career trajectory prediction, time sequential modeling, and collaborative filtering.</p><p>Career trajectory prediction. Career trajectory prediction is an important topic in human resource management <ref type="bibr" target="#b50">[52,</ref><ref type="bibr" target="#b51">53]</ref>. Traditional studies usually focused on the qualitative analysis <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b39">41]</ref>. In recent years, there is an increasing interest in applying machine learning solutions, especially deep learning methods, to career trajectory modeling. Many of them focused on the transitions of companies and positions. For example, Li et al. <ref type="bibr" target="#b17">[19]</ref> designed a recurrent neural network to predict the employee's next career move. Liu et al. <ref type="bibr" target="#b22">[24]</ref> utilized a multi-task learning model for predicting career paths while He et al. <ref type="bibr" target="#b8">[10]</ref> chose to predict job seekers' future job information by convolutional neural networks. Xu et al. <ref type="bibr" target="#b47">[49]</ref> developed a deep sequence career trajectory prediction model based on the recurrent neural network model to predict whether there is a job change in six months. Recently, Meng et al. <ref type="bibr" target="#b25">[27]</ref> predicted the next potential company and how long the talent will stay in the next job with an attention-based Long Short-Term Memory model. Besides the above works, there are also some researchers who tried to construct job recommender systems based on the prediction of career trajectories <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b49">51]</ref>. For example, Shalaby et al. <ref type="bibr" target="#b36">[38]</ref> used a graph-based approach for building an item-based job recommender system. Besides, some works took the employees' skills into considerations for better job recommendation <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b28">30]</ref>.</p><p>Different from the above works, we provide a unified solution for all three job recommendation tasks (i.e., the next company, position, and current working duration) by integrating sequential modeling and collaborative filtering methods.</p><p>Time sequential modeling. Time sequential modeling has achieved great success in a variety of applications, such as recommender system, events prediction, time-evolving graphs, and so on <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b30">32]</ref>. Early sequential prediction tasks focused on the sequential pattern mining <ref type="bibr" target="#b37">[39]</ref> and transition modeling <ref type="bibr" target="#b34">[36]</ref>. Since recurrent neural networks (RNNs) <ref type="bibr" target="#b10">[12]</ref> (e.g., the well-known Long Short-Term Memory (LSTM) <ref type="bibr" target="#b7">[9]</ref> and Gated Recurrent Unit (GRU) <ref type="bibr" target="#b3">[5]</ref>), have achieved great success on various sequential modeling tasks due to their superior performance, they are also widely applied in personalized prediction systems. One representative application is sequential recommendation, which is based on the sequential prediction task. For instance, Wang et al. <ref type="bibr" target="#b44">[46]</ref> modeled complicated interactions among multiple factors by using different aggregation operations over the representations. Quadrana et al. <ref type="bibr" target="#b31">[33]</ref> designed a hierarchical recurrent neural network with cross-session information transfer. Li et al. <ref type="bibr" target="#b19">[21]</ref> incorporated users' historical preferences and consumption motivations for next-item recommendation scenario.</p><p>While many current studies focus on sequences with fixed intervals <ref type="bibr" target="#b16">[18]</ref>, variable interval time sequences is still a great challenge, where the time intervals are different, and thus temporal information would be more influential in exploring the state changes at different time points and making next predictions. Quite recently, some works tried to capture the dynamic temporal information in the sequences. For example, Pavlovski et al. <ref type="bibr" target="#b29">[31]</ref> calculated a temporal score to measure the influence of irregular time intervals. Tan et al. <ref type="bibr" target="#b38">[40]</ref> designed a dual-attention GRU to handle the missing values in time intervals for patients. Li et al. <ref type="bibr" target="#b16">[18]</ref> chose to incorporate the time relation matrix into self-attention units. However, all of the above works just consider the dynamic temporal information in the modeling process but not the prediction process, and thus cannot handle the varying user status for the next prediction. In this paper, we design a general temporal encoding mechanism for both the modeling and prediction stages.</p><p>Collaborative filtering. Generally, collaborative filtering (CF) methods can be further divided into two classes, i.e., neighborhood based and latent factor based methods. Neighborhood based CF methods <ref type="bibr" target="#b35">[37]</ref> usually first search the nearest neighbors from the user or item aspect and then make recommendations according to the neighbors' records. By comparison, latent factor based CF methods choose to project users and items into latent factor space. For example, probabilistic matrix factorization <ref type="bibr" target="#b26">[28]</ref>, as one of the most widely used latent factor models, factorized the rating matrix into the product of user and item latent vectors in a low-rank space. Recently, many researchers began to combine neural networks with CF methods. For instance, He et al. <ref type="bibr" target="#b9">[11]</ref> leveraged a multi-layer perceptron to learn the user-item interaction function and Xue et al. <ref type="bibr" target="#b48">[50]</ref> designed an implementation of matrix factorization by using multi-layer perception networks. Moreover, Wang et al. <ref type="bibr" target="#b42">[44]</ref> and Li and She <ref type="bibr" target="#b18">[20]</ref> exploited the stacked denoising autoencoders and variational autoencoders for combining collaborative filtering with deep content embeddings.</p><p>Some researchers tried to combine neighborhood based CF methods with job recommender systems <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b49">51]</ref>. However, neighborhood based CF methods usually perform not well in sparse situations <ref type="bibr" target="#b13">[15]</ref>. In this paper, we incorporate the latent factor based CF method in our proposed framework for generating high-quality personalized recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we proposed a novel time-aware career trajectory prediction (TACTP) framework for jointly predicting the three key elements in career trajectory, i.e., timing, company, and position. A unique perspective of TACTP is that we can generate time-aware predictions according to the varying duration of the current job owing to our proposed temporal encoding mechanism. Specifically, we first developed a unified time-aware sequential model based on recurrent networks to map the heterogeneous inputs into latent factor vectors from time, company, and position perspectives for each talent. Then we combined the talent representations with company and position representations to make predictions by latent factor based collaborative filtering. Finally, we conducted extensive experiments on a large-scale real-world dataset to demonstrate the effectiveness of TACTP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A motivating example of career path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distributions of career trajectory records.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The network architectures of career modeling and prediction process in TACTP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The time perception layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Analysis on temporal encoding. The two figures present the Euclidean distances among the latent time vectors obtained by manually specified and jointly learning approaches, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The visualization of TACTP based company clustering. (The clusters are distinguished by different colors.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The statistical information of the dataset.</figDesc><table><row><cell>The number of total job records</cell><cell>1,872,624</cell></row><row><cell>The number of users</cell><cell>414, 266</cell></row><row><cell>The number of companies</cell><cell>1, 002</cell></row><row><cell>The number of positions</cell><cell>26</cell></row><row><cell>The mean value of the lengths of career paths</cell><cell>4.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The description of the features in our dataset.</figDesc><table><row><cell cols="2">Feature level Feature Type</cell><cell>Category</cell><cell>Feature</cell></row><row><cell></cell><cell></cell><cell cols="2">Categorical User ID</cell></row><row><cell>User</cell><cell>Static</cell><cell cols="2">Numerical Number of social connections Text Self-introduction</cell></row><row><cell></cell><cell cols="3">Time-varying Numerical working seniority</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Company ID</cell></row><row><cell></cell><cell>Static</cell><cell>Categorical</cell><cell>Company age Company type</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Company location</cell></row><row><cell>Company</cell><cell></cell><cell cols="2">Text Categorical Company size Company description</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Job duration</cell></row><row><cell></cell><cell>Time-varying</cell><cell>Numerical</cell><cell>Company flow in ratio Company flow out ratio</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Company flow transfer ratio</cell></row><row><cell>Position</cell><cell>Static</cell><cell cols="2">Categorical Position ID</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>The overall performance for next company prediction, next position prediction and current working duration prediction tasks. ("-" means the method is not suitable for this task.) five times and reported all the results by mean values. For each user, we validated the prediction performance of three tasks on every job record except for the first job.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Company</cell><cell></cell><cell></cell><cell cols="2">Position</cell><cell></cell><cell cols="2">Duration</cell></row><row><cell>Methods</cell><cell cols="10">Acc@1 Acc@15 Acc@30 MRR Acc@1 Acc@2 Acc@3 MRR MAE RMSE</cell></row><row><cell>PP</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">3.190 4.296</cell></row><row><cell>MHP</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">3.267 4.715</cell></row><row><cell>GBDT</cell><cell>0.022</cell><cell>0.196</cell><cell>0.320</cell><cell>0.075</cell><cell>0.212</cell><cell>0.327</cell><cell>0.413</cell><cell cols="3">0.369 3.992 5.471</cell></row><row><cell>RF</cell><cell>0.045</cell><cell>0.285</cell><cell>0.393</cell><cell>0.107</cell><cell>0.262</cell><cell>0.428</cell><cell>0.531</cell><cell cols="3">0.445 3.303 5.146</cell></row><row><cell>LR</cell><cell>0.055</cell><cell>0.317</cell><cell>0.425</cell><cell>0.123</cell><cell>0.341</cell><cell>0.494</cell><cell>0.596</cell><cell cols="3">0.511 3.226 4.994</cell></row><row><cell>CRF</cell><cell>0.058</cell><cell>0.336</cell><cell>0.453</cell><cell>0.129</cell><cell>0.344</cell><cell>0.459</cell><cell>0.537</cell><cell cols="3">0.491 3.277 5.091</cell></row><row><cell>CTMC</cell><cell>0.060</cell><cell>0.336</cell><cell>0.457</cell><cell>0.089</cell><cell>0.342</cell><cell>0.462</cell><cell>0.542</cell><cell cols="3">0.492 4.225 5.938</cell></row><row><cell>HCPNN</cell><cell>0.076</cell><cell>0.408</cell><cell>0.540</cell><cell>0.159</cell><cell>0.352</cell><cell>0.523</cell><cell cols="2">0.630, 0.528</cell><cell>-</cell><cell>-</cell></row><row><cell>NEMO</cell><cell>0.124</cell><cell>0.507</cell><cell>0.636</cell><cell>0.224</cell><cell>0.392</cell><cell>0.553</cell><cell cols="2">0.653, 0.559</cell><cell>-</cell><cell>-</cell></row><row><cell>TACTP (RNN)</cell><cell>0.104</cell><cell>0.481</cell><cell>0.612</cell><cell>0.200</cell><cell>0.390</cell><cell>0.551</cell><cell cols="4">0.652, 0.558 2.806 3.744</cell></row><row><cell>TACTP (GRU)</cell><cell>0.135</cell><cell>0.535</cell><cell>0.657</cell><cell>0.239</cell><cell>0.400</cell><cell>0.562</cell><cell cols="4">0.663, 0.555 2.771 3.752</cell></row><row><cell cols="2">TACTP-P (LSTM) 0.141</cell><cell>0.545</cell><cell>0.667</cell><cell>0.248</cell><cell>0.396</cell><cell>0.559</cell><cell cols="4">0.660, 0.564 3.761</cell></row><row><cell>TACTP (LSTM)</cell><cell>0.150</cell><cell>0.560</cell><cell>0.680</cell><cell cols="2">0.258 0.401</cell><cell>0.564</cell><cell cols="4">0.664 0.568 2.774 3.732</cell></row><row><cell>split each dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The performance of different ways for handling temporal information in TACTP framework.</figDesc><table><row><cell></cell><cell>Company</cell><cell>Position</cell><cell>Duration</cell></row><row><cell></cell><cell cols="2">Acc@1 MRR Acc@1 MRR</cell><cell>MAE</cell></row><row><cell>TACTP-N</cell><cell cols="2">0.117 0.217 0.390 0.552</cell><cell>2.788</cell></row><row><cell>TACTP-C (M)</cell><cell cols="2">0.123 0.223 0.394 0.562</cell><cell>2.785</cell></row><row><cell cols="3">TACTP-O (M) 0.127 0.230 0.396 0.563</cell><cell>2.786</cell></row><row><cell>TACTP (M)</cell><cell cols="2">0.134 0.240 0.398 0.566</cell><cell>2.781</cell></row><row><cell>TACTP-C (J)</cell><cell cols="2">0.134 0.235 0.397 0.564</cell><cell>2.775</cell></row><row><cell>TACTP-O (J)</cell><cell cols="2">0.138 0.241 0.392 0.560</cell><cell>2.777</cell></row><row><cell>TACTP (J)</cell><cell cols="2">0.150 0.258 0.401 0.568</cell><cell>2.774</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Analysis on position vectors obtained by TACTP. The values in the brackets are the cosine similarities between the latent vectors of the given position and the target position.</figDesc><table><row><cell>Target position</cell><cell></cell><cell>Positions and cosine similarities</cell><cell></cell></row><row><cell>entrepreneurship</cell><cell cols="2">consulting (0.2432) community and social services (-0.1894) quality assurance (-0.1797) finance (0.2288)</cell><cell>operation (0.2009) purchasing (-0.1686)</cell></row><row><cell>sale</cell><cell>market (0.2403) quality assurance (-0.2647)</cell><cell>accounting (0.2182) legal (-0.2531)</cell><cell>operation (0.2102) research (-0.1765)</cell></row><row><cell>program and project management</cell><cell>consulting (0.5006) health-care services (-0.3719)</cell><cell>engineering (0.3857) real estate (-0.3551)</cell><cell>business development (0.3695) legal (-0.2998)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This research was supported by grants from the <rs type="funder">National Natural Science Foundation of China</rs> (No.<rs type="grantNumber">61836013</rs>, <rs type="grantNumber">91746301</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_a75Jwns">
					<idno type="grant-number">61836013</idno>
				</org>
				<org type="funding" xml:id="_qPtWJc4">
					<idno type="grant-number">91746301</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Continuous-time Markov chains: An applicationsoriented approach</title>
		<author>
			<persName><forename type="first">Anderson</forename><surname>William</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2007. k-means++: The advantages of careful seeding</title>
		<author>
			<persName><forename type="first">David</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms</title>
		<meeting>the eighteenth annual ACM-SIAM symposium on Discrete algorithms</meeting>
		<imprint>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tree-Based Contextual Learning for Online Job or Candidate Recommendation With Big Data Support in Professional Social Networks</title>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaokang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menglan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kehao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dapeng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="77725" to="77739" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A combined representation learning approach for better job and skill recommendation</title>
		<author>
			<persName><forename type="first">Baichuan</forename><surname>Vachik S Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalifeh</forename><surname>Al Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Aljadda</surname></persName>
		</author>
		<author>
			<persName><surname>Korayem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="1997">2018. 1997-2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Competing on talent analytics</title>
		<author>
			<persName><forename type="first">Jeanne</forename><surname>Thomas H Davenport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard business review</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="52" to="58" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional sequence to sequence learning</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE international conference on acoustics, speech and signal processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Career Trajectory Prediction based on CNN</title>
		<author>
			<persName><forename type="first">Dayong</forename><surname>Miao He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanyuan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renjie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongshan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="22" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the national academy of sciences</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
			<date type="published" when="1982">1982. 1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Estimating the days to success of campaigns in crowdfunding: A deep survival perspective</title>
		<author>
			<persName><forename type="first">Binbin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongke</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4023" to="4030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Point processes and their statistical inference</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Karr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
		<title level="m">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting Path Failure In Time-Evolving Graphs</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lujia</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1279" to="1289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Time Interval Aware Self-Attention for Sequential Recommendation</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nemo: Next career move prediction with contextual embedding</title>
		<author>
			<persName><forename type="first">Liangyue</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">How</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bee-Chung</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
		<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="505" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Collaborative variational autoencoder for recommender systems</title>
		<author>
			<persName><forename type="first">Xiaopeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>She</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="305" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning from history and present: Next-item recommendation via discriminatively exploiting user behaviors</title>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongke</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1734" to="1743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Temporal learning and sequence modeling for a job recommender system</title>
		<author>
			<persName><forename type="first">Kuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linhong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Recommender Systems Challenge</title>
		<meeting>the Recommender Systems Challenge</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical similarity based job recommendation service framework for university students</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenge</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanxin</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Computer Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="912" to="922" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fortune teller: predicting your career path</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">S</forename><surname>Rosenblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008. 2008</date>
			<pubPlace>Nov</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The neural hawkes process: A neurally self-modulating multivariate point process</title>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6754" to="6764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Hierarchical Career-Path-Aware Neural Network for Job Mobility Prediction</title>
		<author>
			<persName><forename type="first">Qingxin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keli</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="14" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Machine learned job recommendation</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Paparrizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barla Cambazoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aristides</forename><surname>Gionis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM Conference on Recommender Systems</title>
		<meeting>the fifth ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="325" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">CaPaR: a career path recommendation framework</title>
		<author>
			<persName><forename type="first">Bharat</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Kakuste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalini</forename><surname>Eirinaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Third International Conference on Big Data Computing Service and Applications (BigDataService)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Time-Aware User Embeddings as a Service</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Pavlovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Gligorijevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Stojkovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shabhareesh</forename><surname>Komirishetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djordje</forename><surname>Gligorijevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narayan</forename><surname>Bhamidipati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoran</forename><surname>Obradovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3194" to="3202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging</title>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Perslev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sune</forename><surname>Darkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Poul</forename><forename type="middle">J?rgen</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4417" to="4428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Personalizing session-based recommendations with hierarchical recurrent neural networks</title>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bal?zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Cremonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Toward an integrated model of intrinsic motivation and career self-management</title>
		<author>
			<persName><forename type="first">R</forename><surname>Narda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><forename type="middle">G</forename><surname>Quigley</surname></persName>
		</author>
		<author>
			<persName><surname>Tymon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Career development international</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Software framework for topic modelling with large corpora</title>
		<author>
			<persName><forename type="first">Radim</forename><surname>Rehurek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on World Wide Web</title>
		<meeting>the 10th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Help me find a job: A graph-based approach for job recommendation at scale</title>
		<author>
			<persName><forename type="first">Walid</forename><surname>Shalaby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bahaaeddin</forename><surname>Alaila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Korayem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Layla</forename><surname>Pournajaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalifeh</forename><surname>Aljadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename><surname>Quinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wlodek</forename><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1544" to="1553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Personalized trajectory matching in spatial networks</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruogu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="449" to="468" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DATA-GRU: Dual-Attention Time-Aware Gated Recurrent Unit for Irregular Multivariate Time Series</title>
		<author>
			<persName><forename type="first">Qingxiong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoyao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><forename type="middle">Jinhua</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Cheuk-Fung Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Hung</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pongchi</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="930" to="937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Global talent management: Literature review, integrative framework, and suggestions for further research</title>
		<author>
			<persName><forename type="first">Ibraiz</forename><surname>Tarique</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Randall</forename><forename type="middle">S</forename><surname>Schuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of world business</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="122" to="133" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Exploiting the Contagious Effect for Employee Turnover Prediction</title>
		<author>
			<persName><forename type="first">Mingfei</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The analysis and design of the job recommendation model based on GBRT and time factors</title>
		<author>
			<persName><forename type="first">Pengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Knowledge Engineering and Applications (ICKEA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="29" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning hierarchical representation model for nextbasket recommendation</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Career self-management as a key factor for career wellbeing</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hirschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory, Research and Dynamics of Career Wellbeing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="117" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning career mobility and human activity patterns for job change analysis</title>
		<author>
			<persName><forename type="first">Huang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1057" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dynamic talent flow analysis with deep sequence prediction modeling</title>
		<author>
			<persName><forename type="first">Huang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiwen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1926" to="1939" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep Matrix Factorization Models for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hong-Jian</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3203" to="3209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Combining content-based and collaborative filtering for job recommendation system: A cost-sensitive Statistical Relational Learning approach</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Korayem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalifeh</forename><surname>Aljadda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trey</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriraam</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Job2Vec: Job title benchmarking with collective multi-view representation learning</title>
		<author>
			<persName><forename type="first">Denghui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2763" to="2771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Large-Scale Talent Flow Forecast with Dynamic Latent Factor Model?</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2312" to="2322" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
