<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deterministic single exponential time algorithms for connectivity problems parameterized by treewidth ✩</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hans</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
							<email>h.l.bodlaender@uu.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marek</forename><surname>Cygan</surname></persName>
							<email>cygan@mimuw.edu.pl</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="institution">University of Warsaw</orgName>
								<address>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stefan</forename><surname>Kratsch</surname></persName>
							<email>stefan.kratsch@tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jesper</forename><surname>Nederlof</surname></persName>
							<email>jespernederlof@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deterministic single exponential time algorithms for connectivity problems parameterized by treewidth ✩</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8EE92F647BCD8F483CDB1802FDD7036C</idno>
					<idno type="DOI">10.1016/j.ic.2014.12.008</idno>
					<note type="submission">Received 1 September 2013</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information and Computation</head><p>Contents lists available at ScienceDirect</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The notion of treewidth proved to be an excellent tool for dealing with many NP-hard problems on graphs. In the 1970s and 1980s, several groups of researchers discovered the concept independently. In their fundamental work on graph minors, Robertson and Seymour <ref type="bibr" target="#b1">[2]</ref> introduced the notions treewidth and tree decomposition, and these became the dominant ✩ A preliminary version of this work appeared at ICALP 2013 <ref type="bibr" target="#b0">[1]</ref>. The second author was partially supported by NCN DEC-2012/05/D/ST6/03214 and Foundation for Polish Science. The third author was supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO), project: 'KERNELS'. The fourth author was supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO), project: 'Space and Time Efficient Structural Improvements of Dynamic Programming Algorithms'.</p><p>terminology. The notion has been extensively studied and used in various areas of (theoretical and applied) computer science (see for example <ref type="bibr" target="#b2">[3]</ref> for a survey). Informally, the notion measures how well a graph can be decomposed in a tree-like manner, resulting in a so-called tree decomposition. This is useful since many efficient algorithms solving NP-hard problems on trees generalize to efficient algorithms for graphs with good tree decompositions. Almost without exception these algorithms crucially rely on the dynamic programming paradigm, so studying the complexity of problems on graphs of small treewidth amounts to studying the dynamic programming paradigm.</p><p>Two influential results are Bodlaender's <ref type="bibr" target="#b3">[4]</ref> and Courcelle's theorems <ref type="bibr" target="#b4">[5]</ref>, showing that if we assume that input graphs have bounded treewidth, then there are linear time algorithms to find an optimal tree decomposition and for each property that can be expressed in monadic second order logic, given such a tree decomposition, to decide if the property holds for the input graph. Algorithmic engineering evaluations of Bodlaender's and Courcelle's algorithms are not encouraging however, due to the large constant factors in the running times, even for small values of the treewidth, e.g., the running time of Bodlaender's algorithm is O(tw O(tw 3 ) n).</p><p>Hence a natural question is how much we can optimize the dependence on the treewidth, that is, we aim for a running time of the type f (tw)n c on graphs with n vertices and a tree decomposition of width tw of where we first aim at obtaining a small growing (but, since we assume P = NP, exponential) function f (tw) and second a small exponent c. For problems with locally checkable certificates, that is, certificates assigning a constant number of bits per node that can be checked by a cardinality check and iteratively looking at all neighborhoods of the input graph, 1 it quickly became clear that f (tw) only needs to be single exponential. See <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> for sample applications to the Independent Set/Vertex Cover problems.</p><p>From the work of <ref type="bibr" target="#b7">[8]</ref> and known Karp-reductions between problems it follows that this dependence cannot be improved to subexponential algorithms unless the Exponential Time Hypothesis (ETH) fails, i.e., unless CNF-SAT has a subexponential algorithm. In <ref type="bibr" target="#b8">[9]</ref> it was shown that under a stronger assumption (the so-called Strong Exponential Time Hypothesis, SETH), the current algorithms are optimal even with respect to polynomial jumps, that is, problems with current best running time f (tw)n O (1) cannot be solved in f (tw) 1-n O (1) for positive where f (tw) is 2 tw , 3 tw for respectively Independent Set and Dominating Set. While there is no consensus opinion on whether ETH and SETH are true, improving beyond lower bounds proven under either of them is at least as hard as improving the state of the art of CNF-SAT in the respective way.</p><p>A natural class of problems that does not have locally checkable certificates are connectivity problems such as Hamiltonian Cycle and Steiner Tree (see for example <ref type="bibr" target="#b9">[10,</ref><ref type="bibr">Section 5]</ref>), begging the question whether these can be solved within single exponential dependence on tw as well. Early work shows that if we assume, in addition to small treewidth, that the input graph is planar, or, more general, avoids a minor, then many connectivity problems have algorithms with single exponential dependence of tw, exploiting Catalan structures <ref type="bibr" target="#b10">[11]</ref>. A positive answer to the question, using a randomized approach termed "Cut &amp; Count", was found by Cygan et al. <ref type="bibr" target="#b11">[12]</ref>: It provided a transformation of the natural certificates to "cut-certificates" transforming the connectivity requirement into a locally checkable requirement. The transformation is only valid modulo 2, but by a standard technique <ref type="bibr" target="#b12">[13]</ref> introducing randomization, the decision variant can be reduced to the counting modulo 2 variant. This result was considered surprising since in the folklore 2 O(tw log tw) n O (1) dynamic programming routines for connectivity problems all information stored seemed needed: Given two partial solutions inducing different connectivity properties, one may very well be extendable to a solution while the other one is not (this resembles the notion of Myhill-Nerode equivalence classes <ref type="bibr" target="#b13">[14]</ref>).</p><p>The Cut &amp; Count approach is one of the algorithms from the family of dynamic programming based algorithms using a modulo 2 based transformation <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. These algorithms give the smallest running times currently known, but have several disadvantages compared to traditional dynamic programming algorithms: (a) They are probabilistic. (b) The dependence on the inputs weights in weighted extensions is pseudo-polynomial. (c) They do not extend to counting the number of witnesses. (d) They do not give intuition for the optimal substructure/equivalence classes. An additional disadvantage of the Cut &amp; Count approach of <ref type="bibr" target="#b11">[12]</ref>, compared to traditional dynamic programming algorithms on tree decompositions, is that their dependence in terms of the input graph is superlinear. Our work shows that each of these disadvantages can be overcome, with two different approaches, both giving deterministic algorithms for connectivity problems that are single exponential in the treewidth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Our contribution</head><p>Our contribution consists of two new approaches that resolve the aforementioned issues of the Cut &amp; Count approach, the "Rank based" and "Squared determinant" approaches. They can be used to quickly and deterministically solve respectively weighted and counting versions of problems solved by the Cut &amp; Count approach. Additional advantages of the rank based approach are that it gives a more intuitive insight in the optimal substructure/equivalence classes of a problem and that it has only a linear dependence on the input graph in the running time. The only disadvantage of both approaches when compared to the Cut &amp; Count approach is that the dependence on the treewidth or pathwidth in the running time is slightly worse. However, although we did not manage to overcome it, this disadvantage might not be inherently due to 1 For example, for the odd cycle transversal problem that asks to make the input graph bipartite by removing at most k vertices, a locally checkable certificate would be a solution set combined with a proper two-coloring of the remaining bipartite graph. </p><formula xml:id="formula_0">••• (••••) •••-••• 3 Table 1</formula><p>Table with our results. Rows 1-4 are discussed in Section 3 while rows 5-7 are discussed in Section 4. Line 7 is the result of applying the determinant approach to Feedback Vertex Set (note that we do not solve the counting variant). The symbol ω denotes the matrix multiplication exponent (currently it is known that ω &lt; 2.3727 due to <ref type="bibr" target="#b20">[21]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem</head><p>Pathwidth Treewidth</p><formula xml:id="formula_1">1 Weighted Steiner Tree n(1 + 2 ω ) pw pw O(1) n(1 + 2 ω+1 ) tw tw O(1) 2 Traveling Salesman n(2 + 2 ω/2 ) pw pw O(1) n(5 + 2 (ω+2)/2 ) tw tw O(1) 3 k-Path n(2 + 2 ω/2 ) pw (k + pw) O(1) n(5 + 2 (ω+2)/2 ) tw (k + tw) O(1) 4 Feedback Vertex Set n(1 + 2 ω ) pw pw O(1) n(1 + 2 ω+1 ) tw tw O(1) 5 # Hamiltonian Cycle Õ(6 pw pw O(1) n 2 ) Õ(15 tw tw O(1) n 2 ) 6 # Steiner Tree Õ(5 pw pw O(1) n 3 ) Õ(10 tw tw O(1) n 3 ) 7 Feedback Vertex Set Õ(5 pw pw O(1) n 3 ) Õ(10 tw tw O(1) n 3 )</formula><p>the new methods. Due to the generality of our key ideas, we feel our methods may inspire future work not involving tree decompositions as well.</p><p>Although both approaches apply to all problems studied in <ref type="bibr" target="#b11">[12]</ref>, we only study (variants of) Steiner Tree, Hamiltonian Cycle, and Feedback Vertex Set in this work in order to prevent losing focus. Our results on these problems are described in Table <ref type="table">1</ref>.</p><p>Since one of the main strengths of the treewidth concept seems to be its ubiquity, it is perhaps not surprising that our results improve, simplify, generalize, or unify a number of seemingly unrelated results. In all cases, problem instances can be reduced to instances with small tree-or pathwidth using standard techniques. This is further discussed in Section 1.2.</p><p>We would like to mention that very recently, a subset of the current authors found an efficient rank bound of a partial solution versus partial solution matrix for the Hamiltonian Cycle problem. We will use this in the current work to get a low running time for the Traveling Salesman problem.</p><p>A similar concept of maintaining only a "representative" subset of the so far constructed partial solutions in FPT algorithms was used in the algorithm of Monien <ref type="bibr" target="#b21">[22]</ref> for the k-Path problem and extended to matroids <ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>. We also recently became aware<ref type="foot" target="#foot_0">2</ref> of a discussion of Lovász <ref type="bibr" target="#b26">[27]</ref> relevant to our rank based approach. Specifically, Lovász introduced "connection matrices" of graph parameters and showed that good rank bounds on them imply efficient algorithms for determining the graph parameter on graphs of small treewidth (see <ref type="bibr" target="#b26">[27,</ref><ref type="bibr">Theorem 6.48]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1.">Rank based approach</head><p>Our first tool is the rank based method (presented in Section 3). This is based on a very generic idea to improve a dynamic programming algorithm, that we will now outline.</p><p>Recall that a dynamic programming algorithm fixes a way to decompose certificates into 'partial certificates', and builds partial certificates in a bottom-up manner while storing only their essential information. Given some language L ⊆ {0, 1} * , this is typically implemented by defining an equivalence ∼ on partial certificates x, y ∈ {0, 1} * such that x ∼ y if xz ∈ L ↔ yz ∈ L, for every extension z ∈ {0, 1} * . For connectivity problems on treewidth, the number of non-equivalent certificates can be seen to be larger than our running times. See for example <ref type="bibr" target="#b27">[28]</ref> for a lower bound in communication complexity. We will use however, that sometimes we can represent the joint essential information for sets of partial certificates more efficiently than naively representing essential information for every partial certificate separately. The rank based approach achieves this as follows: Given a dynamic programming algorithm, consider the matrix A whose rows and columns are indexed by partial certificates, with A[x, y] = 1 if and only if xy ∈ L. Then observe that if a set of rows X ⊆ {0, 1} * is linearly dependent (modulo 2), any partial certificate x ∈ X is redundant in the sense that for any z with xz ∈ L there exists an y ∈ X, y = x with yz ∈ L. Hence, the essential information can be reduced to rk( A) partial certificates.</p><p>For getting this approach to work we require an upper bound on the rank of the matrix M defined as follows: Fix a ground set U and let p and q be partitions of U (p and q represent connectivity induced by partial solutions), define M[p, q] to be 1 if and only if the join of p and q is the trivial partition, that is, if the union of the partial solutions induce a connected solution. Although this matrix has dimensions of order 2 θ(|U | log |U |) , we given a simple factorization in GF(2) of matrices with inner dimension 2 |U | using an idea of <ref type="bibr" target="#b11">[12]</ref>. Interestingly, our factorization (Lemma 3.13) can be derived from a much more general setting studied in communication complexity <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> (more specifically, Lemma 5.7 from <ref type="bibr" target="#b28">[29]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2.">Squared determinant approach</head><p>Our second tool is the squared determinant approach (presented in Section 4). This gives a generic transformation of counting connected objects to a more local transformation. In <ref type="bibr" target="#b11">[12]</ref> the existence of such a transformation in GF(2) was already given. For extending this to counting problems, we will need three key insights. The first insight is that (a variant of) Kirchhoff's Matrix Tree Theorem gives a reduction from counting connected objects to computing a sum of determinants. However, we cannot fully control the contribution of a connected object (it will appear to be either 1 or -1). To overcome this we ensure that every connected object contributes exactly once, by computing a sum of squares of determinants. The last obstacle is that the computation of a determinant is not entirely local (in the sense that we can verify a contribution by iteratively considering its intersection with all bags) since we have to account for the number of inversions of a permutation in every summand of the determinant. To overcome this obstacle, we show that this computation becomes a local computation once we have fixed the order of the vertices in a proper way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Relations to previous work</head><p>As mentioned before, our results improve, simplify, generalize, or unify a number of seemingly unrelated results. We will support this claim in this subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1.">Algorithms for problems with small solutions</head><p>Although we do not improve the running time of known algorithms, a significant advantage of our approach is that it unifies several known non-trivial algorithms. We proceed by giving three important examples:</p><p>Finding long paths In <ref type="bibr" target="#b30">[31]</ref>, the authors gave a deterministic 2 O(k) |E| lg |V | time algorithm that finds a simple path on k vertices in a graph G = (V , E), resolving the open question whether simple paths of length log n can be found in polynomial time from <ref type="bibr" target="#b31">[32]</ref>. In a follow-up work, <ref type="bibr" target="#b32">[33]</ref> this was improved to a 4 k+O(log 3 k) |V ||E| time algorithm. All these algorithms use the (arguably) involved construction of perfect hash families, and no 2 O(k) |V | O (1) time deterministic algorithm avoiding the use of such families was previously known.</p><p>As a corollary of our technique we can obtain a simple 2 O(k) k O (1) |V | + O(|E|) time algorithm, or an 4.28 k k O (1) |V | + O(|E|) with a standard technique from <ref type="bibr" target="#b33">[34]</ref> (see also <ref type="bibr" target="#b34">[35]</ref>) as follows. Create a depth first search tree of the input graph; if the height of the tree is more than k, the longest path from a leaf to the root gives a k-path and we are done. Otherwise, there is a path decomposition of width at most k, with for every leaf-root path a bag with the vertices on this path. Since this can be performed in linear time (see <ref type="bibr" target="#b34">[35]</ref> for details) we can respectively apply a simple variant of the algorithm from Section 3.4 or the algorithm from Theorem 3.20 to obtain the algorithms.</p><p>Finding feedback vertex sets Many papers (see <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36]</ref> and the references therein) have been devoted to the Feedback Vertex Set problem: Given an input graph G = (V , E) and a (small) parameter k, can we remove at most k vertices from G in order to obtain a forest? It should be noted that if this is indeed the case, then a tree decomposition of width k + 1 of G is easily obtained from a solution X by adding X to all bags of a tree decomposition of the forest V \ X . Based on this simple observation, deterministic 2 O(k) k O (1) |V | +|E| algorithms are easily obtained by using a constant-factor approximation or the method of iterative compression. We would like to mention that this is very different from previously known deterministic (1) algorithms that all rely on a measure-based branching strategy <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b35">36]</ref>.</p><formula xml:id="formula_2">2 O(k) k O(1) |V | O</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H-minor-free graphs</head><p>In <ref type="bibr" target="#b37">[38]</ref>, it was shown that any H -minor-free graph either has treewidth bounded by O( √ k), or a 2</p><formula xml:id="formula_3">√ k × 2 √</formula><p>k grid as a minor. Many problems can easily be solved once we know that the input graph has such a grid (for instance a 2</p><formula xml:id="formula_4">√ k × 2 √</formula><p>k grid as a minor guarantees that the graph does not have a vertex cover smaller than k or does have a 4k-path). See e.g., <ref type="bibr" target="#b38">[39]</ref> for an overview of this approach, known under the name of bidimensionality.</p><p>Thus, we are left with solving the problem with the assumption of bounded treewidth. In the case of problems with a local verification algorithm such as vertex cover, a standard dynamic programming algorithm then gives us a 2 O( √ k) n O (1)   algorithm to check whether a graph has a vertex cover no larger than k. In the case of k-Path, however, the standard dynamic programming routine gives a 2 O( 1) complexity. Motivated by this a number of papers showed that the fact that G is H -minor-free can be exploited to give 2 O(tw) n O (1) time algorithms (see <ref type="bibr" target="#b10">[11]</ref> and the references therein).</p><formula xml:id="formula_5">√ k log k) n O(</formula><p>In <ref type="bibr" target="#b11">[12]</ref> this result was extended to general graphs at the cost of randomization and a pseudo-polynomial dependence on the input weights, if present. In the current work we resolve the latter issues thereby fully unifying these previous results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2.">Graph classes with small treewidth</head><p>Sometimes the input is restricted to a graph class that is guaranteed to have small treewidth by known results. We survey here some connections of our work to previous results that were more tailor-made for such a graph class.</p><p>Bounded degree A number of problems have been studied in the setting where the input graph has bounded degree. For example, the Traveling Salesman has received considerable attention <ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref>. Our contribution is a derandomization at the cost of a slightly larger base of the exponential dependence.</p><p>Throughout the following, we let n denote the number of vertices of the given graph. Then the following theorem by Fomin et al. reduces the bounded degree setting to small treewidth: Theorem 1.1. (See <ref type="bibr" target="#b43">[44]</ref>.) For any &gt; 0 there exists an integer n such that for any graph G with n &gt; n vertices, pw(G) ≤ </p><formula xml:id="formula_6">n 5 + n ≥6 + n,</formula><p>where n i is the number of vertices of degree i in G for any i ∈ {3, . . . , 5} and n ≥6 is the number of vertices of degree at least 6. This theorem is constructive, and the corresponding path decomposition (and, consequently, tree decomposition) can be found in polynomial time. Using this result one can get fast deterministic algorithms for all the connectivity problems listed in Section 1.3.3 in <ref type="bibr" target="#b11">[12]</ref>. In this paper we restrict ourselves to the most studied setting, Traveling Salesman problem for cubic graphs. In <ref type="bibr" target="#b11">[12]</ref> a 1.201 n n O (1) Monte Carlo algorithm was obtained for Hamiltonian Cycle; Very recently in <ref type="bibr" target="#b44">[45]</ref>, this is improved to a 1.1583 n n O (1) time Monte Carlo algorithm. By combining the ideas of this paper with a result from <ref type="bibr" target="#b44">[45]</ref>, we obtain a 1.2186 n n O (1) time deterministic algorithm for the Traveling Salesman problem on cubic graphs in Corollary 3.19.</p><p>Planar graphs Recall that n denotes the number of vertices of the given graph. Here we begin with a consequence of <ref type="bibr" target="#b45">[46]</ref>: Proposition 1.2. (See <ref type="bibr" target="#b45">[46]</ref>.) For any planar graph G, tw(G)</p><formula xml:id="formula_7">+ 1 ≤ 3 2 √ 4.5n ≤ 3.183 √ n.</formula><p>Moreover a tree decomposition of such width can be found in polynomial time.</p><p>Using this we immediately obtain the following result for Traveling Salesman on planar graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 1.3.</head><p>There exists an algorithm that solves Traveling Salesman on planar graphs in time 4.28 3.183 (1) .</p><formula xml:id="formula_8">√ n n O(1) = 2 6.677 √ n n O</formula><p>The best known algorithm so far was the O(2 6.903 √ n ) time algorithm of Bodlaender et al. <ref type="bibr" target="#b46">[47]</ref>. A 2 6.366   √ n n O (1) randomized algorithm for Hamiltonian Cycle was given in <ref type="bibr" target="#b11">[12]</ref>.</p><p>Similarly, we obtain an O(2 6.677 √ n ) time deterministic algorithm for k-Cycle on planar graphs (compare to the O(2 7.223   √ n ) time of <ref type="bibr" target="#b46">[47]</ref>), and c √ n time algorithms for the other connectivity problems studied in <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>Graphs We use standard graph theory notation. Additionally, for a subset of edges X ⊆ E of an undirected graph G = (V , E) by G[ X] we denote the subgraph induced by edges and endpoints of X , i.e., G[ X] = (V (X), X). For X, Y ⊆ V we let E( X, Y ) be the set of all edges with one endpoint in X and one in Y . For a vertex v and X ⊆ V we denote deg X (v) for the number of neighbors of v contained in X .</p><p>Partitions and the partition lattice Given a base set U , we use Π(U ) for the set of all partitions of U . It is known that, together with the coarsening relation , Π(U ) gives a lattice, with the maximum element being {U } and the minimum element being the partition into singletons. We denote for the join operation and for the meet operation in this lattice; these operators are associative and commutative. I.e., for two partitions p and q, p q is obtained as follows: let ∼ be the relation on the elements with v ∼ w, if and only if v and w belong to the same set in p or v and w belong to the same set in q. Now, p q is the partition of U into the equivalence classes of the transitive closure of ∼. (In simple graph terms: build a graph H with a vertex set U , by turning each set in p and each set in q into a clique. Now, p q is the partition of U into the connected components of H .) p q precisely consists of all sets that are the nonempty intersection of a set from p and a set from q. We use Π 2 (U ) ⊂ Π(U ) to denote the set of all partitions of U in blocks of size 2, or equivalently, the set of perfect matchings over U . Given p ∈ Π(U ) we let #blocks(p) denote the number of blocks of p. If X ⊆ U we let p ↓X ∈ Π(X) be the partition obtained by removing all elements not in X from it, and analogously we let for U ⊆ X denote p ↑X ∈ Π(X) for the partition obtained by adding singletons for every element in X \ U to p. Also, for X ⊆ U , we let U [X] be the partition of U where one block is {X} and all other blocks are singletons. If a, b ∈ U we shorthand U [ab] = U [{a, b}]. The empty set, vector and partition are all denoted by ∅.</p><p>In definitions, where we take the minimum or maximum over a set of integers or real values, we follow the convention that min ∅ = ∞, and max ∅ = -∞.</p><p>Tree decompositions and treewidth A tree decomposition <ref type="bibr" target="#b1">[2]</ref> of a graph G is a tree T in which each node x has an assigned set of vertices B x ⊆ V (called a bag) such that x∈T B x = V with the following properties:</p><p>• for any uv ∈ E, there exists an</p><formula xml:id="formula_9">x ∈ T such that u, v ∈ B x , • if v ∈ B x and v ∈ B y , then v ∈ B z</formula><p>for all z on the (unique) path from x to y in T.</p><p>The treewidth tw(T) of a tree decomposition T is the size of the largest bag of T minus one, and the treewidth of a graph G is the minimum treewidth over all possible tree decompositions of G (thus the graphs of treewidth one are exactly the forests and trees that are not also independent sets). Finding a tree decomposition of minimum treewidth is NP-hard <ref type="bibr" target="#b47">[48]</ref>, but for each fixed integer k there is a linear time algorithm for finding a tree decomposition of width at most k (if it exists) <ref type="bibr" target="#b3">[4]</ref>. In this paper, we will always assume that tree decompositions of the appropriate width are given.</p><p>Dynamic programming algorithms on tree decompositions are often presented on nice tree decompositions, introduced by Kloks <ref type="bibr" target="#b48">[49]</ref>; see also <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref> regarding treewidth and dynamic programming. We present a slightly augmented variant that specifies bags/nodes for introducing edges; this was already used by Cygan et al. <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.1 (Nice tree decomposition).</head><p>A nice tree decomposition is a tree decomposition with one special bag z called the root and in which each bag is one of the following types:</p><p>• Leaf bag: a leaf x of T with B x = ∅. • Introduce vertex bag: an internal vertex x of T with one child vertex y for which B x = B y ∪ {v} for some v / ∈ B y . This bag is said to introduce v.</p><p>• Introduce edge bag: an internal vertex x of T labeled with an edge uv ∈ E with one child bag y for which u, v ∈ B x = B y . This bag is said to introduce uv.</p><p>• Forget bag: an internal vertex x of T with one child bag y for which B x = B y \ {v} for some v ∈ B y . This bag is said to forget v.</p><p>• Join bag: an internal vertex x with two child vertices l and r with B x = B r = B l .</p><p>We additionally require that every edge in E is introduced exactly once.</p><p>Proposition 2.2. Given a tree decomposition of some graph G = (V , E), a nice tree decomposition of same width rooted at an empty forget v bag for any choice of v ∈ V , or rooted at an introduce edge bag for any choice of {u, v} ∈ E can be computed in time ntw O (1) .</p><p>Proof. (Sketch) First, we briefly sketch how to get a nice tree decomposition that is rooted at the introduce edge bag for a chosen edge {u, v} ∈ E. To get an empty forget v root bag instead, we proceed analogously and add a series of forget vertex bags that ends in a new (empty) root, which is a forget v bag.</p><p>Let T be a tree decomposition for G and let {u, v} ∈ E be the chosen edge. Pick an arbitrary bag, say B r , of T that contains both u and v or forget v as the root and follow the arguments given by Kloks <ref type="bibr" target="#b48">[49]</ref> to generate a nice tree decomposition with root bag B r in linear time. Now additionally do the following. Below each leaf add a series of introduce vertex bags, starting from an empty bag, to make all (new) leaf bags be empty. To add an introduce edge bag for an edge {p, q} take the highest bag which contains both p and q, split the bag into two identical copies and use the upper one to introduce {p, q}. We perform this operation for the edge {u, v} at the end, to ensure that the root becomes the introduce edge {u, v} bag. 2</p><p>Note that we may assume that the number of bags of such a nice tree decomposition is linear in the number of edges of G, which is in turn at most the number of vertices times the treewidth of G.</p><p>By fixing the root of T, we associate with each bag x in a tree decomposition T a vertex set V x ⊆ V where a vertex v belongs to V x if and only if there is a bag y which is a descendant of x in T with v ∈ B y (recall that x is its own descendant). We also associate with each bag x of T a subgraph of G as follows:</p><formula xml:id="formula_10">G x = V x , E x = {e|e is introduced in a descendant of x}</formula><p>Path decompositions and pathwidth A path decomposition is a tree decomposition where the tree of nodes is restricted to be a path. The pathwidth of a graph is the minimum width of all path decompositions. Path decompositions can, similarly as above, be transformed into nice path decompositions, these obviously contain no join bags.</p><p>Further notation For two integers a, b we use a ≡ b to indicate that a is even if and only if b is even. We use N to denote the set of all non-negative integers. We use Iverson's bracket notation: if p is a predicate we let [p] be 1 if p is true and 0 otherwise. If ω : U → {1, . . . , N}, we shorthand ω(S) = e∈S ω(e) for S ⊆ U . For a function/vector s, by s</p><formula xml:id="formula_11">[v → α] we denote the function s \ {(v, s(v))} ∪ {(v, α)}.</formula><p>Note that this definition works regardless of whether s(v) is already defined or not.</p><p>We use s| X to denote the function obtained by restricting the domain to X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The rank based approach</head><p>This section is devoted to a complete presentation of our rank based approach for connectivity problems parameterized by treewidth. At the heart of the approach is a technique for reducing large sets of partial solutions, expressed as weighted partitions (to be defined later), down to smaller sets that maintain the same optimal solution value along with at least one optimal solution (though we point out that this reduction by design cannot maintain all optimal solutions). The main result behind the approach is presented in Section 3.2; it ensures that we can always find a small set of representative partial solutions. To avoid creating a series of ad hoc results for single problems, we introduce a collection of natural operations on families of weighted partitions, such that our results apply to any dynamic programming (DP) formulation that can be expressed using these operators only (see Section 3.1). The main strength of this abstraction layer compared to possible others (e.g., a logical approach <ref type="bibr" target="#b51">[52]</ref>) is that, even without further effort, it does not incur additional runtime.</p><p>In Sections 3.3, 3.4, and 3.5 we give DP formulations using our operators for Steiner Tree, Traveling Salesman, and Feedback Vertex Set respectively. Except for Feedback Vertex Set, where this turns out to be more involved, the programs are close to naive formulations that give runtimes 2 Ω(tw•log tw) (note that our operators and language of weighted partitions are nonstandard). At the first read of this section, it is perhaps useful to read only one of the DP formulations, but the different problems solved by them should indicate the versatility of our operators. Section 3.6 presents the proofs for the main building blocks of the approach (those given in Section 3.2). Finally, Section 3.7 discusses limitations and possible improvements to the results presented in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Operators on sets of weighted partitions</head><p>We will now introduce formally what we mean by sets of weighted partitions and followed by a definition of the mentioned collection of operations on such partition sets. Definition 3.1 (Set of weighted partitions). Recall that Π(U ) denotes the set of all partitions of some set U . A set of weighted partitions is a set A ⊆ Π(U ) × N, i.e., a family of pairs, each consisting of a partition of U and a non-negative integer weight. We say that A is unweighted if (p, w) ∈ A implies that w = 0.</p><p>The operators naturally apply to connectivity problems by allowing, e.g., gluing of connected components (i.e., different sets in a partition), or joining of two partial solutions by taking the join operation on the respective partitions. We will later see that if the recurrence only uses these operators, then the naive algorithm evaluating the recurrence can be improved beyond the typical 2 Ω(tw•log tw) that comes from the high number of different possible partial solutions.</p><p>For notational ease, we let rmc(A) denote the set obtained by removing non-minimal weight copies, i.e.,</p><formula xml:id="formula_12">rmc(A) = (p, w) ∈ A p, w ∈ A ∧ w &lt; w .</formula><p>Definition 3.2 (Operators on weighted partitions). Let U be a set and A ⊆ Π(U ) × N.</p><formula xml:id="formula_13">Union. For B ⊆ Π(U ) × N, define A ∪ ↓ B = rmc(A ∪ B).</formula><p>Combine two sets of weighted partitions and discard dominated partitions.</p><formula xml:id="formula_14">Insert. For X ∩ U = ∅, define ins(X, A) = {(p ↑U ∪X , w) | (p, w) ∈ A}.</formula><p>Insert additional elements into U and add them as singletons in each partition.</p><formula xml:id="formula_15">Shift. For w ∈ N define shft(w , A) = {(p, w + w ) | (p, w) ∈ A}.</formula><p>Increase the weight of each partition by w .</p><p>Glue. For u, v, let Û = U ∪ {u, v} and define glue(uv, A)</p><formula xml:id="formula_16">⊆ Π( Û ) × N as glue(uv, A) = rmc Û [uv] p ↑ Û , w (p, w) ∈ A .</formula><p>Also, if ω : Û × Û → N, let glue ω (uv, A) = shft(ω(u, v), glue(uv, A)). In each partition combine the sets containing u and v into one; add u and v to the base set if needed.</p><formula xml:id="formula_17">Project. For X ⊆ U let X = U \ X , and define proj(X, A) ⊆ Π(X) × N as proj(X, A) = rmc (p ↓X , w) (p, w) ∈ A ∧ ∀e ∈ X : ∃e ∈ X : p U [ee ] .</formula><p>Remove all elements of X from each partition, but discard partitions where this would reduce the number of blocks/sets.</p><formula xml:id="formula_18">Join. For B ⊆ Π(U ) × N let Û = U ∪ U and define join(A, B) ⊆ Π( Û ) × N as join(A, B) = rmc (p ↑ Û q ↑ Û , w 1 + w 2 ) (p, w 1 ) ∈ A ∧ (q, w 2 ) ∈ B .</formula><p>Extend all partitions to the same base set. For each pair of partitions return the outcome of the join operation , with weight equal to the sum of the weights.</p><p>Regarding the definition, note the role of U [ab]: Using p U <ref type="bibr">[ab]</ref> we obtain a partition that is the same as p except that the sets containing a and b are now merged into one (if they were one set already then nothing happens). When we use p U <ref type="bibr">[ab]</ref> then this is true if a and b are in the same set in the partition p (but the set can be larger than just {a, b}). Note also that ins(•, •) and shft(•, •) are the only operators that do not require rmc() in their definition; all other operators may create weighted partitions that consist of the same partition but with different weights (we want to keep only the cheapest one).</p><p>Straightforward implementation gives the following, assuming log S ≤ |U | O (1) (this can be established by for example applying the rmc(•) operation): Proposition 3.3. Each of the operations union, shift, insert, glue, and project can be performed in time S|U | O (1) where S is the size of the input of the operation. Given A, B, join(A, B) can be computed in time |A| • |B| • |U | O (1) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.L. Bodlaender et al. / Information and Computation</head><formula xml:id="formula_19">••• (••••) •••-•••</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Representing collections of weighted partitions</head><p>The key idea for getting a faster dynamic programming algorithm is to follow the naive DP, but to consider only small representative sets of weighted partitions instead of all weighted partitions that would be considered by the naive DP. Intuitively, a representative (sub)set of partial solutions should allow us to always extend to an optimal solution provided that one of the complete set of partial solutions extends to it. Let us define this formally. Definition 3.4 (Representation). Given a set of weighted partitions A ⊆ Π(U ) × N and a partition q ∈ Π(U ), define opt(q, A) = min w (p, w) ∈ A ∧ p q = {U } .</p><p>For another set of weighted partitions A ⊆ Π(U ) × N, we say that A represents A if for all q ∈ Π(U ) it holds that opt(q, A ) = opt(q, A).</p><p>Note that the definition of representation is symmetric, i.e., if A represents A then A also represents A . However, we will only be interested in the special case where A ⊆ A and where we have a size guarantee for finding a small such subset A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3.5 (Preserving representation). A function</head><formula xml:id="formula_20">f : 2 Π(U )×N × Z → 2 Π(U )×N is said to preserve representation if for every A, A ⊆ Π(U ) × N and z ∈ Z it holds that if A represents A then f (A , z) represents f (A, z).</formula><p>(Note that Z stands for any combination of further inputs.)</p><p>Completing the required tools, the following lemma and theorem establish that the operations needed for the DP preserve representation, and that we can always find a reasonably small representative set of weighted partitions. The proofs are deferred to Section 3.6.</p><p>Lemma 3.6. The union, insert, shift, glue, project, and join operations from Definition 3.2 preserve representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.7 (reduce). There exists an algorithm reduce that given set of weighted partitions</head><formula xml:id="formula_21">A ⊆ Π(U ) × N, outputs in time |A|2 (ω-1)|U | |U | O(1) a set of weighted partitions A ⊆ A such that A represents A and |A | ≤ 2 |U |-1</formula><p>, where ω denotes the matrix multiplication exponent.</p><p>It was recently shown that ω &lt; 2.3727 <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Application to Steiner Tree</head><p>In this section we show how to solve the Steiner Tree problem via a dynamic programming formulation that requires only the operators introduced in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Steiner Tree</head><formula xml:id="formula_22">Input: A graph G = (V , E), a weight function ω: E → N \ {0}, a terminal set K ⊆ V and a nice tree decomposition T of G of width tw. Question: The minimum of ω(X) over all subsets X ⊆ E of G such that G[ X] is connected and K ⊆ V (G[X]).</formula><p>Of course, since the weights are positive, in an optimal solution X indeed induces a tree as the problem name suggests. We will start by restating the recurrence used by the folklore algorithm for solving this problem using the introduced terminology on weighted partitions. Generally, we will denote the (to be computed) tables as A x (•) whereas E x (•) stands for a set of partial solutions; in both cases x denotes the current bag. For a bag x, and s ∈ {0, 1} B x define</p><formula xml:id="formula_23">A x (s) = p, min X∈E x (p,s) ω(X) p ∈ Π s -1 (1) ∧ E x (p, s) = ∅ E x (p, s) = X ⊆ E x ∀v ∈ B x : v ∈ V G[X] ∨ v ∈ K → s(v) = 1 ∧ ∀v 1 , v 2 ∈ s -1 (1) : v 1 v 2 are in same block in p ↔ v 1 , v 2 connected in G[X] ∧ #blocks(p) = cc G[X] .</formula><p>Note that s: B x → {0, 1} expresses which vertices we chose for the Steiner tree (namely those with s(v) = 1). Intuitively, E x (p, s) is the set of partial solutions having (a subset of) s -1 (1) as incident vertices in B x and connecting the vertices of s -1 (1) according to p. Furthermore, the definition ensures that all connected components spanned by the edges of any partial solution contain at least one vertex of the current bag, and all terminals are contained in some connected component.</p><p>Thus if we pick the tree decomposition T such that the root is the forget node, say x, for some terminal, say v, then we can check at the (single) child y of x the entry A y (s) where s(v) = 1 (there are no other vertices in this bag): This allows only the partition p = {{v}}, and by definition it must correspond to a minimum weight set of edges that spans a single connected component that contains all terminals.</p><p>We proceed with the recurrence for A x (s) which is used by the folklore dynamic programming algorithm. In order to simplify the notation, let v denote the vertex introduced and contained in an introduce bag, and let y, z denote the left and right children of x in T, if present. We distinguish on the type of bag in T:</p><formula xml:id="formula_24">Leaf bag x: A x (∅) = (∅, 0)</formula><p>Indeed, E x (p, s) only contains the empty set; it connects nothing and has weight 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduce vertex v bag x with child</head><formula xml:id="formula_25">y: A x (s) = ins({v}, A y (s| B y )), if s(v) = 1 A y (s| B y ), if s(v) = 0 ∧ v / ∈ K ∅, if s(v) = 0 ∧ v ∈ K</formula><p>Using v for a Steiner tree corresponds to s(v) = 1, and we insert v as a singleton into each partition (as there are no edges incident with v yet). If v is a terminal, then not inserting v is not feasible. Else, if v / ∈ K , and we do not use v then we get the same partial solutions as the previous bag.</p><p>Forget vertex v bag x with child y:</p><formula xml:id="formula_26">A x (s) = A y s[v → 0] ∪ ↓ proj v, A y s[v → 1]</formula><p>We combine partial solutions that either include v or exclude v. If v is included, we ensure it was connected to other vertices by removing it with the project operation (if it was a singleton then the corresponding partition is effectively eliminated).</p><p>Introduce edge e = uv bag x with child y:</p><formula xml:id="formula_27">A x (s) = A y (s) if s(u) = 0 ∨ s(v) = 0 A y (s) ∪ ↓ glue ω (uv, A y (s)), otherwise.</formula><p>To be able to include the edge we need by the definition of E x (p, s) that s(u) = s(v) = 1. If we include the edge, we account for the weight ω(u, v) and update the connectivity p by connecting u and v with the glue operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Join bag x with children y and z: A x (s) = join A y (s), A z (s) .</head><p>We know that every partial solution represented in A x (s) can be obtained from partial solutions represented by A y (s) and A z (s). To combine two partial solutions from A y (s) and A z (s), we have to sum the weights of the used edges and join the connectivity, and this is exactly what the join operation does. Theorem 3.8. There exist algorithms that given a graph G solve Steiner Tree in time n(1 + 2 ω ) pw pw O (1) if a path decomposition of width pw of G is given, and in time n(1 + 2 ω+1 ) tw tw O (1) if a tree decomposition of width tw of G is given.</p><p>Proof. The algorithm is the following: use the above dynamic programming formulation as discussed to compute A r (where r is the child of the root, as discussed), but after evaluation of every entry A x , use Theorem 3.7 to obtain and store A x = reduce(A x ) rather than A x . Since A x = reduce(A x ) represents A x and the recurrence uses only the operators defined in Definition 3.2 which all preserve representation by Lemma 3.6, we have as invariant that for every x ∈ T the entry A x stored for A x represents A x by Lemma 3.6. In particular, the stored value A r (s) represents A r (s) and hence we can safely read off the answer to the problem from this stored value as done from A r (s) in the folklore dynamic programming algorithm. Let us focus on the time analysis: since for all operations from Definition 3.2 we can apply Proposition 3.3, and for obtaining the tree/path decomposition with the required properties we can use Proposition 2.2 the bottleneck clearly is the reduce algorithm.</p><p>If we are given a path decomposition, it can easily be seen that the intermediate sets of weighted partitions are always of size at most 2 |s -1 (1)|+1 , and hence the time needed for computing reduce(A x (s)) for any bag x and all functions s : B x → {0, 1} can be upper bounded by (1) . If we are given a tree decomposition, we need to consider the time required to compute A x (s) where x is a join bag.</p><formula xml:id="formula_28">i 0 +i 1 =|B x | |B x | i 1 1 i 0 2 ωi 1 pw O(1) ≤ (1 + 2 ω ) pw pw O</formula><p>Then the size of the intermediate sets of weighted partitions is easily upper bounded by 4 |s -1 (1)| , and hence the time needed for computing reduce(A x (s)) can be upper bounded by (1) . 2</p><formula xml:id="formula_29">i 0 +i 1 =|B x | |B x | i 1 1 i 0 2 (ω+1)i 1 tw O(1) ≤ (1 + 2 ω+1 ) tw tw O</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.L. Bodlaender et al. / Information and Computation</head><formula xml:id="formula_30">••• (••••) •••-•••</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Application to Traveling Salesman</head><p>In this section we give an algorithm for Traveling Salesman by expressing a corresponding dynamic programming using the operators from Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Traveling Salesman</head><p>Input: A graph G = (V , E), a weight function ω: E → N and a tree decomposition T of G of width tw. Question: The minimum of ω(X) over all Hamiltonian cycles X ⊆ E.</p><p>First, for technical convenience, we guess an edge v 1 v n ∈ X that has to be included in the Hamiltonian cycle. Note that this can be done with only tw guesses since we can guess an edge adjacent to a vertex of minimum degree which is easily seen to be at most tw. Now, using Proposition 2.2, we turn the tree decomposition T into a nice tree decomposition that is rooted at the introduce edge bag for {v 1 , v n }; slightly abusing notation we refer to the latter as T. After accounting for the weight of {v 1 , v n }, this reduces the problem to tw instances of finding a minimum weight Hamiltonian path between two fixed vertices.</p><p>For a bag x and s ∈ {0, 1, 2} B x define</p><formula xml:id="formula_31">A x (s) = M, min X∈E x (M,s) ω(X) M ∈ Π s -1 (1) ∧ E x (M, s) = ∅ E x (M, s) = X ⊆ E x : v ∈ B x → deg X (v) = s(v) ∧ v ∈ V x \ B x → deg X (v) = 2 ∧ {u, v} ∈ M → u and v are connected in G x [X] ∧ G x [X] contains no cycles .</formula><p>In this case, s: B x → {0, 1, 2} encodes the degree of vertices in B x in the corresponding partial solution (the degree bound and exclusion of cycles implies that these are collections of paths). Our partitions M ∈ Π 2 (s -1 (1)) store the pairing of degree-1 vertices induced by connecting paths. Again naively implemented this would give 2 Ω(tw log tw) partial solutions, but our concept of representative sets gives the desired single exponential runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider the table entry</head><formula xml:id="formula_32">A z (s) where z is the root of T, s(v 1 ) = s(v n ) = 1 and for v = v 1 , v n we have s(v) = 2.</formula><p>It is easy to see that this table entry is empty if there is no Hamiltonian path from v 1 to v n and otherwise it is ({{v 1 , v n }}, w) where w is the weight of the minimum Hamiltonian path. Hence, to solve the problem it suffices to compute A z (s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leaf bag x:</head><p>We have B x = ∅. For ease of notation we permit a single table entry for the empty partition of B x into vertices labeled 0, 1, and 2:</p><formula xml:id="formula_33">A x (∅) = (∅, 0)</formula><p>Introduce vertex v bag x with child y: We have B x = B y ∪ {v}. For all s ∈ {0, 1, 2} B x we compute A x (s) as follows</p><formula xml:id="formula_34">A x (s) = A y (s| B y ) if s(v) = 0, ∅ otherwise.</formula><p>Since v is just introduced it cannot have neighbors in V x and there is no change in connectivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forget vertex v bag x with child y:</head><p>We have B y = B x ∪ {v}. For all s ∈ {0, 1, 2} B x we compute A x (s) as follows</p><formula xml:id="formula_35">A x (s) = A y s[v → 2] .</formula><p>The vertex v cannot have neighbors outside V x so it must have its two neighbors in</p><formula xml:id="formula_36">V x . Note that s[v → 2] ∈ {0, 1, 2} B y , with s(v) = 2.</formula><p>Introduce edge e = uv bag x with child y: We have B x = B y . For all s ∈ {0, 1, 2} B x we compute A x (s) as follows</p><formula xml:id="formula_37">A x (s) = A y (s) ∪ ↓ ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ ∅, if s(u) = 0 ∨ s(v) = 0, glue ω (uv, A y (s[u, v → 0])) if s(u) = s(v) = 1, proj({v}, glue ω (uv, A y (s[u → 0, v → 1]))) if s(u) = 1 ∧ s(v) = 2, proj({u}, glue ω (uv, A y (s[u → 1, v → 0]))) if s(u) = 2 ∧ s(v) = 1, proj({u, v}, glue ω (uv, A y (s[u, v → 1]))) if s(u) = 2 ∧ s(v) = 2.</formula><p>In all cases, an optimal solution may simply make no use of the edge e; hence we copy the set of matchings from the child accordingly (this gives the term A y (s)). If s(u) or s(v) is 0, the edge cannot have been used. When considering partial solutions using e, we have to use the entry of A y where the degree of u and v is decreased by 1 to account for the edge. In the case that s(u) and s(v) are 1 we can simply add the edge to the matching. In the case that s(u) = 1 and s(v) = 2 (or the symmetric opposite), we have to glue e to M, meaning that in the new matching u is matched with the vertex, say w, that v was previously matched with; here glue first creates a set {u, v, w} and project shrinks it to {u, w} (since v now has degree two and its specific connectivity needs not be traced). In the case that s(u) and s(v) both are 2, including e in a matching M in A y (s) gives the matching M \ {au, bv} ∪ {ab} for some a, b. We have to ensure that {a, b} = {u, v} which is done by projecting (if {a, b} = {u, v} then projection eliminates the partition).</p><p>Join bag x with children y and z: We have B x = B y = B z and compute A x (s) for all s ∈ {0, 1, 2} B x as follows</p><formula xml:id="formula_38">A x (s) = ↓ l+r=s proj s -1 (2) \ l -1 (2) ∪ r -1 (2) , join A y (l), A z (r)</formula><p>Note here that l, r, s ∈ {0, 1, 2} B x hence the summation is vector summation. Since we combine two characteristics of partial solutions into a new one, the degrees of the left and right partial solution (l and r) have to sum up to the degrees of the new one (s). Two characteristics (M 1 , w 1 ) <ref type="formula" target="#formula_78">2</ref>)) (that is, all vertices that had degree 1 in both subsolutions) are connected to vertices in s -1 (1) in the resulting partition</p><formula xml:id="formula_39">∈ A y (l) and (M 2 , w 2 ) ∈ A z (r) combine to a characteristic of A x (s) if and only if M 1 ∪ M 2 is acyclic which is equivalent to saying that all vertices in s -1 (2) \ (l -1 (2) ∪ r -1 (</formula><formula xml:id="formula_40">M 1 M 2 ,</formula><p>and the latter is ensured by the project operation.</p><p>Using the tools from Section 3.2, we obtain the following result. However, it should be noted that we give an improvement of this in Section 3.6, using a non-trivial result from <ref type="bibr" target="#b44">[45]</ref>.</p><p>Theorem 3.9. There exist algorithms that given a graph G solve Traveling Salesman in time n(2 + 2 ω ) pw pw O (1) if a path decomposition of width pw of G is given, and in time n(7 + 2 (ω+1) ) tw tw O (1) if a tree decomposition of width tw of G is given.</p><p>Proof. The algorithm is the following: use the above dynamic programming formulation to compute A r , but after evaluation of every entry A x , use Theorem 3.7 to store A x = reduce(A x ) rather than A x . Since A x = reduce(A x ) represents A x and the recurrence uses only the operators defined in Definition 3.2 which all preserve representation by Lemma 3.6, we have as invariant that for every x ∈ T the entry A x represents A x . In particular, the stored value A z (s) represents A z (s) where z is the root of T and hence we can safely read off the answer to the problem as done in the naive dynamic programming algorithm from A z (s).</p><p>Let us focus on the time analysis: since for all operations from Definition 3.2 we can apply Proposition 3.3, and for obtaining the tree/path decomposition with the required properties we can use Proposition 2.2 the bottleneck clearly is the reduce algorithm. Also, note that the guessing of the edge v 1 v n gives overhead of at most pw or tw so this will be subsumed by the last term of the claimed running time.</p><p>In the first algorithm that is given a path decomposition, note we can assume x is either a leaf, introduce vertex, forget vertex or introduce edge bag. In this case the size of the intermediate sets of weighted partitions is by our invariant at most 2 |s -1 (1)| . Then the time needed to perform reduce(A x (s)) is at most 2 ω|s -1 (1)| pw O (1) and the time to compute A x (s) for every</p><formula xml:id="formula_41">s ∈ {0, 1, 2} B x is s∈{0,1,2} Bx 2 ω|s -1 (1)| pw O(1) ≤ i 0 +i 1 +i 2 =|B x | |B x | i 0 , i 1 , i 2 1 i 0 1 i 2 2 ωi 1 pw O(1) = 2 + 2 ω |B x | pw O(1) ,</formula><p>where the last equality is due to the multinomial theorem. Hence A x can be computed for every x ∈ T in the claimed time bound.</p><p>For tree decompositions, note that if x is a join bag, and we denote Â for the intermediate values in the computation of</p><formula xml:id="formula_42">A (x) then Âx (s) ≤ l+r=s 2 |l -1 (1)| 2 |r -1 (1)| = |B x | i=1 l i +r i =s i 2 [l i =1]+[r i =1] = 4 |s -1 (1)| 6 |s -1 (2)| ,</formula><p>where in the first equality we expand into independent products over all coordinates of the vectors and use the following simple observation in the second equality</p><formula xml:id="formula_43">l i +r i =s i 2 [l i =1]+[r i =1] = 1 if s i = 0 4 if s i = 1 6 if s i = 2.</formula><p>(1) Using this, it can also be seen that the reduce operation to obtain A x (s) is performed in time bounded by (1) . Then the total time needed to evaluate A x (s) for every s ∈ {0, 1, 2} B x is bounded by</p><formula xml:id="formula_44">4 |s -1 (1)| 6 |s -1 (2)| 2 (ω-1)|s -1 (1)| |B x | O</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.L. Bodlaender et al. / Information and Computation</head><formula xml:id="formula_45">••• (••••) •••-••• i 0 +i 1 +i 2 =|B x | |B x | i 0 , i 1 , i 2 1 i 0 2 (ω+1)i 1 6 i 2 ≤ 7 + 2 (ω+1) tw ,</formula><p>by the multinomial theorem and the claim follows. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Application to Feedback Vertex Set</head><p>As a third application of the rank based approach we show how to formulate and solve Feedback Vertex Set using a dynamic programming formulation based on the operators introduced in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feedback Vertex Set</head><p>Input: An undirected graph G = (V , E), an integer k and a nice tree decomposition T of G of width tw.</p><formula xml:id="formula_46">Question: Find a set Y ⊆ V such that |Y | ≤ k and G[V \ Y ] is a forest.</formula><p>Using the operators for weighted partitions for solving Feedback Vertex Set requires a slight reformulation of the problem. The reason is that the operators are designed to maximize connectivity, whereas Feedback Vertex Set requires that we avoid creating cycles in introduce edge nodes of the tree decomposition. (It can be seen that certain more directly applicable operators do not preserve representation, e.g., selection of all partitions in which two vertices are connected, but we omit a detailed discussion at this point.)</p><p>The idea for the reformulation is to seek an induced subgraph that is a tree on at least i = |V |k vertices; this is equivalent to requiring maximum connectivity using only i -1 edges. Of course, this requires that the connected components created by the deletion of a feedback vertex set can be connected into a single tree. To this end, we make the following changes: We modify G, by adding a special universal vertex v 0 to it, i.e., it is adjacent to all vertices of G. Denote E 0 for the set of edges incident to v 0 . Then we ask for a pair (Y ,</p><formula xml:id="formula_47">Y 0 ) such that Y ⊆ V \ {v 0 }, |Y | ≤ k, Y 0 is a subset of E 0 , and the graph (V \ Y , E[V \ Y ] ∪ Y 0 ) is a tree. (By E[ X]</formula><p>we mean all edges in E with both endpoints in X .) This is clearly equivalent to the original problem statement since G[V \ (Y ∪ {v 0 })] can be extended to a tree in this way if and only if it is a forest. We emphasize that the tree must contain all edges between all selected original vertices and may contain any edges incident on v 0 (this in particular affects the possibilities and introduce edge bags). Note also that we can modify the tree decomposition T accordingly by adding v 0 to all bags and making it nice again.</p><p>For a bag x, integers i, j and s ∈ {0, 1} B x define</p><formula xml:id="formula_48">A x (s, i, j) = (p, 0) p ∈ Π s -1 (1) ∧ E x (p, s, i, j) = ∅ E x (p, s, i, j) = (X, X 0 ) ∈ 2 V x × 2 E 0 ∩E x |X| = i ∧ E x X \ {v 0 } ∪ X 0 = j ∧ X ∩ B x = s -1 (1) ∧ v 0 ∈ B x → s(v 0 ) = 1 ∧ ∀u ∈ X \ B x ∃u ∈ s -1 (1) : u, u connected in X, E x X \ {v 0 } ∪ X 0 ∧ ∀v 1 , v 2 ∈ s -1 (1) : v 1 v 2 are in same block in p ↔ v 1 , v 2 are connected in X, E x X \ {v 0 } ∪ X 0 .</formula><p>In words, (p, 0) ∈ A x (s, i, j) indicates that there exists a subset {v 0 } ∩ V x ⊆ X ⊆ V x with X ∩ B x = s -1 (1) and a subset X 0 ⊆ E x ∩ E 0 such that in the graph (X, E x [X \ {v 0 }] ∪ X 0 ) we have i vertices, j edges, no connected component fully contained in V x \ B x , and that the elements of s -1 (1) are connected according to the partition p. It follows that the given instance of Feedback Vertex Set is a YES-instance if and only if for some i ≥ |V |k we have that A y ({v 0 }, i, i -1) is nonempty, where B y = {v 0 } is the only child of the empty root bag B z , which is a forget node for v 0 . For the forward direction, we can take a solution and extend it to a tree of the required type using the incident edges of v 0 . For the backward direction, we have that (X, E x [X \ {v 0 }] ∪ X 0 ) contains i vertices and i -1 edges and that it is connected; hence it is a tree and V \ X is a feedback vertex set.</p><p>In order to simplify the notation, let v denote the vertex introduced and contained in an introduce bag, and let y, z denote the left and right children of x in T, if present. As usual, undefined table entries are assumed to be empty for notational convenience. We distinguish on the type of bag in T:</p><formula xml:id="formula_49">Leaf bag x: A x (∅, 0, 0) = (∅, 0)</formula><p>Clearly, if i = j = 0 then E x (∅, i, j) = {(∅, ∅)} and it is empty otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduce vertex v bag x with child</head><formula xml:id="formula_50">y: A x (s, i, j) = ⎧ ⎨ ⎩ ∅ if v = v 0 ∧ s(v) = 0, ins({v}, A y (s| B y , i -1, j)), if s(v) = 1, A y (s| B y , i, j),</formula><p>otherwise.</p><p>If v = v 0 we require s(v) = 1 by definition. Otherwise, if s(v) = 1, we account for its inclusion in X : We extend solutions where the number of vertices is i -1 (effectively, this increases the number of vertices, as intended).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forget vertex v bag x with child</head><formula xml:id="formula_51">y: A x (s, i, j) = A y s[v → 0], i, j ∪ ↓ proj v, A y s[v → 1], i, j .</formula><p>We combine solutions from the child bag where v can be included or excluded in the intended tree (since the current bag does not specify s(v)). For previous solutions with s(v) = 1, we remove v from the partitions using the project operator; this eliminates partial solutions that have v as a singleton in the partition since that would create a separate component that can no longer be connected (deviating from building a single tree).</p><p>Introduce edge e = uv bag x with child y:</p><formula xml:id="formula_52">A x (s, i, j) = ⎧ ⎪ ⎨ ⎪ ⎩ A y (s, i, j) ∪ ↓ glue(v 0 v, A y (s, i, j -1)) if u = v 0 ∧ s(v) = 1, A y (s, i, j) ∪ ↓ glue(v 0 u, A y (s, i, j -1)) if v = v 0 ∧ s(u) = 1, glue(uv, A y (s, i, j -1)) if s(u) = 1 ∧ s(v) = 1, A y (s, i, j)</formula><p>otherwise.</p><p>If u = v 0 (or, by symmetry, v = v 0 ) we can choose to insert the edge v 0 v, and account for it by extending previous solutions with j -1 edges. If s(u) = s(v) = 1 we have to include the edge uv in E x [X] and again build upon solutions with j -1 edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Join bag x with children y and z</head><formula xml:id="formula_53">: A x (s, i, j) = ↓ i 1 +i 2 =i+s -1 (1) j 1 + j 2 = j join A y (s, i 1 , j 1 ), A z (s, i 2 , j 2 ) .</formula><p>We first compensate for vertices accounted for twice in the i counter since they were introduced in both subtrees of T by subtracting their number; these are exactly the vertices in s -1 (1) ⊆ B x (they are selected for the tree and by basic tree decomposition properties they must be contained in B x if they are in both subtrees). Then we simply add the number of edges of both subsolutions, and their connectivity is automatically joined by the join operator.</p><p>We obtain the following theorem, whose proof is analogous to the proof of Theorem 3.8 and therefore omitted. However, let us explain why we can still obtain a time bound that is linear in n, despite the two additional table dimensions i and j of range O(n). The trick here is to see that we do not need to fully evaluate the table, but that smaller ranges for i and j suffice. First, let us see that we can restrict our attention to i ∈ { j + 1, . . . , j + tw + 1}: If j ≥ i then the partial solution must already contain a cycle (and every further added vertex needs at least one incident edge so we cannot reach i * vertices and i * -1 edges). If i &gt; j + tw + 1 then the table is empty, since matching partial solutions would have more than tw + 1 connected components, which violates the condition that each component is connected to a vertex of the current bag. Second, to see that only considering a small range of values for i suffices at each bag, consider the following:</p><p>If we have a nonempty table entry A x (s, i, j), then any table entry A x (s , i , j ) with i &lt; itw is suboptimal (and hence not required): We can always add B x \ {v 0 } to the implicit feedback vertex set of any solution in A x (s, i, j) to get a better solution than A x (s , i , j ); it is less constrained since its connected components contain only the mandatory v 0 from B x and it has at least i vertices in connected components. Theorem 3.10. There exist algorithms that given a graph G solve Feedback Vertex Set in time n(1 + 2 ω ) pw pw O (1) if a path decomposition of width pw of G is given, and in time n(1 + 2 ω+1 ) tw tw O (1) if a tree decomposition of width tw of G is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Representing collections of weighted partitions based on rank</head><p>Preserving representation We first need to prove Lemma 3.6. That is, that the operations union, insert, shift, glue, project, and join preserve representation.</p><p>Proof of Lemma 3.6. In the following let U be a set, let A, A ⊆ Π(U ) × N, and assume that A represents A. Note that the union and join operations are symmetric and hence we only need to show the preservation of representation with respect to one of the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Union:</head><p>We have for all q ∈ Π(U ) and B ⊆ Π(U ) × N that opt q, A ∪ ↓ B = min opt q, A , opt(q, B) = min opt(q, A), opt(q, B) = opt q, A ∪ ↓ B .</p><p>Insert: We may assume that X = {e} since for Y ∩ Z = ∅, ins(Y ∪ Z , A) equals ins(Y , ins(Z , A)). Note that if {e} ∈ q, opt(q, ins({e}, C)) = ∞ and representation is preserved trivially. Otherwise, we have for every C ⊆ Π(U ) × N and any q ∈ Π(U ∪ {e}) with {e} / ∈ q that opt q, ins {e},</p><formula xml:id="formula_54">C = min w (p, w) ∈ C ∧ p ↑U ∪{e} q = U ∪ {e} = min w (p, w) ∈ C ∧ p q ↓U = {U } = opt(q ↓U , C).</formula><p>Note that the second equivalence uses the fact that e must be connected to some e ∈ U in q, since {e} / ∈ q. Now preservation of representation follows since opt q, ins {e}, A = opt q ↓U , A = opt(q ↓U , A) = opt q, ins {e}, A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shift:</head><p>We have for all q ∈ Π(U ) and w ∈ N that opt q, shft w , A = w + opt q, A = w + opt(q, A) = opt q, shft w , A .</p><p>Glue: We may assume that a, b ∈ U since otherwise glue(ab, A) = glue(ab, ins({a, b} \ U , A)). Note that for every C ⊆ Π(U ) × N and any q ∈ Π(U ) we have that</p><formula xml:id="formula_55">opt q, glue(ab, C) = min w (p, w) ∈ C ∧ p U [ab] q = {U } = min w (p, w) ∈ C ∧ p q U [ab] = {U } = opt q U [ab], C .</formula><p>Then preservation of representation follows since opt q, glue ab, A = opt q U [ab], A = opt q U [ab], A = opt q, glue(ab, A) .</p><p>It is clear from its definition that the variant of glue with three parameters also preserves representation.</p><p>Project: We may assume that X = {e} since for Y ∩ Z = ∅, proj(Y ∪ Z , A) equals proj(Y , proj(Z , A)). Then for every C ⊆ Π(U ) × N and any q ∈ Π(U \ {e}) we have that</p><formula xml:id="formula_56">opt q, proj {e}, C = min w (p, w) ∈ C ∧ p ↓U \{e} q = U \ {e} ∧ {e} / ∈ p = min w (p, w) ∈ C ∧ p q ↑U = {U } = opt(q ↑U , C).</formula><p>Now preservation of representation follows directly since opt q, proj {e}, A = opt q ↑U , A = opt(q ↑U , A) = opt q, proj {e}, A .</p><p>Join: We may assume that A, B ⊆ Π( Û ) × N since otherwise we can use</p><formula xml:id="formula_57">join(A, B) = join ins U \ U , A , ins U \ U , B . For every B ⊆ Π( Û ) × N and r ∈ Π( Û ) it holds that opt r, join A , B = min w 1 + w 2 (w 1 , p) ∈ A , (w 2 , q) ∈ B ∧ p q r = { Û } = min opt q r, A + w 2 (w 2 , q) ∈ B = min opt(q r, A) + w 2 (w 2 , q) ∈ B = min w 1 + w 2 (w 1 , p) ∈ A, (w 2 , q) ∈ B ∧ p q r = { Û } = opt r, join(A, B) .</formula><p>Finding small representative subsets The remainder of this subsection is devoted to the proof of Theorem 3.7. The key idea is as follows: To find optimal partial solutions in a set A of weighted partitions, one checks for certain partitions q what is the minimum weight w such that A contains some pair (p, w) such that p q gives the unit partition. For intuition let us ignore the weights for the moment and only look at the partitions in A. Very roughly we need to find a subset of those partitions that can complete any partition q to the unit partition {U }, assuming that some partition in A does that too (we only need to represent what A can do). It can be seen that any set cover of partitions p such that for any q at least one of them gives p q = {U } suffices. It turns out that taking a subset of partitions that form a basis in a certain matrix can play the same role, and is much easier to handle (both in proof and for finding it algorithmically). Given that, it is not hard to get the additional property that the representative subset always matches the correct weight that the original set A would provide; this corresponds essentially to a basis of minimum weight. Our matrix simply states for all pairs p and q of partitions whether or not the join operation applied to them gives the unit partition. The crucial part, of course, is to show that it has low rank, in order to guarantee a small basis. The matrix is formally defined as follows; for notational ease let us fix U = [t], and let us shorthand</p><formula xml:id="formula_58">(V 1 , V 2 ) for a partition {V 1 , V 2 } ∈ Π(U ). Definition 3.11. Define M ∈ Z Π(U )×Π(U ) 2 by M[p, q] = 1 p q = {U },<label>0 else.</label></formula><p>The idea for getting a good rank bound for this matrix is to consider a simple class of partitions, namely cuts into only two sets (where the second set may in fact be empty). The subsequent lemma then shows that in arithmetic modulo two, the matrix M can be written as the product of two cutmatrices C, which are defined as follows. Definition 3.12. Define cuts(t)</p><formula xml:id="formula_59">:= {(V 1 , V 2 ) | V 1 ∪ V 2 = U ∧ 1 ∈ V 1 }, where 1 stands for an arbitrary but fixed element of U . Define C ∈ Z Π(U )×cuts(t) 2 by C[p, (V 1 , V 2 )] = [(V 1 , V 2 ) p].</formula><p>Intuitively, the matrix C represents which pairs of partitions and cuts are consistent, i.e., the partition needs to be a refinement of the cut. It is crucial that one side of the cut is fixed to contain a particular vertex since that allows the following trick via counting modulo two: For each pair of partitions, the product CC T can be seen to count the number of partitions that are consistent with both p and q. If p q = {U } then there is only one such partition. Otherwise, if p q is a partition with at least two sets then there is an even number of cuts that are consistent (to see this, pair the cuts by including respectively excluding any set that does not include the special element 1 ∈ V 1 ). Lemma 3.13. It holds that M ≡ CC T .</p><p>Proof. For every p, q ∈ Π(U ):</p><formula xml:id="formula_60">CC T [p, q] = (V 1 ,V 2 )∈cuts(t) (V 1 , V 2 ) p (V 1 , V 2 ) q = (V 1 ,V 2 )∈cuts(t) (V 1 , V 2 ) p ∧ (V 1 , V 2 ) q = (V 1 ,V 2 )∈cuts(t) (V 1 , V 2 ) p q = 2 #blocks(p q)-1 ≡ p q = {U } .</formula><p>The key here is that we count the number of cuts which are coarser than both p and q, i.e., cuts (V 1 , V 2 ) ∈ cuts(t) such that each set of p or q is completely contained in V 1 or V 2 . It follows easily, that this is equivalent to each set of p q being contained in V 1 or V 2 . Considering the blocks of p q it is clear that the block containing 1 must be in V 1 , by the definition of cuts(t). Any further block can be either in V 1 or V 2 , which gives a total of 2 #blocks(p q)-1 coarser cuts. Clearly, that number is odd if and only if there is a single block in p q (the one containing 1), i.e., if p q = {U }. 2</p><p>From the factorization we pretty immediately get the following lemma that encapsulates the idea behind finding small representative subsets. It shows that linear dependence allows us to discard one of the corresponding partitions (e.g., the one of highest weight). Lemma 3.14. Let X ⊆ Π(U ) and q, r ∈ Π(U ) such that C[q, •] ≡ p∈ X C[p, •] and r q = {U }. Then, there exists p ∈ X such that r p = {U }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Improvements and limitations of the approach</head><p>The main ingredient for the proof of Theorem 3.7 is Lemma 3.14 which in turn follows directly from the factorization M = CC T (Lemma 3.13). Thus by establishing a better factorization (that is, with smaller inner dimension) using other matrices whose entries are computable in polynomial time, we would immediately get improved algorithmic results.</p><p>It can be seen that such an improvement is not possible in the general case: Assume that |U | is odd and fix an element u 0 ∈ U . The submatrix of M with rows and columns indexed by {U [X] | u 0 ∈ X ∧ |X| = (|U | + 1)/2} is easily seen to be an identity matrix, since the join of two of such partitions gives the unit partition if and only if they are constructed from X 1 and X 2 with X 1 = U \ X 2 ∪ {u 0 }. Since the inner dimension is an upper bound on the rank this rules out relevant improvements to the factorization of M, because the above construction shows that the rank is at least 2 |U | /|U |.</p><p>However, if we restrict our attention to the submatrix of M corresponding only to perfect matchings (such as we use for the TSP algorithm) then the following improved factorization can be established.</p><p>Theorem 3.16. (See <ref type="bibr" target="#b44">[45]</ref>.) Let H be the submatrix of M restricted to all matchings. Then H can be factorized into two matrices whose entries can be computed in time |U | O (1) , where the inner dimension of the factorization is</p><formula xml:id="formula_61">2 |U |/2-1 .</formula><p>Combining this result with the proof technique of Theorem 3.7, we obtain the following improvement:</p><p>Corollary 3.17. There exists an algorithm reducematchings that given a set of weighted matchings A ⊆ Π 2 (U ) × N, outputs in |A|2</p><p>(ω-1)</p><formula xml:id="formula_62">2 |U | |U | O(1) time a set of weighted matchings A ⊆ A such that A represents A and |A | ≤ 2 |U |/2</formula><p>, where ω denotes the matrix multiplication exponent.</p><p>Proof. The proof is almost identical to the proof of Theorem 3.7: let H = C C be the matrix factorization from Theorem 3.16. Then by the same proof, Lemma 3.14 holds when we replace C with C and restrict X and p and r to consist of matchings. Then reducematchings is obtained from reduce by replacing C with C . The arguments for the correctness and running times of this algorithm are analogous to the arguments from the proof of Theorem 3.7. 2</p><p>Thus, for problems whose dynamic programming formulation via our introduced set of operators requires only weighted perfect matchings, but not the generality of weighted partitions, we get somewhat faster algorithms; among the considered problems this is true for Traveling Salesman, and it seems unlikely for Steiner Tree or Feedback Vertex Set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.18.</head><p>There exist algorithms that given a graph G solve Traveling Salesman in time n(2 + 2 ω/2 ) pw pw O (1) if a path decomposition of width pw of G is given, and in time n(5 + 2 (ω+2)/2 ) tw tw O (1) if a tree decomposition of width tw of G is given.</p><p>The proof is analogous to the proof of Theorem 3.9, the only difference being the use of reducematchings instead of reduce.</p><p>Proof. The algorithm is the following: use the above dynamic programming formulation from Section 3.4 to compute A r , but after evaluation of every entry A x , use Theorem 3.7 to store reducematching(A x ) rather than A x . This is possible because by definition A x clearly is a set of weighted matchings. Since reducematchings(A) represents A and the recurrence uses only the operators defined in Definition 3.2 which all preserve representation by Lemma 3.6, we have as invariant that for every x ∈ T the entry stored for A x represents A x by Lemma 3.6. In particular, the stored value for A r (s) dominates A r (s) and hence we can safely read off the answer to the problem as done in Section 3.4.</p><p>Let us focus on the time analysis: since for all operations from Definition 3.2 we can apply Proposition 3.3, the bottleneck clearly is the reducematchings algorithm. Recall that the guessing of the edge v 1 v n gives overhead of at most pw or tw so this will be subsumed by the last term of the claimed running time.</p><p>In the first algorithm that is given a path decomposition, note we can assume x is either a leaf, introduce vertex, forget vertex or introduce edge bag. In this case the size of A x (s) is by our invariant at most 2 |s -1 (1)|/2 . Then the time needed to perform reducematchings(A x (s)) is at most 2 ω/2|s -1 (1)| pw O (1) and the time to compute A x (s) for every s ∈ {0, 1) ,</p><formula xml:id="formula_63">1, 2} B x is s∈{0,1,2} Bx 2 ω/2|s -1 (1)| pw O(1) ≤ i 0 +i 1 +i 2 =|B x | |B x | i 0 , i 1 , i 2 1 i 0 1 i 2 2 ω/2 i 1 pw O(1) = 2 + 2 ω/2 |B x | pw O(</formula><p>where the last equality is due to the multinomial theorem. Hence A x can be computed for every x ∈ T in the claimed time bound.</p><p>In this section we are up to compute the number of connected edgesets X such that X ∈ F where F is some implicitly defined set family. Our main idea is to use Lemma 4.1 to reduce this task to computing the quantity X∈F det(F X ) 2 instead, and to ensure that if X ∈ F is connected, then it is a tree.</p><p>For two (not necessarily disjoint) subsets V 1 , V 2 of an ordered set let us define inv(</p><formula xml:id="formula_64">V 1 , V 2 ) = |{(u, v) : u ∈ V 1 , v ∈ V 2 , u &gt; v}|.</formula><p>If X, Y are ordered sets, recall that for a permutation f : X</p><p>1-1</p><p>→ Y we have that the sign equals sgn( f ) = (-1) |{(e 1 ,e 2 ):e 1 ∈X∧e 2 ∈Y ∧e 1 &lt;e 2 ∧ f (e 1 )&gt; f (e 2 )}| .</p><p>The following proposition will be useful: Proposition 4.2. Let X l , X r ⊆ V and Y l , Y r ⊆ E such that X l ∩ X r = ∅ and Y l ∩ Y r = ∅, and for every e 1 ∈ Y l and e 2 ∈ Y r we have that e 1 &lt; e 2 . Suppose f l :</p><formula xml:id="formula_65">Y l 1-1 → X l and f r : Y r 1-1 → X r . Denote f = f l ∪ f r , that is, f (v) = f l (v) if v ∈ Y l and f (v) = f r (v) if v ∈ Y r .</formula><p>Then it holds that sgn( f ) = sgn( f 1 )sgn( f 2 ) • (-1) inv( X l ,X r ) .</p><p>To see that the proposition is true, note that from the definition of sgn, the pairs e 1 , e 2 with e 1 , e 2 ∈ Y l or e 1 , e 2 ∈ Y r are already accounted for in the part sgn( f 1 )sgn( f 2 ) so it remains to show that</p><formula xml:id="formula_66">(e 1 , e 2 ) : e 1 ∈ Y l , e 2 ∈ Y r ∧ e 1 &lt; e 2 ∧ f (e 1 ) &gt; f (e 2 )</formula><p>indeed equals inv( X l , X r ), but this is easy to see since we have by assumption that e 1 &lt; e 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Counting Hamiltonian cycles</head><p>For our first application to counting Hamiltonian cycles, we derive the following formula which expresses the number of Hamiltonian cycles of a graph:</p><formula xml:id="formula_67">X⊆E ∀ v∈V deg X (v)=2</formula><p>[X is a Hamiltonian cycle] {a 2-regular graph has n subtrees on n -1 edges if it is connected and 0 otherwise}</p><formula xml:id="formula_68">= 1 n • X⊆E ∀ v∈V deg X (v)=2 S⊆ X,|S|=n-1 (V , S) is a tree {Lemma 4.1} = 1 n • X⊆E ∀ v∈V deg X (v)=2 S⊆ X,|S|=n-1 det(F S ) 2 .</formula><p>By plugging the permutation definition of a determinant, we obtain the following expression for the number of Hamiltonian cycles of a graph:</p><formula xml:id="formula_69">1 n • X⊆E ∀ v∈V deg X (v)=2 S⊆ X,|S|=n-1 f :S 1-1 → V \{v 1 } sgn( f ) e∈S a f (e),e 2 = 1 n • X⊆E ∀ v∈V deg X (v)=2 S⊆ X f 1 , f 2 :S 1-1 → V \{v 1 } sgn( f 1 )sgn( f 2 )</formula><p>e∈S a f 1 (e),e a f 2 (e),e .</p><p>Note that in the last equality we dropped the assumption |S| = n -1, as it follows from the fact that f 1 (and f 2 ) is a bijection.</p><p>Our goal is to compute the formula by dynamic programming over some nice tree decomposition T. To this end, let us define a notion of "partial sum" of the above formula, that we will store in our dynamic programming table entries. For every bag x ∈ T,</p><formula xml:id="formula_70">s deg ∈ {0, 1, 2} B x , s 1 ∈ {0, 1} B x and s 2 ∈ {0, 1} B x define A x (s deg , s 1 , s 2 ) = X⊆E x ∀ v∈(V x\Bx) deg X (v)=2 ∀ v∈Bx deg X (v)=s deg (v) S⊆ X f 1 :S 1-1 → (V x \{v 1 })\s -1 1 (0) f 2 :S 1-1 → (V x \{v 1 })\s -1 2 (0) sgn( f 1 )sgn( f 2 )</formula><p>e∈S a f 1 (e),e a f 2 (e),e .</p><p>(</p><p>Intuitively in s deg we store the degrees of vertices of B x in G[ X], whereas s 1 (and s 2 ) specify whether a vertex of B x was already used as a value of the bijection f 1 (and f 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leaf bag x:</head><p>A x (∅, ∅, ∅) = 1.</p><p>Introduce vertex v bag x with child y: for s deg ∈ {0, 1, 2} B x and s 1 ,</p><formula xml:id="formula_72">s 2 ∈ {0, 1} B x A x (s deg , s 1 , s 2 ) = A y (s deg | B y , s 1 | B y , s 2 | B y ) if s deg (v) = s 1 (v) = s 2 (v) = 0 0 o t h e r w i s e .</formula><p>Since the vertex v is not incident to any edge from E x , we have that deg X = 0 and hence all summands in which f 1 or f 2 map an edge to v will vanish.</p><p>Forget vertex v bag x with child y: for s deg ∈ {0, 1, 2} B x and s 1 ,</p><formula xml:id="formula_73">s 2 ∈ {0, 1} B x A x (s deg , s 1 , s 2 ) = A y (s deg [v → 2], s 1 [v → 1], s 2 [v → 1]) if v = v 1 A y (s deg [v → 2], s 1 [v → 0], s 2 [v → 0]) otherwise.</formula><p>Since v is moved out of B x we need to make sure deg X (v) = 2, and since no edges incident to v will be introduced anymore we require s</p><formula xml:id="formula_74">1 (v) = s 2 (v) = 1, unless v = v 1 :</formula><p>Since it is not used as a value for bijections f 1 , f 2 , we need to handle this vertex separately.</p><p>Introduce edge e = uv bag x with child y: Here we have three cases. Either the edge e is not contained in the set X , or it is a part of X \ S, or finally it is a part of S. In the last case we need to choose the values f 1 (e) and f 2 (e) and account for their contribution to sgn( f 1 )sgn( f 2 ), but we can restrict ourselves to values of (s -1 1 (1) \ {v 1 }) ∩ e and (s -1 2 (1) \ {v 1 }) ∩ e respectively, because otherwise either we do not obtain a bijection or the whole summand will disappear since a v ,e = 0 for v / ∈ e.</p><formula xml:id="formula_75">If s deg (u), s deg (v) ≥ 1, then we set A x (s deg , s 1 , s 2 ) = A y (s deg , s 1 , s 2 ) + A y s deg , s 1 , s 2 + u ∈(s -1 1 (1)\{v 1 })∩e v ∈(s -1 2 (1)\{v 1 })∩e A y s deg , s 1 u → 0 , s 2 v → 0 • a u ,e • a v ,e • (-1) inv(s -1 1 (1),u )+inv(s -1 2 (1),v ) ,</formula><p>where s deg is the function s deg with the values for u and v decreased by one. Observe that on the first two mentioned cases are accounted for on the first line. For the third case, we need to account for the new number of inversions contributing to sgn( f 1 )sgn( f 2 ). Note that vertices from V x \ B x cannot participate in such an inversion since the vertex and edge are both smaller than v and e due to the ordering.</p><p>To this end, we can use Proposition 4.2 with Y r = {e} and X r = {v } since e is the largest edge in E x , and it follows that the factor (-1) inv(s -1</p><p>1 (1),u )+inv(s -1</p><p>2 (1),v ) indeed accounts for the new inversions.</p><p>Finally, when s deg (u) = 0 or s deg (v) = 0, then we set</p><formula xml:id="formula_76">A x (s deg , s 1 , s 2 ) = A y (s deg , s 1 , s 2 ).</formula><p>Join bag x with children y and z:</p><formula xml:id="formula_77">A x (s deg , s 1 , s 2 ) = s deg, y +s deg,z =s deg s 1, y +s 1,z =s 1 s 2, y +s 2,z =s 2 A y (s deg, y , s 1, y , s 2, y ) • A z (s deg,z , s 1,z , s 2,z ) • (-1) inv(s -1 1, y (1),s -1 1,z (1))+inv(s -1 2, y (1),s -1 2,z<label>(</label></formula><p>1)) .</p><p>In the above formula when adding two functions we denote coordinate-wise addition. To see that we correctly account for the new number of inversions, first note that vertices from V x \ B x cannot participate in such an inversion since the vertex and incident edge are both smaller than the vertices appearing in B x and their incident edges e due to the ordering. Then by Proposition 4.2 we correctly account for the new inversions since all edges from E y are smaller than E z due to the post-ordering of edges. In the described dynamic programming we have 3 • 2 • 2 = 12 states per vertex, however observe that when s deg (v) = 0, then all non-zero summands of the partial sum (3) satisfy s 1 (v) = s 2 (v) = 0, since otherwise the function f 1 (or f 2 ) assigns the value of v to an edge that was not incident to v. Similarly when v = v 1 and s deg (v) = 2, then it is enough to store the states only with s 1 (v) = s 2 (v) = 1, because if v was not yet assigned as a value by f 1 (or f 2 ), then since we cannot add to X any more edges incident to v, this table entry will not be used as in the forget node we require that s 1 (v) = s 2 (v) = 1. Hence for each vertex v = v 1 there are only 6 triples (s deg (v), s 1 (v), s 2 (v)), i.e., (0, 0, 0), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1) and (2, 1, 1), which is enough to show the claimed running time for path decompositions.</p><p>In case of tree decompositions we need to analyze the time complexity needed to handle the summation in join nodes. Observe that there are exactly 15 pairs of triples, which describe states of vertices in the left and right subtree, according to the following table, where X denotes that this pair is not a valid pair of triples. Hence we can restrict ourselves to these triples when evaluating the summation.</p><formula xml:id="formula_78">(0, 0, 0) ( 1, 0, 0) ( 1, 0, 1) ( 1, 1, 0) ( 1, 1, 1) ( 2, 1, 1) (0, 0, 0) ( 0, 0, 0) ( 1, 0, 0) ( 1, 0, 1) ( 1, 1, 0) ( 1, 1, 1) ( 2, 1, 1) (1, 0, 0) ( 1, 0, 0) X X X (2, 1, 1) X (1, 0, 1) ( 1, 0, 1) X X (2, 1, 1) X X (1, 1, 0) ( 1, 1, 0) X (2, 1, 1) X X X (1, 1, 1) ( 1, 1, 1) ( 2, 1, 1) X X X X (2, 1, 1) ( 2, 1, 1) X X X X X<label>2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Counting Steiner trees</head><p>In this section we show how to count the number of Steiner trees of a prescribed size. Let v 1 be an arbitrary fixed terminal from K . The number of Steiner trees with exactly k edges is expressed by the following formula.</p><formula xml:id="formula_79">X⊆E,| X|=k [X is a Steiner tree] = Y ⊆V ,|Y |=k-1,K ⊆Y X⊆E(Y ,Y ),|X|=|Y |-1 (Y , X) is a tree = Y ⊆V ,|Y |=k-1,K ⊆Y X⊆E(Y ,Y ),|X|=|Y |-1 det(F Y ,X ) 2 ,</formula><p>where F Y ,X is the submatrix of F with rows in Y \ {v 1 } and columns in X . Again, by plugging the permutation definition of a determinant we obtain:</p><formula xml:id="formula_80">Y ⊆V ,|Y |=k-1,K ⊆Y X⊆E(Y ,Y ),|X|=|Y |-1 f 1 , f 2 :X 1-1 → Y \{v 1 } sgn( f 1 )sgn( f 2 ) e∈ X a f 1 (e),e a f 2 (e),e ,</formula><p>where sgn( f ) = (-1) |{(e 1 ,e 2 ):e 1 ,e 2 ∈X∧e 1 &lt;e 2 ∧ f (e 1 )&gt; f (e 2 )}| .</p><p>Let us define a "partial sum" of the above formula. For every bag x ∈ T,</p><formula xml:id="formula_81">0 ≤ i ≤ |V x |, s Y ∈ {0, 1} B x , s 1 ∈ {0, 1} B x and s 2 ∈ {0, 1} B x define: A x (i, s Y , s 1 , s 2 ) = Y ⊆V x |Y |=i (K ∩V x )⊆Y Y ∩B x =s -1 Y (1) X⊆E(Y ,Y )∩E x f 1 :X 1-1 → Y \{v 1 }\s -1 1 (0) f 2 :X 1-1 → Y \{v 1 }\s -1 2 (0) sgn( f 1 )sgn( f 2 ) e∈ X</formula><p>a f 1 (e),e a f 2 (e),e .</p><p>Note that in the above definition when s Y (v) = 0, then in order to have a non-zero table entry we need to have s 1 (v) = s 2 (v) = 0, since otherwise an edge of X would be assigned (by f 1 or f 2 ) a vertex which is not its endpoint, which leaves only 5 reasonable states per vertex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leaf bag x:</head><p>A x (0, ∅, ∅, ∅) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduce vertex v bag x with child y: for</head><formula xml:id="formula_82">0 ≤ i ≤ |V x |, s Y ∈ {0, 1} B x and s 1 , s 2 ∈ {0, 1} B x A x (i, s Y , s 1 , s 2 ) = A y (i, s Y | B y , s 1 | B y , s 2 | B y ) if s Y (v) = s 1 (v) = s 2 (v) = 0, v / ∈ K A y (i -1, s Y | B y , s 1 | B y , s 2 | B y ) if s Y (v) = 1, s 1 (v) = s 2 (v) = 0 0 o t h e r w i s e .</formula><p>Without loss of generality we can assume that the graph G contains an isolated vertex, which we denote as v 1 . Since if such vertex is not present we can add it, increase k by one and update the tree decomposition accordingly. Clearly v 1 is contained in any maximal induced forest. So far by using squared determinant we counted trees, but now we want to check whether there exists an induced forest of a prescribed size. To achieve this we define a new set of edges E containing all the edges between v 1 and V \ {v 1 } (note that E ∩ E(G) = ∅). Observe, that there exists an induced forest containing v 1 with n 0 vertices and m 0 edges (hence nm 0 connected components) in G iff there exists an induced tree in G = (V , E(G) ∪ E ) containing v 1 with n 0 vertices and n -m 0 -1 edges of E . Therefore it is enough to count induced trees in G , while keeping track of the number of used edges from E . Consequently it is enough to find, whether the following sum is positive</p><formula xml:id="formula_83">Y ⊆V ,v 1 ∈Y ,|Y |=k X⊆E(Y ,Y )∪E (Y ,Y ) E(Y ,Y )⊆X |X|=|Y |-1 (Y , X) is a tree = Y ⊆V ,v 1 ∈Y ,|Y |=k X⊆E(Y ,Y )∪E (Y ,Y ) E(Y ,Y )⊆X |X|=|Y |-1 det F Y ,X 2 ,</formula><p>where F Y ,X is an orientation of an incidence matrix of G with rows from Y \ {v 1 } and columns from X . By plugging the permutation definition of the determinant we obtain the following</p><formula xml:id="formula_84">Y ⊆V ,v 1 ∈Y ,|Y |=k X⊆E(Y ,Y )∪E (Y ,Y ) E(Y ,Y )⊆X f 1 , f 2 :X 1-1 → Y \{v 1 } sgn( f 1 )sgn( f 2 ) e∈ X a f 1 (e),e a f 2 (e),e ,</formula><p>where sgn( f ) = (-1) |{(e 1 ,e 2 ):e 1 ,e 2 ∈X∧e 1 &lt;e 2 ∧ f (e 1 )&gt; f (e 2 )}| . Note that we have removed the assumption that |X| = |Y | -1 as this is enforced by the assumption that f 1 is a bijection. Observe, that from a tree decomposition of G one can obtain a tree decomposition of G while increasing the width by at most one by ensuring that v 1 is included in every bag. Therefore we assume that we are given a nice tree decomposition T of G . Let us define a "partial sum" of the above formula. For every bag x ∈ T, 0 ≤ i ≤ |V x |, s Y ∈ {0, 1} B x , s 1 ∈ {0, 1} B x and s 2 ∈ {0, 1} B x define:</p><formula xml:id="formula_85">A x (i, s Y , s 1 , s 2 ) = Y ⊆V x ({v 1 }∩V x )⊆Y |Y |=i Y ∩B x =s -1 Y (1) X⊆E x E x ∩E(Y ,Y )⊆X f 1 :X 1-1 → Y \{v 1 }\s -1 1 (0) f 2 :X 1-1 → Y \{v 1 }\s -1 2 (0)</formula><p>sgn( f 1 )sgn( f 2 ) e∈ X a f 1 (e),e a f 2 (e),e .</p><p>The dynamic programming part of our algorithm is very similar to the one described for Steiner Tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leaf bag x:</head><p>A x (0, ∅, ∅, ∅) = 1.</p><p>Introduce vertex v bag x with child y: for 0 ≤ i ≤ |V x |, s Y ∈ {0, 1} B x and s 1 ,</p><formula xml:id="formula_86">s 2 ∈ {0, 1} B x A x (i, s Y , s 1 , s 2 ) = A y (i, s Y | B y , s 1 | B y , s 2 | B y ) if s Y (v) = s 1 (v) = s 2 (v) = 0, v = v 1 A y (i -1, s Y | B y , s 1 | B y , s 2 | B y ) if s Y (v) = 1, s 1 (v) = s 2 (v) = 0 0</formula><p>o t h e r w i s e .</p><p>Note that v 1 has to be included into Y .</p><p>Forget vertex v bag x with child y: for 0</p><formula xml:id="formula_87">≤ i ≤ |V x |, s Y ∈ {0, 1} B x and s 1 , s 2 ∈ {0, 1} B x A x (i, s Y , s 1 , s 2 ) = ⎧ ⎨ ⎩ A y (i, s Y [v → 1], s 1 [v → 0], s 2 [v → 0]) if v = v 1 A y (i, s Y [v → 1], s 1 [v → 1], s 2 [v → 1]) +A y (i, s Y [v → 0], s 1 [v → 0], s 2 [v → 0]) otherwise.</formula><p>Introduce edge e = uv bag x with child y:</p><formula xml:id="formula_88">A x (i, s Y , s 1 , s 2 ) = e ∈ E ∨ s Y (u) = 0 ∨ s Y (v) = 0 A y (i, s Y , s 1 , s 2 ) + u ∈(s -1</formula><p>1 (1)\{v 1 })∩e v ∈(s -1 2 (1)\{v 1 })∩e • (-1) inv(s -1</p><formula xml:id="formula_89">A y i, s Y , s 1 u → 0 , s 2 v → 0 • a u ,e • a v ,e • s Y (u) = s Y (v) = 1 (-1)</formula><p>1, y (1),s -1 1,z (1))+inv(s -1 2, y (1),s -1 2,z (1)) .</p><p>Observe that the function s Y is used in both children, to make the choice of taking a vertex to Y or not consistent between the two subtrees.</p><p>Theorem 4.5. There exist algorithms that given a graph G solve the Feedback Vertex Set problem in time Õ(5 pw pw O(1) n 3 ) if a path decomposition of width pw is given, and in time Õ(10 tw tw O(1) n 3 ) if a tree decomposition of width tw is given.</p><p>Proof. Observe that when all the table entries of a tree decomposition rooted at an empty bag z are computed, the there exists an induced forest in G with n 0 vertices iff A z (n 0 + 1, ∅, ∅, ∅) &gt; 0. Moreover each of the t w O (1) n nodes involves operations on integers of bitlength O(n log n), since all the table entries have absolute value at most n O(n) . Similarly as in the case of Steiner Tree we can assume that each vertex v = v 1 the triple (s Y (v), s 1 (v), s 2 (v)) is of one of the following forms (0, 0, 0), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1), which is enough to prove the claimed running time for path decompositions.</p><p>In order to handle join nodes effectively, observe that there are exactly 10 pairs of triples, which describe states of vertices in the left and right subtree, according to the following table, where X denotes that this pair is not a valid pair of triples. The table is identical to the one used in the Steiner Tree problem.</p><p>(0, 0, 0)</p><p>( 1, 0, 0) (</p><p>(0, 0, 0) ( 0, 0, 0) X X X X</p><p>(1, 0, 0)</p><formula xml:id="formula_91">X (1, 0, 0) ( 1, 0, 1) ( 1, 1, 0) ( 1, 1, 1) (1, 0, 1) X (1, 0, 1) X (1, 1, 1) X (1, 1, 0) X (1, 1, 0)<label>( 1, 1, 1) X X</label></formula><p>(1, 1, 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X</head><p>(1, 1, 1) X X X 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we have given deterministic algorithms for connectivity problems on graphs of small treewidth, with the running times only single exponential in the treewidth. We have given two different techniques. Each technique solves the standard unweighted versions, but for variants (counting, weighted versions, . . . ), sometimes only one of the techniques appears to be usable. Both techniques make novel use of classic linear algebra. As the treewidth and branchwidth of a graph differ by a constant factor, our algorithms also work for graphs of bounded branchwidth, and one can easily translate our algorithms to algorithms working on branch decompositions.</p><p>Our work improves upon the Cut &amp; Count approach not only by having deterministic algorithms, but also (some of) our algorithms only use time that is linear in the number of vertices in the graph. However, the base of the exponent is somewhat larger, and an important question is whether this can be reduced. In the rank based approach, this amounts to the following question: Can Algorithm reduce from the proof of Theorem 3.7 be implemented in linear time? It would also be interesting to have a linear time implementation of Algorithm reducematchings from Corollary 3.17.</p><p>Our algorithms not only break a theoretical barrier, but can also be of practical use. This was shown in a recent algorithm engineering study by Fafianie et al. <ref type="bibr" target="#b54">[55]</ref> for the Steiner Tree problem. The following approach can be used. Run the standard DP on the tree decomposition, but as soon as we work with a table of size larger than 2 tw , we can use the rank based approach and remove table entries by finding a base. Thus, we are guaranteed that we never have to process tables of size larger than 2 tw , at the cost of running a number of Gaussian elimination steps. We believe that this approach is also viable for other problems, e.g., Hamiltonian Circuit on graphs of small treewidth.</p><p>It also may be interesting to see how this combines with a well known heuristic by Cook and Seymour for TSP <ref type="bibr" target="#b55">[56]</ref>, that uses finding a minimum length Hamiltonian Circuit in a graph with small branchwidth as a central step.</p><p>Our result combines well with a recent result by Bodlaender et al. <ref type="bibr" target="#b56">[57]</ref>, who give an algorithm that gives a 5-approximation of treewidth in time O(c tw n), for some (large) constant c. Thus, at the cost of increasing the constant at the base of the exponent significantly, we can drop the requirement that a tree decomposition is given as part of the input in about all of our results. (This constant c is however so large, that these results are only of theoretical interest.) A final very intriguing question that our work implies is the following: Is the rank based approach also usable in settings outside graphs of small treewidth? The rank based approach gives a new twist to the dynamic programming approach, in the sense that we consider the "algebraic structure" of the partial certificates in a quite novel way. Thus, this suggests a study of this algebraic structure for dynamic programming algorithms for problems in other areas.</p><p>We would like to mention that uses of the rank based approach could also be found in work on rank-width and booleanwidth <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b59">59]</ref>, but in these cases the rank structure exploited is by more explicit assumptions present in the input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>JID:YINCO AID:4064 /FLA [m3G; v1.143-dev; Prn:31/12/2014; 10:14] P.3 (1-26) H.L. Bodlaender et al. / Information and Computation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Observe that when all the table entries of a tree decomposition rooted at an empty bag z are computed, the number of Hamiltonian cycles is equal to A z (∅, ∅, ∅)/n. Moreover each of the tw O(1) n nodes involves operations on integers of bitlength O(n log n), since all the table entries have absolute value at most nO(n) .</figDesc><table /><note><p><p>Theorem 4.3. There exist algorithms that given a graph G solve # Hamiltonian Cycle in time Õ(6 pw pw O(1) n 2 ) if a path decomposition of width pw is given, and in time Õ(15 tw tw O(1) n 2 ) if a tree decomposition of width tw is given.</p>Proof.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.L. Bodlaender et al. / Information and Computation••• (••••) •••-•••Observe that we have an option of not including e into X only if e ∈ E or min(s Y (u), s Y (v)) = 0.Join bag x with children y and z: A x (s Y , s 1 , s 2 ) = s 1, y +s 1,z =s 1 s 2, y +s 2,z =s 2 A y (s Y , s 1, y , s 2, y ) • A z (s Y , s 1,z , s 2,z )</figDesc><table /><note><p><p>inv(s -1 1 (1),u )+inv(s -1 2 (1),v ) .</p>H</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We thank Fedor Fomin for pointing this out.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>[m3G; v1.143-dev; Prn:31/12/2014; 10:14] P.9 (1-26)H.L. Bodlaender et al. / Information and Computation••• (••••) •••-•••</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Piotr Sankowski for pointing us to relevant literature of matrix-multiplication time algorithms. Moreover the second author thanks Marcin Pilipczuk and Łukasz Kowalik for helpful discussions at the early stage of the paper.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.L. Bodlaender et al. / Information and Computation</head><p>Where the equivalences respectively follow by <ref type="bibr">Lemma 3.13</ref>, assumption, and Lemma 3.13 combined with linearity of matrix multiplication. In particular, M[q, r] ≡ p∈ X M[p, r]. Thus, if M[q, r] = 1 then M[p, r] = 1 for some p ∈ X and the lemma follows. 2</p><p>At this point any naive algorithm for finding a lightest basis would suffice to complete our algorithm, e.g., this is straightforward via Gaussian elimination when the rows are ordered by weight. However, aiming for a faster algorithm, the following lemma finds the required basis faster via matrix multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3.15.</head><p>There is an algorithm that, given an n ×m matrix with m ≤ n and with entries from the field F 2 and weights ω : [n] → N, finds a basis X ⊆ [n] of the row space minimizing ω(X) in O(nm ω-1 ).</p><p>Proof. First observe that a basis minimizing the weight is just a lexicographically minimum basis, as independent sets of rows form a matroid. Notice that we may assume that n ≤ 2m since we can start with the first m rows and then iteratively introduce m new rows, find a new basis and discard all introduced rows not in this basis. This takes at most n/m iterations, so if we manage to perform one iteration in time m ω , this procedure indeed implements the lemma.</p><p>Recall that a matrix is in row echelon form if 1. All nonzero rows (rows with at least one 1) are above all rows of all zeroes.</p><p>2. The leading coefficient (the first nonzero number from the left, also called the pivot) of a nonzero row is always strictly to the right of the leading coefficient of the row above it. 3. All entries in a column below a leading entry are zeroes (implied by the first two criteria)</p><p>We use the folklore fact that an n × 2n matrix can be brought into row echelon form that is obtained using only elementary row operations in time O(n ω ) (see for example <ref type="bibr" target="#b52">[53,</ref><ref type="bibr">Proposition 16.9]</ref>).</p><p>We proceed as follows: given an n × m matrix with m ≤ n ≤ 2m we first transpose it and then sort the columns on their weight in increasing order. Then we bring it in row echelon form in time O(m ω ) as discussed above. Since elementary row operations preserve linear column combinations we can now restrict ourselves to finding a minimum weight basis in the obtained matrix that is in row echelon form. And it is easy to see that in this matrix the minimum weight basis is exactly the set of columns that contain a leading 1: it is clearly a set of linearly independent columns, and if a column is not in the basis it can be expressed as a linear combination of columns to the left of it since for all non-zero entries of that column there is a leading 1 appear on the same row in a column before it by the row echelon property. 2</p><p>Now we can wrap up and prove Theorem 3.7.</p><p>Proof of Theorem 3.7. The algorithm reduce is as follows:</p><p>Clearly, A = reduce(A) ⊆ A. Since the number of columns of C equals 2 |U |-1 , X being a basis for the row space guarantees that |A | ≤ 2 |U |-1 . The running time is clearly dominated by the call to the algorithm of Lemma 3.15 since any entry of C can be computed in time |U | O (1) . Then, since C[A, •] is a |A| × 2 |U |-1 matrix, the claimed running time follows.</p><p>It remains to argue that A represents A. Suppose for a contradiction that this is not the case. Since A ⊆ A we have for every q that opt(q, A) ≤ opt(q, A ). Thus our assumption implies that opt(q, A) &lt; opt(q, A ), that is, for some q there is (p, w) ∈ A and q such that p q = {U } and w &lt; opt(q, A ). Since X is a basis of the row space of C [A, •] we know that the row C[p, •] is a linear combination of a set of rows from C[X, •]. Let Y ⊆ X be the set of indices of these rows. By Lemma 3.14, we know that there exists p i ∈ Y such that q p i = {U }; Hence, since w &lt; opt(q, A ), it must be that w i &gt; w. But we have that (X \ {p i }) ∪ {p} also is a basis of the row space of</p><p>where we use in the second-last equation that</p><p>(2)</p><p>Using this, it can also be seen that the reduce operation on A x (s) is performed in time bounded by (1) . Then the total time needed to evaluate A x (s) for every s ∈ {0, 1, 2} B x is bounded by</p><p>and the claimed running time follows by the multinomial theorem. 2</p><p>Combining the ideas from the proof of Theorem 3.18 with Lemma 1.1 and a trick from <ref type="bibr" target="#b11">[12]</ref> we obtain the following corollary:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 3.19.</head><p>There is an algorithm solving Traveling Salesman on cubic graphs in time 1.2186 n n O (1) .</p><p>The observation from <ref type="bibr" target="#b11">[12]</ref> is that on cubic graphs, we know that the degree of a vertex in a subsolution cannot be 2 if at most one incident edge is introduced, and it cannot be 0 if at least two edges are introduced since the remaining edge is not enough to make the degree 2. Hence these states can be safely ignored.</p><p>With a proof similar to that of Theorem 3.18, we can also rather easily obtain the following result:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.20. There exist algorithms that given a graph G and an integer k find a path of length k, if it exists in G and otherwise</head><p>determine that no such path exists, in time n(2 + 2 ω/2 ) pw (k + pw) O (1) if a path decomposition of width pw of G is given, and in time n(5 + 2 (ω+2)/2 ) tw (k + tw) O (1) if a tree decomposition of width tw of G is given.</p><p>The idea is to slightly modify the table entries from Section 3.4: In the definition of E x we relax the requirement</p><p>and hence the formula in the forget bag has to be altered to</p><p>). Then we can set all weights to 1 and now we are up to maximizing ω(X). It is easy to see that our approach can be altered to deal with maximization problems and hence this gives the required result since the involved weight being more than k • tw already guarantees that we have a k-path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Determinant approach</head><p>In this section we will present the determinant approach that can be used to solve counting versions of connectivity problems on graphs of small treewidth. Throughout this section, we will assume a graph G along with a path/tree decomposition T of G of width pw or tw is given.</p><p>Let A be an incidence matrix of an orientation of G, that is A = (a i, j ) is a matrix with n rows and m columns. Each row of A is indexed with a vertex and each column of A is indexed with an edge. The entry a v,e is defined to be 0 if v / ∈ e; -1 if e = uv and u &lt; v; or 1 if e = uv and u &gt; v. We assume, that all the vertices are ordered with respect to the post-ordering of their forget nodes in the tree, that is vertices forgotten in a left subtree are smaller than vertices forgotten in the right subtree, and a vertex forgotten in a bag x is smaller than a vertex forgotten in a bag which is an ancestor of x. Similarly we order edges according to the post-ordering of the introduce edge nodes in the tree decomposition.</p><p>Let v 1 be an arbitrary fixed vertex and let F be the matrix A with the row corresponding to v 1 removed. For a subset S ⊆ E let F S be the matrix with n -1 rows and |S| columns, whose columns are those of F with indices in S. The following folklore lemma is used in the proof of the Matrix Tree Theorem (see for example <ref type="bibr" target="#b53">[54,</ref><ref type="bibr">Page 203]</ref> where our matrix is denoted by N).   </p><p>Valid pairs of triples in the join node computation for counting Steiner trees.</p><p>(0, 0, 0)</p><p>Note that the choice of including (or not) the vertex v into Y is described by s Y (v) and moreover if v ∈ K then we have to include v into Y .</p><p>Forget vertex v bag x with child y: for 0</p><p>Introduce edge e = uv bag x with child y:</p><p>Join bag x with children y and z:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>)) .</head><p>Observe that the function s Y is used in both children, to make the choice of taking a vertex to Y or not consistent between the two subtrees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 4.4.</head><p>There exist algorithms that given a graph G count the number of Steiner trees of size i for each 1 ≤ i ≤ n -1 in time Õ(5 pw pw O(1) n 3 ) if a path decomposition of width pw is given, and in time Õ(10 tw tw O(1) n 3 ) if a tree decomposition of width tw is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof.</head><p>Observe that when all the table entries of a tree decomposition rooted at an empty bag z are computed, the number of Steiner trees with exactly i edges is equal to A z (i + 1, ∅, ∅, ∅). Moreover each of the t w O (1) n nodes involves operations on integers of bitlength O(n log n), since all the table entries have absolute value at most n O(n) .</p><p>As we have already noted we can assume that for each vertex v = v 1 the triple (s Y (v), s 1 (v), s 2 (v)) is of one of the following forms (0, 0, 0), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1), which is enough to prove the claimed running time for path decompositions.</p><p>In order to handle join nodes effectively, observe that there are exactly 10 pairs of triples, which describe states of vertices in the left and right subtree, according to the Table <ref type="table">2</ref>, where X denotes that this pair is not a valid pair of triples. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Feedback vertex set</head><p>Note that to solve the Feedback Vertex Set problem it is enough to solve its dual, which will be easier to work with in the squared determinant framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maximum Induced Forest</head><p>Input: An undirected graph G, an integer k and a nice tree decomposition T of G of width tw. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deterministic single exponential time algorithms for connectivity problems parameterized by treewidth</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cygan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nederlof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICALP</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="196" to="207" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graph minors, III: planar tree-width</title>
		<author>
			<persName><forename type="first">N</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Seymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comb. Theory, Ser. B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="64" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<title level="m">Treewidth: structure and algorithms</title>
		<imprint>
			<publisher>SIROCCO</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="11" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A linear-time algorithm for finding tree-decompositions of small treewidth</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1305" to="1317" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The monadic second-order logic of graphs, I: recognizable sets of finite graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Courcelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Comput</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="75" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Algorithm</forename><surname>Design</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Invitation to Fixed-Parameter Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Niedermeier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Which problems have strongly exponential complexity?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Impagliazzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paturi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="512" to="530" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Known algorithms on graphs on bounded treewidth are probably optimal</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lokshtanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saurabh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SODA</title>
		<imprint>
			<biblScope unit="page" from="777" to="789" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Locally checkable proofs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Göös</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suomela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>PODC</publisher>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Catalan structures and dynamic programming in H -minor-free graphs</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Thilikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1606" to="1622" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Solving connectivity problems parameterized by treewidth in single exponential time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cygan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nederlof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pilipczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pilipczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M M</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Wojtaszczyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>FOCS</publisher>
			<biblScope unit="page" from="150" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Matching is as easy as matrix inversion</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mulmuley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="113" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<title level="m">Introduction to Automata Theory, Languages, and Computation, 2nd edition</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Determinant sums for undirected Hamiltonicity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Björklund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>FOCS</publisher>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Shortest cycle through specified elements</title>
		<author>
			<persName><forename type="first">A</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Husfeldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taslaman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SODA</title>
		<imprint>
			<biblScope unit="page" from="1747" to="1753" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Limits and applications of group algebras for parameterized problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Koutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICALP</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="653" to="664" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Faster algebraic algorithms for path and packing problems</title>
		<author>
			<persName><forename type="first">I</forename><surname>Koutis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICALP</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="575" to="586" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On determinants, matchings, and random algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>FCT</publisher>
			<biblScope unit="page" from="565" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finding paths of length k in O (2 k ) time</title>
		<author>
			<persName><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="315" to="318" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Multiplying matrices faster than Coppersmith-Winograd</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>STOC</publisher>
			<biblScope unit="page" from="887" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How to find long paths efficiently</title>
		<author>
			<persName><forename type="first">B</forename><surname>Monien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Discrete Math</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="239" to="254" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Flats in matroids and geometric graphs</title>
		<title level="s">Combinatorial Surveys</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="45" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A parameterized view on matroid optimization problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">410</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page" from="4471" to="4479" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Kratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wahlström</surname></persName>
		</author>
		<title level="m">Representative sets and irrelevant vertices: new tools for kernelization</title>
		<imprint>
			<publisher>FOCS</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="450" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient computation of representative sets with applications in parameterized and exact algorithms</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lokshtanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saurabh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SODA</title>
		<imprint>
			<biblScope unit="page" from="142" to="151" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Large Networks and Graph Limits</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>American Mathematical Society</publisher>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the &quot;log rank&quot;-conjecture in communication complexity</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Spieker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="567" to="588" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<title level="m">Communication complexity: a survey, in: Paths, Flows, and VLSI-Layout</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="235" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Communication complexity and combinatorial lattice theory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Saks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="322" to="349" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Color-coding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="844" to="856" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On limited nondeterminism and the complexity of the V-C dimension</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
		<idno type="DOI">10.1006/jcss.1996.0058</idno>
		<ptr target="http://dx.doi.org/10.1006/jcss.1996.0058" />
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="170" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Randomized divide-and-conquer: improved path, matching, and packing algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kneis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mölle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rossmanith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1006/jcss.1996.0058</idno>
		<ptr target="http://epubs.siam.org/doi/abs/10.1137/080716475" />
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2526" to="2547" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">On search, decision and the efficiency of polynomial-time algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Fellows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Langston</surname></persName>
		</author>
		<idno type="DOI">10.1137/080716475</idno>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>STOC</publisher>
			<biblScope unit="page" from="501" to="512" />
		</imprint>
	</monogr>
	<note>extended abstract</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On linear time minor tests with depth-first search</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<idno type="DOI">10.1006/jagm.1993.1001</idno>
		<ptr target="http://dx.doi.org/10.1006/jagm.1993.1001" />
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">On feedback vertex set new measure and new structures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1006/jagm.1993.1001</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>SWAT</publisher>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improved algorithms for feedback vertex set problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Villanger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1188" to="1198" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Algorithmic graph minor theory: decomposition, approximation, and coloring</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Hajiaghayi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>FOCS</publisher>
			<biblScope unit="page" from="637" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The bidimensionality theory and its algorithmic applications</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hajiaghayi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. J</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="292" to="302" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Trimmed Möbius inversion and graphs of bounded degree</title>
		<author>
			<persName><forename type="first">A</forename><surname>Björklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Husfeldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kaski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koivisto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="637" to="654" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The traveling salesman problem for cubic graphs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Eppstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Graph Algorithms Appl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="81" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">On the number of Hamilton cycles in bounded degree graphs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gebauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ANALCO</publisher>
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">An improved exact algorithm for cubic graph tsp</title>
		<author>
			<persName><forename type="first">K</forename><surname>Iwama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakashima</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>COCOON</publisher>
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On two techniques of combining branching and treewidth</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gaspers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saurabh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Stepanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fast Hamiltonicity checking via bases of perfect matchings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cygan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kratsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nederlof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>STOC</publisher>
			<biblScope unit="page" from="301" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A simple and fast approach for solving problems on planar graphs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Thilikos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>STACS</publisher>
			<biblScope unit="page" from="56" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Efficient exact algorithms on planar graphs: exploiting sphere cut decompositions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Penninkx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="790" to="810" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Linear time algorithms for NP-hard problems restricted to partial k-trees</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arnborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Proskurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="24" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>Kloks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Treewidth, Computations and Approximations</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">842</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Combinatorial optimization on graphs of bounded treewidth</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M C A</forename><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. J</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="269" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Branch and tree decomposition techniques for discrete optimization</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M C A</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kolotoǧlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tutorials in Operations Research</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Problems parameterized by treewidth tractable in single exponential time: a logical approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pilipczuk</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2034006.2034055" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Mathematical Foundations of Computer Science, MFCS&apos;11</title>
		<meeting>the 36th International Conference on Mathematical Foundations of Computer Science, MFCS&apos;11<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="520" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Algebraic Complexity Theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bürgisser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Shokrollahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">315</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Proofs from THE BOOK</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>th edition</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Speeding up dynamic programming with representative sets-an experimental evaluation of algorithms for Steiner tree on tree decompositions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fafianie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nederlof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><surname>Ipec</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">8246</biblScope>
			<biblScope unit="page" from="321" to="334" />
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Tour merging via branch-decomposition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Seymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS J. Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="248" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">An O (c k n) 5-approximation algorithm for treewidth</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Drange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Dregi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lokshtanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pilipczuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>FOCS</publisher>
			<biblScope unit="page" from="499" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S.-I</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Approximating clique-width and branch-width</title>
		<author>
			<persName><forename type="first">P</forename><surname>Oum</surname></persName>
		</author>
		<author>
			<persName><surname>Seymour</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jctb.2005.10.006</idno>
		<ptr target="http://dx.doi.org/10.1016/j.jctb.2005.10.006" />
	</analytic>
	<monogr>
		<title level="j">J. Comb. Theory, Ser. B</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="514" to="528" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Boolean-width of graphs</title>
		<author>
			<persName><forename type="first">B.-M</forename><surname>Bui-Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Telle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vatshelle</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jctb.2005.10.006</idno>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">412</biblScope>
			<biblScope unit="issue">39</biblScope>
			<biblScope unit="page" from="5187" to="5204" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
