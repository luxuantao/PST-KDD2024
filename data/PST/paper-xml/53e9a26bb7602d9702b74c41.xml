<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Studying Driver Attention and Behaviour for Three Configurations of GPS Navigation in Real Traffic Driving</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Brit</forename><forename type="middle">Susan</forename><surname>Jensen</surname></persName>
							<email>britjensen@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Mikael</forename><forename type="middle">B</forename><surname>Skov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nissanthen</forename><surname>Thiruravichandran</surname></persName>
							<email>nissanthen@gmail.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">HCI Lab</orgName>
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<addrLine>Selma Lagerlöfs Vej 300</addrLine>
									<postCode>9220</postCode>
									<settlement>Aalborg East</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>April 10-15</addrLine>
									<postCode>2010</postCode>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Studying Driver Attention and Behaviour for Three Configurations of GPS Navigation in Real Traffic Driving</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">630AF12BE5B5A74CA981F6F40B61875C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GPS</term>
					<term>navigation guide</term>
					<term>in-vehicle systems</term>
					<term>eye glances</term>
					<term>output modalities</term>
					<term>driving</term>
					<term>field experiment H5.m. Information interfaces and presentation (e.g.</term>
					<term>HCI): Miscellaneous CHI 2010: Driving</term>
					<term>Interrupted</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Global Positioning System (GPS) navigation systems were amongst the top selling consumer technologies in 2008 and research has indicated that such technologies could affect driving behaviour. In this paper, we study how different output configurations (audio, visual and audio-visual) of a GPS system affect driving behaviour and performance. We conducted field experiments in real traffic with 30 subjects. Our results illustrated that visual output not only causes a substantial amount of eye glances, but also led to a decrease in driving performance. Adding audio output decreased the number of eye glances, but we found no significant effects on driving performance. Although the audio configuration implied much fewer eye glances and improved driving performance, several participants expressed preference for the audio/visual output.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>The market of in-vehicle systems has grown exponentially over the last three decades -a proliferation, which was set in motion by a reduction in hardware costs as well as innovation in communication and information technology <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>. In-vehicle systems serve a variety of purposes, e.g. navigational guidance, media players, climate controls, and communication. The development of in-vehicle systems has initiated debates and inspired research on road and driving safety. In-vehicle systems may provide compelling means to enhance mobility <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23]</ref>, but research has shown that these systems may distract the driver and hereby divert focus from the primary task of driving, which could lead to driving accidents <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref>. Also, in-vehicle systems have become increasingly sophisticated due to the integration of advance functionalities, novel interaction techniques, and emerging wireless network infrastructures. This progression may present the driver with tasks that are unrelated to the driving task (secondary tasks), which in hand may require high attentive interaction.</p><p>Global Positioning System (GPS) navigation systems were amongst the top selling consumer technologies in 2008. In the recent years the GPS has become a subject of research. Current research on GPS systems has shed light on the way in which the utilization of these navigation systems may alter driving practices and affect the way people understand the environment in which they navigate <ref type="bibr" target="#b21">[22]</ref>. Studies have also addressed important usability aspects by evaluating the learn ability and memorability of a GPS system in order to identify problems associated with first-time and infrequent use <ref type="bibr" target="#b17">[18]</ref>. Furthermore, additional research studies focus on how navigational information should be presented in order to enhance user comprehension or satisfaction <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>However, we still have a rather limited understanding of GPS navigation systems on their effect on driver attention and driving behaviour <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. The inherent challenge of dividing attention of the driver between road information and GPS navigation directions calls for further experiments and studies how to design such GPS systems. Particularly we need to understand how navigational outputs influence driving performance <ref type="bibr" target="#b15">[16]</ref> and especially if we consider how secondary task performance can lead to various kinds of accidents <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. Thus, we need research that investigates how such systems are used in natural contexts, i.e. as field studies involving real traffic driving <ref type="bibr" target="#b7">[8]</ref>.</p><p>In this paper, we investigate different output modalities of a GPS navigation guide on their effects on driving behaviour and performance by comparing three output configurations; audio, visual and audio-visual. The paper is structured as follows. First, we present previous research on in-vehicle systems research. Secondly, we outline our experiment with the adapted measures used to investigate driver behaviour and driving performance. Next, we present results from the experiment and finally, we discuss the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>The literature on in-vehicle systems research is particularly concerned with effects of such systems on driver attention, driver distraction, and driving behaviour <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>. Research studies separate between different types of driver distraction where withdrawal of attention from the driving scene is the most commonly used. According to Brown <ref type="bibr" target="#b3">[4]</ref>, withdrawal of attention can either be general or selective. The general withdrawal of attention (or eyes-off-the-road) refers to the insufficient (visual) perception of the driving information, e.g. when drivers operate a media player while glancing at it <ref type="bibr" target="#b12">[13]</ref>. Selective withdrawal of attention (or mind-off-the-road) is a more subtle type of distraction as it involves e.g. perceptual interpretation or decision selection <ref type="bibr" target="#b14">[15]</ref>. Horberry et al. <ref type="bibr" target="#b16">[17]</ref> verify that the level of complexity of a given secondary task is correlated with the level of driver distraction. Drivers are required to have their eyes on the road in order to ensure safe driving; hence secondary tasks involving visual attention can induce safety risks.</p><p>Research studies have attempted to reduce driver distraction through novel means of interaction to support secondary tasks. Geiger et al. <ref type="bibr" target="#b10">[11]</ref> conducted a comparative study in which they evaluated the use of a tactile interface and a gesture-based interface for secondary tasks. Their findings showed that the use of the tactile interface entailed higher task completion times and lower recognition performance. However, the gesture-based interface enabled the drivers to perform secondary tasks more accurately, and they further perceived the gesture-based interface to be less distracting.</p><p>Bach et al. <ref type="bibr" target="#b1">[2]</ref> compared three interaction techniques for a media player -a tactile interface, a touch interface, and a gesture-based interface. The interaction techniques were compared in two complementary experiments. The findings showed an inclination towards the gesture-based interface. The touch interface allowed drivers to complete secondary tasks with significantly fewer eye glances in comparison to the tactile and touch interfaces. The tactile interface lacked intuitiveness; the system demanded perceptual resources in order to be operated and hereby diverting attention from the primary task. The touch interface introduced a lower task completion time and fewer interaction errors, in comparison to the other two interfaces.</p><p>While novel input techniques are important contributions to the field of in-vehicle systems research, it is also essential to consider potential opportunities and limitations of output modalities <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23]</ref>. Green et al. <ref type="bibr" target="#b15">[16]</ref> evaluated four configurations of a GPS navigation guide -auditory, auditory with landmarks, visual and visual with landmarks -in a simulated driving setting. The aim of the study was to clarify how much attention the systems required and how the participants perceived the use of the systems. The participants watched a video recording of a driver's view and received route guidance information. They were asked to press a button when they saw the intersections described by the GPS navigation guide. The study showed that the auditory configuration required less attention and gave the lowest driver reaction time when compared to the visual configuration. When supplementing the audio and visual configurations with information on landmarks no penalties to driver attention incurred. The participants predominantly favoured configurations that included landmarks as opposed to the ones without landmarks. They generally expressed a slight inclination towards visual output.</p><p>A recent empirical study by <ref type="bibr">Moldenhauer and McCrickard [23]</ref> partly confirms the results by Green et al. <ref type="bibr" target="#b15">[16]</ref>. They investigated trade-offs involving information conveyance by evaluating four information modalities -audio, audio with overhead map, visual and visual with overhead mapin a driving simulator. Their results showed that the visual modality with an overhead map resulted in the highest number of driving errors and highest reaction time, whereas participants expressed that the information provided by the audio-based modalities were more difficult to comprehend. They acknowledged that a more immersive setting could provide further validation of the results.</p><p>While the above studies provide insights into the potential opportunities and limitations of different output modalities of in-vehicle systems, we still need further investigations on such modalities and especially we need studies conducted in real traffic driving and not only driving simulators. Bach et al. <ref type="bibr" target="#b0">[1]</ref> found that a considerable part of in-vehicle system research is conducted in either driving simulators or as controlled driving situations. Especially, we need studies on GPS navigation guides focusing on output modalities, as these systems are highly output-oriented towards the driver and less input-oriented. Leshed et al. <ref type="bibr" target="#b21">[22]</ref> conducted a study on the use of GPS guides in real traffic driving where they argue that GPS navigation sometimes can disengage people from their surrounding environment or context, but they also argue that these systems have the potential to open up novel ways to engage with the context. While their study provides design implications, the focus is on content of GPS guides rather than interaction and output modalities.</p><p>Inspired by previous research we evaluated the navigational output provided by a GPS system. As stated above, the majority of in-vehicle systems research has been conducted in controlled and simulated settings <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23]</ref>. We chose to conduct the experiment in the field (in real traffic driving) due to the inadequacy of immersive settings within the area of in-vehicle research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXPERIMENT</head><p>The purpose of our experiment was to study how different output modalities of a GPS navigation guide affect drivers and driving performance during real traffic driving. We included three output modalities namely audio, visual, and audio-visual. In the following, we outline the experiment, the participants, GPS system, procedure, and data analysis.</p><p>Participants 30 people ranging between 21 -38 years of age ( = 25.2, SD = 2.65) participated in the experiment. All participants (7 women and 23 men) carried valid driver licenses and had between 3 and 19 years of driving experience ( = 6.85, SD = 2.71). They drove by their own estimate between 0 -40.000 kilometres per year ( = 7598.33, SD = 8557.9). On the basis of self-assessment -9 participants indicated that they had poor knowledge of Aalborg and its surroundings, 15 indicated basic knowledge, and finally 6 claimed that they had good knowledge of Aalborg. The average amount of kilometres driven per year was equalled out between the three participant groups. Each participant group indicated equal acquaintance with the greater Aalborg area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Design</head><p>We utilized a between-subject experimental design using output modality configurations (audio, visual, audio-visual) as independent variables and dependent variables included primary driving task performance (longitudinal control, lateral control, traffic violations), secondary driving task performance (navigational errors and task completion time) and eye glance behaviour (below 0.5 seconds, 0.5 -2.0 seconds, above 2 seconds).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPS Navigation Guide</head><p>The GPS navigation guide used in the experiment was a TOMTOM GO 930, which at the time of the experiment was a state-of-the-art model that had received favourable reviews <ref type="bibr" target="#b6">[7]</ref>. The GPS came pre-installed with maps and a POI (Points of Interests) covering Europe.</p><p>The main input interface is a 4.3" touch screen with a 480 x 272 pixel resolution for visual output and an internal speaker for audio output. With participants having Danish as their native language, we selected the language setting to match this for both visual and audio output. The three test configurations (audio, visual, audio-visual) consisted of different combinations of output modalities. The audio configuration consisted exclusively of the system's audio output, while the visual configuration consisted exclusively of the system's visual output. The configuration on audiovisual comprised both output modalities.</p><p>Audio output consists of navigational instructions presented through pre-recorded speech (hence no speech output for street names was available) using a female voice. Nixon et al. found that female voices are easier to hear in noisy environments <ref type="bibr" target="#b23">[24]</ref>. Each instruction included an estimated distance and a direction -for example 'after 200 meters, turn left' -followed by a repetition of the direction. If there was a need to perform a sequence of turns (within 200 meters of the first turn) this would be included in the instructions -for example 'after 200 meters, turn right and then turn left'. On longer stretches of road (over 500 meters) the system would add an additional reminder. Visual output in the GPS system consisted of the 'driving view' (illustrated in figure <ref type="figure" target="#fig_0">1</ref>). This screen consists of a 3D map showing the current part of the route. The selected route is marked with red line, manoeuvres are illustrated with green icons and the current position of the vehicle is shown with a blue arrow. The bottom part of the screen shows navigation instructions including distance, estimated arrival time, signal strength among others. The GPS navigation guide was placed at the lower centre of the windscreen (as recommended in the instruction booklet) for all configurations (shown in figure <ref type="figure" target="#fig_1">2</ref>). This ensured that participants using visual output unobstructed view of the visual output. For the sessions involving audio output, the internal speaker volume was set to 75%. None of the participants found it necessary to adjust the volume during the experiment. Furthermore, the GPS guide was slanted in a manner, which ensured that the participants were only able to receive auditory output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks</head><p>The experiment comprised four scenario-driven tasks -the tasks involved driving to predetermined locations and collecting associates of the University -for example "Collect Lisa Nielsen who lives on Poseidonvej 15, 9210". By applying scenario-driven tasks, we sought to promote a natural setting for the field trials. The GPS system served as an optional component allowing participants to approach a given task unassisted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>We conducted our experiment as a field experiment in real traffic. All participants drove vehicles (C-segment -small family cars) equipped with manual transmissions. The field trials were conducted during daytime and in good weather conditions. As such, we strived for consistency between the sessions and to minimize safety hazards. We conducted two pilot tests to test and adjust the equipment.</p><p>The participants were classified as one of the following user types -GPS system users or non-users -the decisive factor for this classification process was based on whether or not the participants had used GPS systems previously. The participants were randomly assigned to a configuration until an equal distribution of GPS system users (15) and nonusers <ref type="bibr" target="#b14">(15)</ref> were attained -we assigned five GPS system users and five non-users to each of the three configurations (which constitute three groups of ten). We ensured that each group had at least one female participant (audio = 3, visual = 3, audio-visual = 1). We collected demographic data of the participants through an interview.</p><p>Before the driving sessions, participants were introduced to the experiment. First, we introduced the GPS system and the car and we stressed the fact that they had to adhere to the general traffic rules. Participants were told that they were supposed to drive around the greater Aalborg area to pick up different people. They were given oral instructions of addresses to visit and had to type in these addresses in the GPS system. Secondly, participants were allowed to take a test drive to familiarize them with the car. Also, we stressed that we were testing different configurations of the GPS system and not their performance and they were told that they could pull over at any time while driving if they needed a break. Finally, participants were asked to sign an information and consent form. All field trials started at the Computer Science Department at Aalborg University. The participants were not given tasks during driving -each task was presented prior to the associated driving segment. The estimated length of the entire route was 16 kilometres -the segments comprised both rural and densely populated areas in order to expose the participants to varied traffic environments and areas of Aalborg, which they may either be familiar or unacquainted with. The permitted speed limit ranged from 30 -80 kilometres per hour in the four driving segments -we avoided motorways due to safety concerns.</p><p>All field trials were filmed using two camcorders -one of the camcorders was mounted on the dashboard in order to capture eye glances. The second camcorder was affixed on the front passenger seat to record lateral and longitudinal control errors, and driver view (as seen through the front windscreen). We refrained from asking questions during the field trials. Dialogues only took place when participants initiated a conversation. The test manager was sitting next to the participant and a logger was sitting at the back seat.</p><p>The test manager ensured that the experiment proceeded as intended while the logger collected qualitative data, e.g. verbal comments from participants.</p><p>The participants were debriefed as a concluding segment of the experiment. We conducted a semi-structured interview where participants were asked about subjective matters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>Inspired by previous research studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>, we integrated several measures for understanding driving behaviour and driving performance. Our measures included 1) primary driving task performance (longitudinal and lateral control errors, traffic light and directional indicator violations), 2) secondary driving task performance (task completion times and navigational errors), and also 3) eye glance behaviour (below 0.5 seconds, 0.5 -2.0 seconds, above 2.0 seconds).</p><p>We analyzed the 30 video recordings (one for each session) both individually and collaboratively. One recording was omitted (only for the eye glance measure analysis) due to incomplete data collection caused by a technical error in the camera. The data analysis was done in three steps. First, we initially analyzed three randomly chosen video recordings collaboratively in order to establish guidelines and metrics for the subsequent individual video analysis. Secondly, two authors analyzed 16 video recordings individually reporting incidents on the selected measures. We randomly selected ten of the recordings for analysis of both authors to ensure procedural consistency. The produced incident lists of these ten recordings were compared and an inter-rate reliability test (weighted Cohen's Kappa) gave Κ=0.75 corresponding to a substantial agreement according to Fleiss et al. <ref type="bibr" target="#b9">[10]</ref>. Thirdly, we compared and merged all incident lists into one combined list. If disagreeing, the authors would analyze the recordings once more to determine whether the concerned incident was valid or not. In the following, we outline the included measures in more detail.</p><p>1) The first measure was primary driving task performance and involved several variables <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b26">27]</ref>. We integrated longitudinal and lateral control errors, traffic lights crossing and directional indicator violations. Longitudinal control errors were defined as speeding violations in three different categories (inspired by current Danish legislation) namely speeding level 1, 2, and 3. Speeding level 1 was defined as participants exceeding the prescribed speed limit by three kilometres per hour (implies a speeding fine), speeding level 2 was when participants exceeded the speed limit by 30 percent (implies endorsement of license -one penalty point), and finally speeding level 3 was when participants exceeded the prescribed speed limit by 60 percent (implies loosing the driving license). Lateral control errors denote loss of lateral vehicle control, i.e. lane excursions. We also recorded incidents where participants did not adhere to the stop signals assigned by traffic lights and incidents where participants failed to activate the directional indicator as required by Danish traffic regulations.</p><p>2) Secondary driving task performance denotes incidents in which participants diverged from the specified route due to misinterpretation of the navigational information provided by the GPS system. We also recorded the completion times for each of the four tasks.</p><p>3) Eye glance behaviour is a commonly applied measure for driver attention <ref type="bibr" target="#b11">[12]</ref>. We adapted the coding of Bach et al. <ref type="bibr" target="#b1">[2]</ref> where eye glances were measured from three categories namely below 0.5 seconds (not eye fixation <ref type="bibr" target="#b28">[29]</ref>), between 0.5 and 2.0 seconds, and above 2.0 seconds (drivers are usually reluctant to continue without roadway information for more than 2 seconds <ref type="bibr" target="#b24">[25]</ref>). Our coding involved counting recorded video frames where category one (below 0.5 seconds) corresponds to less than 14 frames, category 2 (0.5 -2.0 seconds) corresponds to 14 -50 frames, and category 3 (above 2.0 seconds) is more than 50 frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head><p>In this section we present the results from the experiment. First, we will present primary driving task performance including longitudinal and lateral control errors, next we present secondary driving task performance and finally eye glance behaviour. The results were subjected to one-way independent-samples ANOVA tests and Tukey HSD post hoc tests. The results are presented in tables 1, 2, 3, and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Primary Driving Task Performance</head><p>We integrated metrics for measuring primary driving task performance primarily longitudinal control errors (speeding violations) but also lateral control errors (lane excursions), directional indicators, and traffic light violations.</p><p>Our results showed that visual and audio-visual participants in general had many more longitudinal control errors (i.e. speeding violations) than audio participants and that they had more lateral control errors (i.e. lane excursions) during driving. In total, we identified 647 violations concerning primary driving task performance across all configurations (Audio = 110, Visual = 265, Audio-Visual = 272). Of the 647 primary driving task violations, 522 are classified as longitudinal control errors (illustrated in table 1). When assessing speeding violations we identified some major differences between the three configurations.</p><p>Audio participants had significantly fewer speeding level 1 violations (&gt; 3 km/t) than both visual and audio-visual participants. Our experiment showed that participants using the audio configuration on average had 8.8 violations during the trails whereas visual participants on average had 17.9 violations and audio-visual participants had 19.3</p><p>violations. An ANOVA test showed significant difference among the three configurations, F(2,27) = 6.67, p &lt; 0.01. A Tukey HSD post hoc test showed that audio-visual had significantly more speeding violations than audio (p &lt; 0.01) and audio had significant fewer violations than visual (p &lt; 0.05). A comparison between the visual and audio-visual configurations showed no significant difference.</p><p>When looking at speeding level 2 violations (exceeding the allowed speed limit by more than 30 percent), we found a similar pattern as with speeding 1 violations. Audio-visual participants had more than 6 times as many speeding 2 violations than audio participants. The audio configuration had on average 0.6 violations while visual participants had 2.2 and participants in the audio-visual configuration had 3.3 violations, F(2,27) = 5.78, p &lt; 0.01. Not surprisingly, a post-hoc test confirmed that audio-visual participants had significantly more violations than audio participants (p &lt; 0.01). On the other hand, while visual participants had more than 3 times as many eye glances as the audio participants this difference was not significant. Finally, we found no statistically significant differences between the visual and audio-visual configurations.</p><p>We identified only one speeding level 3 violation incident (exceeding the prescribed speed limit by 60 percent) in the visual configuration. Thus, no significant or key differences were found for this speeding violation. The three speeding violation levels showed key differences between the three configurations of the GPS navigation guide and hence, this is also illustrated in the total number of speeding violations. First, we saw that participants using the audio configuration had fewer speeding violations in total in comparison to participants using the visual and audio-visual configurations. This may not come as a major surprise when the results from the experiment show that the visual (accounts for 202 speeding violations) and audiovisual configurations (accounts for 226 speeding violations) both have more than twice the speeding violations in comparison to the audio configuration (accounts for 94 speeding violations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Audio</head><p>Our participants using the audio configuration had an average of 9.4 speeding incidents, participants using the visual configuration had 20.2, while finally the participants using the audio-visual had 22.6, F(2, 27) = 8.09, p &lt; 0.01. A Tukey HSD post hoc test showed significant difference at the 5% level between audio and visual participants as well as strong significant difference at the 1% level between audio and audio-visual participants. When re-assessing the incidents related to longitudinal control we see that there are no significant differences between the audio-visual and visual configurations -both these configurations constitute almost an equal number of speeding violations.  Besides speeding violations, we further analyzed additional primary driving task performance measures including lateral control errors (lane excursions), directional indicator errors, and traffic light crossing violations (see table <ref type="table" target="#tab_2">2</ref>). In total, we identified 77 lateral control errors. When comparing the lateral control errors, we see a difference as participants in the visual and audio-visual configurations collectively constituted 95% of all errors. Participants in the audio configuration accounted for only two errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Audio</head><p>Our experiment showed that participants using the audio configuration on average had 0.4 lateral control errors, participants using the visual configuration had 4.3, while participants using audio-visual had 3.0, F(2,27) = 4.92, p &lt; 0.05. Using a post-hoc test we found that this difference lies between the audio and visual configurations where the participants using the visual configuration constitute a total of 43 lateral control errors, which is significantly more than the number of lateral control errors committed by audio participants (p &lt; 0.05). Somewhat surprisingly there is no significant difference between audio and audio-visual despite the fact that the audio-visual participants had more than seven times as many incidents.</p><p>We further compared the results on violations related to traffic light (not adhering to the caution and stop signals assigned by traffic lights) and the directional indicators (failing to activate the directional indicators). We found no significant differences between the three configurations where participants using the audio configuration had an average of 1.0 violations, participants using a visual configuration had 1.7 violations while participants using the audio-visual configuration had 1.3 violations, F(2,27) = 0.69, p &gt; 0.51. When assessing traffic light violations, the results show that the number of incidents is almost equally distributed amongst the three configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Secondary Driving Task Performance</head><p>When assessing secondary driving task performance, we used the following measurement variables; task completion time and navigational errors. Our results revealed that the three configurations were relatively alike and participants were rather alike within each configuration especially for task completion time (shown in table <ref type="table" target="#tab_3">3</ref>). Task completion times for each of the four tasks showed an average of 24.13 minutes (SD=1:44) for audio users, 22.55 minutes (SD=0:58) for visual and 23.05 minutes (SD=1:06) for audio-visual users. We also identified 34 navigational errors (Audio = 10, Visual = 14, Audio-Visual = 10). The results do not reveal any significant differences when compared across the three configurations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eye Glance Behaviour</head><p>Eye glances were categorized into three categories based on previous research <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. These include category one glances (below 0.5 seconds), category two glances (0.5 -2.0 seconds) and category 3 glances (above 2.0 seconds). Due to technical problems during the trails, the audio-visual configuration included one participant where eye glances could not be identified.</p><p>Our results revealed that participants in both the visual and audio-visual configurations had many more eye glances than audio participants (as shown in table <ref type="table" target="#tab_4">4</ref>). While this is not surprising in itself, the rather high number of glances for visual and audio-visual is surprising. We identified a total of 3977 glances within all the field trials.</p><p>For the category one glances (below 0.5 seconds), our experiment showed that participants on average had 6.6 in the audio configuration, 45.4 in visual and 51.67 glances in audio-visual. A one-way ANOVA test confirms that there is a significant differences among the three configurations, F(2,26) = 14.65, p &lt; 0.001. Subjecting these results to a Tukey HSD post hoc test showed that participants using the audio configuration have significantly less category one glances than participants in the visual and audio-visual configurations, p &lt; 0.01. This may not come as a surprise when the results show that audio participants only account for 7% of the recorded glances in the category one variable. The remaining occurrences in category one are almost equally distributed between the visual and audio-visual configurations; hence we found no significant differences. When looking at category two glances (0.5 -2 seconds), our experiment revealed a surprising total of 2905 glances (Audio = 28, Visual = 1783, Audio-Visual = 1094) and we can see that participants in both the visual and audio-visual configurations had an extremely high number of glances. The audio participants had on average 2.8 glances, 178.3 for participants using visual and 121.56 for participants using audio-visual, F(2,26) = 95.93, p &lt; 0.001. A post-hoc test showed significant differences at the 1% level between the visual configuration and the two other configurations. This is also reflected in the results where participants using the visual configuration accounted for 73% of all category two glances, whereas audio participants accounted for less than 1%. The post-hoc test also revealed a significant difference between audio and audio-visual, where the audio configuration (28 incidents) has nearly none compared to audio-visual (1094 incidents), p &lt; 0.01.</p><p>When assessing category three glances (above 2 seconds), we found a total of 87 glances (Audio = 0, Visual = 67, Audio-Visual = 20), where audio-visual participants on average had 2.33, participants using visual had 6.7 and audio had 0.0. A one-way ANOVA test showed that the difference among the configurations is significant, F(2,26) = 12.71, p &lt; 0.001. The visual configuration participants accounted for 76% of all category three glances. A post-hoc test showed that participants using visual have significantly more category three glances than participants in the audio configuration (p &lt; 0.01). A comparison of the visual and audio-visual configurations reveals a significant difference, where participants using visual have more category three glances than audio-visual (p &lt; 0.01). Interestingly, we saw approximately the same glance ratio between the visual and the audio-visual configurations as for category two glances, participants using the visual configuration again accounted for three times as many glances as audio-visual participants.</p><p>Not surprisingly, we identified large differences on total number of glances between the three configurations. From the total of 3977 glances, 94 glances occurred in the audio configuration, 2304 in visual and 1579 in audio-visual.</p><p>Participants using the audio configuration had an average of 9.4, participants in visual had 230.4 and audio-visual participants had 175.44 glances, F(2,26) = 74.49, p &lt; 0.001. The post-hoc test showed that the visual configurationwhich accounted for 58% of all the glances -has a significantly higher number of glances compared to the audio configuration, which only accounted for 2.3% of the glances (p &lt; 0.01). When comparing the audio and audiovisual configurations, we found that the audio configuration has a significantly lower number of glances than audiovisual (p &lt; 0.01). Further, the difference between the visual and audio-visual configurations showed significance at the 5% level. Audio-visual participants accounted for 39.7% of all glances -nonetheless, participants in the visual configurations accounted for significantly more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPS Versus Non-GPS Users</head><p>We divided the participants between the configurations according to whether they had previous experiences with GPS navigation guides. Each configuration had five GPS users and five non-GPS users. We identified no significant differences between GPS and non-GPS users. However, we did find that GPS participants on average had fewer eye glances than non-GPS participants on all three categories 140.33 against 124.80, but this difference was not significant. However, GPS users had a higher number of speeding violations and driving errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>Previous research indicates that the use of GPS systems can result in decreased driving performance. We set out to evaluate three configurations of output modalities in order to shed light on how drivers are affected by such a highly output oriented device. Through our evaluation we also sought to identify potential design implications. We will initiate the discussion by focusing on eye glance behaviour, since eyes-off-the-road time is known to affect primary driving task performance <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eye Glance Frequency</head><p>Not surprisingly, our results showed a correlation between GPS visual output and eye glance frequency. Although we expected visual output to stimulate eye glances, we were surprised to see how often participants diverted their visual attention from the driving scene to the GPS system. Green found in a comparable field study a glance frequency of one glance every 8.5 seconds for a satellite navigation system <ref type="bibr" target="#b12">[13]</ref>. This corresponds well with our results as our audiovisual configuration participants had an average glance frequency of one glance every 7.8 seconds while visual participants glanced at the GPS system every 5.9 seconds on average. Thus, adding audio output seems to decrease eye glance frequency. However, if we consider that all participants in the experiment were equally successful in completing the navigational tasks, a frequency of one eye glance every 7.8 seconds is still extremely high. Having more than one output source available did not seem to be an advantage. Visual output only seemed to make participants take their eyes of the road perhaps due to the fact that found driving tedious and felt entertained by the visual output.</p><p>Since driving performance usually decreases when visual demand increases <ref type="bibr" target="#b2">[3]</ref>, such high eye glance frequencies are problematic for off-the-shelves GPS navigation systems. But the high glance frequency in our experiment could be explained by the fact that several of our participants belong to a relatively young age group. Similar studies indicate that younger and older drivers differ in driving behaviour <ref type="bibr" target="#b16">[17]</ref> and Green et al. found that younger drivers on average have a higher glance frequency compared to older drivers <ref type="bibr" target="#b15">[16]</ref>.</p><p>Finally, the eye glance frequency did not appear to be influenced by the context. Participants repeatedly looked at the system in both densely populated areas as well as on longer rural segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Driving Performance While Using GPS Systems</head><p>We found no significant differences on driving performance for the visual and audio-visual configurations even though eye glance frequency differed significantly between the two configurations. In spite of these consequences and previous research findings <ref type="bibr" target="#b17">[18]</ref>, our study did not seem to confirm these. This is quite surprisingly as lack of visual attention usually decreases primary driving task performance <ref type="bibr" target="#b0">[1]</ref>.</p><p>While glance frequency did not seem to affect participants driving performance -the presence of visual output did. We recorded several incidents (e.g. running red lights, missing turns or speeding violations) while participants glanced at the GPS system. Our results showed that audio only participants performed better in relation to primary driving task performance than the other participants. Other research studies confirm that audio configurations would be most ideal in terms of road safety <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>. Nonetheless, it is also important to consider that driving performance differences between the configurations could be explained by the difference in how visual and audio information is acquired. Cautious driving could be a result of participants relying on the GPS system to guide them and not being in control of when and where they receive instructions. This level of uncertainty and alertness could cause an increased cognitive workload of drivers. This matter is further emphasized by a behavioural pattern seen in all audio participants, where they drastically decrease speed when presented with auditory instructions. Studies on voice instructions reveal that a decrease in speed is one of the most significant indicators of increased cognitive workload <ref type="bibr" target="#b27">[28]</ref>.</p><p>The lack of attention on the driving activity resulted in participants missing turns when attempting to relate the map provided by the GPS to their surroundings. Two of the participants became so engulfed by the system that the vehicle nearly came to a standstill while traversing a roundabout. We further found that all participants using the visual configuration repeatedly looked at the system while performing driving manoeuvres, e.g. while making a turn or driving through a roundabout. This behavioural pattern only occurred in two field trials, which involved the audio-visual configuration. This could be explained by the difference in how visual and audio information is provided. Visual information is readily available allowing users to retrieve information whenever they deem it necessary while the audio configuration only provides information in selected situations. Since GPS navigation guides serve as navigators within unfamiliar environments, drivers using only visual output need to confirm their manoeuvres and driving while the addition of audio output seems to alleviate this need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using GPS Instructions and other IVS</head><p>One of the known challenges or limitations of GPS guides is precision and accuracy of the guidance, e.g. maps have to be updated regularly. One visual configuration participant intentionally diverted from the route assigned by the GPS system. This was motivated by the fact that the participant knew a better route. The participant defined a better route as involving less turns and traffic lights, while permitting a higher speed level. The tendency to ignore GPS instructions while driving in familiar areas is also identified in a study by <ref type="bibr">Leshed et al. [22]</ref>. This study describes how users would still utilize the system in order to feel in control by locating and orienting themselves on the map. We also observed this pattern as the participant repeatedly looked at the system in order to see if his chosen route was shorter than the one recommended by the GPS system.</p><p>GPS navigation guides comprise just one class of in-vehicle systems that are going to compete for the driver attention in the future. Other research studies have investigated how we can minimize driver distraction through different interaction techniques <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. Possibly, one should understand the use of GPS navigation guides in the context of other systems used in the car, e.g. climate control, audio players.</p><p>When considering the measurement variables, our results showed an inclination towards the audio configuration. To shed light on this matter we assessed the data collected through the post-task questionnaire in order to evaluate the participants' opinions of the audio configuration. When asked to assess the system instructions and output modality, the audio configuration was rated highest (rated from 'neutral' to 'very satisfied') compared to visual and audiovisual (several of the ratings were 'dissatisfied' and 'very dissatisfied'). The outcome of the questionnaire indicates an overall satisfaction amongst the audio participants. The responses given in the interview contradict these findings. Over half the participants expressed that they would prefer the presence of visual output (where two only preferred visual output). Interestingly, half of the visual participants expressed the desire to have both visual and audio output (three preferred audio only), while half of the audio-visual participants would have preferred visual output only. The expressed opinions contradict each other, but a third of the participants stated that they would prefer to enable and disable the audio output in accordance to their own preferences. This seems to indicate that the audio-visual configuration would result in the highest user satisfaction, even though results indicated that it is less safe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design Implications</head><p>With the improvement of technologies and prize reduction, GPS navigation systems have become popular consumer technologies over the past years <ref type="bibr" target="#b6">[7]</ref>. Most current GPS systems utilize touch-screen interfaces and rely extensively on visual interaction. Our findings suggest that producers should consider output modalities for future GPS systems.</p><p>Previous research studies have found that car drivers prefer navigation instructions in terms of e.g. landmarks, road numbers, or street names, whereas distance instructions are less desired <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref>. Several of our participants with audio output experienced problems relating such information to their surroundings and requested use of more landmarks and descriptive details in the instructions. We believe that this additional descriptive information would not only support drivers, but also alleviate confusion caused by technical limitations in GPS systems. More than half of our participants experienced problems with inconsistency in the GPS system's distance estimates -for example, delayed updates of visual maps or instructions due to unstable satellite signals or loss hereof. Areas, which had several navigational options, caused confusion amongst the drivers, which consequently led to navigational errors. Utilizing landmarks and additional descriptive information would further enable drivers to relate visual maps and instructions to their surroundings.</p><p>The audio participants also expected more guidance before they were to traverse a complex intersection or roundabout.</p><p>Allowing the user to retrieve information whenever they deem it necessary could be a potential solution as it also maintains an auditory interface. On the other hand, designers should also consider how to restrict or omit visual output when the car is in motion.</p><p>During the audio configuration field trials, we observed that participants looked at the system during travel, even though no visual output was provided. Since most GPS systems are sold as independent consumer technologies, they have the disadvantage of giving the user a visual focal point that may attract their attention when presented with instructions. We believe that by integrating GPS systems into vehicles and utilizing the car stereo for audio output could eliminate the visual focal point. This concept is similar to many handsfree phone systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>The market for in-vehicle systems has grown significantly over the last years and especially GPS navigation guides have become very popular. We conducted an experiment with the aim to compare three output configurations of a GPS guide on drivers and driving performance. Our results indicated that visual output not only causes a substantial amount of eye glances, but also leads to a considerable decrease in driving performance. While the introduction of audio output in combination with visual output reduced the frequency of glances, the effects on driving performance were minimal. This could indicate that the presence of audio output may induce additional cognitive workload, nonetheless audio output is beneficial when considering eye glance behaviour and glance tendencies. A direction to be pursued is to design an audio output based navigation system, which accedes to user preferences, as our results already indicate that audio output is an adequate output modality in terms of road safety. Moreover, further studies are needed to fully understand the behavioural patterns emerging when using GPS systems.</p><p>Although we strived to approximate a natural setting, we cannot eliminate the possibility that participant behaviour was affected by the fact that they were being observed.</p><p>During the interview, two participants expressed that they chose to follow the provided route despite disagreements with the given instructions, as they believed that a linear approach was necessary in order to complete the tasks. We also acknowledge that there is an imbalance between the visual and audio configurations in relation to the way the navigational information was provided. Participants in the visual output configurations had additional information e.g. street names, estimated arrival time or distance, which was not available through audio output. Finally, the setup of our experimental study could be problematic as drivers often fit the involvement of in-vehicle systems with the driving activity as pointed out by Esbjörnsson et al. <ref type="bibr" target="#b8">[9]</ref>. This could also be the case for GPS navigation guides.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Example of the GPS in driving view. The map is illustrated in 3D. Included in the map are street names, POI icons and zoom options. Navigation and system information are shown on the bottom part of the screen.</figDesc><graphic coords="3,345.06,164.46,184.68,71.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Experimental setup with the placement of the GPS system in the lower-middle area of the windscreen (as seen from the driver's point of view).</figDesc><graphic coords="4,54.12,331.26,241.02,160.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Speeding violations (longitudinal control errors) for the three configurations. Standard deviations are given in parentheses. A plus denotes a significant difference at the 1% or 5% significance levels to the configuration marked with a minus.</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Visual</cell><cell>Audio-Visual</cell></row><row><cell></cell><cell>(N=10)</cell><cell>(N=10)</cell><cell>(N=10)</cell></row><row><cell>Speeding (&gt; 3 km/t) (N=460)</cell><cell cols="3">8.8 (4.16) -17.9 (8.03) + 19.3 (8.17) +</cell></row><row><cell>Speeding (&gt; 30%) (N=61)</cell><cell>0.6 (0.97) -</cell><cell>2.2 (1.81)</cell><cell>3.3 (2.31) +</cell></row><row><cell>Speeding (&gt; 60%) (N=1)</cell><cell>0.0 (0.0)</cell><cell>0.1 (0.32)</cell><cell>0.00 (0.00)</cell></row><row><cell>Total (N=522)</cell><cell cols="3">9.4 (4.81) -20.2 (8.87) + 22.6 (9.03) +</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 . Additional primary driving task performance measures for each output configuration. Standard deviation is given in parentheses. A plus denotes a significant difference at the 1% or 5% significance levels to the configuration marked with minus.</head><label>2</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 . Navigational errors and task completion times as mean values. Standard deviation is given in parentheses.</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 . Eye glance behaviour for the three configurations. Standard deviation is given in parentheses. A plus denotes a significant difference at 1% or 5% significance levels to the configuration marked with minus.</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell>Audio</cell><cell>Visual</cell><cell>Audio-Visual</cell></row><row><cell></cell><cell>(N=10)</cell><cell>(N=10)</cell><cell>(N=9)</cell></row><row><cell>&lt; 0.5 sec (N=985)</cell><cell>6.6 (4.55) -</cell><cell>45.4 (22.67) +</cell><cell>51.67 (26.21) ±</cell></row><row><cell>0.5 -2 sec (N=2905)</cell><cell>2.8 (2.35) -</cell><cell cols="2">178.3 (33.35) + 121.56 (38.11) +</cell></row><row><cell>&gt; 2 sec (N=87)</cell><cell>0.0 (0.0) -</cell><cell>6.7 (4.37) +</cell><cell>2.22 (2.86) -</cell></row><row><cell>Total (N=3977)</cell><cell>9.4 (5.93) -</cell><cell cols="2">230.4 (37.47) + 175.44 (64.24) ±</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>April 10-15, 2010, Atlanta, GA, USA</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank our participants for the involvement in the experiment. Also, we thank anonymous reviewers for valuable and comments on previous versions of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Interacting with In-Vehicle Information Systems: Understanding, Measuring, and Evaluating Attention</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Skov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Thomassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HCI 2009</title>
		<meeting>the HCI 2009</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="453" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">You Can Touch, but You Can&apos;t Look: Interacting with In-Vehicle Systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Skov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thomassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual SIGCHI Conference on Human Factors in Computing Systems (CHI&apos;08)</title>
		<meeting>the 26th annual SIGCHI Conference on Human Factors in Computing Systems (CHI&apos;08)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1139" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotonirainy</surname></persName>
		</author>
		<title level="m">-vehicle technologies, Advanced Driver Assistance Systems and CHI 2010: Driving, Interrupted</title>
		<meeting><address><addrLine>Atlanta, GA, USA driver distraction</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04-10">2007. April 10-15, 2010</date>
		</imprint>
	</monogr>
	<note>Research challenges. Distracted driving. Australasian College of Road Safety</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Driver Fatigue in Human Factors</title>
		<author>
			<persName><forename type="first">I</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="298" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Broy</surname></persName>
		</author>
		<title level="m">Challenges in Automotive Software Engineering in ICSE</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Turn Right at the Traffic Lights -The Requirement for Landmarks in Vehicle Navigation Systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Burnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Navigation</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="499" to="510" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">TOMTOM GO 930 Review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cassavoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PC World</title>
		<imprint>
			<date type="published" when="2008-11">2008. November 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The Effects of Secondary Tasks on Naturalistic Driving Performance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devonshire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Flannagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sayer</surname></persName>
		</author>
		<idno>UMTRI-2005-29</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>The University of Michigan Transportation Research Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Drivers Using Mobile Phones in Traffic: An Etnographic Study of Interactional Adaptation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Esbjörnsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Juhlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weilenmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="58" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName><surname>Cho</surname></persName>
		</author>
		<title level="m">Statistical Methods for Rates and Proportions</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Intermodal Differences in Distraction Effects while Controlling Automotive User Interfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zobl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bengler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Usability Evaluation and Interface Design</title>
		<meeting>Usability Evaluation and Interface Design</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Gellatly</surname></persName>
		</author>
		<title level="m">The Use of Speech Recognition Technology in Automotive Applications. Faculty of the Virginia Polytechnic Institute and State</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Customer Needs, New Technology, Human Factors, and Driver Science Research for Future Automobiles</title>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society of Mechanical Engineers</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Michigan Transportation Research Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Visual and Task Demands of Driver Information Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
		<respStmt>
			<orgName>The University of Michigan Transportation Research Institute</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Variations in Task Performance Between Younger and Older Drivers: UMTRI Research on Telematics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Automotive Medicine Conference on Aging and Driving</title>
		<meeting><address><addrLine>Southfield, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Examination of a Videotape-based Method to Evaluate the Usability of Route Guidance and Traffic Information Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoekstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>George</surname></persName>
		</author>
		<idno>UMTRI-93-31</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Driver Distraction: The Effects of Concurrent In-Vehicle Tasks, Road Environment Complexity and Age on Driving Performance</title>
		<author>
			<persName><forename type="first">T</forename><surname>Horberry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Accident Analysis and Prevention</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="191" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Jovanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
		<title level="m">Effect of In-Vehicle Route Guidance Systems on Driver Workload and Choice of Vehicle Speed: Findings From a Driving Simulator Experiment. Ergonomics and safety of intelligent driver interfaces</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="97" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning-oriented Vehicle Navigation Systems: A Preliminary Investigation in a Driving Simulator</title>
		<author>
			<persName><forename type="first">O</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Burnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Human Computer Interaction with Mobile Devices and Services</title>
		<meeting>the 10th International Conference on Human Computer Interaction with Mobile Devices and Services</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Distraction from Multiple In-Vehicle Secondary Tasks: Vehicle Performance and Mental Workload Implications in Ergonomics</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Lansdown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brook-Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kersloot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Taylor &amp; Francis Group</publisher>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="91" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Speechbased Interaction with In-vehicle Computers: The Effect of Speech-based E-mail on Drivers&apos; Attention to the Roadway</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Iowa</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">In-Car GPS Navigation: Engagement with and Disengagement from the Environment</title>
		<author>
			<persName><forename type="first">G</forename><surname>Leshed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Velden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sengers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Conference on Human Factors in Computing Systems (CHI&apos;08)</title>
		<meeting>ACM Conference on Human Factors in Computing Systems (CHI&apos;08)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1675" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Effect of Information Modality on Geographic Cognition in Car Navigation Systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moldenhauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mccrickard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>HCI and Department of Computer Science, Virginia Tech</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Female Voice Communications in High Level Aircraft Cockpit Noises part II: Vocoder and Automatic Speech Recognition Systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aviation, Space and Environmental Medicine</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1087" to="1094" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spare Visual Capacity in Driving -Revisited: New Empirical Results for an Old</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Rockwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision in Vehicles II</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Gale</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier Science, North Holland</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visual Demand of Driving and the Execution of Display-Intensive</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tsimhoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vehicle Tasks in Proceedings of the Human Factors and Ergonomics Society 45th Annual Meeting</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1586" to="1590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Address Entry While Driving: Speech Recognition Versus a Touch-Screen Keyboard</title>
		<author>
			<persName><forename type="first">O</forename><surname>Tsimhoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="610" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Voice Information System Adapted to Driver&apos;s Mental Workload</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Uchiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Terashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wakita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Proceedings of the Human Factors and Ergonomics Society</publisher>
			<biblScope unit="page" from="1871" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Wickens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Hollands</surname></persName>
		</author>
		<title level="m">Engineering Psychology and Human</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
