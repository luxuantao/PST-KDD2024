<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local versus Global Lessons for Defect Prediction and Effort Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Tim</forename><surname>Menzies</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Butcher</surname></persName>
							<email>abutcher@afrolegs.com</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">David</forename><surname>Cok</surname></persName>
							<email>dcok@grammatech.com..</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Andrian</forename><surname>Marcus</surname></persName>
							<email>amarcus@wayne.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Lucas</forename><surname>Layman</surname></persName>
							<email>llayman@fc-md.umd.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Forrest</forename><surname>Shull</surname></persName>
							<email>fshull@fc-md.umd.edu</email>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Burak</forename><surname>Turhan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Zimmermann</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">D</forename><surname>Cok</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">B</forename><surname>Turhan</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">T</forename><surname>Zimmermann</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Lane Department of Computer Science and Electrical Engineering</orgName>
								<address>
									<addrLine>West Virginia Uni-versity</addrLine>
									<settlement>Morgantown</settlement>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Ithaca</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Wayne State University</orgName>
								<address>
									<settlement>Detroit</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Fraunhofer Center</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Information Processing Science</orgName>
								<orgName type="institution">University of Oulu</orgName>
								<address>
									<settlement>Oulu</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Local versus Global Lessons for Defect Prediction and Effort Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5AA99B73D2C9541E29F1A09FAB02D418</idno>
					<idno type="DOI">10.1109/TSE.2012.83</idno>
					<note type="submission">received 12 Jan. 2012; revised 16 Aug. 2012; accepted 22 Oct. 2012; published online 27 Nov. 2012.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data mining</term>
					<term>clustering</term>
					<term>defect prediction</term>
					<term>effort estimation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>P ROCESS and product data are used in software engineer- ing (SE) to support a variety of tasks, such as defect prediction, effort estimation, refactoring of source code, determination of the social networks of programmers, learning the expected interface between modules, and so on. Two questions are at the center of much of the research in the field: 1) What data (e.g., which metrics) are best suited to support specific tasks? and 2) what is the best way to reason about SE data? This paper explores the latter question, in the context of:</p><p>. software effort reduction: finding rules for reducing a project's development time; . software defect reduction: finding rules for reducing a project's defect count. Our focus in this paper is not on what data (e.g., process or product data) are used for building models for defect prediction or effort estimation, but rather on the source of the data and, implicitly, the applicability of the lessons derived by the models. Software data come from some sources (e.g., different companies for effort data or different projects for defect data). These data show the defects or effort associated with examples (e.g., projects for effort data or classes for defect data) from that source.</p><p>How should we reason about these data? On this point, the literature is contradictory. Some existing work argues that data from multiple sources can generate rules that apply in any context (i.e., project or company) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. We call these global lessons (or rules).</p><p>On the other hand, other papers indicate that the best lessons are learned from within one source (rather than across all sources), which implies that these lessons are only useful in their context <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. We call these local lessons.</p><p>When project managers want to make changes in their projects to minimize the development effort or the rate of defects, they are faced with two options: 1) make changes based on global lessons available from existing data, or 2) mine data about the current project and infer local lessons. The dilemma of the manager is obvious. In the first case, expensive changes (based on the global lessons) may be undertaken without reaching the desired goal if the global lessons prove to be wrong for this context. In the second case, an upfront investment is needed to collect and analyze data and to generate the local lessons, which may be unnecessary if the global lessons apply to this context. This paper addresses this dilemma and reports on experiments where:</p><p>. Data from different sources are combined. . Within that combination, automatic tools find clusters of related examples. Note that clusters may contain examples from multiple sources. . Data mining is then used to learn lessons from the examples in each cluster. . The generated lessons are compared.</p><p>Before this experiment, our previous work indicated that local lessons seem to be best for defect prediction and effort estimation <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. The surprising result of the experiment presented in this paper is that the best lessons for a project from one source come from neighboring clusters with data from nearby sources, but not inside that source. We will call such lessons neighbor lessons.</p><p>We conclude that when project managers attempt to draw lessons (i.e., about defect or effort reduction) from some historical data source, they should: 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters that are nearest to the test data (regardless of the source of the data). While the paper focuses on defect prediction and effort estimation data, we believe that our conclusions can translate to other types of data, related to different SE tasks.</p><p>This paper extends a prior publication <ref type="bibr" target="#b9">[10]</ref> in the following way:</p><p>. That paper only explored four datasets. Here, we explore over twice that number of datasets. . That prior publication only explored local versus global lessons and found evidence that supported local lessons over the global ones. In this paper, we offer new experiments in Section 4 (which have not appeared previously) that explore clusters from multiple sources. . This paper's literature review is more extensive (see Fig. <ref type="figure">2</ref>). The rest of this paper is structured as follows: First, we explore in Section 2 the literature on defect prediction and effort estimation. This highlights the lack of stable conclusions on what the best way to create predictors is (i.e., how to best learn lessons from the existing data). Section 4 presents two experiments that compare rules for defect prediction and effort estimation generated from global data, from strict local data, and from clusters, whereas Section 3 discusses the details of the clustering and rule learning algorithms used in these experiments. Section 5 discusses the external validity of the conclusions resulting from the two experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LITERATURE REVIEW</head><p>The main goal of this section is not to provide a generic review of defect prediction and effort estimation work, but to highlight work that documents contradictory results which make it difficult to generalize solutions for defect prediction or effort estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Effort Estimation</head><p>Conclusion instability in effort estimation may be a fundamental property of the datasets we are exploring <ref type="bibr" target="#b10">[11]</ref>. For example, Fig. <ref type="figure">1</ref> tests the stability of Boehm's COCOMO software development effort estimation model <ref type="bibr" target="#b10">[11]</ref>. In that analysis, 20 times, we learned effort ¼</p><formula xml:id="formula_0">0 þ 1 x 1 þ 2 x 2 þ .</formula><p>. . using a random 2 3 rds sample from 93 NASA projects (this subset size was chosen to be similar in size to the 61 projects used to find the original COCOMO coefficients). As shown in Fig. <ref type="figure">1</ref>, only the coefficient on lines of code (loc) was stable. The observed ranges on the other i coefficients were very large (e.g., À8 vexp À3:5). In fact, the signs of five coefficients even changed from positive to negative (see stor, aexp, modp, cplx, sced). This coefficient instability is particularly troubling because we know of NASA project managers who have made acquisition decisions worth tens of millions of dollars based on the COCOMO coefficients (i.e., they decided to acquire the technologies that had the most impact on the variables with largest coefficients).</p><p>Other papers also report contradictory findings about effort estimation. Jorgensen <ref type="bibr" target="#b40">[41]</ref> reviewed 15 studies comparing model-based to expert-based methods. Five of those studies favored expert-based methods, five found no difference, and five favored model-based methods. Kitchenham et al. <ref type="bibr" target="#b41">[42]</ref> reviewed studies that checked if data imported from other organizations were as useful as local data (for the purposes of building effort models). From a total of seven studies, three found that models from other organizations were not significantly worse than those based on local data, while four found that they were significantly different (and worse). MacDonell and Shepperd <ref type="bibr" target="#b42">[43]</ref> also Fig. <ref type="figure">1</ref>. Sorted i values from local calibration on 20 Ã (66 percent) samples of NASA93 data (from <ref type="bibr" target="#b10">[11]</ref>). Coefficients learned using Boehm's recommended methods <ref type="bibr" target="#b11">[12]</ref>. A greedy backward selection removed attributes with no impact on estimates (so some attributes have less than 20 results). performed a review on the value of local versus global effort estimation models through a replication of <ref type="bibr" target="#b41">[42]</ref>. From a total of 10 studies, two were found to be inconclusive, three supported global models, and five supported local models. Similarly, Mair and Shepperd <ref type="bibr" target="#b43">[44]</ref> compared regression to analogy methods for effort estimation and found conflicting evidence. From a total of 20 empirical studies, seven favored regression, four were indifferent, and nine favored analogy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Defect Prediction</head><p>In the area of defect prediction, there are also many contradictory findings. For example, Zimmermann et al. <ref type="bibr" target="#b44">[45]</ref> learned defect predictors from 622 pairs of projects hproject 1 ; project 2 i. In only 4 percent of pairs did the defect predictors learned in project 1 work in project 2 . Similar findings (of contradictory conclusions) concern the OO metrics as well. Fig. <ref type="figure">2</ref> lists 28 studies that offer contradictory conclusions regarding the effectiveness of OO metrics for predicting defects (exception: response for class is often a useful indicator of defects). To create Fig. <ref type="figure">2,</ref><ref type="figure">we:</ref> 1. Used our domain knowledge to pick three highimpact seed articles <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. 2. Used Google Scholar<ref type="foot" target="#foot_0">1</ref> to find 500+ relevant studies that cited any of those seed articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Removed false positives by scanning titles and abstracts. This reduced the 500+ articles to 86. 4. Applied the following relevancy rule to reduce the 86 studies to 28: Reject all papers that do not offer a univariate predictive analysis for the validation of the metric(s) under investigation. 5. Checked the literature reviews of important papers in this field <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b45">[46]</ref> for papers not in our sample. For the manager of a software project Fig. <ref type="figure">2</ref> is particularly troubling. Each study makes a clear, but usually different, conclusion. Hence, it is difficult for a manager to make a clear decision about, for example, the merits of a proposed coding standard, where maximum depth of inheritance is required to be less than some expertspecified threshold.</p><p>As to the root cause of the instabilities of Fig. <ref type="figure">2</ref>, we offer the following conjecture. We showed above in Section 2.1 that models learned from different regions within effort data can have very different properties. If defect data were as varied as effort data, then we would naturally expect that different samples of different projects would yield different models (e.g., as seen in Fig. <ref type="figure">2</ref>) due to dataset shift <ref type="bibr" target="#b46">[47]</ref>.</p><p>If this conjecture is correct, then we would expect that clusters within the data should produce different models. This paper is a test of that conjecture. In short, we show that different regions of the data generate different models. Further, the models built from specialized regions within the dataset perform better than those learned across all data. Fig. <ref type="figure">2</ref>. Contradictory conclusions from OO-metrics studies for defect prediction. Studies report significant ("+") or irrelevant ("-") metrics verified by univariate prediction models. Blank entries indicate that the corresponding metric is not evaluated in that particular study. Colors comment on the most frequent conclusion of each column. CBO = coupling between objects; RFC = response for class (#methods executed by arriving messages); LCOM = lack of cohesion (pairs of methods referencing one instance variable, different definitions of LCOM are aggregated); NOC = number of children (immediate subclasses); WMC = #methods per class.</p><p>Before we describe our experiments, this section reviews the technical details of the clustering algorithm and the rule learner used in these experiments. Note that our algorithms are agnostic with respect to the semantics of their input data, which means that we use the same algorithms for defect data and effort data.</p><p>To better relate the algorithms to our context (i.e., defect prediction and effort estimation) and to better understand the experiments of the subsequent sections, Figs. <ref type="figure">3</ref> and<ref type="figure">4</ref> provide examples of instances from one of the actual effort estimation datasets used in the experiments. In this dataset, each project is a point in a 16-dimensional space of "independent" attributes. Each point also has one "dependent" attribute (in Fig. <ref type="figure">3</ref> it is the development effort associated with each project). The attribute names in this figure concern function points of these projects and are defined in Fig. <ref type="figure">5</ref>.</p><p>Fig. <ref type="figure">4</ref> shows the same data as Fig. <ref type="figure">3</ref>, but each value has been categorized into "hi" or "lo," depending on whether it falls above or below the mean value for each row. This figure classifies our projects into two "hi" effort projects (project1 and project2) and one "lo" effort project (project3).</p><p>Contrast sets list the differences between classes. To find a contrast set, we look for an attribute where 1) all the values from one class are similar, but 2) those values differ in different classes. The only such contrast set in Fig. <ref type="figure">4</ref> is the row marked in gray which denotes the function points of internal logical files. Using this contrast set, we would say that "lo" file function points is the factor that most selects for low effort projects.</p><p>While the rules generated with contrast sets are simple, they are quite powerful and our choice is not accidental. We have previously conducted extensive evaluations of contrast set learning with other learners on SE data <ref type="bibr" target="#b47">[48]</ref>. We found that these succinct rules outperformed more complex models generated by standard classifier or optimization algorithms <ref type="bibr" target="#b48">[49]</ref>. Also, using stochastic sampling, contrast set learning can process very large datasets in linear time, which is an advantage when the datasets are large. Further, a major advantage of contrast set learning for SE is that it generates very succinct rules. For example, the single rule generated by this example is</p><formula xml:id="formula_1">if file ¼ lo then effort ¼ lo:</formula><p>In <ref type="bibr" target="#b49">[50]</ref>, we argued that such brevity was important when explaining data mining results to business users and we prefer such rules (when possible) over more complex ones, which tend to be harder to understand.</p><p>To test this rule, we run a selection study, where we look at the class distribution of all projects where file ¼ lo. In this case, 100 percent of projects with file ¼ lo have "lo" effort. Note that for this test to be valid, it should be conducted on data not used for learning the rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Clustering Data with WHERE</head><p>Our clustering algorithm, named WHERE, assumes that the dimensions of most interest are the dimensions of greatest variability. This assumption is shared by other researchers, such as those using feature weighting based on variance <ref type="bibr" target="#b50">[51]</ref> or principal component analysis (PCA), e.g., <ref type="bibr" target="#b3">[4]</ref>.</p><p>Matrix factorization methods like PCA take polynomial time to execute <ref type="bibr" target="#b51">[52]</ref>. We focus in this paper on defect and effort data, but our long term view is that these techniques can be used for other types of SE data. Hence, we adopt a more efficient solution for our tools. Faloutsos and Lin <ref type="bibr" target="#b52">[53]</ref> offer a linear-time heuristic for generating these dimensions, which we use in our work. Given N instances, their "FASTMAP" heuristic finds the dimension of greatest variability to a line drawn between the two furthest points. These two points are found in linear time, as follows: First select any instance Z at random, second find the instance X that is furthest away from Z, third find the instance Y that is furthest away from X. The line XY is an approximation to the first component found by PCA.</p><p>As shown in Fig. <ref type="figure">6a</ref>, an orthogonal dimension to XY can be found by declaring that the line XY is of length c and runs from point ð0; 0Þ to ð0; cÞ. Each instance now has a distance a to the origin (instance X) and distance b to the most remote point (instance Y ). From the Pythagorean Theorem and cosine rule, each instance is at the point</p><formula xml:id="formula_2">x ¼ ða 2 þ c 2 À b 2 Þ=ð2cÞ and y ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi a 2 À x 2 p</formula><p>. Fig. <ref type="figure">6a</ref> shows four quadrants defined by the median values of each dimension ðx; ŷÞ: NorthWest, NorthEast, SouthWest, and SouthEast.</p><p>WHERE constructs Fig. <ref type="figure">6a</ref> using a standard euclidean distance operator, then it recurses on each quadrant. This generates a balanced tree of quadrants, stopping when a subquadrant has less than a minimum number instances (currently the square root of the total number of instances). The resulting tree of quadrants is then pruned from the leaves back to the root: Leaf quadrants with similar density (currently, within 50 percent) are grouped together.</p><p>Fig. <ref type="figure">6b</ref> shows the CHINA effort estimation dataset from the PROMISE repository mapped onto the axes found by FASTMAP. Each dot describes one project using multiple independent attributes and one dependent attribute showing the development effort (in months). For an example of one of those dots, see Fig. <ref type="figure">3</ref>.</p><p>Fig. <ref type="figure">6c</ref> shows the leaf quadrants found by WHERE's recursive exploration of the NorthWest, NorthEast, South-West, and SouthEast quadrants.</p><p>Fig. <ref type="figure">6d</ref> shows the results of leaf pruning: Those clusters are colored to show the median intracluster development effort (dark red = highest effort while dark green = lowest effort). Now consider the three clusters labeled C; C 0 ; C 00 . Suppose a manager of a project in the orange cluster C is considering how to decrease the development effort of that project (of all the neighbors of that cluster, the green cluster C 0 has the lowest development effort). Accordingly, that manager would learn rules over the C 0 data to find treatments that convert projects of type C to C 0 (note that such a strategy is not available to the manager of projects in the dark green cluster C 00 because no neighbor of C 00 has a shorter development effort, so there we would advise to maintain the status quo).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Rules with WHICH</head><p>A vital requirement for this work is that whatever data miner is used, it can generate rules that can be compared Fig. <ref type="figure">6</ref>. Each dot is a D-dimensional instance from the CHINA dataset mapped into two dimensions (for an example of three such dots, see Fig. <ref type="figure">3</ref>). From that data, a new dimension is synthesized on a line between X (at the origin) and the most remote instance Y (at 0; c)-see Fig. <ref type="figure">6a</ref> . Each dot has distance a from the origin and b from the most remote point. The median points on the x-and y-axes are x and ŷ, respectively. The algorithm then recurses on each quadrant to generate grids. Leaf pruning then combines the smaller clusters into the colored regions shown in Fig. <ref type="figure">6d</ref>.</p><p>with the general truisms in the field. Therefore, we eschew learners that use statistical distributions and probability calculations to generate models which, even if they work successfully, are opaque to a human reader. Hence, we do not use Bayes classifiers <ref type="bibr" target="#b53">[54]</ref> or neural networks <ref type="bibr" target="#b54">[55]</ref>. For the same reason, we also choose not to use learners that generate numeric combinations of project influences, e.g., linear regression, logistic regression, simulated annealing <ref type="bibr" target="#b55">[56]</ref>, model trees <ref type="bibr" target="#b56">[57]</ref>, or support vector machines. Finally, we avoid learners that produce large and hard to read theories, e.g., genetic programming algorithms <ref type="bibr" target="#b57">[58]</ref> that can learn large and intricate rules.</p><p>For this research, we use the WHICH contrast rule learner <ref type="bibr" target="#b58">[59]</ref>. WHICH was informally introduced at the start of Section 3. More formally, we say that WHICH learns rules of the form if R x thenðchange ¼ 1 = 0 Ã supportÞ:</p><p>Here, R x is a treatment containing a set of attribute value pairs a v ; 0 is the median score for instances in the untreated population. Referring back to Fig. <ref type="figure">4</ref>, we say that the untreated population is all the test data (i.e., all of Fig. <ref type="figure">4</ref>) and the treated population are the rows found by the selection study (i.e., all the examples that do not conflict with the treatment). 1 is the median score for the population subset selected by the rule. For effort and defect prediction, the ratio 1 = 0 is smaller if the treatment selects for better instances. For an example of such a rule, see the start of this section.</p><p>WHICH builds these rules by looping over attribute value combinations, combining those that look most promising (for the AI-literate reader, we note that WHICH is a fuzzy beam search). Continuous attributes are first discretized to a few discrete values. A stack is created containing one item for every attribute value. The items in that stack are sorted using 1 = 0 Ã support (where support is the percent of the data selected by that rule). WHICH generates new rules as follows: Several times, 1) select two items at random, favoring those with better 1 = 0 Ã support; 2) combine the pair into a new item and score it. The new rules are then sorted back into the stack. This process repeats until no new improvements are seen at the top-ofstack. WHICH returns the rule at the top-of-stack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We ran a set of experiments that compare the results of defect prediction and effort estimation obtained from learning rules from global data, local data, and clusters, respectively.</p><p>The objects of our experiments are the nine datasets shown in Fig. <ref type="figure" target="#fig_1">7</ref>. Each of the nine datasets used in the experiments was scored with their project effort or number of defects. There are two datasets used for effort estimation and seven used for defect prediction. The projects have three sets of attributes:</p><p>1. NASACOC contains the independent attributes from Fig. <ref type="figure">1</ref>. Its dependent attribute is development effort, measured in terms of calendar months (at 152 hours per month, including development and management hours). 2. CHINA contains the independent attributes of Fig. <ref type="figure">5</ref> and the dependent attribute shown in the last row of that table (summary work effort). 3. The other seven datasets contain the independent attributes of Fig. <ref type="figure" target="#fig_3">8</ref> and the dependent attribute of defect counts (as seen in a postrelease bug tracking system). NASACOC and CHINA are effort estimation datasets, while the other seven are defect prediction datasets. Thanks to the researchers who shared the data via the PROMISE repository <ref type="bibr" target="#b59">[60]</ref>, we were able to experiment with a diverse set of data which remains available for future replications.</p><p>The main research question we are addressing is how to generate lessons that lead to rules for minimizing effort and defects. On one hand, we generated lessons from global data and applied them to individual project data. On the other hand, we clustered the data and for each cluster, we applied lessons from the best neighboring cluster (i.e., with better defect or effort values). We present an informal example, followed by the formal description of the treatments we chose.</p><p>Assume that we have data from two sources (e.g., effort or defect data from different companies) A and B:</p><p>. Dataset A ¼ fXa; Ya; Zag . Dataset B ¼ fXb; Yb; Zbg. We combine the data fXa; Ya; Xb; Yb; Za; Zbg and cluster it. We obtain three clusters: C ¼ Xa; Xb, C 0 ¼ Ya; Yb, and C 00 ¼ Za; Zb. We want to see what treatments to each cluster of data result in lowering the defect (or effort) values. The question we are addressing is how to infer the rules (using WHICH). We have the following options:</p><p>1. Global learning. For cluster C, WHICH learns the rules from all the data (minus what is in the cluster-fYa; Yb; Za; Zbg) and test it on the data in C, i.e., fXa; Xbg. 2. Cluster learning. For cluster C, WHICH learns the rules on the data from cluster C 0 , i.e., fYa; Ybg, (we assume here that C 0 is the neighbor cluster to C with the best defect/effort values) and we test it on the data in C, i.e., fXa; Xbg. We further refine the cluster learning:</p><p>a. Neighbor learning (cross). For the data in C from one source (e.g., Xa), WHICH learns on the data from C 0 that does not come from the same source (i.e., Yb in this example). Note that this is an overfitting-avoidance strategy because it somewhat increases the difference of the training data from the test data. More details on this issue are provided later in this section. b. Local learning (within). For the data in C from one source (e.g., Xa), WHICH learns on the data from C 0 that also comes from the same source (i.e., Ya in this example). We conducted the experiment in two stages: one for steps 1 and 2 above and one for steps 2a and 2b. Before we describe the experiments more formally, we need to introduce some notation:</p><p>. Let all refer to all examples in C. . Let treated refer to the examples of C selected by the rules predicting for lower class values (treated all).</p><p>In the case of the defect datasets, the class is "number of defects" while in the case of the effort datasets, the class is "development effort." Note that in both cases, we wish to minimize the class value. . Let D treated be the distribution of class variables seen in treated. . Let D all be the distribution of the class variables seen in all and max be the maximum value of that distribution (i.e., the worst-case result). Normalize all values in D all by expressing them as a percent of the max worst case. For example, in D treated , a value of 50 would denote a class value that is half of the maximum value seen in the raw data D all . . Find the 25th, 50th, 75th, 100th percentile normalized value in D treated and D all . For both distributions, let the median, stability, and worst case values to be the 50th, 75th-25th, and 100th percentile values, respectively. Formally, in each case, the following steps were done:</p><p>1. Combine all the data from all sources; e.g., for defect reduction, combine together data from S 1 ¼ JEDIT , S 2 ¼ XERCES, S 3 ¼ XALAN, and so on.</p><p>2. Cluster the combined data using WHERE. Note that each cluster may now contain examples from multiple sources. 3. For each cluster C, find C 0 (the neighboring cluster with the best median score of its dependent variable). 4. Apply WHICH to C 0 to learn some rules. Then apply those learned rules, i.e., that predicts for lower defects, to C. 5. Report the median, stability, and worst case values in all and some. For experiments 2a and 2b, step 3 becomes: 3ab.For data in C from source S i , find examples in C 0 from other sources S j , where i 6 ¼ j. For experiment 2a, step 4 becomes: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment #1: Global Rules Are Suboptimal</head><p>In the first experiment, we compared global lessons with cluster lessons. We used WHERE to cluster all the available data separately for effort estimation and defect prediction. Our clustering algorithm takes care to skip the dependent variable during clustering. That is, when computing the distance between examples (i.e., projects for effort estimation and classes for defect prediction), the defect or effort values in those examples are ignored. The dependent variable is used only after clustering.</p><p>Once WHERE divides the data, WHICH is applied to each cluster C to find the cluster rules for selecting lower defect/ effort values. Next, the dependent values are used to score each cluster (median defect/effort values of projects in that cluster). For each cluster C, we search its neighbors for the cluster C 0 6 ¼ C ^adjacentðC; C 0 Þ ^ðscoreðC 0 Þ &lt; scoreðCÞÞ with the best score (lowest median defect/effort values). The rule C 0 :cluster is then applied to C to find treated C. See above the definition for treated and score.</p><p>For every cluster C, we compared the two treated sets:</p><p>. one using C 0 :cluster and . the other using rules generated globally across all the data (by applying WHICH to all the datasets, rather than to a single cluster). We found that the rules generated from cluster lessons were better and different than those learned globally. Fig. <ref type="figure">9</ref> shows the rules learned in different datasets. Each dataset generated between two (SYNAPSE) to eight (XALAN) clusters. One cluster always had the best score (lowest effort or defects) and this cluster was labeled C0. No rules were learned for this cluster because our recommendation for projects in C0 is to "maintain the status quo"-i.e., we do not know how to improve the median value of the dependent variable (defect or effort) for this cluster, given the current data. Lines C i 2 C1::C7 show the cluster rules learned from C i 's best neighbor. The underlined cluster rules are those that are same as the global rules (these appear in the results for XALAN and XERCES). Note that there are very few cluster rule sets that are the same as the global rules.</p><p>The effects of applying these rules are shown in Fig. <ref type="figure">10</ref>. These results are expressed in terms of percentile bands: median, stability, and worst case. All values are expressed as ratios of maximum values seen in the untreated dataset (e.g., "50" means the middle value of the untreated data).</p><p>The first thing to note in Fig. <ref type="figure">10</ref> is that our rule learning method is effective: The median and stability values of the above are small percentages of original data. Indeed, in five of the seven defect prediction experiments, the cluster rules selected projects with zero defects.</p><p>The second important conclusion of Fig. <ref type="figure">10</ref> is that the cluster rules performed better than the global rules:</p><p>. The median performance of cluster rules is significantly better than the median performance of the global rules (Wilcoxon, 95 percent confidence). . The stability around the median is greater with cluster rules than with global rules, i.e., if we use the global rules, then we will be less confident in our predictions on the effects of those rules. . The worst case results with global rules are far worse than the worst case results of cluster rules. In all cases, the worst case performance of the global rules is the same as the untreated data (see the second last row of the table). On the other hand, in seven results, the worst case performance of the cluster rules is one-third or less of the maximum in the untreated data. Why is the performance of the global rules suboptimal? Our hypothesis is that software construction is such a diverse task that any global conclusion that holds across all Fig. <ref type="figure">9</ref>. Global and cluster rules for each cluster C i . In this study, all the numerics were discretized into seven equal frequency bins so, e.g., kloc ¼ 1 should be read as "set kloc to its minimal value." The underlined bold entries denote the rules that were the same globally as at cluster level. Note that there are very few rules that are the same globally as at cluster level. Fig. <ref type="figure">10</ref>. Global versus cluster reasoning. In this figure, smaller values are better. All values are percentages of the maximum effort or defect values seen in the untreated datasets so, e.g., a median global value of "17" in NASACOC is 17 percent of the maximum effort value in the NASACOC datasets.</p><p>projects may be somewhat different from the conclusions learned from individual projects.</p><p>In summary, the data we obtained are not supportive of the claim that global lessons are the best for defect prediction or effort estimation. However, it would be a mistake to conclude that this experiment supports delphi localisms. As shown in our next experiment, the best way to divide the data is not via delphi localizations (into, say, just the JEDIT or LUCENE datasets) but by automatic localizations that cross dataset boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment #2: Local Rules Are Suboptimal</head><p>If a data miner is overly zealous, then it could read too much into the training data. In this situation, the learner may overfit its models to spurious details in the training data. Hence, many data mining algorithms employ overfitting-avoidance strategies to prune away needless elaborations. For example:</p><p>. Early versions of decision tree learners produced very big and bushy decision trees. One of the key innovations of C4.5 <ref type="bibr" target="#b60">[61]</ref> was leaf pruning, which prunes leaves until the error rate in the pruned tree starts increasing. . After the INDUCT rule learner builds a rule condition, it runs a greedy back-select algorithm that checks if any condition can be removed while preserving the accuracy of that rule <ref type="bibr" target="#b61">[62]</ref>. Accordingly, the following experiment checked if WHERE and WHICH can be improved by an overfittingavoidance strategy. Specifically, we selected the data used for training in each cluster, based on which source they come from (as explained in the beginning of this section-see step 3ab). This resulted in two ways of learning the rules.</p><p>We call the steps selecting data from different sources the cross treatment because it ensures that data from one source are treated with rules learned from data from other sources. We call the generated rules neighbor rules because the source of the data is not random as it comes from a neighboring cluster. The second treatment is referred to as within treatment and the rules are called local rules, as the data are treated with the rules learned from the same sources (caveat: provided that the data falls into separate neighboring C; C 0 clusters). It is important to note that in both treatments, rules are applied to the same subset S i of C and that these rules select only some subset of that data.</p><p>As before, our results are expressed in terms of median, stability, and worst case. We express those percentiles as a ratio of the maximum value seen in the untreated S i data of C (i.e., the maximum value seen before any rule selects some subset). That is to say, all our results are expressed as values ranging from 0 to 100 percent.</p><p>The results are shown in Fig. <ref type="figure" target="#fig_4">11</ref>. To ensure external validity, the above procedure is repeated multiple times. The results of each repetition are shown in different columns of Fig. <ref type="figure" target="#fig_4">11</ref>. Each repetition combines together the data from three sources. Within each group of three, one source is the designated test cluster S j (again, selected at random). While the datasets were picked at random from the PROMISE data repository, all had to conform to the same ontology (in practice, that meant that Experiment #2 was conducted on datasets of the OO ontology of Fig. <ref type="figure" target="#fig_3">8</ref> since this is the most frequently shared ontology in PROMISE).</p><p>One issue that arises in these results is that the within treatment is so effective that it is sometimes hard to distinguish further improvements. For example, at first glance, the stability results of cross seem worse than within. However, the raw values for stability are so small that a single value (the "8" in the last column) can throw off the results. The same effect (that the baseline within results are very small) also confuses an analysis of the median results.</p><p>However, when we turn to the worst case results, the numbers are large enough to allow for a differentiation of the within and cross results. We observe that the worst case results of the cross study are much better than the within.</p><p>In summary, based on an analysis of rules learned from neighboring clusters in different sources, we conclude that it is suboptimal to learn purely local rules from the clusters within the same source as the test data. This is the standard overfitting-avoidance result <ref type="bibr" target="#b53">[54]</ref>: It is best not to learn too much from local data. Rather, it is better for a learner to step back a little and train from related concepts (rather than concepts that are too similar).</p><p>We conjecture that the diverse nature of software construction means that even for projects built within the same organization, it is more useful to chase external data sources than just to use the local historical data. However, when using data from other sources, it is best to cluster that data and just use a small portion of data from the nearest cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXTERNAL VALIDITY</head><p>External validity is the issue of the generality of the conclusions of a study to data not used in that particular study. Within the specific context of effort estimation and defect prediction, the central claim of this paper is that any standard discussion on external validity cannot be trusted for SE data. That is, the methodology of this paper precludes a claim of external validity about specific conclusions (e.g., the relationship of inheritance depth to defects).</p><p>But this paper is not a counsel of despair. An essential feature of our work is that the same algorithms were used to generate recommendations for both defect reduction and effort reduction. This makes this paper somewhat unique since, in the literature, effort estimation and defect prediction are usually explored by different research teams<ref type="foot" target="#foot_1">2</ref> and techniques. That is:</p><p>. While this paper has shown that any specific conclusion about reducing effort or defects may not be externally valid (since they are project dependent) ... . ... our externally valid metaconclusion is that there are general techniques (i.e., WHERE+WHICH) for finding local conclusions in different projects. In other words, while we do not provide general lessons that work for defect prediction or effort estimation on any project, we provide instead a technique (using WHERE and WHICH) that can be used on any project with the available data.</p><p>To disprove the external validity of this metaconclusion, a research team would need to demonstrate the stability of conclusions across multiple projects. We would propose one sanity check for that demonstration: The projectindependent conclusion must be "significant."</p><p>For examples of less-than-significant conclusions, we refer the reader to the global results shown in the first line of Fig. <ref type="figure">9</ref>. Here, we read that effort or defects can be reduced by: . Minimizing lines of code: See the kloc ¼ 1 results for NASACOC and loc ¼ 1 for XALAN; . Minimizing function points: See the afp ¼ 1 result from CHINA. That is, those global conclusions are just trite statements that if programmers write less code, they can do so in less time (and introduce fewer defects). In most development projects, programmers do not have the option of writing less code. What makes WHICH's local conclusions nontrite is that most often they are not about merely reducing the size of a system. Rather, as seen in Fig. <ref type="figure">9</ref>, they are about system reorganization (such as reorganizing the class hierarchy).</p><p>Note that, in terms of the current literature, current results support the external validity of the conclusions of this paper. Inspired by our earlier work <ref type="bibr" target="#b9">[10]</ref>, Bettenburg et al. <ref type="bibr" target="#b5">[6]</ref> recently repeated our experiment #1 using different clustering tools. That study found the same conclusion as ours, i.e., that cluster rules do better than rules learned across the whole data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>This paper has discussed ways to collect training data for learning lessons from SE projects and to generate rules for reducing the number of defects or the development effort.</p><p>At issue here is how the chief information officers should set policies for their projects. Should they demand that all their projects rigorously apply all the advice from the standard SE textbooks or other literature? Or should they devote resources to a "local lessons team" that explores local data to find the best local practices?</p><p>The results of this paper strongly endorse the creation of the local lessons team. However, that team should apply automatic algorithms to build clusters from all available data. The best cluster is the one that is nearby (see Experiment #1) but not from the same source as the test data (see Experiment #2). While we experimented only on defect prediction and effort estimation data, our procedure is data agnostic and we believe it would apply to other kinds of data, for other tasks.</p><p>More generally, in terms of SE research, the experiments of this paper show that an SE project is an intricate entity that is best described in terms of a complex combination of multidimensional factors. Hence:</p><p>. Trite global rules are not sufficient for controlling such complex entities, at least when it comes to defect prediction and effort estimation. . Neither is it sufficient to characterize the data with simple divisions of data into local contexts. Before researchers attempt to draw lessons from some historical data source, they should:</p><p>ignore any existing local divisions into multiple sources, -cluster across all available data, then restrict the learning of lessons to the clusters from other sources that are nearest to the test data. As to future work, it is important to check how often in other datasets cluster rules are better than global rules.</p><p>Other future work might include improving WHICH and WHERE. WHICH contains numerous design options that deserve closer attention. Like any beam search, WHICH only stores the top (N ¼ 50) rules in its stack. Also, prior to building rules, WHICH discretizes numeric data into B ¼ 7 equal frequency bins. It is possible that different values of N and B would result in better rules.</p><p>More fundamentally, WHICH is one of a large class of contrast set learners. Other candidate contrast set learners which might do better than WHICH are MINWAL <ref type="bibr" target="#b64">[65]</ref>, STUCCO <ref type="bibr" target="#b65">[66]</ref>, and others <ref type="bibr" target="#b66">[67]</ref>.</p><p>Another task deserving future research is to explore multigoal optimization. In the results of Fig. <ref type="figure">10</ref>, we tried to minimize effort in the NASACOC and CHINA datasets while minimizing defects in the remaining seven datasets. A more challenging goal would be to reduce defects and effort at the same time. The search-based SE literature <ref type="bibr" target="#b67">[68]</ref> lists many techniques that might be useful in this regard, including tabu search <ref type="bibr" target="#b68">[69]</ref>, ant algorithms <ref type="bibr" target="#b69">[70]</ref>, and particle swarm optimization <ref type="bibr" target="#b70">[71]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .Fig. 4 .Fig. 5 .</head><label>345</label><figDesc>Fig. 3. Example data. Three examples from the CHINA effort estimation dataset. Fig. 4. Example data of Fig.3, all data categorized as "hi" or "lo" depending on whether it is above or below the mean value for each row, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Data from for this study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4a.</head><label></label><figDesc>Apply WHICH to the S j data from C 0 . In this experiment, the S i examples in C are the all set while some are the examples selected by the rules learned from other sources S j in C 0 . For the experiment 2b, step 4 becomes: 4b. The S i examples in C are treated with the rules learned from the same sources S i in C 0 . Next, we discuss the details of the experiments separately along with their results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. OO measures used in the LUCENE, XALAN, JEDIT, VELOCITY, SYNAPSE, TOMCAT, and XERCES defect datasets. The last line shows the dependent attribute (defects reported to a postrelease bug-tracking system).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Experiment 2. Using groups of three projects, S j (the test cluster) is picked at random (marked in bold underline).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://scholar.google.com.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Exception-see the work of Martin Shepperd<ref type="bibr" target="#b62">[63]</ref>,<ref type="bibr" target="#b63">[64]</ref> who explores both areas.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work was funded by US National Science Foundation (NSF) grants CCF:1017330 and CCF: 1017263, the Qatar/ WVU research grant NPRP 09-12-5-2-470, partly funded by the Finnish Funding Agency for Technology and Innovation (TEKES) under the Cloud Software Program and the Academy of Finland with Grant Decision No. 260871. Also, the research reported in this document was performed in connection with contract/instrument W911QX-10-C-0066 with the US Army Research Laboratory. The views and conclusions contained in this document/presentation are those of the authors and should not be interpreted as presenting the official policies or position, either expressed or implied, of the US Army Research Laboratory or the US Government unless so designated by other authorized documents. Citation of manufacturers or trade names does not constitute an official endorsement or approval of the use thereof.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<title level="m">Estimating Software Costs</title>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>second ed</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Madachy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steece</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chulani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Abts</surname></persName>
		</author>
		<title level="m">Software Cost Estimation with Cocomo II</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evidence-Based Software Engineering</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dyba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jorgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Int&apos;l Conf. Software Eng</title>
		<meeting>26th Int&apos;l Conf. Software Eng</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="273" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mining Metrics to Predict Component Failures</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Int&apos;l Conf. Software Eng</title>
		<meeting>28th Int&apos;l Conf. Software Eng</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ecological Inference in Empirical Software Engineering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Posnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Filkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Devanbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE/ACM Int&apos;l Conf. Automated Software Eng</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Think Locally, Act Globally: Improving Defect and Effort Prediction Models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bettenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth IEEE Working Conf. Mining Software Repositories</title>
		<meeting>Ninth IEEE Working Conf. Mining Software Repositories</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="60" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Local Bias and Its Impacts on the Performance of Parametric Estimation Models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dvalerdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Seventh Int&apos;l Conf. Predictive Models in Software Eng</title>
		<meeting>Seventh Int&apos;l Conf. Predictive Models in Software Eng</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hihn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<title level="m">Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?&quot; Proc. ISPA Conf</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data Mining Static Code Attributes to Learn Defect Predictors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Local vs Global Models for Effort Estimation and Defect Prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. 26th IEEE/ACM Int&apos;l Conf. Automated Software Eng</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Simple Software Cost Estimation: Safe or Unsafe?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Port</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hihn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Predictive Models in Software Eng. Workshop</title>
		<meeting>Workshop Predictive Models in Software Eng. Workshop</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Boehm</surname></persName>
		</author>
		<title level="m">Software Engineering Economics</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Empirical Validation of Three Software Metrics Suites to Predict Fault-Proneness of Object-Oriented Classes Developed Using Highly Iterative or Agile Software Development Processes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Olague</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Etzkorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gholston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quattlebaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="402" to="419" />
			<date type="published" when="2007-06">June 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Empirical Analysis for Investigating the Effect of Object-Oriented Metrics on Fault Proneness: A Replicated Case Study</title>
		<author>
			<persName><forename type="first">K</forename><surname>Aggmakarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malhotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Process: Improvement and Practice</title>
		<imprint>
			<date type="published" when="2009-01">Jan. 2009</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="39" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting Fault Prone Components in a JAVA Legacy System</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arisholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM/IEEE Int&apos;l Symp. Empirical Software Eng</title>
		<imprint>
			<biblScope unit="page" from="8" to="17" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Validation of Object-Oriented Design Metrics as Quality Indicators</title>
		<author>
			<persName><forename type="first">V</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="751" to="761" />
			<date type="published" when="1996-10">Oct. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploring the Relationships between Design Measures and Software Quality in Object-Oriented Systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Systems and Software</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="273" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Replicated Case Studies for Investigating Quality Factors in Object-Oriented Designs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Eng</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="58" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Empirical Investigation of an Object-Oriented Software System</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cartwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="786" to="796" />
			<date type="published" when="2000-08">Aug. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Prediction of Faulty Classes Using Object-Oriented Design Metrics</title>
		<author>
			<persName><forename type="first">K</forename><surname>El Emam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Machado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Systems and Software</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="75" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Validation of Object-Oriented Metrics</title>
		<author>
			<persName><forename type="first">K</forename><surname>El Emam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Benlarbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat&apos;l Research Council of Canada</title>
		<imprint>
			<biblScope unit="volume">1063</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>NRC/ ERB</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Empirical Study on Object-Oriented Metrics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth Int&apos;l Software Metrics Symp</title>
		<meeting>Sixth Int&apos;l Software Metrics Symp</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting Fault-Proneness Using OO Metrics an Industrial Case Study</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Systa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sixth European Conf. Software Maintenance and Reeng</title>
		<meeting>Sixth European Conf. Software Maintenance and Reeng</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="99" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Empirical Analysis of CK Metrics for Object-Oriented Design Complexity: Implications for Software Defects</title>
		<author>
			<persName><forename type="first">R</forename><surname>Subramanyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="310" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Empirical Analysis of Object-Oriented Design Metrics for Predicting High and Low Severity Faults</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="771" to="789" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Empirical Validation of Object-Oriented Metrics on Open Source Software for Fault Prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gyimothy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ferenc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Siket</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="897" to="910" />
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Holschuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Premraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeller</surname></persName>
		</author>
		<title level="m">Predicting Defects in SAP Java Code: An Experience Report</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="172" to="181" />
		</imprint>
	</monogr>
	<note>Proc. 31st Int&apos;l Conf. Software Eng.-Companion Volume</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Effectiveness of Software Metrics in Identifying Error-Prone Classes in Post-Release Software Evolution Process</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shatnawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Systems and Software</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1868" to="1882" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Study on Fault-Proneness Detection of Object-Oriented Systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fioravanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth European Conf. Software Maintenance and Reeng</title>
		<meeting>Fifth European Conf. Software Maintenance and Reeng</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting Faulty Classes Using Design Metrics with Discriminant Analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thongmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Muenchaisri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Software Eng. Research and Practice</title>
		<meeting>Int&apos;l Conf. Software Eng. Research and Practice</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="621" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An Empirical Evaluation of Object Oriented Metrics in Industrial Setting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Denaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lavazza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pezze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth CaberNet Plenary Workshop</title>
		<meeting>Fifth CaberNet Plenary Workshop</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Identification of Defect-Prone Classes in Telecommunication Software Systems Using Design Metrics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Janes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stefanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Succi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="3711" to="3734" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fault Detection and Prediction in an Open-Source Software Project</title>
		<author>
			<persName><forename type="first">M</forename><surname>English</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Exton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rigon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Int&apos;l Conf. Predictor Models in Software Eng</title>
		<meeting>Fifth Int&apos;l Conf. Predictor Models in Software Eng</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Quantitative Investigation of the Acceptable Risk Levels of Object-Oriented Metrics in Open-Source Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shatnawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="216" to="225" />
			<date type="published" when="2010-04">Mar./Apr. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Empirical Validation of Object-Oriented Metrics for Predicting Fault Proneness Models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malhotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Quality J</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="35" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Validating Object-Oriented Design Metrics on a Commercial JAVA Application</title>
		<author>
			<persName><forename type="first">D</forename><surname>Glasberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>El Emam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Memo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Madhavji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NRC</title>
		<imprint>
			<biblScope unit="volume">44146</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics</title>
		<author>
			<persName><forename type="first">K</forename><surname>El Emam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Benlarbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="630" to="650" />
			<date type="published" when="2001-07">July 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Software Defects and Object Oriented Metrics-An Empirical Analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thapaliyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Computer Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An Empirical Validation of Object-Oriented Design Metrics for Fault Prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Capretz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Computer Science</title>
		<imprint>
			<biblScope unit="page" from="571" to="577" />
			<date type="published" when="2008-07">July 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Practical Assessment of the Models for Identification of Defect-Prone Classes in Object-Oriented Commercial Systems Using Design Metrics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Succi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Systems and Software</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Review of Studies on Expert Estimation of Software Development Effort</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jorgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Systems and Software</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="37" to="60" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cross versus Within-Company Cost Estimation Studies: A Systematic Review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kitchenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Travassos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="316" to="329" />
			<date type="published" when="2007-05">May 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Comparing Local and Global Software Effort Estimation Models-Reflections on a Systematic Review</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Macdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. First Int&apos;l Symp. Empirical Software Eng. and Measurement</title>
		<imprint>
			<biblScope unit="page" from="401" to="409" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The Consistency of Empirical Comparisons of Regression and Analogy-Based Software Project Cost Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int&apos;l Symp. Empirical Software Eng</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cross-Project Defect Prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Giger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Seventh Joint Meeting European Software Eng. Conf. and ACM SIGSOFT Symp. Foundations of Software Eng</title>
		<meeting>Seventh Joint Meeting European Software Eng. Conf. and ACM SIGSOFT Symp. Foundations of Software Eng</meeting>
		<imprint>
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Empirical Studies of Quality Models in Object-Oriented Systems</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wuest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Computers</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="98" to="167" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the Dataset Shift Problem in Software Engineering Prediction Models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Turhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="62" to="74" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Defect Prediction from Static Code Features: Current Results, Limitations, New Approaches</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Milton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Turhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="407" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automatically Finding the Control Variables for Complex System Behavior</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gundy-Burlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="468" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Data Mining for Very Busy People</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="2003-11">Nov. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">A Hybrid Approach to Expert and Model-Based Effort Estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Baker</surname></persName>
		</author>
		<ptr target="https://eidr.wvu.edu/etd/documentdata.eTD?documentid=5443" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Lane Dept. of Computer Science and Electrical Eng., West Virginia Univ</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Low-Complexity Principal Component Analysis for Hyperspectral Image Compression</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fastmap: A Fast Algorithm for Indexing, Data-Mining and Visualization of Traditional and Multimedia Datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM SIGMOD Int&apos;l Conf</title>
		<imprint>
			<biblScope unit="page" from="163" to="174" />
			<date type="published" when="1995">1995</date>
			<publisher>Management of Data</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<title level="m">Data Mining</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning Representations by Back-Propagating Errors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Simulated Annealing for Improving Software Quality Prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouktif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sahraoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antoniol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eighth Ann. Conf. Genetic and Evolutionary Computation</title>
		<meeting>Eighth Ann. Conf. Genetic and Evolutionary Computation</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1893" to="1900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning with Continuous Classes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Australian Joint Conf. Artificial Intelligence</title>
		<meeting>Fifth Australian Joint Conf. Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="343" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">When Will It Be Done? The 300 Billion Dollar Question, Machine Learner Answers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Boetticher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="48" to="50" />
			<date type="published" when="2003-06">May/June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">When to Use Data from Other Projects for Effort Estimation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kocaguneli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Keung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE/ACM Int&apos;l Conf. Automated Software Eng</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kocaguneli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Turhan</surname></persName>
		</author>
		<ptr target="http://promisedata.googlecode.com" />
		<title level="m">The Promise Repository of Empirical Software Engineering Data</title>
		<imprint>
			<date type="published" when="2012-06">June 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Quinlan</surname></persName>
		</author>
		<title level="m">C4.5: Programs for Machine Learning</title>
		<imprint>
			<publisher>Morgan Kaufman</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Induction of Ripple Down Rules</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gaines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Compton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Australian Conf. Artificial Intelligence</title>
		<meeting>Fifth Australian Conf. Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="349" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A General Software Defect-Proneness Prediction Framework</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2010.90</idno>
		<ptr target="http://dx.doi.org/10.1109/TSE.2010.90" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="356" to="370" />
			<date type="published" when="2011-06">May/June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A Systematic Review of Software Development Cost Estimation Studies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Software Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="53" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Mining Association Rules with Weighted Items</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int&apos;l Database Eng. and Applications Symp</title>
		<imprint>
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Detecting Change in Categorical Data: Mining Contrast Sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Int&apos;l Conf. Knowledge Discovery and Data Mining</title>
		<meeting>Fifth Int&apos;l Conf. Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lavra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="2009-06">June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Search-Based Software Engineering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="833" to="839" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Modern Heuristic Techniques for Combinatorial Problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laguna</surname></persName>
		</author>
		<editor>C. Reeves</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Blackwell Scientific Publishing</publisher>
		</imprint>
	</monogr>
	<note>Tabu Search</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Model-Based Search for Combinatorial Optimization: A Critical Survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zlochin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meuleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="373" to="395" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Particle Swarm-Simulated Annealing Fusion Algorithm and Its Application in Function Optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Computer Science and Software Eng</title>
		<meeting>Int&apos;l Conf. Computer Science and Software Eng</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="78" to="81" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
