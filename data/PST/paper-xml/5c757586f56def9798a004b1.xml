<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lecture Notes: Temporal Point Processes and the Conditional Intensity Function</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-06-04">June 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jakob</forename><forename type="middle">Gulddahl</forename><surname>Rasmussen</surname></persName>
							<email>jgr@math.aau.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Sciences</orgName>
								<orgName type="institution">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lecture Notes: Temporal Point Processes and the Conditional Intensity Function</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-06-04">June 4, 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1806.00221v1[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>These short lecture notes contain a not too technical introduction to point processes on the time line. The focus lies on defining these processes using the conditional intensity function. Furthermore, likelihood inference, methods of simulation and residual analysis for temporal point processes specified by a conditional intensity function are considered.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A temporal point pattern is basically a list of times of events. Many real phenomena produce data that can be represented as a temporal point pattern; the left column of Table <ref type="table">1</ref> shows a few examples. Common to these examples is that we do not know how many events will occur, or at what times they will occur. Usually complex mechanisms are behind these seemingly random times, for example earthquakes cause new earthquakes in the form of aftershocks. An essential tool for dealing with these mechanisms, for example in predicting future events, is a stochastic process modelling the point patterns: a temporal point process. The term point is used since we may think of an event as being instant and thus can represent it as a point on the time line. For the same reason the words point and event will be used interchangeably throughout this note.</p><p>Often there is more information available associated with an event. This information is known as marks. Examples are given in the right column of Table <ref type="table">1</ref>. The marks may be of separate interest or may simply be included to make a more realistic model of the event times. For example, it is of practical relevance to know the position and magnitude of an earthquake, not just its time. At the same time, the magnitude of an earthquake also influences how many aftershocks there will be, so a model not including magnitudes as marks may not be reliable at modelling the event times either.</p><p>In this note, familiarity with the Poisson process on the line as well as basic probability theory and statistics is assumed. On the other hand, measure theory is not assumed; for a much more thorough treatment with all the measure theoretical details, see <ref type="bibr" target="#b0">Daley and Vere-Jones (2003)</ref> and <ref type="bibr" target="#b1">Daley and Vere-Jones (2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evolutionary point processes</head><p>There are many ways of treating (marked) temporal point processes. In this note we will explore one approach based on the so-called conditional intensity function. To understand what this is, we first have to understand the concept of evolutionarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evolutionarity</head><p>Usually we think of time as having an evolutionary character: what happens now may depend on what happened in the past, but not on what is going to happen in the future. This order of time is also a natural starting point for defining practically useful temporal point processes. Roughly speaking, we can define a point process by specifying a stochastic model for the time of the next event given we know all the times of previous events. The term evolutionary point process is used for processes defined in this way.</p><p>The past in a point process is captured by the concept of the history of the process. If we consider the time t, then the history H t− is the knowledge of times of all events, say (. . . , t 1 , t 2 , . . . , t n ), up to but not including time t; H t also includes the information whether there is an event at time t. Note that theoretically the point process may extend infinitely far back in time, but it does not have to do this. Note also that we assume that we have a simple point process, i.e. a point process where no points coincide, such that the points can be strictly ordered in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interevent times</head><p>When specifying a temporal point process we can use many different approaches. In this note, we start by specifying the distribution of the time lengths between subsequent events, and then in the next section we reformulate this in terms of conditional intensity functions.</p><p>The lengths of the time intervals between subsequent events are known as interevent times. We can define a temporal point process by specifying the distributions of these. Let f (t n+1 |H tn ) be the conditional density function of the time of the next event t n+1 given the history of previous events (. . . , t n−1 , t n ). Note that the density functions f (t n | . . . , t n−2 , t n−1 ) specify the distributions of all interevent times, one by one, starting in the past, and thus the distribution of all events is given by the joint density</p><formula xml:id="formula_0">f (. . . , t 1 , t 2 , . . .) = n f (t n | . . . , t n−2 , t n−1 ) = n f (t n |H t n−1 )</formula><p>in the same manner as the joint density for a bivariate random variable factorises into p(x, y) = p(x)p(y|x). Let us consider a simple example of a point process defined by specifying the density function for interevent times:</p><p>Example 2.1 (Renewal process and Wold process). The simplest process we can define by specifying the distribution of the interevent times is the renewal process. This process is defined by letting the interevent times be i.i.d. stochastic variables, i.e. f (t n |H t n−1 ) = g(t n − t n−1 ) where g is a density function for a distribution on (0, ∞). An important special case of this is the homogeneous Poisson process with intensity λ, where g is the density of the exponential distribution with inverse mean λ. Figure <ref type="figure">1</ref> shows simulations of three different renewal processes: one is the homogeneous Poisson process, one is more clustered than the Poisson process (i.e. the points tend to occur in clusters), and one is more regular than the Poisson process (i.e. the points tend to be more evenly spread out).</p><p>q qqq qq qqq q qq q q q q q qq q qq q q q q q q qq qqqq q q qq q q q q q qq q q qq q q qq qqq qqq q qq q q q q q q q q qqq q q q qqq qqq q q qq q qq q qqq q q q q q q q q q q q q q q qq q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q qq q q q q q q q q q q q qq q q q q q q q q qq qq q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q qq q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0 2 4 6 8 10 0.5 2.0 3.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time</head><p>Figure <ref type="figure">1</ref>: Three simulations of renewal processes with different interevent time distributions: Gamma(0.02,0.2) (upper), Gamma(0.1,1) (middle), Gamma(2,20) (lower). Note how the upper case is clustered and the lower case is regular compared to the middle case (which is a Poisson process). Also note that all the simulations have roughly 100 points for easy comparison (they are very densely packed together for the upper case).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Conditional intensity function</head><p>Example 2.1 show cases where t n depends only on t n−1 . However, in general it may depend on the whole history, and it turns out that the density function of the interevent times is not the best way of specifying the general case. Instead the conditional intensity function is a more convenient and intuitive way of specifying how the present depends on the past in an evolutionary point process. Consider the conditional density f (t|H tn ) and its corresponding cumulative distribution function F (t|H tn ) for any t &gt; t n .</p><p>Then the conditional intensity function (or hazard function) is defined by</p><formula xml:id="formula_1">λ * (t) = f (t|H tn ) 1 − F (t|H tn )</formula><p>.</p><p>(1)</p><p>The conditional intensity function can be interpreted heuristically in the following way: consider an infinitisemal interval around t, say dt, then </p><formula xml:id="formula_2">λ * (t)dt = f (t|H tn )dt 1 − F (t|H tn ) = P(t n+1 ∈ [t,</formula><formula xml:id="formula_3">P(t n+1 / ∈ (t n , t)|H tn ) = P(t n+1 ∈ [t, t + dt]|t n+1 / ∈ (t n , t), H tn ) = P(t n+1 ∈ [t, t + dt]|H t− ) = E[N ([t, t + dt])|H t− ],</formula><p>where N (A) denotes the number of points falling in an interval A, and the last equality follows from the assumption that no points coincide, so that there is either zero or one point in an infinitisemal interval. In other words, the conditional intensity function specifies the mean number of events in a region conditional on the past. Here we use the notation * from <ref type="bibr" target="#b0">Daley and Vere-Jones (2003)</ref> to remind ourselves that this density is conditional on the past right up to but not including the present, rather than writing explicitly that the function depends on the history. We consider a few examples of point processes where the conditional intensity has particular functional forms:</p><p>Example 2.2 (Poisson process). The (inhomogeneous) Poisson process is among other things characterised by the number of points in disjoint sets being independent. The conditional intensity function inherets this independence. The Poisson process is quite simply the point process where the conditional intensity function is independent of the past, i.e. the conditional intensity function is equal to the intensity function of the Poisson process, λ * (t) = λ(t).</p><p>Example 2.3 (Hawkes process). Define a point process by the conditional intensity function</p><formula xml:id="formula_4">λ * (t) = µ + α t i &lt;t exp(−(t − t i )),<label>(2)</label></formula><p>where µ and α are positive parameters. Note that each time a new point arrives in this process, the conditional intensity grows by α and then decreases exponentially back towards µ. In other words, a point increases the chance of getting other points immediately after, and thus this is model for clustered point patterns. A simulation of the process with parameters (µ, α) = (0.5, 0.9) is shown in Figure <ref type="figure" target="#fig_0">2</ref> together with its conditional intensity function (in Section 4 we will learn how to make such a simulation).</p><p>The so-called Hawkes process is a generalization of this process and has the conditional intensity function</p><formula xml:id="formula_5">λ * (t) = µ(t) + α t i &lt;t γ(t − t i ; β),</formula><p>where µ(t) ≥ 0, α &gt; 0, and γ(t; β) is a density on (0, ∞) depending on some parameter β (which may be a single value or a vector, depending on the choice of distribution). For more on the Hawkes process, see e.g. <ref type="bibr" target="#b3">Hawkes (1971b</ref><ref type="bibr" target="#b4">Hawkes ( ,a, 1972))</ref>; <ref type="bibr" target="#b5">Hawkes and Oakes (1974)</ref>.</p><p>qq q q q q q qq q q q q qq q qq q q q q qq q q q q q q q q q q q q q q q q q q q q q q qqq q 0 2 4 6 8 10 Example 2.4 (Self-correcting process). What do we do if we want a point process for regular point patterns? Exchanging the plus for a minus in the Hawkes process will not work, since a conditional intensity function has to be non-negative. We can instead use</p><formula xml:id="formula_6">λ * (t) = exp µt − t i &lt;t α ,</formula><p>where µ and α are positive parameters. Now the intensity rises as time passes, but each time a new point appears we multiply by a constant e −α &lt; 1, and thus the chance of new points decreases immediately after a point has appeared; in other words, this is a regular point process. A simulated point pattern and the conditional intensity function is shown in Figure <ref type="figure" target="#fig_1">3</ref>. This process is a special case of the so-called self-correcting process <ref type="bibr" target="#b6">(Isham and Westcott, 1979)</ref>.</p><p>q q q qq q q q q 0 2 4 Note that the point pattern is regular.</p><p>Note that the models in examples 2.3 and 2.4 are specified simply by choosing a particular form of the conditional intensity and interpreting this. A little creativity and common sense can be used to define many new models using the conditional intensity function. This, of course, depends on the fact that the conditional intensity function uniquely defines a point process.</p><p>To prove this we first need to note that the definition of the conditional intensity function can also be reversed such that an expresion for the density or cumulative distribution function of the interevent times can be obtained:</p><p>Proposition 2.1. The reverse relation of ( <ref type="formula">1</ref>) is given by</p><formula xml:id="formula_7">f (t|H tn ) = λ * (t) exp − t tn λ * (s)ds ,<label>(3)</label></formula><p>or</p><formula xml:id="formula_8">F (t|H tn ) = 1 − exp − t tn λ * (s)ds , (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>where t n is the last point before t.</p><p>Proof. By (1), we get that</p><formula xml:id="formula_10">λ * (t) = f (t|H tn ) 1 − F (t|H tn ) = d dt F (t|H tn ) 1 − F (t|H tn ) = − d dt log(1 − F (t|H tn )). (<label>5</label></formula><formula xml:id="formula_11">)</formula><p>Integrating both sides, we get by the fundamental theorem of calculus that </p><formula xml:id="formula_12">t tn λ * (s)ds = −(log(1−F (t|H tn ))−log(1−F (t n |H tn ))) = − log(1−F (t|H tn )), since F (t n |H tn ) =</formula><formula xml:id="formula_13">• 0 ≤ F (t|H tn ) ≤ 1, • F (t|H tn ) is a non-decreasing function of t, • F (t|H tn ) → 1 for t → ∞,</formula><p>which means that F (t|H tn ) is a distribution function. Uniqueness follows from Proposition 2.1, since F (t|H tn ) is uniquely obtained from λ * (t) using (4).</p><p>Note that item 2. in Proposition 2.2 implies that the point process continues forever, a property which is often not desireable for practical useluckily we can get rid of this assumption. If we remove this, the proof still holds except that item 2. in the proof has to be removed. Now F (t|H tn ) → p for some probability p &lt; 1, so we have to understand what it means when the cumulative distribution function for the interevent time does not tend to one when time tends to infinity. Basically this means that there is only probability p of having one (or more) points in the rest of the process, and with probability 1 − p the process terminates with no more points.</p><p>Example 2.5 (Two terminating point processes). Consider a unit-rate Poisson process on [0, 1]. This has conditional intensity function λ</p><formula xml:id="formula_14">* (t) = 1[t ∈ [0, 1]]</formula><p>. Thus starting at zero (with no points so far), we get that</p><formula xml:id="formula_15">F (t|H 0 ) = 1 − exp − t 0 1[s ∈ [0, 1]]ds = 1 − exp (− min{t, 1}) ,</formula><p>where 1[•] denotes the indicator function. For t &gt; 1, this equals 1 − exp(−1) ≈ 0.63, so there is a probability of about 0.37 of having no points at all. If we do get a point, say t 1 , there is an even smaller chance of getting another point in the remaining interval (t 1 , 1]. Another terminating unitrate process could be a process that behaves like a Poisson process but stops after n points. In this case</p><formula xml:id="formula_16">F (t|H t i ) = (1 − exp(−t))1[i &lt; n].</formula><p>Both these examples illustrate that assumption 3. in Proposition 2.2 is not necessary to get well-defined point processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The marked case</head><p>The conditional intensity function also generalises to the marked case, but before we get that far it is worth reminding ourselves that the mark space M can be many different types of spaces, often (a subset of) R or N. We can specify the distribution of the mark κ associated with the point t by its conditional density function f * (κ|t) = f (κ|t, H t− ), i.e. this specifies the distribution of the mark κ given t and the history H t− , which now includes information of both times and marks of past events. Here the term density function is used in a broad sense: if the mark is a continuous random variable, this is the usual (conditional) density function, but if it is a discrete random variable, this is its (conditional) probability function. Note also that f * (κ|t) = f (κ|t, H tn ) if t n is the the last point before t, since the additional condition that the next point is located at t means that the histories H t− and H tn contain the same information.</p><p>We can now define the conditional intensity function for the marked case as</p><formula xml:id="formula_17">λ * (t, κ) = λ * (t)f * (κ|t),</formula><p>where λ * (t) is called the ground intensity, and is defined exactly as the conditional intensity function for the unmarked case, except that it is allowed to depend on the marks of the past events also; note the close resemblance of this formula with p(x, y) = p(x)p(y|x) for the relation between the joint, marginal and conditional distributions for random variables. Thus we can rewrite this expression to</p><formula xml:id="formula_18">λ * (t, κ) = λ * (t)f * (κ|t) = f (t|H tn )f * (κ|t) 1 − F (t|H tn ) = f (t, κ|H tn ) 1 − F (t|H tn ) ,</formula><p>where f (t, κ|H tn ) is the joint density of the time and the mark (again the word the density is used in a broad sense) conditional on past times and marks, and F (t|H tn ) is the conditional cumulative distribution function of t also conditional on the past times and marks. Therefore following the same arguments as in Section 2.3, the conditional intensity function λ * (t, κ) can now be interpreted for the case of discrete marks by</p><formula xml:id="formula_19">λ * (t, κ)dt = E[N (dt × κ)|H t ],</formula><p>that is, the mean number of points in a small time interval dt with the mark κ. Similarly for the continuous case,</p><formula xml:id="formula_20">λ * (t, κ)dtdκ = E[N (dt × dκ)|H t ],</formula><p>that is, the mean number of points in a small time interval dt with the mark in a small interval dκ. We revisit the Hawkes process from Example 2.3, now with marks:</p><p>Example 2.6 (marked Hawkes process). The ETAS (epidemic type aftershock sequence) model is a particular type of marked Hawkes process for modelling earthquakes times and magnitudes. Here κ i ∈ [0, ∞) denotes the magnitude of an earthquake occurring at time t i . In its simplest form the ETAS model can be defined by its ground intensity</p><formula xml:id="formula_21">λ * (t) = µ + α t i &lt;t e βκ i e −γ(t−t i ) ,</formula><p>where α, β, γ &gt; 0 are parameters, and an exponential distribution as its mark density f * (κ|t) = δe −δκ .</p><p>Equivalently we could define it by its conditional intensity function including both marks and times</p><formula xml:id="formula_22">λ * (t, κ) = µ + α t i &lt;t e βκ i e −γ(t−t i ) δe −δκ .</formula><p>The idea behind using this model is that earthquakes cause aftershocks -this is reflected in the fact that every new earthquake increases the intensity by αe βκ i . Note that large earthquakes increase the intensity more than small earthquakes. For more on the ETAS model, see e.g. <ref type="bibr" target="#b11">Ogata (1988</ref><ref type="bibr" target="#b12">Ogata ( , 1998))</ref>.</p><p>We sometimes make simplifying independence assumptions on the marks. An unpredictable mark is a mark that does not depend on the past (and therefore cannot be "predicted" using the information about the past, hence the term "unpredictable"). Example 2.6 has unpredictable marks, since f * (κ|t) does not depend on the past. An even stronger assumption is that of an independent mark, which means that κ i is independent of everything else except maybe t i . Example 2.6 does not have independent marks, since the ground intensity depends on the past marks (which is just another way of saying that the marks depend on the future events).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Inference</head><p>There are many possibilities for estimating the parameters in a process specified by a conditional intensity function. The likelihood function for such a process has a fairly simple expression, which usually means that maximum likelihood inference or Bayesian inference are good choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Likelihood function</head><p>Assume that we have observed a point pattern (t 1 , . . . , t n ) on [0, T ) for some given T &gt; 0, and if we are in the marked case, also its accompanying marks (κ 1 , . . . , κ n ). Furthermore, let the integrated conditional intensity function (or integrated ground intensity function in the marked case) be given by</p><formula xml:id="formula_23">Λ * (t) = t 0 λ * (s)ds.</formula><p>Then the likelihood function is given by the following proposition.</p><p>Proposition 3.1. Given an unmarked point pattern (t 1 , . . . , t n ) on an observation interval [0, T ), the likelihood function is given by</p><formula xml:id="formula_24">L = n i=1 λ * (t i ) exp(−Λ * (T )).</formula><p>Given a marked point pattern ((t 1 , κ 1 ), . . . , (t n , κ n )) on [0, T ) × M, the likelihood function is given by</p><formula xml:id="formula_25">L = n i=1 λ * (t i , κ i ) exp(−Λ * (T )).</formula><p>Proof. The likelihood function is the joint density function of all the points in the observed point pattern (t 1 , . . . , t n ) ∈ [0, T ), and can therefore be factorised into all the conditional densities of each points given all points before it. This yields</p><formula xml:id="formula_26">L = f (t 1 |H 0 )f (t 2 |H t 1 ) • • • f (t n |H t n−1 )(1 − F (T |H tn )),</formula><p>where the last term (1 − F (T |H tn )) appears since the unobserved point t n+1 must appear after the end of the observation interval, and the term H 0 contains the information that there are no events before time 0. Using (1) and ( <ref type="formula" target="#formula_7">3</ref>), we get that</p><formula xml:id="formula_27">L = n i=1 f (t i |H t i−1 ) f (T |H tn ) λ * (T ) = n i=1 λ * (t i ) exp − t i t i−1 λ * (s)ds exp − T tn λ * (s)ds = n i=1 λ * (t i ) exp − T 0 λ * (s)ds ,</formula><p>where t 0 = 0. This proves the result for the unmarked case. To obtain the result for the marked case, start by the factorisation</p><formula xml:id="formula_28">L = f (t 1 |H t 0 )f (κ 1 |t 1 , H t 0 ) • • • f (t n |H t n−1 )f (κ n |t n , H t n−1 )(1 − F (T |H tn ))</formula><p>All the terms except the conditional mark densities f (κ i |t i ,</p><formula xml:id="formula_29">H t i−1 ) = f * (κ i |t i )</formula><p>are the same as in the unmarked case, so</p><formula xml:id="formula_30">L = n i=1 f * (κ i |t i ) n i=1 λ * (t i ) exp − T 0 λ * (s)ds = n i=1 λ * (t i , κ i ) exp − T 0 λ * (s)ds ,</formula><p>which establishes the result for the marked case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Estimation</head><p>Although Proposition 3.1 gives an explicit expression for the likelihood function, it is rarely simple enough that we can find the maximum likelihood estimate (MLE) analytically. One special case where we can find the MLE is the homogeneous Poisson process:</p><p>Example 3.1 (MLE for the homogeneous Poisson process). For the homogeneous Poisson process with intensity λ * (t) = λ observed on an interval [0, T ) for some T &gt; 0, the likelihood simplifies to</p><formula xml:id="formula_31">L = λ n exp(−λT ).</formula><p>Differentiating this and equating to zero, we get that the MLE is given by λ = n T .</p><p>Note that this expression does not depend on the times of the points, only the total number of points. However, this is not true for other processes.</p><p>For most other point processes we will require numerical methods to obtain estimates, such as Newton-Raphson for maximizing the likelihood, or Markov chain Monte Carlo for approximating the posterior in a Bayesian approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulation</head><p>Simulation turns out to be fairly easy when the conditional intensity function is specified. The conditional intensity function leads to two different approaches for simulating a point process: The inverse method and Ogata's modified thinning algorithm. Both are generalisations of similar methods for simulation of inhomogeneous Poisson processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Inverse method</head><p>The basic idea in the inverse method is that we simulate a unit-rate Poisson process (this is just a series of independent exponential random variables with mean one) and transform these into the desired point process using the integrated conditional intensity function. The following proposition is the key result behind this method.</p><p>Proposition 4.1. If (s i ) i∈Z is a unit rate Poisson process on R, and t i = Λ * −1 (s i ), then (t i ) i∈Z is a point process with intensity λ * (t i ).</p><p>Proof. We prove this by induction, so assume that for i ≤ n, s i follows a unit rate Poisson process, and t i follows a point process with intensity λ * . Now consider the next point in both processes, say S n+1 and T n+1 = Λ * (S n+1 ). Letting S = S n+1 − s n follow a unit rate exponential distribution which is independent of everything else, we need to prove that T n+1 follows a point process with intensity λ * or equivalently has the correct distribution function F (•|H tn ). Denoting the distribution function of T n+1 by F T n+1 (t|H tn ), we get that</p><formula xml:id="formula_32">F T n+1 (t|H tn ) = P(T n+1 ≤ t|H tn ) = P(Λ * −1 (S + s n ) ≤ t|H tn ) = P(S ≤ Λ * (t) − s n |H tn ) = 1 − exp(−(Λ * (t) − s n )) = 1 − exp(−(Λ * (t) − Λ * (t n ))) = 1 − exp − t tn λ * (u)du = F (t|H tn ),</formula><p>where we have used that s n = Λ * (t n ) in the fifth equality, and (4) in the last one. Thus T n+1 follows the correct distribution.</p><p>Although the point process is defined on the whole of R in Theorem 4.1, this condition can be relaxed. If we instead use a Poisson process with s i ∈ [0, T ], then we get a new point process with t i ∈ [0, Λ * −1 (T )], i.e. we also need to transform the final end point. This means we cannot simply simulate a Poisson process on the interval needed, since this interval changes during the transformation, so we need to simulate one exponential variable at a time, and then transform them to see if our simulation fills out the whole interval. The following algorithm does this. 1. Set t = 0, t 0 = 0 and n = 0 (note that t 0 is not an event).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Repeat until</head><formula xml:id="formula_33">t &gt; T : (a) Generate s n ∼ Exp(1). (b) Calculate t, where t = Λ * −1 (s n ). (c) If t &lt; T , set n = n + 1 and t n = t. 3. Output is {t 1 , . . . , t n }.</formula><p>The difficult part of this algorithm is of course calculating t in step 2(b) since this requires finding the inverse of the integrated conditional intensity function. Notice that since λ * is non-negative, we get that Λ * is non-decreasing. Strictly speaking, this means that Λ * may not even be an invertible function, since it can be constant on intervals (corresponding to λ * being zero in these intervals). However, any point s i from the Poisson process will hit these points with probability zero, so we never need to evaluate Λ * −1 , where it is not well-defined.</p><p>Example 4.1 (Hawkes process, Inverse method). We revisit the special case of Hawkes process from Example 2.3 given by (2). For this we get the integrated conditional intensity function</p><formula xml:id="formula_34">Λ * (t) = µt + α t i &lt;t 1 − e −(t−t i ) .</formula><p>Looking at the expression, it seems to be hard solve this with respect to t, so an analytical expression for Λ * −1 is not available, meaning we will need to approximate this when we use Algorithm 4.1. A simple way of doing this is to calculate si = Λ * ( ti ) starting at very small values of ti and then increase ti until s i ≈ Λ * ( ti ), and then use t i = ti .</p><p>The easiest way to generalise this to the marked case is to simulate the associated mark to an event t i just after we have transformed s i to t i (notice that we have all the information that this may depend on, since we have already simulated the past events and marks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ogata's modified thinning algorithm</head><p>Ogata's modified thinning algorithm <ref type="bibr" target="#b10">(Ogata, 1981)</ref> is a thinning algorithm based on simulating homogeneous Poisson processes with too high intensities and then thin out the points that are too many according to the conditional intensity function. Since the conditional intensity function depends on the past, we have to do this starting in the past and follow the direction of time.</p><p>The basic idea behind the algorithm is that when we are at time t we need to find out where to place the next point t i &gt; t. To do this we simulate a homogeneous Poisson process on some interval [t, t + l(t)] for some chosen function l(t) (this is the maximum distance we may go forward in time from t and it may be infinite). </p><formula xml:id="formula_35">∼ Unif([0, 1]). (c) If s &gt; l(t), set t = t + l(t). (d) Else if t + s &gt; T or U &gt; λ * (t + s)/m(t), set t = t + s. (e) Otherwise, set n = n + 1, t n = t + s, t = t + s. 3. Output is {t 1 , . . . , t n }.</formula><p>Proposition 4.2. The output of Algorithm 4.2 is a realisation of a point process with conditional intensity function λ * (t).</p><p>Proof. It follows from independent thinning that this process has the right conditional intensity function (essentially the explanation above the algorithm is the proof).</p><p>Example 4.2 (Hawkes process, Ogata's modified thinning algorithm). In order to use the algorithm we need to choose the m(t) and l(t), and the only requirement is that the inequality ( <ref type="formula">6</ref>) is fulfilled at any possible step of the algorithm. Since</p><formula xml:id="formula_36">λ * (t) = µ + α t i &lt;t exp(−(t − t i )),</formula><p>is non-increasing (except when new points appear), we can choose m(t) = λ(s) at every starting point s in the algorithm and any t ≥ s, and l(t) = ∞. This choice can be used for any point process where λ * (t) only increases when new points arrive. So the Hawkes process can be simulated either by the inverse method or Ogata's modified thinning algorithm (but in fact there are simpler methods for simulating the Hawkes process, see e.g. <ref type="bibr">Møller and</ref><ref type="bibr">Rasmussen (2005, 2006)</ref>).</p><p>It is easy to generalise the algorithm to the marked case: every time we keep a point t i in the algorithm, we should simulate its marks from the mark distribution f * (κ i |t i ) (just as for the inverse method we have the required knowledge of the past when we need to simulate this).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Why simulate a point process?</head><p>Simulations of point processes are useful for many things:</p><p>What does a point pattern typically look like? Simulating a point process a couple of times for a given model and a given set of parameters will provide valuable information on what a typical point pattern looks. Is it clustered or regular? Is it inhomogeneous or homogeneous? Does it look anything remotely like the data you are going to spend the next week fitting the model to?</p><p>Prediction: Given an observed past, what does the future hold? The specification of the conditional intensity function means that it is easy to include the already observed past, and then simulate the future.</p><p>Model checking: Prediction can also be used for model checking if we only use the data in the first half of the observation interval to fit a model, and then simulate predictions of the second half to see if this corresponds to the second half of the observed data. Or we can use all of the data, and compare with simulations of the whole dataset.</p><p>Summary statistics: Many quantities can be calculated explicitly from the conditional intensity function, such as the probability of getting no events in the next month or the mean time to the next event. However, particularly complicated summary statistics may not be available on closed form, but can instead be approximated by simulation. For example, the mean number of events in a given time interval may not be available on closed form for a complicated model, but we can then approximate it by the average number of points in a number of simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Model checking</head><p>In addition to the model checking approaches mentioned in Section 4.3, there is a particular kind of model checking associated with the conditional intensity function known as residual analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Residual analysis</head><p>Residual analysis <ref type="bibr" target="#b11">(Ogata, 1988)</ref> is a type of model checking for point processes specified by a conditional intensity function. It is based on the reverse transformation than the one used in Proposition 4.1.</p><p>Proposition 5.1. If (t i ) i∈Z is a point process with intensity λ * (t i ), and s i = Λ * (t i ), then (s i ) i∈Z is a unit rate Poisson process. Proof. This is proved in a similar manner as Proposition 4.1.</p><p>Thus if a point pattern is a realization of a point process with conditional intensity function λ * , then the integrated conditional intensity function will transform the pattern into a realization of a unit rate Poisson process. In practice this means that if we have modelled an observed point pattern with a point process, and the type of point process is well-chosen, then the transformed pattern should closely resemble a unit-rate Poisson process. In other words, the model checking boils down to checking whether the interevent times are independent exponential variables with mean one.</p><p>If the model does not fit, residual analysis may provide important information on how it does not fit. For example, if the data contains an unrealistically large gap for the model between t i and t i+1 , then the transformed data will contain a large gap between s i and s i+1 , i.e. s i+1 −s i will be to large to realistically come from a unit rate exponential distribution. A bit of creativity in analysing the residuals can give us all kinds of information about the original point pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding remarks</head><p>We have now seen that the conditional intensity function is a valuable tool for point process modelling, and can be used at all stages of data analysis:</p><p>• Preliminary analysis (simulation of potential models)</p><p>• Model specification and interpretation.</p><p>• Parameter estimation (maximum likelihood or Bayesian estimation).</p><p>• Model checking (residual analysis or simulation based approaches).</p><p>• Prediction.</p><p>However, we should note that basing parameter estimation and model checking on the same functions of the data is usually considered bad practice. For example, if we fit a model using maximum likelihood estimation, we have essentially fitted the conditional intensity function as well as we can, and it should not come as a surprise if the residuals fit rather well, since they are also based on the conditional intensity function. Here it would be more appropriate to base the model checking on other aspects of the model (such as the summary statistics given for example in <ref type="bibr" target="#b9">Møller and Waagepetersen (2004)</ref>), which may not be caught so well by the conditional intensity function.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A simulation of the Hawkes process is shown at the bottom of this plot, and the corresponding conditional intensity function is shown in the top. Note that the point pattern is clustered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A simulation of a self-correcting process is shown at the bottom of this plot, and the corresponding conditional intensity function is shown in the top. Note that the point pattern is regular.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>0 (point t n+1 = t n with probability zero, since the point process is simple). Isolating F (t|H tn ) we get (4), and (3) then follows by differentiating F (t|H tn ) with respect to t, again using the fundamental theorem of calculus.Proposition 2.2. A conditional intensity function λ * (t) uniquely defines a point process if it satisfies the following conditions for any point pattern (. . . , t 1 , . . . , t n ) and any t &gt; t n :1. λ * (t) is non-negative and integrable on any interval starting at t n , and 2.Proof. The distribution of the point process is well-defined, if all interevent times have well-defined densities, i.e. f (t|H tn ) should be a density function on t ∈ [t</figDesc><table /><note>t tn λ * (s)ds → ∞ for t → ∞. n , ∞), or equivalently F (t|H tn ) should be a cumulative distribution function. From the assumptions and (4) it follows that</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>This Poisson process has a chosen constant intensity on [t, t + l(t)], which fulfills Actually we only need to simulate the first point t i of this Poisson process. There are now two possibilities: If t i &gt; l(t), then there is no point in [t, t + l(t)], so we start again from t + l(t), but if t i ≤ l(t), there may be a point at t i in [t, t + l(t)]. In the latter case we need to figure out whether to keep this point or not. To get the correct intensity, we keep it with probability λ * (t i )/m(t). Whether or not we keep it, we start all over at t i .</figDesc><table><row><cell>m(t) ≥ sup</cell><cell>λ  *  (s).</cell><cell>(6)</cell></row><row><cell>s∈[t,t+l(t)]</cell><cell></cell><cell></cell></row><row><cell cols="2">Algorithm 4.2. (Ogata's modified thinning algorithm.)</cell><cell></cell></row><row><cell>1. Set t=0 and n=0.</cell><cell></cell><cell></cell></row><row><cell>2. Repeat until t &gt; T :</cell><cell></cell><cell></cell></row><row><cell>(a) Compute m(t) and l(t).</cell><cell></cell><cell></cell></row><row><cell cols="3">(b) Generate independent random variables s ∼ Exp(m(t)) and U</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Introduction to the Theory of Point Processes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Daley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vere-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Elementary Theory and Methods</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">I</biblScope>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An Introduction to the Theory of Point Processes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Daley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vere-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">General Theory and Structure</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">II</biblScope>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Point spectra of some mutually exciting point processes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="438" to="443" />
			<date type="published" when="1971">1971a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectra of some self-exciting and mutually exciting point processes</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1971">1971b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectra of some mutually exciting point processes with associated variables</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Point Processes</title>
				<editor>
			<persName><forename type="first">P</forename><forename type="middle">A W</forename><surname>Lewis</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1972">1972</date>
			<biblScope unit="page" from="261" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A cluster representation of a selfexciting process</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Hawkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oakes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="493" to="503" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A self-correcting point process</title>
		<author>
			<persName><forename type="first">V</forename><surname>Isham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Westcott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stoch. Proc. Appl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="335" to="347" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perfect simulation of hawkes processes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. in Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="646" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximate simulation of hawkes processes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methodol. Comput. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Statistical Inference and Simulation for Spatial Point Processes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Møller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Waagepetersen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton, Florida</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On Lewis&apos; simulation method for point processes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ogata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory, IT</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical models for earthquake occurrences and residual analysis for point processes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ogata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">401</biblScope>
			<biblScope unit="page" from="9" to="27" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Space-time point-process models for earthquake occurrences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ogata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the Institute of Statistical Mathematics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="379" to="402" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
