<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Minghao</forename><surname>Chen</surname></persName>
							<email>minghao.chen@stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haibin</forename><surname>Ling</surname></persName>
							<email>haibin.ling@stonybrook.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite remarkable progress achieved, most neural architecture search (NAS) methods focus on searching for one single accurate and robust architecture. To further build models with better generalization capability and performance, model ensemble is usually adopted and performs better than stand-alone models. Inspired by the merits of model ensemble, we propose to search for multiple diverse models simultaneously as an alternative way to find powerful models. Searching for ensembles is non-trivial and has two key challenges: enlarged search space and potentially more complexity for the searched model. In this paper, we propose a one-shot neural ensemble architecture search (NEAS) solution that addresses the two challenges. For the first challenge, we introduce a novel diversity-based metric to guide search space shrinking, considering both the potentiality and diversity of candidate operators. For the second challenge, we enable a new search dimension to learn layer sharing among different models for efficiency purposes. The experiments on ImageNet clearly demonstrate that our solution can improve the supernet's capacity of ranking ensemble architectures, and further lead to better search results. The discovered architectures achieve superior performance compared with state-of-the-arts such as MobileNetV3 and EfficientNet families under aligned settings. Moreover, we evaluate the generalization ability and robustness of our searched architecture on the COCO detection benchmark and achieve a 3.1% improvement on AP compared with MobileNetV3. Codes and models are available here.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The emergence of deep neural networks greatly relieves the need for feature engineering. Previous studies have shown that the design of neural network architecture <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b40">41]</ref> is essential to the performance for varied tasks in computer vision. However, the number of possible architectures is enormous, making the manual design very difficult. Neural Architecture Search (NAS) <ref type="bibr" target="#b47">[48]</ref> aims to automate the design process. Recently, NAS methods have achieved state-of-the-arts on varied tasks such as image classification <ref type="bibr" target="#b47">[48]</ref>, semantic segmentation <ref type="bibr" target="#b22">[23]</ref>, object detection <ref type="bibr" target="#b3">[4]</ref>, etc. Despite great progress achieved, most of the NAS methods focus on searching for optimal architectures of single models. However, the generalization ability and performance of single models are usually affected by different initialization, noisy data, and training recipe modification.</p><p>Model ensemble has been proved to be a universally effective method to build more robust and accurate models compared with single models. Implicit ensemble methods like Dropout <ref type="bibr" target="#b33">[34]</ref>, Dropconnect <ref type="bibr" target="#b39">[40]</ref>, StochDepth <ref type="bibr" target="#b14">[15]</ref>, Shake-Shake <ref type="bibr" target="#b8">[9]</ref> are already widely used in neural architecture design. On the contrary, although explicit ensemble methods like averaging, bagging, boosting, and stacking have been commonly adopted in large competitions and real-world scenarios. The use of explicit ensemble methods in designing efficient models is not fully explored due to the extra computation they brought.</p><p>Inspired by the effectiveness of ensemble, we propose to search for multiple models instead of one simultaneously to form a robust, accurate and efficient ensemble model. However, the combination of NAS and ensemble faces two challenges: (1) efficient search and supernet optimization over a large search space <ref type="bibr" target="#b1">(2)</ref> reducing the extra complexity brought by model ensemble. Addressing these challenges, in this paper, we propose a one-shot neural ensemble architecture search (NEAS) approach searching for lightweight ensemble models.</p><p>To solve the first challenge caused by the enlarged space of ensemble models compared with single models, we propose a novel metric called diversity score to progressively drop inferior candidates during the supernet training process, thus reduce the difficulty of finding promising ensemble models. This metric explicitly quantifies the diversity between the operators, which is commonly believed to be a key factor in building models with better feature expression capability.</p><p>To solve the second challenge, we introduce the layer sharing mechanism to reduce the model complexity. We allow the ensemble components share some shallow layers and search for the best architectures of the shared layers together with the architectures of the rest layers. We further introduce a new search dimension called split point to automatically find optimal layers for sharing under a given FLOPs constraint.</p><p>Comprehensive experiments verify the effectiveness of the proposed diversity score and layer sharing strategy. They improve the ranking ability of trained supernet and lead to better searched architectures under same complexity constraint. The searched architectures generate new stateof-the-art performance on ImageNet <ref type="bibr" target="#b7">[8]</ref>. For instance, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, our search algorithm finds a 314M FLOPs model that achieves 77.9% top-1 accuracy on ImageNet, which is 19% smaller and 1.6% better than EfficientNet-B0 <ref type="bibr" target="#b36">[37]</ref>. The architecture discovered by NEAS transfers well to downstream object detection task, suggesting the generalization ability of the searched models. We obtain an AP of 33.0 on COCO validation set, which is superior to the state-of-the-art backbone, MobileNetV3 <ref type="bibr" target="#b11">[12]</ref>.</p><p>In summary, we make the following contributions:</p><p>• We propose a pipeline, NEAS, searching for diverse models under certain resource constraints. Our approach could search for both homogeneous and heterogeneous ensemble models.</p><p>• We design a new metric, diversity score, to guide the shrinking process of search space. We evaluate its superiority on supernet training and the performance of searched models by enormous experiments.</p><p>• We propose a layer-sharing strategy to reduce the complexity of ensemble models and enlarge the search space to search for an optimal split point.</p><p>• We compare the searched architectures to state-of-theart NAS methods on the image classification task and achieve state-of-the-art results. Furthermore, we evaluate our searched model on the downstream object detection task, showing their generalization ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>Neural Architecture Search. Early NAS approaches search the architectures using either reinforcement learning <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b44">45]</ref> or evolution algorithms <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b34">35]</ref>. These methods have demonstrated that NAS can find architectures that surpass hand-crafted ones on a variety of tasks. However, these approaches require training thousands of architecture candidates from scratch, leading to unaffordable computation overhead. Most recent works resort to the weight sharing strategy to amortize the searching cost.</p><p>Those approaches train a single over-parameterized supernet and then share the weights across subnets. They could be further categorized as two types: path-based <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b4">5]</ref> and gradient-based methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b41">42]</ref>. Path-based methods sample paths in each iteration to optimize the weights of supernets. Once the training process is finished, the subnets can be ranked by the shared weights. On the other hand, gradient-based methods relax the discrete search space to be continuous, and optimize the search process by the efficient gradient descent. Ensemble Learning. Ensemble methods are widely used to boost the performance of neural networks <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b32">33]</ref>. Strategies for building ensembles could be mainly divided into two categories. The first ones train different models independently and then apply ensemble methods to form a more robust model, such as boosting, bagging, and stacking <ref type="bibr" target="#b46">[47]</ref>. The other methods train only one model with specific strategies to achieve implicit ensemble <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b13">14]</ref>. Different from the above methods, we perform explicit ensemble without separate training and search for diverse model architectures to build ensemble models with great feature expression ability. Search Space Shrinking. Recent works have shown search space shrinking is effective in boosting the ranking ability of NAS methods, especially when the search space is huge. <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b26">27]</ref>. These methods could be classified into different types according to their evaluation metrics. There are three basic types: accuracy-based, magnitudebased, and angle-based metrics. For example, PCNAS <ref type="bibr" target="#b19">[20]</ref> drop unpromising operators layer by layer using accuracy and shows that it improves candidate networks' quality. An-gleNAS <ref type="bibr" target="#b12">[13]</ref> uses the angles between weights of models to guide the search process. However, existing shrinking techniques only consider operators independently. Therefore, they can't directly adapt to search for ensemble models. We design a new metric considering both the performance of single operators and the diversity across them.   It takes the search space as the input and outputs an ensemble model with shared shallow layers. We set the number of paths in the searched models to 2 and choice operators to 4 for explanation. The overlapping upper lines in the right graph indicate that the two paths share the first two layers. They then branch to two different paths. ER means the expansion ratio for the mobile inverted residual block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>In Section 3.1, we give the formulation of NEAS. In Section 3.2, we present the definition of the diversity score and the space shrinking pipeline. In Section 3.3, we introduce the layer sharing mechanism and the new search dimension Split Point. In Section 3.4, we give the detailed pipeline of NEAS which allows to search under different resource constrains. The overall framework is visualized in Fig. <ref type="figure" target="#fig_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">NEAS Formulation</head><p>Given the search space Ω of single deep neural networks, denote A = {φ k ∈ Ω:k =1 ,...,K} as a set of K architectures with corresponding parameters W = {ω k : k =1 ,...,K}, Φ(•; A, W) as the ensemble model, and S =Ω K as the search space of ensemble models. The goal of NEAS is to find an optimal architectures set A * that maximizes the overall validation accuracy. To reduce the search cost, we constrain Ω to a certain architecture family, specifically, the subnetworks induced by a predefined supernet. In our work, we specify Φ(•; A, W) as:</p><formula xml:id="formula_0">Φ(•; A, W)= K i=1 φ i (•; w i ) K .<label>(1)</label></formula><p>We then formulate NEAS as a two-stage optimization problem like other one-shot methods (e.g., <ref type="bibr" target="#b9">[10]</ref>). The firststage is to optimize the weight of the supernet by:</p><formula xml:id="formula_1">W S =argmin W L train (Φ(•; A,W(A))),<label>(2)</label></formula><p>where L train is the loss function on the training set, W (A) means architectures in A inherit weights from W . This step is done by uniformly sampling an ensemble architecture Φ from S and performing backpropagation to update the weight of the corresponding blocks in the supernet for each iteration. Please refer to Section 3.4 for details.</p><p>The second step is to search for an optimal architecture set A * via ranking the performance based on learned weight W S of supernet, which is formulated as</p><formula xml:id="formula_2">A * =argmax A ACC val (Φ(•; A,W S (A))), s.t. K i g i (φ i ) &lt;C,<label>(3)</label></formula><p>where g and C are the resource computation functions and the resource constraints. Typical constraints include FLOPs, parameters size, and run-time latency.</p><p>Since it is difficult to enumerate all ensemble architectures for evaluation, we resort to a specific K-path evolution algorithms to find the most promising one. The details are presented in Appendix B and Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Diversity-Guided Search Space Shrinking</head><p>Since we search directly for the ensemble models, the search space for each layer increases exponentially from</p><formula xml:id="formula_3">N to A K N = N ! (N −K)</formula><p>! compared with single path methods, where N is number of the alternative operators for each layer. The large search space causes inefficiency search and supernet optimization problem. Search space shrinking is a feasible solution to alleviate the problem by discarding inferior operators progressively with a specific metric. Since diversity plays a key role in building a robust ensemble model, we design a new metric to explicitly quantify the diversity across operators inspired by fixed-size determinantal point processing (K-DPP) <ref type="bibr" target="#b16">[17]</ref>, a popular sampling model with great ability to measure the global diversity and quality within a set. In the following section, we first define the diversity score of an operator combination and then present the diversity-guided search space shrinking pipeline. Definition of Diversity Score. Assume we have an ensemble model Φ(.; A,W(A)), wherer</p><formula xml:id="formula_4">A = {φ 1 ,φ 2 , ••• ,φ K } consisting of K different paths.</formula><p>Since we fix the depth of the search space, we can slice A into operator combinations by layer. Then, A can be reshaped as</p><formula xml:id="formula_5">{h m |h m =( o 1,m ,o 2,m , ••• ,o K,m ),m =1 , 2, ••• ,d},</formula><p>where m and d are the index of the layer and number of total layers, o i,m denotes the operator on layer m of the path i. Now our goal changes to find the optimal operator combination for each layer.</p><p>Given that layer m has N alternative operators</p><formula xml:id="formula_6">O = O 1,m ,O 2,m , ••• ,O N,m , we construct a DPP kernel L ∈ R N ×N for layer m as: L m =diag(r m ) • S m • diag(r m ),<label>(4)</label></formula><p>where the kernel is formed by two components: a similarity matrix S m ∈ R N ×N and a quality matrix</p><formula xml:id="formula_7">r m ∈ R N . Let v 1 , ••• ,v K denote the feature maps output from the K different paths φ 1 , ••• ,φ K of the ensemble model Φ(.; A,W(A)).</formula><p>We define the similarity S m i,j of two operators O i,m and O j,m as expected the similarity between paths that contains the two operators, respectively:</p><formula xml:id="formula_8">S m i,j = E A⊆S p,q I(i, j, p, q)exp(−β v p − v q 2 ) ,<label>(5)</label></formula><p>where 1 ≤ p, q ≤ K, β is a scaling factor, and the indicator function is defined as:</p><formula xml:id="formula_9">I(i, j, p, q)= 1,O i,m ∈ φ p , 0,O j,m ∈ φ q . (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>The quality of operator O i,m is computed by taking expected accuracy of paths containing it. The formal definition is: Training the supernet G for E epochs following Section 3.4;</p><formula xml:id="formula_11">r m i = γ E A⊆S φq|Oi,m∈φq ACC train ′ (φ q ) #{φ p |O i,m ∈ φ p } ,<label>(7)</label></formula><formula xml:id="formula_12">4: Sample Z ensemble models Φ 1 , Φ 2 , ••• , Φ Z ran- domly; 5:</formula><p>Compute diversity score of each operator combination from S using Eq. 5,7,</p><p>Removing k operator combination from S with the lowest k scores 7: end while where φ q ,φ p ∈A , ACC train ′ is the accuracy evaluated on a small part of training dataset.</p><p>In practice, we do not calculate the exact expectation of similarity matrix and quality matrix. Instead, we randomly sample a finite number of ensemble models and use the mean as an approximate of the expectation.</p><p>The diversity score of a certain operator combination h m of layer m is defined as following:</p><formula xml:id="formula_14">Score(h m )=det(L y m ),<label>(8)</label></formula><p>where L y m is the submatrix of L m that contains all operators of h m . The trade-off between similarities and accuracy is controlled by the hyperparameter γ.</p><p>According to the the definition of diversity score, we have the following property: For h m and h m that are different by only the i th operator, if</p><formula xml:id="formula_15">S m i,j &lt;S m i ′ ,j for j =1, 2, ••• ,K and r m i &gt;r m i ′ , then Score(h m ) &gt;Score(h ′ m ).<label>(9)</label></formula><p>This property suggests that the metric will drop similar and unpromising operator combinations while keep diverse and accurate operator combinations. We refer to Appendix A for a proof. Diversity-Guided Search Space Shrinking. Based on the diversity score, we present Algorithm 1 to describe the diversity-guided search space shrinking pipeline shown in middle of Fig. <ref type="figure" target="#fig_2">2</ref>. Note that during the shrinking process, at least one operator combination is preserved, since our method does not change the connectivity of the supernet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Layer Sharing Among Ensemble Components</head><p>The challenge of potential massive complexity of searched ensemble models is handled by the layer sharing mechanism. This mechanism is inspired by several recent studies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30]</ref>. These works find that both the same neural architectures with different initialization and different architectures learn similar features in their lower layers. Therefore, we consider to share the shallow layers of different ensemble components. We propose to search for diverse ensemble components with shared shallow layers and different deep layers to reduce the computation cost. To automatically find which layers should be shared, we design a new search dimension called split point. The split point defines where the ensemble model will have heterogeneous architectures. It also handles the trade-off between diversity and computation constrain. A comparison between the architectures searched by NEAS and other NAS methods such as <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref> is presented in Fig. <ref type="figure" target="#fig_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Neural Ensemble Architecture Search</head><p>As state in Section 3.1 and in Fig. <ref type="figure" target="#fig_2">2</ref>, NEAS includes two sequential phases: K-path supernet training with diversityguide search space shrinking, and K-path evolution search. </p><formula xml:id="formula_16">A split = {h s+1 ,h s+2 , ••• ,h d }</formula><p>for the rest of layers from the shrunk search space. The loss L i of each path φ i is computed independently while the backpropagation is performed using the combined loss L = K i L i to update the weights of corresponding blocks in the supernet. Following this updating process, the whole network is still trained in an end-to-end style. After training the supernet for several epochs, we follow the steps in Algorithm 1 to shrink the search space. The shrinking and training are conducted alternatively.</p><p>During inference, these selected paths make predictions independently, and our ensemble network's output is the average of predictions from all paths. Phase 2: K-Path Evolution Search. After obtaining the trained supernet, we perform evolution search on it to obtain an optimal ensemble model. These models are evaluated and picked according to the manager of the evolution algorithm. It is worth noting that, before evaluating an ensemble model, we first need to recalculate the batch normalization (BN) statistics for each block. This is because, during the supernet training, the BN statistics of different blocks are optimized simultaneously. These statistics are usually not applicable to the subnets. We randomly extract a part of the ImageNet training set to recalculate the BN statistics.</p><p>At the beginning of the evolution search, we pick N seed random architecture as seeds. The top k architectures are picked as parents to generate the next generation by crossover and mutation. In one crossover, two randomly se- lected candidates are picked and crossed to produce a new one during each generation. We drop the architecture got by crossover if the corresponding architecture is not in the shrunk search space or exceeds the FLOPs constraint. In one mutation, a candidate mutates its split point with a probability P s . If the split point increases, the number of sharing layers increases with the same number. We randomly pick one path and move its corresponding architectures to the sharing architecture. Otherwise, if the split point decreases, we cut the sharing architecture and add it to each path's architecture. At last, the candidate mutates its layers with a probability of P m to produce a new candidate. It is worth noting that the operation combinations are only picked from the shrunk search space. We perform crossover and mutation several times to generate new candidates. We generate some random architectures after crossover and mutation to meet the given population demanding. We provide the detailed algorithm in the Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head><p>In this section, we first give details of our search space and implementation. We then present ablation studies dissecting our method, followed by a comparison with previous state-of-the-art NAS methods. At last, we evaluate the generalization ability and robustness of the searched architecture on COCO object detection benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>Search Space. Consistent with previous NAS methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b36">37]</ref>, our search space includes a stack of mobile inverted bottleneck residual blocks (MBConv). We also add squeeze-excitation modules to each block following Effi-cientNet <ref type="bibr" target="#b36">[37]</ref> and MobileNetV3 <ref type="bibr" target="#b11">[12]</ref>. For details, there are 7 basic operators for each layer, including MBConv with kernel sizes of 3,5,7, expansion rates of 4,6 and skip con- nect for elastic depth. The split point space is set to range <ref type="bibr" target="#b8">(9,</ref><ref type="bibr" target="#b19">20)</ref> to handle different complexity constrains. In total we have 7 20K × 12 ≥ 7 × 10 33 (K ≥ 2) architectures, which is much larger than most NAS methods. A more detailed description of search space could be found in Appendix A.</p><p>Supernet Training. We train the supernet for 120 epochs using the settings similar to SPOS <ref type="bibr" target="#b9">[10]</ref>: SGD optimizer with momentum 0.9 and weight decay 4e-5, initial learning rate 0.5 with a linear annealing. The shrinking process is conducted every 20 epochs. The number of operators dropped each time is empirically set to 20. β in the computing the similarity matrix is set to 1e-3 according to experimental results.</p><p>Evolution Search. We set the population N seed of evolution search to 50 with the size of top candidates pool k equals to 10. The number of generations is 20. P s and P m are both 0.1. The number of candidates performs mutation and crossover are set to 25 in each generation. We recalculate the BN statistics on a subset of ImageNet.</p><p>Retrain. We retrain the discovered architectures for 350 epochs on ImageNet using similar settings as Efficient-Net <ref type="bibr" target="#b36">[37]</ref>: RMSProp optimizer with momentum 0.9 and decay 0.9, weight decay 1e-5, dropout ratio 0.2, initial learning rate 0.064 with a warmup in the first 10 epochs and a cosine annealing. AutoAugment <ref type="bibr" target="#b6">[7]</ref> and exponential moving average are also used for training. We retrain the models with a batch size of 2,048 on 16 Nvidia Tesla V100 GPUs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study</head><p>Effectiveness of Diversity Score. We set the baseline as NEAS without diversity-guided shrinking. In addition, we compare the diversity score with the accuracy metric to further verify its efficacy. Since the accuracy-based methods only consider the accuracy of single operators in each layer. We adapt the definition of accuracy to the accuracy of operator combinations. Other methods like Angle-based metric can not easily adapt to search for ensembles. We first perform correlation analysis to evaluate whether the training process with diversity shrinking can improve the ranking ability of supernet. We randomly sample 30 subnets and calculate the rank correlation between the weight sharing performance and the true performance of training from scratch. Training many such subnets on Im-ageNet is very computationally expensive. We follow the setting of Cream <ref type="bibr" target="#b28">[29]</ref>, which constructs a subImageNet dataset consisting of 100 classes randomly sampled from  <ref type="table" target="#tab_3">2</ref> suggests that our diversity score effectively helps supernet to rank the ensemble architectures in the supernet. We also retrain the searched architectures by the three methods under the same FLOPs constraint. The top-1 and top-5 accuracy results on the ImageNet dataset are shown in the third and fourth columns in Table <ref type="table" target="#tab_3">2</ref>. We could see that the diversity-guided shrinking is 0.6% better than the baseline and 0.7% better than the accuracy-based method. We further compare the average accuracies of the architectures in the last generation of evolution search, displaying in the fourth columns. Our diversity-guided shrinking surpass the baseline and accuracy-based method by 0.5% and 1.1% top-1 accuracy on ImageNet in the supernet. The results suggest that the diversity score helps remove unpromising candidates and enhance the convergence of supernet. Impact of Heterogeneous Path Architectures. Ensembling models of homogeneous (homo) architectures are known to be an effective way of building powerful models <ref type="bibr" target="#b17">[18]</ref>. We here compare the ensemble models of homogeneous and heterogeneous architectures to show the importance of heterogeneous ensemble. We use our searched two-path ensemble model as the baseline. Then we mirror one path of the searched architecture to form two homogeneous ensemble models for comparison. Fig. <ref type="figure" target="#fig_7">4</ref> gives the visualization of the final hidden features of baseline and the homogeneous network fine-tuned on CIFAR-10. We can see that the homo paths have a similar feature distribution. However, the hetero paths have varied feature distribution and a clearer margin between the clusters.</p><p>In table <ref type="table">3</ref>, we compare the performance of these three models on ImageNet. This table shows an interesting fact that even the stand-alone performance of homo paths are better than hetero. However, the performance of the homo  Impact of Layer Sharing. Layer sharing plays a significant role in reducing the complexity of an ensemble model. Here, we explore the effectiveness of layer sharing. The baseline is the ensemble model with no shared layers searched by our method. In Table <ref type="table">4</ref>, we could see that layer sharing will help to reduce the complexity of ensemble models largely while keeping outstanding performance. Besides, we observed that in our searched models, the larger model attempts to share fewer layers. One reason could be that the feature expression ability of stand-alone paths in larger models is already strong since it is more complicated. Therefore, they prefer to share fewer layers and get more diverse paths. Impact of Number of Paths for Ensemble. The number of paths K used to form the ensemble model is a hyperparameter we define at first. We compare the performance of the searched model under the mobile setting ( 600M FLOPs) using different K. From Table <ref type="table">5</ref>, we can see that when the number of paths is equal to 2, we achieve the best results.</p><p>One likely reason could be that if a network has too many paths, each path's stand-alone feature expression ability decreases a lot due to complexity constraints. Impact of Search Algorithm. Random search is known to be a competitive baseline in NAS methods. We com- pare random search with evolution search to evaluate the effectiveness of evolution search. We demonstrate the performance of architectures using the weights inherited from supernet on the validation dataset during the search. Top 50 candidates until the current iteration are depicted at each iteration. Fig. <ref type="figure">5</ref> illustrates that evolution search is better for searching on supernet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparisons with State-of-the-Art Methods</head><p>Table <ref type="table" target="#tab_2">1</ref> presents the comparison of our method with state-of-the-arts under mobile settings on ImageNet. It shows that when considering models with FLOPs smaller than 600M, our method consistently outperforms the recent MobileNetV3 <ref type="bibr" target="#b11">[12]</ref> and EfficientNet-B0/B1 <ref type="bibr" target="#b36">[37]</ref>. In particular, NEAS-L achieves 80.0% top-1 accuracy with only 574M FLOPs, which is 160M FLOPs smaller and 0.8% better than EfficientNet-B1. NEAS-M obtains 79.5% top-1 accuracy with 472M FLOPs. NEAS-S achieves 77.9% accuracy using only 314M FLOPs, which is 1.6% better and 19% smaller than EfficientNet-B0. We also provide results of other state-of-the-art NAS methods in Table <ref type="table" target="#tab_2">1</ref>. It is worth noting that some NAS methods like OFA <ref type="bibr" target="#b0">[1]</ref>, BigNAS <ref type="bibr" target="#b43">[44]</ref>, DNA <ref type="bibr" target="#b18">[19]</ref> use knowledge distillation to boost the training process and also improve the accuracy of searched models. However, even compared with these methods, our searched ensemble architectures, which do not use knowledge distillation, still achieve superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Generalization Ability and Robustness</head><p>To further evaluate the generalization ability of the architectures found by NEAS, we transfer the architectures to the downstream COCO <ref type="bibr" target="#b21">[22]</ref> object detection task. We use the NEAS-S (pre-trained 500 epochs on ImageNet) as a dropin replacement for the backbone feature extractor in Reti-naNet <ref type="bibr" target="#b20">[21]</ref> and compare it with other backbone networks. We perform training on the train2017 set (around 118k images) and evaluation on the val2017 set (5k images) with 32 batch sizes using 8 V100 GPUs. Following the settings in <ref type="bibr" target="#b5">[6]</ref>, we train the detection model with 12 epochs, an initial learning rate of 0.04, and multiply the learning rate by 0.1 at epochs 8 and 11. The optimizer is SGD with 0.9 momentum and 1e-4 weight decay. As shown in Table <ref type="table" target="#tab_4">6</ref>, our method surpasses MobileNetV2 by 4.7% using similar FLOPs. Compared with MnasNet <ref type="bibr" target="#b35">[36]</ref>, our method utilizes 7% fewer FLOPs while achieving 2.5% higher performance, suggesting the architecture has good generalization ability when transferred to other vision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose a novel approach to search for lightweight ensemble models based on one-shot NAS. We design a new metric, called diversity score, to guide search space shrinking. We further use the layer-sharing mechanism to reduce the complexity of ensemble models and introduce a new search dimension, called split point, to handle the trade-off between diversity and complexity constraint. Extensive experiments demonstrate that the proposed new metric is effective and improves the weight sharing supernet's ranking ability. Our searched architectures do achieve not only state-of-the-art performance on ImageNet but also have great generalization ability and robustness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Comparison of our method with state-of-the-art approaches on ImageNet under mobile settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. NEAS contains mainly two steps: K-path Supernet Training with Diversity-Guided Shrinking, and K-path Evolution Searching. It takes the search space as the input and outputs an ensemble model with shared shallow layers. We set the number of paths in the searched models to 2 and choice operators to 4 for explanation. The overlapping upper lines in the right graph indicate that the two paths share the first two layers. They then branch to two different paths. ER means the expansion ratio for the mobile inverted residual block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Phase 1: K-Path Supernet Training with Diversity-Guide Search Space Shrinking. For each training iteration, an ensemble model Φ(.; A,W(A)) is randomly sampled. In specific, we randomly sample the split point s, the architecture of sharing layers A sharing = {o 1 ,o 2 , ••• ,o s }, and the operator combinations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. (a) The architecture searched by classical NAS methods (e.g., [10, 6]). (b) The architecture searched by NEAS. Different color means different expansion ratio while the length of the block represents the kernel size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Comparison of architectures with homogeneous (homo) and heterogeneous (hetero) paths. Both architectures have two paths. The numbers in the columns 2,3,4 are the top-1 accuracies. Path 1 (%) Path 2 (%) Ens.(%) FLOPs(Comparison of split point in different searched models. Baseline: ensemble model (2 models) with no shared layers. Top-1 and Top-5 represents the top-1 and top-5 accuracy on ImageNet. Model Split point Top-1 (%) Top-5 (%) FLOPs (M) class has 250 training images and 50 validation images. We use Kendall Tau to show the ranking capacity of supernet. The second column of Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. t-SNE visualization on the final hidden features of two different ensemble model. The first row denotes the model with two homogeneous path, while the second has two heterogeneous paths. The inputs are the test set of CIFAR-10. Table 5. Impact of number of paths predefined for NEAS. Top-1 and Top-5 represents the top-1 and top-5 accuracy on ImageNet. #paths Top-1 (%) Top-5 (%) FLOPs (M) 2 80.0 94.8 574 3 79.5 94.6 564 5 78.5 94.1 570</figDesc><graphic url="image-5.png" coords="7,435.56,192.92,76.36,77.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Algorithm 1 Diversity-Guided Search Space Shrinking Input: A search space S, threshold of search space size T , number of operators dropped out each shrinking k, supernet G, number of ensembles sampled each shrink Z, training epochs between each shrink E. Output: A shrunk search space S.</figDesc><table /><note>1: Let S = S 2: while | S| &gt; T do 3:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Comparison of state-of-the-art NAS methods on ImageNet. †: TPU days, ⋆: reported by<ref type="bibr" target="#b9">[10]</ref>, ‡: searched on CIFAR-10, "-" means not reported. ♦: Tested on NVIDIA GTX 1080Ti.</figDesc><table><row><cell></cell><cell>Methods</cell><cell cols="3">Top-1 Top-5 FLOPs (%) (%) (M)</cell><cell>Memory cost</cell><cell cols="3">Superne train Search cost Retrain epochs (GPU days) (GPU days)</cell></row><row><cell></cell><cell>MobileNetV3Large1.0 [12]</cell><cell>75.2</cell><cell>-</cell><cell>219</cell><cell>single path</cell><cell>288  †</cell><cell>-</cell><cell>150</cell></row><row><cell>200 -350M</cell><cell>OFA [1] MobileNetV2 [32] MnasNet-A1 [36] FairNAS-C [6] FBNetV2-L1 [39]</cell><cell>76.9 72.0 75.2 74.7 77.2</cell><cell>-91.0 92.5 92.1 -</cell><cell>230 300 312 321 325</cell><cell cols="2">two paths --53 single path 288  † single path 10 --</cell><cell>2 --2 -</cell><cell>--350 -400</cell></row><row><cell></cell><cell>SPOS [10]</cell><cell>74.7</cell><cell>-</cell><cell>328</cell><cell>single path</cell><cell>12 ♦</cell><cell>&lt; 1</cell><cell>240</cell></row><row><cell></cell><cell>NEAS-S (Ours)</cell><cell>77.9</cell><cell>93.9</cell><cell>314</cell><cell>K paths</cell><cell>12</cell><cell>&lt; 1</cell><cell>350</cell></row><row><cell>350 -500M</cell><cell>GreedyNAS-A [43] EfficientNet-B0 [37] FBNetV2-L2 [39] ProxylessNAS[2] Cream-M [29]</cell><cell>77.1 76.3 78.2 75.1 79.2</cell><cell>93.3 93.2 --94.2</cell><cell>366 390 422 465 481</cell><cell>single path --two paths two paths</cell><cell>7 --15 12</cell><cell>&lt; 1 ---0.02</cell><cell>300 350 400 300 500</cell></row><row><cell></cell><cell>NEAS-M (Ours)</cell><cell>79.5</cell><cell>94.6</cell><cell>472</cell><cell>K paths</cell><cell>12</cell><cell>&lt; 1</cell><cell>350</cell></row><row><cell></cell><cell>DARTS [24]</cell><cell>73.3</cell><cell>91.3</cell><cell>574</cell><cell>whole supernet</cell><cell>4  ‡</cell><cell>-</cell><cell>250</cell></row><row><cell>500 -600M</cell><cell>BigNASModel-L [44] OFALarge [1] DNA-d [19] EfficientNet-B1 [37]</cell><cell>79.5 80.0 78.4 79.2</cell><cell>--94.0 94.5</cell><cell>586 595 611 734</cell><cell>two paths two paths single path -</cell><cell>96  † 53 24 -</cell><cell cols="2">--2 -0.6 500 -350</cell></row><row><cell></cell><cell>NEAS-L (Ours)</cell><cell>80.0</cell><cell>94.8</cell><cell>574</cell><cell>K paths</cell><cell>12</cell><cell>&lt; 1</cell><cell>350</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Comparison of different shrink metrics. Baseline means no search space shrinking during the supernet training. †: average accuracy use weight inherits from supernet. The accuracies are evaluated on ImageNet.</figDesc><table><row><cell>Metric</cell><cell cols="4">Kendall Tall Top-1 (%) Top-5 (%) Top-1  † (%)</cell></row><row><cell>Baseline</cell><cell>0.45</cell><cell>77.3</cell><cell>93.3</cell><cell>67.8</cell></row><row><cell>Accuracy</cell><cell>0.42</cell><cell>77.2</cell><cell>93.2</cell><cell>67.2</cell></row><row><cell>Diversity</cell><cell>0.65</cell><cell>77.9</cell><cell>93.9</cell><cell>68.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>Object detection results of various drop-in backbones on COCO val2017. Top-1 accuracies are on ImageNet. †: reported by<ref type="bibr" target="#b5">[6]</ref>.</figDesc><table><row><cell>Backbones</cell><cell cols="8">FLOPs (M) AP (%) AP50 AP75 APS APM APL Top-1 (%)</cell></row><row><cell>MobileNetV3  † [12]</cell><cell>219</cell><cell>29.9</cell><cell>49.3</cell><cell>30.8</cell><cell>14.9</cell><cell>33.3</cell><cell>41.1</cell><cell>75.2</cell></row><row><cell>MobileNetV2  † [32]</cell><cell>300</cell><cell>28.3</cell><cell>46.7</cell><cell>29.3</cell><cell>14.8</cell><cell>30.7</cell><cell>38.1</cell><cell>72.0</cell></row><row><cell>FairNAS-C [6]</cell><cell>325</cell><cell>31.2</cell><cell>50.8</cell><cell>32.7</cell><cell>16.3</cell><cell>34.4</cell><cell>42.3</cell><cell>76.7</cell></row><row><cell>MnasNet-A2  † [36]</cell><cell>340</cell><cell>30.5</cell><cell>50.2</cell><cell>32.0</cell><cell>16.6</cell><cell>34.1</cell><cell>41.1</cell><cell>75.6</cell></row><row><cell>MixNet-M  † [38]</cell><cell>360</cell><cell>31.3</cell><cell>51.7</cell><cell>32.4</cell><cell>17.0</cell><cell>35.0</cell><cell>41.9</cell><cell>77.0</cell></row><row><cell>SPOS  † [10]</cell><cell>365</cell><cell>30.7</cell><cell>49.8</cell><cell>32.2</cell><cell>15.4</cell><cell>33.9</cell><cell>41.6</cell><cell>75.0</cell></row><row><cell>NEAS-S</cell><cell>314</cell><cell>33.0</cell><cell>53.3</cell><cell>34.4</cell><cell>17.9</cell><cell>36.2</cell><cell>43.8</cell><cell>78.0</cell></row><row><cell cols="3">Figure 5. Random search versus evolution algorithm.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are very grateful to Minghao's mentor Dr. Houwen Peng at MSRA for his great and thorough contributions in all aspects including idea proposals, intensive discussion, experiment design and analysis, and writing, etc. Ling was supported in part by US National Science Foundation (1814745 and 2006665).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Once-for-all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware. ICLR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Detnas: Backbone search for object detection</title>
		<author>
			<persName><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mixpath: A unified approach for one-shot neural architecture search</title>
		<author>
			<persName><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xudong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.05887</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation policies from data</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Ekin D Cubuk</surname></persName>
		</author>
		<author>
			<persName><surname>Zoph</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Gastaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07485</idno>
		<title level="m">Shake-shake regularization</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Single path one-shot neural architecture search with uniform sampling</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for mo-bilenetv3</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Angle-based search space shrinking for neural architecture search</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruosi</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">E</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00109</idno>
		<title level="m">Snapshot ensembles: Train 1, get m for free</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Similarity of neural network representations revisited</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">k-dpps: Fixed-size determinantal point processes</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Balaji Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><surname>Blundell</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Blockwisely supervised neural architecture search with knowledge distillation</title>
		<author>
			<persName><forename type="first">Changlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiefeng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liuchun</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangrun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving one-shot nas by suppressing the posterior fading</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Focal loss for dense object detection</title>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">COCO: Common objects in context</title>
		<author>
			<persName><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<publisher>Microsoft</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Darts: Differentiable architecture search</title>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Insights on representational similarity in neural networks with canonical correlation</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Xnas: Neural architecture search with expert advice</title>
		<author>
			<persName><forename type="first">Niv</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asaf</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itamar</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihi</forename><surname>Zelnik</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Asap: Architecture search, anneal and prune</title>
		<author>
			<persName><forename type="first">Asaf</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niv</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadav</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivan</forename><surname>Doveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itamar</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihi</forename><surname>Zelnik</surname></persName>
		</author>
		<editor>AISTATS. PMLR</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Cream of the crop: Distilling prioritized paths for one-shot neural architecture search</title>
		<author>
			<persName><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability</title>
		<author>
			<persName><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A genetic programming approach to designing convolutional neural network architectures</title>
		<author>
			<persName><forename type="first">Masanori</forename><surname>Suganuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinichi</forename><surname>Shirakawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoharu</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GECOO</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Mixconv</surname></persName>
		</author>
		<title level="m">Mixed depthwise convolutional kernels. BMVC</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fbnetv2: Differentiable neural architecture search for spatial and channel dimensions</title>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Le Cun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Greedynas: Towards fast oneshot nas with greedy supernet</title>
		<author>
			<persName><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingmin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
		<title level="m">Ruoming Pang, and Quoc Le. Bignas: Scaling up neural architecture search with big single-stage models. ECCV</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Practical block-wise neural network architecture generation</title>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Ensemble methods: foundations and algorithms</title>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Ensembling neural networks: many could be better than all</title>
		<author>
			<persName><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>AI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
