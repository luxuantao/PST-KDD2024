<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">APT-GET : Profile-Guided Timely Software Prefetching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Tanvir</roleName><forename type="first">Saba</forename><surname>Jamilan</surname></persName>
							<email>sjamilan@ucsc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Tanvir</forename><forename type="middle">Ahmed</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
							<email>barisk@umich.edu</email>
						</author>
						<author>
							<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
							<email>hlitz@ucsc.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
							<email>granta@google.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">APT-GET : Profile-Guided Timely Software Prefetching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3492321.3519583</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>‚Ä¢ Software and its engineering ‚Üí Compilers; ‚Ä¢ Computer systems organization ‚Üí Architectures Software Prefetching, Compiler Analysis</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prefetching which predicts future memory accesses and preloads them from main memory, is a widely-adopted technique to overcome the processor-memory performance gap. Unfortunately, hardware prefetchers implemented in today's processors cannot identify complex and irregular memory access patterns exhibited by modern data-driven applications and hence developers need to rely on software prefetching techniques. We investigate the challenges of enabling effective, automated software data prefetching. Our investigation reveals that the state-of-the-art compiler-based prefetching mechanism falls short in achieving high performance due to its static nature. Based on this insight, we design APT-GET , a novel profile-guided technique that ensures prefetch timeliness by leveraging dynamic execution time information. APT-GET leverages efficient hardware support such as Intel's Last Branch Record (LBR), for collecting application execution profiles with negligible overhead to characterize the execution time of loads. APT-GET then introduces a novel analytical model to find the optimal prefetch-distance and prefetch injection site based on the collected profile to enable timely prefetches. We study APT-GET in the context of 10 real-world applications and demonstrate that it achieves a speedup of up to 1.98√ó and of 1.30√ó on average. By ensuring prefetch timeliness, APT-GET improves the performance by 1.25√ó over the state-of-the-art software data prefetching mechanism.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A vast majority of today's software runs on processors inspired by the Von-Neumann architecture. Consequently, the Von-Neumann bottleneck (i.e., the processor-memory speed gap <ref type="bibr" target="#b45">[49,</ref><ref type="bibr" target="#b76">80,</ref><ref type="bibr" target="#b121">125]</ref>) is the root cause of many performance problems in today's software systems <ref type="bibr" target="#b10">[14,</ref><ref type="bibr" target="#b46">50,</ref><ref type="bibr" target="#b58">62,</ref><ref type="bibr" target="#b61">65,</ref><ref type="bibr" target="#b94">98]</ref>. To make matters worse, the data-driven nature of modern applications (e.g., machine learning <ref type="bibr" target="#b2">[6,</ref><ref type="bibr" target="#b30">34,</ref><ref type="bibr" target="#b123">127]</ref>,mobile applications <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b20">24]</ref>, and data analytics <ref type="bibr" target="#b19">[23,</ref><ref type="bibr" target="#b21">25,</ref><ref type="bibr" target="#b124">128,</ref><ref type="bibr" target="#b126">130]</ref>) has increased data footprints significantly, thus limiting the ability of traditional approaches such as deeper cache/memory hierarchies or compile-time data locality optimizations to scale and provide significant performance improvements <ref type="bibr" target="#b10">[14]</ref>. Consequently, widely-used modern applications lose more than 60% of all processor cycles due to frequent on-chip cache misses and the subsequently induced high memory access latency <ref type="bibr" target="#b9">[13,</ref><ref type="bibr" target="#b37">41,</ref><ref type="bibr" target="#b58">62,</ref><ref type="bibr" target="#b109">113]</ref>.</p><p>Prefetching-anticipating upcoming memory accesses and loading them before their use-can hide this memory access latency if performed accurately and in a timely manner <ref type="bibr" target="#b44">[48]</ref>. Therefore, a rich body of hardware <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b26">30,</ref><ref type="bibr" target="#b36">40,</ref><ref type="bibr" target="#b55">59,</ref><ref type="bibr" target="#b64">68,</ref><ref type="bibr" target="#b84">88,</ref><ref type="bibr" target="#b91">95,</ref><ref type="bibr" target="#b104">108,</ref><ref type="bibr" target="#b110">114,</ref><ref type="bibr" target="#b117">121,</ref><ref type="bibr" target="#b118">122]</ref> and software <ref type="bibr" target="#b5">[9,</ref><ref type="bibr" target="#b28">32,</ref><ref type="bibr" target="#b29">33,</ref><ref type="bibr" target="#b33">37,</ref><ref type="bibr" target="#b74">78,</ref><ref type="bibr" target="#b79">83,</ref><ref type="bibr" target="#b85">[89]</ref><ref type="bibr" target="#b86">[90]</ref><ref type="bibr" target="#b87">[91]</ref><ref type="bibr" target="#b112">116]</ref> data prefetching mechanisms have been proposed in the literature to reduce memory access latency. While there exists an exotic range of irregular data prefetching proposals (e.g., record and replay prefetchers <ref type="bibr" target="#b114">[118]</ref> and indirect prefetchers <ref type="bibr" target="#b122">[126]</ref>) in the computer architecture literature, only simple prefetchers (e.g., next-line <ref type="bibr" target="#b105">[109]</ref> and stride prefetchers <ref type="bibr" target="#b57">[61]</ref>) are implemented in today's hardware since complex prefetchers require impractical on-chip metadata storage along with significant hardware modifications <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10]</ref>.</p><p>Consequently, to avoid the memory access latency induced by irregular access patterns (e.g., indirect array access of the form, ùê¥[ùêµ [ùëñ]]), developers must rely on software data prefetching mechanisms <ref type="bibr" target="#b61">[65]</ref>. Manual software prefetching performed by programmers has shown to be cumbersome and error prone as it is difficult to evaluate the efficacy of a manually inserted prefetch <ref type="bibr" target="#b72">[76]</ref>. For irregular accesses, memory addresses are computed by sequences of instructions (the load-slice) rendering manual prefetch injection challenging <ref type="bibr" target="#b5">[9]</ref>. Code changes can easily break the prefetch address computation leading to inaccurate prefetches. As software prefetching introduces an instruction overhead, inaccurate prefetches can lead to a performance regression. Recent work on compiler-based automatic prefetch injection schemes <ref type="bibr" target="#b5">[9]</ref> has addressed the challenge of generating accurate prefetch-slices, however, it is still unable to address the memory access latency problem satisfactorily.</p><p>In this work, we first perform a comprehensive characterization of existing automated software data prefetching mechanisms. Specifically, we investigate why the state-of-the-art software data prefetching mechanism <ref type="bibr" target="#b5">[9]</ref> falls significantly short of an ideal (in terms of accuracy, coverage, and timelines) data prefetcher. In our investigation, we find that the existing static software-based solutions fail to prefetch memory blocks in a timely manner, thereby missing significant performance opportunities. In particular, prefetches generated too early may be evicted from the processor's caches unused while late prefetches are unable to hide the access latency of demand loads completely. We find that for timely prefetching, dynamic information such as the execution time of the optimized code is required. Unfortunately, state-ofthe-art software mechanisms only rely on static heuristics to inject prefetch instructions and hence cannot achieve the full performance potential of an ideal data prefetcher.</p><p>Driven by our analysis, we propose APT-GET 1 , a novel profile-guided mechanism to ensure the timeliness of software prefetch operations. APT-GET realizes software prefetch timeliness by effectively finding the optimal value for two key parameters: prefetch-distance and prefetch injection site. We define prefetch-distance as the distance between the current memory access and a future memory access, measured in terms of the number of memory accesses. It defines how far into the future we need to prefetch and it is determined by the program execution time that elapses in between the memory accesses. Prefetch injection site, on the other hand, determines the program location where the prefetch instruction is inserted. Instead of exhaustively searching over all-possible values of prefetch-distance and prefetch injection site, APT-GET obtains these values through a new profiling methodology leveraging existing hardware support. 1 as an appropriate and timely (APT ) prefetch <ref type="bibr">(GET )</ref> In particular, APT-GET profiles the elapsed time between two instances of the same memory access instruction to determine near optimal prefetch-distance and prefetch injection site for the corresponding prefetch.</p><p>We evaluate APT-GET in the context of 10 real-world, memory-latency-bound applications. Across all applications, APT-GET achieves an average execution time speedup of 1.30√ó. By optimizing the prefetching timeliness, APT-GET significantly outperforms the state-of-the-art software prefetching mechanism <ref type="bibr" target="#b5">[9]</ref> and provides on average 1.25√ó greater speedup.</p><p>Overall, we make the following contributions: ‚Ä¢ A thorough investigation of how existing software prefetching techniques fall significantly short of an ideal data prefetcher due to lack of prefetch timeliness ‚Ä¢ APT-GET : A profile-guided mechanism to ensure software prefetch timeliness by identifying the optimal prefetchdistance and the optimal prefetch injection site. ‚Ä¢ An LLVM compiler pass for automatically injecting prefetches that supports variable prefetch-distance and prefetch injection site. ‚Ä¢ An evaluation showing APT-GET 's effectiveness at ensuring prefetch timeliness for several widely-used memorybound applications while achieving a significant performance improvement.</p><p>As an outline for the rest of this paper, we first characterize the key challenges of automated software prefetching in ¬ß2. Next, we describe APT-GET 's design in ¬ß3. We then describe APT-GET 's evaluation on real-world applications and benchmarks in ¬ß4. After discussing the related work in ¬ß5, we finally conclude in ¬ß6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Understanding the Challenges of Automated Software Prefetching</head><p>In this section, we investigate the performance of existing automated software prefetching techniques and show why they fall short of providing high performance. In particular, we demonstrate that while existing techniques can achieve high accuracy and coverage, they are often unable to generate timely prefetches. This is because existing approaches utilize static techniques to inject prefetch instructions without incorporating dynamic information such as execution time. We perform this in-depth investigation using a microbenchmark and highlight the challenges of injecting timely prefetch instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Methodology</head><p>We analyze existing automated software prefetching techniques using a microbenchmark with an indirect memory access pattern as shown in Listing 1. The microbenchmark implements a two-nested loop leveraging indirect memory addresses to retrieve a data value from a target array T. whose work is dependent on the loaded data. We define two parameters to affect the behavior of the microbenchmark. INNER determines the trip count <ref type="bibr" target="#b53">[57]</ref> of the inner loop, while COMPLEXITY defines the time spent in the work function. We perform our microbenchmark analysis on an Intel Xeon Gold 6242R CPU running at 3.10GHz (4.1GHz Turbo) and 768GByte of DDR4-2666 DRAM. Because the microbenchmark is performing indirect memory accesses, Intel's hardware prefetchers <ref type="bibr" target="#b111">[115]</ref> are unable to predict the irregular memory addresses, leaving opportunities for software prefetching. We automatically inject software prefetches utilizing the state-of-the-art software prefetching approach <ref type="bibr" target="#b5">[9]</ref> implemented as an LLVM compiler pass. The pass operates at the intermediate representation (IR) level of LLVM and determines software prefetching opportunities through static code analysis. The pass identifies indirect memory accesses (loads) and then performs a backward data dependency analysis utilizing depth-first search until it finds the first loop induction variable, while keeping track of all the instructions that are encountered during this search. Since load instructions are located inside the loop, their memory addresses are dependent on the induction variable of the loop. Therefore, we need to know the value of the induction variable in each loop iteration to calculate the next memory addresses of the load that we want to prefetch. We can calculate the addresses for the next iterations by adding the prefetch-distance to the current induction variable. Additionally, the key difference between irregular access patterns such as in pointer chases and indirect memory accesses inside loops is, that all indirect accesses depend on the induction variable. Therefore, we need to know the induction variable value to generate prefetch instructions.</p><p>The identified instructions, which we refer to as a load-slice, are duplicated for prefetching. This duplicated load-slice is then transformed by replacing the original Figure <ref type="figure">1</ref>. Performance impact of prefetching various distances for indirect memory accesses with 256 inner loop iterations and varying work function complexity load instruction with a prefetch instruction. The prefetch instruction's address is computed by adding a constant prefetch-distance to the address of the original memory access. This allows prefetching memory blocks that will be accessed in subsequent loop iterations. We note that the technique described above relies on static code transformation, and it also depends on programmer-specified flags (e.g.,-DFETCHDIST=32) to ensure the timeliness of prefetches by tuning the prefetch-distance.</p><p>Next, we show that static approaches do not generalize well across a large variety of application use cases. Moreover, we also demonstrate that static techniques are unable to realize a significant amount of the performance benefits offered by the optimal software prefetching mechanism that prefetches memory blocks with near-perfect accuracy, i.e., by covering all potential data cache misses in a timely manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prefetching Timeliness</head><p>For the first experiment, we configure the microbenchmark to utilize a loop trip count of ùêº ùëÅ ùëÅ ùê∏ùëÖ = 256. We choose three different work functions with low, medium, and high complexity. Figure <ref type="figure">1</ref> shows the speedup obtained by injecting prefetches for different prefetch-distance. There are a number of interesting observations. First, the potential performance gains delivered by prefetching are significant, exceeding 200% for a prefetch-distance of 16 and a medium complexity work function. Second, choosing the optimal prefetching distance has a significant performance impact. Third, the optimal prefetch-distance varies between configurations and depends on the complexity of the work function. In particular, for the low, medium, and high complexity work functions, the optimal prefetch-distance is 32, 16, and 4 respectively. Existing techniques <ref type="bibr" target="#b5">[9]</ref> utilize a static prefetch-distance and hence do not provide optimal and generalized performance for different applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">PMU Counter Study</head><p>To provide additional insight, we perform a performance analysis with the tool, perf stat <ref type="bibr" target="#b39">[43,</ref><ref type="bibr" target="#b67">71]</ref>. We analyze the performance of the microbenchmark choosing a low work complexity and ùêº ùëÅ ùëÅ ùê∏ùëÖ = 256 while varying the prefetching distance between 0, 1, 64, and 1024. Table <ref type="table" target="#tab_1">1</ref> shows the instructions per cycle (IPC) performance as well as the prefetch accuracy which is defined as the number of prefetches (offcore_requests.all_data_rd-offcore_requests.demand_data_rd) divided by the number of all loads (offcore_requests.all_data_rd). As can be seen, as soon as prefetching is enabled with a prefetchdistance of 1 or 64, 70% of all demand loads are effectively prefetched, proving that automated injection passes are effective in determining the correct addresses to prefetch. However, when the distance (1024) exceeds the loop trip count, prefetches are no longer accurate, since most of them are too early prefetches. Therefore, prefetches which are generated by using a very large prefetch-distance, can be evicted from the cache before they are used while displacing other useful data.</p><p>Observation: PMU counters reveal that for a range of prefetch-distance, a significant fraction of demand loads can be correctly prefetched using automatic prefetch injection. Insight: Static prefetch injection is sufficient to enable high prefetching coverage and accuracy.</p><p>Column 4 of Table <ref type="table" target="#tab_1">1</ref> shows the late prefetch ratio which is defined as the number of demand loads hitting a prefetch residing in the fill buffer (FB) of the processor (LOAD_HIT_PRE.SW_PF). Processors utilize fill buffers or miss status hold registers to coalesce multiple loads to the same cache line into a single memory access. The occurrence of this event means that a demand load was correctly prefetched, however, that the prefetch was issued too late. As the prefetched cache line has not yet been retrieved from memory, the demand load needs to stall until the prefetch has been completed.</p><p>Observation: For small prefetching distances, processors exhibit many events where a demand load hits a corresponding prefetch in the fill buffer. Insight: Static prefetching techniques are unable to consistently achieve timely prefetches, thus dynamic profiling information is required. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Prefetch Injection Site</head><p>Table <ref type="table" target="#tab_1">1</ref> showed that for a too-large prefetch-distance, prefetches are no longer accurate (nor timely) and hence may lead to a performance regression. Figure <ref type="figure" target="#fig_0">2</ref> shows the prefetching performance for the microbenchmark using low work function complexity while varying the loop trip count between 4, 16, and 64. It can be seen that for a loop trip count of 4, prefetching is no longer beneficial while for trip counts of 16 and 64 improvements are moderate and furthermore require a small prefetch-distance. Existing static prefetch injection techniques offer no flexibility besides injecting prefetches in the inner loop as they possess no information about the optimal prefetch injection site. To enable significant prefetching performance gains in cases where the loop trip count is small, a prefetching mechanism should also be able to evaluate additional prefetch injection sites such as the outer loop based on dynamic profiling information.</p><p>Observation: Choosing the prefetch injection site statically for example by always injecting prefetches into the inner loop does not provide significant performance gains for loops with low trip counts. Insight: Dynamic techniques are required to determine the optimal injection site of a prefetch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Static Techniques to Infer Execution Time</head><p>Static compile-time techniques can, in principle, predict the execution time of input-independent loops by counting the number of instructions and by leveraging cost models <ref type="bibr" target="#b23">[27,</ref><ref type="bibr" target="#b40">44,</ref><ref type="bibr" target="#b119">123]</ref> to infer the cost of each instruction. However, due to the complexity of contemporary microprocessors, cost models show limited accuracy <ref type="bibr" target="#b32">[36]</ref>. The state-of-the-art static techniques <ref type="bibr" target="#b0">[4,</ref><ref type="bibr" target="#b25">29,</ref><ref type="bibr" target="#b54">58,</ref><ref type="bibr" target="#b69">73,</ref><ref type="bibr" target="#b70">74,</ref><ref type="bibr" target="#b83">87,</ref><ref type="bibr" target="#b99">103]</ref> incur 9-36% average errors while predicting the execution time of basic blocks even under the assumption that all memory access times are constant and well-known <ref type="bibr" target="#b32">[36]</ref>. Moreover, these cost models have to be well maintained and frequently updated when the hardware changes <ref type="bibr" target="#b54">[58]</ref>. For instance, as modern superscalar processors are deeply pipelined executing multiple instructions simultaneously, the cycle-per-instruction (CPI) of a particular instruction is not fixed, but instead, it depends on its data and control flow dependencies. Furthermore, the average memory access time of a load is significantly affected by its locality and cache-ability which is generally unknown at compile time. Lastly, in the presence of input-dependent code, static techniques cannot predict the execution time. For these reasons, we propose a dynamic profile-guided technique to predict the execution time of loops enabling us to infer the elapsed time between two instances of the same load instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Design of APT-GET</head><p>Our analysis shows that the prefetch timeliness, both in terms of the prefetch-distance and the prefetch injection site, significantly affects the effectiveness of automated software prefetching mechanisms in achieving predictable highperformance gains across different applications. While a complete design space exploration can identify the best configuration, performing such an exhaustive search over all prefetch-distances and prefetch injection sites is infeasible in large-scale real-world software systems. Hence, we propose APT-GET , a novel profile-guided mechanism to identify the optimal prefetch-distance and the optimal prefetch injection site using only a single profiling run to capture the dynamic behavior of an application. Specifically, APT-GET employs efficient hardware support (Intel's LBR <ref type="bibr" target="#b66">[70]</ref>) to collect the application profile with negligible overhead ( ¬ß3.1). As widely-used profile-guided code layout optimization techniques <ref type="bibr" target="#b27">[31,</ref><ref type="bibr" target="#b48">52,</ref><ref type="bibr" target="#b62">66,</ref><ref type="bibr" target="#b92">96,</ref><ref type="bibr" target="#b93">97]</ref> already collect similar program execution profiles in production, APT-GET can be seamlessly integrated into existing systems. Based on this profile, APT-GET applies a novel analytical technique to find both the optimal prefetch-distance ( ¬ß3.2) and the optimal prefetch injection site ( ¬ß3.3). Without LBR, APT-GET lacks the dynamic information needed to improve prefetch timeliness. While it may be possible to estimate loop execution times with software techniques <ref type="bibr" target="#b82">[86]</ref>, LBR provides the most accurate results with the lowest overheads. Apart from Intel processors, AMD processors support branch sampling <ref type="bibr" target="#b43">[47]</ref> and future ARM processors will implement the Branch Record Buffer Extension (BRBE) <ref type="bibr" target="#b95">[99]</ref>, which can be used as an alternative to LBR. Finally, APT-GET revises existing compiler-based prefetching mechanisms to incorporate these optimal prefetch configurations to ensure the timeliness of prefetch operations ( ¬ß3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Profile Collection</head><p>Enabling timely prefetches requires a detailed characterization of the corresponding demand loads. This characterization includes the hit/miss ratio and the performance impact of the load, the trip count of the loop containing the load instruction, and the execution time of a single loop For instance, as shown in the analysis section ( ¬ß2), we need to determine the elapsed time between two instances of the same load instruction for computing the optimal prefetch-distance. The loop latency (execution time) is hereby defined by two components: the instruction component (IC) and the memory component (MC). The instruction component includes all (non-load) instructions implementing the loop. The latency of this component, IC_latency depends on the number of instructions and their data and control flow dependencies. However, frequently in practice, IC_latency does not differ significantly across different loop iterations. Moreover, this latency is constant even in the presence of optimal prefetching. The memory component, on the other hand, includes the loads causing frequent cache misses. Therefore, the latency of this component, MC_latency is determined by the level within the memory hierarchy that serves the load. As the L1 cache access latency (4 cycles) differs significantly from the DRAM access latency (hundreds of cycles), MC_latency is highly variable. Our prefetching technique captures this variance to identify the optimal prefetchdistance. To determine the optimal prefetch-distance, we need to learn the latency of both the instruction and memory component, so that:</p><formula xml:id="formula_0">ùêºùê∂_ùëôùëéùë°ùëíùëõùëêùë¶ √ó ùëùùëüùëí ùëì ùëíùë°ùëê‚Ñé_ùëëùëñùë†ùë°ùëéùëõùëêùëí = ùëÄùê∂_ùëôùëéùë°ùëíùëõùëêùë¶ (1)</formula><p>If Equation (1) holds then the MC_latency can be hidden with prefetching. To separate the IC_latency from the MC_latency, it is insufficient to measure the average time between two instances of a load. Instead, we need to predict the execution time of a loop in the absence of cache misses deriving the optimal prefetch distance.</p><p>To enable the load characterization outlined above, we leverage the Last Branch Record (LBR) feature offered by Intel CPUs <ref type="bibr" target="#b66">[70]</ref>. The LBR is a buffer that holds several key pieces of information about the last 32 basic blocks (BBL) executed by the CPU. A basic block is defined as a sequence of consecutive instructions that was terminated by a taken branch. Hence, when APT-GET collects hardware performance event samples with the LBR feature enabled, the collected profile includes LBR entries for the last 32 taken branches immediately preceding the instruction that triggers the performance event. We show an example schematic view of the multiple LBR entries in Figure <ref type="figure" target="#fig_1">3</ref>.</p><p>As we show in Figure <ref type="figure" target="#fig_1">3</ref>, each LBR entry contains the program counter (PC) of a taken branch, the target of the branch, and the CPU cycle when the branch was executed. By finding two instances of the same branch PC implementing a loop and subtracting their cycle counts, we can compute the execution time of a loop iteration. As a specific demand load instruction exists exactly once for a single loop iteration, this enables us to compute the elapsed time between two instances of the same load instruction. In the case of a nested loop, if we know the branch PC corresponding to the outer loop and the branch PC corresponding to the inner loop, we can count the number of inner branch PCs within two outer branch PCs in the LBR to compute the number of inner loop iterations. For instance, in Figure <ref type="figure" target="#fig_1">3</ref>, the average loop execution time of I is 2.2 and the average loop trip count of I is 2.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Determining the Optimal Prefetch Distance</head><p>As we describe in ¬ß3.1, measuring the average loop iteration time is insufficient for determining the optimal prefetchdistance. In particular, we need to predict the loop's instruction component (IC) execution time under the assumption that memory blocks corresponding to all memory accesses have already been prefetched and that they can be served with low latency. During the profiling step of our technique, we have not injected any prefetches yet and hence this information is unavailable. To address this challenge, we profile the latency distribution of delinquent loads (loads that cause frequent LLC misses) <ref type="bibr" target="#b35">[39]</ref>, instead of solely measuring their average memory access time, resulting in the following application profiling technique.</p><p>First, we capture delinquent load PCs that induce frequent Last Level Cache (LLC) misses utilizing precise event-based sampling (PEBS) <ref type="bibr" target="#b67">[71,</ref><ref type="bibr" target="#b115">119]</ref>. Second, we capture LBR samples at the default frequency of once per millisecond while executing the application. Third, we search all LBR samples that contain a delinquent load PC. In particular, the load PC must be greater or equal to the start PC of a BBL and smaller than the terminating branch PC of the BBL (as provided by PC and target information of two consecutive branch entries in the LBR). Fourth, for all LBR samples that contain at least two instances of the BBL containing the delinquent load, we measure the loop execution time by subtracting the cycle counts of the two subsequent branches. Fifth, we analyze the latency distribution of the loop's execution time to predict the latency in the case that the load is served from the L1 or L2 cache.</p><p>Figure <ref type="figure" target="#fig_2">4</ref> shows a distribution plot of the execution time of a loop containing the delinquent load PC as used in the graph benchmarks evaluated in ( ¬ß4). The plot shows four peaks at around 80, 230, 400, and 650 cycles. As the execution time of non-load instructions is relatively stable across loop iterations, we posit that these peaks are caused by loads </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Finding the Optimal Prefetch Injection Site</head><p>As we demonstrate in ¬ß2.4, when loops have low trip counts and low execution time per iteration, prefetch instructions inserted in the inner loop could not provide any performance benefit. We extend APT-GET 's LBR-based analytical technique described in ¬ß3.2 to identify such inner loops and inject prefetch instructions into the outer loop instead of the inner loop. This optimization enables APT-GET to prefetch ahead and improve prefetch timeliness. To determine whether to inject prefetches in the outer or inner loop, APT-GET analyzes the recorded LBR samples and determines the average trip count of the inner loop (e.g., 2.2 in the example shown in Figure <ref type="figure" target="#fig_1">3</ref>). Then, APT-GET injects prefetch instructions into the outer loop instead of in the inner loop only if the following equation holds.</p><formula xml:id="formula_1">ùëôùëúùëúùëù_ùë°ùëüùëñùëù_ùëêùëúùë¢ùëõùë° √ó ùëò &lt; ùëùùëüùëí ùëì ùëíùë°ùëê‚Ñé_ùëëùëñùë†ùë°ùëéùëõùëêùëí<label>(2)</label></formula><p>In Equation <ref type="formula" target="#formula_1">2</ref>, ùëò represents a constant and APT-GET determines its value based on the loop characteristics. Every loop, where prefetch instructions are injected, contains a prologue and epilogue of size prefetch-distance (in iterations) in which prefetching does not occur. No prefetches are executed for the loads in the prologue and the prefetches performed in the epilogue will not match any corresponding demand load. As a result, if we want to prefetch 80% of all demand loads, the value of ùëò needs to be 5. If APT-GET determines to inject prefetches in the outer loop, the prefetch-distance will be computed on the execution latency distribution of the outer loop as described in Section 3.2. To implement prefetching in the outer loop, we extend our LLVM pass to extract the load-slice in the inner loop and replicate it into the outer loop. Furthermore, the induction variable of the outer loop which is considered a constant from the perspective of the inner loop (and the extracted load-slice), needs to be multiplied with the prefetch-distance to form the final prefetching instruction sequence. Next, we provide APT-GET 's further implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Automated Profiling Methodology</head><p>APT-GET performs a fully automated approach consisting of the following steps to generate timely software prefetch instructions. First, APT-GET utilizes perf record <ref type="bibr" target="#b39">[43,</ref><ref type="bibr" target="#b67">71]</ref> to detect frequent cache miss inducing loads and derives the start PCs of their basic blocks. Second, APT-GET captures application's LBR profiles and filters them for the PCs determined in the previous step. To compute prefetch-distance and prefetch injection site, APT-GET extracts the average loop trip count by counting the number of consecutive inner loop PCs in the LBR record. It furthermore, computes the average iteration execution time from the cycle counts in the LBR record. Therefore, APT-GET obtains the peaks in the scatter plot as they represent the execution time of the BBL when the delinquent load PC is served from a level in the memory hierarchy. For detecting the peaks inside the plot automatically, APT-GET uses find_peaks_cwt [2, 45] of scipy.signal [1], which performs a continuous wavelet transform algorithm to find the location of the peaks. The result of our automated approach is a list of delinquent load PCs with their corresponding prefetch-distance and prefetch injection site which can be consumed by the LLVM software prefetching pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">LLVM Prefetch Injection Pass</head><p>We implement a function level LLVM pass that detects indirect memory access patterns inside the IR of an application and injects prefetching kernels based on the generated list of delinquent loads. To convert a delinquent load PC to an instruction in the IR, APT-GET utilizes AutoFDO's <ref type="bibr" target="#b27">[31]</ref> capability of converting arbitrary PCs into lines of code in the IR. Algorithm 2 describes an overview of our implemented LLVM pass for software prefetching of indirect memory access patterns. During the initialization of our algorithm, Lines 3-7, it scans through every function in the module and checks whether there are samples related to functions inside the application IR or not. If it finds at least one sample, we can use the input profile to find precisely the delinquent load PC inside the IR. In this case, the algorithm sets AutoFDOMapping variable to True. If the algorithm doesn't find any sample during initialization, Lines 35-38, it performs the same static searching scheme as proposed by Ainsworth &amp; Jones <ref type="bibr" target="#b5">[9]</ref>  to capture all load instructions with indirect memory access patterns for generating prefetch-slices. If there exists an AutoFDO mapping for a function containing a delinquent load PC (line 14-35), the algorithm traverses the BBLs inside the function to capture the delinquent load PCs identified inside the LBR sample. In Line 18, the FoundHints function compares the debugging location of each load instruction inside the BBLs with the profiling information in the sample to find the precise delinquent Load PC's location. When a delinquent load PC is found inside the IR the algorithm reads the sample to capture the corresponding calculated prefetch-distance from LBR analysis for the load instruction (lines 18-20).</p><p>In Lines 22-24, the algorithm calls the SearchAlgorithm function, which is a load slice search function similar to Depth-First Search (DFS) algorithm proposed by Ainsworth &amp; Jones <ref type="bibr" target="#b5">[9]</ref>. This function extracts the load slices of the load instructions by performing a backward data dependency analysis while tracking all instructions that form the load slice. The search terminates when all loop induction variables (PHINode), that the load is dependent have been found. We extend Ainsworth &amp; Jones's algorithm by continuing to search for backward-dependent instructions after the first induction variable is found for the purpose of enabling outer-loop prefetch injection. In particular, we explore the previous BBL and if the two BBLs implement a nested loop, we determine the induction variable of the outer loop by extending the prefetch slice to contain both induction variables enabling injection into both the inner and/or outer loop.</p><p>After capturing load slices determined by the PHINodes of delinquent load instructions (lines <ref type="bibr" target="#b21">[25]</ref><ref type="bibr" target="#b22">[26]</ref><ref type="bibr" target="#b23">[27]</ref><ref type="bibr" target="#b24">[28]</ref><ref type="bibr" target="#b25">[29]</ref><ref type="bibr" target="#b26">[30]</ref><ref type="bibr" target="#b27">[31]</ref><ref type="bibr" target="#b28">[32]</ref><ref type="bibr" target="#b29">[33]</ref><ref type="bibr" target="#b30">[34]</ref><ref type="bibr" target="#b31">[35]</ref>, the algorithm executes the corresponding prefetching function to inject the prefetch-slice into the IR of the application. If the number of captured PHINodes for a delinquent load PC is more than one, it means that the load is located inside a nested loop and algorithm calls the InjectPrefechesMorePhis function, otherwise, the algorithm calls the InjectPrefechesOnePhi function for inserting the slice. For generating the prefetch slice, the captured load slice is replicated while replacing the delinquent load instruction with a prefetch instruction and adding the calculated prefetch-distance from LBR analysis to the BBL induction variable.</p><p>Listing 3 illustrates the simplified IR representation of the nested loop with an indirect memory access pattern as shown in the microbenchmark code 1.The indirect pattern load is located in line 13 and is dependent on the instructions in lines 7-12 as well as on the inner loop induction variable %iv2 in line 6. It is also dependent on the outer loop induction variable %iv1 in line 2 and the instruction in line3. For this code, we can inject the prefetch instructions inside the inner loop for the indirect pattern load by replicating lines 2-7. In this case the outer loop induction variable %iv1 is considered a constant for all executions of the inner loop. The highlighted lines, line 13-21, in Listing 4 illustrates the IR representation of the microbenchmark 1 after injecting the prefetch slice for the indirect pattern load inside the inner loop. In line 9, the calculated prefetch-distance value by APT-GET is added to the inner loop induction variable, %iv2, to generate timely prefetch instructions. If we want to inject prefetches into the outer loop, %iv1 is no longer considered a constant, hence, we need to extend our prefetch-slice by following dependencies across the inner BBL including %iv1. Note that, from the outer loop perspective, the inner loop induction variable %iv2 is unknown (it depends on the inner loop iteration). As a result, we assign %iv2 to 0, line 6, so that only the first inner loop iteration is prefetched in the outer loop. To improve coverage, we can emit multiple prefetches where %iv2 is swept from 0 to the average number of inner loop iterations as observed in ¬ß2 using LBR-based profile.</p><p>To further generalize our technique, our pass introduces the capability for detecting indirect pattern loads that have non-canonical-type induction variables. In particular, our pass supports arbitrary computation on the loop induction variable such as i*=2 instead of just allowing i++. We also Listing 4. The simplified LLVM's IR-level representation of the microbenchmark 1 after injecting the prefetch slice inside the inner loop add support for multiple and complex exit conditions to break out of a loop such as for(i:K){if(cond(i)) break;}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Limitations of APT-GET</head><p>Our proposed technique has a number of limitations. However, none of these limitations has shown to be a significant issue in practice. The first two limitations are due to the limited size of the LBR containing only 32 entries on our system. In the case of a two-nested loop, where the inner loop containing the delinquent load has a high loop trip count, LBR samples will only contain the branch PC implementing the inner loop. As a result, we cannot measure the outer loop latency. This is not a real problem because with high loop trip counts we can always prefetch in the inner loop and do not have to revert to outer loop prefetch injection.</p><p>Another potential scenario limiting APT-GET 's effectiveness can occur when the inner loop containing the delinquent load also contain 32 other taken branches. Consequently, LBR samples contain the inner loop branch PC only once prohibiting latency measurements. In this case, the loop execution time is generally high enough so that a default prefetch-distance of one is sufficient.</p><p>Lastly, if the execution time of a loop is input datadependent, we need to re-profile the application for each input. This means that in contrast to static compile-time techniques, APT-GET also allows optimizing input-dependent code. We believe re-profiling is feasible in this case, especially in the data center setting where profile-guided optimization techniques have been most successful <ref type="bibr">[15, 64-67, 79, 96, 112]</ref> and where applications are compiled and released at high cadence. Furthermore, AutoFDO <ref type="bibr" target="#b27">[31]</ref> has shown that even stale profiles enable PGO techniques to provide good performance as data inputs tend to change slowly over the course of multiple weeks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In this section, we describe the software infrastructure, test setups, real world benchmarks and data sets that we use to evaluate APT-GET .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>The techniques described in Section 3 are implemented as a function level LLVM pass <ref type="bibr" target="#b68">[72]</ref> that is available at <ref type="bibr" target="#b1">[5]</ref>. We utilize the Clang compiler, version 10.0, on Ubuntu Linux 20.04 with kernel version 5.4 to apply the pass on the IR representation of the applications. We enable the highest compiler-level optimizations (-O3). We use (-gmlt) and (-fdebug-info-for-profiling) to emit debugging information for identifying delinquent load PCs inside the pass [3]. We compare APT-GET against a no-prefetching baseline and against the static prefetch injection technique Ainsworth &amp; Jones <ref type="bibr" target="#b5">[9]</ref>. We execute each experiment three times and utilize perf stat <ref type="bibr" target="#b39">[43,</ref><ref type="bibr" target="#b67">71]</ref> to obtain the results presented in this section. The machine configuration of the evaluated system is described in Table <ref type="table" target="#tab_3">2</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Methodology</head><p>Our proposed technique is generic and automated; hence it can in principle be applied to any application that is performance limited by LLC cache misses. For evaluating APT-GET , we examine ten real-world, memory-bound applications as described in Table <ref type="table" target="#tab_4">3</ref>. In accordance with prior work <ref type="bibr" target="#b5">[9]</ref>, applications were selected for exhibiting indirect memory accesses located inside loops (including nested loops) as hardware prefetchers do not handle those. Figure <ref type="figure" target="#fig_4">5</ref> shows how much the selected applications are bounded by the L3 cache and DRAM. In particular, we evaluated graph full programs including breadth-first search (BFS), depth-first search (DFS), pageRank (PR), betweenness centrality (BC), and single-source shortest path algorithm (SSSP) from the CRONO benchmark suite <ref type="bibr" target="#b3">[7]</ref>. Traversing graph data structures frequently requires executing indirect memory access patterns inside a nested loop where the loop trip counts depends on the number of graph vertices or edges. For running these applications, we use both real-world graph data-sets from the Stanford Network Analysis Platform (SNAP) <ref type="bibr" target="#b73">[77]</ref> as well as synthetic graphs that exhibit  <ref type="table" target="#tab_5">4</ref>.</p><p>We evaluate additional applications including Integer Sort (IS) and Conjugate Gradient (CG) applications from the NAS parallel benchmark suite <ref type="bibr" target="#b12">[16]</ref>. The integer sort algorithm induces indirect memory access patterns during the bucket sorting process of random integers inside an array. For evaluating IS we set the number of the iterations to 25 using two different problem sizes, Class B and Class C. The CG benchmark executes sparse matrix multiplications generating irregular indirect memory accesses for traversing vectors in the compressed sparse row (CSR) format. We also evaluate the RandomAccess (randAccess) benchmark from HPC Challenge Benchmark Suite <ref type="bibr" target="#b81">[85]</ref> which randomly updates elements of a large table to compute the giga updates per second (GUPS) memory system performance. We utilize a table size of 1GiB for the RandomAccess benchmark suite.</p><p>We also use two different forms of the Hash join benchmark <ref type="bibr" target="#b15">[19]</ref>, Hash Join 2EPB (HJ2) and Hash Join 8EPB (HJ8), to evaluate the performance of APT-GET . Both Hash Join benchmarks implement hashing to lookup target values based on some key distribution, where HJ8 utilizes hash buckets of 8 elements while HJ2 just utilizes 2 elements per bucket. The size of hash table is 970 MiB and we run both of these benchmarks with two hasing algorithms (NPO and NPO_st). The Graph500 benchmark <ref type="bibr" target="#b88">[92]</ref> executes breadth-first search on an undirected graph that has an average degree of 16. We utilize a scale factor of 22 and an edge-factor of 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Improvement</head><p>Figure <ref type="figure" target="#fig_5">6</ref> shows the execution time speedup of APT-GET and Ainsworth &amp; Jones <ref type="bibr" target="#b5">[9]</ref> across all benchmarks over the no-prefetching baseline. Ainsworth &amp; Jones utilizes a static prefetch-distance and, furthermore, is limited to injecting prefetches into the inner loop. As can be seen, APT-GET provides a maximum speedup of 1.98√ó for HJ8 and BFS and an average speedup of 1.30√ó over the baseline while Ainsworth &amp; Jones only provides gains for few applications resulting in an average speedup of 1.04√ó. We calculate the average speedup values by using the geometric mean. Except for the CG benchmark, APT-GET improves performance for all applications whereas Ainsworth &amp; Jones shows a performance regression for BC. This shows that injecting prefetches with non-optimal prefetch-distance and prefetch injection site can reduce performance due to the injected instruction overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Cache Miss Reduction</head><p>In Figure <ref type="figure" target="#fig_6">7</ref> we show the cache miss reduction enabled by APT-GET measured in misses per kilo instructions (MPKI). We measure misses utilizing the offcore_requests.demand_data_rd PMU counter and compare against the non-prefetching baseline. Note that demand loads that hit a prefetch to the same address in the fill buffer are counted as a cache miss. In average, APT-GET reduces cache misses by 65.4%, while Ainsworth &amp; Jones reduces cache misses by 48.3% and MPKI improvements are most significant where APT-GET also provides the highest execution time benefits. We leave analyzing the interplay of hardware and software prefetches for future work. While for BC with 50K nodes and degree of 8, Ainsworth &amp; Jones reduces cache misses over APT-GET it also injects significantly more instructions as we will show in Figure <ref type="figure" target="#fig_10">11</ref> explaining the higher execution time improvement of APT-GET . To provide further insights, in the following sections, we evaluate the individual techniques of APT-GET .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Effectiveness of the LBR Profiling</head><p>We first evaluate the effectiveness of our LBR profiling technique to determine the optimal prefetch-distance. Therefore, we execute all benchmarks with the following 8 different prefetch distances ùê∑ = {1, 2, 4, 8, 16, 32, 64, 128}. We then take the prefetch-distance that performed best and compare the achieved performance against APT-GET . As shown in Figure <ref type="figure" target="#fig_7">8</ref>, the proposed LBR approach is able to determine a near optimal prefetch-distance for all applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Effectiveness of the Prefetch Distance</head><p>Optimization In figure <ref type="figure" target="#fig_8">9</ref>, we evaluate the effectiveness of our proposed LBR sampling technique against using a static prefetch-distance approach. We compare the speedup results for APT-GET against 3 different static prefetch-distance values of 4, 16, 64,  and the calculated prefetch-distance value from LBR samples for each workload. As we can see, for most of the applications APT-GET achieves a higher performance gain by using the calculated prefetch-distance from LBR samples than utilizing a static prefetch-distance of 4, 16, 64, highlighting the efficacy of our approach. While a static prefetch-distance of 64 also performs well it is outperformed by APT-GET by 1.06√ó for RandomAccess and by 1.09√ó for HJ2-NPO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Effectiveness of the Prefetch Injection Site</head><p>Optimization Figure <ref type="figure" target="#fig_9">10</ref> shows the effect of optimizing the prefetch injection site for all applications. In this experiment, we measure the speedup of APT-GET by prefetching either in the outer or the inner loop for all applications that contain nested loops. The goal of these experiments is to evaluate the effectiveness of our proposed approach for detecting the appropriate prefetch injection site. For all the workloads except for DFS, injecting prefetch instructions inside the inner loop decreases the performance over the non-prefetching baseline. Therefore, it is crucial to enable outer-loop prefetching but also to detect the appropriate prefetch injection site for each prefetch individually. We can see that based on the number of edges and vertices the input graph contains, the achieved performance gain from inner or outer loop prefetching can be significantly different. For example, if we compare the achieved speedup for the BFS application by considering two different inputs, loc-Brightkite with 58K nodes and an average edge degree of 3, as well as graph with 80K nodes and an average edge degree of 8, we can see that the achieved speedup gain from outer loop prefetching differs significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Instruction Overhead</head><p>Injecting prefetch slices introduces overheads in terms of additional instructions that need to be executed by the  While for most applications the instruction overhead is negligible, for IS and RandomAccess, it is significant which limits the performance gains provided for these applications. We believe there exist future research opportunities in considering the instruction overhead for conditional prefetch slice injection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Inputs for profiling and testing</head><p>We use different realistic data sets (such as graphs) for evaluating the input sensitivity of APT-GET . In particular, Figure <ref type="figure" target="#fig_0">12</ref> shows the performance of training and evaluating APT-GET on the same input (TRAIN-DATA) vs. evaluating on a different input (TEST-DATA). The obtained results indicate that there are no significant performance differences between the two inputs showing that APT-GET can generalize across inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Profiling overhead</head><p>In Google's data centers, all applications are already continuously profiled <ref type="bibr" target="#b11">[15,</ref><ref type="bibr" target="#b98">102]</ref> and recompiled before deployment. Our technique does not introduce additional overheads here. Our approach only requires a single profiling run. The average total overhead is less than 15-20 seconds. Note that optimization is performed only once in data centers while the application is executed on 1000s of nodes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Prefetching is a well-studied and yet widely open area that spans many types of access patterns and implementations. We classify prior works in three categories. Software prefetching. Traditional software prefetching <ref type="bibr" target="#b22">[26]</ref> techniques utilize compilers to perform static code analysis to generate fixed prefetch targets <ref type="bibr" target="#b7">[11,</ref><ref type="bibr" target="#b31">35,</ref><ref type="bibr" target="#b49">53,</ref><ref type="bibr" target="#b107">111]</ref>. These approaches are limited by lacking knowledge about which memory accesses actually cause performance degradation and which prefetch distances should be used. Furthermore, they are limited by practical constraints such as the ability to only detect simple patterns such as Singly-Nested Loop Nests <ref type="bibr" target="#b116">[120]</ref> or strides <ref type="bibr" target="#b59">[63,</ref><ref type="bibr" target="#b87">91,</ref><ref type="bibr" target="#b120">124]</ref>. Other approaches can analyze more complex behaviors like linked list traversals and insert jump pointers into source code at compile time <ref type="bibr" target="#b34">[38,</ref><ref type="bibr" target="#b79">83,</ref><ref type="bibr" target="#b100">104,</ref><ref type="bibr" target="#b101">105]</ref>. However, these require source code modification and result in additional run-time storage costs whenever a pointer is inserted into a data structure. In contrast, APT-GET does not rely on source code modification, it can handle arbitrarily complex indirect and direct access patterns, and uses profiling information to identify performancecritical loads and tune prefetch distances to improve prefetch timeliness.</p><p>Improving upon static methods, some prior works utilize dynamic profiling to better identify prefetch candidates <ref type="bibr" target="#b77">[81,</ref><ref type="bibr" target="#b80">84]</ref>, but they don't utilize profiling information to improve timeliness, or introduce overheads by requiring to executed a separate prefetching thread in parallel to the workload <ref type="bibr" target="#b127">[131]</ref>.</p><p>Hardware prefetching. Stream prefetchers <ref type="bibr" target="#b52">[56,</ref><ref type="bibr" target="#b102">106]</ref> and pattern-based prefetchers <ref type="bibr" target="#b38">[42,</ref><ref type="bibr" target="#b55">59,</ref><ref type="bibr" target="#b64">68,</ref><ref type="bibr" target="#b65">69,</ref><ref type="bibr" target="#b84">88,</ref><ref type="bibr" target="#b91">95,</ref><ref type="bibr" target="#b96">100,</ref><ref type="bibr" target="#b103">107,</ref><ref type="bibr" target="#b105">109]</ref> can be implemented with low to moderate hardware complexity and are capable of prefetching strides and other simple access patterns. Spatial <ref type="bibr" target="#b14">[18,</ref><ref type="bibr" target="#b17">21,</ref><ref type="bibr" target="#b47">51,</ref><ref type="bibr" target="#b106">110]</ref> and temporal <ref type="bibr" target="#b13">[17,</ref><ref type="bibr" target="#b24">28,</ref><ref type="bibr" target="#b51">55,</ref><ref type="bibr" target="#b56">60,</ref><ref type="bibr" target="#b113">117]</ref> prefetchers can learn and replay more Figure <ref type="figure" target="#fig_0">12</ref>. Execution time speedup provided by APT-GET over the non-prefetching baseline for different inputs as train/test data: APT-GET achieves 1.36√ó average speedup on average for test data sets compared to the 1.39√ó average speedup obtained for train data sets complex memory access patterns, but they require costly onchip storage and rely upon highly-recurrent access patterns. None of these prefetchers is well-suited for large instruction footprint applications exhibiting many irregular and indirect memory patterns such as pointer-based traversals.</p><p>Several hardware mechanisms have been proposed to prefetch complex memory access patterns that are based on the data and control flow of an application <ref type="bibr" target="#b8">[12,</ref><ref type="bibr" target="#b35">39,</ref><ref type="bibr" target="#b42">46,</ref><ref type="bibr" target="#b50">54,</ref><ref type="bibr" target="#b71">75,</ref><ref type="bibr" target="#b78">82,</ref><ref type="bibr" target="#b89">93,</ref><ref type="bibr" target="#b90">94,</ref><ref type="bibr" target="#b97">101,</ref><ref type="bibr" target="#b128">132]</ref>. While general-purpose in nature, they require fast and complex hardware resources such as helper threads to run ahead of the application and prefetch upcoming memory accesses. Unlike APT-GET , these techniques cannot easily filter relevant address calculations from the main application and their high cost and complexity is often better spent on additional CPU cores.</p><p>Hybrid hardware-software prefetching. Hybrid hardware-software prefetching mechanisms <ref type="bibr" target="#b6">[10,</ref><ref type="bibr" target="#b16">20,</ref><ref type="bibr" target="#b62">66,</ref><ref type="bibr" target="#b110">114,</ref><ref type="bibr" target="#b125">129]</ref> attempts to combine the best of both worlds while also addressing the limitations of hardware-only and software-only mechanisms. However, these techniques require both hardware prefetching support and software programming model, neither of which exists in today's processor. In contrast, APT-GET employs hardware and software interfaces already available in today's processors, identifies the key limitation of software-managed prefetching in terms of prefetch timeliness, and proposes a profile-guided low-overhead mechanism to ensure the timeliness. Hence, APT-GET can be readily be employed on existing processors to optimize the performance of real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose a novel automated prefetch injection technique for reducing stall cycles in memory latency-bound programs. Our approach provides performance gains of up to 1.98√ó and 1.30√ó in average over state-of-the-art mechanisms. To motivate our technique, we first study prior software-based prefetching mechanisms for indirect memory access patterns that cannot be handled by existing hardware prefetchers. This analysis reveals that, while existing techniques provide high accuracy and coverage, due to their static nature, they are unable to generate timely prefetches. To address this challenge, we propose a profile-guided optimization technique utilizing the last branch record capability of contemporary microprocessors. Our approach, implemented as an LLVM compiler pass, enables a detailed characterization of memory latency-bound loops, enabling timely prefetching of the performance limiting loads. We believe that this work can establish dynamic prefetch injection as a generic, efficient, low-overhead compiler technique.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Performance impact of prefetch-distance for indirect memory access kernel with low work function complexity and varying inner loop trip count</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Schematic view of the Intel CPU's Last Branch Record (LBR) highlighting the outer loop branches in blue, the inner loop branches in orange and the cycle times of each branch in green</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Distribution of a loop's execution time containing a delinquent load [39] in terms of CPU cycles measured using LBR samples</figDesc><graphic url="image-28.png" coords="6,327.56,72.00,220.84,176.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>inbounds i32, i32* %T, i64 %6 13 %8 = load i32, i32* %7 14 [....] Listing 3. The simplified LLVM's IR-level representation of the microbenchmark 1 before injecting the prefetch slice 1 for.body1: 2 %iv1 = phi i64 3 %1 = getelementptr inbounds i32, i32* %BO, i64 %iv1 4 [....] 5 for.body2: ; preds = %for.body1 6 %iv2 = phi i64 7 %2 = load i32, i32* %1 8 %3 = getelementptr inbounds i32, i32* %BI, i64 %v2 9 %4 = load i32, i32* %3 10 %5 = add i32 %2, %4 11 %6 = sext i32 %5 to i64 12 %7 = getelementptr inbounds i32, i32* %T, i64 %6 13 %9 = add i64 %iv2, prefetch_distance 14 %10 = icmp slt i64 %INNER, %9 15 %11 = select %10, i64 %INNER, i64 %9 16 %12 = getelementptr inbounds i32, i32* %BI, i64 %11 17 %13 = load i32, i32* %12 18 %14 = add i32 %2, %13 19 %15 = sext i32 %14 to i64 20 %16 = getelementptr inbounds i32, i32* %T, i64 %15 21 %17 = bitcast i32* %16 to i8* 22 call void @llvm.prefetch.p0i8(i8* %17, i32 0, i32 3, i32 1) 23 %8 = load i32, i32* %7 24 [....]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The percentage of L3/DRAM stalls is obtained for each application's non-prefetching baseline. On average, the performance of selected applications is 49.37% bounded by the memory system.</figDesc><graphic url="image-29.png" coords="10,63.60,72.00,220.84,182.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Execution time speedup provided by APT-GET over the non-prefetching baseline: APT-GET achieves 1.30√ó average speedup on average, compared to the 1.04√ó speedup provided by the state of the art (Ainsworth &amp; Jones).</figDesc><graphic url="image-30.png" coords="11,74.16,72.00,463.69,160.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. APT-GET 's LLC MPKI, misses per 1000-instructions, reduction over the non-prefetching baseline (lower is better): on average, APT-GET provides 1.35√ó greater MPKI reduction than the state of the art (Ainsworth &amp; Jones).</figDesc><graphic url="image-31.png" coords="11,74.16,279.97,463.67,159.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure8. Speedup of prefetch-distance from LBR sampling technique and optimal prefetch-distance over non-prefetching baseline: LBR sampling technique achieves 1.30√ó overall speedup in average, compared to 1.32√ó speedup of optimal prefetchdistance, over non-prefetching baseline.</figDesc><graphic url="image-32.png" coords="12,74.16,72.00,463.69,160.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Speedup for different static offset values and LBR over non-prefetching baseline: prefetch-distance of 4, 16, 64, and LBR sampling technique achieve 1.16√ó, 1.26√ó, 1.28√ó, and 1.30√ó speedup in average over non-prefetching baseline, respectively.</figDesc><graphic url="image-33.png" coords="12,74.16,291.93,463.69,160.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Figure10. Speedup of injecting prefetches inside the outer or inner loops over non-prefetching baseline: For most of the applications, injecting prefeches inside the outer loop achieves 1.20√ó overall speedup in average, while injecting prefetches inside the inner loop improves speedup for DFS up to 1.11√ó over non-prefethcing baseline.</figDesc><graphic url="image-34.png" coords="13,74.16,72.00,463.69,160.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. The overhead of injected prefetching instructions over non-prefetching baseline: APT-GET increases the total number of instructions 1.14√ó in average, compared to 1.19√ó in average of Ainsworth &amp; Jones, over non-prefetching baseline.</figDesc><graphic url="image-35.png" coords="13,74.16,291.93,463.69,160.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-36.png" coords="14,74.16,72.00,463.68,185.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Prefetch accuracy and timeliness depending on the prefetch-distance</figDesc><table><row><cell>Prefetch</cell><cell cols="3">IPC Prefetch Accuracy Late Prefetch</cell></row><row><cell>None</cell><cell>0.33</cell><cell>0%</cell><cell>0%</cell></row><row><cell>Dist-1</cell><cell>0.42</cell><cell>72%</cell><cell>95%</cell></row><row><cell>Dist-64</cell><cell>0.73</cell><cell>70%</cell><cell>1%</cell></row><row><cell cols="2">Dist-1024 0.29</cell><cell>3%</cell><cell>0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>to traverse through all BBLs inside each function</figDesc><table><row><cell cols="2">Algorithm 2. An overview of proposed profile-guided</cell></row><row><cell cols="2">LLVM pass for software prefetching</cell></row><row><cell>1</cell><cell>// REQUIRE input profiling file</cell></row><row><cell>2</cell><cell>bool AutoFDOMapping;</cell></row><row><cell>3</cell><cell>doInitialization(Module &amp;M){</cell></row><row><cell>4</cell><cell>for (F: M):</cell></row><row><cell>5</cell><cell>if(SamplesFound):</cell></row><row><cell>6</cell><cell>AutoFDOMapping=true;</cell></row><row><cell>7</cell><cell>}</cell></row><row><cell>8</cell><cell>runOnFunction(Function &amp;F) {</cell></row><row><cell>9</cell><cell>modified = false;</cell></row><row><cell>10</cell><cell>//vectors to keep candidate loads and their</cell></row><row><cell>11</cell><cell>//prefetch-distance for emitting prefetches</cell></row><row><cell>12</cell><cell>SmallVector&lt;Instruction*,30&gt; prefetches;</cell></row><row><cell>13</cell><cell>SmallVector&lt;Instruction*,30&gt; prefetchDists;</cell></row><row><cell>14</cell><cell>if(AutoFDOMapping):</cell></row><row><cell>15</cell><cell>//Map the PC to the correct load instruction</cell></row><row><cell>16</cell><cell>//inside the IR</cell></row><row><cell>17</cell><cell>for(curLoad: BBL):</cell></row><row><cell>18</cell><cell>HintsFound =FoundHints(curLoad,SamplesFound);</cell></row><row><cell>19</cell><cell>if(HintsFound):</cell></row><row><cell>20</cell><cell>for(S: HintsFound)</cell></row><row><cell>21</cell><cell>prefechDist = S.second;</cell></row><row><cell>22</cell><cell>if(SearchAlgorithm(curLoad, SetOfPhiNodes,</cell></row><row><cell></cell><cell>SetOfPhiLoads, SetOfInstrs)):</cell></row><row><cell>23</cell><cell>prefetches.push_back(curLoad);</cell></row></table><note>24prefetchDists.push_back(prefechDist); 25 for(p: prefetches): 26 if(SetOfPhiNodes[p].size()&gt;1): 27 //The load is located inside a nested 28 //loops 29 if(InjectPrefechesMorePhis(p, prefechDists[p])): 30 modified =true; 31 else: 32 //The load is located inside a single 33 //loop 34 if(InjectPrefechesOnePhi(p, prefechDists[p])): 35 modified =true; 36 else: 37 //Search BBLs statically to emit prefetches 38 //for all indirect memory patterns 39 return modified; 40 }</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>The Machine Configuration</figDesc><table><row><cell>Component</cell><cell>Parameters</cell></row><row><cell>Core</cell><cell>Intel(R) Xeon(R) Gold 5218 CPU @2.30GHz (3.9GHz Turbo)</cell></row><row><cell>L1 I/D Cache</cell><cell>64KiB/core</cell></row><row><cell>L2 Cache</cell><cell>1MiB/core</cell></row><row><cell>LLC</cell><cell>22MiB shared</cell></row><row><cell></cell><cell>DIMM DDR4</cell></row><row><cell>Main Memory</cell><cell>capacity: 32GiB, channels: 6,</cell></row><row><cell></cell><cell>@2666MHz</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>The list of real-applications</figDesc><table><row><cell>App</cell><cell>Description</cell></row><row><cell>BFS</cell><cell>Searches a target vertex given a start node in a graph</cell></row><row><cell></cell><cell>Searches a target vertex</cell></row><row><cell>DFS</cell><cell>by performing a depth-first traversal</cell></row><row><cell></cell><cell>given a start node</cell></row><row><cell>PR</cell><cell>Computes ranking of web-pages</cell></row><row><cell></cell><cell>A measure of centrality computed by</cell></row><row><cell>BC</cell><cell>finding all the shortest paths between</cell></row><row><cell></cell><cell>all vertices</cell></row><row><cell>SSSP</cell><cell>Computes the shortest path to all vertices given a source vertex</cell></row><row><cell>IS</cell><cell>Bucket sorting of random integers</cell></row><row><cell>CG</cell><cell>sparse matrix multiplications</cell></row><row><cell>RandAcc</cell><cell>Measuring memory system performance</cell></row><row><cell>HJ2/HJ8</cell><cell>Represents a database application</cell></row><row><cell>Graph500</cell><cell>Breadth-first search on an undirected graph</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Graph data-sets properties</figDesc><table><row><cell>Data-set Name</cell><cell cols="2">#Vertices #Edges</cell></row><row><cell>web-Google (WG)</cell><cell>875,713</cell><cell>5,105,039</cell></row><row><cell>p2p-Gnutella31 (P2P)</cell><cell>62,586</cell><cell>147,892</cell></row><row><cell>roadNet-CA (CA)</cell><cell cols="2">1,965,206 2,766,607</cell></row><row><cell>roadNet-PA (PA)</cell><cell cols="2">1,088,092 1,541,898</cell></row><row><cell>loc-Brightkite (LBE)</cell><cell>58,228</cell><cell>214,078</cell></row><row><cell>web-BerkStan (WB)</cell><cell>685,230</cell><cell>7,600,595</cell></row><row><cell>web-NotreDame (WN)</cell><cell>325,729</cell><cell>1,497,134</cell></row><row><cell>web-Stanford (WS)</cell><cell>281,903</cell><cell>2,312,497</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their insightful feedback and suggestions. This work was supported by Google and NSF grants #1942754 and #2010810, and the Applications Driving Architectures (ADA) Research Center, a JUMP Center co-sponsored by SRC and DARPA. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies. We thank Anant Nori and Ahmad Yasin from Intel for their helpful discussions and feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://llvm.org/docs/CommandGuide/llvm-mca.html" />
		<title level="m">llvm-mca -LLVM Machine Code Analyzer</title>
				<imprint>
			<date type="published" when="2021-10">2021. October-2021</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://github.com/SabaJamilan/Profile-Guided-Software-Prefetching" />
		<title level="m">Profile Guided Software Prefetching</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TensorFlow: A System for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajat</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pete</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi" />
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation</title>
				<meeting><address><addrLine>Savannah, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crono: A benchmark suite for multithreaded graph algorithms executing on futuristic multicores</title>
		<author>
			<persName><forename type="first">Masab</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farrukh</forename><surname>Hijaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingchuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Symposium on Workload Characterization</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="44" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph prefetching using data structure knowledge</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Supercomputing</title>
				<meeting>the 2016 International Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Software prefetching for indirect memory accesses</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="305" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An event-triggered programmable prefetcher for irregular workloads</title>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ainsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigplan Notices</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="578" to="592" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Compilerdirected content-aware prefetching for dynamic data structures</title>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Al-Sukhni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Bratt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Connors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2003 12th International Conference on Parallel Architectures and Compilation Techniques</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data prefetching by dependence graph precomputation</title>
		<author>
			<persName><forename type="first">Murali</forename><surname>Annavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jignesh</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">S</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 28th Annual International Symposium on Computer Architecture</title>
				<meeting>28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Memory hierarchy for web search</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ho Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="643" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Classifying Memory Access Patterns for Prefetching</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
	<note>Christos Kozyrakis, and Parthasarathy Ranganathan</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">AsmDB: understanding and mitigating front-end stalls in warehousescale computers</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayana</forename><forename type="middle">Prasad</forename><surname>Nagendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoun</forename><forename type="middle">Kyu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trivikram</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
				<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="462" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rob Van Der Wijngaart, Alex Woo, and Maurice Yarrow. 1995. The NAS parallel benchmarks 2.0</title>
		<author>
			<persName><forename type="first">David</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Saphir</surname></persName>
		</author>
		<idno>NAS-95-020</idno>
		<imprint>
			<publisher>NASA Ames Research Center</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domino temporal data prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bingo spatial data prefetcher</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Bakhshalipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehran</forename><surname>Shakerinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pejman</forename><surname>Lotfi-Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Sarbazi-Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="399" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Main-memory hash joins on multi-core CPUs: Tuning to the underlying hardware</title>
		<author>
			<persName><forename type="first">Cagri</forename><surname>Balkesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Teubner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√ñzsu</forename><surname>Tamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 29th International Conference on Data Engineering (ICDE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="362" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis and optimization of the memory hierarchy for graph processing workloads</title>
		<author>
			<persName><forename type="first">Abanti</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuangchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><forename type="middle">Min</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinfeng</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="373" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dspatch: Dual spatial pattern prefetcher</title>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><surname>Subramoney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="531" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Serving mobile apps: A slice at a time</title>
		<author>
			<persName><forename type="first">Ketan</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ada</forename><surname>Gavrilovska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth EuroSys Conference</title>
				<meeting>the Fourteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rock you like a hurricane: Taming skew in large scale analytics</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Bindschaedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmina</forename><surname>Malicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Schiper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashvin</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
				<meeting>the Thirteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Google workloads for consumer devices: Mitigating data movement bottlenecks</title>
		<author>
			<persName><forename type="first">Amirali</forename><surname>Boroumand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saugata</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngsok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachata</forename><surname>Ausavarungnirun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Shiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daehyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aki</forename><surname>Kuusela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Knies</surname></persName>
		</author>
		<author>
			<persName><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="316" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Runtime object lifetime profiler for latency sensitive big data applications</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duarte</forename><surname>Patricio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos√©</forename><surname>Sim√£o</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Veiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth EuroSys Conference</title>
				<meeting>the Fourteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Software Prefetching</title>
		<author>
			<persName><forename type="first">David</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Porterfield</surname></persName>
		</author>
		<idno type="DOI">10.1145/106972.106979</idno>
		<ptr target="https://doi.org/10.1145/106972.106979" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems<address><addrLine>Santa Clara, California, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
	<note>ASPLOS IV)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compiler optimizations for improving data locality</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chau-Wen</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="252" to="262" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning i/o access patterns to improve prefetching in ssds</title>
		<author>
			<persName><forename type="first">Chandranil</forename><surname>Chakraborttii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="427" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CQA: A code quality analyzer tool at binary level</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Andres S Charif-Rubial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jos√©</forename><surname>Oseret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Noudohouenou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghislain</forename><surname>Jalby</surname></persName>
		</author>
		<author>
			<persName><surname>Lartigue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 21st International Conference on High Performance Computing (HiPC)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Generalized correlationbased hardware prefetching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">P</forename><surname>Charney</surname></persName>
		</author>
		<author>
			<persName><surname>Reeves</surname></persName>
		</author>
		<idno>EE- CEG-95-1</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications</title>
		<author>
			<persName><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Xinliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Symposium on Code Generation and Optimization</title>
				<meeting>the 2016 International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving Hash Join Performance through Prefetching</title>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Data Engineering</title>
				<meeting>the 20th International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving index performance through prefetching</title>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phillip</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="235" to="246" />
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">TVM: An automated end-to-end optimizing compiler for deep learning</title>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eddie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haichen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meghan</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Ceze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="578" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Data access microarchitectures for superscalar processors with compiler-assisted data prefetching</title>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>William Y Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pohua</forename><forename type="middle">P</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In MICRO</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="69" to="73" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">BHive: A benchmark suite and measurement framework for validating x86-64 basic block performance models</title>
		<author>
			<persName><forename type="first">Yishen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Brahmakshatriya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charith</forename><surname>Mendis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Renda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ond≈ôej</forename><surname>S·ª≥kora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on Workload Characterization (IISWC)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="167" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dynamic hot data stream prefetching for general-purpose programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Trishul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><surname>Hirzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 2002 Conference on Programming language design and implementation</title>
				<meeting>the ACM SIGPLAN 2002 Conference on Programming language design and implementation</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="199" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pointer cache assisted prefetching</title>
		<author>
			<persName><forename type="first">Jamison</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suleyman</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th annual ACM/IEEE international symposium on Microarchitecture</title>
				<meeting>the 35th annual ACM/IEEE international symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="62" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Speculative precomputation: Long-range prefetching of delinquent loads</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Jamison D Collins</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dean M Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong-Fong</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">P</forename><surname>Lavery</surname></persName>
		</author>
		<author>
			<persName><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 28th Annual International Symposium on Computer Architecture</title>
				<meeting>28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="14" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A stateless, content-directed data prefetching mechanism</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cooksey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Jourdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="279" to="290" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Coz: Finding code that counts with causal profiling</title>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Curtsinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emery</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles</title>
				<meeting>the 25th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="184" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Effectiveness of Hardware-Based Stride and Sequential Prefetching in Shared-Memory Multiprocessors</title>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Dahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Per</forename><surname>Stenstr√∂m</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">hpca</title>
				<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="68" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The new linux&apos;perf&apos;tools</title>
		<author>
			<persName><forename type="first">Arnaldo</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Slides from Linux Kongress</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A compiler cost model for speculative parallelization</title>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Cintra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Improved peak detection in mass spectrum by incorporating continuous wavelet transform-based pattern matching</title>
		<author>
			<persName><forename type="first">Pan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warren</forename><forename type="middle">A</forename><surname>Kibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">M</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2059" to="2065" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving data cache performance by pre-executing instructions under a cache miss</title>
		<author>
			<persName><forename type="first">James</forename><surname>Dundas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Mudge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Supercomputing</title>
				<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Stephane</forename><surname>Eranian</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/875869/" />
		<title level="m">Add AMD Fam19h Branch Sampling support</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A primer on hardware prefetching</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Architecture</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Make the most out of last level cache in intel processors</title>
		<author>
			<persName><forename type="first">Alireza</forename><surname>Farshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Roozbeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><forename type="middle">Q</forename><surname>Maguire</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Dejan</forename><surname>Kostiƒá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth EuroSys Conference</title>
				<meeting>the Fourteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Clearing the clouds: a study of emerging scale-out workloads on modern hardware</title>
		<author>
			<persName><forename type="first">Almutaz</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Adileh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stavros</forename><surname>Kocberber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Volos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djordje</forename><surname>Alisafaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cansu</forename><surname>Jevdjic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><forename type="middle">Daniel</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2012">2012</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spatial memory streaming with rotated patterns. 1st</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Michael Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JILP Data Prefetching Championship</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Propeller: Profile Guided Optimizing Large Scale LLVMbased Relinker</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://github.com/google/llvm-propeller" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Compiler-directed data prefetching in multiprocessors with memory hierarchies</title>
		<author>
			<persName><forename type="first">Elana</forename><forename type="middle">D</forename><surname>Edward H Gornish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">V</forename><surname>Granston</surname></persName>
		</author>
		<author>
			<persName><surname>Veidenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Supercomputing 25th Anniversary Volume</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="128" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Continuous runahead: Transparent hardware acceleration for memory intensive workloads</title>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jichuan</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02329</idno>
		<title level="m">Christos Kozyrakis, and Parthasarathy Ranganathan</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Learning memory access patterns</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Memory prefetching using adaptive stream detection</title>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society</title>
				<meeting>the 39th Annual IEEE/ACM International Symposium on Microarchitecture. IEEE Computer Society</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="397" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Stride prefetching by dynamically inspecting objects</title>
		<author>
			<persName><forename type="first">Tatsushi</forename><surname>Inagaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamiya</forename><surname>Onodera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hideaki</forename><surname>Komatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshio</forename><surname>Nakatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="269" to="277" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<ptr target="https://software.intel.com/content/www/us/en/develop/articles/intel-architecture-code-analyzer.html" />
		<title level="m">Intel Architecture Code Analyzer</title>
				<imprint>
			<publisher>Intel Corporation</publisher>
			<date type="published" when="2019-10">2019. October-2021</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Access map pattern matching for high performance data cache prefetch</title>
		<author>
			<persName><forename type="first">Yasuo</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Inaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kei</forename><surname>Hiraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction-Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2011">2011. 2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Linearizing irregular memory accesses for improved correlated prefetching</title>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 46th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="247" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers</title>
		<author>
			<persName><forename type="first">Jouppi</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Profiling a Warehouse-scale Computer</title>
		<author>
			<persName><forename type="first">Svilen</forename><surname>Kanev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Pablo</forename><surname>Darago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Parthasarathy Ranganathan</surname></persName>
		</author>
		<author>
			<persName><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><surname>Gu-Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><surname>Brooks</surname></persName>
		</author>
		<idno type="DOI">10.1145/2749469.2750392</idno>
		<ptr target="https://doi.org/10.1145/2749469.2750392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42Nd Annual International Symposium on Computer Architecture</title>
				<meeting>the 42Nd Annual International Symposium on Computer Architecture<address><addrLine>Portland, Oregon; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="158" to="169" />
		</imprint>
	</monogr>
	<note>ISCA &apos;15)</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A case for resource efficient prefetching in multicores</title>
		<author>
			<persName><forename type="first">Muneeb</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Hagersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 43rd International Conference on Parallel Processing</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Twig: Profile-Guided BTB Prefetching for Data Center Applications</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Tanvir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Niranjan K Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><forename type="middle">A</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="816" to="829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">DMon: Efficient Detection and Correction of Data Locality Problems using Selective Profiling</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barzan</forename><surname>Mozafari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th USENIX Symposium on Operating Systems Design and Implementation (OSDI</title>
				<meeting>the 15th USENIX Symposium on Operating Systems Design and Implementation (OSDI</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>USENIX Association</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">I-SPY: Context-Driven Conditional Instruction Prefetching with Coalescing</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Ripple: Profile-Guided Instruction Cache Replacement for Data Center Applications</title>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dexin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Devietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Pokam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Computer Architecture (ISCA</title>
				<meeting>the 48th International Symposium on Computer Architecture (ISCA</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>ISCA 2021</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Path confidence based lookahead prefetching</title>
		<author>
			<persName><forename type="first">Jinchun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Al Narasimha Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Kill the program counter: Reconstructing program behavior in the processor cache hierarchy</title>
		<author>
			<persName><forename type="first">Jinchun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elvira</forename><surname>Teran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">V</forename><surname>Gratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Jim√©nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="737" to="749" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">An Introduction to Last Branch Records</title>
		<author>
			<persName><forename type="first">Andi</forename><surname>Kleen</surname></persName>
		</author>
		<ptr target="https://lwn.net/Articles/680985/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">Andi</forename><surname>Kleen</surname></persName>
		</author>
		<ptr target="https://github.com/andikleen/pmu-tools" />
		<title level="m">GitHub -andikleen/pmu-tools: Intel PMU profiling tools</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">LLVM: A compilation framework for lifelong program analysis &amp; transformation</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Lattner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikram</forename><surname>Adve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Code Generation and Optimization</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004. 2004</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Laukemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Wellein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2019">2019. 2019</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>Automatic throughput and critical path analysis of x86 and ARM assembly kernels</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">performance modeling, benchmarking and simulation of high performance computer systems (PMBS)</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Laukemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Wellein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM</title>
		<imprint>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="2018">2018. 2018</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>Automated instruction stream throughput prediction for intel and amd microarchitectures</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Prefetching with helper threads for loosely coupled multiprocessor systems</title>
		<author>
			<persName><forename type="first">Jaejin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhee</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daeseob</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Solihin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1309" to="1324" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">When prefetching works, when it doesn&apos;t, and why</title>
		<author>
			<persName><forename type="first">Jaekyu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Architecture and Code Optimization (TACO)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Krevl</surname></persName>
		</author>
		<title level="m">SNAP Datasets: Stanford large network dataset collection</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Competitive prefetching for concurrent sequential I/O</title>
		<author>
			<persName><forename type="first">Chuanpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Athanasios</forename><forename type="middle">E</forename><surname>Papathanasiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems</title>
				<meeting>the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="189" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">CRISP: Critical Slice Prefetching</title>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grant</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
				<meeting>the 27th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Bridging the processor-memory performance gap with 3D IC technology</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Christianto C Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ganusov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandip</forename><surname>Burtscher</surname></persName>
		</author>
		<author>
			<persName><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Design &amp; Test of Computers</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="556" to="564" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The performance of runtime data cache prefetching in a dynamic optimization system</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Chung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bobbie</forename><surname>Othmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pen-Chung</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong-Yuan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 36th annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">180</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Dynamic helper threaded prefetching on the sun ultrasparc cmp processor</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Chung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khoa</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santosh G</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 38th annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Compiler-based prefetching for recursive data structures</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="222" to="233" />
			<date type="published" when="1996">1996</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Profile-guided post-link stride prefetching</title>
		<author>
			<persName><forename type="first">Chi-Keung</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harish</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Lowney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on Supercomputing</title>
				<meeting>the 16th international conference on Supercomputing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="167" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The HPC Challenge (HPCC) benchmark suite</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Piotr R Luszczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">F</forename><surname>Kepner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolf</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisuke</forename><surname>Rabenseifner</surname></persName>
		</author>
		<author>
			<persName><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 ACM/IEEE conference on Supercomputing</title>
				<meeting>the 2006 ACM/IEEE conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="1188455" to="1188677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Break dancing: low overhead, architecture neutral software branch tracing</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Alexandrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Moseley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems</title>
				<meeting>the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="122" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Ithemal: Accurate, portable and fast basic block throughput estimation using deep neural networks</title>
		<author>
			<persName><forename type="first">Charith</forename><surname>Mendis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Renda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saman</forename><surname>Amarasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4505" to="4515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Best-offset hardware prefetching</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Tolerating latency through software-controlled prefetching in shared-memory multiprocessors</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="106" />
			<date type="published" when="1991">1991. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Automatic Compiler-Inserted I/O Prefetching for Out-of-Core Applications</title>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><forename type="middle">K</forename><surname>Demke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orran</forename><surname>Krieger</surname></persName>
		</author>
		<idno type="DOI">10.1145/238721.238734</idno>
		<ptr target="https://doi.org/10.1145/238721.238734" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second USENIX Symposium on Operating Systems Design and Implementation (OSDI)</title>
				<editor>
			<persName><forename type="first">Karin</forename><surname>Petersen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Willy</forename><surname>Zwaenepoel</surname></persName>
		</editor>
		<meeting>the Second USENIX Symposium on Operating Systems Design and Implementation (OSDI)<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996-10-28">1996. October 28-31, 1996</date>
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Design and Evaluation of a Compiler Algorithm for Prefetching</title>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.1145/143365.143488</idno>
		<ptr target="https://doi.org/10.1145/143365.143488" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Fifth International Conference on Architectural Support for Programming Languages and Operating Systems<address><addrLine>Boston, Massachusetts, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="62" to="73" />
		</imprint>
	</monogr>
	<note>ASPLOS V)</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Introducing the graph 500</title>
		<author>
			<persName><forename type="first">Kyle</forename><forename type="middle">B</forename><surname>Richard C Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">W</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><surname>Ang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cray Users Group (CUG)</title>
				<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="45" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Techniques for efficient processing in runahead execution engines</title>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="370" to="381" />
			<date type="published" when="2005">2005</date>
			<publisher>IEEE Computer Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Runahead execution: An alternative to very large instruction windows for out-of-order processors</title>
		<author>
			<persName><forename type="first">Onur</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Ninth International Symposium on High-Performance Computer Architecture</title>
				<imprint>
			<date type="published" when="2003">2003. 2003. 2003</date>
			<biblScope unit="page" from="129" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Data cache prefetching using a global history buffer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">E</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th International Symposium on High Performance Computer Architecture (HPCA&apos;04)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="96" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">BOLT: a practical binary optimizer for data centers and beyond</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Nell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</title>
				<meeting>the 2019 IEEE/ACM International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Lightning BOLT: powerful, fast, and scalable binary optimization</title>
		<author>
			<persName><forename type="first">Maksim</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Auler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laith</forename><surname>Sakka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilherme</forename><surname>Ottoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM SIGPLAN International Conference on Compiler Construction</title>
				<meeting>the 30th ACM SIGPLAN International Conference on Compiler Construction</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Locating cache performance bottlenecks using data profiling</title>
		<author>
			<persName><forename type="first">Aleksey</forename><surname>Pesterev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nickolai</forename><surname>Zeldovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">T</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European conference on Computer systems</title>
				<meeting>the 5th European conference on Computer systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="335" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Add support for the Branch Record Buffer extension</title>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Prates</surname></persName>
		</author>
		<ptr target="https://reviews.llvm.org/D92389" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Sandbox prefetching: Safe run-time evaluation of aggressive prefetchers</title>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Seth H Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Chishti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Fei</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aamer</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><surname>Jaleel</surname></persName>
		</author>
		<author>
			<persName><surname>Shih-Lien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kingsum</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><surname>Balasubramonian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="626" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Runahead threads to improve SMT performance</title>
		<author>
			<persName><forename type="first">Tanausu</forename><surname>Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Pajuelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliverio</forename><forename type="middle">J</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateo</forename><surname>Valero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE 14th International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Google-wide profiling: A continuous profiling infrastructure for data centers</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Gang Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tipp</forename><surname>Tune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvius</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName><surname>Hundt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE micro</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="65" to="79" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Difftune: Optimizing cpu simulator parameters with learned differentiable surrogates</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Renda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yishen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charith</forename><surname>Mendis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="442" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Dependence based prefetching for linked data structures</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurindar</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="115" to="126" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Effective jump-pointer prefetching for linked data structures</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurindar</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="111" to="121" />
			<date type="published" when="1999">1999</date>
			<publisher>IEEE Computer Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A decoupled predictor-directed stream prefetching architecture</title>
		<author>
			<persName><forename type="first">Suleyman</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="260" to="276" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Efficiently prefetching complex address patterns</title>
		<author>
			<persName><forename type="first">Manjunath</forename><surname>Shevgoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sahil</forename><surname>Koladiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Balasubramonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seth</forename><forename type="middle">H</forename><surname>Pugsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeshan</forename><surname>Chishti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="141" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">A hierarchical neural model of data prefetching</title>
		<author>
			<persName><forename type="first">Zhan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parthasarathy</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="861" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Sequential program prefetching in memory hierarchies</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="7" to="21" />
			<date type="published" when="1978">1978. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Spatial memory streaming</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="263" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A compiler-directed data prefetching scheme for chip multiprocessors</title>
		<author>
			<persName><forename type="first">Seung</forename><surname>Woo Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmut</forename><surname>Kandemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Karakoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruva</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Sigplan Notices</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="209" to="218" />
			<date type="published" when="2009">2009</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Thermometer: Profile-Guided BTB Replacement for Data Center Applications</title>
		<author>
			<persName><forename type="first">Shixin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanvir</forename><surname>Ahmed Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><forename type="middle">Mahdizadeh</forename><surname>Shahri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreenivas</forename><surname>Niranjan K Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Jim√©nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baris</forename><surname>Litz</surname></persName>
		</author>
		<author>
			<persName><surname>Kasikci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">49th Annual International Symposium on Computer Architecture (ISCA)</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Softsku: Optimizing server architectures for microservice diversity@ scale</title>
		<author>
			<persName><forename type="first">Akshitha</forename><surname>Sriraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Dhanotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th International Symposium on Computer Architecture</title>
				<meeting>the 46th International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="513" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Prodigy: Improving the memory latency of data-indirect irregular workloads using hardware-software codesign</title>
		<author>
			<persName><forename type="first">Nishil</forename><surname>Talati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Behroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuba</forename><surname>Kaszyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Vasiladiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarunesh</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawen</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="654" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Disclosure of hardware prefetcher control on some Intel processors</title>
		<author>
			<persName><surname>Vish Viswanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intel SW Developer Zone</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Guided region prefetching: A cooperative hardware/software approach</title>
		<author>
			<persName><forename type="first">Zhenlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">C</forename><surname>Weems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th Annual International Symposium on Computer Architecture</title>
				<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="388" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Practical off-chip meta-data for temporal memory streaming</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Thomas F Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 15th International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Temporal streaming of shared memory</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Thomas F Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jangwoo</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastassia</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Symposium on Computer Architecture (ISCA&apos;05)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">Intel Performance Counter Monitor -A Better Way to Measure CPU Utilization</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Willhalm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Dementiev</surname></persName>
		</author>
		<ptr target="https://software.intel.com/en-us/articles/intel-performance-counter-monitor#abstracting" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">High performance compilers for parallel computing</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Wolfe</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wolfe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Addison-Wesley Reading</publisher>
			<biblScope unit="volume">102</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Temporal prefetching without the off-chip metadata</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendra</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Pusdesris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 52nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="996" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Efficient metadata management for irregular data prefetching</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishnendra</forename><surname>Nathella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dam</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Compiler-driven dependence profiling to guide program parallelization</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Kejariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">CƒÉlin</forename><surname>Ca≈ücaval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Languages and Compilers for Parallel Computing</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="232" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Efficient discovery of regular stride patterns in irregular programs and its use in compiler prefetching</title>
		<author>
			<persName><forename type="first">Youfeng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="210" to="221" />
			<date type="published" when="2002">2002</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Hitting the Memory Wall: Implications of the Obvious</title>
		<author>
			<persName><forename type="first">Wm</forename><forename type="middle">A</forename><surname>Wulf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Mckee</surname></persName>
		</author>
		<idno type="DOI">10.1145/216585.216588</idno>
		<ptr target="https://doi.org/10.1145/216585.216588" />
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="20" to="24" />
			<date type="published" when="1995-03">1995. March 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">IMP: Indirect memory prefetcher</title>
		<author>
			<persName><forename type="first">Xiangyao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadathur</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Devadas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
				<meeting>the 48th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="178" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Dynamic control flow in large-scale machine learning</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
				<meeting>the Thirteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Michael J Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><surname>Stoica</surname></persName>
		</author>
		<title level="m">Spark: Cluster computing with working sets. HotCloud</title>
				<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">RnR: A software-assisted record-and-replay hardware prefetcher</title>
		<author>
			<persName><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaochen</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="609" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Riffle: optimized shuffle service for large-scale data analytics</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ergin</forename><surname>Seyfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avery</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference</title>
				<meeting>the Thirteenth EuroSys Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">A selfrepairing prefetcher in an event-driven dynamic optimization framework</title>
		<author>
			<persName><forename type="first">Weifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Code Generation and Optimization</title>
				<meeting>the International Symposium on Code Generation and Optimization</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="50" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Accelerating and adapting precomputation threads for efficient prefetching</title>
		<author>
			<persName><forename type="first">Weifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE 13th International Symposium on High Performance Computer Architecture</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="85" to="95" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
