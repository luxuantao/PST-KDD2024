<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrast and Generation Make BART a Good Dialogue Emotion Recognizer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-01-24">24 Jan 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shimin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hang</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
							<email>xpqiu@fudan.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Guangdong</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Shanghai Key Laboratory of Intelligent Information Processing</orgName>
								<orgName type="institution">Fudan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Contrast and Generation Make BART a Good Dialogue Emotion Recognizer</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-01-24">24 Jan 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2112.11202v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In dialogue systems, utterances with similar semantics may have distinctive emotions under different contexts. Therefore, modeling long-range contextual emotional relationships with speaker dependency plays a crucial part in dialogue emotion recognition. Meanwhile, distinguishing the different emotion categories is non-trivial since they usually have semantically similar sentiments. To this end, we adopt supervised contrastive learning to make different emotions mutually exclusive to identify similar emotions better. Meanwhile, we utilize an auxiliary response generation task to enhance the model's ability of handling context information, thereby forcing the model to recognize emotions with similar semantics in diverse contexts. To achieve these objectives, we use the pretrained encoder-decoder model BART as our backbone model since it is very suitable for both understanding and generation tasks. The experiments on four datasets demonstrate that our proposed model obtains significantly more favorable results than the state-of-the-art model in dialogue emotion recognition. The ablation study further demonstrates the effectiveness of supervised contrastive loss and generative loss 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>With the development and popularization of personal intelligent terminal technology and social networks, the importance of constructing a dialogue system that can comprehend user emotions and intentions and conduct effective dialogue interactions has increased significantly. A critical module in the dialogue system is the natural language understanding module that analyzes user behaviors like intents or emotions. Analyzing user sentiments with contextual relationships is an advanced step for simple sentiment classification tasks and is more suitable for usage scenarios in the real world with more research value. The task of emotion recognition in conversation (ERC) is to assign emotion labels to all the utterances in a historical dialogue with a contextual relationship. At the same time, each historical dialogue contains interactions between multiple different speakers, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>There are three challenges for ERC.</p><p>(1) The first challenge is that the emotion of each utterance may be affected</p><p>[Jade]: Oh, Bob, he was nothing compared to you. I had to bite my lip to keep from screaming your name.</p><p>[Chandler]: Well, that makes me feel so good.</p><p>[Jade]: It was just so awkward and bumpy</p><p>[Ross]: Bumpy?</p><p>[Chandler]: Well, maybe he had some kind of, uh, new, cool style, that you're not familiar with.</p><p>[Jade]: Well, there really wasn't much time to get used to it, you know what I mean? by contextual information. For example, specific emotions will depend on certain utterances of the context. Meanwhile, utterances with the same expression may have completely different emotions in various contexts. Therefore, effectively modeling the context dependency and the speaker dependency is the main factor distinguishing this task from traditional sentiment classification. (2) The second challenge is that each speaker's emotion is influenced by the utterance of other speakers in the conversation, so there may exist a sudden change in a speaker's emotion. (3) The third challenge lies in semantically similar but different categories of emotions, such as "frustrated" to "sad", "happy" to "excited", etc. It is difficult to distinguish these semantically similar sentiment categories.</p><p>Recent related work addressed contextual dependencies and speaker relations using various graph networks <ref type="bibr" target="#b23">(Shen et al. 2021b;</ref><ref type="bibr" target="#b7">Ghosal et al. 2019;</ref><ref type="bibr" target="#b12">Ishiwatari et al. 2020;</ref><ref type="bibr" target="#b24">Sheng et al. 2020)</ref>. However, as the number of layers deepens, the phenomenon of over-smoothing <ref type="bibr" target="#b3">(Chen et al. 2020a</ref>) starts to appear, resulting in the representation of similar sentiments tending to be indistinguishable. This work deals with the above challenges by better modeling the context and speaker information and auxiliary generation task.</p><p>Firstly, we introduce a dialogue-level Transformer <ref type="bibr" target="#b24">(Vaswani et al. 2017</ref>) layer to model the long-range context dependencies between utterances. A pre-trained language model captures the representation of each utterance. Compared to previous approaches that only adopt pre-trained models as a feature extractor <ref type="bibr" target="#b19">(Liu et al. 2019</ref>) and employ the extracted features as the node representation of downstream graph networks, a pure Transformer structure makes fewer prior structural assumptions <ref type="bibr" target="#b18">(Lin et al. 2021)</ref>.</p><p>Secondly, we adopt supervised contrastive learning (SCL) <ref type="bibr" target="#b13">(Khosla et al. 2020)</ref> to alleviate the difficulty in categorizing similar emotions, which makes samples with same sentiments cohesive and different sentiments mutually exclusive under the fully utilization of label information. Compared with the cross-entropy loss for noisy labels, the supervised contrastive loss can increase the stability of training and improve the generalization of the model <ref type="bibr" target="#b8">(Gunel et al. 2021)</ref>. Unlike the regular SCL, we copy the hidden state of all samples in a batch and detach off its gradient as its multiview representation. The reason is that the categories in existing ERC datasets are highly unbalanced, and some categories may exist in a batch with only one sample. If only the original SCL is used, it will lead to incorrect loss calculation.</p><p>Thirdly, we introduce an auxiliary response generation task to enhance the ability of capturing the context information for ERC. The prediction of the following utterance makes the model fully consider contextual dependencies, thus forcing the model to consider the information in the context and rely on the current utterance itself when recognizing the sentiment in the conversation. Moreover, by splicing the speaker directly before utterance as a hint for speaker information, the dependency between speakers and utterances is modeled adequately without additional parameters.</p><p>Finally, we utilize <ref type="bibr">BART (Lewis et al. 2020)</ref>, a pre-trained Transformer with an encoder-decoder structure, as our backbone model and enhance it by contrastive and generative loss. Our proposed COnstrastive-and-Generation-enhanced BART (CoG-BART) obtains state-of-the-art results on four ERC datasets compared to the baseline models. Additionally, ablation experiments and case studies prove the effectiveness of the contrastive and generative losses in the ERC task.</p><p>To summarize, our main contributions can be concluded as follows:</p><p>• To the best of our knowledge, we utilize supervised contrastive learning for the first time in ERC and significantly improve the model's ability to distinguish different sentiments.</p><p>• By incorporating response generation as an auxiliary task, the performance of ERC is improved when certain contextual information is involved. • Our model is easy-to-implemented since it does not depend on external resources, like graph-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>This section will introduce related works in ERC. Due to context-dependency and speaker dependency properties, it is natural for researchers to employ graph neural networks. Therefore, many works have constructed various task-specific graph structures. Meanwhile, with the excellent performance of the pre-trained model in diverse downstream tasks, an increasing number of works adopt the pretrained model as the feature extractor for the input of the downstream model or directly fine-tune it with downstream datasets. Therefore, this section divides the related work into two categories: graph-based models and pre-train-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialog Emotion Recognition</head><p>Graph-based model Considering the unidirectionality of information interaction, DAG <ref type="bibr" target="#b23">(Shen et al. 2021b)</ref>  Pre-train-based model Suppose each utterance is regarded as an independent sentence, regardless of its contextdependence and speaker information. In that case, the problem can be transformed into a simple sentence classification so that pre-trained models <ref type="bibr" target="#b21">(Qiu et al. 2020</ref>) such as BERT <ref type="bibr" target="#b5">(Devlin et al. 2019)</ref>, <ref type="bibr">BART (Lewis et al. 2020)</ref>, and RoBERTa <ref type="bibr" target="#b19">(Liu et al. 2019</ref>) can be used directly for finetuning. HiTrans <ref type="bibr" target="#b16">(Li et al. 2020)</ref> adopts BERT to extract utterance features, followed by transformer structure for modeling context. Considering speaker dependence, the auxiliary task of judging whether two utterances are the same speaker is used to model the speaker information. COS-MIC <ref type="bibr" target="#b7">(Ghosal et al. 2020)</ref> exploits RoBERTa as the feature extractor of each utterance and model the dependency of the context with RNN. In addition, the common knowledge transformer COMET <ref type="bibr" target="#b0">(Bosselut et al. 2019)</ref>   pays attention to different aspects of dialogue information. <ref type="bibr" target="#b11">Ide and Kawahara (2021)</ref> trained BART with both generation and classification in a multi-task format, though their method focused on response generation, treating emotion recognition as an auxiliary task. However, we focus on ERC and apply supervised contrastive loss as an additional optimization goal.</p><formula xml:id="formula_0">L CE L CE L CE L CE L CE L CE L GEN L GEN L GEN L GEN L GEN BART-Encoder L SCL L SCL Max-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrastive Learning</head><p>Unsupervised contrastive learning In the field of computer vision, SimCLR <ref type="bibr" target="#b4">(Chen et al. 2020b</ref>) takes pictures obtained from the same image through randomly different data augmentation methods as positive samples and other pictures as negative samples, thereby optimizing contrastive loss. The naive sentence representation obtained by BERT has poor performance in semantic text similarity tasks. Therefore, ConSERT <ref type="bibr" target="#b26">(Yan et al. 2021</ref>) introduces selfsupervised contrast loss in the fine-tuning stage of BERT. MBERT <ref type="bibr" target="#b14">(Kim, Yoo, and Lee 2021)</ref> does not use data augmentation to construct positive samples but uses BERT with frozen parameters and fine-tunable parameters as a special siamese model to construct positive samples.</p><p>Supervised contrastive learning To make full use of label information, <ref type="bibr" target="#b13">Khosla et al. (2020)</ref> extends it to supervised contrastive learning based on self-supervised training so that samples belonging to the same label are gathered in the embedding space while pushing samples of different categories away. Given that cross-entropy loss may cause model training instability and converge to a local optimum, SCL <ref type="bibr" target="#b8">(Gunel et al. 2021</ref>) introduces supervised contrastive loss in the finetuning stage, which greatly improves the model's perfor-mance in few-shot learning scenarios. SimCSE (Gao, Yao, and Chen 2021) uses entailment pair in the annotated NLI dataset as the positive sample and the contradict pair as the negative sample in supervised contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology Problem Definition</head><p>In dialogue emotion recognition, the data is composed of multiple conversations {c 1 , c 2 , • • • , c N }, with each conversation composed of several utterances</p><formula xml:id="formula_1">c i = [u 1 , u 2 , • • • , u m ] and emotion labels Y ci = {y 1 , y 2 , • • • , y m } ∈ S,</formula><p>where S indicates the categories of emotions. For an utterance, it is comprised of several tokens</p><formula xml:id="formula_2">u t = [w t,1 , w t,2 , • • • , w t,n ].</formula><p>Every utterance in a conversation c i is uttered by one speaker which can be represented as p</p><formula xml:id="formula_3">(c i ) = [p(u 1 ), • • • , p(u i ), • • • , p(u m )]</formula><p>and p(u i ) ∈ P , where P indicates the categories or names of the speakers. Accordingly, the whole problem can be expressed as getting the emotional label of each utterance based on the context and speaker information in a piece of conversation:</p><formula xml:id="formula_4">Y ci = f (c i , p(c i )).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised Contrastive Learning for ERC</head><p>Utterance Encoding To model the dependencies between speaker and utterance, for a certain utterance u t in a conversation, we splice the speaker's name or category before the utterance. After tokenizing the utterance prepended with the speaker information, we get:</p><formula xml:id="formula_5">ũt = s , w t,1 , • • • , w t,i , • • • , w t,|nt| , /s ,<label>(1)</label></formula><p>where s and /s are treated as special tokens to indicate the beginning and end of an utterance. Then the token se-quence after tokenization is fed to the shared embedding layer of BART to acquire the hidden state of each token in utterance before sending it to the encoder and decoder of BART. After sending H t to BART, the representation of the current utterance H t is acquired:</p><formula xml:id="formula_6">H t = EmbeddingLayer(ũ t ),<label>(2)</label></formula><formula xml:id="formula_7">H t = BART-Model(H t ),<label>(3)</label></formula><p>where H t , H t ∈ R s×d , and s, d indicates the length of the sequence and hidden dimension respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue Modeling</head><p>The representation H t obtained by the BART-Model is max-pooled to obtain the aggregated representation of the utterances as follows:</p><formula xml:id="formula_8">ȟt = max-pooling( H t ).<label>(4)</label></formula><p>To model the historical context information of the dialogue, we exploit a dialogue-level Transformer <ref type="bibr" target="#b24">(Vaswani et al. 2017</ref>) layer as the context encoder. The multi-head attention mechanism can capture the interaction between different dialogues in multiple rounds of dialogue and aggregate different features to obtain the final implicit representation, thereby fully modeling the complex dependence between different utterances and context relations. For all utterances in a context, the multi-head attention score of the hidden state between two different utterances in a conversation ȟj , ȟk can be calculated by the following formulas:</p><formula xml:id="formula_9">Atten(Q, K, V ) = softmax( QK T √ d k )V,<label>(5)</label></formula><formula xml:id="formula_10">head i = Atten( ȟj W Q i , ȟk W K i , ȟk W V i ),<label>(6)</label></formula><formula xml:id="formula_11">MultiHead(Q, K, V ) = [head 1 ; • • • ; head n ]W O ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_12">W Q i ∈ R d×dq , W K i ∈ R d×d k , W V i ∈ R d×dv and W O ∈ R d×d</formula><p>are parameters that can be optimized, d q , d k and d v are dimensions of query, key and value vectors, n indicates the number of heads.</p><p>Therefore, the utterance representation that models the context-dependence can be obtained through the abovementioned dialogue-level Transformer:</p><formula xml:id="formula_13">H win = [ ȟt , ȟt+1 , • • • , ȟt+bs−1 ],<label>(8)</label></formula><formula xml:id="formula_14">H d-win = Dialogue-Transformer(H win ),<label>(9)</label></formula><p>where H win ∈ R bs×d indicates utterances in a conversation within the window size bs and H d-win ∈ R bs×d denotes the utterances after context modeling.</p><p>Supervised Contrastive Learning Supervised contrastive learning assumes that some crucial aspects get attention and allows few-shot learning to be more stable when fine-tuned on pre-trained models <ref type="bibr" target="#b8">(Gunel et al. 2021)</ref>. For ERC, the number of samples in each category in some datasets <ref type="bibr" target="#b17">(Li et al. 2017</ref>) is highly unbalanced, while the supervised contrastive learning will mask itself when calculating the loss. If only one sample exists for a category in the batch, it cannot be directly applied to calculate the loss. Therefore, a copy of the hidden state of the utterance H d-win is made to obtain H d-win , and its gradient is detached. Hence the parameter optimization is maintained stable.</p><p>For a batch with N training samples, each sample is operated by the above mechanism to obtain multiview 2N samples, then the supervised contrastive loss of all samples in a batch can be expressed by the following equation:</p><formula xml:id="formula_15">X = [H d-win , H d-win ],<label>(10)</label></formula><formula xml:id="formula_16">L SCL = i∈I −1 |P (i)| p∈P (i) SIM(p, i),<label>(11)</label></formula><formula xml:id="formula_17">SIM(p, i) = log exp((X i • X p )/τ ) a∈A(i) exp(X i • X a /τ ) ,<label>(12)</label></formula><p>where </p><formula xml:id="formula_18">X ∈ R 2N ×d , i ∈ I = {1, 2, • • • , 2N } indicate</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Auxiliary Response Generation</head><p>To facilitate the model to consider richer contextual information when determining utterance sentiment, the model is required to generate its following utterance u t+1 given the current utterance u t . The output hidden state of each token in u t+1 is generated by the BART decoder sequentially.</p><p>Ht = BART-Encoder(H t ), (13) hd j = BART-Decoder( Ht ; hd &lt;j ),</p><formula xml:id="formula_19">u t+1,j = Softmax( hd j ),<label>(14)</label></formula><formula xml:id="formula_20">L Gen = − N i=1 log p(u t+1 |u t , θ), (<label>(15)</label></formula><formula xml:id="formula_21">)<label>16</label></formula><p>where θ is the parameters of BART need to be optimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Training</head><p>The loss of model training consists of three parts: the hidden state H d-win obtained after context modeling passes through a multilayer perceptron to obtain logits for calculating crossentropy loss. The other part is the supervised contrastive loss and the loss of response generation. The loss is a weighted sum of the three components, and the sum of their weights equals one. </p><formula xml:id="formula_22">P i = Softmax(W s H d-win,i + b s ), (<label>17</label></formula><formula xml:id="formula_23">) ŷi = argmax(P i ),<label>(18)</label></formula><formula xml:id="formula_24">L CE = − 1 N N i=1 C c=1 y i,c • log ŷi,c ,<label>(19)</label></formula><formula xml:id="formula_25">L = (1 − α − β)L CE + αL SCL + βL Gen ,<label>(20)</label></formula><p>where y i,c represents the label of a certain utterance, ŷi,c indicates the probability distribution of category c output by the dense layer, α denotes the weight for supervised contrastive loss and β is the weight for loss of response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>This section will elaborate on the datasets, baseline models, experimental conditions, and parameter settings adopt in the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Setup</head><p>The code framework and initial weight of BART come from Huggingface's Transformers <ref type="bibr" target="#b25">(Wolf et al. 2020)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>This section will introduce four benchmark datasets: MELD <ref type="bibr" target="#b20">(Poria et al. 2019)</ref>, EmoryNLP <ref type="bibr" target="#b28">(Zahiri and Choi 2018)</ref>, Dai-lyDialog <ref type="bibr" target="#b17">(Li et al. 2017)</ref>, and IEMOCAP <ref type="bibr">(Busso et al. 2008)</ref> for comparison with the baseline models.</p><p>MELD This dataset comes from the dialogue content of the characters in the American drama Friends. MELD originally contained multi-modal data, but we used only the text data for the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EmoryNLP (ENLP) This dataset also comes from</head><p>Friends, and the difference from MELD is the annotation of utterance's emotional label category. The emotional tags contained in this dataset are: joyful, neutral, powerful, mad, sad, scared, and peaceful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DailyDialog (DD)</head><p>Manually compiled data sets about daily communication. The annotation method used in this data set is Ekman's emotion type <ref type="bibr" target="#b6">(Ekman 1993)</ref>, which includes six basic emotion tags, including happiness, surprise, anger, disgust, fear, and sadness.</p><p>IEMOCAP Like MELD, it is a multi-modal dataset. The content is derived from the lines in the scripts of the two actors, and the emotional tags included are excited, neutral, frustrated, sad, happy, and angry.</p><p>The detailed statistics of the four datasets are shown in Table <ref type="table" target="#tab_2">1</ref>, where "#Dial" indicates the number of dialogue in train/dev/test, "#Utter" represents the number of all utterances in dialogue, and "#CLS" denotes the number of categories of each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head><p>For MELD, EmoryNLP and IEMOCAP, we adopt weighted average F1 as the evaluation metrics. In that "neutral" occupies the majority in DailyDialog, micro-F1 is employed as the evaluation metric for this data set, and we ignore the label "neutral" when calculating the results as in the previous works <ref type="bibr" target="#b30">(Zhu et al. 2021;</ref><ref type="bibr" target="#b23">Shen et al. 2021b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Results</head><p>Table <ref type="table" target="#tab_4">2</ref> and 3 record the results of comparing CoG-BART with the baseline models on four datasets.</p><p>Among the pre-train-based models and their variants, the selected baseline models are BERT <ref type="bibr" target="#b5">(Devlin et al. 2019)</ref>, RoBERTa <ref type="bibr" target="#b19">(Liu et al. 2019)</ref>, HiTrans <ref type="bibr" target="#b16">(Li et al. 2020)</ref>, Di-alogXL <ref type="bibr" target="#b22">(Shen et al. 2021a</ref>) and XLNet <ref type="bibr" target="#b27">(Yang et al. 2019)</ref>. In MELD <ref type="bibr" target="#b20">(Poria et al. 2019</ref>), CoG-BART has an approximate absolute 1.24% improvement over the previous state-of-theart <ref type="bibr">BART-large (Lewis et al. 2020)</ref>.</p><p>For graph-based models, KET <ref type="bibr" target="#b29">(Zhong, Wang, and Miao 2019)</ref>, RGAT <ref type="bibr" target="#b12">(Ishiwatari et al. 2020)</ref>, <ref type="bibr">DialogGCN (Ghosal et al. 2019)</ref>, DialogCRN <ref type="bibr" target="#b10">(Hu, Wei, and Huai 2021)</ref>, <ref type="bibr">COS-MIC (Ghosal et al. 2020)</ref>, and DAG-ERC <ref type="bibr" target="#b23">(Shen et al. 2021b</ref>) are listed.</p><p>Compared to the graph-based model, CoG-BART improves 0.53 points over COSMIC <ref type="bibr" target="#b7">(Ghosal et al. 2020)</ref>. It is worth noting that RoBERTa-large is used as the feature extractor in COSMIC, while CoG-BART only adopts BARTlarge as the backbone structure to obtain competitive results, indicating that adequate knowledge transfer of pre-trained models which effectively model the dependencies between contexts can also yield promising results in MELD.</p><p>We can observe from the results in EmoryNLP (Zahiri and Choi 2018) that the graph-based model using the pre-trained model as the feature extractor works better overall than the model applying only the pre-trained model as the backbone network. Meanwhile, CoG-BART still achieves results with significant improvement. Also, the graph-based model can obtain higher F1 overall on IEMOCAP <ref type="bibr">(Busso et al. 2008)</ref> compared to the pre-trained based models.   The micro-F1 values of CoG-BART in DailyDialog are lower compared to the results of some graph neural network models. Still, it can achieve similar results to some pre-trainbased models such as BERT <ref type="bibr" target="#b5">(Devlin et al. 2019)</ref>, RoBERTa <ref type="bibr" target="#b19">(Liu et al. 2019)</ref> and DialogXL <ref type="bibr" target="#b22">(Shen et al. 2021a</ref>). Therefore, the graph-based model may have the advantage over pre-train-based models by more adequately modeling context dependencies on this dataset.  The Potency of Supervised Contrastive Learning Qualitative Analysis of SCL To conduct a qualitative analysis of supervised contrastive learning, we utilize t-SNE <ref type="bibr" target="#b9">(Hinton and Roweis 2002)</ref> to visualize the distribution of high-dimensional hidden states obtained by the model trained with supervised contrastive loss. By controlling different sizes of α, the ratio of supervised contrastive loss is controlled to 0% and 80%, respectively, to obtain the hidden state output by the model under different levels of supervised contrastive learning.</p><p>As illustrated in Figure <ref type="figure" target="#fig_4">3</ref>, when the supervised contrastive loss is not exploited, that is, when the cross-entropy loss function is completely adopted, the overlap rate of samples between different labels is particularly high, especially for some samples with similar emotions, which increase the difficulty of learning the decision boundaries. As the proportion of supervised contrastive loss increases, it can be distinctly observed that the degree of coupling between different classes is gradually enlarged, and the same classes begin to cohesive. It is worth mentioning that although the distance within the class has been reduced, the uniformity <ref type="bibr" target="#b25">(Wang and Isola 2020)</ref> between samples has been well maintained, indicating that the information has been well preserved and no representation collapse has occurred. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantitative Analysis of SCL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Response Generation</head><p>Response generation has a facilitating effect on modeling context dependence to some extent. As the two cases in Figure <ref type="figure">4</ref> illustrate, if only the current utterance itself is considered, the expression may cause the model to misjudge the sentiment of the current utterance, while generating responses leads the model to pay more attention to contextual information, thus making correct predictions which consistent with the scenario. As for the impact of different weights of response generation loss, Table <ref type="table" target="#tab_7">4</ref> illustrates that when fixing α and adjusting β, there is also a slight impact on the model's overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Analysis</head><p>To investigate the impacts of individual modules and combinations of several components on the overall effect of the model, this section conducts an ablation study on three modules in CoG-BART. As illustrated in Table <ref type="table" target="#tab_8">5</ref>, the selected datasets are MELD and IEMOCAP, where "-" indicates the removal of the single method or several methods, "Gen" denotes the auxiliary task of response generation, "SCL loss" means supervised contrastive loss, and "Speaker" indicates the splicing of speaker label before utterance.</p><p>From the results of MELD, removing any of the three modules makes the overall performance worse, while dis-carding the supervised contrastive loss and response generation has the greatest impact on the performance of CoG-BART in MELD. These indicate that supervised contrastive loss leverage label information better compared to crossentropy loss, thus effectively distinguishing different sentiments.</p><p>Consistent results are also obtained in IEMOCAP, indicating that the improvement in model performance from these three modules transfers well across these datasets. However, the more unexpected finding was that removing the speaker's information made CoG-BART most degraded in IEMOCAP. By analyzing this dataset, we found that it involved 302 speakers, so it may be crucial to fully model the speaker information for this dataset. It also proves the effectiveness of the simple method of splicing the speaker information directly in front of the utterance. Furthermore, removing the supervised contrastive loss alone degrades the performance by 1.95 points on IEMOCAP, indicating that supervised contrastive learning significantly impacts CoG-BART on this dataset. The results after removing Dialoglevel Transformer suggest that this module improves overall performance by modelling longer contextual dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We propose supervised contrastive learning with response generation as an auxiliary task for BART, namely CoG-BART, for emotion recognition in conversation (ERC). First, supervised contrastive learning is introduced into the training process to distinguish similar emotions, reducing intraclass distance and increasing inter-class variance. Meanwhile, the response generation is adopted as an auxiliary task; hence, the model categorizes utterances with similar semantics but different emotions by considering the context. The results obtained on four datasets compared with the current state-of-the-art baseline methods demonstrate the proposed method's effectiveness. Furthermore, ablation studies demonstrate that supervised contrastive learning can effectively improve the model's efficacy in recognizing emotions, thus improving the overall performance. Also, response generation as an auxiliary task helps the model fully consider the context to discern the emotions of semantically similar utterances in varying contexts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The conversation flow chart in multi-person dialogue emotion recognition. The solid line indicates that the previous utterance directly influences the current speaker's emotion. The dashed line signifies that the same speaker is influenced by other utterances and expresses different emotions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overall framework of CoG-BART. The utterance is fed into BART for N utterances in a batch to get its hidden state. The representation of the utterance obtained after max-pooling the hidden state of each utterance is fed to the upper-level dialogue-level Transformer for modeling context dependencies. The obtained context-dependent utterance representations are utilized to compute the cross-entropy loss and supervised contrastive loss. In addition, the two adjacent utterance pairs are used for the auxiliary response generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The typical contrastive learning uses only one pair of positive examples, while all other samples are treated as negative examples. Supervised contrastive learning treats all examples with the same label in the batch as positive examples by making full use of label information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the index of the samples in a multiview batch, τ ∈ R + denotes the temperature coefficient used to control the distance between instances, P (i) = I j=i − {i} represents samples with the same category as i while excluding itself, A(i) = I − {i, N + i} indicates samples in the multiview batch except itself.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The t-SNE visualization results of the model output when α is 0 and 0.8, respectively.</figDesc><graphic url="image-10.png" coords="6,45.60,367.07,115.33,107.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of four benchmark datasets.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>DD</cell><cell cols="3">MELD ENLP IEMOCAP</cell></row><row><cell>#Dial</cell><cell cols="2">Train 11118</cell><cell>1038</cell><cell>713</cell><cell>120</cell></row><row><cell></cell><cell>Dev</cell><cell>1000</cell><cell>114</cell><cell>99</cell><cell>120</cell></row><row><cell></cell><cell>Test</cell><cell>1000</cell><cell>280</cell><cell>85</cell><cell>31</cell></row><row><cell cols="3">#Utter Train 87170</cell><cell>9989</cell><cell>9934</cell><cell>5810</cell></row><row><cell></cell><cell>Dev</cell><cell>8069</cell><cell>1109</cell><cell>1344</cell><cell>5810</cell></row><row><cell></cell><cell>Test</cell><cell>7740</cell><cell>2610</cell><cell>1328</cell><cell>1623</cell></row><row><cell>#CLS</cell><cell></cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>6</cell></row></table><note>The overall framework of CoG-BART is illustrated in Figure2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We conducted a hyperparameter search for model training through the reserved validation set. The results on the test set come from the best checkpoint in the validation set, and we average the scores from five different random seeds. All experiments are performed on GeForce RTX 3090 GPU.</figDesc><table /><note>. The optimizer applied for model training is AdamW with a linearscheduled warm-up strategy. The parameters adjusted in this experiment include batch size, learning rate, warm-up ratio, α, and β.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>The reason is that The overall results of CoG-BART with pre-train-based baseline models on four datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="2">MELD</cell><cell></cell><cell cols="2">EmoryNLP</cell><cell cols="2">IEMOCAP</cell><cell cols="2">DailyDialog</cell></row><row><cell>Model</cell><cell>Weighted</cell><cell>Micro-F1</cell><cell cols="2">Weighted</cell><cell>Micro-F1</cell><cell>Weighted</cell><cell>Micro-F1</cell><cell>Weighted</cell><cell>Micro</cell></row><row><cell></cell><cell>-Avg-F1</cell><cell></cell><cell cols="2">-Avg-F1</cell><cell></cell><cell>-Avg-F1</cell><cell></cell><cell>-F1-neural</cell><cell>-F1-neutral</cell></row><row><cell>BERT</cell><cell>62.28</cell><cell>63.49</cell><cell cols="2">34.87</cell><cell>41.11</cell><cell>60.98</cell><cell>-</cell><cell>53.41</cell><cell>54.85</cell></row><row><cell>RoBERTa</cell><cell>62.51</cell><cell>63.75</cell><cell cols="2">35.90</cell><cell>40.81</cell><cell>63.38</cell><cell>-</cell><cell>52.84</cell><cell>54.33</cell></row><row><cell>HiTrans</cell><cell>61.94</cell><cell>-</cell><cell cols="2">36.75</cell><cell>-</cell><cell>64.50</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DialogXL</cell><cell>62.41</cell><cell>-</cell><cell cols="2">34.73</cell><cell>-</cell><cell>65.94</cell><cell>-</cell><cell>-</cell><cell>54.93</cell></row><row><cell>XLNet</cell><cell>61.65</cell><cell>-</cell><cell cols="2">34.13</cell><cell>-</cell><cell>61.33</cell><cell>-</cell><cell>-</cell><cell>53.62</cell></row><row><cell>BART-large</cell><cell>63.57</cell><cell>64.41</cell><cell cols="2">35.98</cell><cell>38.93</cell><cell>56.14</cell><cell>56.67</cell><cell>54.83</cell><cell>55.34</cell></row><row><cell cols="10">CoG-BART 64.81 (±0.19) 65.95 (±0.44) 39.04 (±0.10) 42.58 (±0.94) 66.18 (±0.45) 66.71 (±0.49) 56.09 (±0.01) 56.29 (±0.17)</cell></row><row><cell>Dataset</cell><cell>MELD</cell><cell cols="4">EmoryNLP IEMOCAP DailyDialog</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Weighted</cell><cell>Weighted</cell><cell>Weighted</cell><cell>Micro</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-Avg-F1</cell><cell>-Avg-F1</cell><cell>-Avg-F1</cell><cell cols="2">-F1-neutral</cell><cell></cell><cell></cell><cell></cell></row><row><cell>KET</cell><cell>58.18</cell><cell>34.39</cell><cell>59.56</cell><cell>53.37</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RGAT</cell><cell>60.91</cell><cell>34.42</cell><cell>65.22</cell><cell>54.31</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RGAT+RoBERTa</cell><cell>62.80</cell><cell>37.89</cell><cell>66.36</cell><cell>59.02</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DialogGCN</cell><cell>58.10</cell><cell>-</cell><cell>64.18</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DialogCRN</cell><cell>58.39</cell><cell>-</cell><cell>66.20</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>COSMIC</cell><cell>64.28</cell><cell>37.10</cell><cell>63.05</cell><cell>56.16</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DAG-ERC</cell><cell>63.65</cell><cell>39.02</cell><cell>68.03</cell><cell>59.33</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>CoG-BART 64.81 (±0.19) 39.04 (±0.10) 66.18 (±0.45) 56.29 (±0.17)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Comparison with graph-based models.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>MELD 64.57 63.99 64.42 61.84 64.83 63.70 IEMOCAP 64.38 66.18 65.12 63.38 66.18 63.54 EmoryNLP 39.04 36.68 36.90 35.24 37.45 37.57</figDesc><table><row><cell>Metric</cell><cell>Weighted Average F1</cell></row><row><cell>Datasets</cell><cell>α=0.2 α=0.4 α=0.6 α=0.8 β=0.1 β=0.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>The F1 scores for different values of α and β</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>The effects of different proportions of supervised contrastive learning on CoG-BART are illustrated in Table4, where the weighted average F1 of CoG-BART with different proportions of SCL loss is recorded. Different α have a large impact on the outcomes, e.g., there exists a 2.8 points difference in F1 values between α equals 0.4 and 0.8 for IEMOCAP, reflecting the significant positive effect of supervised contrastive learning for this dataset. Meanwhile, different datasets have different values of α in obtaining the relatively best gain effect. For instance, Case studies show that response generation enables the model to correctly predict the emotion based on context. Ablation study to evaluate the impact of different components on the overall performance of the model on MELD and EmoryNLP CoG-BART performs best when α = 0.2 in MELD, while achieving the best result when α = 0.4 in IEMOCAP.</figDesc><table><row><cell cols="2">Utterance for Prediction</cell><cell>Generated Response</cell><cell>Predict w/o RG</cell><cell>Predict with RG</cell><cell>Golden label</cell></row><row><cell cols="2">Joey : Thursday's clearly not good for ya, pick a day!</cell><cell>Sarah : So that's two boxes of the Brown Birds of America, I salute you. Holiday Macaroons. On behalf of the</cell><cell>anger</cell><cell>joy</cell><cell>joy</cell></row><row><cell cols="2">Joey: Man, that was great! Huh? Can you believe how long we threw that ball around?</cell><cell>Rachel : Yeah, it is amazing it lasted that long.</cell><cell>surprise</cell><cell>joy</cell><cell>joy</cell></row><row><cell>Figure 4: Dataset</cell><cell>MELD</cell><cell>IEMOCAP</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="2">Weight-Avg-F1</cell><cell></cell><cell></cell></row><row><cell>CoG-BART</cell><cell>64.81</cell><cell>66.18</cell><cell></cell><cell></cell></row><row><cell>-Gen</cell><cell cols="2">64.26 (↓0.55) 64.74 (↓1.44)</cell><cell></cell><cell></cell></row><row><cell>-SCL loss</cell><cell cols="2">64.28 (↓0.53) 64.23 (↓1.95)</cell><cell></cell><cell></cell></row><row><cell>-Speaker</cell><cell cols="2">64.14 (↓0.67) 55.41 (↓10.77)</cell><cell></cell><cell></cell></row><row><cell>-Gen, SCL loss</cell><cell cols="2">63.57 (↓1.24) 62.90 (↓3.28)</cell><cell></cell><cell></cell></row><row><cell cols="3">-SCL loss, Speaker 63.72 (↓1.09) 54.83 (↓11.35)</cell><cell></cell><cell></cell></row><row><cell>-Gen, Speaker</cell><cell cols="2">64.02 (↓0.79) 54.95 (↓11.23)</cell><cell></cell><cell></cell></row><row><cell>-Dialog-Trans</cell><cell cols="2">64.40 (↓0.41) 64.19 (↓1.99)</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are very grateful to the reviewers for their diligent and rigorous attitude towards our work and their valuable suggestions for improvement during the whole review process. This work was supported by the National Key Research and Development Program of China (No. 2020AAA0108702) and the National Natural Science Foundation of China (NO. 62022027).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">COMET: Commonsense Transformers for Automatic Knowledge Graph Construction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28">2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4762" to="4779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Busso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bulut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kazemzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactive emotional dyadic motion capture database. Language resources and evaluation</title>
	</analytic>
	<monogr>
		<title level="j">IEMOCAP</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring and Relieving the Over-Smoothing Problem for Graph Neural Networks from the Topological View</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07">2020a. February 7-12, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="3438" to="3445" />
		</imprint>
	</monogr>
	<note>The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Simple Framework for Contrastive Learning of Visual Representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
				<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07-18">2020b. 13-18 July 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Minneapolis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Facial expression and emotion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American psychologist</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">384</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno>CoRR, abs/2104.08821</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong; China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2021. 2020. 2019</date>
			<biblScope unit="page" from="154" to="164" />
		</imprint>
	</monogr>
	<note>Findings of the Association for Computational Linguistics: EMNLP 2020</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria</title>
				<imprint>
			<date type="published" when="2021-05-03">2021. May 3-7, 2021</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stochastic Neighbor Embedding</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 15 [Neural Information Processing Systems, NIPS 2002</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</editor>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002-12-09">2002. December 9-14, 2002</date>
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7042" to="7052" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, NAACL-HLT 2021</title>
				<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop, NAACL-HLT 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-06-06">2021. June 6-11, 2021</date>
			<biblScope unit="page" from="119" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ishiwatari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yasuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
				<editor>
			<persName><forename type="first">B</forename><surname>Webber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Cohn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</editor>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="7360" to="7370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<title level="m">Supervised contrastive learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-Guided Contrastive Learning for BERT Sentence Representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021<address><addrLine>Lewis, M</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021, 2528-2540</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>BART; Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">HiTrans: A Transformer-Based Context-and Speaker-Sensitive Model for Emotion Detection in Conversations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
				<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<publisher>International Committee on Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4190" to="4200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<title level="s">Long Papers</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Asian Federation of Natural Language Processing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04554</idno>
		<title level="m">A Survey of Transformers</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>CoRR, abs/1907.11692</idno>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pre-trained Models for Natural Language Processing: A Survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SCIENCE CHINA Technological Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1872" to="1897" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021-02-02">2021a. February 2-9, 2021</date>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="13789" to="13797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Directed Acyclic Graph Network for Conversational Emotion Recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/I-JCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021b. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1551" to="1560" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summarize before Aggregate: A Global-to-local Heterogeneous Graph Inference Network for Conversational Emotion Recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
				<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Barcelona, Spain; Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04">2020. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
	<note>Proceedings of the 28th International Conference on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-18">2020. 13-18 July 2020. 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Proceedings of the 37th International Conference on Machine Learning, ICML 2020</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5065" to="5075" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>; D'alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08">2019. 2019. 2019. December 8-14, 2019</date>
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Emotion Detection on TV Show Transcripts with Sequence-Based Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Zahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Workshops of the The Thirty-Second AAAI Conference on Artificial Intelligence, New Orleans</title>
				<meeting><address><addrLine>Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
			<biblScope unit="page" from="44" to="52" />
		</imprint>
	</monogr>
	<note>WS-18 of AAAI Workshops</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<idno>CoRR, abs/1909.10681</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pergola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Zong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1571" to="1582" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
