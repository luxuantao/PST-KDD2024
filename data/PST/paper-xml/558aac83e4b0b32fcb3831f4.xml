<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Real-Time Periodic Motion Detection, Analysis, and Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ross</forename><surname>Cutler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">AV Williams Blvd. Computer Science Department</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">AV Williams Blvd. Computer Science Department</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Real-Time Periodic Motion Detection, Analysis, and Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F14284E98551F9CFB1DC04D89694F5A5</idno>
					<note type="submission">received 21 Apr. 1999; revised 26 Feb. 2000; accepted 28 Mar. 2000.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T05:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index TermsÐPeriodic motion</term>
					<term>motion segmention</term>
					<term>object classification</term>
					<term>person detection</term>
					<term>motion symmetries</term>
					<term>motion-based recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AbstractÐWe describe new techniques to detect and analyze periodic motion as seen from both a static and a moving camera. By tracking objects of interest, we compute an object's self-similarity as it evolves in time. For periodic motion, the self-similarity measure is also periodic and we apply Time-Frequency analysis to detect and characterize the periodic motion. The periodicity is also analyzed robustly using the 2D lattice structures inherent in similarity matrices. A real-time system has been implemented to track and classify objects using periodicity. Examples of object classification (people, running dogs, vehicles), person counting, and nonstationary periodicity are provided.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>O BJECT motions that repeat are common in both nature and the man-made environment in which we live. Perhaps the most prevalent periodic motions are the ambulatory motions made by humans and animals in their gaits (commonly referred to as ªbiological motionº <ref type="bibr" target="#b15">[16]</ref>). Other examples include a person walking, a waving hand, a rotating wheel, ocean waves, and a flying bird. Knowing that an object's motion is periodic is a strong cue for object and action recognition <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b10">[11]</ref>. In addition, periodic motion can also aid in tracking objects. Furthermore, the periodic motion of people can be used to recognize individuals <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>Our work is motivated by the ability of animals and insects to utilize oscillatory motion for action and object recognition and navigation. There is behavioral evidence that pigeons are well-adapted to recognize the types of oscillatory movements that represent components of the motor behavior shown by many living organisms <ref type="bibr" target="#b8">[9]</ref>. There is also evidence that certain insects use oscillatory motion for navigational purposes (hovering above flowers during feeding) <ref type="bibr" target="#b16">[17]</ref>. Humans can recognize biological motion from viewing lights placed on the joints of moving people <ref type="bibr" target="#b15">[16]</ref>. Humans can also recognize periodic movement of image sequences at very low resolutions, even when point correspondences are not possible. For example, Fig. <ref type="figure" target="#fig_1">1</ref> shows such a sequence. The effective resolution of this sequence is W Â IS pixels (it was created by resampling a IRH Â PIV (8-bit, 30fps) image sequence to W Â IS and back to IRH Â PIV using bicubic interpolation). In this sequence, note the similarity between frames 0 and 15. We will use image similarity to detect and analyze periodic motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Periodicity and Motion Symmetries</head><p>We define the motion of a point t, at time t, periodic if it repeats itself with a constant period p, i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t p t tY I</head><p>where t is a translation of the point. The period p is the smallest p b H that satisfies <ref type="bibr" target="#b0">(1)</ref>; the frequency of the motion is Iap. If p is not constant, then the motion is cyclic. In this work, we analyze locally (in time) periodic motion, which approximates many natural forms of cyclic motion. Periodic motion can also be defined in terms of symmetry. Informally, spatial symmetry is self-similarity under a class of transformations, usually the group of Euclidean transformations in the plane (translations, rotations, and reflections) <ref type="bibr" target="#b35">[36]</ref>. Periodic motion has a temporal (and sometimes spatial) symmetry. For example, Figs. 3a, 4a, 5a, and 6a show four simple dynamic systems (pendulums). For each system, the motion is such that t p t for a point t on the pendulum. However, each system exhibits qualitatively different types of periodic motion. Fig. <ref type="figure" target="#fig_5">5a</ref> is a simple planar pendulum with a fixed rod under a gravitational field. The motion of this system gives it a temporal mirror symmetry along the shown vertical axis. The system in Fig. <ref type="figure" target="#fig_4">4a</ref> is a similar pendulum, but with sufficient initial velocity such that it always travels in one angular direction. The motion of this system gives it a temporal mirror symmetry along the shown vertical axis. The system in Fig. <ref type="figure" target="#fig_3">3a</ref> is a similar pendulum, but in zero gravity; note it has an infinite number of axes of symmetry that pass through the pivot of the pendulum. The system in Fig. <ref type="figure" target="#fig_6">6a</ref> consists of a pair of uncoupled and IVH out of phase pendulums, a system which is often used to model the upper leg motion of humans <ref type="bibr" target="#b23">[24]</ref>. This system has a temporal mirror symmetry along the shown vertical axis, as well as an approximate spatial mirror symmetry along the same vertical axis (it is approximate because the pendulums are not identical).</p><p>The above examples illustrate that while (1) can be used to detect periodicity, it is not sufficient to classify different types of periodic motion. For classification purposes, it is necessary to exploit the dynamics of the system of interest, which we do in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Assumptions</head><p>In this work, we make the following assumptions: 1) the orientation and apparent size of the segmented objects do not change significantly during several periods (or do so periodically); 2) the frame rate is sufficiently fast for capturing the periodic motion (at least double the highest frequency in the periodic motion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Contributions</head><p>The main contribution of this work is the introduction of novel techniques to robustly detect and analyze periodic motion. We have demonstrated these techniques with video of the quality typically found in both ground and airborne surveillance systems. Of particular interest is the utilization of the symmetries of motion exhibited in nature, which we use for object classification. We also provide several other novel applications of periodic motion, all related to automating a surveillance system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Organization of the Paper</head><p>In Section 2, we review and critique the related work. The methodology is described in Section 3. Examples and applications of periodic motion, particularly for the automated surveillance domain, are given in Section 4. A realtime implementation of the methods is discussed in Section 5, followed by a summary of the paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There has been recent interest in segmenting and analyzing periodic or cyclic motion. Existing methods can be categorized as those requiring point correspondences <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b34">[35]</ref>; those analyzing periodicities of pixels <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b29">[30]</ref>; those analyzing features of periodic motion <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>; and those analyzing the periodicities of object similarities <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Related work has been done in analyzing the rigidity of moving objects <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Below we review and critique each of these methods. Due to some similarities with the presented method, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b29">[30]</ref> are described in more detail than the other related work.</p><p>Seitz and Dyer <ref type="bibr" target="#b32">[33]</ref> compute a temporal correlation plot for repeating motions using different image comparison functions, d e and d s . The affine comparison function d e allows for view-invariant analysis of image motion, but requires point correspondences (which are achieved by tracking reflectors on the analyzed objects). The image comparison function d s computes the sum of absolute differences between images. However, the objects are not tracked and, thus, must have nontranslational periodic motion in order for periodic motion to be detected. Cyclic motion is analyzed by computing the period-trace, which are curves that are fit to the surface d. Snakes are used to fit these curves, which assumes that d is well-behaved near zero so that near-matching configurations show up as local minima of d. The K-S test is utilized to classify periodic and nonperiodic motion. The samples used in the K-S test are the correlation matrix w and the hypothesized period-trace . The null hypothesis is that the motion is not periodic, i.e., the cumulative distribution function w and are not significantly different. The K-S test rejects the null hypothesis when periodic motion is present. However, it also rejects the null hypothesis if w is nonstationary. For example, when w has a trend, the cumulative distribution function of w and can be significantly different, resulting in classifying the motion as periodic (even if no periodic motion present). This can occur if the viewpoint of the object or lighting changes significantly during evaluation of w (see Fig. <ref type="figure" target="#fig_18">19a</ref>). The basic weakness of this method is it uses a one-sided hypothesis test which assumes stationarity. A stronger test is needed to detect periodicity in nonstationary data, which we provide in Section 3.4.</p><p>Polana and Nelson <ref type="bibr" target="#b29">[30]</ref> recognize periodic motions in an image sequence by first aligning the frames with respect to the centroid of an object so that the object remains stationary in time. Reference curves, which are lines parallel to the trajectory of the motion flow centroid, are extracted and the spectral power is estimated for the image signals along these curves. The periodicity measure of each reference curve is defined as the normalized difference between the sum of the spectral energy at the highest amplitude frequency and its multiples and the sum of the energy at the frequencies half way between.</p><p>Tsai et al. <ref type="bibr" target="#b34">[35]</ref> analyze the periodic motion of a person walking parallel to the image plane. Both synthetic and real walking sequences are analyzed. For the real images, point correspondences were achieved by manually tracking the joints of the body. Periodicity was detected using Fourier analysis of the smoothed spatio-temporal curvature function of the trajectories created by specific points on the body as it performs periodic motion. A motion-based recognition application is described in which one complete cycle is stored as a model and a matching process is performed using one cycle of an input trajectory. Allmen <ref type="bibr" target="#b0">[1]</ref> used spatio-temporal flow curves of edge image sequences (with no background edges present) to analyze cyclic motion. Repeating patterns in the ST flow curves are detected using curvature scale-space. A potential problem with this technique is that the curvature of the ST flow curves is sensitive to noise. Such a technique would likely fail on very noisy sequences, such as that shown in Fig. <ref type="figure" target="#fig_5">15</ref>.</p><p>Niyogi and Adelson <ref type="bibr" target="#b26">[27]</ref> analyze human gait by first segmenting a person walking parallel to the image plane using background subtraction. A spatio-temporal surface is fit to the XYT pattern created by the walking person. This surface is approximately periodic and reflects the periodicity of the gait. Related work <ref type="bibr" target="#b25">[26]</ref> used this surface (extracted differently) for gait recognition.</p><p>Liu and Picard <ref type="bibr" target="#b20">[21]</ref> assume a static camera and use background subtraction to segment motion. Foreground objects are tracked and their path is fit to a line using a Hough transform (all examples have motion parallel to the image plane). The power spectrum of the temporal histories of each pixel is then analyzed using Fourier analysis and the harmonic energy caused by periodic motion is estimated. An implicit assumption in <ref type="bibr" target="#b20">[21]</ref> is that the background is homogeneous (a sufficiently nonhomogeneous background will swamp the harmonic energy). Our work differs from <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b29">[30]</ref> in that we analyze the periodicities of the image similarities of large areas of an object, not just individual pixels aligned with an object. Because of this difference (and the fact that we use a smooth image similarity metric), our Fourier analysis is much simpler since the signals we analyze do not have significant harmonics of the fundamental frequency. The harmonics in <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b29">[30]</ref> are due to the large discontinuities in the signal of a single pixel; our self-similarity metric does not have such discontinuities.</p><p>Fujiyoshi and Lipton <ref type="bibr" target="#b9">[10]</ref> segment moving objects from a static camera and extract the object boundaries. From the object boundary, a ªstarº skeleton is produced, which is then Fourier analyzed for periodic motion. This method requires accurate motion segmentation, which is not always possible (e.g., see Fig. <ref type="figure" target="#fig_13">16</ref>). Also, objects must be segmented individually; no partial occlusions are allowed (as shown in Fig. <ref type="figure" target="#fig_20">21a</ref>). In addition, since only the boundary of the object is analyzed for periodic change (and not the interior of the object), some periodic motions may not be detected (e.g., a textured rolling ball, or a person walking directly toward the camera).</p><p>Selinger and Wixson <ref type="bibr" target="#b33">[34]</ref> track objects and compute selfsimilarities of that object. A simple heuristic using the peaks of the 1D similarity measure is used to classify rigid and nonrigid moving objects, which in our tests fails to classify correctly for noisy images (e.g., the sequence in Fig. <ref type="figure" target="#fig_5">15</ref>).</p><p>Heisele and Wohler <ref type="bibr" target="#b13">[14]</ref> recognize pedestrians using color images from a moving camera. The images are segmented using a color/position feature space and the resulting clusters are tracked. A quadratic polynomial classifier extracts those clusters which represent the legs of pedestrians. The clusters are then classified by a time delay neural network, with spatio-temporal receptive fields. This method requires accurate object segmentation. A 3-CCD color camera was used to facilitate the color clustering and pedestrians are approximately 100 pixels in height. These image qualities and resolutions are typically not found in surveillance applications.</p><p>There has also been some work done in classifying periodic motion. Polana and Nelson <ref type="bibr" target="#b29">[30]</ref> use the dominant frequency of the detected periodicity to determine the temporal scale of the motion. A temporally scaled XYT template, where XY is a feature based on optical flow, is used to match the given motion. The periodic motions include walking, running, swinging, jumping, skiing, jumping jacks, and a toy frog. This technique is view dependent and has not been demonstrated to generalize across different subjects and viewing conditions. Also, since optical flow is used, it will be highly susceptible to image noise.</p><p>Cohen et al. <ref type="bibr" target="#b4">[5]</ref> classify oscillatory gestures of a moving light by modeling the gestures as simple one-dimensional ordinary differential equations. Six classes of gestures are considered (all circular and linear paths). This technique requires point correspondences and has not been shown to work on arbitrary oscillatory motions.</p><p>Area-based techniques, such as the present method, have several advantages over pixel-based techniques, such as <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Specifically, area-based techniques allow the analysis of the dynamics of the entire object, which is not achievable by pixel-based techniques. This allows for classification of different types of periodic motion, such as those given in Section 4.1 and Section 4.4. In addition, areabased techniques allow detection and analysis of periodic motion that is not parallel to the image plane. All examples given in <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b20">[21]</ref> have motion parallel to the image plane, which ensures there is sufficient periodic pixel variation for the techniques to work. However, since area-based methods compute object similarities which span many pixels, the individual pixel variations do not have to be large. For example, our method can detect periodic motion from video sequences of people walking directly toward the camera. A related benefit is that area-based techniques allow the analysis of low S/N images, such as that shown in Fig. <ref type="figure" target="#fig_13">16</ref>, since the S/N of the object similarity measure (such as ( <ref type="formula">5</ref>)) is higher than that of a single pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>The algorithm for periodicity detection and analysis consists of two parts. First, we segment the motion and track objects in the foreground. We then align each object along the temporal axis (using the object's tracking results) and compute the object's self-similarity as it evolves in time. For periodic motions, the self-similarity metric is periodic and we apply Time-Frequency analysis to detect and characterize the periodicity. The periodicity is also analyzed robustly using the 2D lattice structures inherent in similarity matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motion Segmentation and Tracking</head><p>Given an image sequence s t from a moving camera, we segment regions of independent motion. The images s t are first Gaussian filtered to reduce noise, resulting in s Ã t . The image s Ã t is then stabilized <ref type="bibr" target="#b11">[12]</ref> with respect to image s Ã tÀ( , resulting in tYtÀ( . The images tYtÀ( and s Ã t are differenced and thresholded to detect regions of motion, resulting in a binary motion image:</p><formula xml:id="formula_0">w tYÀ( I if s Ã t À tYtÀ( b w H otherwiseY @ P</formula><p>where w is a threshold. In order to eliminate false motion at occlusion boundaries (and help filter spurious noise), the motion images w tY( and w tYÀ( are logically anded together:</p><formula xml:id="formula_1">w t w tYÀ( w tY( X Q</formula><p>An example of w t is shown in Fig. <ref type="figure" target="#fig_20">21b</ref>. Note that, for large values of (, motion parallax will cause false motion in w t .</p><p>In our examples (for a moving camera), ( = 300 ms was used.</p><p>Note that, in many surveillance applications, images are acquired using a camera with automatic gain, shutter, and exposure. In these cases, normalizing the image mean before comparing images s t I and s t P will help minimize false motion due to a change in the gain, shutter, or exposure.</p><p>A morphological open operation is performed on w t (yielding w Ã t ), which reduces motion due to image noise.</p><p>The connected components for w Ã t are computed and small components are eliminated (further reducing image noise). The connected components which are spatially similar (in distance) are then merged and the merged connected components are added to a list of objects y t to be tracked. An object has the following attributes: area, centroid, bounding box, velocity, ID number, and age (in frames). Objects in y t and y tk , k b H, are corresponded using spatial and temporal coherency.</p><p>It should be noted that the tracker is not required to be very accurate, as the self-similarity metric we use is robust and can handle tracking errors of several pixels (as measured in our examples).</p><p>Also note that, when the background of a tracked object is sufficiently homogeneous, and the tracked object does not change size significantly during several periods, then accurate object segmentation is not necessary. In these cases, we can allow y t to include both the foreground and background. Examples of such backgrounds include grassy  fields, dirt roads, and parking lots. An example of such a sequence is given in Fig. <ref type="figure" target="#fig_5">15</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Periodicity Detection and Analysis</head><p>The output of the motion segmentation and tracking algorithm is a set of foreground objects, each of which has a centroid and size. To detect periodicity for each object, we first align the segmented object (for each frame) using the object's centroid and resize the objects (using a Mitchell filter <ref type="bibr" target="#b31">[32]</ref>) so that they all have the same dimensions. The scaling is required to account for an apparent size change due to change in distance from the object to the camera. Because the object segmentation can be noisy, the object dimensions are estimated using the median of x frames (where x is the number of frames we analyze the object over). The object y t 's self-similarity is then computed at times t I and t P . While   many image similarity metrics can be defined (e.g., normalized cross-correlation, Hausdorff distance <ref type="bibr" target="#b14">[15]</ref>, color indexing <ref type="bibr" target="#b1">[2]</ref>), perhaps the simplest is absolute correlation:</p><formula xml:id="formula_2">t I Y t P xYyPf t I y tI xY y À y tP xY y j j Y R</formula><p>where f t I is the bounding box of object y t I . In order to account for tracking errors, the minimal is found by translating over a small search radius r:</p><formula xml:id="formula_3">H t I Y t P min dxYdy j j `r</formula><p>xYyPft I y tI x dxY y dy À y tP xY y j j X S For periodic motions, H will also be periodic. For example, Fig. <ref type="figure">8a</ref> shows a plot of H for all combinations of t I and t P for a walking sequence (the similarity values have been linearly scaled to the gray-scale intensity range [0, 255]; dark regions show more similarity). Note that a similarity plot should be symmetric along the main diagonal; however, if substantial image scaling is required, this will not be the case. In addition, there will always be a dark line on the main diagonal (since an object is similar to itself at any given  time) and periodic motions will have dark lines (or curves if the period is not constant) parallel to the diagonal.</p><p>To determine if an object exhibits periodicity, we estimate the 1D power spectrum of H t I Y t P for a fixed t I and all values of t P (i.e., the columns of H ). In estimating the spectral power, the columns of H are linearly detrended and a Hanning filter is applied. A more accurate spectrum is estimated by averaging the spectra of multiple t I s <ref type="bibr" target="#b30">[31]</ref> to get a final power estimate f i , where f i is the frequency. Periodic motion will show up as peaks in this spectrum at the motion's fundamental frequencies. A peak at frequency f i is significant if</p><formula xml:id="formula_4">f i b " u' Y T</formula><p>where u is a threshold value (typically 3), " is the mean of , and ' is the standard deviation of . Note that multiple peaks can be significant, as we will see in the examples.</p><p>In the above test, we assume that the period is locally constant. The locality is made precise using Time-Frequency analysis given in Section 3.3. We also assume that there are only linear amplitude modulations to the columns of H (so that linear detrending is sufficient to make the data stationary) and that any additive noise to H is Gaussian. Both of these assumptions are relaxed in the method given in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Fisher's Test</head><p>If we assume that columns of H are stationary and contaminated with white noise, and that any periodicity present consists of a single fundamental frequency, then we can apply the well-known Fisher's test <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Fisher's test will reject the null hypothesis (that H is only white noise) if f i is substantially larger than the average value. Assuming x is even, let q x À IaP and</p><formula xml:id="formula_5">i q q mx I i q f i q iI f i X U</formula><p>To apply the test, we compute the realized value x of i q from H and then compute the probability:</p><formula xml:id="formula_6">i q ! x I À q jH ÀI j q j I À jxaq qÀI Y V</formula><p>where z mxzY H. If this probability is less than , then we reject the null hypothesis at level (in practice, we use HXHS). This test is optimal if there exists a single periodic component at a Fourier frequency f i in white noise stationary data <ref type="bibr" target="#b28">[29]</ref>. To test for periodicities containing multiple frequencies, Seigel's test <ref type="bibr" target="#b28">[29]</ref> can be applied.</p><p>In practice, Fisher's test, like the K-S test used by <ref type="bibr" target="#b32">[33]</ref>, works well if the periodic data is stationary with white noise. However, in most of our nonperiodic test data (e.g., Fig. <ref type="figure" target="#fig_18">19a</ref>), which is not stationary, both Fisher's and the K-S test yield false periodicities with high confidence.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Recurrence Matrices</head><p>It is interesting to note that H is a recurrence matrix <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b3">[4]</ref>, without using time-delayed embedded dimensions. Recurrence matrices are a qualitative tool used to perform time series analysis of nonlinear dynamical systems (both periodic and nonperiodic). Recurrence matrices make no assumptions on the stationarity of the data and do not require many data points to be used (a few cycles of periodic data is sufficient). The input for a recurrence matrix is a multidimensional temporally sampled signal. In our use, the input signal is the tracked object image sequence y t and the distance measure is image similarity. Given a recurrence matrix, the initial trajectory t of a point on an object can be recovered up to an isometry <ref type="bibr" target="#b22">[23]</ref>. Therefore, the recurrence plot encodes the spatiotemporal dynamics of the moving object. The similarity plot encodes a projection of spatiotemporal dynamics of the moving object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Time-Frequency Analysis</head><p>For stationary periodicity (i.e., periodicity with statistics that don't change with time), the above analysis is sufficient. However, for nonstationary periodicity, Fourier analysis is not appropriate. Instead, we use Time-Frequency analysis and the Short-Time Fourier Transform (STFT) <ref type="bibr" target="#b27">[28]</ref>:</p><formula xml:id="formula_7">p x tY vY h I ÀI xuh Ã u À te iP%vu duY W</formula><p>where h Ã u À t is a short-time analysis window and xu is the signal to analyze ( H in our case). The short-time analysis window effectively suppresses the signal xu outside a neighborhood around the analysis time point u t. Therefore, the STFT is a ªlocalº spectrum of the signal xu around t.</p><p>We use a Hanning windowing function as the short-time analysis window. The window length should be chosen to be long enough to achieve a good power spectrum estimate, but short enough to capture a local change in the periodicity. In practice, a window length equal to several periods works well for typical human motions. An example of nonstationary periodicity is given in Section 4.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Robust Periodicity Analysis</head><p>In Section 3.2, we used a hypothesis test on the 1D power spectrum of H to determine if H contained any periodic motion. The null hypothesis is that there is only white noise in the spectrum, which is rejected by <ref type="bibr" target="#b5">(6)</ref> if significant periodic motion is present. However, the null hypothesis can also be rejected if H contains significant non-Gaussian noise, or if the period is locally nonconstant, or if H is amplitude modulated nonlinearly. We seek a technique that minimizes the number of false periodicities while maximizing the number of true periodicities. Toward this end, we devise a test that performs well when the assumptions stated in Section 3.2 are satisfied, but does not yield false periodicities when these assumptions are violated.</p><p>An alternative technique to Fourier analysis of the 1D columns of is to analyze the 2D power spectrum of H . However, as noted in <ref type="bibr" target="#b18">[19]</ref>, the autocorrelation of H for regular textures has more prominent peaks than those in the 2D Fourier spectrum. Let e be the normalized autocorrelation of H :</p><formula xml:id="formula_8">ed x Y d y xYyP H xYyÀ " H H xdxYydyÀ " H v xYyP H xYyÀ " H P xYyP H xdx Yydy À " H v P HXS Y IH</formula><p>where " H is the mean of H over the region , " H v is the mean of H over the region shifted by the lag dxY dy, and the regions and v cover H and the lagged H . If H is periodic, then e will have peaks regularly spaced in a planar lattice w d , where d is the distance between the lattice points. In our examples, we will consider two lattices, a square lattice w Yd (Fig. <ref type="figure" target="#fig_2">2a</ref>), and a RS rotated square lattice w Yd (Fig. <ref type="figure" target="#fig_2">2b</ref>). The peaks in e are matched to w d using the match error measure e:   </p><formula xml:id="formula_9">i i wdYiÀij min jT i jw dYi À j jjw dYi À i j h e i ! e n o II ew d i jw dYi À f i jY IP</formula><p>where f i is the closest peak to the lattice point w dYi , h ( h `daP) is the maximum distance i can deviate from w dYi , and e is the minimum autocorrelation value that the matched peak may have. w d matches if all the following are satisfied: Peaks in e are determined by first smoothing e with a Gaussian filter q, yielding e Ã . e Ã iY j is a peak if e Ã iY j is a strict maximum in a local neighborhood with radius x. In our examples, q is a S Â S filter with ' I and x S. Lin et al. <ref type="bibr" target="#b18">[19]</ref> provide an automatic method for determining the optimal size of q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXAMPLES AND APPLICATIONS 4.1 Synthetic Data</head><p>In this section, we demonstrate the methods on synthetic data examples. We generated images of a periodic planar pendulum, with different initial conditions, parameters, and configurations. Note that the equation of motion for a simple planar pendulum is</p><formula xml:id="formula_10">d P dt P g v sin HY IS</formula><p>where g is the gravitational acceleration, v is the length of the rigid rod, and is the angle between the pendulum rod and vertical axis <ref type="bibr" target="#b21">[22]</ref>. In the first example (see Fig. <ref type="figure" target="#fig_3">3a</ref>), we set g H so that the pendulum has a circular motion with a constant angular velocity. The diagonal lines in the similarity plot (Fig. <ref type="figure" target="#fig_3">3b</ref>) are formed due to the self-similarity of the pendulum at every complete cycle. The autocorrelation (Fig. <ref type="figure" target="#fig_3">3c</ref>) has no peaks.</p><p>In the next example, we use the same configuration, but set g b H and the initial angular velocity to be sufficient so that the pendulum still has a single angular direction. However, in this configuration, the angular velocity is not  constant, which is reflected in the qualitatively different similarity plot (Fig. <ref type="figure" target="#fig_4">4b</ref>) and autocorrelation (Fig. <ref type="figure" target="#fig_4">4c</ref>). Note that the peaks in e match the lattice structure in Fig. <ref type="figure" target="#fig_2">2a</ref>.</p><p>By decreasing the initial angular velocity, the pendulum will oscillate with a changing angular direction, as shown in Fig. <ref type="figure" target="#fig_5">5a</ref>. The similarity plot for this system is shown in Fig. <ref type="figure" target="#fig_5">5b</ref> and the autocorrelation in Fig. <ref type="figure" target="#fig_5">5c</ref>. Note that the peaks in e match the lattice structure in Fig. <ref type="figure" target="#fig_2">2b</ref>.</p><p>Finally, for the system of two pendulums IVH out of phase, shown in Fig. <ref type="figure" target="#fig_6">6a</ref>, the similarity plot is shown in Fig. <ref type="figure" target="#fig_6">6b</ref> and the autocorrelation is shown in Fig. <ref type="figure" target="#fig_6">6c</ref>. Note that the peaks in e match the lattice structure in Fig. <ref type="figure" target="#fig_2">2b</ref>. Also note the lower measures of similarity for the diagonal lines H tY t k IaPp and the cross-diagonal lines tY k IaPp À t, and the corresponding effect on e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Symmetry of a Walking Person</head><p>In this example, we first analyze periodic motion with no (little) translational motion, a person walking on a treadmill (Fig. <ref type="figure" target="#fig_7">7</ref>). This sequence was captured using a static JVC KY-F55B color camera at TRH Â RVH at 30fps, deinterlaced, and scaled to ITH Â IPH. Since the camera is static and there is no   translational motion, background subtraction was used to segment the motion <ref type="bibr" target="#b5">[6]</ref>.</p><p>The similarity plot H for this sequence is shown in Fig. <ref type="figure">8a</ref>. The dark lines correspond to two images in the sequence that are similar. The darkest line is the main diagonal since H tY t H. The dark lines parallel to the main diagonal are formed since H tY kpaP t 9 H, where p is the period, and k is an integer. The dark lines perpendicular to the main diagonal are formed since H tY kpaP À t 9 H and is due to the symmetry of human walking (see Fig. <ref type="figure" target="#fig_9">10</ref>).</p><p>It is interesting to note that, at the intersections of these lines, these images are similar to either Fig. <ref type="figure" target="#fig_7">7a</ref>, 7b, or 7c, (see Fig. <ref type="figure">8b</ref>). That is, H encodes the phase of the person walking, not just the period. This fact is exploited in the example in Section 4.5.</p><p>The autocorrelation e of H is shown in Fig. <ref type="figure">9b</ref>. The peaks in e form a RS rotated square lattice (Fig. <ref type="figure" target="#fig_2">2b</ref>), which is used for object classification (Section 4.4). Note that the magnitude of the peaks in e (Fig. <ref type="figure">9b</ref>) have a pattern similar to the e in Fig. <ref type="figure" target="#fig_6">6c</ref>.</p><p>We next analyze the motion of a person who is walking at an approximately PS offset to the camera's image plane from a static camera. (Fig. <ref type="figure" target="#fig_10">11a</ref>). The segmented person is approximately 20 pixels in height, and is shown in Fig. <ref type="figure" target="#fig_2">12a</ref>. The similarity plot (Fig. <ref type="figure" target="#fig_10">11a</ref>) shows dark diagonal lines at a period of approximately 1 second (32 frames), which correspond to the period of the person's walking. The lighter diagonal lines shown with a period of approximately 0.5 seconds (16 frames) are explained by first noting that the person's right arm swing is not fully visible (due to the PS offset to the image plane). Therefore, it takes two steps for the body to be maximally self-similar, while the legs become very self-similar at every step. The effect of this is that the similarity measure H is the composition of two periodic signals, with periods differing by a factor of two. This is shown in Fig. <ref type="figure" target="#fig_2">12b</ref>, where the aligned object image is partitioned into three segments (the upper 25 percent, next 25 percent, and lower 50 percent of the body) and H is computed for each segment. The upper 25 percent, which includes the head and shoulders, shows no periodic motion; the next 25 percent, which includes the one visible arm, has a period double that of the lower 50 percent (which includes the legs). Fig. <ref type="figure" target="#fig_2">12c</ref> shows the average power spectrum for all the columns in H .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Symmetry of a Running Dog</head><p>In this example, we look at the periodicity of a running dog from a static camera. Fig. <ref type="figure" target="#fig_3">13</ref> shows a complete cycle of a dog (a Black Labrador). Unlike the symmetry of a walking or running person, a running dog has a lack of similarity for H tY kp À t. This results in the similarity plot (Fig. <ref type="figure" target="#fig_4">14a</ref>) having dark lines parallel to the main diagonal, formed by H tY kp t, but no lines perpendicular to the main diagonal (as with a walking/running person). The similarity plot has peaks (Fig. <ref type="figure" target="#fig_4">14a</ref>) that correspond to poses of the dog at frame 0 in Fig. <ref type="figure" target="#fig_3">13</ref>. The autocorrelation e of H is shown in Fig. <ref type="figure" target="#fig_4">14b</ref>; the peaks in e form a square lattice (Fig. <ref type="figure" target="#fig_2">2a</ref>), which is used in Section 4.4 for object classification. Fig. <ref type="figure" target="#fig_2">22</ref>. Similarity plots and spectral power for three people in Fig. <ref type="figure" target="#fig_20">21a</ref>. Note that the frequency resolution is not as high as in Fig. <ref type="figure" target="#fig_16">18</ref> since fewer frames are used to estimate the power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Object Classification Using Periodicity</head><p>A common task in an automated surveillance system is to classify moving objects. In this example, we classify three types of moving objects: people, dogs, and other. We use the lattice fitting method described in Section 3.4 for classification, which is motivated by texture classification methods. Specifically, the square lattice w (Fig. <ref type="figure" target="#fig_2">2a</ref>) is used to classify running dogs and the RS square lattice w (Fig. <ref type="figure" target="#fig_2">2b</ref>) is used to classify walking or running people. Note that w Yd is a subset of w Yd , so if both w Yd and w Yd match, w is declared the winner. If neither lattice provides a good match to e, then the moving object is classified as other.</p><p>The video database used to test the classification consists of video from both airborne surveillance (people and vehicles) and ground surveillance (people, vehicles, and dogs). The database consists of 30 vehicle sequences (25 from airborne video); 55 person sequences (50 from airborne video); and 4 dog sequences (all from ground video).</p><p>For the airborne video and dog sequences, the background was not segmented from the foreground object. For these sequences, the background was sufficiently homogeneous (e.g., dirt roads, parking lots, grassy fields) for this method to work. For the other sequences (taken with a static camera), the background was segmented as described in <ref type="bibr" target="#b5">[6]</ref>.</p><p>The airborne video in Fig. <ref type="figure" target="#fig_5">15</ref> was recorded from a Sony XC-999 camera (TRH Â PRH at 30fps) at an altitude of about 1,500 feet. There is significant motion blur due to a slow shutter speed and fast camera motion. Additional noise is induced by the analog capture of the video from duplicated SVHS tape. Fig. <ref type="figure" target="#fig_5">15</ref> shows a person running across a parking lot. The person is approximately IP Â U pixels in size (Fig. <ref type="figure" target="#fig_13">16</ref>). The similarity plot in Fig. <ref type="figure" target="#fig_17">17a</ref> shows a clearly periodic motion, which corresponds to the person running. Fig. <ref type="figure" target="#fig_16">18</ref> shows that the person is running with a frequency of 1.3Hz; the second peak at 2.6Hz is due to the symmetry of the human motion described in Section 4.2. The autocorrelation of H is shown in Fig. <ref type="figure" target="#fig_17">17b</ref>. Fig. <ref type="figure" target="#fig_18">19b</ref> shows the similarity plot for the vehicle in Fig. <ref type="figure" target="#fig_18">19a</ref>, which has no periodicity. The spectral power for the vehicle (Fig. <ref type="figure" target="#fig_19">20b</ref>) is flat. The autocorrelation of H has only 2 peaks (Fig. <ref type="figure" target="#fig_19">20a</ref>). The results of the classifications are shown in Table <ref type="table" target="#tab_0">1</ref>. The thresholds used for the lattice matching are those given in Section 3.4. Each sequence is 100 images (30 fps); a lag time of 30 images (1 second) is used to compute e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Counting People</head><p>Another common task in an automated surveillance system is to count the number of people entering and leaving an area. This task is difficult since, when people are close to each other, it is not always simple to distinguish the individuals. For example, Fig. <ref type="figure" target="#fig_20">21a</ref> is a frame from an airborne video sequence that shows three people running along a road and the result of the motion segmentation (Fig. <ref type="figure" target="#fig_20">21b</ref>). Simple motion blob counting will give an inaccurate estimate of the number of people. However, if we know the approximate location of the airplane (via GPS) and have an approximate site model (a ground plane), we can estimate what the expected image size of an ªaverageº person should be. This size is used to window a region with motion for periodic detection. In this example, three nonoverlapping windows were found to have periodic motion, each corresponding to a person. The similarity plots and spectral powers are shown in Fig. <ref type="figure" target="#fig_2">22</ref>.</p><p>The similarity plots in Fig. <ref type="figure" target="#fig_2">22</ref> can also be used to extract the phase angle of the running person. The phase angle is encoded in the position of the cross diagonals of H . In this example, the phase angles are all significantly different from one another, giving further evidence that we have not over counted the number of people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Simple Event Detection</head><p>In this example, we show how periodicity can be used as input for event detection. Fig. <ref type="figure" target="#fig_21">23a</ref> shows a person walking through a low contrast area (in a shadow) toward the camera; halfway through the 200 image sequence the person stops swinging his arms and puts them into his pockets. This action is shown on the similarity plots for the upper and lower portions of the body. Specifically, in Fig. <ref type="figure" target="#fig_21">23c</ref>, a periodic pattern for the upper part of the body is visible for the images <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">100]</ref>, but not for <ref type="bibr">[101,</ref><ref type="bibr">200]</ref>. This is further shown by the significant peak in the power spectrum for the images [1,100] (Fig. <ref type="figure" target="#fig_22">24a</ref>) and the lack of significant peaks in the power spectrum for the images [101, 200] (Fig. <ref type="figure" target="#fig_22">24b</ref>). Thus, while the image of the person is only 37 pixels high in this sequence and we are not tracking his body parts, we can deduce that he stopped swinging his arms at about frame 100. An automated surveillance system can use this technique to help decide if someone is carrying an object. In <ref type="bibr" target="#b12">[13]</ref>, we combine periodicity and shape analysis to detect if someone is carrying an object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Nonstationary Periodicity</head><p>In this example, a person is walking, and roughly half way through the sequence, starts to run (see Fig. <ref type="figure" target="#fig_24">25a</ref>). The similarity plot (Fig. <ref type="figure" target="#fig_24">25b</ref>) clearly shows this transition. Using a short-time analysis windowing Hanning function of length 3,300 ms (100 frames), the power is estimated in the walking and running stages (Fig. <ref type="figure" target="#fig_23">26</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Estimating Human Stride Using Periodicity</head><p>In <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b19">[20]</ref>, human gait was used for person recognition. In this example, we do not analyze the gait (which is how people walk or run), but rather estimate the stride length of a walking or running person. The stride itself can be useful for person recognition, particularly during tracking. For example, stride length can help object (person) correspondence after occlusions. Stride length can also be used for input to a surveillance system to detect auto theft in a parking area (e.g., a person of different size and stride length drove off with a car than the person who drove in with the car).</p><p>Assume the area of surveillance has a site model, and the camera is calibrated. The estimated stride length is v v g p, where v g is the ground velocity of the person, and p is the period. For best results, v g and p should be filtered to reduce the inherent noise in the tracking and period estimation. For example, in Fig. <ref type="figure" target="#fig_24">25a</ref>, the estimated stride of the person is 22 inches when walking and 42 inches when running, which is within 2 inches of the person's actual stride.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">REAL-TIME SYSTEM</head><p>A real-time system has been implemented to track and classify objects using periodicity. The system uses a dual Processor 550MHz Pentium III Xeon-based PC and runs at 15Hz with TRH Â PRH gray-scale images captured from an airborne video camera. The system uses the real-time stabilization results from <ref type="bibr" target="#b11">[12]</ref>. We will briefly discuss how the method can be efficiently implemented to run on a real-time system. In computing H , for each new frame, only a single column that corresponds to the new frame needs to be recomputed; the remaining entries can be reused (shifted) for the updated H . Therefore, for each new frame, only yx H iY j computations need to be done, where x is the number of rows and columns in H .</p><p>For computing e, the 2D FFT can be utilized to greatly decrease the computational cost <ref type="bibr" target="#b17">[18]</ref>.</p><p>Finally, SIMD instructions, such as those available on the Pentium III, can be utilized for computing H iY j, as well as e (either directly or using the FFT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have described new techniques to detect and analyze periodic motion as seen from both a static and moving camera. By tracking objects of interest, we compute an object's self-similarity as it evolves in time. For periodic motion, the self-similarity measure is also periodic and we apply Time-Frequency analysis to detect and characterize the periodic motion. The periodicity is also analyzed robustly using the 2D lattice structures inherent in similarity matrices.</p><p>Future work includes using alternative independent motion algorithms for moving camera video, which could make the analysis more robust for nonhomogeneous backgrounds for the case of a moving camera. Further use of the symmetries of motion for use in classification of additional types of periodic motion is also being investigated.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Low resolution image sequences of a periodic motion (a person walking on a treadmill). The effective resolution is W Â IS pixels.</figDesc><graphic coords="2,136.29,69.17,293.84,82.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Lattices used to match the peaks of the autocorrelation of H . (a) Square lattice (b) RS rotated square lattice.</figDesc><graphic coords="4,82.03,69.17,402.35,225.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Pendulum in zero gravity with a constant angular velocity. The arrows denote the direction of motion. (b) Similarity plot for pendulum. Darker pixels are more similar. (c) Autocorrelation of similarity plot.</figDesc><graphic coords="4,77.44,566.42,411.65,168.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) Pendulum in gravity with single angular direction. The arrows denote the direction and magnitude of motion; the pendulum travels faster at the bottom of its trajectory than at the top. (b) Similarity plot for pendulum. (c) Autocorrelation of similarity plot. The peaks are denoted by ª+º symbols.</figDesc><graphic coords="5,92.41,275.98,381.71,163.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (a) Pendulum in gravity with an oscillating angular direction. The arrows denote the direction of motion. (b) Similarity plot for pendulum. (c) Autocorrelation of similarity plot. The peaks are denoted by ª+ª symbols.</figDesc><graphic coords="5,92.64,472.48,381.20,162.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Two pendulum out of phase IVH in gravity. The arrows denote the direction of motion. (b) Similarity plot for pendulums. (c) Autocorrelation of similarity plot. The peaks are denoted by ª+º symbols.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Person walking on a treadmill.</figDesc><graphic coords="6,102.50,69.17,98.42,61.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. (a) Similarity plot for the person walking in Fig. 7. (b) Lattice structure for the upper left quadrant of (a). At the intersections of the diagonal and cross diagonal lines, the images are similar to Fig. 7a, 7b, and 7c. This can be used to determine the phase of the walking person.</figDesc><graphic coords="6,82.20,518.00,402.01,217.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig.10. Cycle of a person walking (p QP). Note the similarity of frame t and paP À t, and the similarity of frame t and paP t.</figDesc><graphic coords="7,95.64,69.17,375.25,112.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. (a) First image of a 100-image walking sequence (the subject is walking approximately PS offset from the camera's image plane). (b) Walking sequence similarity plot, which shows the similarity of the object (person) at times t I and t P . Dark regions show greater degrees of similarity.</figDesc><graphic coords="7,109.47,205.12,347.58,189.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .Fig. 13 .</head><label>1213</label><figDesc>Fig. 12. (a) Column 1 of Fig. 11b, with the corresponding segmented object for the local minima. (b) Image similarity for upper 25 percent, next 25 percent, and lower 50 percent of body. (c) Average power spectrum of all columns of Fig. 11b.</figDesc><graphic coords="8,112.37,69.17,341.80,367.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 .Fig. 15 .</head><label>1415</label><figDesc>Fig. 14. (a) Similarity plot of the running dog in Fig. 13. Note that there are no dark lines perpendicular to the main diagonal, as shown in Fig. 8a. (b) Autocorrelation of the similarity plot (smoothed with a S Â S ' I Gaussian filter). The peaks (shown with white ª+º symbols) are used to fit the square lattice in Fig. 2a.</figDesc><graphic coords="9,82.03,69.17,402.35,218.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 16 .</head><label>16</label><figDesc>Fig.<ref type="bibr" target="#b15">16</ref>. Zoomed images of the person in Fig.15, which correspond to the poses in Fig.7. The person is IP Â U pixels in size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>min dI d dP ew d `e Y IQ jfj ! w Y IR where e is a match threshold; d I Y d P is the range of d; w is the minimum number of points in w d to match. In practice, we let h I, e Pjw d j, e Pjw d j, and w HXWjw d jY e HXPS. The range d I Y d P determines the possible range of the expected period, with the requirement H `dI `dP `v, where v is the maximum lag used in computing e. The number of points in w and w can be based on the period of the expected periodicity and frame-rate of the camera. The period p Pd(, where ( is the sampling interval (e.g., ( QQ ms for NTSC video).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 18 .</head><label>18</label><figDesc>Fig.18. Spectral power of the running person in Fig.15.</figDesc><graphic coords="10,52.95,576.96,197.57,167.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. (a) Similarity plot of the running person in Fig. 15. (b) Autocorrelation of upper quadrant of H . The peaks are used to fit the RS rotated square lattice in Fig. 2b.</figDesc><graphic coords="10,82.32,69.17,401.90,216.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. (a) Vehicle driving across a parking lot. (b) Similarity plot of the vehicle.</figDesc><graphic coords="11,80.73,69.17,405.01,220.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. (a) Spectral power of the vehicle in Fig. 19a. (b) Autocorrelation of H of the vehicle in Fig. 19a (smoothed with a S Â S ' IGaussian filter). The peaks are denoted by ª+º symbols.</figDesc><graphic coords="11,81.58,312.95,403.31,216.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. (a) Three people running, viewed from a moving camera at an altitude of 1,500 feet. (b) Segmented motion.</figDesc><graphic coords="12,80.62,69.17,405.24,189.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 23 .</head><label>23</label><figDesc>Fig. 23. (a) Frame 100 from a low contrast 200 frame sequence; the subject (marked with a white arrow) puts his hands in his pockets halfway through the sequence. (b) Similarity plot of the lower 40 percent of the body. (c) Similarity plot of the upper 60 percent of the body. The periodicity ceases after the middle of the sequence.</figDesc><graphic coords="13,109.19,69.17,348.04,398.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 24 .</head><label>24</label><figDesc>Fig. 24. (a) Power spectra of the upper left quadrant of Fig. 23c. (b) Power spectra of the lower right quadrant of Fig. 23c.</figDesc><graphic coords="14,109.81,69.17,346.85,158.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 26 .</head><label>26</label><figDesc>Fig. 26. Spectral power for walking/running sequence in Fig. 25a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. (a) Person walking, then running. (b) Similarity plot of walking/running sequence.</figDesc><graphic coords="15,71.49,312.21,423.50,205.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 Confusion</head><label>1</label><figDesc>Matrix for Person, Dog, and Other Classification</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 22, NO. 8, AUGUST 2000</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The airborne video was provided by the DARPA Airborne Video Surveillance project. This paper was written under the support of contract DAAL-01-97-K-0102 (ARPA Order E653), DAAB07-98-C-J019, and AASERT Grant DAAH-04-96-1-0221.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">ªImage Sequence Description Using Spatiotemporal Flow Curves: Toward Motion-Based Recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Allmen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. of Wisconsin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Swain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ªColor Indexing,º Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Brockwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Davis</surname></persName>
		</author>
		<title level="m">Time Series: Theory and Methods</title>
		<imprint>
			<publisher>Spinger-Verlag</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><surname>Casdagli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªRecurrence Plots Revisited</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="12" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ªDynamic System Representation, Generation, and Recognition of Basic Oscillatory Motion Gestures</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koditschek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int&apos;l Conf. Automatic Face and Gesture Recognition</title>
		<meeting>IEEE Int&apos;l Conf. Automatic Face and Gesture Recognition</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ªView-Based Detection and Analysis of Periodic Motion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Pattern Recognition</title>
		<meeting>Int&apos;l Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1998-08">Aug. 1998</date>
			<biblScope unit="page">A14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
		<title level="m">ªReal-Time Periodic Motion Detection, Analysis, and Applications,º Proc. Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="326" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ªRecurrence Plots of Dynamical Systems</title>
		<author>
			<persName><forename type="first">P</forename><surname>Eckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Kamphorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ruelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Europhysics Letters</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="973" to="977" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ªThe Pigeon&apos;s Discrimination of Movement Patterns (Lissajous Figures) and Contour-Dependent Rotational Invariance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Emmerton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="573" to="588" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ªReal-Time Human Motion Analysis by Image Skeletonization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fujiyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Applications of Computer Vision, p. session 1A</title>
		<meeting>IEEE Workshop Applications of Computer Vision, p. session 1A</meeting>
		<imprint>
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Goddard</surname></persName>
		</author>
		<title level="m">ªThe Interpretation of Visual Motion: Recognizing Moving Light Displays,º Proc. IEEE Workshop Motion</title>
		<imprint>
			<date type="published" when="1989-03">Mar. 1989</date>
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Der Wal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burt</surname></persName>
		</author>
		<title level="m">ªReal-Time Scene Stabilization and Mosaic Construction,º Proc. DARPA Image Understanding Workshop</title>
		<imprint>
			<date type="published" when="1994-11">Nov. 1994</date>
			<biblScope unit="page" from="457" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ªBackpack: Detection of People Carrying Objects Using Silhouettes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Haritaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Computer Vision</title>
		<meeting>Int&apos;l Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ªMotion-Based Recognition of Pedestrians</title>
		<author>
			<persName><forename type="first">B</forename><surname>Heisele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Pattern Recognition</title>
		<meeting>Int&apos;l Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ªComparing Images Using the Hausdorff Distance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="805" to="863" />
			<date type="published" when="1993-09">Sept. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Johansson</surname></persName>
		</author>
		<title level="m">ªVisual Motion Perception,º Scientific Am</title>
		<imprint>
			<date type="published" when="1976-06">June 1976</date>
			<biblScope unit="volume">232</biblScope>
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ªVisual Position Stabilization in the Hummingbird Hawk Moth</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Macroglossum Stellatarum L. I. Behavioural Analysis,º J. Computer Physiology A</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="237" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<title level="m">ªFast Normalized Cross-Correlation,º Vision Interface</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ªExtracting Periodicity of a Regular Texture Based on Autocorrelation Functions</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-N</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="433" to="443" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd</surname></persName>
		</author>
		<title level="m">ªRecognizing People by Their Gate: The Shape of Motion,º Videre</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<title level="m">ªFinding Periodicity in Space and Time,º Proc. Int&apos;l Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="page" from="376" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Marion</surname></persName>
		</author>
		<title level="m">Classical Dynamics of Particles and Systems</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shelhamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ªRecurrence Matrices and the Preservation of Dynamical Properties</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="page" from="43" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Mcmahon</surname></persName>
		</author>
		<title level="m">Muscles, Reflexes, and Locomotion</title>
		<imprint>
			<publisher>Princeton Univ. Press</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ªRigidity Checking of 3D Point Correspondences Under Perspective Projection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcreynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">ªAnalyzing and Recognizing Walking Figures in XYT</title>
		<author>
			<persName><forename type="first">S</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Computer Vision and Pattern Recognition</title>
		<meeting>Int&apos;l Conf. Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1994-12">Dec. 1994</date>
			<biblScope unit="page" from="469" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adelson</surname></persName>
		</author>
		<title level="m">ªAnalyzing Gait with Spatiotemporal Surfaces,º Proc. IEEE Workshop Motion of Non-Rigid and Articulated Objects</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Oppenheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schafer</surname></persName>
		</author>
		<title level="m">Discrete-Time Signal Processing</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename></persName>
		</author>
		<title level="m">ªHarmonic Analysis,º Spectral Analysis for Physical Applications: Multitaper and Conventional Univariate Techniques</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ªDetection and Recognition of Periodic</title>
		<author>
			<persName><forename type="first">R</forename><surname>Polana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Non-Rigid Motion,º Int&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="282" />
			<date type="published" when="1997-07">June/July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vetterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Flannery</surname></persName>
		</author>
		<title level="m">Numerical Recipes in C</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Schumacher</surname></persName>
		</author>
		<title level="m">ªGeneral Filtered Image Rescaling,º Graphics Gems III</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Kirk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ed</forename><surname>Harcourt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Brace</forename><surname>Jovanovich</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ªView-Invariant Analysis of Cyclic Motion,º Int</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Selinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wixson</surname></persName>
		</author>
		<title level="m">ªClassifying Moving Objects as Rigid or Non-Rigid without Correspondences,º Proc. DARPA Image Understanding Workshop</title>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="page" from="341" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ªCyclic Motion Detection for Motion Based Recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kasparis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">603</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Weyl</surname></persName>
		</author>
		<title level="m">Symmetry</title>
		<imprint>
			<publisher>Princeton Univ. Press</publisher>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
