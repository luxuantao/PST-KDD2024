<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SPATIALLY ADAPTIVE STATISTICAL MODELING OF WAVELET IMAGE COEFFICIENTS AND ITS APPLICATION TO DENOISING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><surname>Kavanq Mzhqak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Beckman Institute</orgName>
								<address>
									<addrLine>405 N. Mathews Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Igor</forename><surname>Kozintsev</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Beckman Institute</orgName>
								<address>
									<addrLine>405 N. Mathews Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kannan</forename><surname>Ramchandran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ECE Department</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Beckman Institute</orgName>
								<address>
									<addrLine>405 N. Mathews Ave</addrLine>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SPATIALLY ADAPTIVE STATISTICAL MODELING OF WAVELET IMAGE COEFFICIENTS AND ITS APPLICATION TO DENOISING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">48C18675B5F650BE6E6D81A565833FE7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper deals with the application to denoising of a very simple but effective "local" spatially adaptive statistical model for the wavelet image representation that was recently introduced successfully in a compression context [l]. Motivated by the intimate connection between compression and denoising [2, 3, 41, this paper explores the significant role of the underlying statistical wavelet image model. The model used here, a simplified version of the one in [l], is that of a mixture process of independent component fields having a zero-mean Gaussian distribution with unknown variances (T: that are slowly spatially-varying with the wavelet coefficient location s. We propose to use this model for image denoising by initially estimating the underlying variance field using a Maximum Likelihood (ML) rule and then applying the Minimum Mean Squared error (MMSE) estimation procedure. In the process of variance estimation, we assume that the variance field is "locally" smooth to allow its reliable estimation, and use an adaptive window-based estimation procedure to capture the effect of edges. Despite the simplicity of our method, our denoising results compare favorably with the best reported results in the recent denoising literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION AND MOTIVATION</head><p>Accurate image modeling, whether done explicitly or implicitly, is a critical component to the effectiveness of almost all image processing tasks. For statistical-based approaches to image processing, the choice of an accurate statistical image model is critical. In [l], a simple yet effective statisticalbased spatially adaptive wavelet image model was used in defining a compression algorithm (the so-called Estimation-Quantization (EQ) coder) whose performance ranks among the best in the image coding literature. In this work, we apply a simpler version of that model to the task of image denoising, motivated by the intimate connection between compression and denoising that has been established recently (2, 3, 41, which we will discuss shortly. Here, we use a simplified version of the statistical image model of [l] in formulating a simple method of denoising that attains state-of-the-art performance on standard test images. The key ingredient is the use of spatial adaptivity in a very simple statistical framework.</p><p>While we consider the specific case of additive white Gaussian noise (AWGN) in this work, extensions to more general noise models are possible. In general, the denoising process involves the task of removing most of the artifacts due to noise while leaving the most important image components nearly undistorted. We choose the mean-squarederror (MSE) as the performance measure.</p><p>To motivate our approach, we discuss the relationship between image compression and image denoising. Historically, the problem of image compression has been the area of larger mass appeal and research activity. Partly as a result of this, the state-of-the-art in the image compression field seems to be the more mature of the two, especially with regard to the use of sophisticated and more realistic 'kea1 world" image models. On the other hand, the underlying relationship between the denoising and compression problems implies that the modeling maturity inherent in the successful state-of-the-art image coding algorithms may be effectively applied for the denoising problem as well. In fact, lossy data compression was proposed for denoising in [2]. The intuition behind this approach is that the "typically correlated signal is compressible but uncorrelated noise is not." This principle, in a more rigorous form, is the basis for so-called complexity regularized denoising algorithms. Indeed, many of the recently proposed promising statistical denoising methods owe their improved performance to the more powerful image models that they derive inspired by state-of-the-art image compression algorithms. In the following, we describe some of the statistical image models in compression, starting from the most simple one, and we show how these models can be applied for image denoising.</p><p>A powerful class of image compression algorithms is based on the Discrete Wavelet transform (DWT) which effectively performs energy compaction for typical images by packing most of the image information into a few transform coefficients. The transform coefficients can be modeled as i i d . random variables with Generalized Gaussian distribution (first proposed in (51) and this simple model can be used for designing the source coder. Similar models are used in several abovementioned complexity regularized denoising algorithms [6, 31. These algorithms effectively perform global thresholding of wavelet coefficients, introduced in [7], by retaining only large coefficients and setting the rest to zero. Though wavelet thresholding methods have beautiful theoretical properties for certain classes of statistical models, they have not been very effective on "real-life" images primarily due to the mismatch in the modeling assumption.</p><p>Specifically, the Iilck of spatial adaptivity significantly reduces the performance of the discussed algorithms [6, 3, 71. Our proposed model overcomes this disadvantage and, as a result, achieves a much better performance. It is interesting to note a similar e-rolution in the performance of wavelet image coders due to the spatially adaptive component in the subband image m3dels.</p><p>That is, more sophisticated models for image compression recognize that there exist significant spatial dependencies in the trmsform coefficients and try to describe them using various data structures such as zero-trees introduced in [8]. The performance of the zero-tree based wavelet coders is currently among the best in image compression field. This inspired the proposal of similar methods in the image denoising application. In <ref type="bibr" target="#b1">[4]</ref>, a Hidden Markov model based on a wavelet tree was proposed to perform denoising. This model represents a compromise between an i.i.d. assumption and an overly general 2-D random process model by trying to capture most of the spatial dependencies while maintaining reasonable complexity. In <ref type="bibr" target="#b1">[4]</ref>, however, no real-life image results were presented. Though zero-tree based coders offer very good performance in image compression, attempts to translate this performance into simple algorithms for image denoising have not yet been very successful.</p><p>An alternative approach has been introduced recently, which offers excellent compression performance, while using a very simple and efficient local model [l]. In this work, we propose to modify the model of [l] for the purpose of image denoising and we demonstrate the promise of this approach. In [9] a similar spatially adaptive model for wavelet image coefficients was used to perform image denoising via wavelet thresholding. Within the framework of 191, each wavelet coefficient is modeled as a random variable with a Generalized Gaussian (GG) distribution having unknown parameters. Parameter estimation is carried out by context modeling. Our work, while being similar in approach (it employs the spatially adaptive model), differs from [9] in the statistical methods used for denoisingwe perform MMSE estimation rather than coefficient thresholding. The main message of the paper is to introduce a simple stochastic model for image wavelet coefficients and to show its excellent performance in the denoising of real-life images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM FORMULATION AND SOLUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Stochastic model for wavelet coefficients</head><p>In our model, we assume that there exists a deterministic unknown spatially varying variance field. Given this field, the wavelet coefficients are modeled to be independent Gaussian random variables having zero mean and the variance given by the underlying field. We assume that the variance field is smoothly changing. Hence we approximate the wavelet coefficients as "locally i.i.d.". Within the framework considered in this paper, the image pixels are corrupted by additive white Gaussian noise (AWGN) uncorrelated with the data as illustrated in Fig. <ref type="figure">1</ref>.</p><p>The ' 'Since in this work we use an orthogonal wavelet decomposition, AWGN in spatial domain preserves its statistical properties in the frequency domain.</p><p>denoising problem is to retrieve the original image coefficients as well as possible from the noisy observations. Here, we assume that we know the noise variance at. In Fig. <ref type="figure">1</ref>, X ( k ) represents the wavelet coefficients of a ''clean" image corrupted by additive i.i.d. Gaussian noise samples n ( k ) to produce the observed wavelet coefficients of a noisy image Y ( k ) . In Fig. <ref type="figure">1</ref>, we explicitly show the image coefficients X ( k ) as being obtained from the multiplication of the outcomes of an i.i.d. Gaussian source by samples u ( k ) from an unknown variance field. The model of the wavelet coefficients as being locally i.i.d. Generalized Gaussian was proposed and successfully used in [l] in the context of image compression. There, the variance estimate for the current coefficient was predicted from a quantized casual neighborhood, and the appropriate quantizer and entropy coder were matched to this variance estimate. Similarly, the algorithm proposed in this work is based on the underlying variance field being reasonably smooth to allow its reliable estimation from the local neighborhood of each wavelet coefficient. Specifically, we perform the ML estimation of the variance of each coefficient separately, using the observed noisy data in its neighborhood. This estimate is then used in the MMSE estimation (instead of the "true" variance) of the original wavelet coefficient X ( k ) . Both of these steps are outlined in the next subsections starting from the denoising part f i s t and illustrated in Fig. <ref type="figure">2</ref>. </p><formula xml:id="formula_0">I =@)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Denoising algorithm</head><p>Our proposed denoising algorithm is based on the Minimum Mean Squared error (MMSE) estimation procedure. Cnder the assumptions of independence and Gaussianity, the optimal (in the MSE sense) predictor for the clean data X ( k )</p><p>is linear and is given by:</p><p>where Y ( k ) is the observed data, a'(k) is the variance of X ( k ) and U,' is the variance of the AWGN samples. However, we cannot use the true signal variance az(k) in estimation since it is unknown. Instead, we propose to use the following form of the linear predictor:</p><p>where &amp;'(k) is the estimated variance for the k-th data sample X ( k ) .</p><p>The performance of the proposed predictor ( <ref type="formula">1</ref>) is dependent, to a high extent, on the performance of the estimator of the underlying variance field &amp;'(k). Generally, this relation is unknown and complicated; in the interest of simplicity, we use the guiding principle that a better estimator for the data variance yields a better estimate for the data as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Estimation of the underlying variance field</head><p>The estimation of the underlying variance field is the crux of the proposed denoising algorithm. For each data point (wavelet coefficient) an estimate of its variance is formed based on the local neighborhood of the data point. Under the smoothness assumption of the variance field, the transform coefficients around X ( k ) can be used to estimate a ( k ) .</p><p>It is intuitively clear that the estimate of u ( k ) has to be dewe consider the following setting. Suppose we are given a class of M different variance estimators Q % ( k ) , only one of which will be used for each location k. </p><formula xml:id="formula_1">&amp;(k) = argminE[(o(k) -Q,(k))'], (2) 8,</formula><p>which is easily shown to be equivalent to</p><formula xml:id="formula_2">&amp;(k) = argmin{(E[O,(k)] -~( k ) ) ~ + Var[Qm(k)]}. (3)</formula><p>The last equation is simply a bias-variance MSE decomposition.</p><p>In this work we consider only the specific class of windowtype estimators of the variance of X ( k ) where each data sample in the window around X ( k ) contributes equivalently to the estimation. In general, to choose the estimator both the size and the shape of the neighborhood region should be determined. Obviously, given that the data samples are locally i.i.d., the bigger the size of the region to estimate o ( k ) is, the more reliable this estimate is. However, the locally i i d . assumption becomes inaccurate as the size of the neighborhood grows, and the quality of variance estimation may decrease, because of the possible inclusion of "wrong" data points into estimation. The outlined trade-off suggests the existence of an "optimal" neighborhood region for the 8, variance estimation for each data point. This region is data dependent and has to be determined. In the following, we present our approach to attack the problem of estimation of the variance field and the simulation results which validate the efficiency of our proposed methodology.</p><p>We consider M different local neighborhoods A'k,,, in order to estimate the variance a ' ( k ) for the transform coefficient X ( k ) , where m E { 1 , 2 , . . . , M}. We model the statistical properties of the transform coefficients within the set Nkm as being stationary i.i.d. Thus, the maximumlikelihood variance estimator for X ( k ) using the neighborhood Nkm is:</p><p>In our denoising algorithm, square-shaped windows of different sizes around the data has been used to estimate a2(k) for simplicity. Due to a combination of the intractability of the minimization in (3) because of the presence of the first term as well as the dominance of the second term (which we verify in Table <ref type="table">l</ref>), we propose to modify the criterion <ref type="bibr" target="#b0">(3)</ref> to choose the local estimator by considering only the variance term in the minimization. We found experimentally that this term dominates the estimator error therefore our criterion in simulations was: &amp;*(k) = argminVar[B,(k)J.</p><p>( 5 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8,</head><p>In order to estimate the variance of the estimator, we use a simple technique, called the Bootstrap Method.</p><p>The Bootstrap is a practical technique for validating the accuracy of a parameter estimator and obtaining information about the distribution of the estimator. While other statistical methods having better asymptotical properties exist, they usually require a large number of samples for an efficient performance, which is clearly not the case in our situation. On the other hand, the Bootstrap provides a simple and efficient alternative under the constraint of a limited sample size.</p><p>To understand how the Bootstrap works in our case, suppose the estimator Q,(k) is obtained using the samples in the set Nk,. Let the corresponding data size be I N k m l .</p><p>The first step is the "Resampling" step, where a random sample of size INkml is drawn from the set A'km with replacement. The second step is the calculation of the bootstrap estimate using this random sample (i.e., simply using (4) on this random sample). These two steps are repeated a large number of times. The outcomes of the second step form an approximation to the statistical distribution of the estimator Q , ( k ) from which the standard deviation of the estimator can be approximated. For more information on Bootstrap, the reader is referred to (101.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RESULTS AND DISCUSSION</head><p>We tested our algorithm on a number of images, here, we only report the results for lena and barbara. We generated 2.i.d. Gaussian noise at four different values of the noise variance, U:. We used orthogonal wavelet transform with five levels of decomposition and Daubechies' length-8 wavelet. Square-shaped windows of sizes 3 x 3, 5 x 5, 7 x 7 and 9 x 9 around the data point were employed to find different estimates for o*(k). For each transform coefficient, one of these estimators is favored as a result of our algorithm. A typical estimator assignment map is shown in Figure <ref type="figure" target="#fig_2">3</ref>. No;e that around edges, small size windows are selected beceuse of the fact that the variations in the image data are csnsiderable in these regions. On the other hand, in smoother background regions, windows with larger sizes are preferred. Five different methods have been com-  . We included only the results from [9] which were obtained by using an orthogonal wavelet transform since this is equivalent to our setup. However, it has been reported in [9] that improvements of 1 -1.5 dB can be obtained by using the overcomplete expansion. We plan to extend our method to the non-subsampled wavelet transform domain in our future research.</p><p>For each image we also presented the results obtained from "optimal averaged estimator assignment maps". These maps represent the empirical upper bound on PSNR performance for the class of estimators that we use. Note that the performance of our method is approaching the best performance possible for this class of estimators, which further justifies our estimator selection criterion (5). In this work, a very limited class of estimators was used. We believe that if a richer class of estimators is allowed, the performance would improve substantially. This is the subject of our ongoing research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">R E F E R E N C E S</head><p>[I] S. LoPresto, K. Ramchandran, and M. T. Orchard, "Image coding based on mixture modeling of wavelet </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Model for noisy wavelet coefficients data. X ( k ) represents wavelet coefficients of the "clean" image, each drawn independently from a Gaussian source with zero mean and variance a 2 ( k ) . X ( k ) ' s are corrupted by AWGN samples n ( k ) to produce the observed data Y ( k ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>To decide which estimator to use optimally, one needs to choose the estimator which minimizes the MSE EIX(k) -X(k)I' where X ( k ) is obtained from (1) with &amp;'(k) = Q L ( k ) . Unfortunately, this is an intractable problem, hence we propose to choose the estimator which minimizes the MSE in the estimation of the coefficient variance, i.e., we can select : pendent on the local data statistics. To formalize this idea,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The estimator assignment map for all of the subbands of the lena image when on = 15. N o t e how smaller window sizes for predictors are favored around edges, while larger window sizes for predictors are preferred in smooth background regions. pared, and the PSNR results are shown in Table(1). The fist method is the hard-thresholding of wavelet coefficients using a constant threshold for all subbands, calculated according to [7]. The second method is the image denoising algorithm of MATLAB, which is invoked by wiener2. The third method is based on a framework of spatially adaptive wavelet thresholding, which is a recent work [9]. We included only the results from [9] which were obtained by using an orthogonal wavelet transform since this is equivalent to our setup. However, it has been reported in [9] that improvements of 1 -1.5 dB can be obtained by using the overcomplete expansion. We plan to extend our method to the non-subsampled wavelet transform domain in our future research.For each image we also presented the results obtained from "optimal averaged estimator assignment maps". These maps represent the empirical upper bound on PSNR performance for the class of estimators that we use. Note that the performance of our method is approaching the best performance possible for this class of estimators, which further justifies our estimator selection criterion (5). In this work, a very limited class of estimators was used. We believe that if a richer class of estimators is allowed, the performance would improve substantially. This is the subject of our ongoing research.4. R E F E R E N C E S</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table (</head><label>(</label><figDesc></figDesc><table><row><cell>1). The</cell></row><row><cell>fist method is the hard-thresholding of wavelet coefficients</cell></row><row><cell>using a constant threshold for all subbands, calculated ac-</cell></row><row><cell>cording to [7]. The second method is the image denoising</cell></row><row><cell>algorithm of MATLAB, which is invoked by wiener2. The</cell></row><row><cell>third method is based on a framework of spatially adap-</cell></row><row><cell>tive wavelet thresholding, which is a recent work [9]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>PSNR results for several denoising methods Empirical upper bound 11 34.58 I 32.59 I 31.17 I 30.06 Proc. IEEE Data Compression Conf., 1997. (21 B. Natarajan, "Filtering random noise from determin- istic signals via data compression," IEEE Trans. on Signal Processing, vol. 43, pp. 2595-2605, Kov. 1995.</figDesc><table><row><cell>II</cell><cell>B A R B A R A</cell></row><row><cell cols="2">coefficients and a fast estimation-quantization frame-</cell></row><row><cell>work,"</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Complexity-regulized image denoising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Znt. Conf. Image Proc</title>
		<meeting>IEEE Znt. Conf. Image</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Waveletbased statistical signal processing using hidden markov models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Crouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Rans. on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="1998-04">april 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theory for multiresolution signal decom</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ZEEE Trans. Pattern Anal. Mach. Zntell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="674" to="693" />
			<date type="published" when="1989">1997. July 1989</date>
		</imprint>
	</monogr>
	<note>position: the wavelet representation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simultaneous noise suppression and signal compression using a library of orthonormal bases and the mdl criterion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wavelets in Geophysics</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Foufoula-Georgiou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="299" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ideal spatial adaptation by wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="425" to="455" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Embedded image coding using zerotrees of wavelet coefficients</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I E E E Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="3445" to="3462" />
			<date type="published" when="1993-12">Dec. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Spatially adaptive wavelet thresholding with context modeling for image denoising</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Submitted to IEEE Trans. on Image Processing</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A n Introduction to the Bootstrap</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Chapman and Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
