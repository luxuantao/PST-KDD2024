<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Learning Approach for Short-Term Stock Trends Prediction based on Two-stream Gated Recurrent Unit Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">L</forename><forename type="middle">Minh</forename><surname>Dang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sejong University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Abolghasem</forename><surname>Sadeghi-Niaraki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sejong University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huy</forename><forename type="middle">D</forename><surname>Huynh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Information System</orgName>
								<orgName type="institution">University of Information Technology</orgName>
								<address>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kyungbok</forename><surname>Min</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sejong University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Hyeonjoon</forename><surname>Moon</surname></persName>
							<email>hmoon@sejong.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Sejong University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Learning Approach for Short-Term Stock Trends Prediction based on Two-stream Gated Recurrent Unit Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5518ACA7BAE2FBF56CC9EB1ABBE9852C</idno>
					<idno type="DOI">10.1109/ACCESS.2018.2868970</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2018.2868970, IEEE Access VOLUME XX, 2017 1 This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2018.2868970, IEEE Access VOLUME XX, 2017 9</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The stock market is one of the most important components forming a country's economy. Through IPO -Initial Public Offering, a company is able to raise a substantial amount of money to expand businesses. It is a great opportunity for investors to buy a brand-new stock and become either a stockholder who gets extra benefit from dividends from the firm's shareholder bonus program or a trader who trades stock in the stock market. If the stock trader predicted the stock price trends correctly, he would gain enormous profits. However, the stock market is volatile <ref type="bibr" target="#b0">[1]</ref>, daily news events such as developing political situations, the company's performance and other unexpected events affect stock prices immediately in a positive or negative way. As the result, it is impossible to predict the stock prices and their directions (increase, decrease) accurately, instead investor is only to forecast the upcoming short-term trends.</p><p>He usually evaluates a company's performance before making the decision to buy stock. The evaluation includes analyzing a company quarterly earnings report and paying attention to the important news to avoid buying overrated or high-risk stocks. However, both the speed of release and the number of daily news outlets have skyrocketed over the last few years which overwhelm investor's ability to thoroughly assess such a huge volume of data. As the result, an automated decision support system is essential as it automatically evaluates and shows the prediction for the upcoming stock trends. For example, if the price of the potential stock was predicted to be "going up" tomorrow, investors could either sell the stocks they held at a higher price or wait for the price drops and buy more. Thus, which algorithm is more effective and how to analyze the financial news to increase profits have drawn much interest from the research community.</p><p>Previous studies on this topic were divided into two main approaches: the technical analysis and the fundamental analysis. In the technical analysis, mathematics has been widely used to analyze historical stock price patterns and predict stock prices in the near future. Researchers have applied many algorithms such as multiple kernel learning <ref type="bibr" target="#b2">[3]</ref>, deep learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b16">17]</ref>, stepwise regression analysis <ref type="bibr" target="#b3">[4]</ref>, etc. Although they achieved good results, it is impossible to predict the stock prices accurately by using only the historical prices because unexpected events can affect the stock prices immediately. On the other hand, the fundamental analysis <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref> used natural language processing (NLP) to analyze financial news and financial statements from the company and predict the stock trends in the future (uptrend, downtrend).</p><p>In NLP, the bag-of-words technique is commonly applied to extract features from news articles, it measures the occurrence of each word and then converts text information into vector spaces using these occurrences. After that, machine learning algorithms are implemented to learn the connection between word patterns and stock prices movements. Although bag-of-words based approaches have achieved high accuracy in previous studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>, they ignored one crucial element of the directional predictions, which is the sentiment of the article. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, one important stage is that the published news articles are first interpreted by investors and converted into sentiments (positive, negative); the investors then decide whether to sell/hold/buy stocks based on the sentiment interpretations; finally, market prices aggregate the actions of each investor and reflect them in the final price trends. Therefore, combining the sentiment analysis and natural language processing would become more effective. Sentiment analysis assesses the document from sentiment aspect by measuring the frequency of words, and each word is analyzed and depicted by a sentiment vector. For instance, "increase" can be described as strong and active by looking up in Harvard IV-4 psychological dictionary; on the other case, the word "believe" indicates commitment, social relation, positive features. In a sentiment dictionary, the dimension of the sentiment feature is fixed. Each news article has a specific sentiment vector value; it is calculated by summarizing each word sentiment vectors. Integrating sentiment analysis and bag-of-words brings many benefits:</p><p>(1) Dimension reduction: the bag-of-words approach uses words as features so the larger the dataset the bigger the dimension (tens of thousands of words). On the contrary, the sentiment representation reduces the dimensions to hundreds, e.g. Harvard IV-4 psychological dictionary has 182 dimensions and Loughran-McDonald financial sentiment dictionary has 6 dimensions; (2) Better explanation. It is difficult to explain the mapping generated by bag-of-words. On the other hand, the sentiment values in fixed dimensions give us a more straightforward view of the document.</p><p>Finally, machine learning algorithms are implemented to learn the relationship between the extracted features from news and stocks trends. In recent years, deep neural networks (DNNs)a branch of machine learning has achieved numerous successes in various domains such as speech recognition <ref type="bibr" target="#b14">[15]</ref>, computer vision <ref type="bibr" target="#b15">[16]</ref>. Much of the hype surrounding neural networks is about image-based applications. However, a different approach from the image-based application is Recurrent Neural Networks (RNNs), which have been successfully used in recent years to predict future events in time series as well. RNNs have contributed to the development in a wide variety of fields centered around predicting sequences of events. Because of its efficiency on large-scale datasets <ref type="bibr" target="#b16">[17]</ref>, researchers have already applied some DNN models on features extracted from news articles and historical stock prices such as <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b18">[19]</ref>.</p><p>Based on the above analyses and evaluations, we propose a novel approach to predict daily stock price directions by analyzing financial news articles and historical stock prices using the deep learning approach. The main contributions include four aspects:</p><p> Proposing a two-stream gated recurrent unit (TGRU) for stock price trends prediction.  Proposing a sentiment Stock2Vec embedding model trained on both the stock news and the sentiment dictionary  Applying three technical indicators as an additional feature set for stock prices trend prediction and thoroughly analyzing whether the news impact stock prices immediately or after a short period (2 days, one week). The rest of the paper is organized as follows. Section 2 reviews related work in stock price movements prediction, sentiment analysis, and recurrent neural network. In Section 3, we show the proposed model and explain each module in detailed. In Section 4, we explain the implementation detailed and also show experimental results. In Section 5, we give the conclusion and what should be done in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. SENTIMENT ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) SENTIMENT ANALYSIS FOR FINANCIAL SECTOR</head><p>Sentiment analysis which studies the effect of news articles on stock price movements has been investigated thoroughly in the financial sector. Zhang et al. <ref type="bibr" target="#b7">[8]</ref> inspected NetEaseone of the most famous internet content providers in China and tried to prove that Internet news will be reflected in future market price movements. The results showed a remarkably unusual return and excessive trading volume on the date the event occurs which proved their hypothesis. Baruch et al. <ref type="bibr" target="#b8">[9]</ref> analyzed the effects of positive and negative words news on firms' future performance. They had two conclusions: <ref type="bibr" target="#b0">(1)</ref> There is a relationship between the readers' expectation and the writers' intention; (2) readers strongly against the content of the reports which violate their presumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) SENTIMENT ANALYSIS FOR COMPUTER SCIENCE SECTOR</head><p>In computer science, sentiment analysis refers to word's sentiment level evaluation by checking word sentiment value in the sentiment dictionary. As the results, sentiment dictionaries solely decide the effectiveness of sentiment analysis. A document can be represented as a sentiment vector by stacking up the word sentiment vectors in the document. Integrating sentiment analysis in the model will bring: (1) Reliability: adding sentiment value makes the model more reliable since it takes the emotional aspect into consideration (2) Dimensionality reduction: the sentiment dictionary has a fixed dimension, features extracted from it will effectively reduce the dimension of the original vectors. The construction of the sentiment dictionary can be divided into three categories automatic, semi-automatic and manual as described below:</p><p> Automatic: Initially, a dataset is crawled from the internet, all of the documents from that dataset are categorized into positive or negative by analyzing the positive or negative effect on the market (stock, gold, …). Finally, the sentiment dictionary is constructed by applying NLP on the dataset.  The dictionary is initially constructed by manually selecting some seed words. It is then expanded by following a set of rules on a new dataset.  Manual: The dictionary is collected and analyzed by linguistic experts. It contains fewer words than the one constructed by semi-automatically, but much more accurate. Minh Dang <ref type="bibr" target="#b1">[2]</ref> generated a sentiment dictionary by crawling news from the internet. After that, the author classified each news into positive or negative based on the effect on stock prices, then the sentiment dictionary is generated by weighting the sentiment score (TF-IDF method) and selecting 500 negative and 500 positive words which had the highest sentiment score. Experiment results showed that their system achieved high accuracy (up to 73%) in the stock trends prediction. Zhou and Chen [10] also constructed a Chinese short text sentiment dictionary using Word2Vec algorithm and some initial emotional seed words, the experimental results proved that the dictionary effectively improved the emotional classification of short texts. On the other hand, Zhang <ref type="bibr" target="#b10">[11]</ref> made three hypotheses: (1) the sentiment dictionary can be expanded by constructing negative word, adverb, network word, and other related dictionaries; (2) the sentiment value of a document can be acquired by computing the weight and ( <ref type="formula">3</ref>) the text document on a specific topic is categorized into positive, negative or neutral. Song <ref type="bibr" target="#b11">[12]</ref> created a special module namely finegrained named entity recognizer (NER) which mainly relied on named-entity (NE) dictionary. They constructed NE dictionary by following a semi-automatic approach. The proposed framework automatically generated a pseudodocument for each NE class from Wikipedia. It then computed the similarities between the Wikipedia entries and pseudo-documents by using a vector-space model. Finally, it categorized a new Wikipedia entry into NE classes by referring to the computed similarities. Wei Li <ref type="bibr" target="#b12">[13]</ref> also proposed a sentiment analysis system containing two main sections, domain new words detection, and word propagation. The first section made it possible to detect userinvented words, proper nouns, converted words and the second section allowed the system to detect multiword expressions in the tourism domain. Experimental results showed that their proposed model significantly outperformed traditional sentiment lexicons. Loughran and McDonald <ref type="bibr" target="#b13">[14]</ref> provided a manually made financial sentiment dictionary which contains 6 sentiment dimensions. We summarize the papers reviewed in Table <ref type="table">1</ref>.  <ref type="bibr" target="#b11">[12]</ref> Semi-automatic 29 Li, Wei et al. <ref type="bibr" target="#b12">[13]</ref> Semi-automatic 2 T. Loughran et al. <ref type="bibr" target="#b13">[14]</ref> Manual 6</p><p>Recently a concept-level approach has become an emerging trend in the sentiment analysis. There are two common feature learning techniques: GloVe and Word2Vec. Both models learn geometrical encodings (vectors) of words from their co-occurrence information. Word2vec <ref type="bibr" target="#b30">[31]</ref> learns from the vectors to improve the predictive ability of loss, i.e., the loss of predicting the target words from the context words given the vector representations. On the other hand, GloVe count-based technique <ref type="bibr" target="#b31">[32]</ref> learns its vectors by essentially making a dimensionality reduction on the co-occurrence counts matrix. Then it factorizes this matrix to yield a lowerdimensional matrix, where each row contains a vector representation for each word. In general, this is done by minimizing a "reconstruction loss" which tries to find the lower-dimensional representations. Although <ref type="bibr" target="#b31">[32]</ref> said that GloVe and Word2Vec were equally effective for natural language processing problems, they originated from datasets irrelevant to the financial field which affects the overall performance when they are used for financial applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) APPLICATIONS OF SENTIMENT ANALYSIS</head><p>Since sentiment analysis brings enormous benefit to text mining, computer science researchers have tried to apply the sentiment analysis in real applications. Gelbard <ref type="bibr" target="#b19">[20]</ref> built a conceptual ontology to evaluate human factors by using digital sources and the sentiment analysis available in any organization's information systems. Peng <ref type="bibr" target="#b20">[21]</ref> developed a system which can provide invaluable added value to the government, business owners and Internet users by analyzing the sentiment element from countless amounts of new information entries each day through product descriptions, customer reviews. Zhang <ref type="bibr" target="#b10">[11]</ref> proposed an automated system which can classify Chinese micro-blog topic based on sentiment analysis, it is helpful for the public opinion supervisors to make appropriate decisions. Song <ref type="bibr" target="#b11">[12]</ref> built a system that analyzed users' opinions about specific entities in text messages. As the result, it facilitated the design of human-centric services by social media. Li <ref type="bibr" target="#b12">[13]</ref> proposed a system which can be applied to hot scenic spots analysis and precision marketing by applying sentiment analysis on customer's reviews from Qunar.com and Ctrip.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DEEP LEARNING</head><p>After extracting the features, machine learning algorithms such as in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> are implemented to analyze the relationship between financial news articles and historical stock prices. These works proved that it is possible to effectively forecast the stock prices trend. However, they did not explore the structural relation of the sentence. For example, a news story titled "Apple has finally won $120 million from Samsung patent battle", if the system only analyzes individual terms "Samsung", "won", "Apple", it cannot differentiate between the winner and the loser thus it is unable to anticipate that the stock price of Apple will probably go up in the near future <ref type="bibr" target="#b21">[22]</ref>. The previous problem is the reason why Recurrent Neural Network -another class of Artificial Neural Network proved to be more efficient than CNN in dealing with text and speech analysis <ref type="bibr" target="#b23">[24]</ref>. A recurrent neural network can be imagining as multiple copies of the same network; each copy takes a sequence of vectors (x1, x2, …, xn) as input and passes another sequence (h1, h2, …, hn) that represent a part of the sequence to its successor. Although RNNs have been very effective in text generation and speech recognition tasks <ref type="bibr" target="#b14">[15]</ref>, Hochreiter in <ref type="bibr" target="#b24">[25]</ref> revealed a big problem of RNNs; when the gradient is passed back through many time steps, it tends to grow or vanish, they stated that it was very hard to make RNN remember the long-term dependencies. GRU (Gated recurrent Unit) <ref type="bibr" target="#b22">[23]</ref> and LSTM (Long short-term memory) were proposed as the solution for the problem as they have the ability to keep memory/state from previous activations rather than replacing the entire activation like RNN. The GRU unit controls the flow of information like the LSTM unit, but without having to use a memory unit because it just exposes the full hidden content without any control. Moreover, GRU was computationally more efficient than LSTM as pointed out in <ref type="bibr" target="#b22">[23]</ref>. GRU successfully solved the drawback of RNN. However, it can be further improved by increasing the amount of input information available to the network. Inspired by the model proposed by Schuster in <ref type="bibr" target="#b27">[28]</ref>, which connected two opposite directions hidden layers in the original RNN network to the same output to be able to get information from not only past states but also future states. We apply this structure to form a two-stream GRU which will be effective for the text analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODOLOGY</head><p>As depicted in Fig. <ref type="figure" target="#fig_1">2</ref>, the proposed method includes four sections. 1) In the document preprocessing step, the extracted articles are preprocessed to remove useless information such as stop words, punctuation. 2) The next step includes two tasks: labeling news articles based on stock prices. 3) In Stock2Vec embedding section, we create a new sentiment word embedding model based on financial dataset and sentiment dictionary. 4) In the final step, TGRU network is implemented on the financial news dataset and then multiple scenarios are conducted. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DOCUMENT PREPROCESSING 1) NEWS ARTICLES</head><p>Because the news articles were crawled from the internet and in HTML format, all unnecessary tags were removed. After that, the articles were exported in plain text. Next, each sentence was tokenized into a sequence of tokens; each token represented a single word. Finally, the following steps were implemented:</p><p> Stop word removal: all stop words such as "and", "or", "by", etc., were removed based on the English stop words dictionary proposed by Porter in <ref type="bibr" target="#b25">[26]</ref>.  All punctuation and numbers were also eliminated because they are unnecessary and occur frequently which affect the role of other important words.  A Porter Stemmer <ref type="bibr" target="#b25">[26]</ref> was also used to reduce word inflectional form to a common base form. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DOCUMENT LABELING</head><p>The goal of labeling is to classify each article into either positive, which drives the price up, or negative, which leads to a downward trend of the price. In this study, we choose two classes approach (positive or negative) to reflect the direction of the stock prices <ref type="bibr" target="#b1">[2]</ref>.</p><p>There are two techniques in labeling the news articles using historical stock prices: an open-to-close return (daytime return) and a close-to-close return (overnight return). The open-to-close price return approach was used to determine the label of the document. The reason why we chose open-to-close return instead of close-to-close return originated from the practical viewpoint pointed out in <ref type="bibr" target="#b28">[29]</ref>, the records of the open-to-close are more similar to the total of the same stock, suggesting that the open-to-close return contributes more to the total return.</p><p>We investigated the model at different time periods (i.e., 1 day, 2 days, 5 days, 7 days, and 10 days) to examine the impact of time period on stock prices. The Open-to-Close price return Rdt of day d and time period t (t ∈ [1,2,5,7,10]) is calculated as follows:</p><formula xml:id="formula_0">dt d t d R O C    Article label = if R 0 if R 0 i i Positive Negative     </formula><p>where Od+t is the opening price of the day after day d a period of t (t ∈ [1,2,5,7,10]). For example, if day d is November 13th, 2016 and time period t is 2 then Od+t is the opening price on November 15th, 2016. Cd is the closing price of the stock on day d. If Ri is greater or equal to 0 then the article on that day is classified as positive (stock price will likely go up) whereas if Ri is less than 0 then the news article is labeled as negative (stock price will likely go down).</p><p>Fig. <ref type="figure" target="#fig_2">3</ref> shows an overall process of labeling a news article; each article has a published date which is used to query the opening and closing stock prices from the database, then the Open-to-Close return is computed using opening and closing prices. The return value is then used for labeling the news article into the positive or negative news. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. WORD EMBEDDING</head><p>After the labeling step, a labeled dataset is generated, it is then used to train the proposed Stock2Vec model. The model was implemented using Python programming language; the total training time was approximately 40 minutes, each word is presented by a vector with a maximum length of 300, and the total number of words in the Stock2Vec was limited to 5,000. There are three main functions:</p><p> build_vocab takes Harvard IV-4 dictionary and stock news dataset as the input and the output of the function is word_frequency array which contains a unique word_id and its frequency in the entire dataset. The sentiment value has a range spread from -2 to 2, where -2 is really negative, -1 is negative, 1 is positive, and 2 is really positive so at the end of this step, the word which has high sentiment value will have high word_frequency value.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>      </head><p>where C is closing price of the day under consideration, and Lp and Hp are the lowest and highest prices in the last p days after the day under consideration, respectively.  Relative Strength Index (RSI): a momentum oscillator which evaluates speed and trend of price movements. RSI fluctuates between 0 and 100. In practice, investors usually sell when RSI value ≥ 80 and buy when it is ≤ 20. 100 100 100 RSI RS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>    </head><p>where RS is the average gain of positive periods during a specified time frame / average loss of negative periods during the specified time frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. TGRU NEURON NETWORK ARCHITECTURE</head><p>Each recurrent unit in the GRU network <ref type="bibr" target="#b29">[30]</ref> captures the dependencies of different time scales adaptively. The activation n-dimensional ht of the network at time t is a linear interpolation between element-wise multiplication ⨀ of the previous activation ht-1 and update gate zt and element-wise multiplication ⨀ of the candidate activation t h and (1-zt). (1 )</p><formula xml:id="formula_1">t t t t t h z h z h    </formula><p>where update gate zt decides the level the unit updates its activation or content. The update gate is computed by a linear sum between the newly computed state and existing state with the bias parameter bz. xt is the m-dimensional input vector at time t, σ is the logistic nonlinearity, and Wz (n×m matrix), Uz (n×n matrix), bz (n×1 vector) are fixed sized parameters (two weights and bias) which are shared across an entire network. </p><formula xml:id="formula_2">t z t z t z z W x U h b     </formula><p>GRU exposes to the whole state each iteration. The candidate activation t h is calculated similarly to the traditional recurrent unit.</p><p>1 tanh( ( ) )</p><formula xml:id="formula_3">t t t t r h Wx U r h b    </formula><p>in which rt is a set of reset gates. When the status is off (rt near 0), the reset gate forces the unit to act as it is processing the first symbol in the sequence of input, allowing it to remove previously calculated state ht-1.</p><p>The reset gate rt is computed similarly to the update gate but with different values: (n×m matrix), Ur (n×n matrix), br (n×1 vector). </p><formula xml:id="formula_4">() t r t r t r r W x U h b     </formula><p>By using gating mechanism, GRU can keep memory significantly longer than RNN. However, through observation, we figured out that when GRU analyzes a word it only considers the forward lingual context, so it is impossible for GRU to learn the backward context. As the result, the learning process is partly completed because, in any language model, the meaning of a word in a sentence is affected by not only the forward context but also on the backward context. TGRU was proposed to solve the above issue; it lets the model learn the lingual context of a word from both sides. TGRU is inspired by the bidirectional recurrent neural networks (BRNNs) in <ref type="bibr" target="#b27">[28]</ref>. It divides each training sequence into two separate recurrent nets forwards and backward, both of them are combined to be the output layer. The formulas for update gate, reset gate, activation, and candidate activation of the forward and backward GRU are shown below: Forward pass: </p><formula xml:id="formula_5">() t z t z t z z W x U h b      1 () t r t r t r r W x U h b      1 tanh( ( ) ) t t t t r h W x U r h b     1 (1 ) t t t t t h z h z h    </formula><p>The backward pass is the step we added to our model to explore more valuable information.</p><p>Backward pass:</p><p>1 ()</p><formula xml:id="formula_6">t z t z t z z W x U h b      1 () t r t r t r r W x U h b      1 tanh( ( ) ) t t t t r h W x U r h b     1 (1 ) t t t t t h z h z h    </formula><p>For the activation of a word at time t: In general, the complexity of an algorithm is computed using O(W) and the number of estimated parameters of the algorithm is W. Two common pieces of information used to compute W is the dimension of the input vector mdimensional and hidden layer dimension n-dimensional. Table <ref type="table">2</ref> shows the estimated parameters of GRU, LSTM, and TGRU. The complexity of TGRU doubles the complexity of GRU because the number of parameters are double. As a result, TGRU needs more time and resources for computation than GRU or LSTM. However, TGRU is able to explore valuable information which hugely improves the accuracy of the stock trends prediction. </p><formula xml:id="formula_7">, t t t h h h   </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>In this section, we conduct several experiments to show how well TGRU performs compared to state-of-the-art methods. There are four main parts, the first part describes the dataset, the second part explains carefully about evaluation protocols used in our study, the third part contains three experiments on examining the financial indicators, the impact of a different time period and the effectiveness of TGRU. Finally, TGRU is being compared with recent studies and a trading simulation is conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DATASET</head><p>This study contains two different datasets: (1) Daily financial news from Reuters and Bloomberg from between October 2006 and November 2013, totaling 106,521 and 447,145 news articles from each source respectively. (2) Daily S&amp;P500 stock prices in the same period are downloaded from Yahoo Finance. We then split the dataset (1) into three parts which were similar to those in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. EVALUATION PROTOCOLS</head><p>The performance of the system is evaluated by calculating the confusion matrix. Table <ref type="table">3</ref> describes the components of the confusion matrix which includes TP, TN indicating the right classification for the corresponding class while FP, and FN declaring the false classification for the corresponding class. After obtaining the value in the confusion matrix, precision, and accuracy are used to evaluate system performance. Accuracy is the number of correctly classified samples on the entire dataset. In general, the higher the accuracy, the better the classifier. However, accuracy cannot give us a comprehensive evaluation of the system. As a result, precision and recall are two widely used measurements beside accuracy. High precision means most of the samples which were classified into positive were correct. On the other hand, recall or sensitivity is the proportion of positive trend news that was predicted by our classifier as positive trend news. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. INITIAL EXPERIMENTS</head><p>The implementation is conducted on the NVIDIA DIGITS toolbox with Keras API version 1.2.2 using Python version 2.7.3. The model was trained through 30 epochs, and the average training time for each epoch was 64 minutes. A Linux machine with Ubuntu 14.04 was used for the entire process; the machine specification was: Intel® Core i7-5930K processor with four NVIDIA Titan X 12GB GPUs, four 3072 Cuda cores, and 64GB of DDR4 RAM. Fig. <ref type="figure" target="#fig_13">7</ref> describes each layer in the TGRU in detail. In the input layer, because the article length was different, we limited the length to 300 words, truncating long news articles and padding shorter news articles with zero values. Before combining three financial indicators into the features extracted from the news article, they were normalized to a range between 0 and 1, then the normalized features were combined with the previous features to form the input vectors; each vector now has a dimension of 303. This layer is followed by the Embedding layer which accepts a maximum of 303 input sequences for each news article. The total number of words in the vocabulary was set to the 10,000 most frequent words. The next layer is the TGRU layer with 128 memory units for each forward and backward pass. For each iteration, we applied a dropout for the GRU layer; the input Dropout-W was set to 30 percent while hidden state Dropout-U was set to 30 percent. After merging the forward GRU and backward GRU, another dropout layer was added to drop 50% of the input to cope with the overfitting problem. The last layer is the Dense layer which has a single neuron, and it used sigmoid activation function to decide 0 or 1 for the two classes prediction (positive or negative). Moreover, through each epoch, the mean squared error loss value is calculated to minimize this value; this model uses Adam optimizer with batch size n = 64, learning rate η = 0.001, and learning rate decay t = 0.0001. The timebased learning rate schedule was used to anneal the learning rate over time. Therefore, the learning rate for epoch k-th was determined by: The detailed accuracy and loss model is given in the Fig. <ref type="figure" target="#fig_15">8</ref>. The model is trained in 30. As shown in the figure, the accuracy of training and validation set increase significantly over 85% and corresponding loss of training and validation decrease dramatically below 35% after 10 epochs. Those numbers go stability with very little fluctuation before stopping at over 88% for accuracy and 30% for the loss. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) TGRU AND GRU COMPARISION</head><p>We evaluate TGRU effectiveness over GRU by selecting 100 random news samples from the original dataset, which contain 50 positive news and 50 negative news. As shown in Fig. <ref type="figure" target="#fig_16">9</ref>, the orange line represents the actual class by calculating the Open-to-Close approach (0 stands for negative or 1 stands for positive), while the blue line shows the trends predicted by GRU and TGRU. Because the Dense layer uses the sigmoid function, it returns a real value output between 0 and 1. TGRU achieved an accuracy of 67% while GRU obtained the accuracy of 58%. It is noticeable that the blue line in the TGRU model is nearer to the orange line compared to GRU which indicates TGRU prediction is better than GRU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) EVALUATING THE BEST TIME PERIOD</head><p>In this section, we evaluate the effect of news articles on stock prices on different time periods, by changing the i value (i ∈ [1,2,5,7,10]) of the Open-to-Close price return which indicates the time intervals (1 day, 2 days, 5 days, 7 days, and 10 days). For example, i=1 means the news articles will affect the stock prices within 24 hours after the news was published, so the open and close prices at that day are queried from the database and Open-to-Close price equation will be calculated to decide whether to set a positive or negative label for the news; the remaining time intervals follow the same rule. Fig. <ref type="figure" target="#fig_17">10</ref> shows the performance of the system at different time intervals. The results prove that the model is suitable for daily stock movement rather than the long-term movement with the highest accuracy of 66.32 percent for TGRU. The system performance decreases gradually as the time gets longer which proves the hypothesis given by <ref type="bibr" target="#b1">[2]</ref> that the news article immediately influences the investors trading actions (buy, sell) in a short period (&lt;=24 hours); as the period increases, the news has a lesser impact on the investor's decisions. Take the "Brexit" event in 2016 as an example; it impacted the entire UK stock market immediately in negative ways after "Brexit" was announced by the government. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) FINANCIAL INDICATORS EVALUATION</head><p>In this section, an experiment was conducted to verify the effectiveness of the model when the financial indicators feature was added. Fig. <ref type="figure" target="#fig_18">11</ref> shows the Receiver Operating Characteristic (ROC) for stock movement prediction in two cases: using the financial indicators feature set and without the financial indicators feature. The area under the curve (AUC) was 0.66 for the model which did not use financial indicators features, but when the financial indicators feature was used, we achieved a significant improvement of 0.1 in the area under the ROC curve to 0.76. Through the ROC, it is clear that applying the financial indicators noticeably improved system performance because these indicators are used to verify the labeling procedure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. COMPARING TGRU WITH RECENT STUDIES 1) STOCK TRENDS PREDICTION ON S&amp;P 500</head><p>This section evaluates the system performance compared with recent studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21]</ref>. In <ref type="bibr" target="#b17">[18]</ref>, Ding proposed using Open Information Extraction for event-based stock price trend prediction to extract structured events from large-scale public news articles; the structured event was denoted as (O1, P, O2) where O1 is the first object (ticker name, company name, etc.), O2 is the second object (ticker name, company name, etc.), and P indicates the relationship between them. They applied the feedforward neural network and achieved an accuracy of 55.21%. Using the same dataset, Peng in <ref type="bibr" target="#b20">[21]</ref> employed the word embedding method and used DNNs to predict the future stock movements of the S&amp;P 500 index based on the extracted features, with an accuracy that was slightly improved to 56.87%.</p><p>GRU and TGRU were implemented on the same dataset and same period as these two studies. LSTM (long short-term memory), which is an extension of RNN that has been widely used in recent years <ref type="bibr" target="#b23">[24]</ref>, was also added to this experiment to allow for further comparisons. Both GRU and LSTM are RNN extensions so which algorithm is better? We deploy GRU and LSTM on our dataset with the parameters similar to those in <ref type="bibr" target="#b20">[21]</ref>. The results in Fig. <ref type="figure" target="#fig_19">12</ref> proved that our TGRU outperforms other methods (better than Ding at 55.21% and Peng at 56.87%) at an accuracy of 66.32%. The improvement is explainable because not only did we construct the word embedding, add the sentiment analysis and three technical indicators but we also combined the forward and backward context to learn more valuable information from the news article. It is also noticeable that LSTM and GRU performed better than the results from two previous studies at 60.98% and 58.52%, respectively. We also evaluate the system performance on other metrics. Fig. <ref type="figure" target="#fig_20">13</ref> shows the accuracy, precision, and recall metrics used to judge the system performance using LSTM, GRU, and TGRU. Overall, TGRU has the highest accuracy compared to the others. Also, TGRU has the highest f-measure at 77.3% and precision at 72.1%. The high precision indicates the number of positive prediction samples which are true compared to the number of actual positive samples.</p><p>The main purpose of the model is to predict the price trend in the S&amp;P 500 index -the stock index for 500 large companies which have stock tickers on the NYSE or NASDAQ. Besides, we want to verify the model performance on individual company stock indexes because this approach is more useful for investors who invest in several companies.</p><p>The evaluation was carried out on the three biggest companies in different sectors. Apple represents the Information Technology sector; Amazon stands for the Ecommerce sector, and Airbus represents the manufacturing sector (classified by The Global Industry Classification Standard). From the original dataset, news relating to these three companies are selected (news contains the company name, stock ticker, etc.). Table <ref type="table">4</ref> shows the amount of news for each company. The results in Fig. <ref type="figure" target="#fig_21">14</ref> prove that overall our TGRU achieves better performance than GRU and LSTM. The results from GRU and LSTM are quite similar. Another interesting fact is that the accuracy of Apple-related news using TGRU is over 72.3%, which proves the effectiveness of our system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) STOCK TRENDS PREDICTION ON VNINDEX</head><p>Besides the S&amp;P 500 index, we also perform an additional experiment on Vietnamese stock dataset collected by <ref type="bibr" target="#b1">[2]</ref> to compare TGRU to Support vector machine algorithm. The news dataset contains a total of 2,471 news crawled from Vietstock.vn financial news website between 01/2014 and 05/2015. We divided it similar to those in <ref type="bibr" target="#b1">[2]</ref>, the reason it was separated into three samples is to examine investor's behavior on different time periods. The detailed information is described in Table <ref type="table">5</ref>. In <ref type="bibr" target="#b1">[2]</ref>, the authors used TF-IDF combined with sentiment dictionary as term weighting technique, they also used OCFS (orthogonal centroid feature selection) as term reduction. Finally, in the classification step, they chose Linear SVM using a linear kernel with C=0.5. They also applied LibLinear, which is a famous library for linear kernel support vector machines (SVM). We implemented TGRU on this dataset with the same parameters as described above.</p><p>By observing the results shown in Fig. <ref type="figure" target="#fig_22">15</ref>, our TGRU yields higher prediction accuracy compared to the approach using SVM+TF-IDF. Overall, TGRU achieves the average accuracy of over 70% and it yields a higher accuracy compared to SVM, it is a noticeable accuracy of 77.2% which is 4.2% higher than <ref type="bibr" target="#b1">[2]</ref>. In sample 3, the accuracy for TGRU is 7% better than SVM. As the result, TGRU is proved to outperform SVM when the dataset gets bigger. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) MARKET SIMULATIONS</head><p>In the final experiment, an automated trading system is conducted to evaluate the profits under real trading conditions. The stock investment was carried out on the bluechip stock Google (GOOGL). The initial investment is assumed to be 10,000 USD, and the transaction fee (buy/sell) is charged at 0.25% of the trading amount. The dataset was collected between October 9th, 2017 and November 9th, 2017, while the number of news articles for each day was limited to one. As a result, a total of 24 sets of news were gathered. Figure <ref type="figure" target="#fig_23">16</ref> shows the price movements and the predicted trend of GOOGL during the period. Also, each day is limited to only one transaction (buy/sell) to avoid too many transaction charges resulting from too many trading actions. It operated under the following rules <ref type="bibr" target="#b5">[6]</ref>.</p><p> If there is no news released, do nothing.  If the stock was bought and the prediction was negative for the day under consideration, the stock will be sold when the market opens.  If the stock was bought while the prediction was positive, do nothing.  If the stock was sold while the prediction was positive, do nothing.  If the stock was sold and the prediction was negative, buy with all the money when the market opens. Fig. <ref type="figure" target="#fig_23">16</ref> shows the statistics for the actual trend (orange line) and predicted trend (blue line) over a one-month period. Table <ref type="table">6</ref> describes the detailed transactions of the system. Our system made eight trades in total within a month based on the prediction model. From the initial 10,000 USD investment, at the end of the month we held 10,531 USD, so the profit was over 500 USD. The profit proves that our system is reliable and can be used to support investors in making trading decisions to some extent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>The topic of stock trend prediction using deep learning interests many researchers and investors because the improved prediction accuracy will probably bring enormous profit. In this paper, we introduced a stock movement prediction framework to support investors in trading stock on the market. The proposed Two-stream Gated Recurrent Unit (TGRU) overall accuracy was 66.32% which outperforms the performance of the previous model including GRU, LSTM, our model has two states of learning including backward and forward so it is able to learn more useful information, especially for text processing problem. Then a sentiment Stock2Vec embedding is created by using financial dataset and Harvard IV-4 sentiment dictionary, through the experiments, the Stock2Vec embedding proved to be more effective than the original embedding method such as Glove and Word2Vec because it takes the sentiment value of the word into consideration. Moreover, the financial indicators, which are one of the most important factors in the financial analysis, are also added. The model shows its robustness in both the S&amp;P 500 index and individual stock trend prediction. In addition, a simulation system was conducted to compute the actual profits investors earn when they use our system; it proved to be robust against market volatility and the ability to adjust itself to the risk from the real market. This framework can also be integrated into an automated system to support investors in trading specific stocks.</p><p>There are several ways to extend this work in the future. In our study, only the daily period was considered, so it would be better if the model can be applied to intraday trading which means the system could predict the trend minutes or hours after the news is published. In addition, only three financial indicators are used in this study, so exploring other indicators such as P/E ratio and earnings growth is necessary. Another weakness of the system is in the TGRU network because the complexity of the network double that of GRU so the framework requires long training time and huge computational resources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 .</head><label>1</label><figDesc>FIGURE 1. A general plot illustrates how news impacts the stock price movements. (1) Events occur; (2) News are published; (3) Investors read the news; (4) Investors take actions (buy/sell/hold) based on their interpretations; and (5) The actions affect the stock prices. Idea from [17]</figDesc><graphic coords="2,36.95,490.80,240.50,122.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 2 .</head><label>2</label><figDesc>FIGURE 2. Proposed system for stock trends prediction.</figDesc><graphic coords="4,298.10,441.35,240.70,174.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 .</head><label>3</label><figDesc>FIGURE 3. Document labeling using historical stock prices. Idea from [17]</figDesc><graphic coords="5,298.10,203.05,227.50,148.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 4 .</head><label>4</label><figDesc>FIGURE 4. Flow diagram for the build_vocab function.</figDesc><graphic coords="6,36.95,65.05,220.55,143.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 5 .</head><label>5</label><figDesc>FIGURE 5. Flow diagram for the build_cooccur function.</figDesc><graphic coords="6,36.95,397.45,233.75,160.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 :</head><label>1</label><figDesc>Initialize vector_size=100, iterations=1, learning_rate = 3*10e-5 2: While iterations &lt;25 do 3: W = averaging vocab and vector_size 4: biases = compute based on vocab and vector_size 5: cost = update_cost(vocab, data) 6: Re-update gradient based on cost 7: End While 8: Return the optimal W D. TECHNICAL INDICATORS In addition to the features extracted from the news dataset, we also use another feature set containing three indicators that are commonly used in technical analysis. Technical indicators are mathematical calculations based on the price, volume, or open interest of a security or contract. By analyzing historical data, technical analysts use indicators to predict future price movements [27]. We add them to examine whether the system performance is improved. Three technical indicators are a Stochastic oscillator, William, and Relative Strength Index.  Stochastic oscillator (%K): a momentum indicator which compares the closing price of a stock to its price range over a period. It can be used to foreshadow reversals when the indicator reveals bullish or bearish divergences.   where C is the closing price of the day under consideration, Lp and Hp are lowest and highest prices in the last p days, respectively.  William (%R): a momentum indicator which supports investors in detecting overbought and oversold conditions. It is based on a comparison between the current close and the highest high for a user-defined look back period p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>x1, x2, …, xn) containing n words, every word at time t is represented as a dimensional vector. The forward GRU computes t h which represents the left to the right context of the sentence whereas the backward GRU step took the right to left context t h into consideration. Then the forward and backward context representations were concatenated into a single context. Fig.6shows the detailed structure of TGRU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>FIGURE 6 .</head><label>6</label><figDesc>FIGURE 6. Structure of the TGRU network.</figDesc><graphic coords="7,298.10,518.15,240.45,124.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>for comparison; the training part contains news articles between 2006-10-01 and 2012-12-31 (439,304 articles), the validation part involves news from 2013-01-01 to 2013-06-15 (2,305 articles) and the testing part includs news from 2013-06-16 to 2013-12-31 (98,468 articles).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>FIGURE 7 .</head><label>7</label><figDesc>FIGURE 7. The configuration of TGRU network.</figDesc><graphic coords="8,298.10,221.30,240.70,95.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>(c) 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2018.2868970, IEEE Access VOLUME XX, 2017 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>FIGURE 8 .</head><label>8</label><figDesc>FIGURE 8. Impact of stock news on the price of stock at different time periods.</figDesc><graphic coords="9,36.95,166.30,233.30,187.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>FIGURE 9 .</head><label>9</label><figDesc>FIGURE 9. The configuration of TGRU network.</figDesc><graphic coords="9,36.95,565.90,240.95,92.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>FIGURE 10 .</head><label>10</label><figDesc>FIGURE 10. Impact of stock news on the price of stock at different time periods.</figDesc><graphic coords="9,298.10,346.80,240.70,105.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>FIGURE 11 .</head><label>11</label><figDesc>FIGURE 11. Receiver Operating Characteristic curves with and without indicators.</figDesc><graphic coords="10,36.95,64.80,202.80,152.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>FIGURE 12 .</head><label>12</label><figDesc>FIGURE 12. Our proposed model compared with two previous models.</figDesc><graphic coords="10,36.95,547.90,240.95,141.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>FIGURE 13 .</head><label>13</label><figDesc>FIGURE 13. TGRU, LSTM, and GRU performance on different measurements.</figDesc><graphic coords="10,298.10,203.05,240.95,210.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>FIGURE 14 .</head><label>14</label><figDesc>FIGURE 14. LSTM, GRU and TGRU performance on individual stock trend prediction.</figDesc><graphic coords="11,36.95,262.10,240.75,129.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>FIGURE 15 .</head><label>15</label><figDesc>FIGURE 15. Comparison between our method and SVM on the dataset proposed by [2].</figDesc><graphic coords="11,298.10,203.05,240.70,141.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>FIGURE 16 .</head><label>16</label><figDesc>FIGURE 16. Predicted trend and actual price trend of GOOGL between October 2nd and November 2nd, 2017.</figDesc><graphic coords="12,36.95,64.80,240.50,50.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>2 + nm +n)</head><label></label><figDesc></figDesc><table><row><cell>TABLE II</cell><cell></cell></row><row><cell cols="2">THE NUMBER OF PARAMETERS IN GRU, LSTM AND BGRU</cell></row><row><cell>Model</cell><cell>Number of parameters</cell></row><row><cell>GRU</cell><cell>3×(n 2 + nm +n)</cell></row><row><cell>LSTM</cell><cell>4×(n 2 + nm +n)</cell></row><row><cell>Proposed BGRU</cell><cell>6×(n</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV AMOUNT</head><label>IV</label><figDesc>OF NEWS FOR EACH COMPANY</figDesc><table><row><cell>Company name</cell><cell>Training</cell><cell>Evaluation</cell><cell>Testing</cell></row><row><cell>Apple</cell><cell>1,802</cell><cell>450</cell><cell>1,124</cell></row><row><cell>Amazon</cell><cell>1,188</cell><cell>296</cell><cell>741</cell></row><row><cell>Airbus</cell><cell>1,664</cell><cell>416</cell><cell>1,039</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>2169-3536 (c) 2018 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by Korea Institute of Planning and Evaluation for Technology in Food, Agriculture, Forestry and Fisheries (IPET) through Agri-Bio industry Technology Development Program, funded by Ministry of Agriculture, Food and Rural Affairs (MAFRA) (316033-4).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How does stock market volatility react to oil price shocks</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Bastianin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Manera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Macroeconomic Dynamics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="666" to="682" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improvement methods for stock market prediction using financial news articles</title>
		<author>
			<persName><forename type="first">Minh</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duc</forename><surname>Duong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information and Computer Science (NICS), 2016 3rd National Foundation for Science and Technology Development Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting Noisy Data Normalization for Stock Market Prediction</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Engineering and Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pattern graph tracking-based stock price prediction using big data</title>
		<author>
			<persName><forename type="first">Seungwoo</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonghee</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies</title>
		<author>
			<persName><forename type="first">Eunsuk</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chulwoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="187" to="205" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stock market one-day ahead movement prediction using disparate data sources</title>
		<author>
			<persName><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><forename type="middle">A</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fadel</surname></persName>
		</author>
		<author>
			<persName><surname>Megahed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="153" to="163" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stock price prediction using LSTM, RNN and CNN-sliding window model</title>
		<author>
			<persName><surname>Selvin</surname></persName>
		</author>
		<author>
			<persName><surname>Sreelekshmy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computing, Communications and Informatics (ICACCI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Market reaction to internet news: Information diffusion and price pressure</title>
		<author>
			<persName><forename type="first">Yongjie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Modelling</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Informed trading and price discovery before corporate events</title>
		<author>
			<persName><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marios</forename><surname>Shmuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumar</forename><surname>Panayides</surname></persName>
		</author>
		<author>
			<persName><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Financial Economics</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="561" to="588" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An Approach to Constructing Sentiment Collocation Dictionary for Chinese Short Text Based on Word2Vec</title>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Emerging Technologies for Education</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sentiment analysis of Chinese micro-blog text based on extended sentiment dictionary</title>
		<author>
			<persName><forename type="first">Shunxiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="395" to="403" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semiautomatic construction of a named entity dictionary for entity-based sentiment analysis in social media</title>
		<author>
			<persName><forename type="first">Yeongkil</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seokwon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harksoo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="11319" to="11329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dwwp: domain-specific new words detection and word propagation system for sentiment analysis in the tourism domain</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="203" to="214" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">When is a liability not a liability? Textual analysis, dictionaries, and 10-ks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Loughran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Finance</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Audio-visual speech recognition using deep learning</title>
		<author>
			<persName><forename type="first">Kuniaki</forename><surname>Noda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="722" to="737" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Enhancing quantitative intra-day stock return prediction by integrating both market news and stock prices information</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="228" to="238" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using Structured Events to Predict Stock Price Movement: An Empirical Investigation</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks‖</title>
		<author>
			<persName><forename type="first">Yangtuo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">June 12-17, 2016</date>
			<biblScope unit="page" from="374" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sentiment analysis in organizational work: Towards an ontology of people analytics</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Gelbard</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Expert Systems (2018): e12289</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A review of sentiment analysis research in Chinese language</title>
		<author>
			<persName><forename type="first">Haiyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="423" to="435" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">When does the stock market listen to economic news? New evidence from copulas and news wires</title>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Medovikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Banking &amp; Finance</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="27" to="40" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The vanishing gradient problem during learning recurrent neural nets and problem solutions</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Snowball: A language for stemming algorithms</title>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Approach for Forecasting Stock Price Direction: Nonlinear Probability Models with Application in S&amp;P 500 Index</title>
		<author>
			<persName><forename type="first">Armin</forename><surname>Jabbarzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Engineering Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3870" to="3878" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuldip</forename><forename type="middle">K</forename><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Statistical analysis of the overnight and daytime return</title>
		<author>
			<persName><forename type="first">Fengzhong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">56109</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Gate-variants of Gated Recurrent Unit (GRU) neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Salemt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 60th Midwest Symposium on Circuits and Systems (MWSCAS)</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1597" to="1600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Jun Ryeol Park, Sung Wook Baik: Oversampling Techniques for Bankruptcy Prediction: Novel Features from a Transaction Dataset</title>
		<author>
			<persName><forename type="first">Tuong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mi</forename><forename type="middle">Young</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Baik</surname></persName>
		</author>
		<title level="m">Cluster-based boosting algorithm for bankruptcy prediction in highly imbalanced dataset. Symmetry</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
