<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A methodological approach to the classification of dermoscopy images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><surname>Emre Celebi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<addrLine>416 Yates Street, Room 300</addrLine>
									<postBox>Box 19015</postBox>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nedderman Hall</orgName>
								<address>
									<postCode>76019-0015</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Hassan</forename><forename type="middle">A</forename><surname>Kingravi</surname></persName>
							<email>kingravi@cse.uta.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<addrLine>416 Yates Street, Room 300</addrLine>
									<postBox>Box 19015</postBox>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nedderman Hall</orgName>
								<address>
									<postCode>76019-0015</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bakhtiyar</forename><surname>Uddin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<addrLine>416 Yates Street, Room 300</addrLine>
									<postBox>Box 19015</postBox>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nedderman Hall</orgName>
								<address>
									<postCode>76019-0015</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hitoshi</forename><surname>Iyatomi</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Electrical Informatics</orgName>
								<orgName type="institution">Hosei University</orgName>
								<address>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Y</forename><forename type="middle">Alp</forename><surname>Aslandogan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The University of Texas at Arlington</orgName>
								<address>
									<addrLine>416 Yates Street, Room 300</addrLine>
									<postBox>Box 19015</postBox>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Nedderman Hall</orgName>
								<address>
									<postCode>76019-0015</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">V</forename><surname>Stoecker</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Stoecker &amp; Associates</orgName>
								<address>
									<addrLine>1100 W. 10th Street</addrLine>
									<postCode>65401-2937</postCode>
									<settlement>Rolla</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Randy</forename><forename type="middle">H</forename><surname>Moss</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Missouri-Rolla</orgName>
								<address>
									<addrLine>226 Emerson Electric Co. Hall</addrLine>
									<postCode>65409-0040</postCode>
									<settlement>Rolla</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A methodological approach to the classification of dermoscopy images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">234D1BD26874A59621DD11DB69288F7A</idno>
					<idno type="DOI">10.1016/j.compmedimag.2007.01.003</idno>
					<note type="submission">Received 17 February 2006; accepted 8 January 2007</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T17:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Skin cancer</term>
					<term>Dermoscopy</term>
					<term>Melanoma</term>
					<term>Classification</term>
					<term>Support vector machine</term>
					<term>Model selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper a methodological approach to the classification of pigmented skin lesions in dermoscopy images is presented. First, automatic border detection is performed to separate the lesion from the background skin. Shape features are then extracted from this border. For the extraction of color and texture related features, the image is divided into various clinically significant regions using the Euclidean distance transform. This feature data is fed into an optimization framework, which ranks the features using various feature selection algorithms and determines the optimal feature subset size according to the area under the ROC curve measure obtained from support vector machine classification. The issue of class imbalance is addressed using various sampling strategies, and the classifier generalization error is estimated using Monte Carlo cross validation. Experiments on a set of 564 images yielded a specificity of 92.34% and a sensitivity of 93.33%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Malignant melanoma is one of the most rapidly increasing cancers in the world, with an estimated incidence of 59,580 and an estimated total of 7770 deaths in the United States in 2005 alone <ref type="bibr" target="#b0">[1]</ref>. Early diagnosis is particularly important since melanoma can be cured with a simple excision if detected early.</p><p>Dermoscopy is a non-invasive skin imaging technique that uses optical magnification and either liquid immersion and low angle-of-incidence lighting or cross-polarized lighting to make the contact area translucent, making subsurface structures more easily visible when compared to conventional clinical images <ref type="bibr" target="#b1">[2]</ref>. This reduces screening errors, and provides greater differentiation between difficult lesions such as pigmented Spitz nevi and small, clinically equivocal lesions <ref type="bibr" target="#b2">[3]</ref>. However, it has been demonstrated that dermoscopy may actually lower the diagnos-tic accuracy in the hands of inexperienced dermatologists <ref type="bibr" target="#b3">[4]</ref>. Furthermore, for the diagnosis, dermatologists rely on their clinical experience and visual perception. However, diagnosis made by human vision is somewhat subjective, lacking accuracy and reproducibility.</p><p>Computerized dermoscopy image analysis systems do not have the limitation of this subjectivity. These systems allow the use of a computer as a second independent diagnostic method, which can potentially be used for the prescreening of patients performed by non-experienced operators and for aiding clinicians <ref type="bibr" target="#b4">[5]</ref>. Although computerized analysis techniques cannot provide a definitive diagnosis, they can be used to improve biopsy decision-making, which some observers feel is the most important use for dermoscopy <ref type="bibr" target="#b5">[6]</ref>. For example, clinicians can avoid biopsy for such significant classes of lesions as vascular lesions and dysplastic nevi. Finally, automated analysis can serve as an additional tool to improve follow-up, especially for patients with multiple atypical nevi <ref type="bibr" target="#b4">[5]</ref>.</p><p>Studies related to the automated classification of pigmented skin lesion images have appeared in the literature as early as 1987 <ref type="bibr" target="#b6">[7]</ref>. Different methods for border detection, feature extraction, and classification have been applied to various image sets mostly  obtained from single sources. Table <ref type="table" target="#tab_0">1</ref> summarizes some key results from 2001 onwards.</p><p>In this paper, a methodological approach to the classification of dermoscopy images is presented. Fig. <ref type="figure" target="#fig_0">1</ref> shows an overview of the proposed approach.</p><p>The rest of the paper is organized as follows. Section 2 describes the data set collection. Section 3 explains the border detection. Section 4 discusses the feature extraction. Section 5 describes the feature selection. Section 6 presents the support vector machines. Section 7 describes the classification experiments. Finally, Section 8 gives the conclusions and the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data set description</head><p>The digital dermoscopy images were collected from two dermoscopy atlases <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref>. The images in <ref type="bibr" target="#b1">[2]</ref> were acquired in three university hospitals (University of Graz, Austria, University of Naples, Italy and University of Florence, Italy), while those in <ref type="bibr" target="#b16">[17]</ref> were acquired in the Sydney Melanoma Unit, Sydney, Australia. These were true-color images with a typical resolution of 768 × 512 pixels. Since we had no control over the image acquisition and camera calibration, images that satisfied at least one of the following criteria were omitted from the study: (i) the lesion does not fit entirely within the image frame, (ii) presence of too much hair, and (iii) insufficient contrast between the lesion and the background skin. This selectivity was necessary in order to ensure accurate border detection and reliable feature extraction. Fig. <ref type="figure" target="#fig_1">2</ref> shows sample images that were eliminated using these criteria. A total of 596 images free from the above mentioned problems were included in the initial image set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Border detection</head><p>The first step in the computerized analysis of skin lesion images is the detection of the lesion borders. The importance of the border detection for the analysis is two-fold. First, the border structure provides vital information for accurate diagnosis. Many clinical features such as asymmetry and border irregularity are calculated from the border. Second, the extraction of other important color or texture related clinical features critically depends on the accuracy of the border detection.</p><p>For border detection, an automated method that we developed earlier <ref type="bibr" target="#b17">[18]</ref> was used. The method is based on the JSEG algorithm <ref type="bibr" target="#b18">[19]</ref> and included three main phases: preprocessing, segmentation, and postprocessing. The preprocessing phase included image smoothing using a color median filter with an 11 × 11 kernel, color reduction using the variance-based quantization method <ref type="bibr" target="#b19">[20]</ref>, and approximate lesion localization based on the Otsu thresholding method <ref type="bibr" target="#b20">[21]</ref>. The segmentation phase  The border detection method was applied to the initial set of 596 images. Fig. <ref type="figure" target="#fig_2">3</ref> shows examples of successful and unsuccessful border detection results. In 32 of the images the results were deemed to be unsatisfactory. Failure mostly occurred in one of two cases: (i) lesions in which there is a very smooth transition between the border and the background skin (see Fig. <ref type="figure" target="#fig_2">3c</ref>) and (ii) lesions with regression (scar-like depigmentation) structures (see Fig. <ref type="figure" target="#fig_2">3d</ref>). After the exclusion of these images, 564 images remained in the image set.</p><p>Among the 564 cases, 88 were melanoma and 476 were benign. Among the melanoma cases, 18 were melanomas in situ, 47 were thin invasive melanomas, 13 had a thickness between 0.76 and 1.5 mm, 7 had a thickness of more than 1.5 mm, and 3 were metastasized. The distribution of the benign cases was as follows: 309 Clark nevi, 45 Reed/Spitz nevi, 31 seborrheic keratoses, 19 compound nevi, 17 blue nevi, 9 combined nevi, 9 dermal nevi, 9 melanoses, 9 vascular lesions, 7 lentigines, 4 congenital nevi, 3 junctional nevi, 3 dermatofibromas, and 2 hemangiomas. The lesions were biopsied and diagnosed histopathologically in cases where significant risk for melanoma was present; otherwise they were diagnosed by follow-up examination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Feature extraction</head><p>In this section the features that were used to characterize the skin lesion images are described. A particular problem in the related literature is that a significant number of studies do not report the details of their feature extraction procedure <ref type="bibr" target="#b21">[22]</ref>. This is further compounded by the inconsistency in the definitions of some of the features (especially those pertaining to shape) in the computer vision literature. Therefore, in order to enhance the reproducibility of this study, we explain the rationale for each feature and present the algorithmic aspects involved in its computation in as much detail as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Description of the shape features</head><p>Shape is an important clinical feature in the diagnosis of pigmented skin lesions. In the following discussion, "object" refers to the binary lesion object obtained as a result of the border detection.</p><p>(a) Area (A): The lesion area can be calculated by counting the number of pixels inside the border. However, this method is not very accurate for objects with rough borders <ref type="bibr" target="#b22">[23]</ref>. For this reason, the lesion area was calculated using the method of bit quads <ref type="bibr" target="#b20">[21]</ref> which has been shown to be one of the most accurate area estimators in the literature <ref type="bibr" target="#b22">[23]</ref>. (b) Aspect ratio (A R ): Aspect ratio can be defined as the ratio of the length of the major axis (L 1 ) to the length of the minor axis (L 2 ). These are given in the first column of Table <ref type="table" target="#tab_1">2</ref>.</p><p>Here, (r 0 ,c 0 ) denotes the object centroid, and m pq and μ pq (r 0 , c 0 ) = (m 10 /m 00 , m 01 /m 00 )</p><formula xml:id="formula_0">μ pq = rows i=0 cols j=0 (i -r 0 ) p • (j -c 0 ) q L 1,2 = (8(μ 02 + μ 20 ± ((μ 02 -μ 20 ) 2 + 4μ 11 ) 1/2 )) 1/2 A R = L 1 /L 2 ε = (μ 02 -μ 20 ) 2 +4μ 11 (μ 02 +μ 02 ) 2 θ = 1 2 tan -1 2μ 11 μ 20 -μ 02 A 1 = min(A x , A y ) A × 100% A 2 = A x + A y A × 100%</formula><p>denote the (p + q)th order geometric and central moments of the object, respectively. (c) Asymmetry 1 and 2 (A 1 and A 2 ): In order to evaluate the lesion asymmetry, first, the major axis orientation of the object (θ) was calculated (Table <ref type="table" target="#tab_1">2</ref>). Second, the object was rotated θ degrees clockwise to align the principal (major and minor) axes with the image (x and y) axes. The object was then hypothetically folded about the x-axis and the area difference (A x ) between the overlapping folds was taken as the amount of asymmetry about the x-axis. The same procedure was performed for the y-axis. Two asymmetry measures were calculated from A x and A y as shown in Table <ref type="table" target="#tab_1">2</ref>. (d) Compactness (C): Compactness is usually defined as the ratio of the area of the object to the area of a circle with the same perimeter. This measure compares the object with a circle, which is the most compact shape. However, this requires accurate estimation of the object perimeter. Therefore, an alternative version that avoids using the perimeter was calculated as the ratio between the equivalent and maximum diameters.</p><p>Other shape features include maximum (lesion) diameter (the maximum distance between two points on the border), eccentricity (a measure of elongation, Table <ref type="table" target="#tab_1">2</ref>), solidity (a measure of border irregularity defined as the ratio between the areas of the object and its convex hull), equivalent diameter (the diameter of a circle that has the same area as the object), and two measures related with the object-oriented bounding box (the smallest rectangle that contains the object and is aligned with the principal axes): rectangularity (the ratio between the areas of the object and object-oriented bounding box) and elongation (ratio between the height and width of the object oriented-bounding box).</p><p>Note that features related with the length of the lesion border such as perimeter, circularity, thinness, roundness, form factor, etc. were not considered in this study. This is because these features depend on an accurate estimation of the lesion perimeter. However, the digital perimeter is often considerably different from the actual perimeter for complex shapes such as skin lesions. Furthermore, perimeter estimation depends greatly on the image resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Calculation of the inner and outer peripheral regions</head><p>For the calculation of color and texture features, three significant regions in the image were considered: lesion, inner periphery, and outer periphery. The lesion was obtained as a result of the automatic border detection procedure. The inner and outer peripheral regions were determined from the binary border image using a fast Euclidean distance transform algorithm <ref type="bibr" target="#b23">[24]</ref>. In order to reduce the effects of peripheral inflammation and errors in automatic border detection, the region inside (outside) the border with an area equal to 10% of the lesion area was omitted and the inner (outer) peripheral region was taken as the adjacent region with an area equal to 20% of the lesion area. This is illustrated in Fig. <ref type="figure" target="#fig_3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Description of the color features</head><p>In order to quantify the colors present in a lesion, two statistics (mean and standard deviation) over the channels of six different color spaces and several color asymmetry, histogram distance, and centroidal distance features were calculated. The color spaces considered were RGB, rgb (normalized RGB), HSV, I1/2/3 (Ohta space), l1/2/3 and CIE L * u * v * . All of these except for the l1/2/3 space are well-known in the literature <ref type="bibr" target="#b20">[21]</ref>. The l1/2/3 space is a relatively recent color space model described in <ref type="bibr" target="#b24">[25]</ref>. The nonlinear transformation from RGB to l1/2/3 is given  </p><formula xml:id="formula_1">l1 = (R -G) 2 /((R -G) 2 + (R -B) 2 + (G -B) 2 ) l2 = (R -B) 2 /((R -G) 2 + (R -B) 2 + (G -B) 2 ) l3 = (G -B) 2 /((R -G) 2 + (R -B) 2 + (G -B) 2 )</formula><p>Table <ref type="table" target="#tab_2">3</ref> shows the comparison of these color spaces according to the following criteria: decoupling of chrominance and luminance, invariance to illumination intensity, and perceptual uniformity. The first two criteria are essential for dealing with images that are acquired in uncontrolled imaging conditions such as the ones that are used in this study. The last criterion is necessary for the extraction of one of the color features (histogram distance). As it can be seen from Table <ref type="table" target="#tab_2">3</ref>, none of the six color spaces satisfies all of the criteria. This is the reason why we have considered several color spaces that complement each other. Now, we describe each color feature in detail.</p><p>(a) Mean and standard deviation: The mean and standard deviation values calculated over a particular channel quantify the average color and the color variegation in that channel, respectively. One hundred eight color features were calculated as follows: (6 color spaces) × (3 channels in each color space) × (2 statistics: mean and standard deviation) × (3 regions {lesion, inner periphery, outer periphery}). The ratios and differences of the 2 statistics over the 3 regions were also calculated: (outer/inner), (outer/lesion), (inner/lesion), (outer-inner), (outer-lesion), and (inner-lesion). The motivation for calculating the ratio and differences is two-fold. First, the color characteristics of the three regions signify valuable diagnostic information. For example, a sharp transition from the inner periphery to the outer periphery (or vice versa) indicates malignancy. So, in addition to features calculated over the three regions, the differences and ratios might provide additional information about the transition between these regions. The total number of color features in this category was 324. (b) Color asymmetry: This is a measure of the asymmetry in pigment distribution in a particular color channel. It was calculated similarly to the shape asymmetry (which is a measure of the geometric asymmetry) with the exception that pixel values were incorporated in the calculations of the first order geometric moments and the second order central moments as weighting factors. Also, after the hypothetical folding, the absolute brightness difference between the corresponding pixels in the two folds was accumulated as opposed to counting the pixels in one fold that do not have a counterpart in the other fold. The color asymmetry in the R, G, and B channels were calculated using the two asymmetry measures shown in Table <ref type="table" target="#tab_1">2</ref>. The total number of color features in this category was 6. (c) Centroidal distances: The centroidal distance for a channel is defined as the distance between the geometric centroid (of the binary object) and the brightness centroid of that channel. The brightness centroid was calculated similarly to the geometric centroid except that the moment calculations were weighted by the pixel values. If the pigmentation in a particular channel is homogeneous, the brightness centroid will be close to the geometric centroid and thus the centroidal distance for that channel will be small. In order to achieve invariance to scaling, the distance values were divided by the lesion diameter. The centroidal distance values were calculated for all 3 channels of the 6 color spaces. The total number of color features in this category was 18. (d) LUV histogram distances: In order to determine the color similarity of two regions, the histogram distance in the CIE L * u * v * color space was used. For histogram computation, the color space was coarsely quantized into 4 × 8 × 8 bins. The color similarity between the two regions was quantified by the L 1 -and L 2 -norm histogram distances <ref type="bibr" target="#b20">[21]</ref>. The use of these norms is justified because the color space is coarsely quantized and there is negligible correlation between adjacent histogram bins.</p><p>The histogram distances between pairs of the three regions, i.e. lesion, inner periphery, and outer periphery, using the two distance measures were calculated. The total number of color features in this category was 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Description of the texture features</head><p>In order to quantify the texture present in a lesion, a set of statistical texture descriptors based on the gray level co-occurrence matrix (GLCM) were employed. GLCM-based texture description is one of the most well-known and widely used methods in the literature <ref type="bibr" target="#b25">[26]</ref>. Although many statistics can be derived from the GLCM, eight gray level shift invariant statistics were used in this study in order to obtain a texture characterization that is robust to linear shifts in the illumination intensity. These statistics were maximum probability, energy, entropy, dissimilarity, contrast, inverse difference, inverse difference moment, and correlation.</p><p>To obtain statistical confidence in the estimation of the joint probability distribution, the normalized GLCM should be reasonably dense. For example, at full dynamic range (G = 256 gray levels for 8-bit images), since very few gray level pairs are repeated, the entropy statistic attains similar values for different texture patterns. In a methodological study, Clausi <ref type="bibr" target="#b25">[26]</ref> showed that above a certain threshold, for the same eight statistics, with an increasing G, the discrimination power of the statistics remain the same for two of them (dissimilarity and contrast) while decreasing for the rest. Another problem with high G values is the high computational cost in both the calculation of the GLCM (O(G)) and the statistics (O(G)). Therefore, in order to avoid having a sparse matrix, the images were uniformly quantized to 64 gray levels. Here, the choice of 64 gray levels was arbitrary, though a recent study <ref type="bibr" target="#b25">[26]</ref> has demonstrated that this value should not be too low (for example below 24). Another advantage of using a low G value is the reduction of the effects of noise in the image.</p><p>In order to obtain rotation invariant features, the normalized GLCM was computed for each of the four orientations ({0 • , 45 • , 90 • , 135 • }) and the statistics calculated from these matrices were averaged. These eight statistics were calculated over the three regions, i.e., lesion, inner periphery, and outer periphery, and as in the case of color features, the ratios and differences of the eight statistics over these regions were also calculated. The total number of texture features extracted from each image was 72.</p><p>Overall, the number of features extracted from each image was 437 (11 shape, 354 color, and 72 texture features).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Feature selection</head><p>Feature selection is an important preprocessing step in many machine-learning tasks. The purpose is to reduce the dimensionality of the feature space by eliminating redundant, irrelevant or noisy features. From the classification perspective, there are numerous potential benefits associated with feature selection: (i) reduced feature extraction time and storage requirements, (ii) reduced classifier complexity, (iii) increased prediction accuracy, (iv) reduced training and testing times, and (v) enhanced data understanding and visualization.</p><p>Feature selection algorithms can be classified into two main categories according to their evaluation criteria: filters and wrappers <ref type="bibr" target="#b26">[27]</ref>. Filter methods rely on general characteristics of the data to select a subset of features without involving any learning algorithm. They 'filter' out irrelevant and redundant features before classifier induction begins. On the other hand, wrapper methods use the prediction performance of a predetermined learning algorithm to evaluate the goodness of feature subsets. Although, wrappers are often computationally more expensive, they are better suited to classification tasks in which the classifier is predetermined.</p><p>In this study, the filter methodology is adopted for several reasons. First of all, filter methods are usually very fast which allows one to compare several alternative methods within an optimization framework. Secondly, if a wrapper method is to be used on a particular data set, the target-learning algorithm should have at least satisfactory performance on the original data set so that it can provide valuable feedback to the search procedure. However, as demonstrated in the following section, our target learning algorithm, i.e. the SVM algorithm, does not perform well on the original data due to the presence of many irrelevant or redundant features and the unbalanced distribution of the classes. Finally, the only wrapper implementation available to us was the well-known recursive feature elimination (RFE) <ref type="bibr" target="#b27">[28]</ref> algorithm which uses a linear SVM classifier to rank the features. However, in order to use the original RFE algorithm as a wrapper, one needs to use a linear SVM classifier for classification. Otherwise, if one uses another learning algorithm or even an SVM kernel other than the linear one, the RFE algorithm turns into a computationally expensive filter method! As will be explained in the next section, we decided to use a radial basis function (RBF) kernel rather than a linear one. In fact, the RFE algorithm can be modified to use an RBF kernel <ref type="bibr" target="#b27">[28]</ref>. However, in that case model selection (see Section 7) would become computationally very expensive.</p><p>Among the various filter methods proposed in the literature <ref type="bibr" target="#b26">[27]</ref> the following three were chosen for their good performance on various data sets:</p><p>• ReliefF <ref type="bibr" target="#b28">[29]</ref>: In the original Relief algorithm <ref type="bibr" target="#b29">[30]</ref>, a number of samples are selected at random from the data set and their nearest neighbors are determined. For each selected sample, the values of its features are compared to those of the nearest neighbors and the relevance scores for each feature are updated accordingly. The idea is to estimate the quality of attributes according to how well their values distinguish between samples that are near to each other. The ReliefF algorithm is an extension of the original algorithm that can handle noise and multi-class data sets. • Mutual information based feature selection (MIFS) <ref type="bibr" target="#b30">[31]</ref>:</p><p>Mutual information measures arbitrary dependencies between random variables, and thus is suitable for assessing the information content of the features. The MIFS algorithm evaluates the mutual information between individual features and the class labels, and selects those features that have the maximum mutual information. • Correlation based feature selection (CFS) <ref type="bibr" target="#b31">[32]</ref>: This algorithm tries to find a set of features that individually correlate well with the class but have little intercorrelation. The correlation between two features is measured by symmetric uncertainty <ref type="bibr" target="#b32">[33]</ref> which is an improved form of the well-known information gain measure <ref type="bibr" target="#b33">[34]</ref>.</p><p>For the ReliefF and CFS algorithms the Weka implementations <ref type="bibr" target="#b34">[35]</ref> were used. For the MIFS algorithm, the Tanagra <ref type="bibr" target="#b35">[36]</ref> implementation was used. Before feature selection, the features were discretized using the technique of Fayyad and Irani <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Support vector machines</head><p>Support vector machines (SVMs) have recently drawn considerable attention in the machine learning community due to their solid theoretical foundation and excellent practical performance. They are kernel-based learning algorithms derived from the statistical learning theory <ref type="bibr" target="#b37">[38]</ref>.</p><p>SVMs have several advantages over the more classical classifiers such as decision trees and neural networks. The support vector training mainly involves optimization of a convex cost function. Therefore, there is no risk of getting stuck at local minima as in the case of backpropagation neural networks. Most learning algorithms implement the empirical risk minimization (ERM) principle which minimizes the error on the training data. On the other hand, SVMs are based on the structural risk minimization (SRM) principle which minimizes the upper bound on the generalization error. Therefore, SVMs are less prone to overfitting when compared to the algorithms that implement the ERM principle such as backpropagation neural networks. Another advantage of SVMs is that they provide a unified framework in which different learning machine architectures (e.g., RBF networks, feedforward neural networks) can be generated through an appropriate choice of kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">General theoretical background</head><p>This subsection gives an overview of the SVM theory and is based on <ref type="bibr" target="#b38">[39]</ref>. Consider a set of n training data points {x i ,y i } ∈ R d × {-1, +1} i = 1, . . ., n , where x i represents a point in d-dimensional space and y i is a two-class label. Suppose we have a hyperplane that separates the positive samples from the negative ones. Then the points x on the hyperplane satisfy w • x + b = 0, where w is the normal to the hyperplane, and |b|/||w|| is the perpendicular distance from the hyperplane to the origin. If we take two such hyperplane between the positive and negative samples, the support vector algorithm's task is to maximize the distance (margin) between them. In order to maximize the margin, ||w|| 2 is minimized subject to the following constraints:</p><formula xml:id="formula_2">y i (x i • w + b) -1 ≥ 0 ∀i<label>(1)</label></formula><p>The training samples for which (1) hold are the only ones relevant for the classification. These are called the support vectors.</p><p>The Lagrangian function for the minimization of ||w|| 2 is given by:</p><formula xml:id="formula_3">L l = n i=1 α i - 1 2 n i=1 n j=1 y i y j α i α j x i x j subject to α i ≥ 0 ∀i and n i=1 α i y i = 0 (2)</formula><p>Equation ( <ref type="formula" target="#formula_8">2</ref>) applies only to linearly separable data. In order to handle non-linearly separable data, positive slack variables ξ i , i = 1, . . ., n are introduced into the constraints:</p><formula xml:id="formula_4">y i (x i • w + b) ≥ 1 -ξ i , ξ i ≥ 0 ∀i<label>(3)</label></formula><p>In order to control the trade-off between the model complexity and the empirical risk, a penalty parameter C is introduced into (2):</p><formula xml:id="formula_5">L nl = n i=1 α i - 1 2 n i=1 n j=1 y i y j α i α j x i x j subject to 0 ≤ α i ≤ C ∀i and i α i y i = 0 (4)</formula><p>To generalize these equations for non-linear decision functions, the concept of a kernel is introduced. The data seen in the equations so far appears in the form of dot products x i •x j . If we were to map the data to some other (possibly infinite dimensional) Euclidean space H, using a mapping , the training algorithm would depend on the data through dot products in H, i.e. (x i )• (x j ). Now, if there were a "kernel function" K such that K(x i ,x j ) = (x i )• (x j ), we would only need to use K in the training algorithm, and would never need to explicitly know what is. Substituting the kernel K into the dual SVM gives:</p><formula xml:id="formula_6">L k = n i=1 α i - 1 2 n i=1 n j=1 y i y j α i α j K(x i , x j ) subject to 0 ≤ α i ≤ C and i α i y i = 0 (5)</formula><p>This formulation allows us to deal with extremely high (theoretically infinite) dimensional mappings without having to do the associated computation. Some commonly used kernels are:</p><formula xml:id="formula_7">• Linear: K(x i , x j ) = x T i • x j • Polynomial: K(x i , x j ) = (γx T i • x j + r) d , γ &gt; 0 • Radial basis function (RBF): K(x i , x j ) = e -γ||x i -x j || 2 /2σ 2 , γ &gt; 0 • Sigmoid: K(x i , x j ) = tan h (γx T i • x j + r), γ &gt; 0</formula><p>In this study, the radial basis function (RBF) kernel was adopted for various reasons. Firstly, the linear kernel cannot handle nonlinearly separable classification tasks, and in any case, is a special case of the RBF kernel <ref type="bibr" target="#b39">[40]</ref>. Secondly, the computation of the RBF kernel is more stable than that of the polynomial kernel, which introduces values of zero or infinity in certain cases. Thirdly, the sigmoid kernel is only valid (i.e. satisfies Mercer's conditions <ref type="bibr" target="#b38">[39]</ref>) for certain parameters. Finally, the RBF kernel has fewer hyperparameters (γ) which need to be determined when compared to the polynomial (γ,r,d) and sigmoid kernels (γ,r).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Feature normalization</head><p>In classification tasks the features that characterize the samples quite often have different ranges. Many classifiers such as k-nearest neighbors and neural networks require that the features be normalized so that their values fall within a specified range. In the case of SVMs, feature normalization is an important preprocessing step that is necessary to prevent features with large ranges from dominating the calculations and also to avoid numerical instabilities in the kernel computations.</p><p>One of the most common normalization methods is the zscore transformation <ref type="bibr" target="#b40">[41]</ref> given by:</p><formula xml:id="formula_8">z ij = ((x ij -μ j )/(3σ j ) + 1)<label>2</label></formula><p>where x ij represents the value of the jth feature of the ith sample; μ j and σ j are the mean and standard deviation of the jth feature, respectively.</p><p>Assuming that each feature is normally distributed, this transformation guarantees 99% of z ij be in the [0,1] range. The out-of-range values are truncated to either 0 or 1. The normality of each feature distribution was verified using the moments of skewness and kurtosis (5% significance level). For more information about these tests, the reader is referred to <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Classification experiments</head><p>In this section the classification experiments are described. First, the initial experiments with the SVM classifier are presented. Second, the class imbalance problem and the strategies to deal with it are introduced. Third, the model selection procedure and the experimental results are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Initial experiments with the SVM classifier</head><p>In order to use the RBF kernel, appropriate values for the kernel parameters C (cost/penalty) and γ (kernel width) need to be determined. The purpose of model selection is to identify the optimal values for these parameters that give the maximum prediction accuracy on future as-yet-unseen data. Since there are only two parameters, a grid-search is feasible. Following <ref type="bibr" target="#b42">[43]</ref>, exponentially growing sequences of values, i.e., C ∈ {2 -5 , 2 -3 , . . ., 2 15 } and γ ∈ {2 -15 , 2 -13 , . . ., 2 3 }, for these parameters were tried. During the grid-search procedure, ten-fold stratified cross-validation was performed to evaluate the goodness of a particular combination of parameter values, i.e., (C 0 , γ 0 ). After the grid-search, the SVM classifier was trained with the optimal parameters (C * , γ * ). Ten times 10-fold stratified Monte Carlo cross-validation was used to estimate the classification error.</p><p>Initially, the procedure described above was performed on the full data set (564 samples, 437 features). The optimal parameter values (C * , γ * ) = (2.0, 0.125) yielded 24.7% sensitivity and 97.5% specificity. This unsatisfactory result was expected considering the high number of features (many of which are possibly redundant or irrelevant) and particularly the unbalanced distribution of classes (15.6% melanoma, 84.4% benign). In the next subsection, the class imbalance problem and the strategies to deal with it are described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Dealing with class imbalance</head><p>There has been recent interest in the problem of class imbalance in the machine learning community. This problem typically occurs when one or more classes outnumber the others. In such cases, most classifiers focus on learning the large classes which leads to poor classification accuracy for the small classes. In practice, this may not be catastrophic in domains in which the classes have similar misclassification costs. However, in many domains such as medical diagnosis and fraud detection the misclassification costs are often unequal and classifying the minority (melanoma) samples as majority (benign) implies serious consequences.</p><p>The most common classifier performance measure is the accuracy defined as the percentage of correctly classified samples. However, accuracy is not an appropriate measure of the classification performance when the data is unbalanced. Consider a data set with a class distribution of 99:1. A classifier that always predicts samples as the majority class will have an accuracy of 99%. This is because the accuracy measure is strongly biased to favor the majority class.</p><p>A better performance measure in unbalanced domains is the receiver operating characteristic (ROC) curve. The ROC curve is a plot of the true positive (TP)-rate (percentage of correctly classified positive samples) versus false positive (FP)-rate (percentage of incorrectly classified negative samples). The points for a ROC curve are obtained by varying a threshold on a classifier's continuous output between its extremes and plotting the (TP-rate, FP-rate) for each threshold value. The curve illustrates the behavior of a classifier without regard to class distributions or error costs, and thus decouples the classification performance from these factors. The area under the ROC curve (AUC) represents the expected predictive performance as a single scalar value <ref type="bibr" target="#b43">[44]</ref>. AUC exhibits several desirable properties compared to accuracy. For example, it is independent of the decision threshold and is invariant to apriori class probability distributions. In a recent study Huang and Ling <ref type="bibr" target="#b43">[44]</ref> have demonstrated that AUC is a statistically consistent and more discriminatory measure than accuracy. In this study AUC was used to evaluate the goodness of a particular classifier model.</p><p>One of the most common and effective techniques for dealing with imbalance is sampling <ref type="bibr" target="#b44">[45]</ref>. The motivation for sampling comes from the observation that the natural distribution of the classes might not be optimal from the classification perspective <ref type="bibr" target="#b45">[46]</ref>. Several studies have demonstrated that the accuracy degradation on unbalanced data sets is more severe when the classes overlap significantly <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>; this is the case in skin lesion classification. For example, early melanomas (melanoma in situ) are often confused with Clark nevi by dermoscopy practitioners.</p><p>There are two basic sampling methods: under-sampling (removing majority class samples) and over-sampling (adding minority class samples). In this study, two common sampling methods were compared:</p><p>(a) Random under-sampling, which eliminates randomly chosen majority class samples. (b) Synthetic minority oversampling technique (SMOTE) <ref type="bibr" target="#b48">[49]</ref>,</p><p>which over-samples the minority class by taking each minority class sample and introducing synthetic samples along the line segments joining n of the k minority class nearest neighbors. In this study k = 10 was used. The value of n depends on the amount of over-sampling. For example, if the amount of over-sampling needed is 200%, only two neighbors from the 10 nearest neighbors are chosen and one synthetic sample is generated in the direction of each.</p><p>We decided to add (remove) minority (majority) samples until an approximately balanced class distribution was reached. This was motivated by the results presented in <ref type="bibr" target="#b45">[46]</ref>, in which the authors demonstrate that when AUC is used as the performance measure, the optimal class distribution for learning tends to be near the balanced distribution. For random under-sampling, this amounted to randomly removing 476 × 80% = 380 majority samples resulting in a 96:88 benign to melanoma class ratio. For SMOTE, four synthetic melanoma samples were created from each melanoma sample, resulting in a 476:440 benign to melanoma ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Model selection and experimental results</head><p>As demonstrated earlier, the number of features retained by the feature selection algorithm (k) is an important parameter that needs to be considered in order to obtain a good classification performance. Considering the complexity of the problem in our case, a small number of features is not likely to discriminate between the classes well. On the other hand, a large number of features might lead to overfitting as explained in Section 5. With these considerations, the range of k was restricted to <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>The optimization procedure after the integration of sampling and feature selection was as follows (Fig. <ref type="figure" target="#fig_4">5</ref>): Examining Fig. <ref type="figure" target="#fig_6">6a</ref> closely, it can be seen that the AUC peaks at k = 18 and the inclusion of features beyond this value does not add much to the classifier performance. This shows that most of the features are in fact either redundant or irrelevant. Therefore, we decided to use the top k = 18 features given by the CFS feature selection algorithm. This gave a specificity of 92.34% and a sensitivity of 93.33%. The ROC curve is shown in Fig. <ref type="figure" target="#fig_6">6b</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion and conclusions</head><p>In this study, a methodological approach to the classification of dermoscopy images is presented. The approach involved border detection, feature extraction, and SVM classification with model selection. The system was tested on a large set of images. Promising results were obtained despite the fact that the images came from different sources and there was no control over their acquisition. The total processing time for the classification of a new image ranges from 5 to 10 s. This can be further reduced by using a faster border detection method such as the one presented in <ref type="bibr" target="#b49">[50]</ref>.</p><p>This study differs from earlier studies in several aspects. First, the images used in this study came from different sources. For this reason, care was taken to extract features that are invariant to changes in the imaging conditions. Second, starting from the border detection until the classification, the whole procedure was fully automated. Third, for border detection a published method was used. Fourth, certain diagnostic classes that occur frequently in the clinical setting such as Clark nevi and seborrheic keratoses were not excluded from the image set. In addition, difficult lesions such as melanomas in situ and Spitz nevi were not excluded. Finally, the issue of feature selection was addressed in an optimization framework without using arbitrary cutoffs.</p><p>Despite the high accuracy that can be achieved by computeraided diagnostic systems employing statistics obtained from low-level features such as the one presented, at least two issues need to be addressed before these systems can gain greater clinical acceptance. First, higher level features based on a particular diagnostic scheme such as pattern analysis <ref type="bibr" target="#b1">[2]</ref> should be integrated with the existing low level features. Second, the image set should be expanded to provide better training and testing for the developed algorithms.</p><p>The elimination of some of the images because of the problems noted in Section 2 might be considered a limitation of the present study. However, this is in line with the limitations imposed in previous studies. Studies vary in the detail given about which lesions are included in the training and test sets. In some studies, incompletely imaged lesions were omitted as we have done <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b8">9]</ref>. In some others, some of the lesions that were eliminated here were made acceptable by other means, such as shaving hairs prior to image acquisition <ref type="bibr" target="#b10">[11]</ref> or by obtaining manual borders for the lesions <ref type="bibr" target="#b15">[16]</ref>. An alternative approach to overcome the hair problem could be using a software razor such as Dullrazor <ref type="bibr" target="#b50">[51]</ref> that can, with some modifications, eliminate hairs without altering the pigment network. It is likely that further research, by extraction of critical features such as atypical pigment networks, globules, and blue-white areas <ref type="bibr" target="#b51">[52]</ref>, can increase the diagnostic accuracy of computerized dermoscopy image analysis systems.</p><p>versity of Missouri-Rolla. He is an associate editor of both Pattern Recognition and Computerized Medical Imaging and Graphics. His research interests emphasize medical applications, but also include industrial applications of machine vision and image processing. He is a senior member of IEEE and a member of the Pattern Recognition Society and Sigma Xi. He is a past recipient of the Society of Automotive Engineers Ralph R. Teetor Educational Award and the Society of Manufacturing Engineers Young Manufacturing Engineer Award. He is a past National Science Foundation Graduate Fellow and National Merit Scholar.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic of the system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Sample images omitted from the study: (a) incompletely imaged lesion (diameter = 35 mm), (b) too much hair, and (c) insufficient contrast between the lesion and the background skin.</figDesc><graphic coords="2,111.16,642.54,382.32,76.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Examples of successful (a, b) and unsuccessful (c, d) border detection results.</figDesc><graphic coords="3,76.34,66.25,432.72,277.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Inner and outer peripheral regions of a sample lesion image.</figDesc><graphic coords="4,317.15,568.56,240.12,158.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Overview of the optimization framework.</figDesc><graphic coords="9,36.56,66.17,243.63,153.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Perform feature selection using {CFS, MIFS, ReliefF} (b) Reduce the data dimensionality by keeping only the top k (k ∈ [5,30]) features in the ranking returned by the feature selection algorithm. (c) Perform sampling using {random under-sampling, SMOTE} (d) Perform grid-search. (e) Perform SVM classification (10 times 10-fold Monte Carlo stratified cross validation) using the optimal parameter values returned by the grid-search. Calculate the sensitivity, specificity, and AUC values. The procedure presented was run on three different processors (one 1.8 GHz Intel Xeon and two 1.5 GHz IBM P5-570) in parallel. The total time taken by the experiments was approximately 12 h. The optimization results for the two sampling algorithms are shown in Fig. 6a. Each curve is a plot of AUC versus feature subset size (k). Given a k value, only the highest AUC value achieved by any one of the three feature selection algorithms is shown in the plot. It can be seen that SMOTE performed better than random under-sampling for most k values. This was expected since random under-sampling discards potentially useful data by removing 80% of the majority (benign) class to make the class distributions approximately balanced. For example, during this removal some of the benign subclasses that have few examples such as congenital nevi and dermatofibroma might be completely eliminated. Also, undersampling severely reduces the data set size which makes learning much more difficult.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Optimization results for the two sampling methods, (b) ROC curve for the optimal parameter set.</figDesc><graphic coords="9,83.34,547.10,419.04,179.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Summary of recent studies using dermoscopy images</figDesc><table><row><cell>Source</cell><cell>Year</cell><cell>Segmentation method</cell><cell>Classifier</cell><cell>Total images</cell><cell>Mel. (%)</cell><cell>Dys. (%)</cell><cell>Sens.</cell><cell>Spec.</cell></row><row><cell>[8]</cell><cell>2001</cell><cell>Thresholding</cell><cell>NR</cell><cell>246</cell><cell>26</cell><cell>45</cell><cell>100</cell><cell>84</cell></row><row><cell>[9]</cell><cell>2001</cell><cell>Thresholding + color clustering</cell><cell>kNN</cell><cell>5363</cell><cell>2</cell><cell>19</cell><cell>73</cell><cell>89</cell></row><row><cell>[10]</cell><cell>2001</cell><cell>Thresholding</cell><cell>ANN</cell><cell>58</cell><cell>38</cell><cell>19</cell><cell>77</cell><cell>75</cell></row><row><cell>[11]</cell><cell>2002</cell><cell>Edge detection</cell><cell>ANN</cell><cell>147</cell><cell>39</cell><cell>29</cell><cell>93</cell><cell>92.75</cell></row><row><cell>[12]</cell><cell>2002</cell><cell>None</cell><cell>CART</cell><cell>40</cell><cell>50</cell><cell>30</cell><cell>100</cell><cell>91</cell></row><row><cell>[13]</cell><cell>2003</cell><cell>NR</cell><cell>Multiple classifiers</cell><cell>152</cell><cell>28</cell><cell>NR</cell><cell>81</cell><cell>74</cell></row><row><cell>[14]</cell><cell>2004</cell><cell>Thresholding + region growing</cell><cell>ANN</cell><cell>319</cell><cell>24</cell><cell>59</cell><cell>86.6</cell><cell>90.2</cell></row><row><cell>[15]</cell><cell>2004</cell><cell>NR</cell><cell>Logistic regression</cell><cell>837</cell><cell>10</cell><cell>11</cell><cell>80.0</cell><cell>82.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>88.1</cell><cell>82.7</cell></row><row><cell>[16]</cell><cell>2005</cell><cell>Semi-automatic + manual</cell><cell>Logistic regression</cell><cell>2430</cell><cell>16</cell><cell>25</cell><cell>91</cell><cell>65</cell></row></table><note><p>NR: not reported, kNN: k nearest-neighbor, ANN: artificial neural network, CART: classification and regression trees, Mel.: melanoma, Dys.: dysplastic, Sens.: sensitivity, Spec.: specificity.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Formulae for some of the shape features</cell><cell></cell></row><row><cell>Aspect ratio</cell><cell>Eccentricity</cell><cell>Asymmetry</cell></row><row><cell>rows</cell><cell>cols</cell><cell></cell></row><row><cell>m pq =</cell><cell>i p j q</cell><cell></cell></row><row><cell>i=0</cell><cell>j=0</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Comparison of several color spaces used in the study</figDesc><table><row><cell cols="7">Criterion L  Decoupling of chrominance and luminance RGB rgb HSV I1/2/3 l1/2/3 No No Yes Yes No Yes</cell></row><row><cell>Invariance to illumination intensity</cell><cell>No</cell><cell>Yes</cell><cell>H,S</cell><cell>No</cell><cell>Yes</cell><cell>No</cell></row><row><cell>Perceptual uniformity</cell><cell>No</cell><cell>No</cell><cell>No</cell><cell>No</cell><cell>No</cell><cell>Yes</cell></row><row><cell>by:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>* u * v *</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by grants from NIH (SBIR grant 1R43 CA-101639-01), NSF (#0216500-EIA), Texas Workforce Commission (#3204600182), and James A. Schlipmann Melanoma Cancer Foundation. The permission to use the images from the EDRA Interactive Atlas of Dermoscopy is gratefully acknowledged.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">CA</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jemal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Samuels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghafoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer statistics</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="30" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note>Cancer J Clin</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Dermoscopy: A Tutorial</title>
		<author>
			<persName><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Piccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Delfino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>EDRA Medical Publishing &amp; New Media</publisher>
			<pubPlace>Milan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Statistical evaluation of epiluminescence dermoscopy criteria for melanocytic pigmented lesions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pehamberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Acad Dermatol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="581" to="588" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Epiluminescence microscopy. a useful tool for the diagnosis of pigmented skin lesions for formally trained dermatologists</title>
		<author>
			<persName><forename type="first">M</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch Dermatol</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="286" to="291" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A multicentre study for collection and computer-aided analysis of data from pigmented skin lesions using digital dermoscopy</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gambichler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rick</forename><forename type="middle">A</forename><surname>Kreutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anschuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grunendick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br J Dermatol</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="801" to="809" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Diagnostic and neural analysis of skin cancer (DANAOS)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Epiluminescence microscopy: A re-evaluation of its purpose</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bystryn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch Dermatol</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="378" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A possible new tool for clinical diagnosis of melanoma: The computer</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cascinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferrario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Leo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Acad Dermatol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="367" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic differentiation of melanoma from melanocytic nevi with multispectral digital dermoscopy: A feasibility study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Rabinovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Langley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kamino</surname></persName>
		</author>
		<author>
			<persName><surname>Mihm</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><surname>Mc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Acad Dermatol</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automated melanoma recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ganster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rohrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wildling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Med Imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="239" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Artificial neural networks in cancer diagnosis, prognosis, and patient management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hintz-Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Drzewiecki</surname></persName>
		</author>
		<editor>Naguib RNG, Sherbet GV</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>CRC Press</publisher>
			<biblScope unit="page" from="141" to="183" />
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
	<note>A probabilistic neural network framework for detection of malignant melanoma</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Digital dermoscopy. Analysis and artificial neural network for the differentiation of clinically atypical pigmented skin lesions: A retrospective study</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rubegni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cevenini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Perotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dell</forename><forename type="middle">'</forename><surname>Eva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Barbini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Invest Dermatol</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="471" to="474" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tissue counter analysis of dermatoscopic images of melanocytic skin tumors: Preliminary findings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kahofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hofmann-Wellenhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Melanoma Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="75" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A multiple classifier system for early melanoma diagnosis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sboner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eccher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blanzieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cristofolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zumiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="44" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantitative assessment of tumour extraction from dermoscopy images and evaluation of computer-based extraction methods for an automatic melanoma diagnostic system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Iyatomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Oka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Melanoma Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Digital image analysis for diagnosis of cutaneous melanoma. development of a highly effective computer algorithm based on analysis of 837 melanocytic lesions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luedtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ellwanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schwabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br J Dermatol</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1029" to="1038" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The performance of SolarScan: An automated dermoscopy image analysis instrument for the diagnosis of primary melanoma</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gutenev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Avramidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch Dermatol</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1388" to="1396" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">An atlas of surface microscopy of pigmented skin lesions: dermoscopy. 2nd ed</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Crotty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ingwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Mccarthy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>Sydney</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised border detection in dermoscopy images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Aslandogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Stoecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iyatomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Oka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Skin Res Technol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised segmentation of color-texture regions in images and video</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Machine Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="800" to="810" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Variance-based color image quantization for frame buffer display</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prusinkewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skm</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Color Res Appl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="58" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Digital image processing: PIKS inside</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>rd ed</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automated melanoma diagnosis: where are we at?</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Barbour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Skin Res Technol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Methods to estimate areas and perimeters of blob-like objects: a comparison</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Albregtsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lonnestad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grottum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IAPR workshop on machine vision applications</title>
		<meeting>the IAPR workshop on machine vision applications</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="272" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Distance Transforms of Sampled Functions. Cornell Computing and Information Science TR</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<ptr target="http://people.cs.uchicago.edu/∼pff/papers/dt.pdf" />
		<imprint>
			<date type="published" when="1963">2004. 1963. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Color-based object recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="464" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An analysis of co-occurrence texture statistics as a function of gray level quantization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clausi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canad J Remote Sens</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="62" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Toward integrating feature selection algorithms for classification and clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowledge Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="491" to="502" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barnhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Induction of decision trees using RELIEFF</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Šimec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CISM courses and lectures no. 363</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Riccia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Kruse</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Viertl</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The feature selection problem: traditional methods and a new algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Rendell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 10th Nat Conf Artifi Intell</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Swartout</surname></persName>
		</editor>
		<meeting>10th Nat Conf Artifi Intell</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="129" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using mutual information for selecting features in supervised neural net learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="537" to="550" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Correlation-based feature selection for discrete and numeric class machine learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc 17th Int Conf Machine Learn</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</editor>
		<meeting>17th Int Conf Machine Learn<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="359" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Numerical recipes in C: The art of scientific computing. 2nd ed</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Vetterling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">C4.5: Programs for machine learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Data mining: Practical machine learning tools and techniques. 2nd ed</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TANAGRA: A Free software for research and academic purposes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rakotomalala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conf</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="697" to="702" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note>Proc EGC</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi-interval discretization of continuous attributes as pre-processing for classification learning</title>
		<author>
			<persName><forename type="first">U</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international joint conference on artificial intelligence</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</editor>
		<meeting>the 13th international joint conference on artificial intelligence<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1022" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Statistical learning theory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName><forename type="first">Cjc</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining Knowledge Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Asymptotic behaviors of support vector machines with Gaussian kernel</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1667" to="1689" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Feature normalization and likelihood-based similarity measures for image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog Lett</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="563" to="582" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Testing for normality</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Thode</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>CRC Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A practical guide to support vector classification</title>
		<author>
			<persName><forename type="first">C-W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/∼cjlin/papers/guide/guide.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Using AUC and accuracy in evaluating learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowledge Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="310" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mining with rarity: a unifying framework</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="19" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning when training data are costly: the effect of class distribution on tree induction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Artif Intell Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="315" to="354" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data sets: a comparison of various strategies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshop on Learning from Imbalanced Data Sets</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</editor>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Class imbalances versus class overlapping: an analysis of a learning system behavior</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Prati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geapa</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Monard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third Mexican international conference on artificial intelligence, lecture notes in computer science</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Monroy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Arroyo-Figueroa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Sossa</surname></persName>
		</editor>
		<meeting>the third Mexican international conference on artificial intelligence, lecture notes in computer science</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2972</biblScope>
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">SMOTE: synthetic minority over-sampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Artif Intell Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fast and accurate border detection in dermoscopy images using statistical region merging to appear in</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kingravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Stoecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Aslandogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Proceedings of the SPIE Medical Imaging 2007 Conference</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-02">February 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Dullrazor-A software approach to hair removal from images</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mclean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="533" to="543" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Detection of bluewhite veil areas in dermoscopy images using machine learning techniques</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kingravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Aslandogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Stoecker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Medical Imaging 2006 Conference</title>
		<meeting>the SPIE Medical Imaging 2006 Conference</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">6144</biblScope>
			<biblScope unit="page" from="1861" to="1868" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
