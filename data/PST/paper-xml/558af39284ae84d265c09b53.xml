<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Complex ICA by Negentropy Maximization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Member, IEEE</roleName><forename type="first">Michael</forename><surname>Novey</surname></persName>
							<email>mnovey1@umbc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Maryland Baltimore County</orgName>
								<address>
									<postCode>21250</postCode>
									<settlement>Balti-more</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Complex ICA by Negentropy Maximization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7FE937E3307BC0CB2BD57C0CB1F7E79C</idno>
					<idno type="DOI">10.1109/TNN.2007.911747</idno>
					<note type="submission">received December 4, 2006; revised May 17, 2007; accepted September 1, 2007.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Complex-valued data</term>
					<term>independent component analysis (ICA)</term>
					<term>quasi-Newton algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we use complex analytic functions to achieve independent component analysis (ICA) by maximization of non-Gaussianity and introduce the complex maximization of non-Gaussianity (CMN) algorithm. We derive both a gradient-descent and a quasi-Newton algorithm that use the full second-order statistics providing superior performance with circular and noncircular sources as compared to existing methods. We show the connection among ICA methods through maximization of non-Gaussianity, mutual information, and maximum likelihood (ML) for the complex case, and emphasize the importance of density matching for all three cases. Local stability conditions are derived for the CMN cost function that explicitly show the effects of noncircularity on convergence and demonstrated through simulation examples.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I NDEPENDENT component analysis (ICA) for separating complex-valued signals has found utility in many applications such as communications <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, face recognition <ref type="bibr" target="#b3">[4]</ref>, analysis of functional magnetic resonance imaging <ref type="bibr" target="#b4">[5]</ref>, electroencephalograph <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, and radar data <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Depending on the application, the sources may be both sub-Gaussian and super-Gaussian, and specifically in the complex domain, can have circular (rotation invariant) and noncircular distributions. Several choices exist for performing complex-valued ICA. Earlier methods used fourth-order moments, such as the fourth-order blind identification (FOBI) algorithm <ref type="bibr" target="#b9">[10]</ref>. This method, although very efficient, requires distinct kurtosis values for the sources. For algorithms such as joint approximate diagonalization of eigenmatrices (JADE) <ref type="bibr" target="#b10">[11]</ref>, the extension to the complex case is straightforward due to the algorithm's use of fourth-order cumulants, however performance suffers when the number of sources increases <ref type="bibr" target="#b11">[12]</ref>. Another approach, the strong-correlating transform (SUT) <ref type="bibr" target="#b12">[13]</ref>, uses second-order statistical information through the covariance and pseudocovariance matrices and performs ICA by joint diagonalization of these matrices. Although efficient, the algorithm restricts the sources to be noncircular with distinct spectra of the pseudocovariance matrix. An Edgeworth expansion is used in <ref type="bibr" target="#b13">[14]</ref> to approximate negentropy based on third-and fourth-order cumulants, and hence again, it can be relatively easily applied to the complex case. However, using higher order cumulants typically results in an estimate sensitive to outliers <ref type="bibr" target="#b14">[15]</ref>.</p><p>An alternative approach to achieve independence is to use nonlinear functions to implicitly generate the higher order statistics. They can be used within a maximum likelihood (ML), information-maximization (Infomax), maximization of mutual information, or maximization of non-Gaussianity framework, and all approaches can be observed to be closely related to each other (see <ref type="bibr" target="#b15">[16]</ref> for real-valued algorithms and discussions). Recently, the convergence and accuracy of maximization of non-Gaussianity methods in the real-valued case, such as Fas-tICA, have been studied in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. In the complex domain, however, nonlinearity selection has taken several directions due to the conflict between boundedness and analyticity-Liouville's theorem states that if a function is analytic and bounded in the complex plane, then it is a constant <ref type="bibr" target="#b18">[19]</ref>. Approaches that sacrifice analyticity for boundedness process the real and imaginary parts separately as the arguments to real-valued "split" nonlinear functions <ref type="bibr" target="#b19">[20]</ref>. A second approach processes the modulus in a real-valued nonlinear function foregoing phase information as applied in an Infomax framework <ref type="bibr" target="#b5">[6]</ref> and a maximization of non-Gaussianity framework <ref type="bibr" target="#b20">[21]</ref>. However, analytic nonlinearities have been used effectively when applied to Infomax <ref type="bibr" target="#b21">[22]</ref> and ML <ref type="bibr" target="#b22">[23]</ref> ICA. Due to this success, we utilize analytic functions that are in a maximization of non-Gaussianity framework and introduce two complex maximization of non-Gaussianity (CMN) algorithms. We show that analytic functions produce a rich class of symmetric and asymmetric functions in the complex plane to match a variety of source distributions that cannot be achieved using the approaches that emphasize the boundedness as mentioned previously. We show the importance of matching the cost function to the bivariate source distribution by connecting maximization of non-Gaussianity (negentropy) to mutual information and ML by extending the work of <ref type="bibr" target="#b10">[11]</ref> to the complex case. Specifically, this result establishes the connections for complex-valued ICA using nonlinear functions.</p><p>A gradient-descent and quasi-Newton algorithm are derived for the CMN cost function. The quasi-Newton update is unique in that it is based on a modified Newton's method in the complex domain that uses the full second-order statistics, i.e., the information conveyed through both the covariance and pseudocovariance matrices <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. We show that using the full second-order information provides fast convergence with noncircular sources even when using symmetric nonlinear functions. Stability conditions are then derived in the complex domain for the CMN cost function showing explicitly how noncircularity affects the convergence behavior and that the CMN algorithm converges to the principal component of the source distribution. The analysis we present extends the stability results of <ref type="bibr" target="#b20">[21]</ref> to the more general case by not assuming circular sources.</p><p>This paper is organized as follows. First, some relevant information concerning complex random variables and complex ICA are introduced. We then show the connection between ne-gentropy, mutual information, and ML for the complex case. The CMN cost function, gradient-descent, and quasi-Newton update rules are derived followed by the stability analysis. The performance of the algorithm is demonstrated with simulations followed by concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. COMPLEX ICA BY MAXIMIZATION OF NON-GAUSSIANITY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Complex Preliminaries</head><p>A complex variable is defined in terms of two real variables and as . Statistics of a complex random vector is defined by the joint probability density function <ref type="bibr">(pdf)</ref> provided that it exists. The expectation of a complex random vector is then given with respect to this pdf and is written as . The covariance matrix is written as where denotes Hermitian transpose and the pseudocovariance matrix <ref type="bibr" target="#b23">[24]</ref> is defined as where denotes the transpose. These two quantities together define the second-order statistics of a complex random vector, and the random vector is second-order circular if</p><p>. A stronger definition of circularity is based on the pdf of the complex random variable such that for any , the pdfs of and are the same. A useful property of circular random variables <ref type="bibr" target="#b25">[26]</ref> is only when</p><p>(1)</p><p>The kurtosis of a zero mean complex random variable, often used as a quantitative measure of non-Gaussianity, is defined in <ref type="bibr" target="#b10">[11]</ref> as and reduces to <ref type="bibr" target="#b1">(2)</ref> when is circular with unit variance.</p><p>We use the following definitions of random vectors: where and as defined in <ref type="bibr" target="#b2">(3)</ref>. Using the real-valued transform allows us to write the pdf of as <ref type="bibr" target="#b3">(4)</ref> where is assumed nonsingular and is the joint distribution of . It is straightforward to show that if is unitary then is orthogonal, i.e., , then . Thus, if is unitary, then .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Complex ICA</head><p>In ICA, the observed data are typically expressed as a linear combination of latent variables such that , where is the column vector of latent sources, is the column vector of observed mixtures, and matrix is the mixing matrix assumed invertible. We assume that the sources and mixing matrix are complex valued. ICA then identifies the statistically independent sources given the observed mixtures typically by estimating a demixing matrix so that the source estimates become . We assume without loss of generality that the sources have zero mean and unit variance, i.e.,</p><p>. It has been shown in <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b13">[14]</ref> that one can recover the original sources up to a complex scaling and permutation provided that at most one source is Gaussian.</p><p>A preliminary sphering or whitening of is first performed through the transform , resulting in <ref type="bibr" target="#b4">(5)</ref> where</p><p>. We find that the new mixing matrix is unitary due to . We estimate each source separately by finding a vector such that <ref type="bibr" target="#b5">(6)</ref> where is a column of and when</p><p>. Constraining the source estimates such that also constrains the weights to and unitary due to the whitening transform <ref type="bibr" target="#b9">[10]</ref>. The whitening step allows us to estimate each source separately provided we orthonormalize after each iteration in a "deflationary" algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Complex Maximization of Non-Gaussianity</head><p>The principle of using non-Gaussianity in estimating in (6) may be motivated by the central limit theorem, which loosely states that the sum of independent random variables with finite-support pdfs tends toward the Gaussian distribution. Therefore, one could choose such that has the most non-Gaussian distribution. In other words, when is a column of , then has one nonzero element, however as deviates from this solution, this implies a linear mixture of the sources, causing to become more Gaussian. Non-Gaussianity can be measured explicitly through kurtosis or through the information-theoretic measure negentropy <ref type="bibr" target="#b13">[14]</ref>, which we will pursue in this paper. Negentropy is defined for a real-valued variable as where is the differential entropy, is the pdf, and is a Gaussian random variable with the same variance as . Negentropy is always positive and is zero if and only if is Gaussian <ref type="bibr" target="#b13">[14]</ref>. Maximization of negentropy in practice is carried out on one source estimate at a time <ref type="bibr" target="#b26">[27]</ref>. In the complex case where the source density is defined in terms of the real and imaginary components, we use the bivariate negentropy defined as <ref type="bibr" target="#b6">(7)</ref> where is the entropy of a complex Gaussian random variable. It was shown in <ref type="bibr" target="#b23">[24]</ref> that has the largest entropy of all bivariate densities when the covariance of is fixed. Since is constant, maximizing negentropy can be attained by minimizing the bivariate differential entropy as seen in <ref type="bibr" target="#b6">(7)</ref>. In practice, we replace the expectation operator in calculating the differential entropy with the arithmetic mean of realizations of resulting in <ref type="bibr" target="#b7">(8)</ref> Interestingly, it was shown in <ref type="bibr" target="#b14">[15]</ref> that in the context of realvalued maximization of non-Gaussianity, the optimal nonlinearity in a statistical sense is , i.e., providing the lowest variance estimator. As observed from (8), similarly, in the complex case, the optimal nonlinearity is given by <ref type="bibr" target="#b8">(9)</ref> since it calculates the bivariate differential entropy directly.</p><p>To use differential entropy as the cost function requires knowledge of the pdf which may not be known, or online estimations of the pdf can be computationally difficult. To overcome these situations, nonlinear functions are used to approximate the negentropy and hence generate the higher order statistics implicitly. It was shown through stability analysis in <ref type="bibr" target="#b27">[28]</ref> that practically any nonquadratic even function can be used to construct a cost function for ICA through non-Gaussianity maximization. This observation was extended to complex sources in c-FastICA <ref type="bibr" target="#b20">[21]</ref> by using the cost function <ref type="bibr" target="#b9">(10)</ref> where the nonlinearity is chosen as a smooth even function, e.g., and . Observe that the cost function defined in <ref type="bibr" target="#b9">(10)</ref> does not preserve phase information and specifically uses the signal's modulus for source separation. Because of this property, c-FastICA assumes source distributions to be circular and its performance suffers, especially for sub-Gaussian sources, when the sources are not circular <ref type="bibr" target="#b22">[23]</ref>. Despite the circularity assumption, c-Fas-tICA is a fast algorithm that works well when the sources are primarily circular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Complex Non-Gaussianity and Mutual Information:</head><p>The results from Section II-C, specifically <ref type="bibr" target="#b6">(7)</ref>, are directly related to mutual information which expresses the key property of independence of a random vector and is applied widely in ICA (see, e.g., <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b28">[29]</ref>). In this section, we show that maximizing the bivariate negentropy <ref type="bibr" target="#b6">(7)</ref> for complex sources is equivalent to minimizing the mutual information by extending the real-valued case outlined in <ref type="bibr" target="#b10">[11]</ref> to the complex case. First, we make use of the Kullback-Leibler divergence between two pdfs defined as <ref type="bibr" target="#b10">(11)</ref> where is always nonnegative and zero if and only if the two distributions are the same <ref type="bibr" target="#b29">[30]</ref>. Mutual information may be defined using the Kullback-Leibler divergence by setting to be equal to the joint distribution of a random vector and to the product of the marginals of the random vector. If the joint distribution is factorable to the product of the marginals, then the Kullback-Leibler divergence is zero indicating independence.</p><p>We extend these results to the complex case by noting that the complex sources are independent, however for the real and imaginary parts of a specific source we consider the general case in which they can be dependent. To apply the Kullback-Leibler divergence to our model, we set and , where is a real-valued vector defined in (3), to write the mutual information as <ref type="bibr" target="#b11">(12)</ref> where we used the entropy of the transform in line three. Due to the whitening step, is unitary resulting in as noted in Section II-A and since is constant, we rewrite (12) as ( <ref type="formula">13</ref>) Substituting ( <ref type="formula">7</ref>) into (8), we obtain which shows the relation between mutual information and negentropy for the complex case, i.e., minimizing mutual informa- tion is the same as maximizing the sum of the bivariate negentropies.</p><p>2) Complex Non-Gaussianity and ML: We may also link these results to ML methods by first considering the pdf of the mixtures defined in (5) using the density transform of complex data shown in ( <ref type="formula">4</ref>) as where when we ignore the permutation and scaling ambiguity. We use the independence of complex sources with observations to rewrite the previous expression as ( <ref type="formula">14</ref>) where is the th row of and is the joint density of the real and imaginary parts of source . We then write the log likelihood as where . To make the notation consistent with the mutual information results, we denote the sum over samples, or arithmetic mean times , with the expectation operator resulting in <ref type="bibr" target="#b14">(15)</ref> where since is unitary from the whitening of . We see from ( <ref type="formula">7</ref>), <ref type="bibr" target="#b12">(13)</ref>, and (15) that showing the equivalence of ML, mutual information, and negentropy when we use the joint distribution of each complex source in the formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. CMN Cost Function</head><p>We define the CMN cost function as <ref type="bibr" target="#b15">(16)</ref> where . The motivation for using this contrast function rather than the c-FastICA <ref type="bibr" target="#b20">[21]</ref> cost function we show in <ref type="bibr" target="#b9">(10)</ref> is that the full complex nature of the signals are used, phase and magnitude, in the nonlinearity prior to calculating the magnitude. This property provides the advantage of generating an asymmetric class of functions that cannot be realized with c-FastICA. A number of possibilities exist for in <ref type="bibr" target="#b15">(16)</ref>, e.g., any complex analytic function such as polynomials or transcendental functions. As was shown earlier, the optimal nonlinearity is the log of the joint distribution of the source being estimated. Thus, we want to choose nonlinearities that match the source distribution through the inverse of (9), i.e., . The cost function for CMN implies that the pdf we are matching is where is the pdf associated with the nonlinearity . Noncircular sources by definition have pdfs that are asymmetric, consequently, we would like to choose nonlinearities that have asymmetric associated pdfs.</p><p>Examples of nonlinearities that produce asymmetric costs are and , shown in Fig. <ref type="figure" target="#fig_1">1</ref>(a) and (b), along with the symmetric function , shown in Fig. <ref type="figure" target="#fig_1">1(c</ref>), where we also give their associated pdfs shown in Fig. <ref type="figure" target="#fig_1">1(d)-(f</ref>). What we can glean from the associated pdfs in Fig. <ref type="figure" target="#fig_1">1</ref> is the following: 1) the nonlinearity based on , being asymmetric, is well suited for noncircular sources and also provides robustness against outliers since it grows slower than quadratic in the real and imaginary directions; 2) with peaks at is ideal for bimodal distributions such as sinusoids or BPSK; and 3) polynomials are well fitted to circular sources where the exponent can be adapted to the source distribution <ref type="bibr" target="#b30">[31]</ref>. Note that the trigonometric functions and their hyperbolic counterparts have the same shapes rotated 90 in the complex plane, thus providing equivalent results.</p><p>Functions that contain singularities in the support set of the source distributions, e.g., atanh with singularities at , tanh with singularities at , tan with singularities at , and log with singularities at zero are not pursued in this study as their expectation in <ref type="bibr" target="#b15">(16)</ref> does not exist when applying Riemann integration as is the case with numerical integration. These singularities tend to degrade convergence in the optimization algorithm. We did not pursue the transcendental functions , , and , illustrated in Fig. <ref type="figure" target="#fig_2">2</ref>, since the associated pdfs for these functions do not approximate pdfs of signals of engineering interest. However, utility may exist for some of these nonlinearities such as if the source being estimated is highly asymmetric in the real or imaginary dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CMN ALGORITHMS</head><p>The CMN algorithm determines the optimal weights by maximizing the cost under the unit norm constraint where has been whitened and is , i.e.,</p><p>As stated earlier, projecting the solution to the unit hypersphere through enforces the unit norm constraint where .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gradient CMN Algorithm (G-CMN)</head><p>To calculate the optimal weights, we present a gradient optimization algorithm followed by a normalization step, such that <ref type="bibr" target="#b17">(18)</ref> where is defined in <ref type="bibr" target="#b15">(16)</ref>, is the learning rate, and is a parameter that determines whether we are maximizing or minimizing the cost function. A robust value of which practically always guarantees stability is derived in Section IV. The partial derivative of the cost function with respect to the conjugate of the weight vector, referred to as the conjugate gradient <ref type="bibr" target="#b31">[32]</ref>, is derived in Section B of the Appendix and is given by <ref type="bibr" target="#b18">(19)</ref> where is the derivative of . Let us note that if , we can use the results of Wirtinger and Brandwood <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b11">[12]</ref> and differentiate with respect to while treating as a constant thus providing a straight forward means of finding the complex derivative of nonanalytic functions. After each source is estimated, the vectors are orthogonalized to prevent multiple solutions from converging to the same maximum since is unitary due to the prewhitening step; see Section II-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Quasi-Newton CMN Algorithm (N-CMN)</head><p>The stochastic gradient-descent algorithm given in Section III-A has the advantage of using the data directly in an online update procedure providing good performance in nonstationary environments. This comes at a price, however, in that the convergence rate depends on a good choice of learning rate and the term in <ref type="bibr" target="#b17">(18)</ref> must also be estimated if not known in advance. In this section, we derive an efficient quasi-Newton method similar to that of c-FastICA, however, unlike c-FastICA, we assume noncircular sources and use the pseudocovariance in the formulation.</p><p>We derive the quasi-Newton algorithm for the constrained optimization problem outlined in <ref type="bibr" target="#b16">(17)</ref>. Our starting point is a Newton's method based on the Lagrangian function <ref type="bibr" target="#b19">(20)</ref> where is the real-valued Lagrange multiplier and , the cost, is defined in <ref type="bibr" target="#b15">(16)</ref>.</p><p>We use the complex Newton update defined in <ref type="bibr" target="#b33">[34]</ref> as where is the complex Hessian, is the complex gradient, and vectors are in the augmented form defined in <ref type="bibr" target="#b2">(3)</ref>. The Newton update to the Lagrangian given in ( <ref type="formula">20</ref>) is written as where and , and upon expanding we obtain <ref type="bibr" target="#b20">(21)</ref> The complex Hessian, derived in Section B of the Appendix, is given by ( <ref type="formula">22</ref>), shown at the bottom of the page, where is the derivative of , and . We write as the sum of two matrices , where the equation shown at the bottom of the page holds, to rewrite the product as <ref type="bibr" target="#b22">(23)</ref> Making use of the approximation and the whiteness of allows us to simplify to a diagonal matrix <ref type="bibr" target="#b23">(24)</ref> Note that the quantity converges to at the optimal solution for source . Intuitively, we see that the dependence of on decreases as we approach this solution, hence making the approximation more justifiable. Expanding <ref type="bibr" target="#b22">(23)</ref> and simplifying by retaining the odd-numbered rows results in <ref type="bibr" target="#b24">(25)</ref> where we now have . Substituting ( <ref type="formula">25</ref>) and ( <ref type="formula">19</ref>) into ( <ref type="formula">21</ref> with the constraint . The quasi-Newton algorithm derived here is similar to the c-FastICA update except for the addition of the third term-the third term explicitly contains the second-order noncircular information, i.e., the pseudocovariance matrix , which is zero if the sources are circular.</p><p>We now show conditions for <ref type="bibr" target="#b26">(27)</ref> to be stationary at the optimal solution: 1) the left-hand side of ( <ref type="formula">26</ref>) is real valued since a complex would result in a rotation away from the solution and 2) the right-hand side of ( <ref type="formula">27</ref>) remains fixed at the optimal solution. Condition 2) reduces to showing that the third term in <ref type="bibr" target="#b26">(27)</ref>,</p><p>, since the gradient is zero (first term) and is real valued (second term). We start by using the orthogonal change of coordinates and without loss of generality assume a solution at , where we show in Section IV that is in the direction of the principal component of source . Using the result from <ref type="bibr" target="#b24">(25)</ref>, we expand the first element of vector as <ref type="bibr" target="#b27">(28)</ref> where the argument to the functions and is , and . Noting that is real valued, we concentrate on the last term . We now show three classes of functions which satisfy the stationary conditions: 1) and 2) . 1) The first class of functions we focus on are where . Substituting into <ref type="bibr" target="#b27">(28)</ref>, we obtain which is real valued satisfying condition 1). We also find that satisfy condition 2). 2) The second class of functions are those that satisfy , i.e., the function is equal to its second derivative except for a possible sign change. For example, the transcendental functions , , and satisfy this condition. We show this property by noting that is a complex number with phase angle pointing in the direction of twice the principal component angle. Using this identity and the approximation , we find which is real valued if . Condition 2) is also satisfied since</p><p>, where is a real-valued constant.</p><p>3) The third class of functions is found by writing and in terms of two real-valued functions, and . Expanding results in . The product is real valued if or . For example, and satisfy the second condition because and are orthogonal functions, as are and , i.e., . The orthogonality condition results in , where the limits of integration are over the support of which is assumed to be symmetric. Condition 2) is met due to and as shown previously. The quasi-Newton derivation is novel because it is valid for any analytic and takes into account the noncircular nature of the sources through when optimizing the Lagrangian. To observe this, let us rewrite the algorithm ( <ref type="formula">21</ref>) using ( <ref type="formula">23</ref>) and ( <ref type="formula">24</ref>) as <ref type="bibr" target="#b28">(29)</ref> where</p><p>. Noting that , a real-valued scalar, and do not change the convergence point, we simplify (29) to <ref type="bibr" target="#b29">(30)</ref> We can interpret (30) as a gradient-descent algorithm with a learning rate of and a modified cost function <ref type="bibr" target="#b30">(31)</ref> found as the antiderivative of the second term in <ref type="bibr" target="#b29">(30)</ref>. Note that the modified cost contains a quadratic term that contains the information in the pseudocovariance matrix through the indefinite matrix . How this modified cost affects the convergence properties can be seen by evaluating the complex Hessian of (31) at the optimal solution as which is diagonal as shown in <ref type="bibr" target="#b23">(24)</ref>. A diagonal Hessian ensures that the optimization landscape is positive definite at the optimal solution with desirable convergence properties due to a unity condition number. This result shows us that the quasi-Newton update we present in this paper implicitly modifies the cost to match the source distribution through the quadratic term seen in <ref type="bibr" target="#b30">(31)</ref>, which also explains why we observe improved performance with noncircular sources using a circular symmetric cost function as we will show in Section V. We present a graphical example of the modified nonlinearity derived in <ref type="bibr" target="#b30">(31)</ref> in Fig. <ref type="figure" target="#fig_3">3</ref>.</p><p>Here, we use a symmetric nonlinearity depicted in Fig. <ref type="figure" target="#fig_3">3(a)</ref>, and an example pseudocovariance matrix with resulting in the modified cost function , where . In this example, we see that the quadratic term [Fig. <ref type="figure" target="#fig_3">3(b)</ref>] transforms the nonlinearity to be asymmetric as depicted in Fig. <ref type="figure" target="#fig_3">3(c</ref>). In the special case of the kurtosis-based cost , the resulting landscape has two minima: at the solution and minus the solution. This result is not surprising because the quasi-Newton update is based on the Lagrangian function which has minima at the constrained solution, however for other nonlinearities this may not be true and constraining the weights to unit norm at each step is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. STABILITY ANALYSIS</head><p>For the stability analysis, we use a second-order approximation of the cost function around the stable point. The approximation is a good one as long as the higher order terms of a Taylor series are negligible and the Hessian exists at the stable point.</p><p>We examine the stability of under the constraint . We use the orthogonal change of coordinates and assume the optimal solution is given by as earlier. We show in Section C of the Appendix that in the complex plane of , the extrema for noncircular sources are at <ref type="bibr" target="#b31">(32)</ref> for integer and that any is a solution for circular sources, i.e., a saddle point in the direction. This result shows us that the phase of the stable point is based on the higher order statistics of the sources and not on the nonlinearity . Let us examine the optimization landscape in the complex plane of with an example. We are using the nonlinearity shown in Fig. <ref type="figure">4</ref>(a) along with a noncircular sub-Gaussian source Fig. <ref type="figure">4(b)</ref> with principal component at 45 . Fig. <ref type="figure">4</ref>(c) depicts the optimization landscape showing the minimum occurring at 45 when constrained to . As suggested by <ref type="bibr" target="#b31">(32)</ref>, the minimum is occurring at an angle based on the moments of the noncircular source as seen by the denominator equaling zero since . We now extend the stability conditions of the CMN algorithm to the other dimensions, namely, using a secondorder (Hessian) analysis. We show that the overall stability is particularly important to show the interdependency of stability on multiple noncircular sources, which is ignored when concentrating only on the estimated source dimension .</p><p>The major result of this section, derived in Section C of the Appendix based on a local second-order Fig. <ref type="figure">4</ref>. Example optimization landscape in the complex plane of q using G = asinh. (a) Contours of J = jasinh(q)j . (b) The scatter plot of the noncircular source with principal axis at 45 . (c) The contours of the optimization landscape , where we see the minimum occurring at e aligning with the principal axis of the source.</p><p>analysis, is that a local minimum (respectively, maximum) is achieved for a given source when <ref type="bibr" target="#b32">(33)</ref> where we have defined and , and used the notation and . For circular sources, the expression reduces to <ref type="bibr" target="#b33">(34)</ref> which coincides with the result given in <ref type="bibr" target="#b20">[21]</ref> assuming circularity that implies . This result for circular sources shows that stability is guaranteed as long as one chooses to maximize or minimize the cost depending on the sign of <ref type="bibr" target="#b33">(34)</ref>. However, for the noncircular case, the second term in <ref type="bibr" target="#b32">(33)</ref> is not zero indicating that stability is not guaranteed as we show with the following examples.</p><p>We examine two special cases of (33) using the cost which is motivated by kurtosis <ref type="bibr" target="#b1">(2)</ref>. First, if we assume circular sources, (33) simplifies to , where for Gaussian sources as shown in Section D of the Appendix. Substituting kurtosis (2) into the previous equation we see that the stability condition may also be written in terms of kurtosis, i.e., . Hence, the cost function is minimized for sub-Gaussian sources and maximized for super-Gaussian sources. We use this fact in the gradient-descent algorithm to determine whether to maximize or minimized the cost through in <ref type="bibr" target="#b17">(18)</ref>. However, for cost functions other than kurtosis, we must use the sign of to assure stability.</p><p>The second special case is for noncircular sources in <ref type="bibr" target="#b32">(33)</ref> obtaining where we define the fourth moment and as a measure of (second-order) noncircularity. Due to the unit variance constraint, we find that with equality to zero if source is circular. We show in Section D of the Appendix that where for a circular Gaussian random variable. Fig. <ref type="figure" target="#fig_4">5</ref> illustrates how noncircularity affects the stability by plotting versus the product . What we see in the figure is that for sub-Gaussian sources , the algorithm using is unstable for most types of distributions when the sources are noncircular, i.e., . However, for super-Gaussian sources, we see that if the source distribution is only slightly super-Gaussian , the algorithm is always stable. We conclude from this observation that symmetric nonlinearities are capable of good performance with noncircular sources as long as the sources are super-Gaussian, however noncircular sub-Gaussian sources are more prone to instability. We show this result in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. SIMULATIONS</head><p>We verify the performance of the CMN algorithm presented in this paper using an aggregate of both complex-valued suband super-Gaussian sources with both circular and noncircular distributions. We concentrate on the fixed-point update (N-CMN) instead of the gradient-descent algorithm to alleviate the need to pick a learning rate and in <ref type="bibr" target="#b17">(18)</ref>. However, G-CMN finds utility in nonbatch (stochastic) algorithms or in cases where the mixing matrix and/or sources are not stationary.</p><p>We compare the performance of CMN using the analytic functions , , and with JADE <ref type="bibr" target="#b10">[11]</ref>, and c-FastICA <ref type="bibr" target="#b20">[21]</ref> using the cost function . The functions and were chosen for their asymmetry which matches the pdf of some noncircular sources and their convergence properties in the quasi-Newton update (Section III-B). The exponent of 1.25 used in the symmetric function was chosen heuristically in that it provides a cost function that grows slower than kurtosis providing a more robust performance. The complex-valued mixing matrix was generated using normally distributed real and imaginary values with unit variance. Eight complex-valued sources were used in this study with each source chosen from the following classes.</p><p>• Sub-Gaussian -the telecommunication signals BPSK and 4-QAM as shown in Fig. <ref type="figure" target="#fig_5">6</ref>; -complex sinusoids including chirp signals. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I SOURCE TYPES USED IN SIMULATIONS</head><p>• Super-Gaussian sources using realizations from the exponential power family <ref type="bibr" target="#b34">[35]</ref> where , the shape parameter, is adjusted to yield kurtosis values between 3 and 500. To generate these complex random variables in Matlab, we modify the approach in <ref type="bibr" target="#b35">[36]</ref> for real-valued variables to for the complex-valued case.</p><p>• An aggregate of both sub-Gaussian and super-Gaussian sources outlined in Table <ref type="table">I</ref>. Noncircular sources are generated with different values of real to imaginary asymmetry defined by and then by providing a random phase shift to produce real to imaginary correlation. All simulations are averaged over 100 runs with the matrix and sources realized on each run.</p><p>We use for our performance measure the normalized Amari index defined in <ref type="bibr" target="#b36">[37]</ref> as where . The lower the value is, the better the separation performance becomes with 10 dB indicating the algorithm is not performing adequately.</p><p>We will first look at the performance of CMN using sources typically encountered in telecommunication applications, namely, BPSK and 4-QAM modulations depicted in Fig. <ref type="figure" target="#fig_5">6</ref>. Fig. <ref type="figure">7</ref> shows the average for the five algorithms as a function of sample size for BPSK modulated signals. We see that all the algorithms behave similarly with the exception of c-FastICA. Since BPSK signals are highly sub-Gaussian and noncircular with and , we would expect symmetric cost functions, such as those used with c-FastICA, to not perform well as depicted in Fig. <ref type="figure" target="#fig_4">5</ref>. However, the symmetric cost based on is performing well, contrary to Fig. <ref type="figure" target="#fig_4">5</ref>. This result shows us that the CMN quasi-Newton update adapts the cost to the noncircularity of the source, whereas c-FastICA does not.</p><p>Fig. <ref type="figure">8</ref> depicts the results with 4-QAM sources which are sub-Gaussian and more circular than BPSK with and . Fig. <ref type="figure" target="#fig_4">5</ref> predicts symmetric cost functions to be stable which is the case for c-FastICA and . Here, performs well indicating that its bimodal shape is matching at least two of the four peaks in the 4-QAM constellation as evident from comparing Figs. 1(e) and 6(b). The poor performer is which is what is expected because its asymmetric shape We now look at the performance with respect to the asymmetry depicted in Fig. <ref type="figure">9</ref> with complex sinusoidal signals of size 500. These results again show that as the sub-Gaussian sources become more noncircular, cost functions that are symmetric do not perform well as seen by c-FastICA degrading as increases. However, the function is also symmetric but is modified by the noncircular statistics of the sources in the quasi-Newton algorithm. This modification provides the relatively flat response as increases. As expected, being bimodel fits the sinusoid pdf well. The asymmetric begins separating sources when the source pdf is very noncircular , again when we have a match of source statistics with the shape of the nonlinearity. JADE begins to separate the sources only when the sources are highly noncircular. Fig. <ref type="figure" target="#fig_1">10</ref> depicts the average with super-Gaussian sources with as a function of ; again, each source is of size 500. As seen in the figure, all functions are providing adequate separation with providing the best performance. Here, c-FastICA is showing acceptable results ( 16 dB) as predicted by Fig. <ref type="figure" target="#fig_4">5</ref> with degradation as increases. Again, the quasi-Newton CMN algorithm provides good performance that is invariant to changes in .  <ref type="table">I</ref>. Fig. <ref type="figure" target="#fig_8">11</ref> shows the average as a function of sample size for the sources outlined in Table <ref type="table">I</ref> where half are made noncircular by setting the asymmetry randomly between 10 and 1000. This simulation tests the ability of the algorithms to handle a wide range of source statistics. We see the nonlinearity providing the best performance over all sample sizes due to its ability to handle circular sources and noncircular sources. We also find c-FastICA performing well indicating we are mostly in the stable area of Fig. <ref type="figure" target="#fig_4">5</ref>. The functions and , being intrinsically asymmetric, have degraded performance when confronted with the circular sources. JADE performed poorly specifically due to the small sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we presented the CMN algorithm for separation of both circular and noncircular sources using complex functions. Using complex functions, specifically asymmetric functions, provides improved performance for noncircular sources in a gradient-descent update. We then derived a quasi-Newton version of CMN yielding faster convergence and show that the algorithm modifies the cost function to match the noncircular nature of the sources. Stability requirements around the optimal solution were derived and were used to quantify various constraints on the noncircular nature of the sources. Simulations were used to show that the CMN algorithm provides a powerful approach to the complex ICA problem especially when confronted with a wide range of source statistics.</p><p>A logical extension to this study is to use online estimation of the source's joint distribution as the nonlinearity. Recent approaches to density estimation for the complex case are an ML approach, given in <ref type="bibr" target="#b37">[38]</ref>, using adaptive score functions whereby the nonlinearity is modeled as the sum of basis functions; a quasi-Newton algorithm using kurtosis is developed in <ref type="bibr" target="#b38">[39]</ref>, where the fourth-moment properties of the real and imaginary parts are used; and a method that models the modulus as a variate of the exponential power family as in <ref type="bibr" target="#b30">[31]</ref>. However, further research is needed to determine if density estimation techniques provide significant improvement, given the extra overhead, over the less stringent nonlinearity selection scheme shown here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Preliminaries</head><p>We use the mapping to write the vector as through the transformation . The Taylor series expansions of and are the same when the following gradient and Hessian forms <ref type="bibr" target="#b34">(35)</ref> are used by applying <ref type="bibr" target="#b35">(36)</ref> as defined in <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Derivation of Complex Gradient and Hessian</head><p>First, we show that for , where and are analytic functions, we have <ref type="bibr" target="#b36">(37)</ref> and <ref type="bibr" target="#b37">(38)</ref> where . We first use <ref type="bibr" target="#b35">(36)</ref> to write <ref type="bibr" target="#b38">(39)</ref> We then write as the sum of two real-valued functions and . We use <ref type="bibr" target="#b38">(39)</ref> and the chain rule to obtain Substituting and the Cauchy-Riemann conditions and , we obtain Following similar algebraic steps and <ref type="bibr" target="#b35">(36)</ref>, one can find the following relationships: and Applying the chain rule and the previous equations, we finally obtain <ref type="bibr" target="#b36">(37)</ref> and similarly <ref type="bibr" target="#b37">(38)</ref>.</p><p>Applying <ref type="bibr" target="#b37">(38)</ref> and <ref type="bibr" target="#b36">(37)</ref> to the cost ( <ref type="formula">16</ref>), we obtain the gradient <ref type="bibr" target="#b18">(19)</ref> directly and the Hessian ( <ref type="formula">22</ref>) is found by finding the second derivatives where is the derivative of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Derivation of the Stability Conditions</head><p>We study the local stability of the CMN algorithm by examining the Lagrangian function for the constrained optimization problem <ref type="bibr" target="#b39">(40)</ref> at the optimal solution , where is the realvalued Lagrange multiplier and is the constraint function . The second-order necessary and sufficient conditions for a local minimum (respectively, maximum) at are (41) and (42) with defining the feasible directions <ref type="bibr" target="#b39">[40]</ref>. For the unit norm constraint, the feasible directions thus become which constrains and imposes no constraints on .</p><p>We first evaluate condition (41) by using <ref type="bibr" target="#b36">(37)</ref> and <ref type="bibr" target="#b37">(38)</ref> in <ref type="bibr" target="#b39">(40)</ref> and evaluating at . Noting that the sources are independent with zero mean, we find . . . . . .</p><p>Setting the top row of (4) equal to zero and solving for , we obtain (44)</p><p>where we made the substitution . To find a solution for in (44), we use a MacLaurin series expansion of given by , where we assumed is an odd function and the are the real-valued function-dependent coefficients. Expanding (44) using the MacLaurin expansion and ignoring terms greater than three, we obtain where we used the unit variance and zero mean properties of . The Lagrangian multiplier is real valued at the solution, therefore, the second and third terms must be real valued implying . Substituting , we obtain our result for in <ref type="bibr" target="#b31">(32)</ref>. Note also that if is circular then the second and third terms are zero (1) implying any is a solution.</p><p>To evaluate condition (42), we first find the second derivatives, and again using <ref type="bibr" target="#b36">(37)</ref> and <ref type="bibr" target="#b37">(38)</ref>, we obtain <ref type="bibr">(45)</ref> where is the derivative of . Substituting (45) into <ref type="bibr" target="#b34">(35)</ref> and evaluating at , we obtain the block diagonal matrix for the Hessian Simplifications occur from applying the independence, unit variance, and zero mean properties of the sources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>. Complex linear transforms such as , where , may be rewritten in the real domain as . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a)-(c) Complex functions used in CMN algorithm and (d)-(f) associate pdfs versus real and imaginary parts: (a) jasinh(y)j , (b) jcosh(y)j , (c) jyj , (d) e, (e) e , and (f) e .</figDesc><graphic coords="4,113.46,66.74,363.00,208.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a)-(c) Complex functions that do not yield (d)-(f) pdfs that represent signals of engineering interest, versus real and imaginary parts: (a) jacosh(y)j , (b) jsin(y)j , (c) je j , (d) e , (e) e , and (f) e .</figDesc><graphic coords="5,115.20,66.78,362.00,225.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example of the modified nonlinearity J derived in (31) with (a) the original nonlinearity, (b) the quadratic term, and (c) the difference in the complex plane of q. (a) jq j ; (b) 0:5q Hq; (c) jq j 0 0:5q Hq.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Plot of C C , noncircularity measure where C = Efs g versus the fourth moment = Efjsj g with the area of instability noted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Telecommunication sources. (a) Complex plane of binary phase-shift keying (BPSK) source. (b) Complex plane of four quadrature amplitude modulation (4-QAM) source.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Average I as a function of data length for a mixture of eight complex BPSK sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>Fig.9. Average I as a function of the asymmetry of the real to imaginary parts of eight complex sinusoidal sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Average I as a function of data length for a mixture of eight sources, four sub-Gaussian and four super-Gaussian, where half of each set is noncircular as outlined in TableI.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work of T. Adalı was supported by the National Science Foundation (NSF) under Grants NSF-CCF 0635129 and NSF-IIS 0612076.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We can evaluate condition (42) by analyzing each submatrix in (46) separately. Submatrix must satisfy (minimum), where from the feasible directions constraint. Substituting (44) into the previous, we obtain the condition along dimension for a minimum (respectively, maximum) <ref type="bibr">(48)</ref> where is the th row and th column of . We see from (48) that either a maximum or a minimum will occur at the stable point unless the two sides are equal indicating a saddle point. We show that a saddle point exists when the source is circular by expanding the nonlinearity into its MacLaurin series expansion , where we also find assuming series converge. Substituting the series expansions into (48) and noting that all cross terms vanish for circular sources (1), we obtain after several algebraic steps, thus showing that a saddle point exists for circular sources in the direction of . We examine the behavior along the remaining dimensions through submatrix . Evaluating condition (42) for stability requires each to be positive definite for a local minimum and negative definite for a local maximum. Noting that the form of is the eigenvalues are easily shown to be , which are real valued by inspection of the structure of matrix . The conditions for a local minimum (respectively, maximum) are found by using (47) as and are given in <ref type="bibr" target="#b32">(33)</ref> where we substituted (44) for .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Derivation of the Lower Limit of the Fourth Moment</head><p>Expanding into the real and imaginary parts, we obtain (49)</p><p>We make use of Jensen's inequality to show (50) Applying the unit variance constraint and (50), we find (51)</p><p>where . Taking the derivative of the right-hand side of (51) and setting it equal to zero, we find , thus</p><p>Again applying Jensen's inequality, we find and upon substituting , we obtain (52)</p><p>Substituting the results from ( <ref type="formula">51</ref>) and ( <ref type="formula">52</ref>) into (49), we obtain the lower limit . For a circular Gaussian random variable with unit variance, the variance of the real or the imaginary part is 0.5. The fourth moment for a Gaussian random variable with variance of 0.5 is 0.75. Using these results in (49) we find .</p><p>Michael She joined the faculty at the University of Maryland Baltimore County (UMBC), Baltimore, in 1992. Currently, she is a Professor in the Department of Computer Science and Electrical Engineering at UMBC. Her research interests are in the areas of statistical signal processing, machine learning for signal processing, biomedical data analysis [functional magnetic resonance imaging (MRI), positron emission tomography (PET), computed radiography (CR), electrocardiogram (ECG), and electroencephalography (EEG)], bioinformatics, and signal processing for optical communications.</p><p>Prof. Adali assisted in the organization of a number of international conferences and workshops including the IEEE <ref type="table">International</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algebraic methods for deterministic blind beamforming</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Veen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1987">1987-2008, Oct. 1998</date>
			<biblScope unit="volume">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Suppression of bitpulsed jammer signals in DS-CDMA array system using independent component analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristaniemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Circuits Syst</title>
		<meeting>Int. Symp. Circuits Syst</meeting>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="189" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Blind information-theoretic multiuser detection algorithms for DS-CDMA and WCDMA downlink systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Waheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Salem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="937" to="948" />
			<date type="published" when="2005-07">Jul. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Face recognition using an enhanced independent component analysis approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="530" to="541" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unmixing fMRI with independent component analysis</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Eng. Med. Biol. Mag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="90" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Complex spectral domain independent component analysis of electrocephalographic data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Annemüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Makeig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Independent Component Anal. Workshop</title>
		<meeting><address><addrLine>Nara, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A new constrained independent component analysis method</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1532" to="1535" />
			<date type="published" when="2007-09">Sep. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ICA-based technique for radiating sources estimation: Application to airport surveillance</title>
		<author>
			<persName><forename type="first">E</forename><surname>Chaumette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cornon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inst. Electr. Eng. Proc.-F</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="395" to="401" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Independent component analysis for clutter reduction in ground penetrating radar data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Karlsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Jackobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE AeroSense</title>
		<meeting>SPIE AeroSense<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">4742</biblScope>
			<biblScope unit="page" from="378" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Source separation using higher order moments</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Acoust. Speech Signal Process</title>
		<meeting>Int. Conf. Acoust. Speech Signal ess</meeting>
		<imprint>
			<date type="published" when="1989-05">May 1989</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2109" to="2112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Blind beamforming for non-Gaussian signals</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Souloumiac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inst. Electr. Eng. Proc.-Radar Signal Process</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="362" to="370" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gradient and fixed-point complex ICA algorithms based on kurtosis maximization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Mach</title>
		<meeting>IEEE Workshop Mach<address><addrLine>Maynooth, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">Sep. 2006</date>
			<biblScope unit="page" from="85" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Complex-valued ICA using second-order statistics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koivunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Mach. Learn. Signal Process., Sao Luis</title>
		<meeting>IEEE Workshop Mach. Learn. Signal ess., Sao Luis</meeting>
		<imprint>
			<publisher>Brazil</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Independent component analysis-a new concept?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="287" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One-unit contrast functions for independent component analysis: A statistical analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Neural Netw. Signal Process</title>
		<meeting>Workshop Neural Netw. Signal ess</meeting>
		<imprint>
			<date type="published" when="1997-09">Sep. 1997</date>
			<biblScope unit="page" from="388" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<title level="m">Independent Component Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The FastICA algorithm revisited: Convergence analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1370" to="1381" />
			<date type="published" when="2006-11">Nov. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient variant of algorithm FastICA for independent component analysis attaining the Cramer-Rao lower bound</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Koldovský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tichavský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oja</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1265" to="1277" />
			<date type="published" when="2006-09">Sep. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Complex Variables</title>
		<author>
			<persName><forename type="first">N</forename><surname>Levinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Redheffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Holden-Day</publisher>
			<pubPlace>Oakland, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Blind separation of convolved mixtures in the frequency domain</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A fast fixed-point algorithm for independent component analysis of complex valued signals</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Complex infomax: Convergence and approximation of infomax with complex nonlinearities</title>
		<author>
			<persName><forename type="first">V</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Neural Netw. Signal Process</title>
		<meeting>IEEE Workshop Neural Netw. Signal ess<address><addrLine>Martigny, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09">Sep. 2002</date>
			<biblScope unit="page" from="307" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Independent component analysis by complex nonlinearities</title>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Calhoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Acoust. Speech Signal Process</title>
		<meeting>Int. Conf. Acoust. Speech Signal ess<address><addrLine>Montreal, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="525" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Proper complex random processes with applications to information theory</title>
		<author>
			<persName><forename type="first">F</forename><surname>Neeser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1293" to="1302" />
			<date type="published" when="1993-07">Jul. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Second-order analysis of improper complex random vectors and processes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Schreier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Scharf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="714" to="725" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On circularity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Picinbono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3473" to="3482" />
			<date type="published" when="1994-12">Dec. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast and robust fixed-point algorithms for independent component analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="634" />
			<date type="published" when="1999-05">May 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Independent component analysis by general non-linear Hebbian-like learning rules</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="301" to="313" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Blind signal separation: Statistical principals</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998">2009-2025, Oct. 1998</date>
			<biblScope unit="volume">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptable nonlinearity for complex maximization of non-Gaussianity and a fixed-point algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Novey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Mach</title>
		<meeting>IEEE Workshop Mach<address><addrLine>Maynooth, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">Sep. 2006</date>
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A complex gradient operator and its application in adaptive array theory</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brandwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Inst. Electr. Eng</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="16" />
			<date type="published" when="1983-02">Feb. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Zur formalen theorie der funktionen von mehr complexen veränderlichen</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wirtinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Ann</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="357" to="375" />
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Complex gradient and Hessian</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inst. Electr. Eng. Proc.-Image Signal Process</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="380" to="382" />
			<date type="published" when="1994-12">Dec. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A software tool for the exponential power distribution: The normal package</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mineo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruggieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Statist. Software</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Computer generation of the exponential power distributions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Statist. Comput. Simul</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="239" to="240" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A new learning algorithm for blind signal separation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cichocki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="757" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The maximum likelihood approach to complex ICA</title>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adalı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Acoust. Speech Signal Process</title>
		<meeting>Int. Conf. Acoust. Speech Signal ess<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="page" from="673" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fixed-point complex ICA algorithms for the blind separation of sources using their real or imaginary components</title>
		<author>
			<persName><forename type="first">S</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koivunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Conf. Independent Component Anal</title>
		<meeting>6th Int. Conf. Independent Component Anal<address><addrLine>Charleston, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Nonlinear Programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsekas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Belmont, MA; Athena Scientific</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
