<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient and Scalable Graph Pattern Mining on GPUs</title>
				<funder ref="#_G3gZf8G">
					<orgName type="full">XSEDE</orgName>
				</funder>
				<funder ref="#_fbNbXdF">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">Samsung Semiconductor</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-27">27 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mit</forename><surname>Csail</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arvind</forename><surname>Mit Csail</surname></persName>
						</author>
						<title level="a" type="main">Efficient and Scalable Graph Pattern Mining on GPUs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-27">27 Jul 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2112.09761v3[cs.DC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Pattern Mining (GPM) extracts higher-order information in a large graph by searching for small patterns of interest. GPM applications are computationally expensive, and thus attractive for GPU acceleration. Unfortunately, due to the complexity of GPM algorithms and parallel hardware, hand optimizing GPM applications suffers programming complexity, while existing GPM frameworks sacrifice efficiency for programmability. Moreover, little work has been done on GPU to scale GPM computation to large problem sizes.</p><p>We describe G 2 Miner, the first GPM framework that runs efficiently on multiple GPUs. G 2 Miner uses patternaware, input-aware and architecture-aware search strategies to achieve high efficiency on GPUs. To simplify programming, it provides a code generator that automatically generates pattern-aware CUDA code. G 2 Miner flexibly supports both breadth-first search (BFS) and depth-first search (DFS) to maximize memory utilization and generate sufficient parallelism for GPUs. For the scalability of G 2 Miner, we propose a customized scheduling policy to balance workload among multiple GPUs. Experiments on a V100 GPU show that G 2 Miner is 5.4? and 7.2? faster than the two state-ofthe-art single-GPU systems, Pangolin and PBE, respectively. In the multi-GPU setting, G 2 Miner achieves linear speedups from 1 to 8 GPUs, for various patterns and data graphs. We also show that G 2 Miner on a V100 GPU is 48.3? and 15.2? faster than the state-of-the-art CPU-based systems, Peregrine and GraphZero, on a 56-core CPU machine.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph Pattern Mining (GPM) finds subgraphs in a given data graph which match the given pattern(s) (Fig. <ref type="figure" target="#fig_0">1</ref>). GPM is a key building block in many domains, e.g., protein function prediction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b82">83]</ref>, network alignment <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b75">76]</ref>, spam detection <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37]</ref>, chemoinformatics <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b83">84]</ref>, sociometric studies <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b47">48]</ref>, image segmentation <ref type="bibr" target="#b119">[119]</ref>. Graph machine learning tasks can also benefit from GPM, including anomaly detection <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b77">78]</ref>, entity resolution <ref type="bibr" target="#b11">[12]</ref>, community detection <ref type="bibr" target="#b89">[90]</ref>, role discovery <ref type="bibr" target="#b87">[88]</ref> and relational classification <ref type="bibr" target="#b60">[61]</ref>.</p><p>GPM is extremely compute intensive, since it searches a space that is exponential in the pattern size. For example, Peregrine <ref type="bibr" target="#b52">[53]</ref>, a state-of-the-art GPM system on CPU, takes 9 hours to mine the 4-cycle pattern (see Fig. <ref type="figure" target="#fig_6">3</ref>) in the Friendster graph on a 56-core CPU machine. GPUs provide much higher compute throughput and memory bandwidth than CPUs, and thus are attractive for GPM acceleration.</p><p>However, implementing GPM on GPU efficiently is challenging. This is because it requires sophisticated optimizations by leveraging information in the GPU hardware architecture, the pattern(s) of interest, and the input data graph.</p><p>? Architecture Awareness: A GPU usually has smaller memory capacity than a CPU and requires more fine-grain data parallelism to be fully utilized. More threads, however, require more memory to accommodate intermediate data!</p><p>The search order, BFS or DFS, offers a similar tradeoff between memory and parallelism and therefore, GPM on GPU requires careful orchestration of parallelism and memory usage to maximize efficiency. GPUs are also much more sensitive to thread divergence and workload imbalance <ref type="bibr" target="#b17">[18]</ref> than CPUs. This necessitates a more sophisticated task-tohardware mapping for GPU than that for CPU. ? Pattern Awareness: State-of-the-art GPM systems on CPU use pattern aware search plans that prune the search space using pattern information. This has been shown to be ordersof-magnitude faster than the pattern-oblivious search <ref type="bibr" target="#b52">[53]</ref>. This pattern-aware approach has worked well for CPU, but it has not been well explored on GPU. For example, many We propose G 2 Miner to overcome these challenges. Table <ref type="table" target="#tab_0">1</ref> compares G 2 Miner to the state-of-the-art systems, including those that solve only the subgraph matching problem, which is a subset of the GPM problem. In Table <ref type="table" target="#tab_0">1</ref>, subgraph matching systems include EmptyHeaded, Graphflow, GraphZero, GraphPi and PBE, while Peregrine, Pangolin and G 2 Miner are general GPM systems. Much of the prior work focuses on CPU, and uses DFS to reduce the memory footprint. GPUbased systems (Pangolin and PBE), on the other hand, use BFS because straightforward DFS implementations on GPU suffer from thread divergence and load imbalance. This, however, limits their efficiency and/or the problem size they can solve. Additionally, G 2 Miner simplifies GPU programming with automated CUDA code generation, while Pangolin requires users to write CUDA code manually, and PBE is not programmable at all. Last but not least, G 2 Miner is the only system that scales to multiple GPUs.</p><p>Fig. <ref type="figure">2</ref> shows the overview of G 2 Miner. It consists of a graph loader, a pattern analyzer, a runtime system, a library of CUDA primitives and a code generator. The user is only responsible for specifying the pattern(s) of interest using our API ( ?4). The pattern analyzer does analysis on the pattern and generates a pattern-specific search plan, based on which, the code generator ( ?5) automatically generates pattern-specific CUDA kernels for GPUs. The kernels contain invocations to the device functions defined in the GPU primitive library ( ?6) which includes efficiently implemented set operations. The generated kernels, the GPU primitive library, and the runtime are compiled together by the NVCC compiler to generate the executable that runs on multi-GPU.</p><p>At runtime, the graph loader reads in the data graph, extracts input information (e,g., maximum degree and label distribution) and performs pattern-specific preprocessing on the data graph. The pattern, input and architecture information is fed to the runtime ( ?7) which heuristically handles GPU memory allocation, data transfer, and multi-GPU scheduling.</p><p>This paper makes the following contributions:</p><p>? G 2 Miner is the first pattern-aware, input data-graph-aware and architecture-aware framework for GPM, and it is the first GPM system that automates CUDA code generation for arbitrary patterns to simplify programming. ? G 2 Miner is the first multi-GPU framework for GPM and the first GPU-based GPM framework that flexibly supports both BFS and DFS. It uses a novel task scheduling policy to balance workload among GPUs and we show G 2 Miner performance increases linearly from 1 to 8 V100 GPUs. ? On a V100 GPU, G 2 Miner is 5.4? faster than Pangolin, the only existing GPM system on GPU, and 7.2? faster than PBE, the state-of-the-art subgraph matching solver on GPU, thanks to the optimizations enabled in G 2 Miner (Table <ref type="table" target="#tab_4">2</ref>). ? G 2 Miner on a V100 GPU is 48.3? and 15.2? faster than state-of-the-art CPU-based GPM system Peregrine and subgraph matching system GraphZero on a 56-core CPU.</p><p>2 Background and Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Pattern Mining Problems</head><p>Let G (V , E) be an undirected graph with V as the vertex and E as the edge set. Given a vertex v ? V , the neighbor set of v is N (v), the degree</p><formula xml:id="formula_0">d v of v is |N (v)| and ? is the maximum degree in G. A graph G (W, F) is said to be a subgraph of G if W ? V and F ? E. G is a vertex-induced subgraph of G</formula><p>if F contains all the edges in E whose endpoints are in W .</p><p>G is an edge-induced subgraph of G if W contains all the vertices in V which are the endpoints of edges in F. The definition of support also varies, e.g., the count of matches or the domain support <ref type="bibr" target="#b25">[26]</ref> used in FSM. Note that listing requires enumerating every subgraph, but counting does not. Thus, counting allows more aggressive search-space pruning.</p><p>A pattern P is a small graph that can be defined explicitly or implicitly. An explicit definition specifies the vertices and edges of P , whereas an implicit definition specifies the desired properties of P . For explicit-pattern problems, the solver finds matches of P in S p . For implicit-pattern problems, S p is not known in advance. Therefore, the solver must find the patterns as well as their matches during the search. GPM requires guarantee for completeness, i.e., every match of P in G should be found, and often uniqueness, i.e., every distinct match should be reported only once <ref type="bibr" target="#b100">[101]</ref>. To avoid confusion, we call a vertex in the pattern P as a pattern vertex and denote it as u i , and a vertex in the data graph G as a data vertex and denote it as v i . Our work covers the following GPM problems from the literature <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b100">101]</ref>:</p><p>? Triangle counting (TC): It counts the number of triangles (Fig. <ref type="figure" target="#fig_0">1</ref>), i.e., 3-cliques, in G.</p><formula xml:id="formula_1">? k-clique listing (k-CL): It lists all the k-cliques in G (k ? 3).</formula><p>A k-clique is a k-vertex graph whose every pair of vertices are connected by an edge.</p><p>? Subgraph listing (SL). It lists all edge-induced subgraphs of G that are isomorphic to a pattern P .</p><p>? k-motif counting (k-MC): It counts the number of occurrences of all possible k-vertex patterns. Each pattern is called a motif <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b76">77]</ref>. Fig. <ref type="figure" target="#fig_6">3</ref> shows all 3-motifs and 4motifs. This is also an example of a multi-pattern problem because we have to find all the subgraphs that are isomorphic to any pattern in a given set of patterns. ? k-frequent subgraph mining (k-FSM): Given k and a threshold ? min , this problem considers all patterns with fewer than k edges and lists a pattern P if the support ? of P is greater than ? min . This is called a frequent pattern. If k is not specified, it is set to ?, meaning that it is necessary to consider all possible values of k. In k-FSM, vertices in G have application-specific labels.</p><p>For TC and k-CL, vertex-induced and edge-induced subgraphs are the same. SL and FSM find edge-induced subgraphs, while k-MC looks for vertex-induced subgraphs. All problems seek to find explicit pattern(s) except FSM which finds implicit patterns. k-MC and FSM are multi-pattern problems, while the others are single-pattern problems. Algorithm 1 Pseudo code for finding diamond in DFS order</p><formula xml:id="formula_2">1: for each vertex v 1 ? V in parallel do match v 1 to u 1 2: for each vertex v 2 ? N (v 1 ) do match v 2 to u 2 3: if v 2 ? v 1 then break; symmetry breaking 4: W ? N (v 1 ) ? N (v 2 ); set intersection: buffered in W 5:</formula><p>for each vertex v 3 ? W do match v 3 to u 3 6:</p><p>for each vertex v 4 ? W do match v 4 to u 4 ; W is reused 7:</p><p>if v 4 ? v 3 then break; symmetry breaking 8:</p><p>else count ++; do the counting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pattern-Aware GPM Algorithms</head><p>A GPM problem is a search problem, whose search space is a subgraph tree <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref> (Fig. <ref type="figure" target="#fig_2">4</ref>). Each node in the tree is a subgraph of the data graph G. Subgraphs in level l of the tree have l vertices. The root of the tree (level 0) is an empty subgraph, while the leaves of the tree are potential candidates of matches. A GPM problem can be solved by building this search tree, and checking each leaf if it is isomorphic to the pattern P using the typical graph isomorphism test.</p><p>The search tree is built by vertex extension: subgraph</p><formula xml:id="formula_3">S 1 =(W 1 , E 1 ) can be extended by a single vertex v / ? W 1 to obtain subgraph S 2 =(W 2 , E 2 ), if v is connected to some ver- tex in W 1 (i.e., v</formula><p>is in the neighborhood of subgraph S 1 ). When two subgraphs are related in this way, we say that S 2 is a child of S 1 . Formally, this can be expressed as W 2 =W 1 ? {v} where v / ? W 1 and there is an edge (v, u) ? E for some u ? W 1 . Similarly, edge extension extends a subgraph S 1 with a single edge (u, v), with at least one of the endpoints of the edge is in S 1 .</p><p>The efficiency of a GPM algorithm depends heavily on how much we can prue the search tree. State-of-the-art GPM frameworks <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b73">74]</ref> use pattern-aware search plans that leverage the properties of the pattern to prune the tree. A pattern-aware search plan consists of a matching order and symmetry order. Matching order is a total order that defines how the data vertices are matched to pattern vertices. This order is used to eliminate irrelevant subgraphs on-the-fly. As shown in Fig. <ref type="figure" target="#fig_2">4</ref>, to find the diamond pattern, we use a matching order among pattern vertices: {u 1 ? u 2 ? u 3 ? u 4 }, meaning that each vertex v 1 added at level 1 is matched to u 1 ; each vertex v 2 added at level 2 are matched to u 2 , and so on. To search for matching candidates, there are connectivity constraints for the data vertices. For example, in diamond, since u 3 is connected to both u 1 and u 2 , candidate vertices of v 3 must be found in the intersection of v 1 and v 2 's neighborhoods, i.e., v 3 ? N (v 1 ) ? N (v 2 ). The same constraint should also be applied to v 4 . For a given pattern P , there exist multiple valid matching orders. To choose the best performing matching order, prior works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b92">93]</ref> have proposed various cost models to predict the performance of matching orders, and choose the one with the highest expected performance. Symmetry order is a partial order enforced among data vertices for symmetry breaking, which removes redundant subgraph enumerations (a.k.a automorphism <ref type="bibr" target="#b25">[26]</ref>), and thus guar-Algorithm 2 Pseudo code for finding Pattern P in BFS order </p><formula xml:id="formula_4">&gt; v 2 , v 3 &gt; v 4 }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">DFS vs. BFS</head><p>Any search order (e.g., BFS, DFS) can be used to explore the search tree, but different search orders come with different work efficiency, parallelism and memory consumption. Algorithm 1 shows a DFS algorithm to mine the pattern diamond. It contains 4 nested for loops (Line 1, 2, 5, 6). Each loop corresponds to a data vertex (v 1 , v 2 , v 3 , v 4 ) that is mapped to a pattern vertex (u 1 , u 2 , u 3 , u 4 ) in Fig. <ref type="figure" target="#fig_4">5 (a)</ref>. A buffer W in Line 4 holds intermediate data that is reused multiple times, which avoids redundant computation and thus improves work efficiency. The memory footprint contains only four vertices (v i , i = 1, 2, 3, 4) and W in Line 4 whose size is bounded by ?. In DFS, every parallel task does a DFS walk on the entire subtree rooted at v 1 (Line 1). This is known as vertex parallelism. The amount of parallelism is |V |. Another way to parallelize it is edge parallelism, in which every task contains the subtree rooted at each edge (say, if we make Line 2 in parallel). The amount of parallelism then is |E |.</p><p>The BFS algorithm in Algorithm 2 explores the tree level by level. In each level, it maintains a subgraph list that is shared globally among all threads. Each thread takes a subgraph from the subgraph list (Line 2), and extends it to generate its child subgraphs (Line 5). The child subgraphs are inserted into the next-level subgraph list (Line 8). In BFS, each parallel task is a subgraph in the subgraph list of the current level. Since the size of the subgraph list increases exponentially level by level, the amount of parallelism increases rapidly.  Although it provides more parallelism than DFS, BFS needs much more memory to accommodate the subgraph list. For example, the BFS-based GPM system Pangolin <ref type="bibr" target="#b25">[26]</ref> needs more than 40GB memory to mine the 5-clique pattern in a moderate size graph livejournal, making it impossible to run in most of off-the-shelf GPUs.</p><formula xml:id="formula_5">v 1 v 2 v 1 v 3 v 2 v 1 v 3 v 2 v 4 u 1 u 3 u 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">GPM Systems and Applications</head><p>Many existing GPM systems <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b100">101,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b120">120]</ref> use the BFS order. As they do level-by-level subgraph extension, they generate massive intermediate data and thus are limited to small graphs and patterns. Recently, a few DFS-based GPM systems <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b73">74]</ref> have been proposed to support larger datasets, but they are all CPU-based. Among all, Pangolin is the only existing GPM system that supports GPU. However, limited by the BFS order, Pangolin can only handle small graphs, and it lacks pattern and input awareness.</p><p>There also exist subgraph matching systems on CPU <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b92">93,</ref><ref type="bibr" target="#b103">104]</ref> and GPU <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b117">117]</ref>. But they only support a subset of GPM problems and are usually not programmable.</p><p>Numerous hand-optimized GPM applications have been developed, including triangle counting <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b93">94,</ref><ref type="bibr" target="#b97">98,</ref><ref type="bibr" target="#b108">109,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b116">116]</ref> , k-clique listing <ref type="bibr" target="#b29">[30]</ref> and counting <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b91">92]</ref>, motif counting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b94">95]</ref>, subgraph listing/matching <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b96">97,</ref><ref type="bibr" target="#b102">103,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b107">108]</ref>, and FSM <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b98">99,</ref><ref type="bibr" target="#b99">100,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr" target="#b105">106,</ref><ref type="bibr" target="#b113">114]</ref>. All of them are manually optimized with significant programming effort to achieve high efficiency, which is quite a lot of burden for the domain programmers.</p><p>3 Challenges of Efficient GPM on GPU</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GPM vs. Graph Analytics</head><p>Similar to graph analytics, GPM algorithms are irregular <ref type="bibr" target="#b17">[18]</ref> because the control flow and memory accesses are input-data dependent and thus, cannot be predicted statically. This irregularity causes random memory accesses and load imbalance, making it difficult to be efficiently parallelized. Unlike graph analytics that only accesses 1-hop neighbors, GPM requires accessing multi-hop neighbors, which exacerbates the irregularity problem. For example, load imbalance is much worse for DFS-based GPM than graph analytics because each parallel task (a DFS walk on the entire sub-tree) is more coarsegrain in GPM. In addition, GPM generates intermediate data during the search (buffer W in DFS or subgraph list in BFS), which consumes extra memory than graph analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GPM on GPU vs. GPM on CPU</head><p>Since the tasks are independent of each other, they are fairly easy to parallelize on CPU, as shown in Algorithm 1 Line 1.</p><p>But it is not as straightforward on GPU due to GPU's massively parallel model and limited memory capacity.</p><p>A GPU often consists of multiple streaming multiprocessors (SM). Each SM accommodates multiple vector units. This hardware organization results in a hierarchical parallel model: each CUDA kernel includes groups of threads called cooperative thread arrays (CTAs) or thread blocks. Within each CTA, subgroups of threads called warps are executed simultaneously. Thus GPUs, to be fully utilized, require much more hierarchical parallelism than CPUs.</p><p>GPUs generally have less memory than CPUs, while BFSbased GPM algorithms consume memory exponential in the pattern size. Using DFS can reduce memory consumption, and also improve work efficiency. Hence, state-of-the-art CPUtargeted GPM frameworks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b92">93]</ref> all adopt DFS. However, naively porting the DFS-based CPU algorithms to GPU is not efficient because of the following reasons:</p><p>(1) Branch Divergence. In Algorithm 1, each thread takes a vertex v 1 from V and starts DFS walk rooted by v 1 . Since different vertices have different neighborhoods, the threads in a warp may take different paths at the branches, leading to inefficiency on GPU <ref type="bibr" target="#b86">[87]</ref>. Branch divergence is much more severe for DFS than BFS due to the multiple nested loops for DFS backtracking that access multi-hop neighborhoods.</p><p>(2) Memory Divergence. DFS walk also makes memory accesses more irregular. This causes memory divergence in GPU, i.e., threads in a warp access non-consecutive memory locations. In this case, each load instruction generates multiple (up to the warp size, i.e., 32) memory requests to the memory subsystem, which wastes memory bandwidth, congests onchip data path <ref type="bibr" target="#b23">[24]</ref>, and thus results in poor GPU performance.</p><p>(3) Load Imbalance. Variance of neighborhood sizes in power-law graphs causes load imbalance. In CPU it is less significant because there are limited number of cores/threads and each core is very powerful. However, GPUs have thousands of lightweight cores and more than ten times the number of active threads. If unbalanced, it would be much more costly since the slowest thread is running on a low-frequency core and thousands of cores are waiting. Load imbalance is also less concerned for BFS, since it does level-by-level extension and at each level the tasks are lightweight, i.e., fine-grained.</p><p>Therefore, existing GPU-based GPM systems <ref type="bibr" target="#b25">[26]</ref> and subgraph matching systems <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref> all use BFS order. This severely limits the graph sizes that they can handle. PBE <ref type="bibr" target="#b41">[42]</ref> partitions the data graph to support large graphs, but partitioning introduces cross-partition communication. Note that using beam search <ref type="bibr" target="#b70">[71]</ref> or bounded DFS does not fully resolve these issues, but loses the benefit of work efficiency of using DFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">G 2 Miner System Overview and Interface</head><p>We propose G 2 Miner (Fig. <ref type="figure">2</ref>) to address the challenges in ?3. account the properties of the pattern, input data graph and hardware architecture to achieve high efficiency on GPU. We first describe how to program in G 2 Miner in ?4.1, and then introduce the system interface for extracting information out of the input, pattern and architecture ( ?4.2). Lastly we give an overview of the optimizations in ?4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It hides away GPU programming complexity, and takes into</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Making Programming Easy</head><p>G 2 Miner provides the same API as state-of-the-art CPU-based systems, e.g., Peregrine and Sandslash, making it friendly to users of CPU frameworks. As shown in Listing 1, to program a k-CL solver in G 2 Miner, the user specifies the pattern using an utility function generateClique() (Line 2), and then call list() to do listing or count() to do counting. If count() is used, it allows the system enable counting-only optimizations (details in ?5). To list an arbitrary pattern P (Listing 2), the user can specify P using its edgelist (pattern.el at Line 4).</p><p>By default G 2 Miner finds vertex-induced subgraphs. Since SL requires listing edge-induced subgraphs by definition, the user needs to specify it (EdgeInduced at Line 4).</p><p>For multi-pattern problems, the user is interested in a set of patterns instead of just one. For k-MC in Listing 3, the patterns can be generated by calling an utility function generateAll() (Line 6) or parsing the patterns' edgelists.</p><p>Programmability is particularly important for implicitpattern problems. The user must implement API functions to specify the patterns. For example, for k-FSM in Listing 4, the user chooses to use domain support by implementing updateSupport (Line 8). To specify the properties that differentiate the interesting patterns with irrelevant patterns, the user must define patternFilter (Line 11). As FSM asks for only listing the patterns, we can specify a PATTERN_ONLY keyword in list to avoid listing the subgraphs (Line 16). If the user wants to customize the output, one can define a output() function and pass it to list, instead of using PATTERN_ONLY. This function defines custom operations on each subgraph of interest, which can also be used to do early termination <ref type="bibr" target="#b52">[53]</ref> by checking a user-defined condition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">System Interface</head><p>The pattern specified by user API is fed to a pattern analyzer to extract useful pattern information. Meanwhile, the GPU hardware information is taken by G 2 Miner to enable optimizations in the runtime, code generator and GPU primitives. At runtime, the data graph is loaded by a graph loader which collects input information and also performs preprocessing. Pattern Analyzer. The pattern analyzer generates: (1) a search plan with a matching order and a symmetry order, which is used by the code generator; (2) reuse opportunities using buffers (e.g., W in Algorithm 1), used by the code generator and the runtime; (3) other important properties of the pattern, e.g., whether the pattern is a clique or hub-pattern ( ?5.4 (2)), used by the runtime and code generator.</p><p>The pattern analyzer enumerates all the possible matching orders of P , and uses a cost model to pick the best one. We use the same cost model as GraphZero <ref type="bibr" target="#b72">[73]</ref> for fair comparison, but any cost model can be employed by G 2 Miner. We also use the algorithm in GraphZero to generate a symmetry order: it takes the generated matching order M O and builds a subgraph incrementally in the order specified by M O. At each step it detects symmetric vertex pairs and adds orders accordingly. For example, for diamond, the matching order in Fig. <ref type="figure" target="#fig_4">5 (</ref>  <ref type="table" target="#tab_4">2</ref>: Optimizations in G2Miner. Among them, optimizations A, B, D, E, F, I, J, K, M, N are pattern-aware; optimizations B, C, G, H, I, K, M are architecture-aware; and optimizations B, E, F, K, N are input-aware. Pattern-aware optimizations are applied based on the pattern analysis, while input-aware and architecture-aware optimizations are enabled according to the input and architecture information, respectively. TC: triangle counting. CL/CC: clique listing/counting. MC: motif counting.</p><p>tation <ref type="bibr" target="#b25">[26]</ref> . It gives every edge a direction in the undirected data graph G, which in turn converts G into a directed graph. This halves the edge count in G, significantly reduces ?, and completely eliminates on-the-fly checking. Third, our preprocessor also supports sorting (e.g., by degree) and renaming the vertices in G to improve load balance <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b72">73]</ref>. Note that all these preprocessing operations need to be done only once.  <ref type="formula">2</ref>) do not exist in prior GPM systems (e.g., Pangolin) but have been used in some hand-written GPM applications. For example, optimization D: data graph partitioning has only been used for triangle counting, while in G 2 Miner we generalize it for all the clique patterns. These optimizations are missing in prior GPM systems because prior systems are oblivious to the required pattern, input or architecture information. Optimizations in Category-(3) are novel as they have never been used for GPM, though some of them are known for GPU computing in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overview of Optimizations</head><p>As shown in column 3 to 7 of Table <ref type="table" target="#tab_4">2</ref>, these optimizations have different kinds of effect on GPM applications: (1) mitigating thread divergence; (2) improving load balancing; (3) reducing memory consumption; (4) pruning search space; and (5) improving efficiency based on GPU hardware features.</p><p>The last column of Table <ref type="table" target="#tab_4">2</ref> shows the conditions for each optimization to be applied. All the optimizations in Table <ref type="table" target="#tab_4">2</ref> are automated in G 2 Miner based on detecting the conditions, except for M and N (the last two rows). M and N are particularly used for implicit-pattern problems like FSM, for which the system cannot infer the conditions automatically. Thus, M and N are user-activated by specifying a flag.</p><p>Next, we describe these optimizations in detail, in the three major components of G 2 Miner: the code generator ( ?5), the device function library ( ?6) and the runtime scheduler ( ?7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pattern-specific GPU Code Generation</head><p>G 2 Miner includes a pattern-aware code generator that automatically generate CUDA code specific to the pattern. Prior work <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b73">74]</ref> has explored how to generate pattern-specific CPU code based on the matching order and symmetry order, but code generation is more challenging for GPU.</p><p>Generating pattern-specific CPU code is relatively straightforward. For example, to generate Algorithm 1 for diamond, the matching order in Fig. <ref type="figure" target="#fig_4">5</ref> (a) is used to generate the 4 nested for loops, and the symmetry order is then used to insert breaks at Line 3 and 7. Whenever a set operation is needed, a function call to the set operation primitive (imple-mented in a library) is inserted (Line 4). Since v 3 and v 4 are both from N (v 1 ) ? N (v 2 ), a buffer W is created for data reuse. Finally, task parallelism is used to parallelize the program, i.e., each thread processes one task at a time (Line 1).</p><p>However, generating efficient GPU code is more challenging, because (1) DFS-based GPM suffers from the thread divergence and load imbalance issues ( ?5.1); (2) hybrid search orders are needed in some cases ( ?5.2); and (3) extra support is needed for multi-pattern problems ( ?5.3) and advanced pruning schemes ( ?5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Parallel Strategies for DFS on GPU</head><p>To maximize GPU efficiency for the DFS algorithm, we employ a two-level parallelism strategy in G 2 Miner to exploit both inter-warp task parallelism and intra-warp data parallelism. This is motivated by our key observation that in GPM algorithms most of execution time is spent on set operations. For example, when we executed Peregrine on a multicore CPU, set operations for each benchmark took 75% to 92% of the total execution time. This motivated us to parallelize set operations by exploiting the data parallelism within each warp. It alleviates divergence and also provides more parallelism to fully utilize GPUs. To reduce load imbalance and further increase parallelism, we use edge parallelism for GPU instead of the vertex parallelism used for CPU.</p><p>(1) Reduce divergence with warp-centric parallelism. We could map each task to a thread, a warp or a CTA in a GPU. As DFS has much more coarse-grained tasks than BFS, mapping a task to a thread would be highly divergent and unbalanced for GPUs. However, if we map a task to a CTA, all (e.g., 256) threads in the CTA will be used to process the same set operations. If the two input neighbor-lists of a set operation are small, many threads in the CTA will be idle, leading to low utilization. Moreover, all threads in the CTA will do the same DFS walk, which is a lot of redundant computation.</p><p>In G 2 Miner we use warp-centric data parallelism. Each task is assigned to a warp. All threads in a warp synchronously perform the same DFS walk of the task. During the DFS walk, whenever a set operation is encountered, all threads in the warp work cooperatively to compute the set operation in parallel. It has several benefits. First it achieves higher throughput than CPU since set operations are parallelized. Second, it alleviates thread divergence within each warp as all threads in a warp are progressing synchronously. Third, it causes less redundancy than using CTA. Our evaluation shows it is on average 2? faster than CTA-centric parallelism.</p><p>(2) Reduce task granularity for load balance. GPM systems on CPU use vertex parallelism <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74]</ref>, i.e., each task is a DFS walk rootedin a vertex, as shown in Fig. <ref type="figure" target="#fig_7">6 (a)</ref>. This can already provide enough parallelism for CPU, needs no auxiliary data, and potentially enjoys data reuse within the sub-tree. But the coarse-grain tasks lead to load imbalance which can not be well tolerated by GPUs. To reduce task gran- ularity, we use edge-parallelism, i.e., each task explores the subtree rooted by an edge. As shown in Fig. <ref type="figure" target="#fig_7">6</ref> (b), apparently more work is required to search the subtree below a vertex on average compared to searching the subtree below an edge. In addition to better load balance, edge parallelism can provide more parallelism (|E |&gt;|V |) for GPU than vertex parallelism.</p><p>? By default, our code generator generates edge-parallel kernels. Our evaluation shows they are mostly (1.5? on average) faster than vertex parallel ones. But some GPM algorithms must use vertex parallelism. For example, the 3-MC algorithm in <ref type="bibr" target="#b24">[25]</ref> can only be done in vertex parallelism. G 2 Miner supports both vertex and edge parallelism. The user can set a compiler flag to use vertex parallelism, in which case ? is not generated to save memory. Discussion. Two-level parallelism has been only used for triangle counting <ref type="bibr" target="#b49">[50]</ref>, and it is challenging to extend it for all GPM problems. First, triangle counting does subgraph extension only once, which needs no DFS traversal. Thus, G 2 Miner is the first to support DFS for GPM on GPU. Second, naive GPU implementations for complex patterns can easily run out of memory for intermediate data. This is not a concern for triangle counting. Third, during the DFS traversal, it requires extension to support high-performance generic set operations and multi-pattern, which triangle counting does not require. In the following, we show that these challenges can be resolved by applying optimizations H, I, J, K, M, N in Table <ref type="table" target="#tab_4">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Support for Hybrid Search Orders</head><p>With the two-level parallelism in ?5.1, for many GPM problems, DFS is faster than BFS in G 2 Miner. However, this is not the case for problems like FSM. FSM computes the domain support and thus requires aggregating all the subgraphs for each pattern to compute its support. In the DFS-based FSM algorithm <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b113">114]</ref>, each task is a single-edge pattern (instead of subgraph) and the entire subtree of that pattern. This is pattern-parallel, instead of vertex-parallel or edge-parallel. Since the number of patterns is much smaller than the number of vertices or edges, the parallelism in FSM is not sufficient for GPU. Moreover, the task granularity in pattern-parallelism is much larger than that in vertex-or edge-parallelism, making Algorithm 3 Pseudo code for counting diamond</p><formula xml:id="formula_6">1: for each vertex v 1 ? V in parallel do match v 1 to u 1 2: for each vertex v 2 ? N (v 1 ) do match v 2 to u 2 3: if v 2 ? v 1 then break; symmetry breaking 4: n = |N (v 1 ) ? N (v 2 )|; # triangles incident to (v 1 , v 2 ) 5:</formula><p>count += n*(n-1)/2 choose 2 from n to form a diamond the problem even more unbalanced.</p><p>In G 2 Miner we use a hybrid of BFS and DFS, or bounded BFS search for problems that use domain support (e.g., FSM). At the single-edge level (i.e., level-2), we start with BFS search to aggregate edges by their patterns in parallel, which provides abundant parallelism. As the search goes deeper, the number of subgraphs increases exponentially. To fit the intermediate data in memory, we divide the subgraphs into blocks. Each block has a size that can resides in GPU memory, but also contains enough amount of subgraphs that can fully utilize the GPU. Once the current block is processed, it moves to the next block. Using this bounded BFS search, G 2 Miner can support larger graphs than Pangolin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Support for Multi-pattern Problems</head><p>Multiple patterns may have a common sub-pattern, which can be shared if they are searched in the same CUDA kernel. On the other hand, mining multiple patterns simultaneously would need a significant amount of intermediate resources, e.g., registers, which results in low hardware utilization (occupancy) on GPU.</p><p>Instead of generating a single gigantic kernel for all patterns, we employ kernel fission to reduce register pressure. Given multiple patterns, we leverage pattern analysis to find which patterns share the same sub-pattern, so that they should be merged into the same kernel to enjoy sharing. For those patterns do not share the same sub-patterns, we generate different kernels for them, so that each kernel is lightweight enough to avoid high register pressure. For example, in 4-motifs (Fig. <ref type="figure" target="#fig_6">3</ref>), tailed-triangle, diamond and 4-clique share the same sub-pattern triangle. So we generate a single CUDA kernel for the three patterns, in which they share the same workflow that enumerates triangles. However, for the other patterns, since there is no sharing opportunity, we generate one kernel for each. These separated kernels use fewer registers than a combined kernel, so that each SM in GPU can accommodate more co-running warps to maximize utilization. This improves performance by 15% for mining 4-motifs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Support for Advanced Pruning Schemes</head><p>(1) Counting-only Pruning. If the user is interested in counting instead of listing subgraphs, there may exist an advanced pruning opportunity to further reduce the search space. For example, to count edge-induced diamond (Algorithm 3), because a diamond consists of two triangles, we first compute the triangle count n for each edge (v 1 , v 2 ) using set intersection (Line 4), and then use the formula n 2 = n ? (n -1)/2 to get the diamond count (Line 5). Note that this pruning opportunity is pattern specific and is not always available. For example, there is no such opportunity for 4-cycle. Our pattern analyzer detects the opportunities by using automatic pattern decomposition <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b81">82]</ref>, and based on the detection, our code generator can accordingly generate the CUDA kernel.</p><p>(2) Local Graph Search (LGS). This is a pruning scheme used for hub-patterns. A hub-pattern contains at least one hub vertex that is connected to all other vertices. For example, any vertex in a clique is a hub vertex. The key idea of LGS is, instead of searching a massive data graph G, we can construct a small local graph for each vertex in G and search in the local graphs. For a hub pattern with a hub vertex u 1 , we match the first data vertex v 1 to u 1 , and the entire sub-tree rooted by v 1 is confined within v 1 's 1-hop neighborhood. Fig. <ref type="figure" target="#fig_8">7</ref> shows an example of constructing a local graph. Search in the local graph is faster because the vertex degrees in the local graph are smaller than those in the global data graph. When the pattern analyzer detects a hub-pattern, the code generator inserts a call to construct local graphs, and generates code to search in the local graphs, instead of the original data graph.</p><p>? Previously, LGS has only been used for clique patterns <ref type="bibr" target="#b29">[30]</ref>,</p><p>while G 2 Miner generalizes and automates it for all hub patterns. Moreover, unlike CPUs, naive implementation on GPUs is not beneficial. We combine LGS with the bitmap format (see ?6.2) to achieve significant speedups. ? Input Awareness. LGS is not always beneficial <ref type="bibr" target="#b24">[25]</ref>. The key indicator is the maximum degree ? of the data graph. For example, if ? is too large, it is not beneficial due to high overhead of local graph construction. Therefore, we generate CUDA kernels for both cases:</p><p>LGS enabled and disabled.</p><p>The runtime system checks if ? is above a threshold and decides accordingly which kernel to use. LGS brings us 1.2 ? 3.7? speedup on GPU for various data graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Device Primitives for Set Operations</head><p>As G 2 Miner assigns each task to a warp, whenever there is a set operation, all the thread in a warp work cooperatively to compute it. For example, in Algorithm 1, there is a set intersection at Line 4. In G 2 Miner, set operations are done by invoking the corresponding device functions predefined in the GPU primitive library. We leverage GPU hardware SIMD support to implement efficient set operations ( ?6.1) and flexibly support various data formats for vertex sets ( ?6.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">SIMD-aware Primitives</head><p>Given two sets A and B, we need two major set operations in GPM: (1) set intersection:</p><formula xml:id="formula_7">C = A ? B; (2) set difference: C = A -B,</formula><p>where C is the output set. Besides, another operation set bounding is also often needed: given a set A and an upper bound y, set bounding computes {x|x &lt; y&amp;x ? A}. We discuss set intersection in detail, and the other operations are similar.</p><p>In Algorithm 1 Line 4, the result of set intersection is stored in a buffer W for reuse. Buffering is widely used in GPM algorithms to avoid repetitive computation <ref type="bibr" target="#b73">[74]</ref>. To support buffering in G 2 Miner, each warp is allocated a private buffer in the GPU memory. In the primitive functions, threads in a warp write outputs to the buffer in parallel. To do this efficiently, we use CUDA warp-level primitives <ref type="bibr" target="#b68">[69]</ref> which are supported by the GPU hardware (special instructions). For each vertex v in set A, we use a boolean flag to indicate whether it exists in set B. Using the flag, we compute a mask using __ballot_sync primitive. The mask is then used to compute the index and the total size of the buffer using __popc primitive. Implementation details. Previous work has explored set intersection for SIMD <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b118">118]</ref> or GPU <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b111">112,</ref><ref type="bibr" target="#b112">113]</ref>. We classify their algorithms into 3 categories: Merge-path <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>, Binary-search <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b49">50]</ref> and Hash-indexing <ref type="bibr" target="#b79">[80]</ref>. We have extensively evaluated these methods on GPU, and we find that binary search works the best since it is less divergent. In our library, we implement a high-performance binary search <ref type="bibr" target="#b49">[50]</ref>: to exploit temporal locality, we leverage the scratchpad in GPU to pre-load the first five layers of the binary search tree, which further mitigates memory divergence. We extend this method to also support set difference, set bounding, and local graph construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Flexible Data Representation</head><p>Vertex set is a key data structure in GPM, which is used for the neighbor list in G and the buffer W in Algorithm 1. Its representation on GPU has a major impact on performance. For the set operations particularly, using a dense representation makes set operations easy to compute, but it requires more storage space. If using a sparse representation, it saves space but complicates the computation of set operations.</p><p>We support two types of formats for vertex set on GPU: sorted-list (sparse) and bitmap (dense). sorted-list is a list (i.e. array) of vertices sorted in ascending order. bitmap is a sequence of bits (length=|V |), each of which indicates the connectivity to a vertex in V . Set operations on bitmap are very simple and efficient, but bitmap consumes more space when V is large. Thus, by default we use sorted-list, and we only enable bitmap for hub-patterns since the bitmap size can be reduced significantly (? instead of |V |).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Runtime Scheduling and Management</head><p>Our runtime system is aware of the pattern, input data graph and GPU architecture to balance workload among multiple GPUs ( ?7.1) and make full use of the GPU memory ( ?7.2). BFS-based GPM systems, e.g., Arabesque, RStream, and Pangolin, balance workload by reassigning tasks at every level. But this does not work for the DFS algorithm because DFS does not work in the level-by-level way as BFS. Existing DFS-based GPM systems target only CPUs, and thus can use sophisticated work stealing techniques <ref type="bibr" target="#b32">[33]</ref>. But this will incur non-trivial runtime overhead on multi-GPU (?20%) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b49">50]</ref>. Policy 1: Even-split Scheduling. ? is to evenly split into n consecutive ranges, each of which contains m/n tasks. This is used in existing triangle counting solvers on multi-GPU <ref type="bibr" target="#b79">[80]</ref>. This policy is simple and has no scheduling overhead, but it results in severe load imbalance for skewed graphs. Fig. <ref type="figure" target="#fig_9">8</ref> shows the time spent on each GPU to finish its work under the even-split scheme. Due to the skewness of the workload assigned to each GPU, under the 2-GPU setting we observe that GPU_0 takes much more time to finish its work than GPU_1. The same time variance is observed for the 3-GPU and 4-GPU setting. Worse still, in the 4-GPU setting, since most of the heavy tasks are assigned to GPU_1, it makes the 4-GPU setting even slower than the 3-GPU setting. This means the even-split scheme does not scale beyond 3-GPU for this benchmark. The reason of poor scalability is two-folds: (1) the granularity of splitting workload is too coarse-grain; (2) it is unaware to the skewness of task workload by assuming every task has the same amount of work. Policy 2: Round-robin Scheduling. Each GPU has a task queue, denoted as Q i for the i-th GPU, i ? [0, n). The tasks in ? are assigned to each queue in a round-robin fashion, i.e., e j is assigned to Q i , where i = j mod n, j ? [0, m). This is a finegrained scheduling policy that has been used in existing motif counting solvers on multi-GPU <ref type="bibr" target="#b88">[89]</ref>. The policy comes with some overhead, i.e., copying tasks into task queues. This copy is needed only once for a specific data graph and n, i.e., once done, the queues can be reused for mining different patterns. Policy 3: Chunked Round-robin Scheduling. ? is first split into lots of small chunks, and then we assign chunks to the task queues in a round-robin way. This is a generalization of the previous two policies. When the chunk size c = m/n, it becomes the same as policy 1. When c = 1, it becomes the same as policy 2. Thus if c is too small the data copying overhead will be high, but if c is too large, we see load imbalance as in policy 1. We use c = ? ? y, where y is the total number of warps and ? is a constant (set to 2 empirically). Our chunking is also pattern aware, as described in ?7.2.</p><p>Implementation details. To further reduce data copy overhead, we parallelize it as the location to copy to is fixed for each queue if the chunk size is fixed. Note that this overhead is constant to the pattern size k, which is trivial (&lt; 1%) when k &gt; 3, since the GPM computation is exponential to k. For small pattern like triangle, we overlap the scheduling overhead with the GPU computation, by first assigning a few chunks to each GPU and launch the kernel. During the GPU computation, we continue sending the remaining chunks from the CPU to feed the GPUs. Orthogonal work on ordering tasks in ? <ref type="bibr" target="#b88">[89]</ref> or grouping tasks by community may help further improve load balance and locality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">GPU Memory Management</head><p>GPU memory is a scarce resource. In GPM algorithms, the major memory usage involves the data graph G, the edgelist ? and the buffers (e.g., W in Algorithm 1)). For FSM, the subgraph list of each pattern requires additional space.</p><p>(1) Preprocessing the data graph. We have discussed orientation in ?4.2. In the multi-GPU setting, for any hub-pattern, since the search is confined in the root vertex v 1 's neighborhood, we partition V into n subsets (n is the number of GPUs).</p><p>For each i-th subset we generate its vertex induced subgraph of G, and copy it to the i-th GPU. This partitioning reduces memory usage and guarantees that there is no communication needed between GPUs. This technique has been used in <ref type="bibr" target="#b46">[47]</ref> only for triangle counting. We generalize it for all hub-pattern problems. The scheduling policy is then adjusted by chunking vertices and assigning incident edges in ? to the corresponding GPUs. For non-hub patterns, we do not partition G if it can fit in the single-GPU memory. This is because GPM algo-rithms access multi-hop neighbors, which leads to non-trivial communication overhead <ref type="bibr" target="#b98">[99]</ref>, especially for small-diameter graphs. When G is too large to fit in memory, we leverage community-aware partition <ref type="bibr" target="#b55">[56]</ref> to minimize communication.</p><p>(2) Reducing the size of edgelist. For ?, we apply an important optimization by considering symmetry at the edge level (level-2). Since G is an undirected graph, for each undirected edge in G, the edgelist contains two instances, each for one of the two directions of the edge. However, when there is a partial order between v 1 and v 2 for symmetry breaking, we generate the edgelist that contains only one instance. More specifically, if v 1 &gt; v 2 is included in the symmetry order (e.g., in Fig. <ref type="figure" target="#fig_4">5 (b</ref>)), the edgelist includes only the edges whose source vertex id is larger than its destination vertex id. In this way, we can reduce half of the edges before execution. It not only saves memory but also reduces checking on-the-fly. Note that there is a similar optimization <ref type="bibr" target="#b95">[96]</ref> to split the neighbor list of each vertex v into two sets, with one holding all neighbors whose IDs are larger than v, and the other holding the rest which have smaller IDs than v. This reduces on-the-fly checking, but it is not used to reduce memory usage.</p><p>(3) Adaptive buffering. In G 2 Miner's warp-centric DFS walk, each warp is allocated with X buffers. The value of X is pattern specific and the pattern analyzer can decide it when generating the search plan. For a pattern of size k, X ? k -3 because the first two levels and the last level do not need buffers. So the worst case memory consumption for buffering is O(? ? (k -3)). This is linear to k for a given specific data graph. In comparison, the intermediate data generated in Pangolin is exponential to k, which can be easily over the GPU memory capacity (see in ?8.1). Although ? is much smaller than E (see Table <ref type="table" target="#tab_6">3</ref>), given the large number of warps in GPU, the memory space for buffers can still be very large. Therefore, the runtime limits the total number of warps to save memory usage, so that all tasks assigned to the same warp share the buffer usage. In this way, given different data graphs, we can adaptively tune the number of warps to make full use of memory and maximize parallelism. More specifically, we subtract the size of G and ? from the total GPU memory size, to get the remaining memory size, denoted as Y . Then we can get the maximum number of warps Y /(X ? ?). Finally we launch min(Y /(X ? ?), |?|) warps. (4) Reducing memory allocation using label frequency. This optimization is particularly useful for problems that find frequent patterns, such as FSM. The graph loader in G 2 Miner computes the vertex frequency for each label. This information can be leveraged to find frequent labels, i.e., labels with vertex frequency above the user-defined support threshold ? min . Since infrequent labels can not be part of frequent patterns, the total number of possible frequent patterns N can be significantly reduced, if there are many infrequent labels. Note that in FSM we allocate a subgraph list for each possible pattern to store subgraphs for aggregation, and the memory consumption of these subgraph lists is proportional to N. With  this awareness of the input (i.e., label frequency), we can drastically reduce this memory consumption in many cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head><p>We compare G 2 Miner 2 with state-of-the-art systems: (1) GPM system on GPU, Pangolin <ref type="bibr" target="#b25">[26]</ref>, (2) subgraph matching solver on GPU, PBE <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>, (3) CPU-based GPM system Peregrine <ref type="bibr" target="#b52">[53]</ref> and (4) CPU-based subgraph matching system GraphZero <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b73">74]</ref>. Note that Pangolin also provides a CPU implementation, but it is slower than GraphZero. Table <ref type="table" target="#tab_6">3</ref> lists the data graphs. The first 3 graphs (Mi, Pa, Yo) are vertex-labeled graphs which are used for FSM. We use all the GPM applications listed in ?2.1 for evaluation, i.e., TC, k-CL, SL, k-MC. For SL, we use two patterns 4-cycle and diamond. Note that GraphZero does not support FSM, Pangolin does not support SL, and PBE does not support k-MC and FSM. For FSM, we include DistGraph <ref type="bibr" target="#b98">[99]</ref> in Table <ref type="table" target="#tab_13">8</ref> as the state-of-the-art hand-written FSM solver.</p><p>CPU-based systems and solvers are evaluated on a 4 socket machine with Intel Xeon Gold 5120 2.2GHz CPUs (56 cores in total) and 190GB RAM, while GPU-based solutions are evaluated on NVIDIA V100 GPUs (each with 32GB device memory). We exclude preprocessing (e.g., DAG construction in Pangolin and vertex reordering in Peregrine) time in all systems. We use a time-out of 30 hours for CPU and 8 hours for GPU, and report all results as an average of three runs. We show single-GPU performance in ?8.1 and compare with CPU solutions in ?8.2. Multi-GPU performance of G 2 Miner is shown in ?8.3. Impact of optimizations is analyzed in ?8.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Single-GPU Performance</head><p>We compare with Pangolin and PBE on a V100 GPU. observe that Pangolin runs out of memory for Tw4<ref type="foot" target="#foot_1">3</ref> and Uk, while G 2 Miner can run with all the data graphs. We also observe that G 2 Miner is constantly faster than Pangolin, due to optimized set operations in our library. On average, G 2 Miner is 1.8? faster than Pangolin on V100 GPU. The speedups are more significant for k-CL and k-MC. As shown in Table <ref type="table" target="#tab_9">5</ref>, G 2 Miner outperforms Pangolin by 4.6? and 7.6? for 4-clique listing on Lj and Or respectively. The speedups mainly come from data reuse enabled in DFS (i.e., buffering W in Algorithm 1) and optimized set operations <ref type="foot" target="#foot_2">4</ref> . Meanwhile, for all the rest of graphs and the larger pattern 5clique, Pangolin runs out of memory. Similar trend is found in Table <ref type="table" target="#tab_11">7</ref>, where we observe an average of 21.3? speedup over Pangolin on 3-MC, and Pangolin also runs out of memory for most of the cases. G 2 Miner managed to run all cases, which demonstrates that its DFS order and optimization J and K in Table <ref type="table" target="#tab_4">2</ref> can effectively reduce memory consumption.</p><p>For FSM in Table <ref type="table" target="#tab_13">8</ref>, G 2 Miner is competitive with Pangolin for the small graphs, since we use bounded BFS (optimization M in Table <ref type="table" target="#tab_4">2</ref>) that provides enough parallelism. For the largest graph Yo, Pangolin runs out of memory again, while G 2 Miner succeeds to run it, thanks to both optimization M and N in Table <ref type="table" target="#tab_4">2</ref> which help reduce memory consumption.</p><p>Overall, G 2 Miner achieves an average speedup of 5.4? over Pangolin, and the speedup is more significant for larger patterns. Moreover, G 2 Miner can run much larger graphs.</p><p>We also compare with PBE <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref> on the V100 GPU. PBE partitions the data graph when it gets large, which allows it run all the single-pattern workloads. However, its performance is even worse (3.8? slower) than Pangolin, due to the cross-partition communication overhead and lack of data graph orientation. Particularly, for subgraph listing, as diamond contains a sub-pattern triangle but 4-cycle does not, searching diamond generates much less intermediate data than searching 4-cycle. Thus in Table <ref type="table" target="#tab_10">6</ref> we observe that PBE's 4-cycle performance is much worse than G 2 Miner as     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Mining on GPU vs. on CPU</head><p>To evaluate how much speedup we can get from GPU over CPU, we compare G 2 Miner (on V100 GPU) with GraphZero (on 56-core CPU). Note that for each specific GPM application, G 2 Miner and GraphZero use exactly the same matching order and symmetry order, making it a fair comparison to show the benefit from the difference of hardware architectures. As listed in Table <ref type="table" target="#tab_7">4</ref>, G 2 Miner is significantly faster than GraphZero on TC, with an average speedup of 38.0?. The same trend is observed for k-CL in Table <ref type="table" target="#tab_9">5</ref>, where G 2 Miner outperforms GraphZero by 18.2?. This tremendous performance improvement is due to three parts: (1) the orientation optimization, (2) higher throughput (i.e. more parallelism) on GPU, and (3) our high-performance set operations on GPU. For SL, orientation can not be applied. Thus it can be used to evaluate the benefit of the other two parts. As shown in Table <ref type="table" target="#tab_10">6</ref>, G 2 Miner still achieves overwhelmingly better performance than GraphZero, with an average speedup of 10.5?. The speedup would be marginal if we use the BFS strategy in Pangolin and PBE or implement our DFS scheme naively.</p><p>While TC, k-CL and SL uses only set intersection, k-MC includes both set intersection and set difference. As G 2 Miner optimizes both operations, we also observe dramatic performance boost for k-MC. In Table <ref type="table" target="#tab_11">7</ref>, it constantly outperforms GraphZero for all benchmarks. On average G 2 Miner is 8.5? faster than GraphZero.</p><p>Overall, G 2 Miner on GPU achieves 15.2? speedup over GraphZero on CPU, which demonstrates the significant benefit of using GPU to accelerate GPM applications.</p><p>As GraphZero does not support FSM, we also compared to  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Multi-GPU Scalability</head><p>We evaluate multi-GPU performance by varying the number of GPUs from 1 to 8 in a single machine. Since PBE and Pangolin do not support multi-GPU, we only evaluate G 2 Miner in this section. We compare two task scheduling policies in Fig. <ref type="figure" target="#fig_13">9</ref>. As illustrated, the chunked round-robin scheme constantly works much better than the even-split scheme. More importantly, the chunked scheme scales linearly for all cases, while the even-split scheme fails to scale beyond 3-GPU for 3-MC on Tw2. The poor scalability of even-split is dues to the load imbalance. As shown in Fig. <ref type="figure" target="#fig_14">10</ref>, in the 4-GPU setting, the execution time of each GPU varies dramatically for the even-split setting. In contrast, for the chunked scheme, each GPU finishes its work roughly at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Impact of Optimizations</head><p>Different optimizations in Table <ref type="table" target="#tab_4">2</ref> contribute differently to the performance improvement. First, architecture-aware optimizations are crucial for all workloads on GPU. G 2 Miner is 5.4? faster then Pangolin, where two-level parallelism (C in Table <ref type="table" target="#tab_4">2</ref>) and SIMD-aware primitives (H in Table <ref type="table" target="#tab_4">2</ref>) contribute 3.1? and 1.7? respectively. Second, for a pattern-aware optimization, it is beneficial only for the target pattern(s), and the speedups vary a lot depending on how much the search space is pruned. For example, local-graph search (E+F in Table <ref type="table" target="#tab_4">2</ref>) brings 1.2? ? 3.7? speedup for hub-patterns (2.1? on av-    <ref type="figure" target="#fig_5">11</ref> shows that G 2 Miner can run up to 8-clique listing on a billion-edge graph Fr. In contrast, Pangolin can not even run 4-clique due to out-ofmemory, as shown in Table <ref type="table" target="#tab_9">5</ref>. Fig. <ref type="figure" target="#fig_5">11</ref> also shows that, from 4-clique to 8-clique, G 2 Miner on GPU consistently achieves an order of magnitude speedup over GraphZero on the CPU, although the GPU has much less memory than the CPU. This trend implies that GPUs can be not only capable but also highly efficient for processing large graphs and patterns, thanks to G 2 Miner's memory management and optimizations for the GPU architecture.</p><p>GPU Efficiency. To evaluate GPU utilization, we measure warp execution efficiency, which is the average percentage of active threads in each executed warp. As shown in Fig. <ref type="figure" target="#fig_5">12</ref>, the warp execution efficiency in Pangolin is around 40%. This is relatively low since more than half of the compute horse power is wasted. In comparison, G 2 Miner significantly improves the warp execution efficiency. This is mainly due to the highly efficient implementation of our warp-centric set operations. Besides, we also measure branch efficiency, i.e., the ratio of non-divergent branches to total branches. Although G 2 Miner uses DFS, We find that Pangolin and G 2 Miner have almost the same branch efficiency, thanks to the two-level parallelism scheme. Since we assign each task to a warp, all threads in a warp does the same DFS walk synchronously, which avoids most of the branch divergence. This creates some redundancy, but since most of execution time is spent on set operations, it is still a good tradeoff.</p><p>Counting-only pruning. In ?8.1, we do not enable optimization D in Table <ref type="table" target="#tab_4">2</ref>, because GraphZero and Pangolin do not support it. We observe that for those patterns (e.g., diamond) enabling this pruning in G 2 Miner further improve performance by 6.2? on average. Enabling this optimization in Peregrine also improves its performance, as shown in Table <ref type="table" target="#tab_14">9</ref>. However, due to our high efficiency on GPU, G 2 Miner still outperforms Peregrine by 41.1? when both enable it. This again demonstrates the performance superiority of GPU over CPU, no matter what algorithm optimizations are applied.</p><p>Sorting and renaming vertices. For fair comparison, this optimization done by the preprocessor is also not enabled in ?8.1. Our evaluation shows that this can futher improve G 2 Miner performance by 5% (up to 90%). Applying this to GraphZero also helps, but G 2 Miner is still 12? faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We present G 2 Miner, the first multi-GPU GPM framework that supports efficiently mining large graphs and patterns. For high efficiency, G 2 Miner is aware of the input, pattern and architecture to fully unlock the potential of GPM computing on GPUs, which results in a 5? speedup over the state-of-the-art GPU-based GPM system, Pangolin, on a single GPU. For scalability, G 2 Miner employs a custom task scheduler that can scale GPM computation to multiple GPUs linearly. For programmability, it automatically enables applicable optimizations and generates CUDA code, which hides away GPU programming complexity, and in turn provides the same easy-to-use programming interface as the state-of-theart CPU-based GPM frameworks (e.g., Peregrine). We also show that G 2 Miner on a single V100 GPU is 48? faster than Peregrine on a 56-core Intel CPU, a free lunch for GPM users.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graph Pattern Mining example. The pattern P is a triangle, and 3 triangles are found in the data graph G.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 : 3 -</head><label>33</label><figDesc>Figure 3: 3-vertex (left) and 4-vertex (right) motifs [26].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: A search tree using vertex extension. Vertex colors (not vertex labels) show the matching between data vertices and pattern vertices. The matching order is {u 1 ? u 2 ? u 3 ? u 4 }. The symmetry order is {v a &gt; v b , v c &gt; v d }. Subgraphs in grey are ruled out by symmetry breaking. ? shows the unnecessary extensions that are pruned by the matching order. shows the matched subgraph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>u 4 (</head><label>4</label><figDesc>a) Matching Order (b) Step 1: add partial order between v 1 and v 2 (c) Step 2: no op (d) Step 3: add partial order between v 3 and v 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Generating symmetry order for diamond<ref type="bibr" target="#b26">[27]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Listing 1 :</head><label>1</label><figDesc>k-Clique Listing (k-CL) user code in G 2 Miner 1 Graph G = loadDataGraph (" graph . csr "); 2 Pattern p = generateClique (k); 3 list (G , p); // count (G , p) for counting Listing 2: Subgraph Listing (SL) user code in G 2 Miner 4 Pattern p(" pattern . el " , EdgeInduced ); 5 list (G , p);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Listing 3 :</head><label>3</label><figDesc>k-Motif Counting (k-MC) user code in G 2 Miner 6 Set &lt; Pattern &gt; patterns = generateAll (k); 7 Map &lt; Pattern ,int &gt; result = count (G , patterns ); Listing 4: Frequent Subgraph Mining (k-FSM) user code in G 2 Miner 8 Void updateSupport ( Subgraph s) { 9 map (s. getPattern () , s. getDomain () ); 10 } 11 bool patternFilter ( Pattern p) { 12 return p. getDomainSupport () &gt;= threshold ; 13 } 14 Set &lt; Pattern &gt; patterns = generateAll (k, 15 EdgeInduced , patternFilter ); 16 list (G , patterns , PATTERN_ONLY );</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a) vertex-parallel vs. (b) edge-parallel execution. Each dashed circle is a parallel task. A task is mapped to one thread on CPU, but in G 2 Miner it is mapped to one warp on GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Local graph constructed for v 1 =5 and v 2 =6 which are matched to hub vertices u 1 and u 2 in the pattern respectively. We first compute set intersection of vertex 5 and 6, to get their common neighbors (vertex 7, 8, 9). The common neighbors are renamed to form a local graph. Renaming can reduce bitmap storage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Running time of each GPU using even-split: 3-MC on Tw2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Triangle counting on Tw4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Listing 4-cycle on Fr.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>3-motif counting on Tw2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: G 2 Miner multi-GPU scalability using two task scheduling policies: even-split vs. chunked-split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Running time of each GPU in the 4-GPU setting: 4-cycle on Fr.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 11 :Figure 12 :</head><label>1112</label><figDesc>Figure 11: Running time of k-clique listing over Fr, k ?[4,8].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note><p>Comparison of state-of-the-art GPM systems, in terms of support for generality of the programming model, hardware platforms (CPU/GPU/multi-GPU), search orders, and code generation.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>1 :</head><label>1</label><figDesc>for each level i ? [1, P .size] do</figDesc><table><row><cell></cell><cell cols="3">level i from 1 to the pattern size</cell></row><row><cell>2:</cell><cell cols="2">for each subgraph sg ? SL i in parallel do</cell><cell>SL i : subgraph list</cell></row><row><cell>3:</cell><cell>for each vertex u ? sg do</cell><cell></cell></row><row><cell>4:</cell><cell>for each vertex v ? N (u) do</cell><cell></cell></row><row><cell>5:</cell><cell>sg ? sg ? v</cell><cell cols="2">vertex extension: add vertex v</cell></row><row><cell>6:</cell><cell cols="2">if sg satisfy P .constraints(i) then</cell></row><row><cell>7:</cell><cell cols="2">if i = P .size then count ++;</cell><cell>leaf: a match found</cell></row><row><cell>8:</cell><cell>else SL i+1 .insert(sg )</cell><cell></cell><cell>go to the next level</cell></row><row><cell cols="4">antees that any match of P in G is found only once. For</cell></row><row><cell cols="4">example, for diamond, we enforce that vertices added at level</cell></row><row><cell cols="4">1 must have larger ids than vertices added at level 2, i.e.,</cell></row><row><cell cols="4">v 1 &gt; v 2 . Thus, in level 2 of the tree in Fig. 4, the subgraph</cell></row><row><cell cols="4">{2, 1} is selected to be extended further, but subgraph {1, 2}</cell></row><row><cell cols="4">is pruned. Similarly we add a constraint that v 3 &gt; v 4 . So the</cell></row><row><cell cols="2">symmetry order for diamond is {v 1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>a) results in the three steps shown in (b), (c) and (d), during which we add partial order v 2 &lt; v 1 and v 4 &lt; v 3 .</figDesc><table><row><cell>Category-(1): Known Category-(2): Known, but not enabled in prior GPM systems Category-(3): Novel for GPM Table</cell><cell>Optimizations A: Data graph preprocessing (edge orientation)  ?4.2 B: Data graph partitioning  ?7.2 (1) C: Two-level parallelism  ?5.1 D: Counting-only pruning  ?5.4 (1) E: Local graph search  ?5.4 (2) F: Flexible data format  ?6.2 G: Multi-gpu scheduling  ?7.1 H: SIMD-aware primitives  ?6.1 I: Multi-pattern fission  ?5.3 J: Edgelist reduction  ?7.2 (2) K: Adaptive buffering  ?7.2 (3) M: Hybrid order on GPU  ?5.2 N: memory reduction using label frequency  ?7.2 (4)</cell><cell>mitigate divergence</cell><cell>load balance</cell><cell>Graph Loader and Preprocessor. The data graph G is loaded by the graph loader into the memory in the com-pressed sparse row (CSR) format. As G is being loaded, use-ful input information of the data graph is extracted, e.g., |V |, |E | and ? of G. In addition, if the graph is labelled, the ver-tex frequency of each label is computed (see usage for FSM algorithm pruning extra GPU efficiency Used in Pangolin? Used in hand written apps? Conditions to apply cliques ? TC only hub patterns, graph size, GPU memory size ? TC only always enabled on GPU ? CPU only automatic pattern decomposition [82] ? CL only ? CC only hub patterns &amp; ? &lt;1024 ? MC only always used on multi-GPU ? ? hardware support for warp level primitives ? ? explicit multi-pattern &amp; kernel occupancy by NVCC ? ? if v 0 &gt;v 1 in symmetry order ? ? buffer W usage in matching order &amp; GPU memory size ? ? implicit, intermediate data unbounded, user-specified ? ? implicit, vertex label frequency, user-specified in  ?7.2). Effect mem. saving</cell></row></table><note><p>After G is loaded into memory, some preprocessing is performed on G. First, the neighbor list of each vertex is sorted by ascending order of vertex IDs, so that we can apply early exit when we search the list with an upper bound (i.e., symmetry breaking). Second, if a pattern of clique is detected, G 2 Miner enables a typical optimization called orien-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>lists all the optimizations enabled in G 2 Miner. We classify them into three categories. Optimizations in Category-(1) are those exist in prior GPM systems. Optimizations in Category-(</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Data graphs (symmetric, no loops or duplicate edges). Maximum degrees are smaller when orientation is applied for cliques.</figDesc><table><row><cell>Data Graph</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Uk</cell></row><row><cell>G 2 Miner (GPU)</cell><cell cols="2">0.03 0.14</cell><cell>1.6</cell><cell>5.1</cell><cell>3.2</cell><cell>7.5</cell></row><row><cell>Pangolin (GPU)</cell><cell cols="2">0.06 0.25</cell><cell>3.0</cell><cell>OoM</cell><cell>5.2</cell><cell>OoM</cell></row><row><cell>PBE (GPU)</cell><cell cols="2">0.27 1.12</cell><cell>13.4</cell><cell>53.5</cell><cell>23.0</cell><cell>55.3</cell></row><row><cell>Peregrine (CPU)</cell><cell cols="6">1.63 7.25 112.1 8492.4 100.3 3640.9</cell></row><row><cell>GraphZero (CPU)</cell><cell cols="2">0.61 2.22</cell><cell cols="2">24.4 1399.3</cell><cell cols="2">49.0 1041.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>TC running time (sec). OoM: out of memory.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc>lists the GPU running time for triangle counting (TC). We 2 G 2 Miner source code: https://github.com/chenxuhao/GraphMiner</figDesc><table><row><cell>Pattern</cell><cell></cell><cell></cell><cell>4-CL</cell><cell></cell><cell></cell><cell></cell><cell>5-CL</cell><cell></cell></row><row><cell>Data Graph</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Lj</cell><cell>Or</cell><cell>Fr</cell></row><row><cell>G 2 Miner (G)</cell><cell>0.32</cell><cell>0.54</cell><cell>113.3</cell><cell>362.9</cell><cell>7.3</cell><cell>3.2</cell><cell>1.7</cell><cell>13.1</cell></row><row><cell>Pangolin (G)</cell><cell>1.48</cell><cell>4.04</cell><cell>OoM</cell><cell cols="5">OoM OoM OoM OoM OoM</cell></row><row><cell>PBE (G)</cell><cell cols="2">3.90 11.11</cell><cell>3640.1</cell><cell cols="3">TO 117.8 246.4</cell><cell cols="2">99.2 399.8</cell></row><row><cell>Peregrine (C)</cell><cell cols="3">15.90 73.70 39921.0</cell><cell cols="5">TO 397.3 520.8 782.1 957.6</cell></row><row><cell>GraphZero (C)</cell><cell cols="2">3.48 12.96</cell><cell cols="3">2152.2 20591.1 177.7</cell><cell>60.0</cell><cell cols="2">48.3 243.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>k-CL running time (sec). TO: timed out.</figDesc><table><row><cell>Pattern</cell><cell></cell><cell></cell><cell>Diamond</cell><cell></cell><cell></cell><cell></cell><cell>4-cycle</cell><cell></cell></row><row><cell>Data Graph</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Lj</cell><cell>Or</cell><cell>Fr</cell></row><row><cell>G 2 Miner (G)</cell><cell>0.29</cell><cell>0.75</cell><cell>26.8</cell><cell>183.1</cell><cell>12.8</cell><cell>2.7</cell><cell>33.7</cell><cell>1291.2</cell></row><row><cell>PBE (G)</cell><cell>0.48</cell><cell>1.71</cell><cell>26.3</cell><cell>102.0</cell><cell>39.9</cell><cell>17.3</cell><cell>177.8</cell><cell>5211.3</cell></row><row><cell>Peregrine (C)</cell><cell cols="8">5.38 10.24 553.6 20898.4 178.1 144.4 1867.2 32276.8</cell></row><row><cell cols="2">GraphZero (C) 1.73</cell><cell cols="2">7.27 165.1</cell><cell cols="2">7938.6 136.4</cell><cell>34.0</cell><cell>345.5</cell><cell>9251.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>SL running time (sec). 'G': GPU; 'C': CPU.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>k-MC running time (s). OoM: out of mem.; TO: timed out.it has to do partitioning and suffers from the overhead. Overall, G 2 Miner achieves a 7.2? speedup over PBE on average.</figDesc><table><row><cell>Pattern</cell><cell></cell><cell></cell><cell>3-Motif</cell><cell></cell><cell></cell><cell></cell><cell>4-Motif</cell><cell></cell></row><row><cell>Data Graph</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Lj</cell><cell>Or</cell><cell>Fr</cell></row><row><cell cols="2">G 2 Miner (G) 0.17</cell><cell>0.97</cell><cell>33.3</cell><cell>1703.6</cell><cell>22.0</cell><cell>138.1</cell><cell cols="2">2068.4 15475.4</cell></row><row><cell cols="4">Pangolin (G) 2.05 22.62 1165.5</cell><cell cols="2">OoM OoM</cell><cell>OoM</cell><cell>OoM</cell><cell>OoM</cell></row><row><cell cols="3">Peregrine (C) 9.36 19.46</cell><cell cols="5">418.7 27954.9 367.9 1435.4 20219.1</cell><cell>TO</cell></row><row><cell cols="2">GraphZero (C) 1.50</cell><cell>7.74</cell><cell>276.5</cell><cell cols="4">7439.4 169.6 3039.6 16394.6</cell><cell>TO</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>3-FSM running time (sec). OoM: out of memory.Peregrine. G 2 Miner on GPU is 48.3? faster than Peregrine on CPU. Note that Peregrine does not mine multiple patterns simultaneously for multi-pattern problems. Instead, for k-MC and FSM, it enumerates every pattern one by one, making it impossible to reuse data across similar patterns. Thus it is mostly even slower than GraphZero.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 9 :</head><label>9</label><figDesc>Running time of G 2 Miner vs. Peregrine, both with counting-only pruning enabled. TO: timed out. erage), while counting-only pruning (D in Table 2) achieves 1.2? (diamond, Fr) to 79.7? (3-motif, Tw40), with 6.2? on average. Other optimizations in Table 2 are for memory saving, which is crucial for enabling larger datasets. Large Pattern and Large Graph. A major advantage of G 2 Miner over Pangolin is that G 2 Miner can support much larger graphs and patterns. Fig.</figDesc><table><row><cell>Pattern</cell><cell></cell><cell></cell><cell>Diamond</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3-Motif</cell><cell></cell><cell></cell><cell></cell><cell>4-Motif</cell><cell></cell></row><row><cell>Time (sec)</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Lj</cell><cell>Or</cell><cell>Tw2</cell><cell>Tw4</cell><cell>Fr</cell><cell>Lj</cell><cell>Or</cell><cell>Fr</cell></row><row><cell>G 2 Miner (GPU)</cell><cell cols="2">0.09 0.47</cell><cell>9.9</cell><cell>66.9</cell><cell>10.4</cell><cell cols="2">0.06 0.27</cell><cell>6.8</cell><cell>21.4</cell><cell>5.2</cell><cell>2.6</cell><cell cols="2">34.2 1307.2</cell></row><row><cell>Peregrine (CPU)</cell><cell cols="5">2.20 8.66 245.8 16312.6 158.8</cell><cell cols="5">2.51 4.90 116.0 8447.4 165.3</cell><cell cols="2">163.6 1701.4</cell><cell>TO</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We assume that every GPU has the same compute power for simplicity, otherwise it is not difficult to scale the workload by a factor accordingly.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Since data graphs are oriented in TC, Fr takes less memory than Tw4</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>It can not be directly used for Pangolin, as Pangolin maps connectivity checks<ref type="bibr" target="#b25">[26]</ref> to threads, but G 2 Miner maps set operations to warps.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="10">Acknowledgements</head><p>This research is funded by <rs type="funder">Samsung Semiconductor</rs> (GRO grants) and <rs type="institution">MIT-IBM Watson AI Lab</rs>, and supported by <rs type="funder">XSEDE</rs> allocation <rs type="grantNumber">TG-CIE-170005</rs> and <rs type="grantNumber">ASC22045</rs>. We thank <rs type="person">Tianhao Huang</rs> and OSDI reviewers for their feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_G3gZf8G">
					<idno type="grant-number">TG-CIE-170005</idno>
				</org>
				<org type="funding" xml:id="_fbNbXdF">
					<idno type="grant-number">ASC22045</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Artifact Appendix Abstract</head><p>This artifact appendix helps the readers reproduce the main evaluation results of the OSDI' 22 paper: Efficient and Scalable Graph Pattern Mining on GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scope</head><p>The artifact can be used for evaluating and reproducing the main results of the paper, including Table <ref type="table">4</ref>, Table <ref type="table">5</ref>, Table <ref type="table">6</ref>, Table <ref type="table">7</ref>, Table <ref type="table">8</ref> and<ref type="table">Fig</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contents</head><p>The artifact evaluation includes all the experiments in the paper. Details of the experiments are listed here: https://github.com/chenxuhao/GraphMiner/blob/master/OSDIexperiments-guide.md</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hosting</head><p>The source code of this artifact can be found on GitHub: https://github.com/chenxuhao/GraphMiner, master branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Requirements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hardware dependencies</head><p>This artifact depends on an NVIDIA V100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software dependencies</head><p>This artifact requires CUDA toolkit 11.1.1 or greater and GCC 8 or greater.</p><p>Details of the dependencies are listed here: https://github.com/chenxuhao/GraphMiner/blob/master/OSDIexperiments-guide.md</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scalemine: Scalable parallel frequent subgraph mining in a single large graph</title>
		<author>
			<persName><forename type="first">Ehab</forename><surname>Abdelhamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Kalnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuhair</forename><surname>Khayyat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuad</forename><surname>Jamour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;16</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;16<address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Emptyheaded: A relational engine for graph processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Aberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andres</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunle</forename><surname>N?tzli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Olukotun</surname></persName>
		</author>
		<author>
			<persName><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017-10">October 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient graphlet counting for large networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nesreen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><surname>Duffield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph based anomaly detection and description: a survey</title>
		<author>
			<persName><forename type="first">Leman</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="688" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Almasri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izzat</forename><forename type="middle">El</forename><surname>Hajj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13209</idno>
		<title level="m">K-clique counting on gpus</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Biomolecular network motif counting and discovery by color coding</title>
		<author>
			<persName><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hajirasouliha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hormozdiari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Sahinalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="241" to="249" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distributed evaluation of subgraph queries using worst-case optimal low-memory dataflows</title>
		<author>
			<persName><forename type="first">Khaled</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semih</forename><surname>Salihoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manas</forename><surname>Joglekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="691" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new data layout for set intersection on gpus</title>
		<author>
			<persName><forename type="first">Amossen</forename><surname>Rasmus Resen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rasmus</forename><surname>Pagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE International Parallel &amp; Distributed Processing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="698" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">and Aristides Gionis. Efficient semi-streaming algorithms for local triangle counting in massive graphs</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Becchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="16" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An evaluation of large set intersection techniques on gpus</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Bellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Gounaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DOLAP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="111" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Higher-order organization of complex networks</title>
		<author>
			<persName><forename type="first">Austin</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">353</biblScope>
			<biblScope unit="issue">6295</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Entity resolution in graphs. Mining graph data</title>
		<author>
			<persName><forename type="first">Indrajit</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">311</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CECI: Compact Embedding Cluster Index for Scalable Subgraph Matching</title>
		<author>
			<persName><forename type="first">Bibek</forename><surname>Bhattarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Howie</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data, SIG-MOD &apos;19</title>
		<meeting>the 2019 International Conference on Management of Data, SIG-MOD &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1447" to="1462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient subgraph matching by postponing cartesian products</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data, SIGMOD &apos;16</title>
		<meeting>the 2016 International Conference on Management of Data, SIGMOD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1199" to="1214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Manycore clique enumeration with fast set intersections</title>
		<author>
			<persName><forename type="first">Jovan</forename><surname>Blanu?a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Ienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kubilay</forename><surname>Atasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2676" to="2690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A large time-aware graph</title>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An efficient implementation of a subgraph isomorphism algorithm for gpus</title>
		<author>
			<persName><forename type="first">Vincenzo</forename><surname>Bonnici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosalba</forename><surname>Giugno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bombieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2674" to="2681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A quantitative study of irregular programs on gpus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burtscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nasre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Symposium on Workload Characterization (IISWC)</title>
		<imprint>
			<date type="published" when="2012-11">Nov 2012</date>
			<biblScope unit="page" from="141" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Counting problems on graphs: Gpu storage and parallel computing techniques</title>
		<author>
			<persName><forename type="first">Amlan</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">K</forename><surname>Sridhar Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName><surname>Antonio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops PhD Forum</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="804" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">G-miner: An efficient task-oriented graph mining system</title>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunjian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth EuroSys Conference, EuroSys &apos;18</title>
		<meeting>the Thirteenth EuroSys Conference, EuroSys &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Dwarvesgraph: A highperformance graph mining system with pattern decomposition</title>
		<author>
			<persName><forename type="first">Jingji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Kudu: An efficient and scalable distributed graph pattern mining engine</title>
		<author>
			<persName><forename type="first">Jingji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic load balancing on single-and multi-gpu systems</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oreste</forename><surname>Villa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Krishnamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guang</forename><forename type="middle">R</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Symposium on Parallel &amp; Distributed Processing (IPDPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive cache management for energy-efficient gpu computing</title>
		<author>
			<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">I</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-47</title>
		<meeting>the 47th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-47<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="343" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sandslash: A Two-Level Framework for Efficient Graph Pattern Mining</title>
		<author>
			<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loc</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th ACM International Conference on Supercomputing, ICS &apos;21</title>
		<meeting>the 35th ACM International Conference on Supercomputing, ICS &apos;21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pangolin: An efficient and flexible graph mining system on cpu and gpu</title>
		<author>
			<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2020-08">August 2020</date>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Flexminer: A pattern-aware accelerator for graph pattern mining</title>
		<author>
			<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuotao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Bourgeat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanwoo</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture</title>
		<meeting>the International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dataset for statistics and social network of youtube videos</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://netsg.cs.sfu.ca/youtubedata/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Predicting protein function by frequent functional association pattern mining in protein interaction networks</title>
		<author>
			<persName><forename type="first">Young-Rae</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information technology in biomedicine</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="36" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Listing k-cliques in sparse real-world graphs*</title>
		<author>
			<persName><forename type="first">Maximilien</forename><surname>Danisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oana</forename><surname>Balalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauro</forename><surname>Sozio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference, WWW &apos;18</title>
		<meeting>the 2018 World Wide Web Conference, WWW &apos;18<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Frequent substructure-based approaches for classifying chemical compounds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuramochi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1036" to="1050" />
			<date type="published" when="2005-08">Aug 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Theoretically efficient parallel graph algorithms can be fast and scalable</title>
		<author>
			<persName><forename type="first">Laxman</forename><surname>Dhulipala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Blelloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Shun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th on Symposium on Parallelism in Algorithms and Architectures, SPAA &apos;18</title>
		<meeting>the 30th on Symposium on Parallelism in Algorithms and Architectures, SPAA &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="393" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fractal: A general-purpose graph pattern mining system</title>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorgival</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><surname>Guedes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meira</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 International Conference on Management of Data, SIGMOD &apos;19</title>
		<meeting>the 2019 International Conference on Management of Data, SIGMOD &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1357" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Preference-based configuration of web page content</title>
		<author>
			<persName><forename type="first">Carmel</forename><surname>Domshlak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samir</forename><surname>Genaim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Brafman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th European Conference on Artificial Intelligence (ECAI 2000), Configuration Workshop</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Grami: Frequent subgraph and pattern mining in a single large graph</title>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Elseidy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehab</forename><surname>Abdelhamid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spiros Skiadopoulos, and Panos Kalnis</title>
		<imprint>
			<date type="published" when="2014-03">March 2014</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="517" to="528" />
		</imprint>
	</monogr>
	<note>Proc. VLDB Endow</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A puzzle concerning triads in social networks: Graph constraints and the triad census</title>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Faust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="233" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automatic large scale generation of internet pop level maps</title>
		<author>
			<persName><forename type="first">Dima</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Shavitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Telecommunications Conference (GLOBE-COM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fast and adaptive list intersections on the gpu</title>
		<author>
			<persName><forename type="first">James</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oded</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasimir</forename><surname>Gabert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojing</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE High Performance extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">PDTL: Parallel and distributed triangle listing for massive graphs</title>
		<author>
			<persName><forename type="first">I</forename><surname>Giechaskiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Panagopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yoneki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 44th International Conference on Parallel Processing</title>
		<imprint>
			<date type="published" when="2015-09">Sep. 2015</date>
			<biblScope unit="page" from="370" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Logarithmic radix binning and vectorized triangle counting</title>
		<author>
			<persName><forename type="first">Oded</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alok</forename><surname>Tripathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kasimir</forename><surname>Gabert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Euna</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojing</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumar</forename><surname>Aatish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE High Performance extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gpu merge path: A gpu merging algorithm</title>
		<author>
			<persName><forename type="first">Oded</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Mccoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM International Conference on Supercomputing, ICS &apos;12</title>
		<meeting>the 26th ACM International Conference on Supercomputing, ICS &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gpu-accelerated subgraph enumeration on partitioned graphs</title>
		<author>
			<persName><forename type="first">Wentian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokui</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kian-Lee</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;20</title>
		<meeting>the 2020 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1067" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Exploiting reuse for gpu subgraph enumeration</title>
		<author>
			<persName><forename type="first">Wentian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kian-Lee</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The NBER patent citation data file: Lessons, insights and methodological tools</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trajtenberg</surname></persName>
		</author>
		<ptr target="http://www.nber.org/patents/" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Speeding up set intersections in graph algorithms using simd instructions</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Management of Data</title>
		<meeting>the 2018 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1587" to="1602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Turbo&lt;sub&gt;iso&lt;/sub&gt;: Towards ultrafast and robust subgraph isomorphism search in large graph databases</title>
		<author>
			<persName><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeong-Hoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;13</title>
		<meeting>the 2013 ACM SIGMOD International Conference on Management of Data, SIGMOD &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="337" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">DistTC: High performance distributed triangle counting</title>
		<author>
			<persName><forename type="first">Loc</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishwesh</forename><surname>Jatala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Udit</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurbinder</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPEC 2019 23rd IEEE High Performance Extreme Computing</title>
		<meeting><address><addrLine>Graph Challenge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Local structure in social networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><surname>Leinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological methodology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Accelerating triangle counting on gpu</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data, SIGMOD-/PODS &apos;21</title>
		<meeting>the 2021 International Conference on Management of Data, SIGMOD-/PODS &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="736" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Tricore: Parallel triangle counting on gpus</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC18: International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<imprint>
			<date type="published" when="2018-11">Nov 2018</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Faster set intersection with simd instructions by reducing branch mispredictions</title>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moriyoshi</forename><surname>Ohara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenjiro</forename><surname>Taura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2014-11">November 2014</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="293" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A fast and provable method for estimating clique counts using tur?n&apos;s theorem</title>
		<author>
			<persName><forename type="first">Shweta</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web, WWW &apos;17</title>
		<meeting>the 26th International Conference on World Wide Web, WWW &apos;17<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="441" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Peregrine: A pattern-aware graph mining system</title>
		<author>
			<persName><forename type="first">Kasra</forename><surname>Jamshidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Mahadasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keval</forename><surname>Vora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth EuroSys Conference, Eu-roSys &apos;20</title>
		<meeting>the Fifteenth EuroSys Conference, Eu-roSys &apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Path sampling: A fast and provable method for estimating 4vertex subgraph counts</title>
		<author>
			<persName><forename type="first">C</forename><surname>Madhav Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName><surname>Pinar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW &apos;15</title>
		<meeting>the 24th International Conference on World Wide Web, WWW &apos;15<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="495" to="505" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Graphflow: An active graph database</title>
		<author>
			<persName><forename type="first">Chathura</forename><surname>Kankanamge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amine</forename><surname>Mhedbhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semih</forename><surname>Salihoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17, page 1695-1698</title>
		<meeting>the 2017 ACM International Conference on Management of Data, SIGMOD &apos;17, page 1695-1698<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A fast and high quality multilevel scheme for partitioning irregular graphs</title>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="359" to="392" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Graph kernels for chemoinformatics</title>
		<author>
			<persName><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroto</forename><surname>Saigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masahiro</forename><surname>Hattori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koji</forename><surname>Tsuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chemoinformatics and advanced machine learning perspectives: complex computational methods and collaborative techniques</title>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Parallel graph mining with gpus</title>
		<author>
			<persName><forename type="first">Robest</forename><surname>Kessl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nilothpal</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranay</forename><surname>Anchuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications</title>
		<meeting>the 3rd International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">DUALSIM: Parallel subgraph enumeration in a massive graph on a single machine</title>
		<author>
			<persName><forename type="first">Hyeonji</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juneyoung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourav</forename><forename type="middle">S</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeonghoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongyun</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moath</surname></persName>
		</author>
		<author>
			<persName><surname>Jarrah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data, SIGMOD &apos;16</title>
		<meeting>the 2016 International Conference on Management of Data, SIGMOD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1231" to="1245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Turboflux: A fast continuous subgraph matching system for streaming graph data</title>
		<author>
			<persName><forename type="first">Kyoungmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">In</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeong-Hoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungpack</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyungyu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geonhwa</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Management of Data, SIGMOD &apos;18</title>
		<meeting>the 2018 International Conference on Management of Data, SIGMOD &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="411" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Introduction to statistical relational learning</title>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sa?o</forename><surname>D?eroski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Pfeffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Topological network alignment uncovers biological function and phylogeny</title>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tijana</forename><surname>Milenkovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vesna</forename><surname>Memi?evi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nata?a</forename><surname>Pr?ulj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Society Interface</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">50</biblScope>
			<biblScope unit="page" from="1341" to="1354" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Konect: the koblenz network collection</title>
		<author>
			<persName><forename type="first">J?r?me</forename><surname>Kunegis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on World Wide Web</title>
		<meeting>the 22nd International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1343" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">What is twitter, a social network or a news media?</title>
		<author>
			<persName><forename type="first">Haewoon</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changhyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hosung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sue</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web, WWW &apos;10</title>
		<meeting>the 19th International Conference on World Wide Web, WWW &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Scalable subgraph enumeration in mapreduce</title>
		<author>
			<persName><forename type="first">Longbin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijun</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2015-06">June 2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="974" to="985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<title level="m">Snap: Stanford network analysis platform</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Network motif discovery: A gpu approach</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 31st International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="831" to="842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Efficient subgraph matching using gpus</title>
		<author>
			<persName><forename type="first">Xiaojie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyi</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hua Wang and Mohamed A. Sharaf, editors, Databases Theory and Applications</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="74" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Using cuda warp-level primitives</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Grover</surname></persName>
		</author>
		<ptr target="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Cuda-meme: Accelerating motif discovery in biological sequences using cuda-enabled graphics processing units</title>
		<author>
			<persName><forename type="first">Yongchao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertil</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiguo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><forename type="middle">L</forename><surname>Maskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2170" to="2177" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">The harpy speech recognition system</title>
		<author>
			<persName><surname>Bruce T Lowerre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Distributed graph pattern matching</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinpeng</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Wo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on World Wide Web, WWW &apos;12</title>
		<meeting>the 21st International Conference on World Wide Web, WWW &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="949" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Graphzero: A high-performance subgraph matching system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mawhirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Reinehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="37" />
			<date type="published" when="2021-06">June 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Automine: Harmonizing high-level abstraction and high performance for graph mining</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mawhirter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM Symposium on Operating Systems Principles, SOSP &apos;19</title>
		<meeting>the 27th ACM Symposium on Operating Systems Principles, SOSP &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="509" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Optimizing subgraph queries by combining binary and worst-case optimal joins</title>
		<author>
			<persName><forename type="first">Amine</forename><surname>Mhedhbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semih</forename><surname>Salihoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1692" to="1704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Optimal network alignment with graphlet degree vectors</title>
		<author>
			<persName><forename type="first">Tijana</forename><surname>Milenkovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weng</forename><forename type="middle">Leong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nata?a</forename><surname>Pr?ulj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer informatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2010">2010</date>
			<publisher>CIN-S4744</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Network motifs: Simple building blocks of complex networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Milo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen-Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Itzkovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kashtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chklovskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">298</biblScope>
			<biblScope unit="issue">5594</biblScope>
			<biblScope unit="page" from="824" to="827" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Graph-based anomaly detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Caleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="631" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Merge path-parallel merging made simple</title>
		<author>
			<persName><forename type="first">Saher</forename><surname>Odeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oded</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zahi</forename><surname>Mwassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oz</forename><surname>Shmueli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitzhak</forename><surname>Birk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops &amp; PhD Forum</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1611" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">H-index: Hash-indexing for parallel triangle counting on gpus</title>
		<author>
			<persName><forename type="first">Santosh</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoye</forename><forename type="middle">Sherry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aydin</forename><surname>Buluc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiejun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-09">Sep. 2019</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">One quadrillion triangles queried on one million processors</title>
		<author>
			<persName><forename type="first">Roger</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Steil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">W</forename><surname>Priest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Sanders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Escape: Efficiently counting all 5-vertex subgraphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ali Pinar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaidyanathan</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName><surname>Vishal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web, WWW &apos;17</title>
		<meeting>the 26th International Conference on World Wide Web, WWW &apos;17<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1431" to="1440" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Modeling interactome: scale-free or geometric?</title>
		<author>
			<persName><forename type="first">Natasa</forename><surname>Pr?ulj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">G</forename><surname>Corneil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Jurisica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3508" to="3515" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Graph kernels for chemical informatics</title>
		<author>
			<persName><forename type="first">Liva</forename><surname>Ralaivola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroto</forename><surname>Swamidass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Saigo</surname></persName>
		</author>
		<author>
			<persName><surname>Baldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1093" to="1110" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Pgx. iso: parallel and efficient in-memory engine for subgraph isomorphism</title>
		<author>
			<persName><forename type="first">Raghavan</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oskar</forename><surname>Van Rest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungpack</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on GRAph Data management Experiences and Systems</title>
		<meeting>Workshop on GRAph Data management Experiences and Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Fast and robust distributed subgraph enumeration</title>
		<author>
			<persName><forename type="first">Xuguang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wook-Shin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1344" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Divergence-aware warp scheduling</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">G</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike O'</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tor</forename><forename type="middle">M</forename><surname>Aamodt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="99" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Role discovery in networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nesreen K</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1112" to="1131" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Leveraging multiple gpus and cpus for graphlet counting in large networks</title>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1783" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Graph clustering</title>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Satu</surname></persName>
		</author>
		<author>
			<persName><surname>Schaeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer science review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="64" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Parallel subgraph listing in a large-scale graph</title>
		<author>
			<persName><forename type="first">Yingxia</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;14</title>
		<meeting>the 2014 ACM SIGMOD International Conference on Management of Data, SIG-MOD &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="625" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laxman</forename><surname>Dhulipala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Shun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10047</idno>
		<title level="m">Parallel clique counting and peeling algorithms</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Graphpi: High performance graph pattern matching through effective redundancy elimination</title>
		<author>
			<persName><forename type="first">Tianhui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingshu</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jidong</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;20</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;20</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Multicore triangle computations without tuning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tangwongsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 31st International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2015-04">April 2015</date>
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Accelerating all 5-vertex subgraphs counting using gpus</title>
		<author>
			<persName><forename type="first">Shuya</forename><surname>Suganami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiyuki</forename><surname>Amagasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroyuki</forename><surname>Kitagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database and Expert Systems Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="55" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Efficient parallel subgraph enumeration on a single machine</title>
		<author>
			<persName><forename type="first">Shixuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulin</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lipeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiong</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 35th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="232" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Scaling up subgraph query processing with efficient subgraph matching</title>
		<author>
			<persName><forename type="first">Shixuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiong</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 35th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="220" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Counting triangles and the curse of the last reducer</title>
		<author>
			<persName><forename type="first">Siddharth</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on World Wide Web, WWW &apos;11</title>
		<meeting>the 20th International Conference on World Wide Web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="607" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A distributed approach for graph mining in massive networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1024" to="1052" />
			<date type="published" when="2016-09">September 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Parallel graph mining with dynamic load balancing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Talukder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<date type="published" when="2016-12">Dec 2016</date>
			<biblScope unit="page" from="3352" to="3359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Arabesque: A system for distributed graph mining</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><forename type="middle">J</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgos</forename><surname>Serafini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Siganos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashraf</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><surname>Aboulnaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Operating Systems Principles, SOSP &apos;15</title>
		<meeting>the 25th Symposium on Operating Systems Principles, SOSP &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="425" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Experimental evaluation of a gpu-based frequent subgraph miner using synthetic databases</title>
		<author>
			<persName><forename type="first">Tatsuya</forename><surname>Toki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomonobu</forename><surname>Ozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 Fourth International Symposium on Computing and Networking (CANDAR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="504" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Fast subgraph matching on large graphs using graphics processors</title>
		<author>
			<persName><forename type="first">Ha-Nguyen</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Jae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingsheng</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Database Systems for Advanced Applications</title>
		<editor>
			<persName><forename type="first">Matthias</forename><surname>Renz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiaofang</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Muhammad</forename><surname>Aamir</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cheema</forename></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="299" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">aDFS: An almost Depth-First-Search distributed Graph-Querying system</title>
		<author>
			<persName><forename type="first">Vasileios</forename><surname>Trigonakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Pierre</forename><surname>Lozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom??</forename><surname>Falt?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">P</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iraklis</forename><surname>Psaroudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Delamare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Haprian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Calin</forename><surname>Iorgulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Koupy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinsoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungpack</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Chafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 USENIX Annual Technical Conference (USENIX ATC 21)</title>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2021-07">July 2021</date>
			<biblScope unit="page" from="209" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">An algorithm for subgraph isomorphism</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Ullmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="42" />
			<date type="published" when="1976-01">January 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Graph-based substructure pattern mining using cuda dynamic parallelism</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Data Engineering and Automated Learning -IDEAL 2013</title>
		<editor>
			<persName><forename type="first">Hujun</forename><surname>Yin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ke</forename><surname>Tang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Frank</forename><surname>Klawonn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Minho</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Weise</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xin</forename><surname>Yao</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="342" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Rstream: Marrying relational algebra with streaming for efficient graph mining on a single machine</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiqiang</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tien</forename><surname>Quang Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><forename type="middle">Harry</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18</title>
		<meeting>the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI&apos;18<address><addrLine>Berkeley, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="763" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01527</idno>
		<title level="m">Fast gunrock subgraph matching (gsm) on gpus</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A comparative study on exact triangle counting algorithms on the gpu</title>
		<author>
			<persName><forename type="first">Leyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangzihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Workshop on High Performance Graph Processing</title>
		<meeting>the ACM Workshop on High Performance Graph Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Are dynamic memory managers on gpus slow? a survey and benchmarks</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Parger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mlakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP &apos;21</title>
		<meeting>the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="219" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Fast linear algebra-based triangle counting with kokkoskernels</title>
		<author>
			<persName><forename type="first">Mehmet</forename><surname>Michael M Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">W</forename><surname>Deveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">D</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivasankaran</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><surname>Rajamanickam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">A batched gpu algorithm for set intersection</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyong</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="752" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Efficient lists intersection by cpu-gpu cooperative computing</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyong</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Symposium on Parallel &amp; Distributed Processing, Workshops and Phd Forum (IPDPSW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">gspan: graph-based substructure pattern mining</title>
		<author>
			<persName><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE International Conference on Data Mining</title>
		<meeting>the 2002 IEEE International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec 2002</date>
			<biblScope unit="page" from="721" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Defining and evaluating network communities based on ground-truth</title>
		<author>
			<persName><forename type="first">Jaewon</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title/>
		<author>
			<persName><surname>Corr</surname></persName>
		</author>
		<idno>abs/1205.6233</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Fast triangle counting using cilk</title>
		<author>
			<persName><forename type="first">Abdurrahman</forename><surname>Ya?ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivasankaran</forename><surname>Rajamanickam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">?mit</forename><forename type="middle">V</forename><surname>?ataly?rek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE High Performance extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Gsi: Gpu-friendly subgraph isomorphism</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tamer ?zsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 36th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1249" to="1260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Fesia: A fast and simd-efficient set intersection approach on modern cpus</title>
		<author>
			<persName><forename type="first">Jiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><forename type="middle">G</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Franchetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 36th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1465" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Probabilistic graphlet cut: Exploiting spatial structure cue for weakly supervised image segmentation</title>
		<author>
			<persName><forename type="first">Luming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1908" to="1915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Kaleido: An Efficient Out-of-core Graph Mining System on A Single Machine</title>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhibin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 IEEE International Conference on Data Engineering (ICDE 2020), ICDE &apos;20</title>
		<meeting>the 2020 IEEE International Conference on Data Engineering (ICDE 2020), ICDE &apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
