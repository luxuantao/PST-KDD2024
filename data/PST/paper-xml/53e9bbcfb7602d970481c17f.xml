<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vision-based human motion analysis: An overview</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-01-25">25 January 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ronald</forename><surname>Poppe</surname></persName>
							<email>poppe@ewi.utwente.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering, Mathematics and Computer Science</orgName>
								<orgName type="laboratory">Human Media Interaction Group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mathias</forename><surname>Kolsch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering, Mathematics and Computer Science</orgName>
								<orgName type="laboratory">Human Media Interaction Group</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<postBox>P.O. Box 217</postBox>
									<postCode>7500 AE</postCode>
									<settlement>Enschede</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vision-based human motion analysis: An overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-01-25">25 January 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">AC0699B1E6C9538079B4EF12BDCEC947</idno>
					<idno type="DOI">10.1016/j.cviu.2006.10.016</idno>
					<note type="submission">Received 20 September 2005; accepted 13 October 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human motion analysis</term>
					<term>Pose estimation</term>
					<term>Computer vision</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Markerless vision-based human motion analysis has the potential to provide an inexpensive, non-obtrusive solution for the estimation of body poses. The significant research effort in this domain has been motivated by the fact that many application areas, including surveillance, Human-Computer Interaction and automatic annotation, will benefit from a robust solution. In this paper, we discuss the characteristics of human motion analysis. We divide the analysis into a modeling and an estimation phase. Modeling is the construction of the likelihood function, estimation is concerned with finding the most likely pose given the likelihood surface. We discuss model-free approaches separately. This taxonomy allows us to highlight trends in the domain and to point out limitations of the current state of the art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human body pose estimation, or pose estimation in short, is the process in which the configuration of body parts is estimated from sensor input. When poses are estimated over time, the term human motion analysis is used. Traditionally, motion capture systems require that (electromagnetic) markers are attached to the body. These systems have two major drawbacks: they are obtrusive and expensive. Many applications, especially in surveillance and Human-Computer Interaction (HCI), would benefit from a solution that is markerless. Vision-based motion capture systems attempt to provide such a solution, using cameras as sensors. Over the last two decades, this topic has received much interest, and it continues to be an active research domain. In this overview, we summarize the characteristics of and challenges presented by markerless vision-based human motion analysis. The literature is discussed, with a focus on recent work. However, we do not intend to give complete coverage to all work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Scope of this overview</head><p>Human motion analysis is a broad concept. In theory, as many details as the human body can exhibit could be estimated. This includes facial movement, movement of the fingers and changes in skin surface as a result of muscle tightening. In this overview, pose estimation is limited to large body parts (trunk, head, limbs). Note that, in human motion analysis, we are only interested in the configurations of the body parts over time and not interpretations of the movement. This means that pose recognition, which is classifying the pose to one of a limited number of classes, and gesture recognition, which is interpreting the movement over time, are not discussed in this overview. For some applications, the positioning of individual body parts is not important. The entire body is tracked as a single object, which is termed human tracking or detection. This is often a preprocessing step for human motion analysis, and we will not discuss the topic in detail in this overview. Surveys of literature on related fields can be found in <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b24">25]</ref> (gesture recognition), and <ref type="bibr" target="#b124">[125]</ref> (face recognition).</p><p>In the remainder of this section, we summarize past surveys and taxonomies, and describe the taxonomy that is used throughout this overview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Surveys and taxonomies</head><p>Within the domain of human motion analysis, several surveys have been written, each with a specific focus and taxonomy. Gavrila <ref type="bibr" target="#b26">[27]</ref> divides research into 2D and 3D approaches. 2D approaches are further subdivided into approaches with or without the explicit use of shape models. Aggarwal and Cai <ref type="bibr" target="#b3">[4]</ref> use a taxonomy with three categories: body structure analysis, tracking and recognition. Body structure analysis is essentially pose estimation and is split up into model-based and model-free, depending upon whether a priori information about the object shape is employed. A taxonomy for tracking is divided into single and multiple perspectives. Moeslund and Granum <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64]</ref> use a taxonomy based on subsequent phases in the pose estimation process: initialization, tracking, pose estimation and recognition. Wang et al. <ref type="bibr" target="#b120">[121]</ref> use a taxonomy similar to <ref type="bibr" target="#b3">[4]</ref>: human detection, human tracking and human behavior understanding. Tracking is subdivided into model-based, region-based, active contour-based and feature-based. Wang and Singh <ref type="bibr" target="#b119">[120]</ref> identify two phases in the process of computational analysis of human movement: tracking and motion analysis. Tracking is discussed for hands, head and full bodies.</p><p>Currently, we see some new directions of research such as combining top-down and bottom-up models, particle filtering algorithms for tracking, and model-free approaches. We feel that many of these trends cannot be discussed appropriately within the taxonomies mentioned above. We observe that studies can be divided into two main classes: model-based (or generative) and model-free (or discriminative) approaches. Model-based approaches employ an a priori human body. The pose estimation process consists of modeling and estimation <ref type="bibr" target="#b99">[100]</ref>. Modeling is the construction of the likelihood function, taking into account the camera model, the image descriptors, human body model and matching function, and (physical) constraints. We discuss the modeling process in detail in Section 2. Estimation is concerned with finding the most likely pose given the likelihood surface. The estimation process is discussed in Section 3. Model-free approaches do not assume an a priori human body model but implicitly model variations in pose configuration, body shape, camera viewpoint and appearance. Due to their different nature in both modeling and estimation, we discuss them separately in Section 4. We conclude with a discussion of open challenges and promising directions of research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Modeling</head><p>The goal of the modeling phase is to construct the function that gives the likelihood of the image, given a set of parameters. These parameters include body configuration parameters, body shape and appearance parameters and camera viewpoint. Some of these parameters are assumed to be known in advance, for example a fixed camera viewpoint, or known body part lengths. Estimating a smaller number of parameters makes the problem more tractable but also poses limitations on the visual input that can be appropriately analyzed. Note that the relation between pose and observation is multivalued, in both directions. Due to the variations between people in shape and appearance, and a different camera viewpoint and environment, the same pose can have many different observations. Also, different poses can result in the same observation. Since the observation is a projection (or combination of projections when multiple cameras are deployed) of the real world, information is lost. When only a single camera is used, depth ambiguities can occur. Also, because the visual resolution of the observations is limited, small changes in pose can go unnoticed.</p><p>Model-based approaches use a human body model, which includes the kinematic structure and the body dimensions. In addition, a function that describes how the human body appears in the image domain, given the model's parameters, is used. Human body models are described in Section 2.1.</p><p>Instead of using the original visual input, the image is often described in terms of edges, color regions or silhouettes. A matching function between visual input and the generated appearance of the human body model is needed to evaluate how well the model instantiation explains the visual input. Image descriptors and matching functions are described in Section 2.2. Other factors that influence the construction of the likelihood function are the camera parameters (Section 2.3) and environment settings (Section 2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Human body models</head><p>Human body models describe both the kinematic properties of the body (the skeleton), as the shape and appearance (the flesh and skin). We discuss both below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Kinematic models</head><p>Most of the models describe the human body as a kinematic tree, consisting of segments that are linked by joints. Every joint contains a number of degrees of freedom (DOF), indicating in how many directions the joint can move. All DOF in the body model together form the pose representation. These models can be described in either 2D or 3D.</p><p>2D models are suitable for motion parallel to the image plane and are sometimes used for gait analysis. Ju et al. <ref type="bibr" target="#b43">[44]</ref>, Haritaoglu et al. <ref type="bibr" target="#b32">[33]</ref> and Howe et al. <ref type="bibr" target="#b37">[38]</ref> use a socalled Cardboard model in which the limbs are modeled as planar patches. Each segment has seven parameters that allow it to rotate and scale according to the 3D motion. Navaratnam et al. <ref type="bibr" target="#b69">[70]</ref> take a similar approach but model some parameters implicitly. In <ref type="bibr" target="#b39">[40]</ref>, an extra patch width parameter was added to account for scaling during in-plane motion. In <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b0">1]</ref>, the human body is described by a 2D scaled prismatic model <ref type="bibr" target="#b67">[68]</ref>. These models have fewer parameters and enforce 2D constraints on figure motion that are consistent with an underlying 3D kinematic model. But despite their success in capturing fronto-parallel human movement, the inability to encode joint angle limits and self-intersection constraints renders 2D models unsuitable for tracking more complex movement.</p><p>3D models most often model segments as rigid, and allow a maximum of three (orthogonal) rotations per joint. For each of the rotations individually, kinematic constraints can be imposed. Instead of segments that are linked with zero-displacement, Kakadiaris and Metaxas <ref type="bibr" target="#b45">[46]</ref> model the connection by constraints on the limb ends. In a similar fashion, Sigal et al. <ref type="bibr" target="#b98">[99]</ref> model the relationships between body parts as conditional probability distributions. Bregler et al. <ref type="bibr" target="#b12">[13]</ref> introduce a twist motion model and exponential maps which simplify the relation between image motion and model motion. The kinematic DOF can be recovered robustly by solving simple linear systems under scaled orthogonal projection.</p><p>The number of DOF that are recovered varies between studies. In some studies, a mere 10 DOF are recovered in the upper body. Other studies estimate full-body poses with no less than 50 DOF <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. But even for a model with a limited number of DOF and a coarse resolution in (discrete) parameter space, the number of possible poses is very high. Applying kinematic constraints is an effective way of pruning the pose space by eliminating infeasible poses. Typical constraints are joint angle limits <ref type="bibr" target="#b117">[118,</ref><ref type="bibr" target="#b20">21]</ref> and limits on angular velocity and acceleration <ref type="bibr" target="#b123">[124]</ref>. The fact that human body parts are non-penetrable also introduces constraints <ref type="bibr" target="#b104">[105]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Shape models</head><p>Apart from the kinematic structure, the human shape is also modeled. Segments in 2D models are described as rectangular or trapezoid-shaped patches (see Fig. <ref type="figure" target="#fig_0">1(a)</ref>). In 3D models segments are either volumetric or surface-based. Volumetric shapes depend on only a few parameters. Commonly used volumetric models are spheres <ref type="bibr" target="#b73">[74]</ref>, cylinders <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b92">93]</ref> or tapered super-quadrics <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b46">47]</ref> (see Fig. <ref type="figure" target="#fig_0">1(b)</ref>). Instead of modeling each segment as a separate rigid shape <ref type="bibr" target="#b14">[15]</ref>, surface-based models often employ a single surface for the entire human body (see Fig. <ref type="figure" target="#fig_0">1(c)</ref>). These models typically consist of a mesh of polygons that is deformed by changes to the underlying kinematic structure <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b8">9]</ref>. Pla ¨nkers and Fua <ref type="bibr" target="#b78">[79]</ref> use a more complex body shape model, consisting of three layers: kinematic model, metaballs (soft objects) and a polygonal skin surface.</p><p>The parameters of the shape model, such as shape lengths and widths, are sometimes assumed fixed. However, due to the large variability among people, this will lead to inaccurate pose estimations. Alternatively, these parameters can be recovered in an initialization step, where the observed person is to adopt a specified pose <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>While this approach works well for many applications, it restricts use in surveillance or automatic annotation systems. Online adjustment of these parameters is possible by relying on statistical priors <ref type="bibr" target="#b29">[30]</ref> or specific key poses <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b7">8]</ref>. Cheung et al. <ref type="bibr" target="#b16">[17]</ref> and Mikic ´et al. <ref type="bibr" target="#b60">[61]</ref> use a number of cameras and recover segment shape and joint positions by looking at motion of individual points. Krahnsto ¨ver et al. <ref type="bibr" target="#b48">[49]</ref> report similar work for the upper body using a single camera but only seem to support movement parallel to the image plane.</p><p>The likeliness of the model instantiation given the image can be calculated when functions are available that describe how the model instantiation appears in the image domain and calculate the distance between given image and synthesized model. We describe model appearance in the image domain, and the matching functions, in Section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Image descriptors</head><p>The appearance of people in images varies due to different clothing and lighting conditions. Since we focus on the recovery of the kinematic configuration of a person, we would like to generalize over these kinds of variation. Part of this generalization can be handled in the image domain by extracting image descriptors rather than taking the original image. From a synthesis point of view, this means that we do not need complete knowledge about how a model instantiation appears in the image domain. Often used image descriptors include silhouettes, edges, 3D reconstructions, motion and color. We describe these next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Silhouettes and contours</head><p>Silhouettes and contours (silhouette outlines) can be extracted relatively robustly from images when backgrounds are reasonably static. In older studies, backgrounds were often assumed to be different in appearance from the person. This eliminates the need to estimate environment parameters. Silhouettes are insensitive to variations in surface such as color and texture, and encode a great deal of information to help recover 3D poses <ref type="bibr" target="#b2">[3]</ref>. However, performance is limited due to artifacts such as shadows and noisy background segmentation, and it is often difficult or impossible to recover certain DOF due to the lack of depth information (see Fig. <ref type="figure" target="#fig_1">2</ref>). A matching function is often based on area overlap. In model-free approaches, silhouettes are encoded using central moments <ref type="bibr" target="#b10">[11]</ref> or Hu moments <ref type="bibr" target="#b88">[89]</ref>. Contours can be encoded using a combination of turning angle metric and Chamfer distance <ref type="bibr" target="#b34">[35]</ref> or shape contexts <ref type="bibr" target="#b6">[7]</ref>, and can be compared based on deformation cost <ref type="bibr" target="#b65">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Edges</head><p>Edges appear in the image when there is a substantial difference in intensity at different sides of the image location. Edges can be extracted robustly and at low cost. They are, to some extent, invariant to lighting conditions, but are unsuitable when dealing with cluttered backgrounds or tex-tured clothing. Therefore, edges are usually located within an extracted silhouette <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b117">118,</ref><ref type="bibr" target="#b86">87]</ref> or within a projection of a human model <ref type="bibr" target="#b22">[23]</ref>. Matching functions take into account the normalized distance between model's synthesized edges and the closest edge found in the image. Rohr <ref type="bibr" target="#b86">[87]</ref> uses edge lines instead of edges to partially eliminate silhouette noise. A distance measure based on difference in line segment length, center position and angle is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">3D reconstructions</head><p>Edges and silhouettes lack depth information, at least when only a single camera is used. This also makes it hard to detect self-occlusions. When multiple cameras are used, a 3D reconstruction can be created from silhouettes that are extracted in each view individually. Two common techniques are volume intersection <ref type="bibr" target="#b8">[9]</ref> or a voxel-based approach <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>Another way of obtaining depth information is by using stereometry. Corresponding points are sought in views of calibrated camera pairs. Using triangulation, the depths of the points are calculated. This approach has been taken by Pla ¨nkers and Fua <ref type="bibr" target="#b78">[79]</ref> and Haritaoglu et al. <ref type="bibr" target="#b32">[33]</ref>. Stereo is also used by Jojic et al. <ref type="bibr" target="#b42">[43]</ref>, with the optional aid of projected light patterns. Matching functions are based volume overlap or mean closest point distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4.">Color and texture</head><p>Modeling the human body based on color or texture is inspired by the observation that the appearance of individual body parts remains substantially unchanged, although the body may exhibit very different poses. The appearance of individual body parts can be described using Gaussian color distributions <ref type="bibr" target="#b122">[123]</ref> or color histograms <ref type="bibr" target="#b80">[81]</ref>. Roberts et al. <ref type="bibr" target="#b84">[85]</ref> propose a 3D appearance model to overcome the problems with changing appearance due to clothing, illumination and rotations. They model body parts with truncated cylinders, with surface patches described by a multi-modal color distribution. The appearance model is constructed on-line from monocular image streams. Barro ´n and Kakadiaris <ref type="bibr" target="#b5">[6]</ref> minimize the sum of pixel-wise intensity differences between the image and synthesized model. Skin color can be a good cue for finding head and hands. In <ref type="bibr" target="#b52">[53]</ref>, additional clothing parameters are used to model sleeve, hem and sock lengths.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5.">Motion</head><p>Motion can be measured by taking the difference between two consecutive frames. The brightness of the pixels that are part of the person in the image are assumed to be constant. The pixel displacement in the image is termed optical flow and is used by Bregler et al. <ref type="bibr" target="#b12">[13]</ref> and Ju et al. <ref type="bibr" target="#b43">[44]</ref>. <ref type="bibr">Sminchisescu and Triggs [105]</ref> use optical flow to construct an outlier map that is used to weight the importance of edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.6.">Combination of descriptors</head><p>A likelihood function that takes into account a combination of descriptors proves to be more robust. Silhouette information can be combined with edges <ref type="bibr" target="#b20">[21]</ref>, optical flow <ref type="bibr" target="#b35">[36]</ref> or color <ref type="bibr" target="#b16">[17]</ref>. In <ref type="bibr" target="#b91">[92]</ref>, edges, ridges and motion are used. Filter responses for these image cues are learned from training data. Ramanan and Forsyth <ref type="bibr" target="#b80">[81]</ref> use edges and appearance cues. Care must be taken in constructing the likelihood function, especially when multiple image descriptors are used. Not unusually, a body part configuration that results in a low cost for one image descriptor, will also result in a low cost for a second one. When the likelihood function simply multiplies the cost function for each image descriptor, this may lead to sharp peaks in the likelihood surface. This results in less effective estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Camera considerations</head><p>Regarding the number of cameras that is used, monocular work <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b92">93]</ref> is appealing since for many applications only a single camera is available. When only a single view is used, self-occlusions and depth ambiguities can occur. Sminchisescu and Triggs <ref type="bibr" target="#b104">[105]</ref> estimate that roughly one third of all DOF are almost unobservable. These are mainly motions in depth but also rotations of near-cylindrical limbs about their axes. These limitations can be alleviated by using multiple cameras. In general, there are two main approaches. One is to search for features in each camera image separately and in a later stage combine the information to resolve ambiguities <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b82">83]</ref>. The second approach is to combine the information as early as possible into a 3D reconstruction, as we described before. When multiple cameras are used, calibration is an important requirement. Instead of combining the views, Kakadiaris and Metaxas <ref type="bibr" target="#b45">[46]</ref> use active viewpoint selection to determine which cameras are suitable for estimation.</p><p>Most studies assume a scaled orthographic projection which limits their use to distant observations, where perspective effects are small. Rogez et al. <ref type="bibr" target="#b85">[86]</ref> remove the perspective effect in a preprocessing step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Environment considerations</head><p>Most of the approaches described in this overview can handle only a single person at a time. Pose estimation of more than one person at the same time is difficult because of occlusions and possible interactions between the per-sons. However, Mittal et al. <ref type="bibr" target="#b61">[62]</ref> were able to extract silhouettes of all persons in the scene using the M 2 Tracker. A setup with five cameras provides the input for their method. The W 4 S system <ref type="bibr" target="#b32">[33]</ref> is able to track multiple persons and estimate their poses in outdoor scenes using stereo image pairs and appearance cues.</p><p>The results that are obtained are largely influenced by the complexity of the environment. Outdoor scenes are much more challenging due to the dynamic background and lighting conditions. In most work, the persons are visible without occlusion by other objects. It remains a challenge to recover poses of people under significant occlusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Estimation</head><p>The estimation process is concerned with finding the set of pose parameters that minimizes the error between observations on the one hand, and on the other the projection of the human body model (model-based), projection function (learning-based) or example set (example-based). We can identify two classes of estimation: top-down and bottom-up. Top-down approaches match a projection of the human body with the image observation. Instead, in bottom-up approaches individual body parts are found and then assembled into a human body. Recent work combines these two classes. We discuss both classes and their combination in Section 3.1.</p><p>The likelihood function often has many local maxima <ref type="bibr" target="#b105">[106]</ref>. In this section, we will assume that instead of a likelihood function, a cost function has been constructed. Therefore, we search for minima instead of maxima. Given the high dimensionality of the search space, this search must be efficient. The speed of the pose recovery depends largely on the speed of the estimation strategy. Some approaches report estimation times of several minutes per frame, other approaches can estimate human motion in real time <ref type="bibr" target="#b22">[23]</ref>.</p><p>Many methods are single-hypothesis approaches. Recent studies maintain multiple hypotheses. This reduces the probability of getting stuck at a local minimum. We discuss single and multiple hypothesis tracking, and batch methods, in Section 3.2.</p><p>Estimation of poses over time can be made more stable by assuming a motion model. Usually, these models are specific for a given activity. In Section 3.4, both explicit and implicit motion models are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Top-down and bottom-up estimation</head><p>There are two main approaches for model-based estimation: top-down and bottom-up. Recent work combines these approaches to benefit from the advantages of both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Top-down estimation</head><p>Top-down approaches match a projection of the human body with the image observation. This is termed an analy-sis-by-synthesis approach. A local search is often performed around an initial pose estimate <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b5">6]</ref>. A bruteforce local search is computationally expensive due to the high dimensionality of the pose space. Therefore, the a posteriori pose estimate is often found by applying gradient descent on the cost surface <ref type="bibr" target="#b117">[118]</ref>. The search can also be performed in the image domain. Delamarre and Faugeras <ref type="bibr" target="#b18">[19]</ref> use forces between extracted silhouettes and the projected model to refine the pose estimation. Alternatively, sampling-based approaches are taken. We discuss these in the next section.</p><p>One drawback of top-down estimation is the fact that (manual) initialization in the first frame of a sequence is needed since the initial estimate is often obtained from the estimate in the previous frame. Another drawback is the computational cost of forward rendering the human body model and calculating the distance between the rendered model and the image observation.</p><p>Gavrila and Davis <ref type="bibr" target="#b27">[28]</ref> take a top-down approach with search-space decomposition. Poses are estimated in a hierarchical coarse-to-fine strategy, estimating the torso and head first and then working down the limbs. The initial pose prediction is based on constant joint angle acceleration. An analysis-by-synthesis approach is applied in a discrete fashion, resulting in a limited number of possible solutions per joint.</p><p>Top-down estimation often causes problems with (self)occlusions. Moreover, errors are propagated through the kinematic chain. An inaccurate estimation for the torso/head part causes errors in estimating the orientation of body parts lower in the kinematic chain. To overcome this problem, Drummond and Cipolla <ref type="bibr" target="#b22">[23]</ref> introduce constraints between linked body parts in the kinematic chain. This allows lower parts to effect parts higher in the chain. A pose is described by the rigid displacement for each body part. This yields an over-parameterized system which is solved in a weighted least-squares framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Bottom-up estimation</head><p>Bottom-up approaches are characterized by finding body parts and then assembling these into a human body. The body parts are usually described by 2D templates. Often, these templates produce many false positives, as there are often many limb-like regions in an image. Another drawback is the need for part detectors for most body parts, since missing information is likely to result in a less accurate pose estimate.</p><p>The assembling process takes into account physical constraints such as body part proximity. Temporal constraints can be used to cope with occlusions. Bottom-up approaches have the advantage that no manual initialization is needed and can be used as an initialization for top-down approaches.</p><p>Mori et al. <ref type="bibr" target="#b66">[67]</ref> first perform image segmentation based on contour, shape and appearance cues. The segments are classified by body part locators for half-limbs and torso that are trained on image cues. From this partial configura-tion, the missing body parts are found. Global constraints, including body part proximity, relative widths and lengths and symmetry in color are enforced to prune the search space. A very similar approach has been taken by Ren et al. <ref type="bibr" target="#b83">[84]</ref>, who search for pairwise edges as segment boundaries. Ramanan <ref type="bibr" target="#b79">[80]</ref> improves the deformable model iteratively, but does not perform explicit segmentation. In the first iteration, only edges are used to locate possible body parts. A rough region-based model for each body part and the background is then build from these locations. New locations are found using this model and the process is repeated.</p><p>In <ref type="bibr" target="#b25">[26]</ref> body parts are modeled using 2D appearance models. They use the concept of pictorial structures to model the coherence between body parts. An efficient dynamic programming algorithm is used to find an optimal solution in the tree of body configurations. Trees are extended with correlations between body parts in <ref type="bibr" target="#b49">[50]</ref>. For walking, correlations between upper arm and leg swings are used, resulting in more robust pose estimations. Ronfard et al. <ref type="bibr" target="#b87">[88]</ref> use the pictorial structures concept but replace the body part detectors by more complex ones that learn appearance models using Support Vector Machines. Ramanan and Forsyth <ref type="bibr" target="#b80">[81]</ref> use simple appearance-based part detectors, aided by parallel lines. Motion tracking is reduced to the problem of inference in a dynamic Bayes net. Evaluation on outdoor sequences shows automatic initialization and recovery but tracking occasionally fails, especially for in-plane motion. Ioffe and Forsyth <ref type="bibr" target="#b40">[41]</ref> also take a 2D approach where the appearance of individual body parts is modeled. Inference is used on a mixture of trees, to avoid the time consuming evaluation of each group of candidate primitives. Song et al. <ref type="bibr" target="#b106">[107]</ref> use a similar technique involving feature points and inference on a tree model.</p><p>Sigal et al. <ref type="bibr" target="#b98">[99]</ref> describe the human body as a graphical model where each node represents a parameterized body part (see Fig. <ref type="figure" target="#fig_2">3(a)</ref>). The spatial constraints between body parts are modeled as arcs. Each node in the graph has an associated image likelihood function that models the probability of observing image measurements conditioned on the position and orientation of the part. Pose estimation is simply inference in the graphical model. In <ref type="bibr" target="#b94">[95,</ref><ref type="bibr" target="#b31">32]</ref>, temporal constraints are also taken into account, resulting in a tracking framework. If individual part locators are used, there is the risk that the estimated pose does not explain the image very well. Sigal and Black <ref type="bibr" target="#b96">[97]</ref> introduced occlusion-sensitive image likelihoods, which introduces loops in the graphical model. Recently, they focussed on obtaining 3D poses from these 2D pose descriptions <ref type="bibr" target="#b97">[98]</ref>.</p><p>Ramanan and Sminchisescu <ref type="bibr" target="#b81">[82]</ref> train models that maximize the likelihood for joint localization of all body parts, rather than learning individual part locators. Their training algorithm learns the parameters of a Conditional Random Field (CRF) from a small number of samples.</p><p>In the work by Micilotta et al. <ref type="bibr" target="#b59">[60]</ref>, the location of a person in the image is found first. Part detectors are learned and an assembly is found by applying RANSAC. Heuristics are used to filter unlikely poses, and a pose prior determines the likelihood of the assembly. An example-based approach (see also Section 4.2) is used to find the most likely pose based on extracted silhouette, edges, and hand locations. Although this approach is computationally very efficient, only frontal poses are regarded. It would be interesting to see how the work could be generalized to more unconstrained movements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Combined top-down and bottom-up estimation</head><p>By combining pure top-down and bottom-up approaches, the drawbacks of both can be targeted. Automatic initialization can be achieved within a sound tracking framework.</p><p>Navaratnam et al. <ref type="bibr" target="#b69">[70]</ref> use a search-space decomposition approach. Body parts lower in the kinematic chain are found using part detectors within an image region that is defined by the parent in the kinematic chain. This approach is computationally less expensive but performance depends heavily on the individual part detectors. Demirdjian <ref type="bibr" target="#b19">[20]</ref> uses optical flow in a top-down approach to select a candidate pose estimate. In addition, a view-based key frame that describes the appearance of the person is selected. The motion between the support points of the key frame and the image is used to refine the estimate. The final pose estimate is obtained by fusing both model-based and view-based estimates.</p><p>Hua et al. <ref type="bibr" target="#b38">[39]</ref> incorporate bottom-up information in a statistical framework. Comparable to Sigal et al. <ref type="bibr" target="#b98">[99]</ref>, the human body is modeled as a Markov network. 2D body poses are inferred using a data driven belief propagation Monte Carlo algorithm. Shape, edge and color cues are used to construct the importance sampling functions. Lee et al. <ref type="bibr" target="#b53">[54]</ref> use part detectors and inverse kinematics to estimate part of the pose space. Bottom-up information is only used when available, eliminating the need for a part detector for each limb. The approach targets the drawbacks of a pure top-down approach, while still providing a flexible tracking framework. However, the bottom-up information in used in a fixed analytical way. Not only does this approach require fixed segment lengths, it also prevents correct estimation of certain types of poses (e.g., poses where the elbow is higher than the hand). In <ref type="bibr" target="#b52">[53]</ref>, proposal maps are introduced to facilitate the mapping from 2D observations to 3D pose space.</p><p>Recent work has focussed on the recovery of human poses in cluttered scenes. <ref type="bibr" target="#b54">[55]</ref> adopt a three-stage approach, based on <ref type="bibr" target="#b52">[53]</ref>, to subsequently find human bodies, their 2D body part locations and a 3D pose estimate. Sminchisescu et al. <ref type="bibr" target="#b102">[103]</ref> learn top-down and bottom-up functions in alternate steps. The bottom-up process is tuned using samples from the top-down process, which is optimized to produce estimates that are close to those predicted by the bottom-up process. The processes are guaranteed to converge to equilibrium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Single and multiple hypothesis tracking</head><p>Estimating poses from frame to frame is usually termed tracking. Tracking is used to ensure temporal coherence between poses over time, and to provide an initial pose estimate. When it is assumed that the time between subsequent frames is small, the distance in body configuration is likely to be small as well. These configuration differences can be approximately linearly tracked, for example using a Kalman filter. Traditional tracking was aimed at maintaining a single hypothesis over time. Since this often causes the estimation to lose track, most recent work propagates multiple hypothesis in time. Often, a sampling-based approach is taken. In some works, temporal coherence is achieved by minimizing pose changes over a sequence of frames in a batch approach. Related to this is the estimation of 3D poses from 2D points. Although this topic is outside the scope of our overview, it is relevant and we choose to include it. This section discusses these methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Single hypothesis tracking</head><p>The high dimensionality of the pose space prohibits an exhaustive search of the cost surface. Single hypothesis approaches include Kalman filtering and local-optimization methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b117">118,</ref><ref type="bibr" target="#b44">45]</ref>. Gavrila and Davis <ref type="bibr" target="#b27">[28]</ref> use a discrete estimation to reduce computation time.</p><p>Single hypothesis tracking suffer from accumulation of errors. In case of ambiguity, such as self-occlusion, there is always the possibility of selecting the wrong pose. By maintaining only a single hypothesis, the pose estimation is likely to 'drift off' which makes recovery difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Multiple hypothesis tracking</head><p>To overcome the drifting problem of single hypothesis tracking approaches, multiple hypotheses can be maintained. Cham and Rehg <ref type="bibr" target="#b15">[16]</ref> use a set of Kalman filters to propagate multiple hypotheses. This results in more reliable motion tracking than with a single Kalman filter. Evaluation on challenging dancing sequences shows that the multiple hypotheses are able to track movement where a single mode fails. However, due to their limited appearance model, rotations about limb axes could not be estimated.</p><p>Human motion is non-linear due to joint accelerations. However, Kalman filters are only suitable for tracking linear motion. Sampling-based approaches (particle filtering or CONDENSATION <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42]</ref>) are able to track non-linear motion. In general, a number of particles is propagated in time using a model of dynamics, including a noise component. Each particle has an associated weight, that is updated according to the cost function. Configurations with a low cost are assigned a high weight. Since all weights sum up to one, the pose estimate is obtained by the weighted sum of all particles. (Or alternatively, the particle with the maximum weight is selected.)</p><p>Although, in theory, sampling-based methods are very suitable for tracking, the high dimensionality requires the use of many particles to sample the pose space sufficiently densely. Every particle comes with an increase in computational cost due to propagating the particles according to the dynamical model and the evaluation of the cost function. For each particle, the human body model must be rendered and compared to the extracted image descriptors. Another problem is the fact that particles tend to cluster themselves on a very small area. This is called sample impoverishment <ref type="bibr" target="#b47">[48]</ref>, and leads to a decreasing number of effective particles. Different particle sampling schemes have been proposed to overcome this problem. In <ref type="bibr" target="#b121">[122]</ref>, some common schemes are evaluated quantitatively on the human motion tracking task.</p><p>Currently, there are two main solutions to make the problem more tractable. The first one is to use priors on the movement that can be recognized. This includes learning motion models to guide the particles more effectively, and to learn a low-dimensional space which reduces the number of particles needed. We discuss these topics in Section 3.4. A second solution is to spread particles more efficiently in places where a suitable local minimum is more likely. We discuss this solution below.</p><p>Sminchisescu and Triggs <ref type="bibr" target="#b104">[105]</ref> introduce Covariance Scaled Sampling (CSS) to guide the particles. Instead of inflating the noise component in the model of dynamics, the posterior covariance of the previous frame is inflated. Intuitively, this focuses the particles in the regions where there is uncertainty, for example due to depth ambiguities as observed in monocular tracking. In the unconstrained case and given monocular data and known segment length, each joint has a twofold ambiguity. The connected limb is either placed forwards, or backwards. This also means that there are two local minima. When tracking fails, this is most likely due to choosing the wrong minimum. In <ref type="bibr" target="#b105">[106]</ref>, these ambiguities are enumerated in a tree, and the particles are allowed to 'jump' in the pose space accordingly. Deutscher and Reid <ref type="bibr" target="#b20">[21]</ref> introduce a different approach to guide the particles. They use simulated annealing to focus the particles on the global maxima of the posterior, at the price of multiple iterations per frame. Particles are distributed widely at initialization, and their range of movement is decreased gradually over time.</p><p>MacCormick and Isard <ref type="bibr" target="#b58">[59]</ref> partition the pose space into a number of lower-dimensional subspaces. Because independence between the spaces is assumed, this idea is similar to search-space decomposition. As we discussed in the previous section, Lee et al. <ref type="bibr" target="#b53">[54]</ref> avoid the need of an inhibitingly large number of particles by updating part of the state space using analytical inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Batch methods</head><p>Batch methods optimize poses over a sequence of frames, and are therefore unsuitable for online tracking. They avoid the need of propagating multiple hypotheses, since the most likely sequence of poses can be determined automatically. Pla ¨nkers and Fua <ref type="bibr" target="#b78">[79]</ref> and Liebowitz and Carlsson <ref type="bibr" target="#b56">[57]</ref> use least-squares minimization, Brand <ref type="bibr" target="#b10">[11]</ref> and Navaratnam et al. <ref type="bibr" target="#b69">[70]</ref> use the Viterbi algorithm to find the most probable state sequence in an Hidden Markov Model (HMM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">3D pose estimation from 2D points</head><p>When only 2D points over a sequence of images are known, 3D poses can be estimated if a human body model is taken into account. Liebowitz and Carlsson <ref type="bibr" target="#b56">[57]</ref> reconstruct 3D poses from 2D point correspondences from multiple views and known body segment lengths. Linear geometric reconstruction is used to recover the poses of an entire motion sequence at once. Taylor <ref type="bibr" target="#b110">[111]</ref> uses only a single view and recovers the entire set of pose solutions by considering the foreshortening of the segments of the model in the image. A scaled orthographic projection is assumed, which limits the approach to far views. Depth ordering must be specified manually. Lee and Chen <ref type="bibr" target="#b51">[52]</ref> recover the camera parameters from 6 points on the head. They use an interpretation tree to store all kinematic ambiguities that arise from forward to backward flipping and apply a number of constraints to prune impossible configurations. Additionally, DiFranco et al. <ref type="bibr" target="#b21">[22]</ref> use user-specified 3D key frames. A maximum a posteriori trajectory is calculated using a nonlinear least squares framework, taking into account joint angle limits and smooth dynamics. In <ref type="bibr" target="#b75">[76]</ref>, no camera model is assumed but fixed segment ratios are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Motion priors</head><p>Although the human body can perform a very broad variety of movements, the set of typically performed movements is usually much smaller. Especially when only a single class of movements (e.g., walking, swimming) is regarded, motion priors can aid in performing more stable tracking. However, this comes as a cost of putting a strong restriction on the poses that can be recovered.</p><p>Many prior models are derived from training data. A possible weakness of these motion models is that the ability to accurately represent the space of realizable human movements generally depends significantly on the amount of available training data. Therefore, the set of exemplars must be sufficiently large and account for the variations that can be observed while tracking the movement.</p><p>Generally, we can identify two main classes of motion priors. The first uses an explicit motion model to guide the tracking. The second class learns a low-dimensional activity manifold, in which tracking occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Using motion models</head><p>Most statistical motion models can only be used for specific movements, such as walking <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b86">87]</ref> dancing <ref type="bibr" target="#b82">[83]</ref> or tennis <ref type="bibr" target="#b107">[108]</ref>. However, more general models exist <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b93">94]</ref>.</p><p>Howe et al. <ref type="bibr" target="#b37">[38]</ref> use snippets of motion from a database to recover 3D motion given 2D points. From a sequence of 2D poses, the 3D motion is reconstructed by finding the MAP estimate of the sequence of snippets. Sidenbladh et al. <ref type="bibr" target="#b93">[94]</ref> take a similar approach. They retrieve motion samples similar to the motion being tracked. The dynamics of the sample are used to propagate the particles in a particle filter framework. Ning et al. <ref type="bibr" target="#b70">[71]</ref> use a similar approach, but constrain the propagation of the particles using physical motion constraints.</p><p>Instead of using samples, Pavlovic et al. <ref type="bibr" target="#b76">[77]</ref> learn a dynamical model over the pose space. Agarwal and Triggs <ref type="bibr" target="#b0">[1]</ref> cluster their training data into body poses with similar dynamics. Principal Component Analysis (PCA) is applied to reduce the dimensionality for each cluster, followed by learning a local linear autoregression. A class inference algorithm is able to estimate the current motion cluster and allows for smooth transitions between classes.</p><p>The work of <ref type="bibr" target="#b13">[14]</ref> does not only model the short-term dynamics but also takes into account the history using Variable Length Markov Models (VLMM). Clusters of elementary motion are learned from training data and clustered. State transitions in the VLMM correspond to one of the clusters. Particles are propagated according to the dynamics of the selected cluster. The noise vector, added in the propagation, is sampled from the covariance of the cluster. This is similar in spirit to CSS <ref type="bibr" target="#b104">[105]</ref>, where the noise is sampled from the covariance of the previous posterior distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Dimensionality reduction</head><p>Reducing the dimensionality of the pose space is motivated by the observation that human activities are often located on a latent space that is low-dimensional <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref>. As mentioned before, tracking in this low-dimensional manifold results in lower numbers of required particles. Currently, manifolds are learned for specific activities, such as walking, and it remains to be researched how this can be extended to broader classes of movement.</p><p>Tracking in a low-dimensional manifold requires three components. First, a mapping between original pose space to low-dimensional manifold must be learned. Second, an inverse mapping must be defined. Third, it must be defined how tracking within the low-dimensional space occurs.</p><p>Since the mapping between the original pose space and latent space is in general non-linear, linear PCA is inadequate. Algorithms such as Locally Linear Embedding and Isomap can learn this non-linear mapping but are not invertible. This inverse mapping is needed because the full body configuration is required for evaluation of the likelihood function. Gaussian Process Latent Variable Models (GPLVM, <ref type="bibr" target="#b50">[51]</ref>) and Locally Linear Coordination (LLC, <ref type="bibr" target="#b111">[112]</ref>) do provide the inverse mapping.</p><p>Sminchisescu and Jepson <ref type="bibr" target="#b100">[101]</ref> use spectral embedding to learn the embedding, which is modeled as a Gaussian mixture model. Radial Basis Functions (RBF) are learned for the inverse mapping. A linear dynamical model is used for tracking. Urtasun et al. <ref type="bibr" target="#b115">[116]</ref> use a GPLVM to learn prior models for 3D human tracking. GPLVMs generate smooth mappings between pose space and latent space, which is useful for the use of gradient descent to optimize pose estimates. A second-order Gauss-Markov model is used as a motion model. In later work <ref type="bibr" target="#b118">[119,</ref><ref type="bibr" target="#b114">115]</ref>, a Gaussian Process Dynamical Model (GPDM) is learned from training data. The GPDM also learns a dynamical model in the latent space. Recent work by Moon and Pavlovic <ref type="bibr" target="#b64">[65]</ref> has investigated the effect of dynamics in the embedding on human motion tracking.</p><p>Tian et al. <ref type="bibr" target="#b112">[113]</ref> use a GPLVM for 2D pose estimation. Particle filtering is used, where the samples are drawn from the latent space. Alternatively, Li et al. <ref type="bibr" target="#b55">[56]</ref> use LLC for learning the mappings. Smoothing in the latent space is not enforced but the mapping is such that close points in latent space correspond to close poses in the pose space. Therefore, a simple dynamical model can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model-free approaches</head><p>If no explicit human body model is available, a direct relation between image observation and pose must be established. Two main classes of pose estimation approach can be identified: learning-based (Section 4.1) and examplebased (Section 4.2). In learning-based approaches, a function from image space to pose space is learned using training data. Example-based approaches avoid learning this mapping. Instead, a collection of exemplars is stored in a database, together with their corresponding pose descriptions. For a given input image, a similarity search is performed and candidate poses are interpolated to obtain the pose estimate. Note that although the inverse mapping from image space to pose estimate is multi-valued and cannot be functionally approximated <ref type="bibr" target="#b101">[102]</ref>, most work treats the relation as single-valued.</p><p>Since variations in body configuration, body dimensions, viewpoint and appearance are implicitly modeled in the training data, this data needs to generalize well over the invariant parameters and distinguish well between the variant ones. The training data must account for the high non-linearity of the mapping between image and pose space, which means in practice that the pose space must be densely sampled in the training set. However, the training data can be constructed when keeping in mind that not all kinematically possible poses are also likely.</p><p>Model-free algorithms do not suffer from (re)initialization problems and can in this respect be used for initialization of model-based pose estimation approaches as we discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Learning-based</head><p>Grauman et al. <ref type="bibr" target="#b29">[30]</ref> describe a distribution over both multi-view silhouettes and 3D joint locations with a mixture of probabilistic PCA. Pose inference is based on the maximum a posteriori (MAP) estimate. Silhouettes from a single view are used by Agarwal and Triggs <ref type="bibr" target="#b2">[3]</ref>. They use non-linear regression to model the relation between histograms of shape contexts and 3D poses. Damped leastsquares and Relevance Vector Machine regression over both linear and kernel bases have been evaluated. Ambiguities are resolved using dynamics.</p><p>In recent work, Agarwal and Triggs <ref type="bibr" target="#b1">[2]</ref> use histograms of gradient orientations over a grid of small cells. Non-negative matrix factorization is used to obtain a set of basis vectors that correspond to local features on the human body such as shoulders and bent elbows. When using these vectors to reconstruct an image with clutter, the edges that correspond to the person are obtained. This enables them to recover poses without having to extract the person's outline. Regression is used to recover upper-body poses.</p><p>Brand <ref type="bibr" target="#b10">[11]</ref> models a manifold of pose and velocity configurations with an HMM. Temporal ambiguities are resolved by recovering poses over an entire sequence by applying the Viterbi algorithm. Elgammal and Lee <ref type="bibr" target="#b23">[24]</ref> recover 3D poses from monocular silhouettes using an intermediary activity manifold (see Fig. <ref type="figure" target="#fig_2">3(b)</ref>). Manifolds are learned from visual input and subsequently, mappings are learned from manifolds to visual input and 3D poses. Good generalization for variations in body shape are reported. However, the manifolds are learned for specific activities and viewpoints, and it is unclear how the work would generalize to a more unconstrained motion domain. In <ref type="bibr" target="#b108">[109]</ref>, a pose manifold is learned in addition to the image manifold. LLE is used to learn a mapping between the two manifolds.</p><p>Rosales and Sclaroff <ref type="bibr" target="#b88">[89]</ref> observe that the inverse of the mapping from image space to pose space cannot be modeled by a single function. Therefore, they cluster the 2D pose space and learn specialized functions for each cluster from image descriptors to pose space. A neural network is used as mapping function. In <ref type="bibr" target="#b89">[90]</ref>, the work is extended to allow input from multiple cameras. The pose is estimated for each camera individually and in a subsequent step, the hypotheses are combined into a set of self-consistent 3D pose hypotheses. Sminchisescu et al. <ref type="bibr" target="#b101">[102]</ref> model the multi-valued nature of the mapping from observation to pose state with a mixture of expert models. Each expert learns the conditional state distributions from a database consisting of samples of pose representation and a rendered human body model. Shape contexts in addition to local appearance are used as image descriptors. The samples involve a number of human activities such as walking, running and pantomime. Demonstration on monocular complex motions shows convincing results, and tests on artificial data show that the proposed approach outperforms nearest-neighbor and regression methods. Training these mappings requires large amounts of labelled example pairs consisting of both image descriptors and poses. In <ref type="bibr" target="#b68">[69]</ref>, also data from each of the types separately are used to improve manifold learning.</p><p>Recent work by Taycher et al. <ref type="bibr" target="#b109">[110]</ref> transforms the continuous state estimation problem into a discrete one by using dividing the state space into regions that approximate the posterior. The observation potential function of the CRF is learned off-line from a large number of examples. By focusing only on the regions where the prior state probability is significant, poses can be recovered in real time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Example-based</head><p>Example-based approaches use a database of exemplars that describe poses in both image space and pose space. One drawback of these approaches is the large amount of space needed to store the database.</p><p>Mori and Malik <ref type="bibr" target="#b65">[66]</ref> extract external and internal contours of an object. Shape contexts are employed to encode the edges. In an estimation step, the stored exemplars are deformed to match the image observation. In this deformation, the location of the hand-labelled 2D locations of joints also changes. The most likely 2D joint estimate is found by enforcing 2D image distance consistency between body parts. Shape deformation is also used by Sullivan and Carlsson <ref type="bibr" target="#b107">[108]</ref>. To improve the robustness of the point transferral, the spatial relationship of the body points and color information is exploited. Loy et al. <ref type="bibr" target="#b57">[58]</ref> perform interpolation between key frame poses based on <ref type="bibr" target="#b110">[111]</ref> and additional smoothing constraints. Manual intervention is necessary in certain cases.</p><p>Bowden et al. <ref type="bibr" target="#b9">[10]</ref> fit a non-linear point distribution model (PDM) to their image observations. The PDM consists of the 2D position of head and hands in the image, the 2D body contour, and the 3D structure of the body. The PDM is trained on high-dimensional feature vectors that contain likely body movements. The feature space is projected on a lower dimensional space. In <ref type="bibr" target="#b74">[75]</ref>, the poses in the database are rendered from multiple views, which makes the approach somewhat invariant to the viewpoint. For a monocular image, the view is estimated using a linear discriminant and subsequently the pose is recovered using a nearest neighbor classifier. Ong and Gong <ref type="bibr" target="#b71">[72]</ref> include views from multiple cameras in the PDM and recover a pose from multi-view images.</p><p>Toyama and Blake <ref type="bibr" target="#b113">[114]</ref> also show how to incorporate exemplars in a probabilistic temporal framework. Silhouettes, described using turning angle and Chamfer distance are considered by Howe <ref type="bibr" target="#b34">[35]</ref>. To achieve temporal coherence, he uses Markov Chaining with subsequent smoothing over a sequence of frames. In later work <ref type="bibr" target="#b35">[36]</ref>, optical flow information is used in addition. Motion is used in the estimation process by Ong et al. <ref type="bibr" target="#b72">[73]</ref>. Their exemplar space is clustered and flow vectors between clusters are learned from sequences of training data. A particle filter framework is used where the particles are guided by the flow vectors. This reduces the number of particles needed but puts a strong prior on the motions that can be estimated.</p><p>The computational complexity of a naive Nearest Neighbor search is linear in the number of exemplars. For recovering more unconstrained movements or high number of DOF, the number of exemplars grows substantially. Therefore, Shakhnarovich et al. <ref type="bibr" target="#b90">[91]</ref> introduce Parameter Sensitive Hashing (PSH) to rapidly estimate the pose given a new image. Because of the ambiguity in the use of silhouettes alone, they use edge direction histograms within a contour. PSH is also applied in <ref type="bibr" target="#b82">[83]</ref>, where a bit string of binary local features <ref type="bibr" target="#b116">[117]</ref> extracted from silhouettes obtained using three views are used instead. In addition to PSH, they use a motion graph to find those poses that are not only close in image space, but are also close in pose space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>Human motion analysis is a challenging problem due to large variations in human motion and appearance, camera viewpoint and environment settings. On the other hand, we know much about people's physical appearance and movements. The key point for successful human motion analysis is to use this knowledge effectively. Over the last two decades, a large amount of research has been conducted. Human body models that were initially described in 2D have now evolved into highly articulated 3D models. Deterministic linear tracking has been replaced by sampling-based tracking frameworks that evaluate the cost function effectively. The role of machine learning plays an increasingly important role in human motion analysis, and will continue to do so.</p><p>For each of the methodologies described in this survey, prior knowledge about human movement or appearance is incorporated more and more effectively. For example, joint angle limitations are directly encoded during tracking, instead of as a pose space pruning technique. But although many of these advances have led to impressive results given the complexity of the task, the domain was always limited. Not unusually, it is assumed that a person has been found in the image in a preprocessing step. Furthermore, assumptions about the viewpoint, appearance and motion are often made.</p><p>We expect that combining methodologies is the solution to use prior knowledge even more effectively. Indeed, recent work explores these kind of combinations. While much research is needed, these works are certainly promising. For example, model-based and model-free approaches have been combined <ref type="bibr" target="#b59">[60]</ref> to allow for automatic initialization and recovery. Another promising direction of research is the recent combination of bottom-up and top-down approaches, as described in Section 3.1. This has led to effective tracking frameworks. Also, 2D and 3D models have been combined to facilitate detection and subsequent pose estimation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref>. Also, they have the potential to deal more effectively with occlusions, a problem that is often ignored. Work by Howe <ref type="bibr" target="#b36">[37]</ref> also addresses this issue.</p><p>Also, the role of context should be used more explicitly. Human motion analysis provides input for reasoning about actions and intentions. Reversely, context can be used for human motion analysis, other than implicitly by assuming a fixed domain. Recent work aims at learning models that are conditioned on the context <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b103">104]</ref>.</p><p>The role of human motion models, and how they generalize to broader domains remains to be investigated. Also, the suitability of low-dimensional latent spaces for recovery of more spontaneous movement needs to be assessed.</p><p>From a practical perspective, evaluation of motion analysis algorithms requires a common database, representative for a broad range of domains (indoor, static scenes, and dynamic, cluttered scenes with multiple persons). This database should consist of ground truth data and image sequences. In addition, common criteria (accuracy, smoothness, speed) for evaluation are needed. The recently introduced HumanEva-I database <ref type="bibr" target="#b95">[96]</ref> is a good first step in this direction. When the evaluation criteria are generally accepted, this will contribute significantly in determining promising directions of research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Human shape models with kinematic model. (a) 2D model (reprinted from [40], Ó IEEE 2002); (b) 3D volumetric model consisting of superquadrics (reprinted from [47], Ó Elsevier, 2006); (c) 3D surface model (reprinted from [15], Ó ACM, Inc., 2003).</figDesc><graphic coords="4,124.72,70.12,354.24,240.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Depth ambiguities when using monocular silhouettes [35] (Ó IEEE, 2004).</figDesc><graphic coords="4,47.60,362.83,240.99,184.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Relation between body parts described in a graphical model [99] (Ó MIT Press, 2003); (b) View-based manifold for walking activity [24] (Ó IEEE, 2004)).</figDesc><graphic coords="7,52.55,70.12,482.05,242.95" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>R. Poppe / Computer Vision and Image Understanding 108 (2007) 4-18</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>R. Poppe / Computer Vision and Image Understanding 108 (2007) 4-18</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the European IST Programme Project FP6-033812 (Augmented Multi-party Interaction with Distant Access, publication AMIDA-3), and is part of the ICIS program. ICIS is sponsored by the Dutch government under contract BSIK03024. The author wishes to thank Dariu Gavrila and the anonymous CVIU reviewers for their valuable comments, and all authors that contributed figures to this overview.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tracking articulated motion using a mixture of autoregressive models</title>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;04)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;04)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="54" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A local basis representation for estimating human pose from cluttered images</title>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV&apos;06)-Part 1</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the Asian Conference on Computer Vision (ACCV&apos;06)-Part 1<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-01">January 2006</date>
			<biblScope unit="volume">3851</biblScope>
			<biblScope unit="page" from="50" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recovering 3D human pose from monocular images</title>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="58" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Human motion analysis: a review</title>
		<author>
			<persName><forename type="first">Jake</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="428" to="440" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Estimating anthropometry and pose from a single uncalibrated image</title>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Barro ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><forename type="middle">A</forename><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="284" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Monocular human motion tracking</title>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Barro ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><forename type="middle">A</forename><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="118" to="130" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimation of anthropomeasures from a single calibrated camera</title>
		<author>
			<persName><forename type="first">Chiraz</forename><surname>Benabdelkader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Automatic Face and Gesture Recognition (FGR&apos;06)</title>
		<meeting>the International Conference on Automatic Face and Gesture Recognition (FGR&apos;06)<address><addrLine>Southampton, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-04">April 2006</date>
			<biblScope unit="page" from="499" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A silhouette-based technique for the reconstruction of human movement</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Bottino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Laurentini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="95" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-linear statistical models for the 3D reconstruction of human pose and motion from monocular image sequences</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">A</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mansoor</forename><surname>Sarhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="729" to="737" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shadow</forename><surname>Puppetry</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV&apos;99)</title>
		<meeting>the International Conference on Computer Vision (ICCV&apos;99)<address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1237" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Posecut: Simultaneous segmentation and 3d pose estimation of humans using dynamic graph-cuts</title>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;06)<address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="642" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Twist based acquisition and tracking of animal and human kinematics</title>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Pullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="194" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-time 3-D human body tracking using variable length markov models</title>
		<author>
			<persName><forename type="first">Fabrice</forename><surname>Caillette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aphrodite</forename><surname>Galata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;05)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;05)<address><addrLine>Oxford, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="469" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Free-viewpoint video of human actors</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Carranza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><forename type="middle">A</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="569" to="577" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A multiple hypothesis approach to figure tracking</title>
		<author>
			<persName><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;99)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;99)<address><addrLine>Ft. Collins, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="239" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Shape-fromsilhouette of articulated objects and its use for human body kinematics estimation and motion capture</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>German</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takeo</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)<address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Markerless kinematic model and motion capture from volume sequences</title>
		<author>
			<persName><forename type="first">Chi-Wei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Odest</forename><forename type="middle">C</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><forename type="middle">J</forename><surname>Mataric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)<address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="475" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3D articulated models and multiview tracking with physical forces</title>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Delamarre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Faugeras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="357" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Combining geometric-and view-based approaches for articulated pose estimation</title>
		<author>
			<persName><forename type="first">David</forename><surname>Demirdjian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;04)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;04)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="183" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Articulated body motion capture by stochastic search</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Deutscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="205" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reconstruction of 3-D figure motion from 2-D correspondences</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Difranco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)<address><addrLine>Kauai, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12">December 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Real-time tracking of highly articulated structures in the presence of noisy measurements</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference On Computer Vision (ICCV&apos;01)</title>
		<meeting>the International Conference On Computer Vision (ICCV&apos;01)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-07">July 2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="315" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inferring 3D body pose from silhouettes using activity manifold learning</title>
		<author>
			<persName><forename type="first">Ahmed</forename><forename type="middle">M</forename><surname>Elgammal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan-Su</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="681" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Vision-based hand pose estimation: A review</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Erol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Bebis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mircea</forename><surname>Nicolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">D</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xander</forename><surname>Twombly</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cviu.2006.10.012</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding, this issue</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pictorial structures for object recognition</title>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="79" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The visual analysis of human movement: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dariu</surname></persName>
		</author>
		<author>
			<persName><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="92" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tracking of humans in action: A 3D model-based approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;96)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;96)<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Novel approach to nonlinear/nonGaussian Bayesian state estimation</title>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Salmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><forename type="middle">F M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings-F (Radar and Signal Processing</title>
		<imprint>
			<date type="published" when="1993-04">April 1993</date>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="107" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Inferring 3D structure with a statistical image-based shape model</title>
		<author>
			<persName><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV&apos;03)</title>
		<meeting>the International Conference on Computer Vision (ICCV&apos;03)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Style-based inverse kinematics</title>
		<author>
			<persName><forename type="first">Keith</forename><surname>Grochow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoran</forename><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="522" to="531" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient nonparametric belief propagation with application to articulated body tracking</title>
		<author>
			<persName><forename type="first">Tony</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huazhong</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">W 4 s: A realtime system detecting and tracking people in 2 1/2D</title>
		<author>
			<persName><forename type="first">Ismail</forename><surname>Haritaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;98)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;98)<address><addrLine>Freiburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1406-06">1406. June 1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="877" to="892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Model-based vision: a program to see a walking person</title>
		<author>
			<persName><forename type="first">David</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="20" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Silhouette lookup for automatic pose tracking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><surname>Howe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition Workshops (CVPRW&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition Workshops (CVPRW&apos;04)<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Flow lookup and biological motion perception</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><surname>Howe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Internation Conference on Image Processing (ICIP&apos;05)</title>
		<meeting>the Internation Conference on Image Processing (ICIP&apos;05)<address><addrLine>Genova, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1168" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Boundary fragment matching and articulated pose under occlusion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><surname>Howe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Articulated Motion and Deformable Objects (AMDO&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the International Conference on Articulated Motion and Deformable Objects (AMDO&apos;06)<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07">July 2006</date>
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
	<note>Port d&apos;Andratx</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bayesian reconstruction of 3D human motion from single-camera video</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">T</forename><surname>Leventon</surname></persName>
		</author>
		<author>
			<persName><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting><address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11">November 2000</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="820" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning to estimate human pose with data driven belief propagation</title>
		<author>
			<persName><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="747" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Model-based human body tracking</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition (ICPR&apos;02)</title>
		<meeting>the International Conference on Pattern Recognition (ICPR&apos;02)<address><addrLine>Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="552" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Probabilistic methods for finding people</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="68" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">CONDENSATION-conditional density propagation for visual tracking</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="28" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">3-D reconstruction of multipart, self-occluding objects</title>
		<author>
			<persName><forename type="first">Nebojsa</forename><surname>Jojic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV&apos;98)</title>
		<meeting>the Asian Conference on Computer Vision (ACCV&apos;98)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-01">January 1998</date>
			<biblScope unit="page" from="455" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cardboard people: A parameterized model of articulated image motion</title>
		<author>
			<persName><forename type="first">Shanon</forename><forename type="middle">X</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaser</forename><surname>Yacoob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Automatic Face and Gesture Recognition (FGR&apos;96)</title>
		<meeting>the International Conference on Automatic Face and Gesture Recognition (FGR&apos;96)<address><addrLine>Killington, VT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10">October 1996</date>
			<biblScope unit="page" from="38" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Three-dimensional human body model acquisition from multiple views</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Kakadiaris</surname></persName>
		</author>
		<author>
			<persName><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="191" to="218" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Model-based estimation of 3D human motion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Kakadiaris</surname></persName>
		</author>
		<author>
			<persName><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1453" to="1459" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Markerless tracking of complex human motions from multiple views</title>
		<author>
			<persName><forename type="first">Roland</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="190" to="209" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">How does CONDENSATION behave with a finite number of samples?</title>
		<author>
			<persName><forename type="first">Oliver</forename><forename type="middle">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;00)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;00)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1842-06">1842. June 2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="695" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automatic acquisition and initialization of articulated models</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Krahnsto ¨ver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Yeasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Vision and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="218" to="228" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Beyond trees: commonfactor models for 2D human pose recovery</title>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference On Computer Vision (ICCV&apos;05)</title>
		<meeting>the International Conference On Computer Vision (ICCV&apos;05)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10">October 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="470" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Gaussian process latent variable models for visualisation of high dimensional dataAdvances in</title>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Determination of 3D human body posture from a single view</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hsi-Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zen</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision, Graphics and Image Processing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="148" to="168" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Proposal maps driven mcmc for estimating human body pose in static images</title>
		<author>
			<persName><forename type="first">Mun</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="334" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Particle filter with analytical inference for human body tracking</title>
		<author>
			<persName><forename type="first">Mun</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soon</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ki</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Motion and Video Computing (MOTION&apos;02)</title>
		<meeting>the Workshop on Motion and Video Computing (MOTION&apos;02)<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-12">December 2002</date>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Human pose tracking using multi-level structured models</title>
		<author>
			<persName><forename type="first">Mun</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakant</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;06)<address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="368" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Monocular tracking of 3D human motion with a coordinated mixture of factor analyzers</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tai-Peng</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;06)<address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Uncalibrated motion capture exploiting articulated structure constraints</title>
		<author>
			<persName><forename type="first">David</forename><surname>Liebowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Monocular 3D reconstruction of human motion in long action sequences</title>
		<author>
			<persName><forename type="first">Gareth</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;04)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;04)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="442" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Partitioned sampling, articulated objects, and interface-quality hand tracking</title>
		<author>
			<persName><forename type="first">John</forename><surname>Maccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;00)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;00)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1843-06">1843. June 2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Real-time upper body detection and 3D pose estimation in monoscopic images</title>
		<author>
			<persName><forename type="first">Antonio</forename><forename type="middle">S</forename><surname>Micilotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eng-Jon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;06)<address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="139" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Human body model acquisition and tracking using voxel data</title>
		<author>
			<persName><forename type="first">Ivana</forename><surname>Mikic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mohan</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Cosman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="223" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Human body pose estimation using silhouette shape analysis</title>
		<author>
			<persName><forename type="first">Anurag</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Advanced Video and Signal Based Surveillance (AVSS&apos;03)</title>
		<meeting>the Conference on Advanced Video and Signal Based Surveillance (AVSS&apos;03)<address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">A survey of computer visionbased human motion capture, Computer Vision and Image Understanding (CVIU)</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Granum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="231" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Volker Kru ¨ger, A survey of advances in vision-based human motion capture and analysis</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="90" to="126" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Impact of dynamics on subspace embedding and tracking of sequences</title>
		<author>
			<persName><forename type="first">Kooksang</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><forename type="middle">I</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="198" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Recovering 3D human body configurations using shape contexts</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1052" to="1062" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Recovering human body configurations: Combining segmentation and recognition</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="326" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Singularity analysis for articulated object tracking</title>
		<author>
			<persName><forename type="first">D</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;98)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;98)<address><addrLine>Santa Barbara, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-06">June 1998</date>
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of joint density models for human pose estimation</title>
		<author>
			<persName><forename type="first">Ramanan</forename><surname>Navaratnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;06)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;06)<address><addrLine>Edinburgh, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="679" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Hierarchical part-based human body pose estimation</title>
		<author>
			<persName><forename type="first">Ramanan</forename><surname>Navaratnam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arasanathan</forename><surname>Thayananthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;05)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;05)<address><addrLine>Oxford, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">People tracking based on motion model and motion constraints with automatic initialization</title>
		<author>
			<persName><forename type="first">Huazhong</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1423" to="1440" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A dynamic 3D human model using hybrid 2D-3D representations in hierarchical pca space</title>
		<author>
			<persName><forename type="first">Eng-Jon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;99)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;99)<address><addrLine>Nottingham, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Viewpoint invariant exemplar-based 3D human tracking</title>
		<author>
			<persName><forename type="first">Eng-Jon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><forename type="middle">S</forename><surname>Micilotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="178" to="189" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>CVIU)</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Model-based image analysis of human motion using constraint propagation</title>
		<author>
			<persName><forename type="first">O'</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">I</forename><surname>Rourke</surname></persName>
		</author>
		<author>
			<persName><surname>Badler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="522" to="536" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
	<note>PAMI)</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Jesu ´s Martı ´nez del Rinco ´n, Jose ´Elı ´as Herrero-Jaraba, Gre ´gory Rogez, 2D silhouette and 3D skeletal models for human detection and tracking</title>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Orrite-Urun ˜uela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition (ICPR&apos;04)</title>
		<meeting>the International Conference on Pattern Recognition (ICPR&apos;04)<address><addrLine>Cambridge, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="244" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">View independent human body pose estimation from a single perspective image</title>
		<author>
			<persName><forename type="first">Rama</forename><surname>Vasu Parameswaran</surname></persName>
		</author>
		<author>
			<persName><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="16" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A dynamic Bayesian network approach to figure tracking using learned dynamic models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV&apos;99)</title>
		<meeting>the International Conference on Computer Vision (ICCV&apos;99)<address><addrLine>Kerkyra, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="94" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Visual interpretation of hand gestures for human-computer interaction: A review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="677" to="695" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Tracking and modeling people in video sequences</title>
		<author>
			<persName><forename type="first">Rolf</forename><surname>Pla ¨nkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="302" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning to parse images of articulated bodies</title>
		<author>
			<persName><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS) 19</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-12">December 2006</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Finding and tracking people from the bottom up</title>
		<author>
			<persName><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)<address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="467" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Training deformable models for localization</title>
		<author>
			<persName><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="206" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Learning silhouette features for control of human motion</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Liu Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">K</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanspeter</forename><surname>Hodgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1303" to="1331" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Recovering human body configurations using pairwise constraints between parts</title>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference On Computer Vision (ICCV&apos;05)</title>
		<meeting>the International Conference On Computer Vision (ICCV&apos;05)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10">October 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="824" to="831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Human tracking using 3d surface colour distributions</title>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">W</forename><surname>Ricketts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1332" to="1342" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Jesu ´s Martı ´nez, Carlos Orrite-Urun ˜uela, Viewpoint independent human motion analysis in manmade environments</title>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">´j</forename><surname>Gre ´gory Rogez</surname></persName>
		</author>
		<author>
			<persName><surname>Guerrero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;06)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;06)<address><addrLine>Edinburgh, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="659" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Towards model-based recognition of human movements in image sequences</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Rohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="94" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Learning to parse pictures of people</title>
		<author>
			<persName><forename type="first">Cordelia</forename><surname>Re ´mi Ronfard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;02)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;02)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2353. May 2002</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="700" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Inferring body pose without tracking body parts</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ro ´mer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;00)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;00)<address><addrLine>Hilton Head Island, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="721" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Estimating 3D body pose using uncalibrated cameras</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ro ´mer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matheen</forename><surname>Rosales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)<address><addrLine>Kauai, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12">December 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="821" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Fast pose estimation with parameter-sensitive hashing</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV&apos;03)</title>
		<meeting>the International Conference on Computer Vision (ICCV&apos;03)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="750" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Learning the statistics of people in images and video</title>
		<author>
			<persName><forename type="first">Hedvig</forename><surname>Sidenbladh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Compututer Vision</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="181" to="207" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Stochastic tracking of 3D human figures using 2D image motion</title>
		<author>
			<persName><forename type="first">Hedvig</forename><surname>Sidenbladh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;00)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;00)<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1843-06">1843. June 2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="702" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Implicit probabilistic models of human motion for synthesis and tracking</title>
		<author>
			<persName><forename type="first">Hedvig</forename><surname>Sidenbladh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;02)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;02)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2350. May 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="784" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Tracking loose-limbed people</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sidharth</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;04)<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="421" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Humaneva: Synchronized video and motion capture dataset for evaluation of articulated human motion</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>CS-06-08</idno>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
			<pubPlace>Providence, RI</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Brown University, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Measure locally, reason globally: Occlusion-sensitive articulated pose estimation</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2041" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Predicting 3D people from 2D pictures</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Articulated Motion and Deformable Objects (AMDO&apos;06)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the International Conference on Articulated Motion and Deformable Objects (AMDO&apos;06)<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07">July 2006</date>
			<biblScope unit="page" from="185" to="195" />
		</imprint>
	</monogr>
	<note>Port d&apos;Andratx</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Attractive people: Assembling loose-limbed models using nonparametric belief propagationAdvances in</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Sigelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1539" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Estimation Algorithms For Ambiguous Visual Models-Three Dimensional Human Modeling And Motion Reconstruction in: Monocular Video Sequences</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
			<pubPlace>Grenoble</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute National Politechnique de Grenoble (INPG</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Generative modeling for continuous non-linearly embedded visual inference</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><forename type="middle">D</forename><surname>Jepson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML&apos;04)</title>
		<meeting>the International Conference on Machine Learning (ICML&apos;04)<address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07">July 2004</date>
			<biblScope unit="page" from="759" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Discriminative density propagation for 3D human motion estimation</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atul</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="390" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Learning joint top-down and bottom-up processes for 3D visual inference</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atul</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1743" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Conditional models for contextual human motion recognition, Computer Vision and Image Understanding</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atul</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU)</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="210" to="220" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Estimating articulated human motion with covariance scaled sampling</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotic Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="371" to="392" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Kinematic jump processes for monocular 3D human tracking</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;03)<address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Unsupervised learning of human motion</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="814" to="827" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Recognizing and tracking human action</title>
		<author>
			<persName><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV&apos;02)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the European Conference on Computer Vision (ECCV&apos;02)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2350. May 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="629" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Real-time human pose inference using kernel principal component pre-image approximations</title>
		<author>
			<persName><forename type="first">Therdsak</forename><surname>Tangkuampien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC&apos;06)</title>
		<meeting>the British Machine Vision Conference (BMVC&apos;06)<address><addrLine>Edinburgh, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="599" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Trevor Darrell, Conditional random people: Tracking humans with crfs and grid filters</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Taycher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Demirdjian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Reconstruction of articulated objects from point correspondences in a single uncalibrated image</title>
		<author>
			<persName><forename type="first">J</forename><surname>Camillo</surname></persName>
		</author>
		<author>
			<persName><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="363" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Automatic alignment of local representationsAdvances in</title>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="841" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Tracking human body pose on a learned smooth space</title>
		<author>
			<persName><forename type="first">Tai-Peng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<idno>BUCS-TR-2005-029</idno>
		<imprint>
			<date type="published" when="2005-07">July 2005</date>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Boston University, Computer Science Department</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Probabilistic tracking with exemplars in a metric space</title>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="19" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">3D people tracking with gaussian process dynamical models</title>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Priors for people tracking from small training sets</title>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference On Computer Vision (ICCV&apos;05)</title>
		<meeting>the International Conference On Computer Vision (ICCV&apos;05)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10">October 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;01)<address><addrLine>Kauai, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12">December 2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Tracking persons in monocular image sequences</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Wachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Hellmut</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="174" to="192" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<title level="m">Gaussian process dynamical modelsAdvances in Neural Information Processing Systems (NIPS)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1441" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Video analysis of human dynamics: a survey</title>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Real-Time Imaging</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="321" to="346" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Recent developments in human motion analysis</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="585" to="601" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">A modular approach to the analysis and evaluation of particle filters for figure tracking</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="790" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Pfinder: Real-time tracking of the human body</title>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">R</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><forename type="middle">J</forename><surname>Azarbayejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="780" to="785" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Scene constraintsaided tracking of human body</title>
		<author>
			<persName><forename type="first">Masanobu</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katsutoshi</forename><surname>Yagishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR&apos;00)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR&apos;00)<address><addrLine>Hilton Head Island, SC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="151" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Face recognition: A literature survey</title>
		<author>
			<persName><forename type="first">Wen-Yi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Jonathon</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="458" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
