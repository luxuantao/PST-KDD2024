<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pretty Good Persuasion: A first step towards effective password security in the real world</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dirk</forename><surname>Weirich</surname></persName>
							<email>d.weirich@cs.ucl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>Gower Street UK</addrLine>
									<postCode>WC1E 6BT (+44) 207, 679 3033</postCode>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martina</forename><forename type="middle">Angela</forename><surname>Sasse</surname></persName>
							<email>a.sasse@cs.ucl.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>Gower Street UK</addrLine>
									<postCode>WC1E 6BT (+44) 207, 679 7212</postCode>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pretty Good Persuasion: A first step towards effective password security in the real world</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7BAB4C10EB27968B62836222BAC140F8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>security</term>
					<term>passwords</term>
					<term>user-centered design</term>
					<term>mental models</term>
					<term>cognitive task analysis</term>
					<term>user training</term>
					<term>motivation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the past, research on password mechanisms has focussed almost entirely on technical issues. Only in recent years has the security research community acknowledged that user behavior plays a part in many security failures, and that policies alone may not be sufficient to ensure correct behavior. We argue that password mechanisms and their users form a socio-technical system, whose effectiveness relies strongly on users' willingness to make the extra effort that security-conscious behavior requires. In most organizations, users cannot be forced to comply; rather, they have to be persuaded to do so. Ultimately, the mechanisms themselves, policies, tutorials, training and the general discourse have to be designed with their persuasive power in mind. We present the results of a first study that can guide such persuasive efforts, and describe methods that can be used to persuade users to employ proper password practice.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Password mechanisms are the first line of defense of most computer systems, and therefore affect almost every user on a daily basis. Research on security mechanisms in general has in the past focused almost exclusively on technical issues. Only in recent years has the security community recognized that user behavior is a part of many security failures, and started to consider the effect of human factors in security (see, for example, <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b2">3]</ref>). <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b8">[9]</ref> have shown that current password mechanisms have largely failed to consider usability, and that -given the increasing number of systems and passwords -most users cannot cope with the demands imposed on them. In addition, many users are not sufficiently educated about security issues. Thus, many usersm construct their own, often wildly inaccurate models of security threats and the importance and effective deployment of security measures. All this has led to a situation where a large number of users consistently behave in a manner that undermines the security of the systems they are using: they choose cryptographically weak passwords, write them down, and readily disclose them to other people. It is exactly these kinds of behaviors that are exploited by hackers and industrial spies, many of whom use social engineering <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>We believe that the usability of password mechanisms will be improved, and that users will become better educated. However, even once this is achieved, there is an additional issue that needs to be addressed: the willingness of users to behave in accordance with proper password practice. In most cases, authentication to a system is an enabling task, which means it creates an overhead for the user, who is using that system as a tool to achieve a primary, real-world task. It is predictable that most users will cut corners to reduce that extra load given a chance, unless they are motivated to make the effort to behave in a security-conscious fashion -an argument <ref type="bibr" target="#b9">[10]</ref> have put forward for security mechanisms in general. Oversimplifying for the sake of argument, users of password mechanisms can be divided into two groups: those that face personal damage if they do not behave in a securityconscious fashion, and those that do not put themselves, but others, at risk by cutting corners. Self-employed and home users fall into the first category -users in this group can, if educated about the possible consequences of their behavior, make an informed choice about their behavior, based on an assessment of the risks and the effort required to reduce these risks. Users in an organizational context fall into the second category, and for them education will very often not be sufficient. <ref type="bibr" target="#b8">[9]</ref> found that users who had access to systems essential to the operations of their company -which had experienced a number of break-ins -had an attitude set towards security that could at best be labeled as 'unconcerned'. Organizations put themselves at risk if they have employees with such attitude sets, which are likely to prevail even with further education.</p><p>Work on computer security has always been strongly influenced by its roots in the military environment, where users can be expected to comply with rules given to them. <ref type="bibr" target="#b0">[1]</ref> demonstrated that this approach does not work in modern business organizations with skilled, empowered knowledge workers, who do not work under constant supervision and are supposed to use their own initiative. These users cannot be expected to comply with security practices that they perceive as obstacles on the path to getting their job done. They will be aware that it is impossible to monitor their password behavior constantly, and are therefore likely to ignore such rules. One of the studies in <ref type="bibr" target="#b8">[9]</ref> found that the vast majority of users did not follow company rules for passwords. In many corporate environments, the highest-ranking executives are those least likely to comply with security rules because they "don't have time" to bother with procedures that "get in the way of more important things". Monitoring staff closely to enforce compliance would be prohibitively expensive and unacceptable from a human resources point of view. Since employees cannot simply be forced to comply, they have to be persuaded to do so. We believe that in the long run, any persuasive effort will only be fully effective if the password mechanisms are usable, integrated with real world tasks, and designed from the very beginning with their persuasive power in mind. However, in this paper we will present a first demonstration of 'pretty good persuasion' without changing the mechanisms. Some of these methods rely on changes to the policies and the way they are enforced, and some rely purely on changing the discourse about passwords mechanisms, supported by a social marketing campaign. Ultimately, only a combination of all these methods will achieve maximum persuasive power.</p><p>Our research was originally motivated by a simple set of questions. In large organizations, many users have similar jobs to do, and access information with the same degree of confidentiality. How can it be that some of them are motivated to behave in a security-conscious fashion, and others are not? Is this due to general personality differences, or can it be traced back to their mental constructs, e.g. their knowledge, beliefs and attitudes? And if it can be traced back to their mental constructs, would it be possible to entice users who behave improperly to take on the constructs of users that behave well, thus changing their behavior? In an initial investigation of these questions, we carried out semi-structured in-depth interviews on password security with 17 participants. Ten of these worked for a technology company, 6 were doctoral candidates, and one was a systems administrator working in a bank. The interviews lasted 30-60 minutes and were subsequently transcribed for analysis. Interviews (rather than questionnaires) were chosen in order to allow exploratory questioning, and since it has been reported that a lot of people will answer questions on security in interviews that they will not answer in a questionnaire <ref type="bibr" target="#b1">[2]</ref>. We kept the interviews as open as possible, but were broadly guided by concepts taken from Rogers' protection motivation theory <ref type="bibr" target="#b7">[8]</ref>. The theory is concerned with the use of fear appeals to change the behavior of people. It states that fear appeals will be effective if they convince the recipient that 1. the problem is serious; 2. it may affect her/him; 3. it can be avoided by taking appropriate action; and 4. the recipient is capable of performing the necessary behavior required to avoid the problem.</p><p>We initially analyzed the interviews looking for beliefs, attitudes and knowledge items, but subsequently found the concept of interpretative repertoires (IR) extremely useful. Our use of this concept draws on Potter and Wetherell's formulation of discourse analysis <ref type="bibr" target="#b4">[5]</ref>, and its application in Human-Computer Interaction <ref type="bibr" target="#b6">[7]</ref>. Discourse analysis argues that language constructs reality, rather than representing or reflecting it. There is always more than one way to describe things, and our choice of how to describe particular aspects of reality has an immense power to shape the way we experience the world and behave in it. Interpretative repertoires are the shared linguistic resources we draw on to construct aspects of reality.</p><p>In analyzing the interviews, we made a number of discoveries that we believe to be important for anybody wanting to persuade users in an organizational context to behave in a security-conscious fashion. Section two of the paper will describe these findings in detail, but the following is a high-level summary:</p><p>1. A large number of the participants in the interviews had mental constructs that make it almost impossible to use fear appeals effectively to change their behavior. The good news is that there were also a few participants with mental constructs that can assist us in creating powerful fear appeals.</p><p>2. We found that participants quite freely disclosed their passwords to other members of their organization. The interesting point is that there is a strong social element in sharing passwords -it is seen as a sign of trust among coworkers. In addition, the criteria for who to share with, and when, directly play into the hands of hackers, industrial spies and social engineers.</p><p>3. Another way of persuading users to behave properly would be an advertising approach of associating 'positive qualities' with the desired behaviors. We found that, currently, the exact opposite is the case. People who behave in a securityconscious fashion are often described as 'paranoid' -even by themselves.</p><p>The third section of this paper, will present initial ideas on solving these problems. We are currently applying some of these approaches to establish their effects, whilst the others are promising avenues for future research. In particular, we suggest a three-tiered approach to address the current state of affairs:</p><p>1. In the short run, users' willingness to comply with existing regulations can be improved by changing the discourse about password mechanisms, and by using techniques from social marketing.</p><p>2. Where possible, additional changes to policies and the way they are enforced will increase compliance.</p><p>3. Ultimately, only password mechanisms that have been designed with their 'persuasive power' in mind will achieve the maximum level of compliance, in conjunction with the previous two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">UNDERSTANDING USERS 2.1 Who's afraid of the big bad wolf? Why conventional fear appeals don't work for most users</head><p>In the introduction, we stated the conditions that have to be met for a fear appeal to be successful. In this subsection, we will show that beliefs held by many participants, and the interpretative repertoires they draw on, mean they are effectively immune to conventional fear appeals because not all of the necessary conditions can be met.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Who tries to get into other people's accounts -and why?</head><p>The interpretative repertoires participants draw on to describe the people who try to break into other people's accounts, and their motivation to do so, bear a direct relation on whether they perceived themselves as likely targets for such attacks. The repertoires used by most participants lead them to believe that this likelihood was small, as will be shown in 2.2.2.</p><p>The most prominent repertoire was kids 1 , with vandals and criminals a distant second. The other repertoires reported here were only mentioned by individual participants.</p><p>Kids were described as sad little kids (spotty little s***s, basically, that have nothing better to do than to fascinate themselves by writing programs about how to get into things which they're not supposed to.) or curious kids (Curiosity, just saying "This is secret, can I break into it, that would be fun." Like, basically, kids playing around.). Some technically-minded participants even expressed a certain amount of admiration for them (Very technically literate, very capable technically, with a devious mind. [laughs].). Their motivation is to prove they can do it, to get a buzz, to get a sense of achievement, or to be better than someone else and impress their friends. They target securityconscious organizations, prestigious ones, or the rich and famous. Once they have broken into a system, they might deface a web page, or leave a message, but they don't do any serious harm.</p><p>Vandals are seen as abnormal (I don't know how to describe them. They're obviously not normal people.). They want to have a pop at the establishment or are just plain mad (but all the destructive stuff is like a cat burglar that's just having an episode in a place, you know, they lose their rag, they go completely mad and start racking the place, that seems a bit unnecessary to me). They have the same targets as kids, but unlike them, they do serious damage in the systems they break into.</p><p>Criminals were seen almost exclusively as trying to carry out activities related to online banking -which none of the participants had direct access to from their company accountwith only one participant considering the threat of their account being used as a base to commit fraud undetected.</p><p>Vengeful people are vengeful against a specific individual, whereas disgruntled employees want to get revenge on an organization. The final repertoires that appeared where industrial spies, terrorists, and jokers (And they might even know the person that they're targeting, where it's just a joke, where they then send of an email purporting to come from some individual, saying outrageous things.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Whom do they target?</head><p>The likely targets for attackers are a direct result of the repertoires introduced above. The important point to make here is that none of the participants perceived themselves as falling under one of the repertoires that make up potential targets, except for the weakest link repertoire. Mostly, the targets are security- 1 The special font denotes the interpretative repertoires. conscious organizations or high-profile organizations (They're high-profile. Some of those are supposed to be very secure, like the Pentagon is supposed to be unbeatable, so if you can get into that, it's like a big thing, a big macho-thing, but also if you tell your mates you hacked into some system that nobody has ever heard of, they won't be very impressed, however secure it was. They won't be very impressed. You hacked into X, who is X? No-one's heard of them, so it's not very impressive.). In addition, people with important information are targeted, as are people who have annoyed the attacker. Only few participants, and only after further questioning, drew on the weakest link repertoire (Ahh… yeah, probably not, I think it's unlikely that anyone from outside would choose, you know, that their aim would be to get into specifically my account, but I think they could end up targeting me, you know, like I was saying, searching for a weak link in a corporate organi-, yeah, they want to get into some part of {company name}'s network, and I'm one way in, so they might, I might get targeted in that sense.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">There is no personal danger</head><p>As shown above, the likelihood of being targeted personally was seen as small by the participants. In addition, we could confirm the results of the previous studies <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b8">[9]</ref>: the severity of the negative consequences of someone breaking into the account is regarded as small as well. Participants did on the whole not believe that the information in their account was of importance or use to anybody (but, but I mean, the sort of information that you, that's passworded is not of any interest to anybody. The number of man-hours that have been working on my project, who cares? There are items there that are important to me, and that I would know how to exploit them, but if somebody had a look at them, I think they would have great difficulty, first of all, in understanding them, and secondly, finding a market for them.).</p><p>In addition, a number of mechanisms that organizations employ in order to reduce the possible negative consequences of break-ins directly lead to participants regarding the danger as less strong (Q: Would there be any potential harm to you personally? A: Only if they send emails on my behalf, I think, that's the only scenario I could think of. They could destroy my work, but I use the mainframe as a backup, so everything that's on there is stored elsewhere anyway.). Participants in the commercial organization also showed a strong belief in the security of their Intranet (Ah, perhaps not so important is, to me, is the passwords dealing with computing security in terms of files, file storing places because, mostly, because we're inside an intranet, it's mainly secure from outside.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Hackers can always find a way in</head><p>We have shown that participants did not consider themselves as under threat. We also wanted to know whether they believed they could prevent someone from breaking into their system, and came across a repertoire that clearly diminishes that belief -hackers can always find a way in (Ahm, I think if somebody is determined enough to break into a system, they will expand the effort, either guessing the passwords or rampaging through bins to find those torn-up envelopes or, or whatever. I think if somebody is determined enough, they'll break in. <ref type="bibr">[passwords]</ref> add another level to make it more difficult for people who aren't particularly experienced to access your account.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Personal accountability</head><p>We asked participants what they would do if their superior confronted them with the fact that someone had accessed other parts of the system from their account, causing considerable harm to the organization. Most participants did not regard this as a problem, since they could always rely on the trust in me (people that know me personally would know that I wouldn't do things like that) and the fact that passwords are not infallible (Ahm, I mean, most, we work on, ah, in a company like {company name}, in such a big company, ahm, that sort of stuff may happen, and people are aware that passwords are not infallible and therefore there is kind of a, a trust among people, and if I said 'I didn't do it', then I would expect people to trust me, because, ahm, basically, the, the, it should be clear that systems are not totally infallible and some systems can be compromised.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Is there hope? Why fear appeals could work better for some users</head><p>None of the participants followed regulations on password security to the letter. However, some of them made more of an effort to behave in a manner that they regarded as securityconscious, or at least were aware of the dangers to them of not complying with regulations. The important point about the repertoires we present in this section is that some of them are direct 'antidotes' to the ones presented in previous sections. We present all of the repertoires we have found, even though some of them are likely to be more useful in persuading users to participate in the required manner than others:</p><p>1. Allegiance: Basically, the way I see it, obviously, my main allegiance is to the department at the moment, rather than the College, because that's where I've been for god knows how long, so from my point of view protecting that account and the email that comes to and from that account is more important than the college facilities that I use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Previous break-ins:</head><p>I maintain the highest level of personal security I can on that because that has been hacked before. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yeah, but it, just because everyone else does it…</head><p>First of all, if somebody hacked in through my account into somebody else's account, then my account name will appear on the hacking record or whatever, and therefore I will be blamed for it. I won't be held responsible if my system was too easy to get into or if I had a easy-to-guess password. I'm sure the regulations say my password should be changed frequently and should be hard to guess. And it isn't. And therefore if somebody had broken in through it, I could be held responsible, I guess.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The sharing culture: why social engineering is a no-brainer</head><p>In this section we will investigate the actual situations in which participants shared passwords, and show that there is a social component that currently makes it difficult for many people to refuse a request to disclose their password. In addition, there are common criteria that determine whether a request to disclose one's password is successful or not. The point we want to make here is that the reasons for sharing passwords, and the criteria underlying the decision to disclose passwords, offer ideal entry points for hackers and industrial spies using social engineering techniques. Finally, we point out repertoires that increase resistance to disclosing one's password.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">In what situations do people disclose passwords?</head><p>There are a number of situations that lead to password disclosure. Industrial spies can easily exploit some of these, and hackers can attempt to engineer situations that allow them to ask someone else to disclose their password:</p><p>1. Have somebody access your account: I've also had to give my password to another colleague, because I had to go home and had some urgent email, but I couldn't, I don't have access to email at home, so I gave that person my password and they checked my email for me. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Necessary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Criteria underlying the decision to disclose one's password</head><p>As we have seen, there are certain situations in which people disclose their passwords, and in which it might even be a disadvantage in the social context not to. In addition, there seems to be a common decision-making process that is based on all or some of the following criteria: An additional criterion can be whether nobody else can help: I probably would, if, if I couldn't be there to do it myself, on their behalf, or there's actually nobody else they could go to and it was a particularly important piece of information they needed to get at.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Repertoires that increase resistance to sharing</head><p>There are a number of repertoires that reduced participants' willingness to disclose their passwords -or even completely obliterated it. Again, some of these are direct antidotes to repertoires encouraging password disclosure:</p><p>Can always find an alternative way: so, I wouldn't, if I needed really to read my email or something then I would find another way to do it, not by giving somebody my password to access the system.</p><p>I don't want to become a suspect: and if something happens to that other person's account, then you could be somebody who would become, would be a suspect in that situation, so I don't try to get information about other people's security information or password information other than… They might also be regarded as anal and pedantic: Mmm… I'd just think they were very diligent in following the site's security policy. They're more worried about not to be seen to be breaching any security rules. I mean, some colleagues, even though you might work with them, might be particularly pedantic on that kind of thing, or…</p><formula xml:id="formula_0">I</formula><p>People not disclosing their passwords can be seen as unsociable, or might even get the image of not being team players: Completely closed and shuttered down and, not, don't want to give away, share, not, not team players, as they say. I would say they're those sort of people. But yes, but I think people who are like that as part of their nature, I think that's just how they are as people, and they're, they're just not team players at all, just very shuttered and closed, and I'd probably think they're a bit weird, to be honest.</p><p>People not following regulations can be seen as pragmatic: I think it's, it's interesting, we're all given hold of these passwords, and we're not supposed to share them, but I think people are more pragmatic about things, so I wouldn't be surprised if it happened, so, ah.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPLICATIONS AND FUTURE RESEARCH</head><p>In section two, we have presented a large number of interpretative repertoires that undermine security-consciousness, as well as some that increase it. The aim of any intervention must be to make users abstain from the former and employ the latter. The approaches to achieving this we present here are changes to the mechanisms itself, policies, tutorials, training and the general discourse about passwords. We believe that a combination of all of these will prove most effective, though 'pretty good persuasion' can be achieved without changing the mechanism itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methods not requiring changes to policies or the mechanism itself</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Changes to the discourse about password mechanisms</head><p>The interpretative repertoires we have presented co-exist as a complex, entangled web within individual users. Any discourse about password mechanisms, for example in tutorials and training, should obviously introduce and reinforce the desired repertoires. In addition, it should use those repertoires that act as antidotes to undesirable ones. An example would be to point out that any break-in into an employee's account might result in personal embarrassment (avoid personal embarrassment) in order to combat the general belief that no personal danger can be caused by such break-ins.</p><p>A further interesting area of future research would be the deployment of an adequate metaphor for the whole password mechanism that counteracts some of the repertoires that undermine proper security behaviors. One metaphor we are currently investigating in the context of private users is the 'burglar alarm'. As with password mechanisms, users of burglar alarms are aware of the fact that they can ultimately not keep out a highly determined intruder. Still, most house owners install burglar alarms in order to make it as difficult as possible for the intruder to get in. In the scenario we are currently investigating, we are pointing out that attackers of computer systems will ultimately go for the easiest target -which means that a person employing proper password practice does not fight the intruder, but competes with other users to be better-protected then them, so the intruder attacks them, not her/him. This idea is equivalent to the situation with burglar alarms, and might be conveyed easily by using this metaphor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Social marketing for social people</head><p>An important result of our study are the social and self-image issues we have discovered. An interesting and promising area of future research is the possible use of concepts and methods from social marketing in order to associate positive qualities with proper password practice, and negative ones with bad password practice. One example would be an advertising campaign depicting people behaving properly as professional and caring about their organization, and those behaving improperly as highly unprofessional and anti-social in that they put their colleagues at risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">If there is no reason to be securityconscious, create one: A different way of using fear appeals</head><p>The findings in section 2.1. show that many users do not expect to suffer personal consequences from improper password behavior. Current security policies tend to threaten punishment for improper password practice, but these are hardly ever enforced. It is likely that the actual enforcement of these policies would meet with resistance among users, considering that most of them do not believe there to be any reason to be security-conscious in the first place. The challenge then is to find a way of creating such a reason in a way that meets their acceptance. One such way, which we are currently investigating, is based on a change of policies and the way they are enforced, intertwined with a justification for this change that stresses the danger to the organization rather than the individual. The change we are investigating is based on the following ideas:</p><p>1. Present the danger as one of the organization's reputation being tarnished if it were to be known to the outside world that its employees did not behave in a security-conscious fashion. Depending on the type of the organization, this might focus on issues such as ensuring that customers' data is kept secure. This gives the fear appeal (and its associated punishment) a rational motivation that will raise users' acceptance of it.</p><p>2. Punish non-compliant behavior if it is careless, rather than due to a lack of knowledge and support.</p><p>3. Be seen to punish such behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Changes to the password mechanism itself</head><p>The following is a radical scenario that we are currently investigating in focus groups in order to determine the effectiveness of its individual elements:</p><p>1. The system hands out to each user a unique password that can not be changed.</p><p>2. In addition, the user is given instructions at the time of receiving the password on how to memorize it.</p><p>3. The user can log into his system using the password aloneno user_id is needed.</p><p>4. In case the user forgets his/her password, it takes 24 hours to be allocated a new one.</p><p>5. The password is changed only at long intervals, e.g. every six months or more.</p><p>The aim of these changes is to associate the password closer with its user -since s/he can log in with the password alone, anyone finding a written copy of it can abuse it. Since it is changed only at long intervals, anyone this password is disclosed to has access to the system for a long time. In addition, it is made inconvenient to get a new password, thus increasing the importance of the password, putting it on par with a key that is not replaced instantly either.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>We have put forward an argument that can be summarized as follows:</p><p>1. Password mechanisms and their users form a socio-technical system whose aim it is to achieve security.</p><p>2. Users' willingness to make the extra effort that securityconscious behavior requires is a vital variable influencing the effectiveness of this system.</p><p>3. Users cannot be forced to behave in a proper fashion, but an effort to persuade them to do so has to be made.</p><p>4. Systems, policies, tutorials, trainings and the general discourse about password mechanisms have to be designed with their persuasive power in mind.</p><p>5. Pretty Good Privacy can be achieved without changing the mechanisms themselves, though optimal results will only be obtainable by complete redesign.</p><p>We have given the results of a first study that can be used to guide the development of persuasive methods. In addition, we have given first ideas on which methods might deserve specific research attention in the future. Finally, we would like to stress that the applicability of 'pretty good persuasion' is not restricted to password mechanisms, but is likely to increase the effectiveness of other security mechanisms as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>for work: There's been, when we do experiments, it's often to set, to set up the computer in order to do an experiment, we sometimes have to give each other passwords, I mean I've had another colleagues password as well. Over the last few days, in order to do an experiment because my home directory didn't have the, the correct paths in it. So she gave me hers.</figDesc><table><row><cell>One important finding is that password disclosure is seen as a sign</cell></row><row><cell>of trust between colleagues -and the refusal to disclose as a sign</cell></row><row><cell>of lack of trust (I'm dodgy. Like I'm dodgy. Would they have had</cell></row><row><cell>a good reason? I think intellectually I could understand why</cell></row><row><cell>someone would want to not tell anyone their password but I think</cell></row><row><cell>I'm trustworthy and I would take it as a personal insult if a</cell></row><row><cell>situation arised… had arisen… I think I would… a situation arose</cell></row><row><cell>where I would need to someone's machine to achieve something</cell></row><row><cell>that was important and I couldn't do it because they refused to</cell></row><row><cell>give me their password, I would consider that to be a little over-</cell></row><row><cell>protective. And I think I'd feel a little bit insulted about their</cell></row><row><cell>views about my ability to use that password sensibly. Ahm,</cell></row><row><cell>probably because it comes down to 'Don't you trust me?' Since</cell></row><row><cell>we work together, sort of, on a daily basis.). Someone unwilling</cell></row><row><cell>to participate in this social activity can easily be seen as hiding</cell></row><row><cell>something (Somebody that has something which he's not</cell></row><row><cell>supposed to have, or just very secretive by nature without having</cell></row><row><cell>any reason for it.).</cell></row></table><note><p>3. Following higher orders: Right. Okay. Ahhmm, I'd do that if, if my group leader phoned me up and told me that… 4. Informal support: Ahm. Well, ahm, because I'm computerilliterate, ahm, I have to have a trusted friend who can help me out, so, ahm, one of the young people in the team who is very, very good at jiggling around with PCs has sort of taken me under her wing. And I usually manage to find someone who does that for me, wherever I go, so, ahm, so of course I let her have my password, so she can get onto my PC and change things and do things. 5. Organized sharing: what we do is, we actually, ahm, inside our group, we write, write down passwords that are deemed to be important, and we put them in sealed envelopes, and they're in our head of group's filing cabinet locked away. 2.3.2 'Don't you trust me?' The social component</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Users are not the enemy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Making passwords secure and usable</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HCI&apos;97)</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Thimbleby</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>O'conaill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">P</forename><surname>Thomas</surname></persName>
		</editor>
		<meeting>HCI&apos;97)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">XII</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Usability and Security</title>
		<author>
			<persName><forename type="first">Cornelius</forename><forename type="middle">C</forename><surname>Dufft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juergen</forename><surname>Espey</surname></persName>
		</author>
		<author>
			<persName><surname>Neuf</surname></persName>
		</author>
		<author>
			<persName><surname>Hartmut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Stapf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multilateral Security in Communications</title>
		<editor>
			<persName><forename type="first">Guenter</forename><surname>Mueller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kai</forename><surname>Rannenberg</surname></persName>
		</editor>
		<meeting><address><addrLine>Infrastructure, Economy</addrLine></address></meeting>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">User-centred design of secure software</title>
		<author>
			<persName><forename type="first">U</forename><surname>Holmström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Factors in Telecommunications</title>
		<meeting>Human Factors in Telecommunications<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Discourse and social psychology. Beyond attitudes and behaviour</title>
		<author>
			<persName><forename type="first">J</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wetherell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Sage Publications Ltd</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mitnick to lawmakers: People, phones and weakest links</title>
		<author>
			<persName><forename type="first">K</forename><surname>Poulsen</surname></persName>
		</author>
		<ptr target="http://www.politechbot.com/p-00969.html" />
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Examining users&apos; repertoire of Internet applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wakeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sheeran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction -Proceedings of INTERACT &apos;99</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sasse</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Johnson</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cognitive and physiological processes in fear appeals and attitude change: A revised theory of protection motivation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Psychophysiology</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Cacioppo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Petty</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transforming the &quot;weakest link&quot;: a human-computer interaction approach to usable and effective security</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brostoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weirich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT Technical Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="122" to="131" />
			<date type="published" when="2001-07">2001. July 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Why Johnny can&apos;t encrypt: A usability evaluation of</title>
		<author>
			<persName><forename type="first">A</forename><surname>Whitten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
		<idno>PGP 5.0</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Washington</pubPlace>
		</imprint>
	</monogr>
	<note>8 th USENIX Security Composium</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Corporate Espionage: what it is, why it is happening your company, what you must do about it</title>
		<author>
			<persName><forename type="first">I</forename><surname>Winkler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Prima Publishing, CA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">User-centered security</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Zurko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<pubPlace>New Security Paradigms Workshop, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
