<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Is GitHub Copilot a Substitute for Human Pair-programming? An Empirical Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Saki</forename><surname>Imai</surname></persName>
							<email>simai24@colby.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Colby College Waterville</orgName>
								<address>
									<settlement>Maine</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">ICSE &apos;22 Companion</orgName>
								<address>
									<addrLine>May 21-29</addrLine>
									<postCode>2022</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Is GitHub Copilot a Substitute for Human Pair-programming? An Empirical Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3510454.3522684</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GitHub</term>
					<term>Copilot</term>
					<term>Software Development</term>
					<term>AI</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This empirical study investigates the effectiveness of pair programming with GitHub Copilot in comparison to human pairprogramming. Through an experiment with 21 participants we focus on code productivity and code quality. For experimental design, a participant was given a project to code, under three conditions presented in a randomized order. The conditions are pairprogramming with Copilot, human pair-programming as a driver, and as a navigator. The codes generated from the three trials were analyzed to determine how many lines of code on average were added in each condition and how many lines of code on average were removed in the subsequent stage. The former measures the productivity of each condition while the latter measures the quality of the produced code. The results suggest that although Copilot increases productivity as measured by lines of code added, the quality of code produced is inferior by having more lines of code deleted in the subsequent trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Software and its engineering ? Development frameworks and environments; ? Human-centered computing ? Collaborative and social computing systems and tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>If GitHub Copilot could produce equivalent advantages found in human pair-programming, then adopting the practice of pairprogramming with GitHub Copilot would lead to a more productive and higher quality software development without acquiring additional costs of adding a second programmer. While Vinit Shahdeo, a software engineer at Postman, said Copilot is "going to increase developer's efficiency by reducing development time and suggesting better alternatives", technical blogger Ray Villalobos states that it is hard to get a useful result and that he needs to retype comments to get a productive piece of code <ref type="bibr" target="#b1">[2]</ref>. Although there are claims that these AI tools make software development more productive and they could even substitute human pair-programmers, we have not seen an empirical study to verify if AI tools in software development are more productive and give higher quality code. In this paper, we focus on the issue of productivity and code quality when using GitHub Copilot in software development. We designed a dedicated empirical experiment to compare AI with human participants in a natural software development environment. Through code analysis, we aim to answer our two central research questions focusing on measuring productivity and code quality with GitHub Copilot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>We recognize two major themes in the previous works that have been done in this field. The first is the use of AI in software development. Many studies have shown that the use of AI assists with software development. For instance, one study used a transformerbased model reported accuracy of up to 69% in predicting tokens when code tokens were masked <ref type="bibr" target="#b3">[4]</ref>. Another study using large language models reported that AI could repair 100% of handcrafted security bugs in addition to 58% of historical bugs in open-source projects <ref type="bibr" target="#b7">[8]</ref>. Moreover, a trained GPT language model has been exhibited to solve 70.2% of problems with 100 training samples per problem <ref type="bibr" target="#b2">[3]</ref>, and is also capable of repairing bugs in code <ref type="bibr" target="#b8">[9]</ref>. One study predicted defects with 87% accuracy, decreased inspection effort by 72%, and reduced post-release defects by 44% <ref type="bibr" target="#b10">[11]</ref>.</p><p>The second theme focuses on the study of software development environments, where empirical experimentation of how people write code gives us insights into how to enhance these tools and to possibly discover the best practice of software development <ref type="bibr" target="#b5">[6]</ref>. There have been studies on how professional developers comprehend software to understand how software development should be done, such as how programmers refactor while validating other programmers <ref type="bibr" target="#b6">[7]</ref>, and how implementation of task context for the Eclipse development environment improved productivity of programmers <ref type="bibr" target="#b4">[5]</ref>. We recognize that the study of AI tools in software development has not been studied empirically with a dedicated experiment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACH AND UNIQUENESS</head><p>In this research, we aim to study GitHub Copilot empirically in a natural software development environment (VS Code IDE). Hence, the research questions to be addressed in this study are as follows: (RQ1) Is there an advantage in productivity while using GitHub Copilot as compared to a human pair programmer? (RQ2) What is the quality of code written with Copilot in comparison to human pair programmers?</p><p>In pair programming, two programmers collaboratively work on the same code (typically on the same computer). Each programmer periodically switches between two roles, a driver or navigator. The driver controls the mouse and keyboard and writes code while the navigator observes the driver's work and critically thinks about defects, structural issues, and alternative solutions, while looking at a larger picture <ref type="bibr" target="#b0">[1]</ref>.</p><p>Using GitHub Copilot as a second programmer, we compare code when a participant is pair programming with a human programmer versus Copilot. Twenty-one participants who have taken at least one programming course worked on developing text-based minesweeper game in Python. None of the participants had implemented this game before, and the participants familiarized themselves with the rules by playing this game prior to the development task. The development task was done under three conditions. The conditions are pair programming with Copilot; pair programming with another human experimenter as a driver, and pair programming with another human experimenter as a navigator. The time allocated for is 20 minutes for Copilot, 10 minutes as a driver, and 10 minutes as a navigator (20 minutes total with a human pair). The order of these conditions were randomized to prevent the experiment effect. During the experiment, eye movement is recorded to measure the difference between having Copilot as a collaborator in comparison to a human programmer. The analysis of the produced code is done by using the ndiff function from difflib 1 . This is used to compare the number of added lines to the code and number of deleted lines to the code after each trial, normalized by the duration of the trial.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>To answer our research questions, code productivity in RQ1 is assessed by comparing the number of added lines to the code, and code quality in RQ2 is analyzed by comparing the number of lines deleted in the subsequent trial. Deletion is an indication of low quality code.</p><p>The result of RQ1 is shown in Figure <ref type="figure" target="#fig_1">1</ref>, where we can see that the Copilot condition produced the highest maximum and mean additions to lines of code. The maximum number of lines written in the trial with Copilot was 43 while the code written as a driver and navigator were 27 and 33 respectively. The minimum lines of code added was 9.5 for Copilot and 6 for both driver and navigator. These results suggest higher productivity during pair-programming with Copilot versus human pair-programmers. To answer RQ2, we counted the number of deleted lines in the following trial and normalize the count by the trial duration. For this, the line counts for the last condition were excluded since there was no trial subsequent to that where low quality code can be removed. The maximum lines of code deleted after the Copilot trial was 42 while the lines of code deleted after the driver and navigator trial were lower with 31 and 10, respectively. Figure <ref type="figure" target="#fig_3">2</ref> also shows that the deleted line count in the following trial was higher for Copilot than the other two conditions. Hence, our result suggests that the code generated with Copilot has, on average, lower quality than that produced by human pair-programmers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONTRIBUTIONS</head><p>Our results suggest that although programming with Copilot helps generate more lines of code than human pair-programming in the same period of time, the quality of code generated by Copilot appears to be lower. This result seems to suggest that pairprogramming with Copilot does not match the profile of human pair-programming. We are still in the process of collecting experiment data and analyzing the eye-tracking data that have been recorded throughout the experiment. With the eye-tracking data, we are trying to compare how programmer inspect the code generated by AI to that by human pair-programmer. Our hypothesis is that the overconfidence of AI tools leads to less inspection of code generated by Copilot.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>ICSE '22 Companion, May 21-29, 2022, Pittsburgh, PA, USA Saki Imai</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Number of lines added to a code under three different conditions.</figDesc><graphic url="image-2.png" coords="2,71.86,499.37,211.84,138.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>1 https://docs.python.org/3/library/difflib.html</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Number of lines of code deleted in a trial subsequent to three different conditions.</figDesc><graphic url="image-3.png" coords="2,325.98,257.86,212.43,135.75" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Ritchie</forename><surname>Schacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Will</surname></persName>
		</author>
		<ptr target="https://www.ibm.com/garage/method/practices/code/practice_pair_programming/" />
		<title level="m">Program in Pairs. Retrieved December 31, 2021 from</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Developers react to GitHub Copilot</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Carey</surname></persName>
		</author>
		<ptr target="https://www.infoworld.com/article/3624688/developers-react-to-github-copilot.html" />
		<imprint>
			<date type="published" when="2021-12-31">2021. December 31. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiming</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Ponde De Oliveira Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An Empirical Study on the Usage of Transformer Models for Code Completion</title>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Ciniselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Pascarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Mastropaolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emad</forename><surname>Aghajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denys</forename><surname>Poshyvanyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimiliano</forename><surname>Di Penta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Bavota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using task context to improve programmer productivity</title>
		<author>
			<persName><forename type="first">Mik</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gail</forename><forename type="middle">C</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGSOFT international symposium on Foundations of software engineering</title>
		<meeting>the 14th ACM SIGSOFT international symposium on Foundations of software engineering</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How are Java software developers using the Elipse IDE?</title>
		<author>
			<persName><forename type="first">Mik</forename><surname>Gail C Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName><surname>Findlater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE software</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="76" to="83" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How we refactor, and how we know it</title>
		<author>
			<persName><forename type="first">Emerson</forename><surname>Murphy-Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Parnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="5" to="18" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Hammond</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baleegh</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Karri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Dolan-Gavitt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.02125</idno>
		<title level="m">Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs? arXiv preprint</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Aron</forename><surname>Julian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Romain</forename><surname>Prenner</surname></persName>
		</author>
		<author>
			<persName><surname>Robbes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.03922</idno>
		<title level="m">Automatic Program Repair with OpenAI&apos;s Codex: Evaluating QuixBugs</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Choose Your Programming Copilot: A Comparison of the Program Synthesis Performance of GitHub Copilot and Genetic Programming</title>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Sobania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Briesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Rothlauf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.07875</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ai-based software defect predictors: Applications and benefits in a case study</title>
		<author>
			<persName><forename type="first">Ayse</forename><surname>Tosun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayse</forename><surname>Bener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Resat</forename><surname>Kale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Second IAAI Conference</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
