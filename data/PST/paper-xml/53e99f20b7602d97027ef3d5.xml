<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Precise Selection Techniques for Multi-Touch Screens</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hrvoje</forename><surname>Benko</surname></persName>
							<email>benko@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
							<email>awilson@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Baudisch</surname></persName>
							<email>baudisch@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research One Microsoft Way Redmond</orgName>
								<address>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Precise Selection Techniques for Multi-Touch Screens</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6CE991145781DAE2BECC3E334981B3EB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Touch screens</term>
					<term>tabletop displays</term>
					<term>two-finger</term>
					<term>bi-manual</term>
					<term>interaction techniques</term>
					<term>precise target acquisition H.5.2 [Information Interfaces and Presentation]: User Interfaces -Input devices and strategies</term>
					<term>Interaction styles</term>
					<term>Evaluation/methodology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The size of human fingers and the lack of sensing precision can make precise touch screen interactions difficult. We present a set of five techniques, called Dual Finger Selections, which leverage the recent development of multitouch sensitive displays to help users select very small targets. These techniques facilitate pixel-accurate targeting by adjusting the control-display ratio with a secondary finger while the primary finger controls the movement of the cursor. We also contribute a "clicking" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity. We implemented our techniques on a multi-touch tabletop prototype that offers computer visionbased tracking. In our formal user study, we tested the performance of our three most promising techniques (Stretch, X-Menu, and Slider) against our baseline (Offset), on four target sizes and three input noise levels. All three chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by our participants, with Stretch being the overall performance and preference winner.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>The ability to directly touch and manipulate data on the screen without using any intermediary devices has a very strong appeal to users. In particular, novices benefit most from the directness of touch screen displays. A fast learning curve and inherent robustness (no movable parts) makes touch screens an ideal interface for interacting with public installations, such as information kiosks, automated teller machines, ticketing machines, or gambling devices.</p><p>While touch screen use is widespread in special purpose applications, the slow adoption of touch screens into more general computing devices has be attributed to known issues of relatively high error rates, arm fatigue, and lack of precision <ref type="bibr" target="#b1">[2]</ref>. Due to technical restrictions, most commercially available touch screen devices in use today are only capable of tracking a single point on the surface of the device. However, with the recent emergence of many multi-touch prototype devices <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>, research on multi-finger and multi-hand touch interactions has increased <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b26">27]</ref>. In addition to dealing with the same issues as the single-touch machines, the underlying technology of multi-touch sensitive devices (such as visionbased sensing <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>) often tends to make their input more noisy.</p><p>When running software developed for a normal mouse interface on such a touch screen, these issues become problematic. Today's WIMP (windows, icons, menus and pointing) user interfaces require frequent selection of very small targets. For example, window resize handles are often just 4 pixels wide. Noisy input, lower tracking resolution, and large potential touch area of a finger now become a problem. Furthermore, fingertips can occlude small targets depriving users of visual feedback during target acquisition. Also, the user's hands and arms may contribute to the occlusion problem. Depending on screen orientation, the user may be forced to either look "under hand" (with horizontally positioned screens) or "over hand" (with angled or vertically positioned screens). Finally, it is often difficult to decide the optimal point in the finger's contact area which should anchor the cursor, leaving the usual choice to the center of mass. This can lead to a small but pervasive disconnect between the user's expectations regarding cursor position and what is actually being sensed and computed.</p><p>These issues have been recognized by researchers who have proposed several solutions: adding a fixed cursor offset <ref type="bibr" target="#b20">[21]</ref>, enlarging the target area <ref type="bibr" target="#b18">[19]</ref>, and providing on-screen widgets to aid in selection <ref type="bibr" target="#b1">[2]</ref>. Unlike previous work, we explore the benefits of multi-touch capable devices to provide fluid dual-finger interactions for pixel-accurate targeting. In the techniques presented in this paper, the secondary (non-pointing) finger can quickly modify or switch cursor manipulation modes without disrupting the primary (pointing) finger.</p><p>We present an iteratively designed set of five techniques that allow the user to simultaneously perform both cursor steering and selection of assistance mode (in the form of cursor offset, scale, speed reduction, or a combination). In addition to the precise selection techniques, we contribute a "clicking" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Difficulties with precise interactions on touch screen devices have been addressed before, initially by Potter et al. <ref type="bibr" target="#b20">[21]</ref>. Their Take-Off technique provides a cursor with a fixed offset above the tip of a finger when the user is touching the screen. Lifting the finger off the screen triggered selection ("click"). While this method is effective for most targets sizes, it has been found ineffective when the target size is smaller than 4 pixels. Sears and Shneiderman <ref type="bibr" target="#b23">[24]</ref> explored cursor stabilization improvements that effectively slowed down the cursor movement in various regions around the initial finger contact point, thus allowing for pixel-precise selection. While this method performed well for the target acquisition task, a precise steering task, such as drawing, would be hard due to varying cursor speed.</p><p>More recently, Albinsson and Zhai <ref type="bibr" target="#b1">[2]</ref> explored several onscreen widgets for increasing precision while selecting small targets on a touch screen. Their interactions were designed to be used with touch screens capable of reporting only a single contact point and therefore the users were required to execute multiple discrete steps before selecting the target. These steps were delimited by the user lifting their finger from the screen, thus impeding the overall interaction performance. Interestingly, they observed that even though their baseline zooming technique (ZoomPointing) performed best out of the four techniques compared, its main drawback of losing overview or context can be a significant problem in many applications.</p><p>Increasing the relative size of screen targets has also been explored by scaling the display space <ref type="bibr" target="#b18">[19]</ref> or scaling the motor space <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>. The work of Olwal and Feiner <ref type="bibr" target="#b18">[19]</ref> experimented with hand gestures that activated various levels of fish-eye distortion in the interface to facilitate target selection. Techniques that adaptively increase the motor space while leaving the displayed image unchanged, such as those by Blanch et al. <ref type="bibr" target="#b5">[6]</ref> or Baudisch et al. <ref type="bibr" target="#b2">[3]</ref>, show promising results without introducing screen distortions, but require that the system know all target locations. This information might not be available in many of today's applications. More importantly, such techniques require the use of a relative pointing device such as a mouse. Without such devices, they introduce an unpredictable cursor offset when applied directly to an absolute pointing device such as a touch screen.</p><p>Buxton <ref type="bibr" target="#b7">[8]</ref> identified that most current user interfaces require an interaction model consisting of at least 3 different states (out-of-range, tracking, and dragging). However, many touch sensitive devices can only reliably sense location in one state thus making it hard to disambiguate between dragging and tracking (hover).</p><p>The use of a stylus (pen) is generally preferred in many interfaces that require precise interactions. However, while a stylus has a much smaller tip, the associated issues with hand tremor and resolution make the selection task of small targets more difficult than with a mouse. Ren and Moriya <ref type="bibr" target="#b22">[23]</ref> report that a limiting size for stylus targets is about 1.8 mm, below which even the stylus interaction requires additional assistance.</p><p>Much research has been performed on bimanual interaction in user interfaces. In their pioneering work, Buxton and Myers <ref type="bibr" target="#b8">[9]</ref> demonstrated that users tend to parallelize interaction tasks between hands thus gaining significant performance improvements. Bier et al. <ref type="bibr" target="#b4">[5]</ref>, in their Toolglass and Magic Lenses system, allowed the user to control the transparent tool palette with the non-dominant hand, while the dominant hand controlled the primary cursor with the mouse. This simultaneous bimanual operation eliminated many inefficiencies typical of modal interfaces. Some research by Kabbash et al. <ref type="bibr" target="#b15">[16]</ref> points in the opposite direction, claiming that requiring the user to coordinate actions of their hands in order to perform twohanded interactions may complicate the overall task and slow performance. Two-finger and two-handed interactions for the activation of various tools, menus and widgets have been explored by researchers in many related fields: on tabletop surfaces <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27]</ref>, 3D volumetric displays <ref type="bibr" target="#b12">[13]</ref>, tangible user interfaces <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref>, virtual reality <ref type="bibr" target="#b9">[10]</ref>, and augmented reality <ref type="bibr" target="#b3">[4]</ref>. Rekimoto presented a novel capacitance-based sensing architecture, called SmartSkin <ref type="bibr" target="#b21">[22]</ref>, together with several multi-handed and multi-touch techniques for enabling the manipulation of objects projected on the surface. Cutler et al. <ref type="bibr" target="#b9">[10]</ref> present bimanual interaction research where the user can perform two-handed interactions to manipulate both their perspective and threedimensional models on a 3D tabletop display. Recently, Malik et al. <ref type="bibr" target="#b17">[18]</ref> explored using vision-based hand tracking over a tabletop surface to perform multi-finger and whole-hand gestures to interact with a remote display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DESIGN GUIDELINES</head><p>To address the precision problem of touch screen interactions we developed Dual Finger Selections, two finger (or bi-manual) interactions that allow the user to improve targeting precision when necessary without hindering simple targeting tasks. Dual Finger Selections were designed in an iterative fashion. During their development we followed the following guidelines: 1) Keep simple things simple: The ability to directly touch an object in order to select it (without any offset or displacement) is probably the most appealing aspect of touch screens. We aim to support this direct manner of interaction and require that further assistance is invoked only when the user explicitly requests it. 2) Provide an offset to the cursor when so desired: In addition to not occluding the cursor with the finger while pointing, a spatial offset between the finger and the cursor makes it possible to obtain a more comfortable position when pointing to hard to reach areas (for example: the corner of the screen). The offset should be user-invoked and temporary. Fixed permanent offsets (such as the one used in the Take-Off technique <ref type="bibr" target="#b20">[21]</ref>) require the users to continuously compensate their targeting even in situations when the target is large enough to be easily selected by direct touch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Enable the user to modify the control-display ratio:</head><p>Provide an increased control-display ratio when so desired to aid in targeting and to reduce tracking noise. This change of the control-display ratio should not involve the pointing finger. Before discussing the details of our dual finger selection techniques, it is important to outline the device requirements that enable our interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ENABLING TECHNOLOGIES</head><p>Our techniques require a multi-touch screen that is capable of simultaneously tracking at least two independent contacts on the surface. We also assume that in addition to the location of contacts, their contact areas are reported as well. A brief description of our prototype multi-touch device can be found later in this paper.</p><p>Since most touch screens and tabletops cannot identify which of the individual user's fingers or hands is touching the surface without special gloves <ref type="bibr" target="#b6">[7]</ref>, we have assumed that the first contact with a tabletop surface is a primary finger, while the second contact is a secondary finger. The primary finger is the finger that the user normally points with and tends to be the index finger on the dominant hand. The secondary finger is a helper finger which in Dual Finger Selections can be any other finger on the same or opposite hand. In most cases we observed that users used the index finger on their non-dominant hand as the secondary finger. With some interactions, a single-handed operation is desired, and then the thumb of the dominant hand can serve as a secondary finger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SimPress Clicking</head><p>In addition to disambiguating between fingers, our interactions require that the device implement a clicking operation distinct from merely coming in contact with the surface. Previous techniques that address this issue, such as Land-On or Take-Off <ref type="bibr" target="#b20">[21]</ref>, implicitly perform a "click" when the contact between their finger and the surface is either established or broken, respectively. Such techniques provide a mechanism for clicking, but do not address the needs of current user interfaces that require at least 3 different interaction states <ref type="bibr" target="#b7">[8]</ref>: out-of-range, tracking (also known as hover or proximity), and dragging. Both tracking and dragging states require the contact position to be continuously reported; however, most current touchsensitive devices only sense location when the contact is actually touching the surface, making it difficult to approximate those two states. A possible solution is to use pressure-sensing technology and map the increased pressure to a dragging state, and light pressure to a tracking state.</p><p>Since our device does not report pressure directly, we simulated a pressure-sensitive device by mapping the changes in the finger's contact area to the changes in pressure. In addition to applying different finger areas to different pressure states (which has been implemented in the Synaptics touchpad devices as described by MacKenzie et al. <ref type="bibr" target="#b16">[17]</ref>), we have attempted to reduce cursor noise while the user is changing the pressure states (clicking). The stabilization of the cursor movement during clicking is a crucial aspect of our technique, which we call SimPress (Simulated Pressure). SimPress requires the user to apply a small rocking motion with their finger in order to perform a "click", as seen in Figure <ref type="figure" target="#fig_0">2</ref>. Since the user starts pointing with their finger tip and then rocks the finger to click, the increase in area happens predominately in one direction: from the tip point towards the user's wrist. We used this fact to stabilize the cursor position by fixing the cursor location to the top middle point of the contact area, rather then the center of mass (Figure <ref type="figure" target="#fig_0">2</ref>). In our preliminary experiments, we found that this point naturally moves much less than the center point and therefore reduces the cursor noise during clicking.</p><p>By fixing the cursor to the top-middle point, the user is also able to make a more drastic change in the contact area without significantly disturbing the cursor location, which aids in reduction of the unintentional clicks. Two thresholds on contact area were established to disable spurious switching between the clicking states due to noise or hand tremor. Crossing the high threshold activates the click-on state, and crossing the low threshold returns back to clickoff state. Due to the finger size differences, these high and low thresholds should be automatically recalibrated for each person. Currently, the calibration is done manually.</p><p>SimPress only works if the user is always approaching the tabletop from the same direction, otherwise the orientation of the hand and arm has to be taken into account. A future improvement can potentially use the orientation of the click itself to track the orientation of the user's hand. However, given that in our experiments, the orientation of the user interface was fixed, our users tended to orient themselves straight-ahead. In our dual finger selection techniques, all click events are always triggered by the primary finger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DUAL FINGER SELECTIONS</head><p>Out of the five design prototypes, the first two present simple two-finger extensions of the current state of the art. However, those provide important starting points for our later designs and serve as baseline techniques for comparisons. Therefore, we include them in our discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Finger Offset</head><p>Our initial and simplest Dual Finger Selection technique, called Dual Finger Offset, provides a user triggered cursor offset. The cursor offset is not enabled by default. However, by placing a secondary finger anywhere on the surface, the cursor is subsequently offset with respect to the primary finger by predefined fixed amount. This offset always places the cursor above the primary finger. To accommodate both left-and right-handed users the cursor is placed to the left or to the right of the primary finger based on the relative position of the secondary finger. For example, by placing the secondary finger to the left of the secondary finger to the left of the primary, the cursor appears to the left of and above the primary finger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Finger Midpoint</head><p>To provide both variable offset and enable finer control of the cursor speed, we have designed the Dual Finger Midpoint technique. This technique is triggered by placing the secondary finger on the surface. The cursor is then offset to the midpoint between the primary and the secondary finger. A similar behavior occurs on any resistive touchpad that places the pointer at the midpoint of all touches (e.g., SMART Board Interactive Whiteboard <ref type="bibr" target="#b0">[1]</ref>).</p><p>While both fingers are in contact, moving either or both fingers controls the movement of the cursor. Clicking is still performed only by the primary finger. This technique allows for variable reductions in cursor speed: when both fingers are moving in the same direction and the same speed, the cursor follows with the same speed, while when only one finger is moving, the cursor moves with half the speed of that finger.</p><p>While the Dual Finger Midpoint technique was very appealing to our initial testers and very simple to master, it did not provide enough assistance for selecting the smallest targets (2 pixels or less). At best, this method reduces the finger speed by a factor of 2 which yields good results for most targets; but it does not provide enough control for the smallest targets. An additional shortcoming of this technique is that not all locations on the screen are equally accessible. For example, screen corners are not accessible using midpoint selection. Consequently, the utility of this technique is somewhat limited by the fact that in today's user interfaces small targets often are located in the corners of the screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Finger Stretch</head><p>Inspired by the strong performance of ZoomPointing technique <ref type="bibr" target="#b1">[2]</ref>, we designed a Dual Finger Stretch technique that allows the user to adaptively scale a portion of the screen with the secondary finger while the primary finger performs the selection. To allow for simultaneous "stretching" and selection, the primary finger provides the initial anchor location around which the user interface is scaled, while the secondary finger identifies the corner of the square area which will be scaled. By moving the secondary finger closer or further away from the primary finger, the square stretching area is reduced or expanded as illustrated in Figure <ref type="figure" target="#fig_2">4</ref>. Lifting the secondary finger from the table resets the interface to its default un-stretched state. Upon this reset, the cursor is offset with respect to the primary finger and is placed where it was located in the stretched state. The cursor offset is reset when all fingers are removed from the table. The extent of control-display ratio manipulation depends on two physical limits: the closest perceptible distance between user's fingers and the largest diagonal of the screen. For most common midscreen manipulations, Dual Finger Stretch enables controldisplay ratios roughly up to 10. By allowing clutching and repeated zooming, it may be possible to further increase this ratio.</p><p>The Dual Finger Stretch technique has several advantages over the ZoomPointing technique primarily due to the dual finger design. First, zooming and selection are not decoupled into two separate actions. Instead they can happen concurrently which results in a fluid interaction. Second, the interface scales in all directions from the original primary finger's location. This provides an important advantage over traditional rectangle selection where the two points specify the diagonal corners of the zooming rectangle (also known as bounding box zoom).</p><p>With the rectangle selection, the user tends to place the primary finger off target in order to "capture" the target in the zoomed area, while with Dual Finger Stretch, the user places the primary finger directly on target and the interfaces scales underneath in all directions. Placing the finger off-target requires the user's primary finger to traverse an increased distance to perform final selection because the target will appear to move away from the finger as the zoom level increases. By encouraging placement of the primary finger as close to the target as possible, the eventual distance that this finger will need to traverse to acquire the target is minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Finger X-Menu</head><p>To allow users to adaptively adjust the control-display ratio as well as obtain cursor offset while looking at an unzoomed user interface, we have designed the Dual Finger X-Menu widget. This circular menu is invoked whenever the secondary finger establishes contact with the surface. It is positioned so that the finger is located at its center. The user can select a particular assistance mode by moving the secondary finger to any of the desired regions of the menu (Figure <ref type="figure" target="#fig_4">5</ref>). Dual Finger X-Menu has six selection areas shown in Figure <ref type="figure" target="#fig_3">6</ref>. Four areas control the relative speed of the cursor: normal, slow 4X, slow 10X, and freeze. Normal mode moves the cursor with the same speed as the primary finger; the two slow modes reduce the speed of the cursor by a factor of 4 and 10 respectively, while freeze mode "freezes" the cursor in place, disabling any cursor movement.</p><p>In preliminary experiments, we found that the ability to completely stop the cursor from moving has two benefits. First, by freezing the cursor, the user can quickly and easily establish a desired cursor offset. This is accomplished by freezing the cursor temporarily, moving the finger to achieve the desired offset, and then unfreezing the cursor again. Second, when selecting very small targets, even small amounts of noise can cause an error. Such noise can be due to device tracking errors, tremor in the user's hand, or noise due to the clicking motion. By freezing the cursor in place, the user can ensure that the desired selection is successful even in very noisy conditions.</p><p>The left two areas on the crossing menu invoke two helper modes: "snap" and "magnify". When snapping is triggered, the cursor offset (if any) is removed and the cursor snaps   back to the current location of the primary finger. This mode is useful in repositioning the cursor in the slow movement modes because it is easy to run out of tracked screen space when using the slow cursor modes. Magnify mode presents a small magnification area in the middle of the crossing menu that shows the enlarged area under the cursor. The magnification factor is fixed at 2X. This mode is particularly useful when the primary finger overlaps the cursor. In this case the magnified image acts as a lens showing the portion of the interface obstructed by the primary finger. A simple cursor notification widget displays which cursor speed level is currently selected, without requiring the user to refer back to the menu. The behavior of this notification widget can be seen in Figure <ref type="figure">7</ref>.</p><p>Dual Finger X-Menu is not operated by clicking, but rather by "crossing" the finger into a particular area, which enables more experienced users to activate modes by simply performing quick strokes in a particular direction. With practice, this selection can be made without looking, and could therefore allow for an expert mode in which the menu could be completely hidden from the user. Removing the secondary finger from the surface will cause the menu to disappear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual Finger Slider</head><p>Encouraged by the possibilities of the different interaction modes of Dual Finger X-Menu and the simplicity of Dual Finger Midpoint, we developed the Dual Finger Slider technique, which incorporates the menu's most useful features, but simplifies and streamlines the overall interaction (Figure <ref type="figure">8</ref>). Given that two finger interactions are a very natural way of specifying distance, we have designed this interaction using the distance between fingers to switch between cursor speed reduction modes. This technique does not present an on-screen widget to the user. Instead, it relies completely on the user's ability to gauge the spatial relationship between their fingers. The same cursor notification widget (Figure <ref type="figure">7</ref>) is used to signal the cursor speed to the user.</p><p>Moving the secondary finger towards the primary finger reduces the cursor speed in 3 discrete steps. This allows for the same reductions in cursor speed that is available in Dual Finger X-Menu: normal, slow 4X, slow 10X, and freeze.</p><p>Moving the secondary finger away from the primary increases the speed up to the normal speed. Continuing to move the fingers apart triggers a "snap" which warps the cursor back to the primary finger's location. Snapping is signaled by a distinct sound effect. The distance that the secondary finger traverses in switching speed reduction modes is predefined and is not dependent on the distance between the fingers. The modes are remembered even after the user lifts the secondary finger which allows for clutching in the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROTOTYPE MULTI-TOUCH TABLETOP DISPLAY</head><p>Our interaction techniques are designed for present and future multi-touch screens, and to some extent, they are device independent. However, we have developed them on a prototype multi-touch tabletop display to facilitate research and user studies (see Figure <ref type="figure" target="#fig_6">9</ref>). The prototype uses a diffuse screen coupled with an infrared camera and computer vision algorithm to detect contacts on the tabletop surface. The screen is back-projected with the projector integrated in the base of the table below the screen. Our display uses the infra-red light spectrum for contact detection while all projection is done in the visible spectrum. This separation allows the computer vision algorithms to ignore the projected display in order to see only surface contacts. A similar approach is used in the TouchLight <ref type="bibr" target="#b25">[26]</ref> display system and elsewhere.</p><p>The screen resolution of our prototype multi-touch device is 1024 x 768 (pixels), which, given the screen dimensions of 61 x 46 (cm), yields a pixel size of 0.6mm. The finger that is about 1.5 cm wide covers about 25 screen pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LABORATORY USER STUDY</head><p>To evaluate the Dual Finger Selection and SimPress techniques, we conducted a user study that challenged the users to select small and large targets using the various techniques. Additionally, we were interested in how well these techniques perform on devices of very low precision. Such devices include touch screens based on a small number of sensing elements, touch screens based on noisy computer vision processes, and many prototype research systems which do not achieve the precision of the mouse (e.g. see <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>). Accordingly, in our experiments we added synthetic noise to the sensing system described above, and systematically varied its magnitude.</p><p>Twelve paid participants (9 male and 3 female), ages 20-40, participated in the experiment. All subjects were frequent computer users. They had varying experience with the touch screens, ranging from "monthly" use to "several times a day", with the average corresponding to "weekly" use. All subjects used their right hand as their dominant hand. Eleven subjects identified themselves as righthanded. The single left-handed subject preferred using their right hand for mouse operation and chose to use the right hand as the dominant pointing hand in the experiments. The subjects were pre-screened for color blindness.</p><p>The subjects were asked to perform a simple reciprocal target selection task, with square targets of varying widths, separated by a fixed distance of 100 pixels. This task is loosely based on the Fitts' Law target acquisition task, but without the variation of distance. The task involved clicking on a green square target that was surrounded by a green circle. The other (inactive) target was colored red and the targets alternated between trials. The users were instructed to click on the current green target as fast and as accurately as possible. We recorded both movement times and error rates, but we analyzed completion times only for successfully completed trials. We had hypothesized that the smallest targets might not be reliably selectable by all the techniques tested and therefore were more interested in the impact of our techniques on the reduction of error rate, than the completion time.</p><p>The experiment consisted of two parts: an evaluation of the SimPress technique and a comparative evaluation of the four dual finger selection techniques under varying amounts of noise. Both used the same testing infrastructure to present targets to the user, measure user performance and log all experimental data. In addition, the users completed a post-experiment user preference questionnaire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part One: SimPress Clicking</head><p>We wanted to determine the performance of SimPress clicking technique to obtain a baseline measure of the minimal target width that is possible to select reliably without additional assistance. An additional motivation was to ensure that our subjects mastered and were comfortable using SimPress, since we required them to use it throughout later experiments. Our subjects were first given an introduction to the SimPress technique and then allowed to perform 1 practice run before the actual experiment.</p><p>A within-subjects, repeated measures design was used consisting of 5 target widths (1, 2, 4, 8, and 16 pixels). The widths were chosen to represent the range of smallest available targets in a typical GUI. For example, the smaller toolbar buttons tend to be between 15 and 20 pixels wide, while the resize handles are sometimes less than 5 pixels wide. The experiment consisted of 5 sets (1 set per width) of 5 trials each, for a total of 25 trials per user. The order of the sets was randomized across users.</p><p>Our hypothesis was that the users would be able to reliably select only the largest of our small targets (16 pixels) and that the finger's occlusion of the target and the small amount of noise still present while clicking would make the selection of other target sizes difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We performed a repeated measures ANOVA on the mean error rate data and found the significant main effect with target width (F (4,44) =62.598, p&lt;0.001). The data are summarized in Figure <ref type="figure" target="#fig_8">10</ref>. Paired samples t-tests show no significant differences between the user's performance with 8 and 16 pixel targets. A significance difference in performance is shown between 2 and 4 pixel targets (t (11) =3.95, p=0.002) and 4 and 8 pixel targets (t (11) =4.16, p=0.002). The difference between 1 and 2 pixels is of borderline significance (t (11) =2.41, p=0.034).</p><p>Contrary to our hypothesis, we found that the threshold target size, below which the SimPress technique is not reliable alone, is around 8 pixels. These results show that SimPress is a viable option for use for most general selection tasks in the current user interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part Two: Comparison of Four Dual Finger Techniques</head><p>For the second part of the experiment, we tested the performance of our Dual Finger Selection by comparing the three most versatile techniques (Stretch, X-Menu and Slider) and the Offset technique. By providing no additional assistance other than the cursor offset, the Offset technique served as a baseline. Even though the Midpoint technique received very positive response from our initial testers, this technique was not included due to the relatively small assistance that it offered in selection (the maximum reduction of the cursor speed was a factor of 2) and lack of equal accessibility to all screen locations. Additionally, we were interested in how our techniques would perform in the presence of noisy input. We note that many touch screen devices provide noisier input than standard relative pointing devices such as a mouse. This is particularly true of a whole class of touch screen devices that depend on the video signal for their touch recognition. In addition to noise in the video stream, such devices often require that the video signal is up-sampled to match the screen's resolution. This up-sampling introduces additional sampling noise. In order to test how our techniques deal with increased noise, we added Gaussian noise to the position of each tracked finger, creating three noise levels: low (no additional noise), medium (Gaussian noise with σ=0.5), and high (Gaussian noise with σ=2).</p><p>While the noise can be reduced with a use of a filter (Kalman filter being the most commonly used), this solution either results in a slight cursor lag or overshoot when the finger's velocity abruptly changes, as is the case with any start or stop of the finger. We believe that there is a benefit to having interaction techniques that adaptively allow the user to reduce the noise when so desired, leaving the noisy, but lag-free, input otherwise. By manipulating the control/display ratio, Stretch, X-Menu, and Slider implicitly allowed the reduction of the input noise as well.</p><p>Our study followed a within subjects design that tested 3 noise levels, 4 techniques, and 4 target widths (1, 2, 4, and 8 pixels) per block. Within each block, the user performed 6 trials resulting in a total of 288 trials per user. To eliminate the effects of switching selection strategies (for example deciding to use a different cursor speed reduction for a different target size) we discarded the first trial in each block. All our techniques were modified to completely reset after each click in order to ensure the same starting state for all trials.</p><p>Our main hypothesis was that techniques that increase the control/display ratio lessen the impact of the input noise. Therefore, Stretch, X-Menu and Slider should be less affected by the increase in noise, than the Offset technique. The second hypothesis was that Slider would perform better than X-Menu since the Slider is controlled by the natural bimanual way of specifying spatial extent (finger distance), rather that the independent finger actions in X-Menu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We performed a 3 (Noise) x 4 (Technique) x 4 (Width) repeated measures ANOVA on the mean error rate data and found the significant main effects across all conditions. As expected, noise had a significant main effect on the error rate (F (2,22) =20.24, p&lt;0.001). This confirmed that more errors were committed in the higher noise levels. Significant main effects were also present for width (F (3,33) =150.4, p&lt;0.001) and technique (F <ref type="bibr" target="#b2">(3,</ref><ref type="bibr">33)</ref> =169.138, p&lt;0.001). Paired samples t-tests show that the Offset technique created significantly more errors than the rest (t (11) =14.298, p&lt;0.001), while Stretch was better than the X-Menu or Slider (t (11) =2.864, p=0.015). No significant difference was found in the error rate between X-Menu and Slider techniques.</p><p>The interaction of technique and width (F (9,99) =29.473, p&lt;0.001, Figure <ref type="figure" target="#fig_7">11</ref>) is interesting as it shows that our assistive techniques (Slider, X-Menu, and Stretch) all performed exceptionally well (less than 5% error rate) in all noise conditions for targets 2 pixels or larger (no statistical differences between techniques). For the smallest target (1 pixel), Stretch outperformed X-Menu and Slider (with borderline significance t (11) =2.64, p=0.023). The interaction of noise and technique was also significant (F (6,66) =8.025, p&lt;0.001, Figure <ref type="figure" target="#fig_10">12</ref>). While the increase of noise greatly degraded performance of the Offset technique, the other 3 techniques show no statistically significant effects to the various noise levels. This confirmed our main hypothesis  that users are able to lessen the impact of noise and low precision by using techniques that allow for control-display ratio adjustments.</p><p>Due to the dramatically high number of errors committed by our users using the Offset technique, our data contains several blocks without a single successful trial (all in 1 pixel width condition). While this prevented us from performing a repeated measures ANOVA on movement times, we present the informal analysis of median movement time values for blocks for which we have data. Median times were chosen to correct for the typical skewing due to reaction time data. This also removed the influence of any outliers in the data. Aggregating the movement times across all noise levels and all target widths, the Stretch technique is on average 1s faster than Slider (t (11) =5.011, p&lt;0.001). There do not appear to be statistical differences in the performance times of Slider and X-Menu. This failed to confirm our second hypothesis that Slider would outperform X-Menu. Offset's performance times were comparable to other techniques, indicating that users did not believe that spending more time on targeting would yield more precise targeting with Offset technique. Figure <ref type="figure" target="#fig_11">13</ref> shows the performance of techniques with respect to target width. The data shows a general trend of more time being spent on targeting smaller targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjective Evaluation</head><p>The users filled out a post-experiment questionnaire rating their experience with four techniques on a 5 point Likert scale (1 being most negative and 5 being most positive) They were asked to comment on the following categories: mental effort, learning time, hand fatigue, enjoyment, and performance in low, medium and high conditions.</p><p>Overall, techniques received significantly different results (F (3,33) =45.9, p&lt;0.001). X-Menu required the most mental effort (average score of 2.88), and the longest time to learn (average score of 2.09). Data shows no significant statistical differences between techniques with respect to hand fatigue. Stretching was the most enjoyable (average score of 4.12), followed closely by Slider technique (average score of 4.08). We also asked users to rate their overall preference for the technique for selecting small targets.</p><p>Stretch was the most preferred (7 subjects), followed by Slider (4 subjects), while only one user preferred X-Menu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION AND CONCLUSIONS</head><p>Out of the four compared techniques, the top performer and most preferred technique, Stretch, was the only one that did not provide a cursor offset. This clearly demonstrated that the benefit of increased target size successfully compensated for the fingertip occlusion factor. The data from this experiment is consistent with the results from a study by Albinsson and Zhai <ref type="bibr" target="#b1">[2]</ref> which also showed that their baseline zooming technique outperformed on-screen widgets that provided cursor speed control.</p><p>We feel that Dual Finger Stretch is a simple and powerful interaction that utilizes the distance between fingers in a very natural way. However, in many applications, scaling may have an undesired effect of losing overview of the interface. Therefore, we were very pleased with the strong performance of Slider and X-Menu, which provided comparable error rates with a small time penalty of about 1s when compared to Stretch. In addition, as our subjects' written comments point out, those techniques strongly benefit by the ability to freeze the cursor. As one subject describes, freezing the cursor is a functional equivalent to presenting a user-controlled "are you sure?" dialogue for clicking which enables the user to select a particular point without risk of mistake, or go back and re-target. This was particularly useful with higher noise levels. Experience should also substantially improve our Slider and X-Menu because zooming is a very familiar interaction for most users. As such, it might have an unfair advantage when compared to other speed-controlling techniques.</p><p>The SimPress clicking technique exceeded our performance expectations. This enables the novice users to reliably click on targets that are as small as 8 pixels. We believe that with practice and more thorough calibration, this threshold could be further reduced. Some future work on stabilization is needed in order to completely remove the remaining noise   from clicking. An additional SimPress modification was implemented, but not tested, permitting the user to rapidly click on targets without requiring the rocking motion. This timer solution generates a click event if the contact was present on the surface for less than 0.4 s. This allowed the simple selection of large targets to remain as direct as possible while more complex interactions, such as drag and drop, can be performed using the SimPress technique.</p><p>Our study results show that Dual Finger Selections present viable solutions for increasing precision and accuracy in a small target selection task. They are designed to be used on most multi-touch screens, perform well with the increase of input noise, and fully utilize the benefits of dual finger interactions. Overall, these techniques provide a palette of interactions from which the user may chose depending on the application.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. A small rocking motion of the user's finger triggers the SimPress clicking technique: a) tracking (hover) state, b) dragging (click) state. (The top left corners show the actual area of contact detected by our device as well as the stabilized cursor location.) a) b)</figDesc><graphic coords="3,316.98,544.74,241.02,118.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Dual Finger Midpoint technique positions the cursor at exactly the halfway point between the two fingers, giving the user both a cursor offset as well as a variable reduction of cursor speed.</figDesc><graphic coords="4,315.00,54.00,237.48,69.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Dual Finger Stretch technique adaptively scales the user interface: a) The secondary finger specifies the square zooming area centered at the primary finger's location, b) Primary finger performs precise selection while, simultaneously, the secondary finger adjusts the level of magnification.</figDesc><graphic coords="5,176.52,54.30,118.50,123.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Dual Finger X-Menu contains four selection areas for cursor speed control (normal, slow 4x, slow 10x and freeze), and two toggle areas (snap and magnify). Magnify mode presents an integrated magnification widget in the middle of the menu, while Snap mode removes the current cursor offset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Dual Finger X-Menu enables the user to adjust the cursor speed by crossing over a particular area of the on-screen menu. Freeze mode is selected, making the cursor completely immobile.</figDesc><graphic coords="5,315.00,54.00,241.02,118.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .Figure 7 .</head><label>87</label><figDesc>Figure 8. Dual Finger Slider -the right finger (primary) controls the cursor, the left finger (secondary) is invoking the invisible slider; speed reductions modes are achieved by moving the fingers closer together: a) normal, b) slow 4x, c) slow 10x, d) frozen cursor mode.</figDesc><graphic coords="6,316.98,311.28,241.02,88.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Our multi-touch back-projected tabletop display prototype uses an infra-red illuminant and camera to detect contacts through a diffuse surface.</figDesc><graphic coords="7,65.34,54.00,216.00,144.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Interaction of Noise x Technique graph for error rate (%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Mean error rate (%) using the SimPress technique alone without any assistance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Interaction of Technique x Width graph for error rate (%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Mean performance time (s) with respect to target widths. (Notice: time data is not shown for Offset technique at 1 pixel due to lack of successfully completed trials.)</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank Ed Cutrell, Ken Hinckley, and Steven Feiner, for their support and helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">SMART Technologies</orgName>
		</author>
		<ptr target="http://www.smarttech.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">High Precision Touch Screen Interaction</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Albinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;03</title>
		<meeting>CHI &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Snap-and-go: Helping Users Align Objects Without the Modality of Traditional Snapping</title>
		<author>
			<persName><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cutrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eversole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;05</title>
		<meeting>CHI &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="301" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cross-Dimensional Gestural Interaction Techniques for Hybrid Immersive Environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Benko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ishak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VR &apos;05</title>
		<meeting>IEEE VR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Toolglass and Magic Lenses: The See-Through Interface</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Derose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH &apos;93</title>
		<meeting>ACM SIGGRAPH &apos;93</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic Pointing: Improving Target Acquisition with Control-Display Ratio Adaptation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blanch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guiard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;04</title>
		<meeting>CHI &apos;04</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="519" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Bimanual Tool-Based Direct Manipulation Drawing Environment</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Amant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Habilisdraw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;04 Extended Abstracts</title>
		<meeting>CHI &apos;04 Extended Abstracts</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1301" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Issues and Techniques in Touch-Sensitive Tablet Input</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM SIGGRAPH &apos;85</title>
		<imprint>
			<biblScope unit="page" from="215" to="224" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Study in Two-Handed Input</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;86</title>
		<meeting>CHI &apos;86</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="321" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two-Handed Direct Manipulation on the Responsive Workbench</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fröhlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symposium on Interactive 3D Graphics</title>
		<meeting>Symposium on Interactive 3D Graphics</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DiamondTouch: a Multi-User Touch Technology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lehigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;01</title>
		<meeting>UIST &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DTLens: Multi-User Tabletop Spatial Data Exploration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;05</title>
		<meeting>UIST &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="119" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Finger Gestural Interaction with 3D Volumetric Displays</title>
		<author>
			<persName><forename type="first">T</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;04</title>
		<meeting>UIST &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Low-Cost Multi-touch Sensing Through Frustrated Total Internal Reflection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;05</title>
		<meeting>UIST &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="115" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Two-Handed Virtual Manipulation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Proffitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Kassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Two-Handed Input in a Compound Task</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kabbash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;94</title>
		<meeting>CHI &apos;94</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="417" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Comparison of Three Selection Techniques for Touchpads</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oniszczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;98</title>
		<meeting>CHI &apos;98</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interacting with Large Displays from a Distance with Vision-Tracked Multi-Finger Gestural Input</title>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;05</title>
		<meeting>UIST &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rubbing the Fisheye: Precise Touch-Screen Interaction with Gestures and Fisheye Views</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Supplement of UIST &apos;03</title>
		<imprint>
			<biblScope unit="page" from="83" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sensetable: A Wireless Object Tracking Platform for Tangible User Interfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Patten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pangaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;01</title>
		<meeting>CHI &apos;01</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving the Accuracy of Touchscreens: An Experimental Evaluation of Three Strategies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Proc. CHI &apos;88</title>
		<meeting>CHI &apos;88</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SmartSkin: an Infrastructure for Free-hand Manipulation on Interactive Surfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rekimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI &apos;02</title>
		<meeting>CHI &apos;02</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving Selection Performance on Pen-Based Systems: A Study of Pen-Input Interaction for Selection Tasks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moriya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Human Interaction</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="384" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">High Precision Touchscreens: Design Strategies and Comparisons with a Mouse</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Man-Machine Studies</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="593" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PlayAnywhere: A Compact Tabletop Computer Vision System</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;05</title>
		<meeting>UIST &apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An Imaging Touch Screen and Display for Gesture-Based Interaction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><surname>Touchlight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICMI &apos;04</title>
		<meeting>ICMI &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-Finger and Whole Hand Gestural Interaction Techniques for Multi-User Tabletop Displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST &apos;03</title>
		<meeting>UIST &apos;03</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
