<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrated Active Contours for Texture Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chen</forename><surname>Sagiv</surname></persName>
							<email>chensagi@post.tau.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">Nir</forename><forename type="middle">A</forename><surname>Sochen</surname></persName>
							<email>sochen@post.tau.ac.il</email>
						</author>
						<author>
							<persName><forename type="first">Yehoshua</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
							<email>zeevi@ee.tech-nion.ac.il</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>Columbia</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Technion-Is-rael Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Integrated Active Contours for Texture Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8EBE3A5B9C9351562EB532191F24A84B</idno>
					<idno type="DOI">10.1109/TIP.2006.871133</idno>
					<note type="submission">received February 18, 2004; revised December 8, 2004.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T03:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Active contours without edges</term>
					<term>anisotropic diffusion</term>
					<term>Beltrami framework</term>
					<term>Gabor analysis</term>
					<term>geodesic active contours</term>
					<term>image manifolds</term>
					<term>texture segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We address the issue of textured image segmentation in the context of the Gabor feature space of images. Gabor filters tuned to a set of orientations, scales and frequencies are applied to the images to create the Gabor feature space. A two-dimensional Riemannian manifold of local features is extracted via the Beltrami framework. The metric of this surface provides a good indicator of texture changes and is used, therefore, in a Beltrami-based diffusion mechanism and in a geodesic active contours algorithm for texture segmentation. The performance of the proposed algorithm is compared with that of the edgeless active contours algorithm applied for texture segmentation. Moreover, an integrated approach, extending the geodesic and edgeless active contours approaches to texture segmentation, is presented. We show that combining boundary and region information yields more robust and accurate texture segmentation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>are extracted, e.g., the magnitude of the response of the Gabor filters and particular moments which are calculated from local histograms <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b41">[42]</ref>.</p><p>An introduction of a measure on the texture characteristic features is the heart of the third stage of processing. The measure indicates how much variability is characteristic of the texture. Kulback-Leibler, mutual information, gradients, and other distance measure are typical for this stage.</p><p>Finally, some objective function can be defined using the texture features, and the segmentation is formulated as an optimization, minimization or clustering problem. In region-based algorithms the third and fourth stages become inseparable.</p><p>The texture segmentation algorithm proposed in this study is based on a generalization of the geodesic active contours model from the one-dimensional intensity-based feature space to a multidimensional space of texture features. The Gabor-Morlet transform is applied to the image, in the first stage, using self similar and rotated Gabor functions. At the second stage, features yielding maximum response for the Gabor filters, are selected for each pixel in the image <ref type="bibr" target="#b40">[41]</ref>; this choice defines a subspace of the spatial-feature space. Alternatively, the complete set of the Gabor responses may be selected as features. In the third step a texture edge indicator is defined. Its construction is one of the main contributions of this paper, and we refer to it when describing the Beltrami framework. Finally, a new form of geodesic active contours mechanism is applied to obtain the segmentation. We also study the integration of this active contours model with the edgeless active contours model proposed by Chan et al. <ref type="bibr" target="#b3">[4]</ref>, which was recently extended to texture segmentation <ref type="bibr" target="#b44">[45]</ref>. This approach is based on a general model that was recently developed by Kimmel <ref type="bibr" target="#b22">[23]</ref>, which combines active contours with and without edges.</p><p>An important aspect of our research is how to obtain the texture gradients information. We base our work on the approach developed by Kimmel, Sochen, and Malladi <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> who have shown that the Gabor spatial-feature space can be described, via the Beltrami framework <ref type="bibr" target="#b46">[47]</ref>, as a four-dimensioanl Riemannian manifold embedded in . Using this framework, the Gabor feature space is elaborated for representation, processing and segmentation of textured images via diffusion and curve evolution partial differential equation (PDE) flows applied in this space.</p><p>The construction of the "texture edge indicator," and of the generalized stopping term, in the context of texture-based geodesic active contours, begins with an analysis and a revised viewpoint of the form of the stopping term in the intensity-based geodesic active contours. It is shown that it can be interpreted, via the Beltrami framework, in terms of the Riemannian structure on the two-dimensional (2-D) surface described by the graph of the intensity function. In order to define a meaningful texture gradient the chosen feature subspace is represented, via the Beltrami framework, as a submanifold. This submanifold inherits a Riemannian structure, i.e., the induced metric, from the full spatial-feature space. The metric introduced in the Gaborian subspace is used to derive the inverse edge indicator function , which attracts in turn the evolving curve toward the texture boundary in the geodesic active contours scheme.</p><p>The main contributions of this work are as follows. First, we derive an edge indication function in the Gabor feature space of the images, by viewing this feature space as a manifold. The determinant of this manifold's metric is interpreted as a measure for the presence of gradients on the manifold. This is because the integral over the square root of the determinant of the metric is simply the area of the manifold. When the contribution of the integrand is large, this means that the area of this part of the manifold is large comparing to the projected area on theplane. This is an indication for the existence of large gradients.</p><p>Second, while we look for gradients in the Gabor feature space, Sandberg et. al <ref type="bibr" target="#b44">[45]</ref> are interested in the homogeneity of the Gabor features and apply the vector valued active contours without edges algorithm to this space. We compare the conceptual features and performance of the geodesic snakes and the active contours without edges approaches using synthetic and real life examples, and explore the idea of combining these two approaches into a single segmentation procedure for textured images. This idea is a generalization of a recent publication of Kimmel <ref type="bibr" target="#b22">[23]</ref>, but innovative in expanding the scalar case to a more general vectorial case with application of this idea to the Gabor feature space.</p><p>We begin by briefly reviewing related studies dealing with texture segmentation. Then we present the Gabor transform, feature space generation, the Beltrami framework and geodesic active contours. We review the Gaborian submanifold generation and diffusion, and then the application of the active contours with and without edges in the Gabor feature space. Finally, a combined approach utilizing both geodesic contours and edgeless active contours is considered. Results are compared with those obtained by using the unsupervised "edgeless" texture segmentation technique <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED STUDIES</head><p>Texture representation and modeling can be roughly divided into two classes: statistical-based approaches and filtering-based approaches. Statistical modeling is based on the assumption that each texture has unique statistical attributes. Among them are: local statistical features <ref type="bibr" target="#b6">[7]</ref>, random field models <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b30">[31]</ref>, co-occurence matrices <ref type="bibr" target="#b11">[12]</ref>, second order statistics <ref type="bibr" target="#b5">[6]</ref>, statistics of texton attributes <ref type="bibr" target="#b18">[19]</ref>, local linear transforms <ref type="bibr" target="#b47">[48]</ref>, and a gaussian distribution modeling of the structure tensor <ref type="bibr" target="#b39">[40]</ref>.</p><p>The filtering modeling is based on applying some filter bank to the image and considering the filters' responses as information about the local behavior of the image. A popular choice are the Gabor filters. The motivation for the use of Gabor filters in texture analysis is double fold. First, it is believed that simple cells in the visual cortex can be modeled by Gabor functions <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b31">[32]</ref>, and that the Gabor scheme provides a suitable representation for visual information in the combined frequency-position space <ref type="bibr" target="#b36">[37]</ref>. Second, the Gabor representation has been shown to be optimal in the sense of minimizing the joint 2-D uncertainty in the combined spatial-frequency space <ref type="bibr" target="#b12">[13]</ref>. The analysis of Gabor filters was generalized to multiwindow Gabor filters <ref type="bibr" target="#b52">[53]</ref> and to Gabor wavelets <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b52">[53]</ref>, and studied both analytically and experimentally on various classes of images <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b52">[53]</ref>. Most approaches use the power spectrum of the Gabor filtered images. The local phase information obtained by Gabor filtering was also used for simple test images <ref type="bibr" target="#b9">[10]</ref>. Nevertheless, it seems that utilizing the phase information still requires further investigation. The wavelets approach to texture modeling was also considered <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b47">[48]</ref>. Some approaches combine statistical modeling, structural modeling and the filter bank model. The FRAME theory proposed by Zhu et al. <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref> combines the use of filters, random fields and maximum entropy as a unified approach for texture modeling.</p><p>Once the representation space is selected, texture features are obtained and the segmentation procedure evolves in a boundary-based approach, or a region-based approach. Here, we review some of the schemes already proposed for texture segmentation. We focus on those schemes which either use the Gabor representation or minimization of energy functionals approaches. Lee et al. <ref type="bibr" target="#b27">[28]</ref> attempted to use the Gabor feature space for segmentation, by implementing a variant of the Mumford&amp;ndash;Shah functional adapted to signature vectors in the Gabor space. Porat and Zeevi <ref type="bibr" target="#b37">[38]</ref> proposed using localized features based on the Gabor transform of the image, and computed for this purpose the mean and variance of the localized frequency, orientation and intensity. In a previous study <ref type="bibr" target="#b41">[42]</ref>, we applied a Beltrami-based multivalued snakes algorithm to this feature space. Jain and Farrokhnia <ref type="bibr" target="#b17">[18]</ref> used Gabor filters to obtain texture features by subjecting each filtered image to a nonlinear, threshold-like transform, and computing a measure of "energy" in a window around each pixel. A square error clustering algorithm was then used to produce segmentation. Manjunath and Ma <ref type="bibr" target="#b29">[30]</ref> defined features vector whose components are the responses of the Gabor channels. They used the Euclidean distance between these vectors as a criterion for similarity between textures. Kim et al. <ref type="bibr" target="#b21">[22]</ref> viewed the segmentation problem as a maximization of the mutual information between region labels and the image pixel intensities, subject to a limitation on the length of region boundaries. Hofmann et al. <ref type="bibr" target="#b16">[17]</ref> considered the homogeneity between pairs of texture patches by a nonparametric statistical test applied to the Gabor space. A pairwise data clustering algorithm was utilized to perform segmentation. In Paragios and Deriche <ref type="bibr" target="#b35">[36]</ref>, a supervised variational framework was developed, where the responses of isotropic, anisotropic and Gabor filters applied to the texture image were considered as multicomponent conditional probability density functions. This information served as the stopping term in a variation of the geodesic snakes mechanism. Rousson et al. <ref type="bibr" target="#b39">[40]</ref> extracted texture features using the gray level values and a structure tensor which is defined using smoothed versions of image derivatives. Then, assuming a Gaussian model for the elements of the structure tensor and Parzen density for the image intensity channel, an energy functional that is the a posteriori partitioning probability is maximized. Zhu et al. <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref> proposed an approach called region competition, unifying snakes, region growing and Bayes/MDL criterion by the application of a variational principle for multiband image segmentation. This algorithm integrates the geometric benefits of the snakes/balloons mechanism with the benefits of the statistical modeling used in region growing. Sandberg et al. <ref type="bibr" target="#b44">[45]</ref> applied a vector-valued active contour without edges mechanism <ref type="bibr" target="#b3">[4]</ref> to the Gabor filtered images. Vese and Osher <ref type="bibr" target="#b48">[49]</ref> used a model which assumes that an image is a linear combination of some bounded variation function, a "cartoon" approximation of the image, and an oscillatory function which represents texture or noise, following a model proposed by Meyer <ref type="bibr" target="#b32">[33]</ref>.</p><p>In the framework presented here, we are interested in defining "texture gradients" and utilizing them in the geodesic snakes mechanism, to determine the texture boundaries. The geodesic snakes mechanism is rooted in the popular "snakes," or active contours segmentation algorithm proposed by Kaas et al. <ref type="bibr" target="#b19">[20]</ref>. In this framework, an initial contour is deformed toward the boundary of an object to be detected. The evolution equation is derived from minimization of an energy functional, which obtains a minimum for a curve located at the boundary of the object. The geodesic or geometric active contours model <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b20">[21]</ref> offers a different perspective for solving the boundary detection problem; it is based on the observation that the energy minimization problem is equivalent to finding a geodesic curve in a Riemannian space whose metric is derived from image content. The geodesic curve can be found via a parameterization invariant geometric flow. Utilizing the Osher and Sethian level set numerical algorithm <ref type="bibr" target="#b38">[39]</ref> allows automatic handling of changes of topology. This snakes' model was extended to account for vector-valued active contours, and to handle more complex scenery such as color images <ref type="bibr" target="#b45">[46]</ref> and multitexture images <ref type="bibr" target="#b41">[42]</ref>. Goldenberg et al. <ref type="bibr" target="#b14">[15]</ref> offer a fast algorithm based on the AOS scheme for geodesic active contours and generalize it to color images.</p><p>An edgeless active contours model was recently proposed by Chan and Vese <ref type="bibr" target="#b53">[54]</ref>. It is also based on techniques of curve evolution and level set methods, but the gradient-based information is replaced by a criterion which is related to region homogeneity. The active contours without edges model was extended to vector valued images <ref type="bibr" target="#b3">[4]</ref> and specifically to texture segmentation <ref type="bibr" target="#b44">[45]</ref>. Chan and Vese <ref type="bibr" target="#b53">[54]</ref> use a reduced form of the Mumford-Shah functional <ref type="bibr" target="#b34">[35]</ref> where the image is approximated by a piecewise constant function. They add a regularity term that controls the contour's smoothness which is its arc length. Kimmel <ref type="bibr" target="#b22">[23]</ref> proposed to incorporate a more general weighted arclength in the edgeless active contours method. The arclength is weighted by a function of the image's gradients. This addition is practically the geodesic active contours functional. In his work, he combines the Chan-Vese approach with the geodesic active contours model, along with an alignment term which gets high values if the normal to the curve aligns with the direction of the image's gradient.</p><p>Motivated by the basic approach of the Mum-ford&amp;ndash;Shah functional <ref type="bibr" target="#b34">[35]</ref>, which combines piecewise smoothness with the existence of edges, and by the studies of a general model which combines active contours with and without edges <ref type="bibr" target="#b22">[23]</ref>, we also apply the integrated active contours model (IAC) (with and without edges) to the problem of texture segmentation. Thus, we offer a new mechanism for the concept of "texture gradients" which is based on the metric of the Gabor features space manifold, and combine the information on the gradients of the Gabor features with the information on the homogeneity of these features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gabor Transform and Feature Space</head><p>A Gabor filter centered at the 2-D frequency coordinates has the general form of ( <ref type="formula">1</ref>)</p><p>where</p><p>(3)</p><p>and is the aspect ratio characterizing the elliptic Gaussian window, is the scale parameter, and the major axis of the Gaussian is oriented at angle relative to the axis and to the modulating sinewave gratings. Accordingly, the Fourier transform of the Gabor function is (4) where, and are rotated frequency coordinates. Thus, is a bandpass Gaussian with its minor axis oriented at angle from the axis, and the radial center frequency is defined by: , with orientation . Since maximal resolution in orientation is desirable, the filters whose sinewave gratings are co-oriented with the major axis of the modulating Gaussian are usually considered ( and ), and the Gabor filter is reduced to <ref type="bibr" target="#b4">(5)</ref> It is possible to generate Gabor wavelets from a single mother-Gabor wavelet by transformations such as: translations, rotations and dilations. We can generate, in this way, a set of filters for a known number of scales and orientations <ref type="bibr" target="#b5">(6)</ref> where are the spatial coordinates rotated by and scaled by powers . The responses of Gabor wavelets in the frequency spectrum can be seen in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Alternatively, one can obtain Gabor wavelets by logarithmically distorting the frequency axis <ref type="bibr" target="#b36">[37]</ref> or by incorporating multiwindows <ref type="bibr" target="#b52">[53]</ref>. In the latter case, one obtains a more general scheme wherein subsets of the functions constitute either wavelet sets or Gaborian sets.</p><p>There are several degrees of freedom in selecting the family of Gabor filters to be used: number and values of scales, frequencies, and orientations. In order to obtain good segmentation results, the filters should be carefully selected, so that they represent the data and the differences in textures within the data in an accurate way. Although some techniques were suggested to obtain such selection <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b49">[50]</ref>, they are complex to implement, and we manually selected the number of orientations and the values of scales and frequencies. Our selection was also motivated by the guidelines offered by Lee <ref type="bibr" target="#b26">[27]</ref>.</p><p>The feature space of an image is obtained by the inner product of this set of Gabor filters with the image: <ref type="bibr" target="#b6">(7)</ref> Once this feature space is generated, one may use all channels, or use an appropriate subspace. In this study, the features space is either the full set of Gabor coefficients (for all scales, orientations and frequencies) or only the maximal value of Gabor coefficients at each pixel location, when maximization is done per scale, orientation and frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Beltrami Framework</head><p>Sochen et al. <ref type="bibr" target="#b46">[47]</ref> proposed to view images and image feature spaces as Riemannian manifolds embedded in a higher dimensional space. Their approach, rooted in high-energy physics, is based on the Polyakov action functional which weights the mapping between the image manifold (and its metric) and the image features manifold (and its corresponding metric). The term image manifold is used here as the surface formed by the graph of the image (not to be confused with the space of all images). This functional can be minimized with respect to the image features manifold parameters (embedding space), the Riemannian structure (the metric parameters), or both. It was shown that different choices for minimization lead to different known flows <ref type="bibr" target="#b46">[47]</ref>, e.g., the heat flow, a generalized Perona-Malik flow and the mean curvature flow.</p><p>Using the Beltrami framework, the image is viewed as a 2-D manifold, which represents the spatial extent of the image, embedded in a multidimensional feature space. Formally, an image is described as a section of a fiber bundle. The base manifold of the bundle is the image domain and the fiber is the feature space. A choice of a point in the feature space for each point in the base manifold is called a section. Thus, image analysis turns into analysis of manifolds (sections). The most important concept related to our research is determining distances on the manifold. In many applications, the notion of distance between two locations on the image refers not only to the spatial distance, but also to the "information" part of the distance between points. This can be calculated for example by Euclidean or the Kullback-Leibler distance measures. The Beltrami framework offers a natural choice for distances measurements, as the "information" distance between points in the image turns into distance between points on the image manifold; This can be calculated using the manifold's metric.</p><p>As a simple example, let us examine a gray scale image . It can be viewed as a 2-D Riemannian surface (manifold), with as local coordinates, embedded in with as local coordinates. The relation is given by ( , ,</p><p>). When we consider feature spaces of images, e.g., color space, statistical moments space, and the Gaborian space, we may view the image-feature information as a -dimensional manifold embedded in a dimensional space, where stands for the number of local parameters needed to index the manifold of interest and is the number of feature coordinates. For example, the Gabor transformed image can be viewed as a 2-D manifold with local coordinates embedded in a seven-dimensional (7-D) feature space. The embedding map is , where and are the real and imaginary parts of the Gabor transform value, and , , and are the direction, scale and frequency for which a maximal response has been obtained.</p><p>We are interested in measuring distances on the manifold. For example, consider a 2-D manifold with local coordinates . Since the local coordinates are curvilinear, the distance is calculated using a positive definite symmetric bilinear form called the metric whose components are denoted by <ref type="bibr" target="#b7">(8)</ref> where the Einstein summation convention is used: elements with identical superscripts and subscripts are summed over.</p><p>How is the metric on the manifold chosen? This can be done using either a variational or a geometric approach. In the variational approach the Polyakov action is minimized with respect to the metric <ref type="bibr" target="#b46">[47]</ref>. The resulting Euler-Lagrange equation is solved analytically and the minimizing metric is the induced metric. We describe below how the induced metric is obtained, from a geometric point of view, via the pullback procedure.</p><p>Let be an embedding of in , where is a Riemannian manifold with a metric . is another Riemannian manifold, and thus has its own metric. We assume that the embedding of in is isometric and thus we may use the knowledge of the metric on and the map to construct the metric on . This pullback procedure is as follows: <ref type="bibr" target="#b8">(9)</ref> where we use the Einstein summation convention, , and are the local coordinates on the manifold . We actually use the Jacobian, , of the smooth map to obtain the metric of from the metric of ; the jacobian of the mapping should be computed, and for an Euclidean embedding space with a Cartesian coordinate system (as is the case here), the desired metric can be obtained by multiplying the transpose of that jacobian by the jacobian itself:</p><p>. If we pull back the metric of a 2-D image manifold from the Euclidean embedding space we get <ref type="bibr" target="#b9">(10)</ref> In the more general case of higher dimensional feature space , the metric is given by <ref type="bibr" target="#b10">(11)</ref> It turns out that the inverse of the metric's determinant can serve as a good edge detector. The rationale behind this is as follows: The metric is used to measure distances on manifolds, and its components indicate the rate of change of the manifold given a specific direction. Therefore, when the determinant of has a value which is much larger than unity, it indicates the presence of a strong gradient on the manifold. A value which is close to unity indicates a region where the manifold is almost flat. Thus, we may select as an edge indicator the inverse of the determinant of . Moreover, the metric's determinant gives an indication for the ratio between the size of an area element when measured on the manifold and when measured on theplane. The larger the metric, the less horizontal this patch of the manifold (thus contains an edge).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. GEODESIC ACTIVE CONTOURS</head><p>We review the geodesic active contours method for nontextured images according to the formalism presented in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b20">[21]</ref>.</p><p>Let be a parametrized curve, and let be the given image. Let be an inverse edge detector, so that approaches zero when approaches infinity. Visually, should represent the edges in the image, so that we can judge the "quality" of the stopping term by the way it represents the edges and boundaries in an image. Thus, the stopping term has a fundamental role in the geodesic active snakes mechanism; if it does not well represent the edges, application of the snakes mechanism is likely to fail. Minimizing the energy functional proposed in the classical snakes is generalized to finding a geodesic curve in a Riemannian space by minimizing <ref type="bibr" target="#b11">(12)</ref> We may consider this term to be a weighted length of a curve, where the Euclidean length element is weighted by a factor , which contains information regarding the boundaries in the image. The resultant evolution equation is the gradient descent flow <ref type="bibr" target="#b12">(13)</ref> where denotes curvature and is a unit vector which is normal to the curve.</p><p>Defining a function , so that , we may use the Osher-Sethian level-sets approach <ref type="bibr" target="#b38">[39]</ref> and replace the evolution equation for the curve with an evolution equation for the embedding function <ref type="bibr" target="#b13">(14)</ref> A popular choice for the stopping function is given by: <ref type="bibr" target="#b28">[29]</ref>, but other image-specific functions may also be used. For gray level images, this expression coincides with the determinant of the image's manifold, . Thus, we can rewrite the expression for the stopping term in the geodesic snakes mechanism as follows: <ref type="bibr" target="#b14">(15)</ref> The importance of the Beltrami framework for segmentation, in general, and for texture segmentation in particular, is that it offers a general tool for evaluation of gradients on the image manifold regardless of the features used. Given a set of texture features, we can derive the metric of the image manifold embedded in that feature space, and use it as described to create the edge indicator function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. GABORIAN SUBMANIFOLD</head><p>We choose, in the Gabor feature space, a submanifold of most relevant information for the determination of texture boundaries. We may interpret the Gabor transform of an image as a function assigning to each pixel's coordinates, scale, orientation and frequency, a value . In this study, we select texture features to be either the Gabor responses per scale, orientation and frequency, or alternatively, the scale, orientation and frequency for which maximum amplitude of the transform is obtained at each pixel. Thus, for each pixel, we obtain:</p><p>, the maximum value of the transform, , , and , i.e., the orientation, scale and frequency that yield this maximum value. Whatever the features selection is, it can be naturally represented as a 2-D manifold [with local coordinates ], embedded in a higher dimensional space. This initial manifold is noisy and should be regularized before it can be used. We use here the Beltrami flow with a regularized metric. In order to proceed, we need to define the Riemannian structure on this submanifold. Using the pullback mechanism described earlier, we get the following metric: <ref type="bibr" target="#b15">(16)</ref> where indicates the relevant Gabor features , and accounts for the different weights given to each Gabor feature. As stated earlier, the texture features can be the Gabor response, the scale, the orientation, or the frequency. Each feature has its own range of values. Thus, in order to obtain a meaningful metric, the weights are used to obtain the same numerical range for all features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. GABOR FEATURE SPACE DIFFUSION</head><p>In the previous section, we have described how the Gabor feature space can be treated as a 2-D manifold embedded in a higher dimensional space. We have used a maximum criterion to obtain a single orientation, scale and frequency for each pixel location. This selection has the advantage of being simple. However, it does not always well represent the textural information and is sensitive to local variations in texture characteristics. The resultant Gabor features can, therefore, be quite noisy. The full set of Gabor responses per scale, orientation and frequency can also suffer from noise. Thus, it is desirable to reduce the amount of noise in the Gaborian features and obtain a smoother function to be used in the geodesic snakes mechanism (e.g., <ref type="bibr" target="#b43">[44]</ref>). We present two approaches: the first is the Beltrami flow, applied to texture features which were selected according to the maximum criterion, and the second is a Gaussian-Beltrami flow, applied to the full set of Gabor responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gabor Feature Space Diffusion Via the Beltrami Flow</head><p>In the framework of the Beltrami approach, an energy functional is defined to minimize an area element of a manifold. We consider first how to implement Beltrami diffusion for each feature separately. A coupled scheme is presented in Section VI-A2.</p><p>1) Gabor Feature Space Diffusion Via the Beltrami Flow: Let us take, for example, the orientation feature manifold, which is a 2-D manifold with local coordinates embedded in a three-dimensional feature space . The energy functional is defined as <ref type="bibr" target="#b16">(17)</ref> where is the determinant of the metric of the Gabor features manifold.</p><p>For the orientation feature manifold , this metric is given by <ref type="bibr" target="#b17">(18)</ref> The resultant gradient descent process is the Beltrami flow for the orientation feature . According to the Euler-Lagrange method, we get <ref type="bibr" target="#b18">(19)</ref> where According to the steepest descent method, the evolution equation is <ref type="bibr" target="#b19">(20)</ref> Note that this is identical to Beltrami diffusion for gray level images, as was already presented earlier <ref type="bibr" target="#b23">[24]</ref>. Here, this flow is simply applied to each Gaborian feature.</p><p>2) Gabor Feature Space Diffusion Via a Coupled Beltrami Flow: The coupling term in the coupled Beltrami flow is the metric. In the previous section, each Gaborian component is Beltrami-diffused in a stand alone approach. Here, we define an energy functional which minimizes an area element of the features' manifold, which is a 2-D manifold with local coordinates embedded in a 7-D feature space <ref type="bibr" target="#b20">(21)</ref> where is the determinant of the metric of the Gabor features manifold, given, in general, for any number of features each weighted by [see <ref type="bibr" target="#b15">(16)</ref>]. For the Gabor feature submanifold of maximal feature responses , we assign a metric by the pullback mechanism as follows: <ref type="bibr" target="#b21">(22)</ref> The combination , an area element of the Gabor features manifold, is the term that forces smoothing as the features field reduces its overall area when it flows toward the optimal solution. The resultant gradient descent process is the Beltrami flow for each Gaborian feature. Let represent one of the Gaborian features, then according to the Euler-Lagrange method <ref type="bibr" target="#b22">(23)</ref> where According to the steepest descent method, the evolution equations are <ref type="bibr" target="#b23">(24)</ref> We obtain a set of coupled evolution equations. The update of the values of , , , , is done at the end of each iteration.</p><p>In order to further regularize the process, one can smooth the metric before applying the Beltrami flow. To regularize the metric, we first convolve each feature channel with a Gaussian kernel and only then calculate the derivatives and construct the metric. Once the metric is obtained, we denoise the features with the Beltrami flow as is derived above. This presmoothing of the metric yields a more robust and accurate submanifold, which, in turn, yields a better texture edge detector and a more accurate and robust segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Gabor Feature Space Diffusion Via a Gaussian-Beltrami Flow</head><p>The Beltrami diffusion flow is characterized by its edge preserving ability, in comparison to linear operators. It is advantageous to use bigger stencil for the calculation of the metric in order to improve the robustness of the Beltrami diffusion. The metric used for the Gaussian-Beltrami flow is calculated using gaussian smoothed derivatives of the image. For a gray-level image, the metric is usually calculated as <ref type="bibr" target="#b24">(25)</ref> where and are the image derivatives. For the Gaussian-Beltrami scheme, we convolve the image derivatives with a relatively large gaussian filter , and the metric is then given by <ref type="bibr" target="#b25">(26)</ref> Using a linearly smoothed metric as the edge indicator has the advantage of being more robust, its edge preservation quality is kept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. GABOR-SPACE GEODESIC ACTIVE CONTOURS WITH AND WITHOUT EDGES</head><p>In this section, we review the geodesic snakes and the active contours without edges models applied to the Gabor feature space. We also present the integration of the two models as an extension of the work of Kimmel <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gabor-Space Geodesic Active Contours</head><p>Having the essential components of the formalism presented so far, it is straightforward to generalize the geodesic active contours algorithm to texture segmentation. Based on the defined 2-D submanifold of texture features, and using the natural Riemannian metric defined on it, we proceed to build the key ingredient of the geodesic active contours algorithm, namely the stopping function. We construct it in an analogous way to the intensity-based algorithm <ref type="bibr" target="#b26">(27)</ref> Using this stopping term in the context of the Osher-Sethian formulation yields <ref type="bibr" target="#b27">(28)</ref> The zero crossings of the resulting generates the desired segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Active Contours Without Edges for Texture Segmentation</head><p>The active contours without edges model was extended to vector valued images, in general, <ref type="bibr" target="#b3">[4]</ref>, and was applied to the Gabor space of images for texture segmentation <ref type="bibr" target="#b44">[45]</ref>. The multivalued information is the magnitude of the Gabor transforms obtained when convolving Gabor filters with the image. Let be the textured image, and , , be Gabor transforms of the original image , obtained for different scales, orientations and frequencies. Let be the evolving contour, and and the averages of the Gabor channel inside and outside the curve , respectively. The following energy functional is minimized with respect to , , and <ref type="bibr" target="#b28">(29)</ref> where and are fixed parameters for each channel. Note that the first term is merely the arc-length of the curve. Using the level sets algorithm <ref type="bibr" target="#b38">[39]</ref>, the Euler-Lagrange equation for the level set , which is defined via , is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Combined Energy Functional and Evolution Equation</head><p>Following the model developed by Kimmel <ref type="bibr" target="#b22">[23]</ref> for gray level images, we generalize the active contours model with and without edges to texture segmentation. The energy functional to be minimized can be seen as a natural extension of the Chan and Vese functional, where the term which accounts for the arc length of the curve is replaced by the geodesic length of the curve, which is weighted by the gradient information <ref type="bibr" target="#b30">(31)</ref> where will be calculated as the inverse of the determinant of the features submanifold's metric. Again, the level sets algorithm <ref type="bibr" target="#b38">[39]</ref> is used, and the Euler-Lagrange equation for a level set is <ref type="bibr" target="#b31">(32)</ref> where is the derivative of a regularized Heaviside function. The zero-crossings of the resulting generates the desired segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RESULTS</head><p>To demonstrate the performance of the proposed method, both synthetic and natural images are used. The Gabor feature space is generated for this purpose and the texture features, being the Gabor responses per channel or the maximum response in scale, orientation and frequency, are obtained. The metric of the image manifold embedded in the higher dimensional feature space is calculated, and used to obtain a texture edge detector, to be used in the geodesic active contours mechanism or in the combined model. The selection of the Gabor filters is fine-tuned to obtain the best texture representation. The geodesic snakes mechanism is initialized with a signed distance function.</p><p>The first test image [Fig. <ref type="figure" target="#fig_1">2(a)</ref>] is composed of two Brodatz textures taken from a widely used photographic album <ref type="bibr" target="#b1">[2]</ref>. First, the image is convolved with Gabor wavelets of five scales, eight orientations and a single frequency. Next, the texture features (in this case, the orientation and scale which yielded the maximal Gabor response for each pixel) are obtained. Following a coupled Beltrami process of smoothing, the edge indicator function is calculated, using the metric of the image manifold [Fig. <ref type="figure" target="#fig_1">2(b)</ref>]. As can be seen, there are a few outliers in the background which are weaker than the square's gradients, but do not correspond to any relevant boundary. These outliers are the result of using the maximum value of the Gabor features rather than the complete data. Nevertheless, the result obtained for the Brodatz example is quite satisfying [Fig. <ref type="figure" target="#fig_1">2(c)]</ref>, and comparable to that obtained by Sandberg, Chan and Vese <ref type="bibr" target="#b44">[45]</ref>.</p><p>The second example is of a zebra image [Fig. <ref type="figure" target="#fig_2">3(a)</ref>], tested also in our previous studies <ref type="bibr" target="#b43">[44]</ref>. The texture features selected are the orientation and scale which yielded the maximal Gabor response for each pixel. The Beltrami diffusion procedure was ap-plied to obtain a smooth edge indicator [Fig. <ref type="figure" target="#fig_2">3(b)</ref>]. The resulting segmentation is shown in [Fig. <ref type="figure" target="#fig_2">3(c)</ref>]. The segmentation result obtained in this study is more accurate in comparison to that obtained in our previous study <ref type="bibr" target="#b43">[44]</ref>. This is primarily due to the following improvements. First, a better selection of the Gabor filters was implemented in the present study; indeed, selection of the best (in terms of texture discrimination) Gabor filters is very important, in general, and is especially crucial when considering maximal values as we do. Second, application of Beltrami diffusion to the resultant texture features yields a noise-free edge detector function. Third, a careful selection of the geodesic snakes parameters proves to be very important for obtaining good results. We refer the readers to Rousson et al. <ref type="bibr" target="#b39">[40]</ref> for a comparable result obtained by the structure tensor-based approach. We present another segmentation result for an image of a leopard (Fig. <ref type="figure" target="#fig_3">4</ref>). Segmentation fails in the neck area and in the face area, because the texture in these areas is not very different from the background, and thus, the Gabor filters used for this example are limited in their capability to detect very similar textures. Although further improvement of this result can be obtained, it is interesting to evaluate the performance of our algorithm with that of the geodesic active contours algorithm when simpler edge detectors, such as the popular image gradient, are used. Thus, we obtain the edge detection function using <ref type="bibr" target="#b32">(33)</ref> rather than using <ref type="bibr" target="#b33">(34)</ref> As the segmentation results are very poor when using the usual gradient information, we choose to present the edge detectors obtained (Fig. <ref type="figure">5</ref>). The left image is the edge detector when using our approach. The boundary between the leopard and the background is obvious, and this explains the good segmentation result shown in figure <ref type="bibr" target="#b3">(4)</ref>. The middle image is the edge detector when we use the gradients of the original image <ref type="bibr" target="#b34">(35)</ref> As can be seen, no boundary information exists. There is no valuable edge information in the gradients of a textured image, as the image itself contains several gradients within the textural structure. This is why the Gabor or similar transforms are needed to obtain the boundary information in textured images. To demonstrate the actual benefit of using the edge detector, we also present the edge detector obtained from accumulating the gradient contributions of all the Gabor channels [Fig. <ref type="figure">5(c)</ref>]. Thus, if the Gabor channels are marked as , and is indexing the number of filters used , the edge detector is given by <ref type="bibr" target="#b35">(36)</ref> In this case, the leopard's silhouette can be seen, but there are several outliers and important gradients are not present, so that segmentation fails.  We wish to further assess the performance of our method, and compare it to results that were obtained by another, previously proposed, algorithm. We restrict our comparison to a study which uses a similar conceptual approach. Moreover, we would like to explore the pros and cons of the edge and region-based approaches.</p><p>In the study of Sandberg et al. <ref type="bibr" target="#b44">[45]</ref>, segmentation of the Brodatz image, also used here, is very good. Their study is based on a variational formulation, in which a texture region is characterized by a certain value. Thus, the homogeneity in some variables is important. This refers to the assumption that in each Gaborian channel there is a certain mean response value for each texture. The problem is that this approach will not always work. Consider a simple example of a gray-level image which depicts a bright circle on a dark background, with a tilted plane of illumination added to the image [Fig. <ref type="figure">6(a)</ref>]. While the tilted illumination plane presents no problem to the geodesic snakes mechanism [Fig. <ref type="figure">6(b)</ref>], the approach of active contours without edges fails in this simple segmentation task [Fig. <ref type="figure">6(c)</ref>]. Implicit to the active contours without edges is the assumption that each region, e.g., object and background, can be de scribed by the mean gray level value, without regarding the edges. This example illustrates that edges still contain valuable information.</p><p>A similar argument applies to textured images, where the Gabor channels exhibit properties analogous to that of the tilted illumination plane. We use for this purpose a synthetic image composed of two "spatial chirps" [Fig. <ref type="figure" target="#fig_5">7(a)</ref>]. The base frequency of the squared object is selected to be higher than that of the base frequency of the background. The dependence of the image's horizontal frequency on position resembles the dependence of the gray level value on position in the previous example. In fact, the low-pass filtered image resembles a similar (though tilted toward the horizontal axis) gradient across the field. The squared object is in this case darker than the background.</p><p>The square object gradients are not the only ones present in the edge detection function calculated using our approach [Fig. <ref type="figure" target="#fig_5">7(b)</ref>], but they are definitely the most dominant. Application of geodesic snakes yields the segmentation result shown in [Fig. <ref type="figure" target="#fig_5">7(c)</ref>].</p><p>To compare with, application of the Gabor-based active contours without edges process results in inaccuracies [Fig. <ref type="figure" target="#fig_6">8(a)</ref>]. Let us examine the energy functional in the case of this approach where is the contour, the constants and that depend on are the averages of inside and outside , respectively, and and are fixed parameters for each channel. The second and third terms of the above expression are generated under the assumption that each Gaborian channel is endowed with a certain mean value for each textured region (inside the curve and outside the curve). The contribution of these terms in the evolution equation is depicted in [Fig. <ref type="figure" target="#fig_6">8(c)</ref>]. Thus, because of the frequency-tilted nature of the original image, the minimum value of the defined energy functional is obtained for a falsely segmented image. As can be seen, the tilted background presents no problem for the geodesic snakes process. (c) Segmentation of the circle-on-background image, using the active contours without edge algorithm. As can be seen, the tilted brightness of the backgrounds results in outliers when using the active contours without edges approach.  This function represents the contribution of the Gabor channels to the evolution of the level set 8.</p><p>The next example is composed of two textures [Fig. <ref type="figure" target="#fig_7">9(a)</ref>]. The background texture of a brick wall exhibits a "chirp-like" behavior. Following application of the Gabor filters, the absolute values of the Gabor channels were considered as texture features. Then, these texture features were submitted to the gaussian  Beltrami diffusion mechanism. Applying the geodesic active contours on the the diffused Gabor feature space provides a satisfactory result [Fig. <ref type="figure" target="#fig_7">9(b)</ref>], but the active contours without edges scheme halts away from the boundary [Fig. <ref type="figure" target="#fig_7">9(c)]</ref>.</p><p>Next, we show that the combined approach may produce better segmentation results than the geodesic snakes or the edgeless active contours scheme-when they are independently applied. The first example is again a simple gray level image, yet, it demonstrates the usefulness of applying the IAC model. The image [Fig. <ref type="figure" target="#fig_8">10(a)</ref>] is composed of a bright ring and a darker background. A tilted illumination plane is added to the image at 45 . Thus, the top left corner is the darkest, and the bottom right corner is the brightest, even brighter than the ring. This simple image poses major difficulties to both algorithms. The geodesic snakes algorithm stops at the outer boundary, with no detection of the inner boundary [Fig. <ref type="figure" target="#fig_8">10(b)</ref>]. The edgeless active contours model divides the image into two parts which do not correspond to the actual boundaries [Fig. <ref type="figure" target="#fig_8">10(c)</ref>]. This is because the gradual change in gray level values makes it impossible to characterize the object by one constant value and the background by another constant value. Application of the combined active contours model (with and without edges) results in a good segmentation result, as can be seen in Fig. <ref type="figure" target="#fig_9">11</ref>.</p><p>If we test the idea of the combined approach on the zebra's image we have used before, we may observe the contribution of each approach to the integrated scheme. Application of the Chan-Vese algorithm resulted in a good segmentation, however with a large degree of noise [Fig. <ref type="figure" target="#fig_10">12(a)</ref>]. Recall that application of the geodesic snakes mechanism resulted in a much smoother boundary [Fig. <ref type="figure" target="#fig_2">3(c)</ref>]. The integrated result yields a smooth boundary which captures the details more accurately [Fig. <ref type="figure" target="#fig_10">12(c)]</ref>.</p><p>We have also tested the algorithms on another natural image of a leopard lying on the grass. Gabor wavelets, with six cales, , four orientations, , and a single frequency 0.4 are applied to the image. The texture features are selected for this example to be the Gabor responses for each channel. The resulting segmentation using the geodesic snakes approach, the active contours without edges approach, and the integrated approach are shown in (Fig. <ref type="figure" target="#fig_11">13</ref>). As can be seen, the results are not satisfactory, and further improvement is desirable. Clearly, part of the head, and the front pows, are more similar to the background than to the main texture of the leopard. The problem is caused because of the existence of more then one textural region in the object (the leopard). Still, we would like to present this result to show that combining both approaches provides better results. For example, let us take a closer look on the feet area. Application of the Gabor-space geodesic snakes to the leopard image [Fig. <ref type="figure" target="#fig_11">13(a)</ref>] fails to accurately detect the leopard's feet, as the gradient there is not sharp enough. We may also see that the edgeless active contours model provides unsatisfactory results [Fig. <ref type="figure" target="#fig_11">13(b)</ref>]. However, the leopard's feet are better detected. The IAC mechanism produces the best result, as can be seen in [Fig. <ref type="figure" target="#fig_11">13(c)</ref>]. There are only a few outliers, and the detection of the feet boundaries are improved as can be seen in Fig. <ref type="figure" target="#fig_3">14</ref>.</p><p>These are the best results we got for this image. We cannot say that these are the absolute best results, as the problem involves a large set of parameters (Gabor filters parameters, geodesic snakes parameters, Chan-Vese parameters and the weighting of the two approaches parameters), and each parameter may have a substantial impact on the final result. However, the point we would like to stress here is the usefulness of combining the two conceptually different approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. DISCUSSION</head><p>In the introduction, we pointed out that there are several methods to generate texture features, and at least that many optimization criteria that can be implemented in order to obtain the actual segmentation. It is difficult to assess the performance of each algorithm, and to pinpoint the right choices in each step, e.g., the quality of the feature selection, or the quality of the optimization procedure. Each algorithm seems to be suitable for a specific type of textured image segmentation problem and, most likely, there does not exist a universal segmentation algorithm that is optimal for the entire wide spectrum of natural textured images. It is, therefore, still desirable to enhance the repertoire of methods and algorithms available for applications, and the fittest will survive. However, some rationale should motivate the development of such algorithms so that they will not proliferate without real necessity or purpose. With these boundary conditions in mind, we presented here an approach based on scaled (i.e., wavelet-type) and oriented Gabor representation of images, where the Gaborian filters responses or their maximal values define the texture features. The analysis is based on the gradients present in these texture features space. In some cases, this approach yields better results than approaches based on some homogeneity criteria like the edgeless active contours approach. Further, the combined approach, which combines boundary detection with region growing algorithms can serve as a more general scheme for texture segmentation.</p><p>In this study, we examined a feature set which is generated by taking the maximum amplitude of the Gabor coefficients at each pixel location, along with the scale and orientation for which this maximum value was obtained. This selection is based on the assumption that maximum values provide adequate information about textures, as long as the textures are homogenous. The selection of maximal values provides only partial information regarding image structure, and in turn, may generate less than satisfactory segmentation results in the case of more complex textures. The solution to this problem may be a better selection of the feature space, and adding some statistical data, in the spirit of <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b35">[36]</ref>, and <ref type="bibr" target="#b50">[51]</ref>. A simpler approach applied here, is to improve the Gabor feature space by incorporating a Beltrami-based diffusion scheme <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Moreover, when the full set of Gabor responses was selected, we have used a Gaussian-Beltrami diffusion scheme to eliminate noise.</p><p>The main novelty of this study is in the representation of texture parameters as the embedding of a Riemannian surface in a higher dimensional space. This representation enables the definition of a Riemannian structure and its implementation in the definition of a texture edge indicator. This texture edge indicator is subsequently used in a geodesic active contour algorithm for segmentation. These ideas and techniques are general and are applicable to other choices of texture feature spaces and other multichannel spaces. The advantage of this approach over other algorithms was demonstrated for nonpiecewise constant texture images.</p><p>Another main contribution of this work is the comparison of the geodesic snakes with the edgeless active contours model for  As can be seen, there are many outliers. (c) Combined approach results in a better segmentation, while producing only a small number of outliers. Fig. <ref type="figure" target="#fig_3">14</ref>. Closer look at the leopard's feet shows that (left) the combined approach better detects them than (right) the geodesic snakes alone. the issue of texture segmentation. These attitudes are conceptually different. The snakes mechanism relies on gradients present in the image or image features and the edgeless approach considers the image to be a piecewise constant function. The two approaches were integrated into a unified algorithm in the work of Kimmel <ref type="bibr" target="#b22">[23]</ref>. The proposed energy functional is composed of a geodesic snakes term and a minimal variance term, which is the Chan-Vese approach <ref type="bibr" target="#b53">[54]</ref>. In this study we generalized the unified algorithm of Kimmel for texture images. Both algorithms were independently applied to test images, as well as the integrated scheme. We have shown that both methods have their drawbacks: the geodesic snakes may produce unsatisfactory results when the gradients are not sharp enough, and the edgeless active contours model fails to handle intensity tilts in gray level images, as well as frequency tilts in texture images. The combined approach which accounts for both the gradients between regions and region's homogeneity, may produce better results for gray level and texture images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. In this diagram, the responses in the frequency domian of a possible set of Gabor wavelets is presented. A common design strategy of Gabor filters is to ensure that the half-peak magnitude support of the filter responses in the frequency domain touch each other.</figDesc><graphic coords="4,83.46,65.78,163.00,166.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Image composed of two very similar Brodatz textures. (b) Inverse edge indicator of the Brodatz image. The following orientations: [0; (=8); (2=8); (3=8); (4=8); (5=8); (6=8); (7=8)]; scales: [0:8638; 0:9070; 0:9525; 1]; and a single frequency: 0.15 were used. Beltrami coupled diffusion was applied for 20 iterations with a 0.1 time step. (c) Resultant segmentation of the image composed of Brodatz textures, using the geodesic snakes approach.</figDesc><graphic coords="8,55.68,65.30,218.00,85.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Real-life test image of a zebra. (b) Inverse edge indicator of the zebra image obtained after applying Gabor filters (with orientations:[0; (=6); (=4); (=3); (=2); (2=3); (3=4); (5=6)]; scales: [1; 2; 3]; and frequencies: [0:225; 0:3; 0:375]) and then applying the Beltrami diffusion to each texture feature separately for ten iterations with a 0.1 time step. (c) Segmentation result for the zebra image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.<ref type="bibr" target="#b3">4</ref>. Segmentation result for a leopard using the geodesic snakes algorithm for textures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 ..Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Inverse edge indicator of the leopard image obtained when using: (a) (1= det(g )) edge detector. (b) Image gradients edge detector: E(jr r rI j) = (1=(1+ jr r rI j )). (c) Gradients of the Gbor channels: E(jr r rI j) = 1= 1 + G + G</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) Test image composed of two "spatial chirps." The object's base frequency is higher than that of the background. The Gabor filters applied have seven scales: [0:6667; 1; 1:5; 2:25;3:375;5:0625;7:5938], a single frequency 0.4, and a single orientation zero. (b) Inverse edge indicator of the two-chirps image used along with the Gabor space geodesic snakes algorithm. (c) Segmentation of the two-chirps aquare image, using the gradient-based Gabor space geodesic snakes algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. (a) Squared image segmented by using the active contours without edge-based algorithm. The parameters (32) are: = 10, = 100000, = 50;000.(b) Function used in the active contours without edges algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. (a) Image of a "chirp-like" brick-wall background and a Brodatz texture object. The Gabor filters used here have four orientations: 0, (=4), (=2), (3=4); six scales: [0:3277;0:4096;0:512;0:64;0:8; 1]; and a single frequency 0.4. The texture features are the responses obtained for each Gabor channel. (b) Resultant segmentation following the Gabor space active contours model. (c) Resultant segmentation following the active contours without edges model for the Gabor space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. (a) Test image which is composed of a bright ring on a darker background with a tilted illumination plane. (b) Application of geodesic snakes results in the detection of the outer boundary only. (c) Edgeless active contours model fails to detect the boundary, and divides the image into two parts which have the most different mean gray levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. (Left and middle) Curve's evolution represents the combined influence of both mechanisms. (Right) Application of the combined approach results in an accurate detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. (a) Segmentation of the zebra using the active contours without edges approach results in several outliers. (b) Segmentation of the zebra image can be accurate, smooth and capture details using the integrated approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. (a) Segmentation when applying the geodesic active contours model. There are inaccuracies where the edges are not sharp. (b) Segmentation when applying the active contours without edges model. As can be seen, there are many outliers. (c) Combined approach results in a better segmentation, while producing only a small number of outliers.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Ollendorf Minerva Center, in part by the Fund for the Promotion of Research at the Technion, Israel Academy of Science, Tel-Aviv University fund, and in part by the Adams Center and the Israeli Ministry of Science. The work of Y. Zeevi was supported in part by the Medical imaging Group,</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Chen Sagiv received the B.Sc. degree in physics and mathematics and the M.Sc. degree in physics from the Tel-Aviv University, Tel-Aviv, Israel, in 1990 and 1995, respectively, where she is currenlty pursuing the Ph.D. degree after spending a few years in the high-tech industry.</p><p>Her main research interests are Gabor analysis and the applications of differential geometry in image processing, especially for texture segmentation.</p><p>Nir A. Sochen received the B.Sc. degree in physics and the M.Sc. degree in theoretical physics from the University of Tel-Aviv, Tel-Aviv, Israel, in 1986 and 1988, respectively, and the Ph.D. degree in theoretical physics from the Universite de Paris-Sud, Paris, France, in 1992, while conducting his research in the Service de Physique Theorique at the Centre d'Etude Nucleaire, Saclay, France.</p><p>He continued with one year of research at the Ecole Normale Superieure, Paris, on the Haute Etude Scientifique fellowship, and a three-year NSF fellowship in the Physics Department, University of California (UC), Berkeley. It was at UC Berkeley that his interests shifted from quantum field theories and integrable models, related to high-energy physics and string theory, to computer vision and image processing. He spent one year with the Physics Department, University of Tel-Aviv, and two years with the Faculty of Electrical Engineering, Technion-Israel Institute of Technology, Haifa. Currently, he is a Senior Lecturer with the Department of Applied Mathematics, Tel-Aviv University. His main research interests are the applications of differential geometry and statistical physics in image processing and computational vision.</p><p>Yehoshua Y. Zeevi received the Ph.D. degree from the University of California, Berkeley.</p><p>He is the Barbara and Norman Seiden Professor of Compute Science, Department of Electrical Engineering, Technion-Israel University od Technology, Haifa, where he was the Dean from 1994 to 1999. He is also the Head of the Ollendorff Minerva Center for Vision and Image Sciences and the Zisapel Center for Nano-Electronics. He was a Visiting Scientist at the Lawrence Berkeley Laboratory, Technion; a Vinton Hayes Fellow at Harvard University, Cambridge, MA, where he has been a regular visitor; a Fellow-at-Large at the Massachussetts Institute of Technology (MIT), Cambridge; a Visiting Senior Scientist at NTT Research Center, Yokoska, Japan; and an SCEEE Fellow at the USAF Flight Simulation Center on a joint appointment with MIT. He is also a Visiting Professor at MIT; Harvard University; Rutgers University, New Brunswick, NJ; and Columbia University, New York. He is the co-inventor of patents and the co-author of papers and technical reports related to vision, computational vision, and image processing. His work on automatic gain control in vision led to the development of the Adaptive Sensitivity camera that mimics the eye, and he was one of the founders of i Sight, Inc., that developed this camera. He was also involved in the development of head-and eye-tracking systems for helmet-mounted displays, and of image-guided minimal invasive medical technology (as a co-founder of UltraGuide, Inc.). He is the editor of three books.</p><p>Dr. Zeevi is a Fellow of the SPIE and the Rodin Academy. He is one of the two Editors-in-Chief of the Journal of Visual Communication and Image Representation and a member of editorial boards of several journals. He has served on various boards and national and international committees, including the Technion Board of Governors and Council. He is a member of the IEEE Technical Committee of Image and Multidimensional Signal Processing.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multichannel texture analysis using localized spatial filters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="73" />
			<date type="published" when="1990-01">Jan. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Textures: A Photographic Album for Artists and Designers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brodatz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Dover</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName><forename type="first">V</forename><surname>Caselles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="97" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Active contours without edges for vector-valued images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="141" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Texture analysis and classification with treestructured wavelet transform</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="429" to="441" />
			<date type="published" when="1993-10">Oct. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Segmentation by texture using correlation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="69" />
			<date type="published" when="1983-01">Jan. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A theoretical comparison of texture algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="204" to="222" />
			<date type="published" when="1980-05">May 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Markov random field texture models</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="39" />
			<date type="published" when="1983-01">Jan. 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensinal visual cortical filters</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1160" to="1169" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Texture features based on Gabor phase</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M H</forename><surname>Du Buf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Heitkmper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal Gabor filters for for texture segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="947" to="964" />
			<date type="published" when="1995-07">Jul. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gibbs random fields, co-occurences and texture modeling</title>
		<author>
			<persName><forename type="first">I</forename><surname>Elfadel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="37" />
			<date type="published" when="1994-01">Jan. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Theory of communication</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gabor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inst. Elect. Eng</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="429" to="459" />
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, gibbs distribution and the bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984-11">Nov. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast geodesic active contours</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudzsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tran. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1467" to="1475" />
			<date type="published" when="2001-10">Oct. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A mathematical theory of primal sketch and sketchability</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10">Oct. 2003</date>
			<biblScope unit="page" from="1228" to="1235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation in a deterministic annealing framework</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="803" to="818" />
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised texture segmentation using Gabor filters</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1167" to="1186" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Texton gradients: The texton theory revisited</title>
		<author>
			<persName><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="245" to="251" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kaas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gradient flows and geometric active contour models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kichenassamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="810" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Nonparametric method for image segmentation using information theory and curve evolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yezzy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cetin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1486" to="1502" />
			<date type="published" when="2005-10">Oct. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast edge integration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geometric Level Set Methods in Imaging, Vision, and Graphics</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Osher</surname></persName>
		</editor>
		<editor>
			<persName><surname>Paragios</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="59" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Images as embedded maps and minimal surfaces: Movies, color, texture, and volumetric medical images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="129" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the geometry of texture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Int. Conf. Math. Meth. Curves Surf</title>
		<meeting>4th Int. Conf. Math. Meth. Curves Surf</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Texture classification by wavelet packet signatures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1186" to="1191" />
			<date type="published" when="1993-11">Nov. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Image representation using 2-D Gabor-wavelets</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="959" to="971" />
			<date type="published" when="1996-10">Oct. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Texture Segmentation by Minimizing Vector-Valued Energy Functionals: The Coupled-Membrane Model</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Sini</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">588</biblScope>
			<biblScope unit="page" from="165" to="173" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shape modeling with front propagation: A level set approach</title>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vemuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="175" />
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Texture features browsing and retrieval of image data</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996-10">Oct. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Texture classification and segmentation using multiresolution simultaneous autoregressive models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="173" to="188" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mathematical description of the response of simple cortical cells</title>
		<author>
			<persName><forename type="first">S</forename><surname>Marcelja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Amer</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1297" to="1300" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Oscillating Patterns in Image Processing and Nonlinear Evolution Equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>AMS</publisher>
			<biblScope unit="volume">22</biblScope>
			<pubPlace>Providence, RI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Wave propagation and sampling theory-Part 2: Sampling theory and complex waves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Morlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fourgeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="222" to="236" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optimal approximation by optimal piecewise smooth functions and associated variational problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="685" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Geodesic active regions for supervised texture segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Comput. Vis</title>
		<meeting>Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="22" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The generalized Gabor scheme of image representation in biological and machine vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Porat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="452" to="468" />
			<date type="published" when="1988-04">Apr. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Localized texture processing in vision: Analysis and synthesis in the Gaborian space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Porat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="129" />
			<date type="published" when="1989-01">Jan. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fronts propagating with curvature dependent speed: Algorithms based on Hamilton-Jacobi formulations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="12" to="49" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Active unsupervised texture segmentation on a diffusion based feature space</title>
		<author>
			<persName><forename type="first">'</forename><forename type="middle">M</forename><surname>Rousson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deriche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">Jun. 2003</date>
			<biblScope unit="page" from="699" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gabor space geodesic active contours</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sagiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algebraic Frames for the Perception-Action Cycle</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Sommer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Zeevi</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1888</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Geodesic active contours applied to texture feature space</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sagiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Scale-Space and Morphology in Computer Vision</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Kerckhove</surname></persName>
		</editor>
		<meeting>Scale-Space and Morphology in Computer Vision<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2106</biblScope>
			<biblScope unit="page" from="344" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Gabor feature space diffusion via the minimal weighted area method</title>
	</analytic>
	<monogr>
		<title level="m">Proc. Energy Minimization Meth. Comput. Vis. Pattern Recognit</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Germany</forename><surname>Berlin</surname></persName>
		</editor>
		<meeting>Energy Minimization Meth. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2134</biblScope>
			<biblScope unit="page" from="621" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Texture segmentation via a diffusion-segmentation scheme in the Gabor feature space</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Workshop Texture Anal</title>
		<meeting>2nd Int. Workshop Texture Anal</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="123" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Level-Set and Gabor Based Active Contour Algorithm for Segmenting Textured Images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCLA Comput. Appl. Math. Rep</title>
		<imprint>
			<biblScope unit="page" from="2" to="39" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Vector valued active contours</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="680" to="685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A general framework for low level vision</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sochen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="310" to="318" />
			<date type="published" when="1998-02">Feb. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Local linear transforms for texture measurements</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Modeling Textures With Total Variation Minimization and Oscilating Patterens in Image Processing</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Vese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCLA Comput. Appl. Math. Rep</title>
		<imprint>
			<biblScope unit="page" from="2" to="19" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient Gabor-filter design for texture segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Weldon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2005" to="2016" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Equivalence of Julesz ensembles and FRAME models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="265" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Region competition: Unifying snakes, region growing and Bayes/MDL for multiband image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="884" to="900" />
			<date type="published" when="1996-09">Sep. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Analysis of multiwindow Gabor-type schemes by frame methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zibulski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmonic Anal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="188" to="221" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001-02">Feb. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
