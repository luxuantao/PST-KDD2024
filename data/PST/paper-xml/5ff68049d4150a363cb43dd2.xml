<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Group search optimizer: a nature-inspired meta-heuristic optimization algorithm with its results, variants, and applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Laith</forename><surname>Abualigah</surname></persName>
							<email>aligah.2020@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Sciences and Informatics</orgName>
								<orgName type="institution">Amman Arab University</orgName>
								<address>
									<postCode>11953</postCode>
									<settlement>Amman</settlement>
									<country key="JO">Jordan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Group search optimizer: a nature-inspired meta-heuristic optimization algorithm with its results, variants, and applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE614F8D4AB5C11E5C73EDC797FA3D2A</idno>
					<idno type="DOI">10.1007/s00521-020-05107-y(</idno>
					<note type="submission">Received: 28 January 2020 / Accepted: 5 June 2020 Ó Springer-Verlag London Ltd., part of Springer Nature 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Group search optimizer</term>
					<term>Meta-heuristic optimization algorithms</term>
					<term>Optimization problems</term>
					<term>Nature-inspired algorithms</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, to keep the researchers interested in nature-inspired algorithms and optimization problems, a comprehensive survey of the group search optimizer (GSO) algorithm is introduced with detailed discussions. GSO is a nature-inspired optimization algorithm introduced by He et al. (IEEE Trans Evol Comput 13:973-990, 2009)  to solve several different optimization problems. It is inspired by animal searching behavior in real life. This survey focuses on the applications of the GSO algorithm and its variants and results from the year of its suggestion (2009) to now (2020). GSO algorithm is used to discover the best solution over a set of candidate solution to solve any optimization problem by determining the minimum or maximum objective function for a specific problem. Meta-heuristic optimizations, nature-inspired algorithms, have become an interesting area because of their rule in solving various decision-making problems. The general procedures of the GSO algorithm are explained alongside with the algorithm variants such as basic versions, discrete versions, and modified versions. Moreover, the applications of the GSO algorithm are given in detail such as benchmark function, classification, networking, engineering, and other problems. Finally, according to the analyzed papers published in the literature by the all publishers such as IEEE, Elsevier, and Springer, the GSO algorithm is mostly used in solving various optimization problems. In addition, it got comparative and promising results compared to other similar published optimization algorithm.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Meta-heuristic optimization techniques are chiefly divided into two main parts: local search optimization methods (LSOMs) and population search optimization methods (PSOMs). LSOMs work with one solution during their progress, and they attempt to improve the single candidate agent using the neighborhood mechanisms <ref type="bibr" target="#b0">[1]</ref>, such as hill climbing technique <ref type="bibr" target="#b1">[2]</ref>, b-hill climbing technique <ref type="bibr" target="#b2">[3]</ref>, tabu search technique <ref type="bibr" target="#b3">[4]</ref>, and simulated annealing technique <ref type="bibr" target="#b4">[5]</ref>. However, the foremost benefit of these searching methods is the accelerated search process and problem avoidance. In contrast, the main problem of them is they focus on exploration search (global search/diversification) rather than exploitation search (local search/intensification), which, as a result, increases the probability of falling in the local optima problem. Contrary to LSOMs, PSOMs use multi-agents (population) at each run for enhancing the candidate agents to create one or more better agents at each course of improvements. These searching techniques are powerful in recognizing encouraging areas in the large regions, but it does not utilize the wide areas of the search space effectively <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Swarm intelligence and evolutionary computation are types of PSOMs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. These searching methods are based on the physical behavior and natural evolution of social intelligence development of real animals and others in real life <ref type="bibr" target="#b9">[10]</ref>. Examples of these methods (PSOMs) include harmony search (HS) algorithm <ref type="bibr" target="#b10">[11]</ref>, brain storm optimization (BSO) algorithm <ref type="bibr" target="#b11">[12]</ref>, salp swarm algorithm (SSA) <ref type="bibr" target="#b12">[13]</ref>, grey wolf optimizer (GWO) algorithm <ref type="bibr" target="#b13">[14]</ref>, particle swarm optimization (PSO) algorithm <ref type="bibr">[15]</ref>, mothflame optimization (MFO) algorithm <ref type="bibr" target="#b14">[16]</ref>, gravitational search algorithm (GSA) <ref type="bibr" target="#b15">[17]</ref>, krill herd (KH) algorithm <ref type="bibr" target="#b10">[11]</ref>, whale optimization algorithm (WOA) <ref type="bibr" target="#b16">[18]</ref>, bat algorithm (BA) <ref type="bibr" target="#b17">[19]</ref>, ant lion optimization (ALO) <ref type="bibr" target="#b18">[20]</ref>, cuckoo search algorithm (CSA) <ref type="bibr" target="#b19">[21]</ref>, and symbiotic organism search (SOS) algorithm <ref type="bibr" target="#b20">[22]</ref>.</p><p>Animal communities and social bug swarms motivate swarm intelligence search methods-the GSO algorithm a meta-heuristic PSOM proposed by Shan He et al. in 2009 <ref type="bibr" target="#b21">[23]</ref>. It is inspired by animal behavior, particularly exploring behavior. The structure chiefly relies on the producer-scrounger paradigm. It implies that group agents either ''obtain'' (producer) or ''meet'' (scrounger) possibilities. Depending on this structure, ideas of the exploring behavior, e.g., animal checking approaches, are used to produce the best searching procedures for addressing optimization problems. More details of the GSO algorithm are given in <ref type="bibr" target="#b21">[23]</ref>. GSO algorithm is performed by using two main techniques (i.e., PSOM and LSOM) to produce an intelligent searchable method to find the optimal agent for solving the given problem effectively. Compared to other algorithms, the GSO algorithm is straightforward, adjustable, and easy to execute; as such, it can be applied to address various optimization problems. Due to these given features, the HSO is successfully employed for several problems, such as parameter estimation, feature selection, classification, networking, inverse problem, benchmark functions, economic power dispatch planning, power energy, scheduling problems, and image processing.</p><p>In this survey paper, GSO-based methods are presented with a comprehensive and exhaustive study of the procedures of the GSO algorithm with satisfactory materials to identify the published documents (i.e., journals, conferences, chapters, books, and other papers). The previously published papers on the fitting parameters of GSO are additionally given. We focus on the sources and fundamentals of GSO and its improvement versions and present a full comprehensive report of recent applications and connected enhancements accomplished over several years since 2009. After this survey paper, readers will be qualified to understand the idea and the fundamentals of the GSO algorithm, as well as recognize the developmental levels and various areas that employ GSO to find the optimal agents. Eventually, the conclusion of this survey lists the advantages and disadvantages of the GSO algorithm and justifies possible future areas for research to the interested researchers. While the classifications of problems are generally considered as the minimization, some other problems are considered as the maximization. The authors will use this directly as needed. Table <ref type="table" target="#tab_0">1</ref> gives the number of published papers based on the publishers. It is worth to notice that Table <ref type="table" target="#tab_0">1</ref> presents the number of published papers by researchers from October 2009 to the first quarter of the year 2020 (February 2019) on the GSO algorithm as well as its variants based on the various publishers such as IEEE, Elsevier, Hindawi, Springer, Taylor, and Francis. It is recognized in Table <ref type="table" target="#tab_0">1</ref> that in the last nine years (2010-2019), the GSO publications have exponentially raised. Figure <ref type="figure" target="#fig_0">1</ref> displays the frequency of these publications depending on the classes of GSO applications. Also, Fig. <ref type="figure">2</ref> shows the appearance of these publications according to the classes of the GSO variants.</p><p>The remainder of this survey paper is arranged as follows: Sect. 2 presents the GSO algorithm by highlighting its structure and methods. Section 3 gives an overview of the GSO variants, modifications, and improvements. Application areas and improvements in particular fields are presented in Sect. <ref type="bibr" target="#b3">4</ref>. Section 5 presents theoretical aspects, assessment, and evaluation of the GSO. Section 6 presents the results of GSO compared to other similar optimization methods. Finally, Sect. 7 presents some concluding remarks and draws several future research lists of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Group search optimizer</head><p>In this section, the main procedures of the GSO algorithm are given. This algorithm (GSO) is performed by using a set of candidate agents (population) which is named as the group, and each agent is named as a member <ref type="bibr" target="#b21">[23]</ref>. In the available research space (n-dimensional), the ith iteration has the current solutions' positions X k i = 2 R n , a top angle</p><formula xml:id="formula_0">u k i = (u k i 1 , u k i 2 , …, u k i nÀ1 , u k i n ) 2 R n .</formula><p>The search area of the ith agent, which is a member vector D k i (u k i )= (d k i 1 , d k i 2 , ..., ...,</p><formula xml:id="formula_1">d k i nÀ1 , d k i n ) 2 R</formula><p>n that is determined by u k i via a polar to Cartesian assortment transmutation <ref type="bibr" target="#b22">[24]</ref>, is as follows:</p><formula xml:id="formula_2">d k i 1 ¼ Y nÀ1 q¼1 cosðu k i q Þ<label>ð1Þ</label></formula><formula xml:id="formula_3">d k i j ¼ sinðu k i jÀ1 Þ Á Y nÀ1 q¼1 cosðu k i jÀ1 Þ ðj ¼ 2; 3; . . .; n À 1Þ<label>ð2Þ</label></formula><formula xml:id="formula_4">d k i n ¼ sinðu k i nÀ1 Þ:<label>ð3Þ</label></formula><p>For instance, in three dimensions, if at the kth exploring round, the ith agent's head angle is u k i = (p n3, p n4), using Eq. (1) the search area for the given unit vector can obtain D k i = (1n2, ffiffi ffi 6 p n4, ffiffi ffi 2 p n2). In GSO algorithm, each group of agents contains three kinds of agents or members: producers, scroungers, and dispersed members. The behavior of the producers and scroungers members is based on the predator search (PS) model, and the behavior of the dispersed members is based on performing random walk movements. For the availability of computation, the PS model is explained by considering that there is only one generator (producer) at each searching period, and the remaining agents are from both of scroungers and dispersed agents. The most straightforward joining method considers all scroungers will follow the resource determined by the farmer. In solving the problems, the undiscovered best agent can be considered as open parts stochastic grouped in the available search region. Group agents, accordingly, seek for the pieces by examining the possible search region <ref type="bibr" target="#b23">[25]</ref>. This process is additionally expected that the producer and the scroungers do not oppose in their associated phenotypic properties. Hence, all can change among the given pair roles <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b24">26]</ref>.</p><p>At every course of improvement, a group agent, which is placed in the usual encouraging region and presents the best obtained fitness function, is determined as the producer. It then ends and checks the situation to find the best agent. Checking is an essential part of the exploration direction; it is a collection of tools by which creatures affect sensitive sense and seldom their shapes or accessories to obtain data from around the situation. Checking is achieved by natural touch or by optical, artificial, or sensory devices. In the GSO algorithm, imagination, which is   the primary checking tool utilized by several creature classes, is applied by the producer. To achieve visible exploration, several creatures are converted into a broad range of illustrations with retinas becoming changeable locative decision and then apply rapid focus changes to make the highest resolution area toward a possible destination. Excellent scanning production is necessary for survival <ref type="bibr" target="#b21">[23]</ref>.</p><p>The height of each cone is the period at which the fish arrests and scans for the victim. In GSO, the checking range of imagination is reduced and concluded to an ndimensional search area, which is identified by most hunt phase £ max 2 R 1 as shown in a three-dimensional exploration area in Fig. <ref type="figure">3</ref>.</p><p>The apex is the current position of the producer. In the GSO algorithm, at the course number (iteration) k (kth), the producer X p runs as follows:</p><p>• The producer will investigate at zero and then investigate alongside by stochastic testing three locations in the checking place: One case at zero rate:</p><formula xml:id="formula_5">X z ¼ X k p þ r 1 l max D k p ðu k Þ:<label>ð4Þ</label></formula><p>One point in the right-hand faction hypercube</p><formula xml:id="formula_6">X r ¼ X k p þ r 1 l max D k p ðu k þ r 2 H max n2Þ:<label>ð5Þ</label></formula><p>One point in the left-hand faction hypercube</p><formula xml:id="formula_7">X l ¼ X k p þ r 1 l max D k p ðu k þ r 2 H max n2Þ<label>ð6Þ</label></formula><p>where r 1 2 R 1 is a regularly distributed stochastic value with a mean value 0 and standard deviation value 1 and r 2 2 R nÀ1 is a uniformly doled out stochastic values in the range (0, 1).</p><p>• The producer then will work to get the near-best position with the near-best fitness function. If the best position has a fitness function value than its new position, then it travels toward this position. Alternatively, it will wait in its location and direct its caption to a different randomly created position.</p><formula xml:id="formula_8">u kþ1 ¼ u k þ r 2 a max<label>ð7Þ</label></formula><p>where (a max 2 R 1 ) is the maximum adjusting position. • If the producer cannot obtain a better search space after a number of iterations, it will use its leader back to 0 degree</p><formula xml:id="formula_9">u kþa ¼ u k<label>ð8Þ</label></formula><p>where a 2 R 1 is a constant value.</p><p>At each iteration, several group agents are chosen as scroungers. The scroungers will continue searching for better fitness to meet the fitness function determined by the producer. In the GSO algorithm, just the space copying, Neural Computing and Applications which is the most popular scrounging behavior in sparrows, is used. At the kth redundancy, the space copying behavior of the ith scrounger can be represented as a stochastic walk near the producer</p><formula xml:id="formula_10">X kþ1 i ¼ X k i þ r 3 ðX k p À X k i Þ<label>ð9Þ</label></formula><p>where (r 3 2 R n ) is a uniform stochastic sequence value in the range (0, 1). '''' denotes the product, which calculates the product of the two vectors. During scrounging, the ith scrounger will keep exploring for other possibilities to meet <ref type="bibr" target="#b24">[26]</ref>. This behavior is modeled by applying the ith scrounger's start to a new stochastically generated position using Eq. ( <ref type="formula" target="#formula_8">7</ref>).</p><p>Figure <ref type="figure">4</ref> shows the illustration of the typical paths of scroungers. It deserves considering that in this illustration, the generator in the exploration smallest values is artificially placed. Therefore, all scroungers performed area copying to move toward the producer and finally converged to the global minimum. In the search process, if a scrounger gets a more favorable position than the modern producer and scroungers, in the subsequent repetition, it will change to be a producer and all the other agents, containing the producer in the past repetition, will make scrounging strategies. This switching approach assists the group in escaping from exploitation points in the quicker search about <ref type="bibr" target="#b25">[27]</ref>.</p><p>The remainder of the group agents will be scattered from their contemporary positions. In reality, group agents usually have several searching and competitive functions; small assistants active foragers than the principal command are scattered from the agents. Various forms of dispersions are observed, which range from simple insects to human being. Scattered creatures may use ranging behavior to search and find different environments. Ranging is the first stage of an exploration that begins outwardly signs pointing to a particular device. In the GSO algorithm, if the ith group agent is scattered, it will make classifying. In reality, ranging beings make searching procedures, which involve stochastic walks and methodical exploration approaches to find resources. The first strategy (random walks), which is considered to be the common effective searching method for scholastic allocated fitness values, is used by the rangers. At the kth search, it creates a scholastic front position u i using Eq. ( <ref type="formula" target="#formula_8">7</ref>), and then, it takes an arbitrary distance as follows:</p><formula xml:id="formula_11">l i ¼ a Á r 1 l max<label>ð10Þ</label></formula><p>and proceeds to the new position as follows:</p><formula xml:id="formula_12">X kþ1 i ¼ X k i þ l i D k i ðu kþ1 Þ:<label>ð11Þ</label></formula><p>To enhance the chance of finding the maximization of resources (fitness function), animals employ various approaches to limit their exploration to a successful patch. One essential approach is changing the following into a piece when its end is recognized. This approach is applied by the GSO algorithm to control the limited exploration area: When an agent is far about the exploration area, it will turn back toward the possible exploration area by arranging the values that disrupted bounds to its past preferences. The flowchart of the basic GSO algorithm is shown in Fig. <ref type="figure">5</ref>. The pseudo-code for the basic GSO is shown in Algorithm 1.</p><p>Fig. <ref type="figure">4</ref> Tracks of five scroungers running to the producer in five iterations <ref type="bibr" target="#b21">[23]</ref> Neural Computing and Applications</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluate members</head><p>Choose an agent as producer This section explains the various variants of the GSO algorithm in the following subsections (Fig. <ref type="figure">2</ref>). Several versants have been discussed, which are basic, modified, hybridized, discrete, and other versions of the GSO algorithm. Table <ref type="table" target="#tab_2">2</ref> represents a review of the variants of the GSO algorithm in solving different optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic group searching optimizer</head><p>Several studies have been done using basic GSO algorithm to solve different optimization problems such as <ref type="bibr" target="#b47">[49,</ref><ref type="bibr" target="#b48">50]</ref>. Shan et al. <ref type="bibr" target="#b21">[23]</ref> introduced a novel optimization algorithm called group search optimizer (GSO) inspired by animal performance in the searching behavior. The system basically depends on the producer-scrounger show, which accepts the collection of individuals exploration for the producer or for scrounger possibilities. Based on this system, concepts from creature looking performance, e.g., creature filtering instruments, are utilized allegorically to plan ideal looking methodologies for tackling nonstop optimization issues. The GSO algorithm has similar execution to other EAs in regard to exactness and meeting speed, particularly on high-dimensional multimodal issues. The GSO algorithm is additionally connected to prepare artificial neural systems. The obtained results on three realworld benchmark issues showed the appropriateness of GSO for issue tackling. Wu et al. <ref type="bibr" target="#b49">[51]</ref> presented a novel algorithm based on the use of the GSO. The algorithm depends on the producerscrounger show, which expects to gather individuals look either for judgment (maker) or for meeting (scrounger) openings. Animal filtering instruments are joined to create the algorithm. They also utilized rangers, which perform casual strolls to maintain a strategic distance from entrapment in nearby minima. When tested against benchmark functions, GSO bettered with other developmental algorithms in regard to precision and joining rate on the largest benchmark functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discrete group searching optimizer</head><p>Various studies have been performed utilizing discrete versions of the GSO algorithm such as <ref type="bibr" target="#b50">[52,</ref><ref type="bibr" target="#b51">53]</ref>. Mahmoud et al. <ref type="bibr" target="#b44">[46]</ref> have proposed a discrete GOS algorithm called (DGSO-MDNet) to address the population detection problem in high-dimensional connection arrangements without a piece of earlier information regarding the number of populations. This proposed system was proposed to make a community approach that can maximize the objective function (i.e., multi-slice modularity). The proposed method uses a locus-based adjacency design and different discrete agents. Experiments are conducted on network datasets, and the results show the superiority of the DGSO-MDNet to discover the hidden building within the given arrangements.</p><p>Mahmoud et al. <ref type="bibr" target="#b44">[46]</ref> introduced discrete GSO algorithm (DGSO), which is a useful optimization algorithm to determine the community exposure problem without any prior information about the quantity of communities. The proposed DGSO algorithm uses the locus-based adjacency design and various discrete laborers. Experiments in reallife arrangements proved the ability of the proposed DGSO algorithm to robustly discover the construction hidden within heterogeneous networks matched with other higheffectiveness optimization algorithms published in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Modifications of group searching optimizer</head><p>Several studies have been done using the modified GSO algorithm to solve different optimization problems such as [54-56]. Xiang-wei et al. <ref type="bibr" target="#b34">[36]</ref> proposed a new method to solve the weaknesses, especially the convergence, of the basic GSO called SEGSO. The proposed method is based on a self-adaptive GSO with elitist strategy (SEGSO). To keep the group heterogeneity, SEGSO uses a self-adaptive role distribution strategy, which defines whether an agent is a scrounger or a soldier based on ConK following iterations of the producer. The obtained results showed that SEGSO got better outcomes compared with PSO and basic GSO in convergence speed and left the neighborhood problem.</p><p>Kang and Gu <ref type="bibr" target="#b36">[38]</ref> introduced an enhanced GSO algorithm called fast global GSO (FGGSO) to expand the exploration rate and make a trade-off between the intensification and diversification. At first, studying the computational time configuration of the producer's angle searching approach, a new local exploration tool, named campaign approach, is produced, which is operated by opposition and interaction between competitors in a selecting process. Next, a repair process is used in the searching method to ensure the escape of the exploitation search. The algorithm is assessed on a collection of 11 numerical problems and matched favorably with other versions of GSOs. The obtained outcomes designated an exceptional enhancement in the effectiveness of specific problems.</p><p>In the basic GSO, larger than 80% positions are taken as scroungers, and the maker is the individual. When the producer cannot get more trustworthy positions compared to the past one in some continuous iterations, the scroungers will certainly depart to the identical area, and the group might be stuck in the expiration area through a short number of rangers employed to develop the variety of it. In The obtained results illustrated that CMOGSO could more viably and effectively fathom multi-objective optimization issues compared with other developmental multi-objective optimizers Ya-zhou et al. <ref type="bibr" target="#b42">[44]</ref> Neural Computing and Applications order to enhance the execution of the GSO algorithm, an enhanced GSO with the quantum-behaved administrator for scroungers concurring to a particular probability is introduced by Debao et al. <ref type="bibr" target="#b30">[32]</ref>. Within the strategy, the scroungers are partitioned into two parts: the scroungers within the to begin with portion overhaul their positions with the administrators of QPSO, and the leftovers retain looking for openings to connect the assets determined by the maker. The administrators of QPSO are employed to move forward the differences in the populace for GSO. The proposed IGSO is investigated on a standard benchmark and compared with others. Abdollah et al. <ref type="bibr" target="#b40">[42]</ref> dealt with the error in the completion of the security forces system involvement using improved GSO (self-learning). The hydrothermal arrangement problem is described as an optimization problem, which is required to attend various identities and different restrictions. The driven agents in the first paper of the GSO algorithm do not meet the restriction on the last area size of the hydro units' store one at the current iteration. Consequently, this error was established in the first paper.</p><p>The efficiency and convergence rate of quick GSO are possible to work with a spatial architectural arrangement. This paper proposed the QGSO algorithm in the seismic investigation of iron structures with semirigid associations which more precisely match the working circumstances <ref type="bibr" target="#b37">[39]</ref>. The QGSO is connected with the restriction from the sentence coefficients and active time-history investigation. The production of the QGSO on seismic design has been examined on a two-bay five-layer steel problem. The obtained result revealed that the QGSO algorithm received better output matched with the PSO in regard to convergence rate and the capability of escaping from the optimum local problem. Furthermore, it is possible and practical to implement the QGSO to the optimal seismic design of steel structure.</p><p>Chin-Ling et al. <ref type="bibr" target="#b45">[47]</ref> proposed a forecast prototype based on an enhanced fuzzy interval series and an improved GSO to address the predicting problems effectively. The proposed fuzzy time series can correctly foretell whether the following predicted data will improve or lower depending on the ratio value in the fuzzy logical connection. Besides, improved GSO is employed to change the time. The proposed prototype is used to forecast the enrollments of the University of Alabam. The obtained results revealed that the proposed prototype achieves the smallest forecast error compared to other comparative methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hybridizations of group searching optimizer</head><p>Several studies have been done using hybrid GSO algorithm to solve different optimization problems such as <ref type="bibr">[57,</ref><ref type="bibr">58]</ref>. Juanyan et al. <ref type="bibr" target="#b26">[28]</ref> introduced a new combination of GSO by hybridizing metropolis rule to more improving the capability of escaping from local optima problem. The obtained results showed the production of this proposed algorithm is superior to the basic GSO algorithm and other algorithms in multi-model optimization problems, particularly for high-dimensional problems.</p><p>Chen et al. <ref type="bibr" target="#b35">[37]</ref> proposed a dynamic economic dispatch taking into consideration the valve point impacts of each unit. Moreover, considering the vulnerabilities of wind control and the changes of stack request, the proposed show is defined as a non-convex optimization issue which is illuminated by a novel strategy, GSO with versatile techniques. The proposed approach utilizes the versatile procedures, counting a versatile covariance network and an efficient transformation operation conspire to extend both investigation and abuse capabilities of the GEO. The adequacy of the proposed strategy is inspected utilizing two notable test cases with a comparison between the proposed The proposed excessive dimension interleaved design using HGSO technique plays well than some other methods 2017 Rutuja et al. <ref type="bibr" target="#b46">[48]</ref> approach and other heuristic algorithms. It is illustrated that the proposed plan can understand the energetic financial celerity issue effectively.</p><p>In order to enhance the execution of GSO in tackling severe optimization problems, an opposition learning approach (OBL) and a differential evolution strategy (DE) are combined into GSO to create a half-breed GSO. In this paper <ref type="bibr" target="#b41">[43]</ref>, the methodology of OBL is utilized to broaden the look local, and the administrator of DE is used to improve the nearby look to progress. Comparison tests illustrated that the proposed crossover GSO algorithm performed preferences over the past GSO and DE addresses in merging velocity and precision of arrangement.</p><p>Rutuja et al. <ref type="bibr" target="#b46">[48]</ref> centered on the other trouble of mistakes editing code and delivered a turbo encoder, which makes use of a combination algorithm by using the genetic algorithm (GA) and GSO within the call of hybrid GSO (HGSO) and makes the high-dimensional information transmission. Such a high-dimensional data has changed to low-dimensional data by way of introducing a new excessive measurement interleaved in the traditional design. In which statistics transformation and top of the line pattern technology has taken region the usage of the current meta-heuristic seek algorithm. The overall performance of the proposed system has in comparison with the prevailing GSO, GA, FA, ABC, and random interleaver design in terms of signal-to-noise ratio (SNR), BER, and FER. Additionally, the computation time is calculated for every factor of both present and proposed machine. Eventually, the obtained results showed that the proposed excessive dimension interleaved study using the HGSO technique works well than some other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Chaotic group searching optimizer</head><p>To enhance the performance of the GSO, ZG, and DB, <ref type="bibr" target="#b28">[30]</ref> proposed a new method to solve benchmark functions called CGSO. The proposed method added chaotic theory to the GSO with the global searching characteristic. In CGSO, the excellent position of the producer is renewed by a chaotic searching strategy; the new position is defined by the best position achieved so far by chaotic mutation. CGSO and GSO simulated four-function optimization problems. The obtained results showed that CGSO is more effective than other well-known algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Multi-objective group searching optimizer</head><p>Several studies have been done using multi-objective GSO algorithm to solve different optimization problems such as <ref type="bibr" target="#b50">[52,</ref><ref type="bibr">59]</ref>. Ling et al. <ref type="bibr" target="#b31">[33]</ref> proposed a new multi-objective GSO (NMGSO) for addressing the multi-objective problems. To explain the algorithm, the checking procedure of the basic GSO is superseded by the short-guide exploration method. To improve the exploration of the rangers, a particular variation with a supervising possibility is produced to adjust the diversification and intensification at various searching steps, and randomness is included in defining the coefficients of agents to improve the diversity. To control multi-objectives, the sorting design and numerous generators are utilized. Also, the kernel density operator is applied to keep heterogeneity. The obtained results based on a collection of functions and comparisons with other techniques illustrated the performance and robustness of the proposed method, particularly for the high-dimensional multi-objective optimization problems.</p><p>Feng et al. <ref type="bibr" target="#b32">[34]</ref> proposed a multi-objective ideal plan of outline structures carried out by GSO with Pareto arrangements hypothesis. A one narrow outline structure was utilized to assess the execution of bunch look optimizer. The proposed algorithm has better effectiveness in regrades to convergance rate, achievability, common sense and prevalence in structure ideal plan.</p><p>Ya-zhou et al. <ref type="bibr" target="#b42">[44]</ref> proposed a cooperative co-evolutionary multi-objective GSO (CMOGSO). In CMOGSO, multi-objective optimization issues are decayed, agreeing with their choice factors. They are determined the optimality by comparing subgroups, individually. Collaborators are chosen haphazardly from the file and utilized to build setting vectors to assess the individuals in subgroups. The obtained outcomes illustrated that CMOGSO could numerous viably and adequately fathom multi-objective optimization issues compared with other developmental multi-objective optimizers.</p><p>Ya-zhou et al. <ref type="bibr" target="#b43">[45]</ref> proposed a modern virtual arrange implanting show in this paper. In order to adjust the characteristic limitations of the goals, two physical functions are characterized and optimized at the same time. Multi-objective GSO is utilized to realize the Pareto-optimal set, in which the officer looking procedure is made strides to boost the execution of the algorithm. The test comes about illustrates that the proposed strategy claims excellent performance in terms of the income and acknowledgement proportion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications of group search optimizer</head><p>The GSO algorithm is applied effectively to solve several different applications (optimization problems) of many various disciplines such as benchmark function, machine learning, and engineering design problems. Showing specific optimization problems and determining fit variables and objective functions are the essential matters that can assist in practical problem solving when addressing such optimization problems. The general use of operators, parameter adjustment, and population design are the major issues as regards optimization algorithms. In this section, a study of the literature is conducted by analyzing the application (scientific applicability) domains in the following subsections (Fig. <ref type="figure" target="#fig_0">1</ref>). Table <ref type="table" target="#tab_4">3</ref> shows a review of the applications of the GSO algorithm in addressing different optimization problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benchmark functions</head><p>Several studies have been done using the GSO versions to address different problems, especially in the benchmark functions such as <ref type="bibr">[81,</ref><ref type="bibr">82]</ref>. Guohua et al. <ref type="bibr">[72]</ref> introduced an improved version of the GSO to solve engineering problems called IGSO. The basic version of GSO utilizes the G-best topology construction, which directs the rapid replacement of information between positions. Hence, it is quickly trapped in a local optimum while trading with multi-modal problems. The proposed QGSO got better results using four benchmark functions. In another study, Guo-Hua et al.</p><p>[76] used the GSO incorporated with interactive dynamic neighborhood (IDGSO). The proposed IDGSO is compared with other existing optimization algorithms; it obtained a better result in the high-dimensional optimization problems. The results were compared using four benchmark functions.</p><p>Wen-fen and Zhao-hui [68] proposed an improved GSO in this paper. The noteworthy change is that swarm individuals spare the correct heading of developments amid the look prepare as their involvement and anticipate superior positions from these experiences. The improved GSO encompasses a prevalent look execution on low-dimensional issues and high-dimensional issues. The made strides GSO algorithm is both less complex and faster than the GSO algorithm. A set of four benchmark functions were utilized to assess the progressed algorithm. For the 30 dimensional cases, the made strides algorithm outflanked GA and GSO for all the four benchmark functions and outflanked PSO for 2 of them. For the 300 dimensional cases, the moved forward algorithm contains a particularly prevalent execution to GA, PSO, and GSO algorithms.</p><p>Lijin et al.</p><p>[83] proposed a modified GSO for solving optimization problems, which is based on requiring effort methodology, self-adaptive joining technique, and chaotic transformation technique. The required flight technique is utilized for the maker to rearrange the number and move forward productivity within the investigating space. The self-adaptive joining technique is being utilized for the scroungers strolling to the maker to advance joining speed. The chaotic transformation procedure is outlined for the officers to fortify expansion. Using those procedures, the adjusted algorithm can get way better change between escalated and development. The reenactment tests, which were conducted on benchmark functions, appear that those procedures are compelling, and they make strides the worldwide optimization capacity and merging speed of adjusted GSO for high-dimensional work optimization. Yu et al. <ref type="bibr">[84]</ref> presented a crossover GSO with a differential evolutionary (DE) administrator named DEGSO to upgrade the differing qualities of standard gather look optimizer. In this strategy, the basic GSO and the DE administrator interchange at the odd cycles and the indeed cycles. The outcomes of the tests show that DEGSO is competitive with other similar methods.</p><p>Wen-fen [85] proposed a disentangled GSO algorithm called SGSO for broad-scale global optimization is displayed in this paper to get a straightforward estimate with prevalent execution on high-dimensional issues. The SGSO embraces its solutions to move forward the sharing technique, which offers great members, and employments a less complicated look strategy rather than looking by the head point. Furthermore, the SGSO increases the rate of scroungers to quicken meeting speed. Compared with GA, PSO, and GSO, SGSO is tried on seven benchmark functions with measurements 30, 100, 500, and 1000. It can be concluded that the SGSO encompasses a strikingly effective execution to other methods for large optimization problems.</p><p>Dan et al.</p><p>[86] proposed a diversity-guided GSO (DGSO) with OBL to overcome these impediments. Opposition-based knowledge is employed to quicken the merging rate of GSO. In contrast, the direction of the difference (DG) is used to extend the differing qualities of the populace. A comprehensive set of nineteen sophisticated benchmark functions is being utilized for test confirmation. It is compared to the first GSO algorithm. Numerical tests show that the DGSO gives better execution than the basic GSO within the merging rate and the arrangement exactness. <ref type="bibr">Li et al. [87]</ref> proposed a new optimization algorithm based on the use of the GSO with OPL and Le ´vy walk (GSOICLW). The component of intraspecific competition (IC) and the looking procedure of Le ´vy walk (LW) are joined to the basic GSO algorithm. It has been demonstrated that GSOICLW shows a critical change to GSO after its examination versus standard optimization problems.</p><p>Jia-Jia et al.</p><p>[88] proposed a variation of GSO (VGSO), which creates a producer-organizer demonstrate whereby group agents are expected to seek for openings of either ''finding'' (producing) or ''learning'' (organization). This show empowers VGSO to attain a significant trade-off between its investigation and abuse functions. A comprehensive exploratory considers conducted on a set of benchmark functions and a commonsense optimization issue. The comparison comes about shows that VGSO gets a promising execution on these optimization issues. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification problems</head><p>Cooper et al.</p><p>[74] proposed a modern GSO-based biomarker disclosure strategy for pancreatic cancer determination utilizing mass spectrometry (MS) information. The GSO was inspired by creature social looking conduct. It showed that the worldwide look execution of the GSO is competitive to other organically driven optimization algorithms. They connected a GSO as a highlighted determination strategy to MS information investigation for premalignant pancreatic cancer biomarker disclosure. They begin to connect a smooth nonlinear vitality administrator to distinguish crests. At that point, a GSO with a straight discriminant examination was utilized to choose a miserly collection of top windows that can recognize cancer. After choosing a collection of biomarkers, a back vector machine was at that point connected to construct a classifier to conclusion premalignant cancer cases. They matched the GSO with the GA, advancement procedures, developmental programming, and a molecule swarm optimizer. The outcomes showed that the GSO-based highlight determination algorithm is competent in selecting a stingy set of biomarkers to attain superior classification execution than other estimates. Balakrishnan and Thirunavu [80] proposed a new method for classification problems in this paper. At first, the pre-processing preparation is conducted to choose the leading quality datasets. At that point, a hybrid of progressed integer-coded hereditary algorithm (AICGA) and extraordinary learning machine (ELM), with refined GSO (RGSO) procedure, is utilized for quality choice and cancer classification. AICGA is being used with RGSObased ELM classifier to select an ideal set of qualities that comes about in a proficient crossover algorithm that can handle meager information and test lopsidedness. The refined gather look optimizer-based extraordinary learning machine is utilized to carry out the classification handle. Within the RGSO-based ELM, the weights and predisposition to ELM are optimized using RGSO for superior rearrangements and classification of expansive esteem of quality datasets. The execution of the suggested method is assessed, and the result is compared with the similar strategies. The introduced methods are connected to good time datasets and benchmark datasets taken from dataset stores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Neural network</head><p>Shan [67] proposed a novel artificial neural network (ANN) training algorithm based on an enhanced GSO algorithm. The Gaussian random walk is replaced in the basic GSO with another mechanism called Le ´vy flight. This mechanism is a random search pattern utilized by many searching methods to maximize the performance of resource searches in unknown circumstances. The enhanced GSO with Le ´vy flight (LGSO) is assessed on a collection of five optimization benchmark functions. Then, the LGSO algorithm is utilized to harmonize the parameters of a three-layer feed-forward ANN, including combination weights and bias. Two real-world problems have been used to evaluate the achievement of our LGSO-trained ANN (LGSOANN). When compared with other well-known machine learning techniques, the proposed algorithm produced better convergence and generalization execution. Shan et al.</p><p>[60] applied the GSO to artificial neural organize (ANN) preparing to advance explore its appropriateness to real-world issues. The parameters of a threelayer feed-forward ANN, counting association weights and inclination, are tuned by the GSO algorithm. Two realworld classification issues have been utilized as benchmark issues prepared by the ANN to evaluate the execution of the GSO-trained ANN (GSOANN). In comparison with other advanced machine learning methods, the proposed for ANN making in later a long time, counting a few ANN outfits, GSOANN has way better meeting and generalization exhibitions on the two benchmark issues.</p><p>Wu et al.</p><p>[61] introduced a new algorithm: a GSO for preparing a fake neural arrange (ANN) utilized for the conclusion of breast cancer. The GSO algorithm is propelled by creature social looking conduct. Its worldwide look execution has been demonstrated similar to other developmental algorithms and the molecule swarm algorithm. This algorithm is found to tune the KNN parameters. Wisconsin demonstrative breast cancer information from the UCI store is utilized as a benchmark classification issue to assess the suggested strategy. In matching with other modern machine learning strategies used for ANN preparing, counting a few ANN outfits, the GSO for ANN, GSOANN, incorporates a way better merging rate and generalization exhibitions for the breast cancer conclusion issue.</p><p>Danielle et al.</p><p>[73] presented two half-breed agreeable GSO approaches based on divide-and-conquer worldview, utilizing friendly conduct among numerous GSO bunches to progress the execution of standard GSO. They moreover connected the Weight Rot (WR) procedure to upgrade the generalization control of systems. The obtained results showed that the GSO approaches utilizing participation could attain superior generalization execution than other similar methods. In another study, the execution of GSO in adapting with compelled issues is explored. A few tests are conducted on 13 well-known and broadly utilized benchmarks <ref type="bibr" target="#b27">[29]</ref>. The exploratory comes about to appear that GSO can discover the precise or near to universally ideal methods on most issues. GSO can unravel the obliged problem and is an elective method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Engineering applications</head><p>Several studies have been done using the GSO algorithm to address different optimization problems, especially in the engineering applications such as [89, 92, 93].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Scheduling</head><p>Several studies have been done using GSO algorithm to solve scheduling optimization problems such as <ref type="bibr" target="#b52">[94]</ref>. Zhe and Xingsheng <ref type="bibr" target="#b51">[53]</ref> proposed the combination flow shop scheduling with a random breakdown called (RBHFS) with a discrete GSO (DGSO). Two separate working examples, preempt-resume example and preempt-repeat example, are recognized below accidental analysis. The suggested DGSO uses vector design and various discrete agents. Also, an orthogonal analysis is employed to address the adaptable parameters in the proposed DGSO method. The obtained results in both examples showed that the DGSO increases the achievements matched with other similar methods.</p><p>Deng et al. <ref type="bibr" target="#b50">[52]</ref> performed a multi-objective discrete GSO for blocking stream shop problem. The proposed algorithm is outlined to explore the Pareto-optimal agents reducing the makespan and add up to stream time for the stream shop planning with blocking imperative. Within the proposed algorithm, a beginning expanded populace is developed based on the Nawaz-Enscore-Ham heuristic and its variations. Not at all, like the initial GSO in which persistent arrangement design is utilized, the proposed algorithm uses discrete work change design to adjust to the recognized planning issue. In this manner, operations of a maker, scrounger, and officer are recently planned. An insertion-based Pareto nearby look is put forward in maker strategy, a hybrid process is presented in scrounger strategy, and a neighborhood look based on the embed neighborhood is planned in officer strategy. The results showed that the proposed algorithm is predominant in two existing capable algorithm in regard to modified generational remove and set scope.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Control of power systems</head><p>Li et al. <ref type="bibr" target="#b33">[35]</ref> presented an upgraded GSO with intraspecific competition and Le ´vy walk (GSOICLW). The proposed strategy is utilized to illuminate the ideal control stream (OPF) issue. GSOICLW s a more naturally practical algorithm and performs superior adjust between worldwide and nearby search than basic GSO and Le ´vy walk (LW) are presented GSO. GSOICLW is tested on the IEEE 30-bus control framework, with nursery gasses outflow imperative, considered. The obtained results illustrated the precision and unwavering quality of the proposed algorithm, compared with other EAs.</p><p>Li et al. <ref type="bibr" target="#b38">[40]</ref> introduced the mean-variance (MV) model to resolve control framework responsive power dispatch issues with wind control coordinates. The MV considers the benefit and hazard at the same time beneath the dubious wind control (speed) environment. To portray this uncertain environment, the Latin hypercube examining with Cholesky deterioration recreation strategy is utilized to test changeable wind speeds. A progressed optimization algorithm, GSO with intraspecific competition and Le ´vy walk, is at that point used to optimize the MV show by presenting the hazard resistance parameter. The experimental is conducted based on the IEEE 30-bus control framework, and the outcomes to illustrate the adequacy and legitimacy of the proposed demonstration and the optimization algorithm.</p><p>Zheng et al. <ref type="bibr" target="#b39">[41]</ref> proposed a solution to solve the security-constrained unit commitment problem with combined hydro and thermal generation embedded (RCHTUC), by the self-learning GSO algorithm called SLGSO. The RCHTUC problem needs to minimize the total of fuel costs and start-up prices of thermal plants controlled to different operational limitations. To solve the RCHTUC problem, the proposed SLGSO is introduced from the basic GSO. This proposed method used covariance network to illustrate the ideal procedure and using Le ´vy flights to increase the differences in the bunch. The results are compared with other results on distinctive aqueous structures across the planning skyline. The results illustrated the productivity of the proposed SLGSO for handling the RCHTUC issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Economic load dispatch problem</head><p>Several studies have been done using the GSO algorithm to solve different optimization problems, especially in the economic load dispatch problem such as <ref type="bibr" target="#b53">[95,</ref><ref type="bibr" target="#b54">96,</ref><ref type="bibr" target="#b55">97]</ref>. Economic dispatch (ED) is a crucial optimization problem of a power system. In order to obtain a more accurate ED system, Junpeng et al. <ref type="bibr">[75]</ref> proposed a fast GSO algorithm called (FGSO). The ED design on three test modes is determined, and the simulation results proved that the proposed FGSO converged better, consumed a shorter time, and achieved results with less value of fuel price than the other comparative algorithms. The proposed FGSO achieved more accurate outcomes with less computational time.</p><p>Liao et al. <ref type="bibr" target="#b29">[31]</ref> presented the GSO to solve a control framework DE problem, which is to diminish the fuel fetched and transmission line misfortune within the control framework. GSO is inspired by creature looking behavior and gather living hypothesis. The system of GSO is based on the participation of makers, scroungers, and officers, which play diverse parts amid the look. GSO has been conclusively connected to fathom a more extensive extent of benchmark functions. This paper examines the application of GSO to resolve the control DE issue with the thought of minimizing the goals of fuel taken a toll and transmission line misfortune. The execution of GSO has been compared with that of hereditary algorithm (GA), and the molecule is a swarming optimizer (PSO). The recreation comes about has illustrated that GSO beats the other two algorithms. The application is additionally expanded to decide the ideal areas and control parameters of the adaptable AC transmission system (actualities) gadgets to realize the objective. Results have been carried out on a standard test framework, and superior comes about have been gotten by GSO.</p><p>Liao et al. <ref type="bibr" target="#b56">[98]</ref> proposed a modern optimization algorithm for the arrangement of non-convex and expansive scale ED issues. A ceaseless form of speedy GSO called (QGSO) algorithm is introduced. A more practical ED detailing with considering valve-points impact precluded working zones, transmission misfortunes, and ramp-rate limits are utilized. The execution of the proposed strategy is confirmed by the performance of five test frameworks. Case ponders and numerical illustrations show that the proposed ceaseless QGSO algorithm has superior arrangement quality comparing with the foremost of the latest detailed algorithms within the writing.</p><p>Guo et al. <ref type="bibr" target="#b57">[99]</ref> presented a good strategy for energetic financial emanation expedite (DEED) of control frameworks, employing a novel multi-objective developmental algorithm, GSO with different makers (GSOMP), that incorporates immediate taking care of conspiring presented to bargain with complex limitations. The execution of GSOMP has been assessed on the DEEDs of the IEEE 30-bus and 118-bus frameworks, individually, in comparison with those of multi-objective molecule swarm optimizer (MOPSO) and non-dominated sorting hereditary algorithm-II (NSGA-II). The obtained results showed that the proposed strategy has better execution than MOPSO and NSGA-II and expends much less time than the comparative method.</p><p>Kazem et al. <ref type="bibr" target="#b58">[100]</ref> proposed a novel arrangement based on the GSO strategy in arrange to decide the available ideal method of the ED issue considering valve stacking impacts. The fundamental drawback of the first GSO algorithm is the reality that it provides a near-optimal arrangement instead of an ideal one in a restricted runtime period. In this paper, an excellent modified GSO (MGSO) is displayed for progressing the scrounger and officer administrators of GSO. The MGSO is connected to distinctive test frameworks and matched with similar methods. The outcomes show the adequacy of the MGSO and demonstrate that MGSO can be appropriate for tackling the control framework financial stack alacrity issue, particularly in colossal scale control frameworks.</p><p>Srinivasa et al. <ref type="bibr" target="#b59">[101]</ref> presented a discourse of ''Solving non-convex financial expedite issue with valve point impacts utilizing altered bunch look optimizer method.'' They talked about paper displayed financial celerity issues by testing with three case frameworks considering 3-, 13-, and 40-unit test frameworks considering non-convex taken a toll work with valve point stacking impacts. In any case, within the detailed comes about for the 13-unit test framework with two different stack requests, the total costs cited were diverse for the given era plan. In this communication, clarification concerning taken toll algorithms is displayed. Another discussion can be found in <ref type="bibr" target="#b56">[98]</ref>.</p><p>Farheen et al. <ref type="bibr" target="#b60">[102]</ref> used the GSO to discover the worldwide arrangement for nonlinear optimization issues whereas fulfilling correspondence and imbalance imperatives within the setting of time sweeping assessment of functions. GSO method actualizes the creature filtering instrument metamorphically to plan ideal looking methodologies for understanding optimization issues. Bunch look algorithm utilized in this paper is populacebased algorithm, and asset looking preparation of creatures in nature closely resembles the method of searching for optima in a look space. The promising comes about on the benchmark work appears the pertinence of the gather look optimizer for fathoming financial stack celerity issue. The legitimacy of the proposed strategy has been illustrated for three-, four-, and six-generator electrical control framework.</p><p>Li et al. <ref type="bibr" target="#b61">[103]</ref> presented the mean-variance (MV) to fathom control framework celerity issues with wind control coordinates. Within the MV show, the benefit and the risk are taken into consideration at the same time beneath the dubious wind control (speed) environment. To portray this suspicious environment, the Monte Carlo (MC) reenactment strategy is utilized to test questionable wind speeds. Th GSO algorithm optimizes the MV show by presenting the chance resistance parameter. The recreation is performed based on the IEEE 30-bus control framework, and the outcomes to illustrate the appropriateness of the proposed show into control framework alacrity issues with wind control coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.4">Optimal design problem</head><p>Several studies have been done using the GSO algorithm to solve different optimization problems, especially in the optimal design problem such as [59, <ref type="bibr" target="#b62">104,</ref><ref type="bibr" target="#b63">105]</ref>. Feng et al.</p><p>[70] proposed an improved GSO algorithm (QGSO) to solve structural optimization design jobs. The development of this version has three main features. First, increase the number of ranger, while the target stops going ahead. Second, utilize the search procedure of PSO by studying the best group agent and the most reliable personal agent and use the step search procedure to repair the visual search approach. Third, it represents the ranger with a combination of the group's best agent and the person's most suitable agent. The QGSO algorithm is used to examine the planar and term truss structures with discrete values. The obtained results of the proposed algorithm are associated with the GSO and HPSO. The results confirmed that the proposed QGSO got a better convergence rate and accuracy rate.</p><p>Feng-ming et al.</p><p>[71] proposed a combined method, the GSO algorithm with Pareto solutions theory called MGSO, to solve engineering structure problems. Two cases, including a 10-bar planar truss construction with continuous values and a 25-bar space truss structure with discrete values, are applied to assess the production of the proposed MGSO algorithm. The obtained results confirmed the probability and advantage of MGSO in addressing structure optimal design. The proposed MGSO is of apparent benefits for addressing complex engineering problems, particularly the high-dimensional problems.</p><p>Jing et al.</p><p>[77] introduced a new multi-objective GSO algorithm based on a quick group called MQGSO. This proposed algorithm is mixed with the Pareto optimal theory and crowding distance tool. The proposed MQGSO is utilized to the cross-sectional optimization of 10-bar planar truss construction and the shape optimization of 25-bar spatial truss structures. The proposed MQGSO algorithm got the right balance and high convergence rate compared with other well-known optimization algorithms.</p><p>Zeng and <ref type="bibr">Li [69]</ref> proposed an unused adaptation of the GSO blended with the inactive assemblage to move forward the structural adaptation called IGSO. The proposed adaptation is tried on shape optimization plan of truss structures with discrete factors, counting planar trusses, and spatial trusses. A few numerical illustrations are given to test the IGSO algorithms. The optimization comes about are compared with those of the GSO algorithms and a few algorithms in reference. The outcomes show that the IGSO algorithms have way better execution in terms of merging than the GSO algorithm and other algorithms and can discover the ideal arrangement with less emphasis. Rather, compared with that of the GSO algorithm, the IGSO algorithm program explanation is briefer and more comfortable to be modified. IGSO ought to be utilized for underlying ideal plan issues.</p><p>Guang et al.</p><p>[62] presented a fast GSO with inactive assemblage (QGSOPC) for the ideal plan of stick-associated structure. The algorithm is based on fast GSO (QGSO). The proposed QGSOPC is confirmed and matched with other similar methods for solving the plans of two planar and spatial truss structures. The outcomes showed that the QGSOPC algorithm not as it had an ideal joining rate and precision. However, it has the most excellent solidness of joining scale and accuracy. It is craved for QGSOPC to be utilized more viably for commonsense underlying ideal plan issues.</p><p>Haobin et al.</p><p>[63] utilized a new optimization technique, named GSO algorithm with a couple of advancements, to truss structure problems. Moreover, the progressed strategies are utilizing concordance memory and following to the boundary, which can move forward the algorithm. At that point, a straightforward and compelling topology strategy, discretization of topology factors are consolidated with made strides GSO to create beyond any doubt that the design optimization operates well. After the paper, two ideal design models are utilized to examine these problems based on the made strides GSO. The results show that the approach with moved forward GSO is doable and reliable for truss design problems.</p><p>Hai et al.</p><p>[56] presented an improved GSO algorithm called (iGSO) for fathoming mechanical plan problems. Within the proposed method, subpopulations and a developmental cooperation technique were received to develop the worldwide look ability and merging execution. The proposed iGSO is assessed on two hard optimization problems of the classical mechanical plan: spring and weight vessel. The test comes about is analyzed with those detailed within the sorts of writing. The results show that iGSO has many ways of better merging execution and is less demanding to actualize in comparison with other similar methods.</p><p>Li-juan et al.</p><p>[64] presented a novel optimization algorithm called GSO algorithm. The execution strategy of this algorithm is displayed in detail. The GSO is utilized to explore the truss structures with nonstop factors and was tried by three truss structure optimization issues. The optimization comes about was compared with those of the PSO, the PSO with the inactive assemblage (PSOPC), and the HPSO. The proposed algorithm results showed that the GSO has best joining rate and exactness. Results from the three tried cases outlined the competitive capacity of the GSO to discover the ideal comes about. It is craved for GSO to be utilized for underlying ideal plan issues.</p><p>Xie et al.</p><p>[66] presented a novel method, named GSO, to solve design problems. The GSO is moved forward in two angles, which are counting utilizing agreement memory and following to the boundary. Two topology strategies, such as heuristic topology and discretization of topology factors, are joined with GSO. Two numerical cases were utilized to test the enhanced GSO. The obtained outcomes show that the improved GSO is attainable and stable for design problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Networks applications</head><p>Several studies have been done using the GSO algorithm to solve different optimization problems, especially in the networking domains such as <ref type="bibr" target="#b64">[106]</ref><ref type="bibr" target="#b65">[107]</ref><ref type="bibr" target="#b66">[108]</ref>. Localization is one of the most difficulties in remote sensor systems. It is conducted to decide the area data of sensor hubs within the organization. When the sensors gather information and report occasions, it is critical to recognize the beginning of knowledge and opportunities. In this paper <ref type="bibr" target="#b67">[109]</ref>, a new optimization algorithm, called GSO, is introduced for finding sensor hubs in a dispersed WSN situation. WSN localization is defined as a nonlinear optimization issue and unraveled utilizing GSO.</p><p>Xiang et al. <ref type="bibr" target="#b68">[110]</ref> proposed a modern Web of Things GSO called (ITGSO) to unravel data combination issues cleverly within the high-dimensional multi-sensor systems. ITGSO is inspired by the most recent inquire about accomplishment around pioneer choice in Nature and works almost social coordination, which comprises three parts: fundamental bunch look optimizer, parallel gather look optimizer, and social choice demonstrates. With ITGSO, they require less time to get least Bayes taken a toll than molecule swarm optimization. And data of questionable social cleverly issues can be combined. In this paper, they grant the hypothetical essential of ITGSO and demonstrated its legitimacy utilizing numerical examination. Another discussion can be found in <ref type="bibr" target="#b69">[111]</ref> Dan et al. <ref type="bibr" target="#b70">[112]</ref> introduced a diversity-guided GSObased approach for tackling the area administration issue in versatile computing. The area administration issue, which is to discover the ideal arrange setups of administration beneath the portable computing environment, is considered here as an optimization issue. The proposed diversityguided GSO algorithm is realized with the help of differing qualities administrator, which makes a difference ease the previous meeting issue of gather look optimizer algorithm, a fruitful optimization algorithm inspired by the creature behavior. To address the area administration problem, diversity-guided GSO algorithm is misused to optimize arrangement setups of administration by minimizing the whole of area overhaul taken a toll and area paging fetched. Exploratory comes about outlines the viability of the proposed approach.</p><p>Qi et al. <ref type="bibr" target="#b71">[113]</ref> proposed a novel productive populationbased heuristic approach for ideal area and capacity of dispersed eras (DGs) in dispersion systems. The proposed method deals with minimizing the destinations of fuel fetched, control misfortune diminishment, and voltage profile advancement. The approach utilizes an improved GSO (iGSO) by consolidating PSO into GSO for the ideal set of DGs. The proposed method is executed on an organized dispersion system-the IEEE 14-bus test framework for diverse targets. The outcomes are moreover compared to those performed by fundamental GSO algorithm and PSO algorithm on the same test framework. The outcomes show the viability and promising applications of the proposed approach in the ideal area and capacity of DGs.</p><p>Harikrishnan and Kumar <ref type="bibr" target="#b72">[114]</ref> proposed an approach of one such bio-inspired algorithm called as GSO localization algorithm coordinates with Xbee arduino sensor arrange, which is utilized to play down the localization blunder of remote sensor systems. The estimate is created from the motivation of creature nourishment and necessary need foraging behavior and could be a gather-based localization optimization algorithm. This utilizes an asset finding maker and scrounger devotee show. Genuine-time information collected by Xbee arduino sensor arrange is being used by GSO localization algorithm to self decide the area data of sensor hubs.</p><p>Arul et al. <ref type="bibr" target="#b73">[115]</ref> proposed an information calamity recuperation handle utilizing oppositional GSO (OGSO) algorithm, which primarily maintains a strategic distance from the fiasco within the cloud. The proposed information recuperation handle comprises four modules, such as record uploading module, reproduction era module, information reinforcement module, and catastrophe recuperation module. They divide the information into several records and transfer the record to the comparing virtual machine utilizing OGSO algorithm. After that, they create a reproduction based on each record transfer speed. The print is primarily used for information reinforcement procedures. At last, the client inquiry-based records are reinforcement and recovery based on copies. The exploratory comes about to shows that the proposed OGSO-based information calamity recuperation prepared is superior to other approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Other applications</head><p>Several studies have been done using the GSO algorithm to solve different optimization problems such as <ref type="bibr" target="#b74">[116,</ref><ref type="bibr" target="#b75">117]</ref>. Zhao et al. <ref type="bibr">[78]</ref> proposed an improved GSO based on the system of the social algorithm is displayed. Also, the colony fitness fluctuation is presented to choose whether to experience the operation of impact function such that the meeting effectiveness can arise. The comparison experimentations with GA, PSO, and GSO are made, and the made strides GSO algorithm is additionally connected to the optimization problem of the benefit within the butane alkylation prepare. The obtained results issued the viability of the made strides algorithm.</p><p>Hui et al.</p><p>[79] proposed a strategy for cognitive radio (CR) range detection based on made strides GSO algorithm. The improved GSO is utilized to induce the weight vector within the straight participation show. Moreover, it is compared with the four strategies of the single CR strategy, the determination combining strategy (SC), the break even with pick-up combining strategy (EGC), and the altered avoidance coefficient strategy (MDC). Recreation comes about shows that the made strides GSO is superior in the meeting than the traditional gather look optimizer. It can get superior location likelihood than the four strategies. The discovery execution gets to be higher with the increment of CR clients and gets to be lower beneath the more awful of commotion condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and theoretical aspects</head><p>This section presents theoretical aspects, assessment, and evaluation of the GSO algorithm.</p><p>Global numerical problems like benchmark optimization functions are associated with a process of obtaining nearoptimal agents of a mathematical paradigm through obtaining the desired minimum or maximum values (objective function). Because increasing the complexity of the optimization process employed in several optimization problems, the development of effective stochastic techniques is becoming much necessary, critical, and important than before. Over the recent decade, many complex optimization methods have been applied according to different aspects of biology or natural life.</p><p>According to the candidate agents, optimization algorithms are divided into a couple of subclasses of individualbased optimization methods (one agent/LSOMs) and population-based optimization techniques (many agents/ PSOMs). Extensive data is needed by the above stated, that is individual-based optimization algorithms, and it usually, this type works via one single unsystematic agent, improved over a specified number of iterations. These kinds of algorithms need less mathematical algorithm, and the right approach is implemented to obtain the near-optimal agent (globally) for the sake of natural patterns or problems. However, they usually have defects such as illation mechanism, new convergence (fast), and sensitive search (unstable) in complex situations. Concerning the last, the stochastic procedures trend to start with a population of stochastic agents generated from the available search regions and developed by the iterations, one by one. It is a fundamental technique that utilized these generating agents to avert trapped in local search. Furthermore, the mutual information across the candidate agents further supports the used technique grows, although several dilemmas of complex-wide search regions <ref type="bibr" target="#b76">[118]</ref>.</p><p>The distribution of the addressing rule is classified into a couple of stages, which is the prime advantage of multiagent methods (i.e., stochastic search: exploration and exploitation) <ref type="bibr" target="#b77">[119]</ref>. The above-mentioned (exploration) indicates a manner where the population (agents) trend to be developed repeatedly and examine the encouraging areas of the search space as ample as possible. Dissimilarity and the search agents are controlled or led by the exploitation or intensification to draw close the near-optimal agent obtained in the global search stage.</p><p>The converging on local search has resulted in a fast convergence, but the dominant local search strategy is escaped from this problem, and the result id maintaining the agents diversification. Therefore, a robust procedure can work in producing a normal equipoise among these search methods (i.e., exploration and exploitation). More newly, meta-heuristic optimization methods have worked notably in addressing a wide variety of real-world optimization problems because of its features such as adaptability, naturalness, privation-free technicality, and escape the local optima. For this reason, these methods (the population-based optimization algorithms) employed to solve various problems quickly. Researchers applied several reliable and valuable optimization approaches because natural life behaviors motivate them.</p><p>The benefit of meta-heuristic algorithms is illustrated for many causes. The first cause, the utility of random procedure, supports these algorithms to avoid the stuck in local search and converge to the near-optimal agent. Presently, the goal is not to get the best agent of the problem agents but to determine the near-optimal agent (with high-grade fineness within a reasonable running time). The main factor in producing this objective is to get the proper balance across search strategies. Exploration propose is to determine the more encouraging areas in a complex-wide search area.</p><p>Consequently, the exploitation strategy is enhanced (intensified) by the local search strategy in an encouraging area to produce better agents. The optimal execution and effectiveness of a particular optimization technique in trade-off these methods, the superior ability will be achieved. The current meta-heuristic algorithms achieve the balance among these two methods. In different ways, they could be further modified and adjusted for local or for global search strategies. Two or more optimization techniques are merged by combining its components to get its stable features together and powerful than each one alone while averting as much as potential their disadvantages and shortcomings. The second cause, the success of optimization techniques, is due to its principle, abilities, simplicity, and adjust experimentally.</p><p>Optimization algorithms have been used widely to tackle different problems. However, for complex cases, the most significant part of the optimization techniques still yield trapped in local search and be unsuccessful in achieving the near-global agent. This is the purpose of the week of diversification (global search) part (i.e., component) in the used technique. Several diversification search strategies are employed to enhance the effectiveness of well-known optimization techniques and support in stopping the drawbacks. These optimization techniques are hybridization and elitism: the existence of an elite as a dominating component in a method <ref type="bibr" target="#b78">[120,</ref><ref type="bibr" target="#b79">121]</ref>. GSO algorithm has grown exponentially and become a powerful mechanism for tackling complex problems as other optimization techniques. It is an artificially intelligent technique, works by stochastic computational mechanisms, to determine the near-optimal agent for the multi-dimensional functions and one-dimensional according to its objective function. The GSO algorithm runs in a standard procedure; it is easily implemented and easily used in a wide variety of domains. The results summarized in this review paper give evidence and proof of performance achievement of the GSO algorithm in regard to the effectiveness and accuracy of the obtained best result. This assurance is determined according to exploring and analyzing the obtained results among the GSO algorithm and recently published optimization techniques.</p><p>Similar to several optimization techniques, the GSO algorithm owns several advantages (strong points) and few weaknesses. Even though there is no concourse evidence for this algorithm, the final characterizations are summarized in this review to prove that the GSO competitiveness over other optimization algorithms in regard to convergence accelerated (rate). Table <ref type="table" target="#tab_6">4</ref> shows the advantages and disadvantages of the GSO algorithm. The main challenge of the GSO algorithm is how to determine the probabilistic convergence characteristics of GSO, which is needed to grasp the given technique fully. The issue of new convergence (premature convergence) in the GSO usually begins the improvement procedure to be stuck during the exploitation search. This issue usually happens, while the agent's divergence reduces, and the agents cannot avoid falling in the local optima. Moreover, there are significant potentials for researchers to utilize and apply the advantages of the GSO algorithm to address the involved industry and any real-world problems.</p><p>Based on the previous studies, there are developing models in general direction that appeared in the years 2009 to 2020. Figure . 2 presents a different kind of hybridization, modifications, binary, alternatives, and applications in regard to the whole published papers per year. As observed in the results of Table <ref type="table" target="#tab_0">1</ref>, 2014 presents the highest use of the GSO algorithm compared to the rest years. This certainly proved that the use of the GSO algorithm in that domain had gained attention and benefit after one year. Figure <ref type="figure" target="#fig_0">1</ref> demonstrates clearly that the GSO was employed with different optimization methods and problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and comparisons</head><p>This section offers a wide variety of benchmark test function (as standard optimization problems) with various characteristics (as shown in Table <ref type="table" target="#tab_7">5</ref>) to examine, analyze, and validate the effectiveness of the GSO <ref type="bibr" target="#b80">[122]</ref> compared to other comparable and well-known optimization algorithms (i.e., particle swarm optimization (PSO) <ref type="bibr" target="#b81">[123]</ref>, genetic algorithm (GA) <ref type="bibr" target="#b82">[124]</ref>, bat algorithm (BA) <ref type="bibr" target="#b83">[125]</ref>, firefly algorithm (FA) <ref type="bibr" target="#b84">[126]</ref>, and gravitational search algorithm (GSA) <ref type="bibr" target="#b15">[17]</ref>). Results values are normalized between 0 and 1 to investigate and compare the obtained results of all benchmark function problems. To conclude the importance and significance of the obtained results, a ranking statistical test called Friedman ranking test is carried out and is shown in Table <ref type="table" target="#tab_8">6</ref>.</p><p>As shown in Table <ref type="table" target="#tab_7">5</ref>, the obtained results show that the GSO algorithm got better results in almost all test cases and comparative results in some cases. Firstly, the GSO provides better results on three out of six unimodal benchmark functions according to the given results above. Because of the characteristics of the unimodal test functions, these obtained results proved that the GSO algorithm has high exploitation search and convergence rates. Secondly, as shown in Table <ref type="table" target="#tab_7">5</ref>, the results confirmed that the GSO got better results compared with all optimization algorithms employed on the multi-modal benchmark functions (F7, F9, F11, and F12). The obtained results confirmed the GSO benefits from high exploration search and averted from the trapped in local optima. Finally, the results of the GSO on the composite benchmark functions confirmed the excellence of GSO in solving optimization problems with extended search spaces. According to the normalization results, the overall performance of all parallel algorithms can also be compared. The last row of Table <ref type="table" target="#tab_7">5</ref> shows the summation of the average results of all algorithms on all benchmark functions. It is observed that GSO gives the minimum average value that GSO reliably overwhelms other comparative algorithms. Table <ref type="table" target="#tab_8">6</ref> shows the summation, average, and final ranking of the ranking results of all algorithms on all benchmark functions. The ranking results in Table <ref type="table" target="#tab_8">6</ref> show that the performance of the GSO is statistically significant; it got the first ranking compared with all well-known optimization algorithms followed by FA, PSO, GSA, GA, and BA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and possible future directions</head><p>In this paper, a comprehensive and exhaustive literature review of the group search optimizer (GSO) algorithm is presented. The main aim of this survey is studying and reviewing the variants, applications, and results of the GSO algorithm in all categories. All the given details and information in this paper were taken from the published papers that have been used GSO algorithm in solving various problems such as benchmark functions, machine learning, engineering, networks, and other optimization problems. Moreover, several researchers noted that the GSO algorithm could solve other complex optimization problems such as scheduling problems, clustering optimization problems, pattern recognition problems, and unconstrained optimization problems. Consequentially, the GSO is a robust algorithm in all the examined problems based on the given analysis and information. As the conclusion, there is still needed for improving the performance of GSO algorithms by extending the basic version into different hybridizations, modifications, improved, and other variants based on the demands of the given problems. Consequently, the results of this survey paper could be useful for researchers who are interested in researching in that domain by showing the conducted improvements and applications, and its advantages, and disadvantages.</p><p>For possible future research, we recommend to employ and enhance the GSO algorithm with other algorithms components or other techniques for further improvements to solve new optimization problems. In future work, we will focus on the following aspects:</p><p>• Adapting the GSO algorithm to solve the unsolved optimization problems before by GSO algorithm (new optimization problems). • Employing the GSO algorithm to solve multi-objective optimization problems. • Modifying the GSO algorithm to deal with NP-hard real-world problems and other optimization problems.</p><p>Compliance with ethical standards </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Applications of the group search optimizer algorithm</figDesc><graphic coords="3,183.69,324.28,360.69,208.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 Fig. 3</head><label>23</label><figDesc>Fig. 2 Variants of the group search optimizer algorithm</figDesc><graphic coords="4,183.69,59.24,360.69,204.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,203.53,448.84,340.76,262.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="6,203.50,68.81,272.92,238.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The number of published papers based on the publishers</figDesc><table><row><cell cols="2">Publisher IE.</cell><cell>Els.</cell><cell>Sp.</cell><cell>Hin.</cell><cell>TF.</cell><cell>Oth.</cell></row><row><cell>Year</cell><cell cols="2">J. C. Ch. J.</cell><cell></cell><cell></cell><cell></cell></row></table><note><p>C. Ch. J. C. Ch. J. C. Ch. J. C. Ch. J. C. Ch.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>The variants of the group searching optimizer algorithm</figDesc><table><row><cell>Proposed</cell><cell>Application</cell><cell>Description</cell><cell>Results and conclusion</cell><cell>Year Authors/</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Ref)</cell></row><row><cell>GSO</cell><cell>Benchmark</cell><cell>A new optimization</cell><cell>The GSO algorithm has competitive execution to other EAs</cell><cell>Shan et al.</cell></row><row><cell></cell><cell>functions</cell><cell>algorithm called GSO</cell><cell>in terms of exactness and meeting speed, particularly on</cell><cell>[23]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>high-dimensional multimodal issues</cell><cell></cell></row><row><cell>GSO</cell><cell>High-</cell><cell>A new combination of</cell><cell>This proposed method is superior to the basic GSO</cell><cell>Juanyan</cell></row><row><cell></cell><cell>dimensional</cell><cell>GSO by hybridizing</cell><cell>algorithm and particle swarm optimization in multi-model</cell><cell>et al. [28]</cell></row><row><cell></cell><cell>problems</cell><cell>metropolis rule</cell><cell>optimization problems</cell><cell></cell></row><row><cell>GSO</cell><cell>Unconstrained</cell><cell>Basic GSO algorithm</cell><cell>The exploratory comes about shows that GSO can discover</cell><cell>Hai et al.</cell></row><row><cell></cell><cell>optimization</cell><cell></cell><cell>the precise or near to universally ideal methods on most</cell><cell>[29]</cell></row><row><cell></cell><cell>problems</cell><cell></cell><cell>issues. GSO can unravel the obliged problem and is an</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>elective bio-inspired optimization algorithm</cell><cell></cell></row><row><cell>CGSO</cell><cell>Benchmark</cell><cell>Improved GSO with</cell><cell>The obtained results showed that CGSO is more effective</cell><cell>Fang and</cell></row><row><cell></cell><cell>functions</cell><cell>chaotic mutation</cell><cell>than other well-known algorithms</cell><cell>Chen [30]</cell></row><row><cell>GSO</cell><cell>Control</cell><cell>Basic GSO</cell><cell>The application is additionally expanded to decide the ideal</cell><cell>Liao et al.</cell></row><row><cell></cell><cell>financial</cell><cell></cell><cell>areas and control parameters of the adaptable AC</cell><cell>[31]</cell></row><row><cell></cell><cell>problem</cell><cell></cell><cell>transmission system (actualities) gadgets to realize the</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>objective. Results have been obtained by a standard test</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>framework, and superior results have been obtained by</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>GEO.</cell><cell></cell></row><row><cell>IGSO</cell><cell>Benchmark</cell><cell>An improved GSO</cell><cell>The made strides GSO algorithm (IGSO) is tested on a few</cell><cell>Debao et al.</cell></row><row><cell></cell><cell>functions</cell><cell>optimizer with quantum</cell><cell>benchmark functions and compared with others</cell><cell>[32]</cell></row><row><cell></cell><cell></cell><cell>behavior</cell><cell></cell><cell></cell></row><row><cell>NMGSO</cell><cell>Multi-objective</cell><cell>A new multi-objective</cell><cell>The obtained results illustrated the effectiveness and</cell><cell>Ling et al.</cell></row><row><cell></cell><cell>problems</cell><cell>GSO (NMGSO)</cell><cell>robustness of the proposed method</cell><cell>[33]</cell></row><row><cell>GSO</cell><cell>Pareto</cell><cell>A new multi-objective</cell><cell>The proposed algorithm comes about shows the stochastic</cell><cell>Feng et al.</cell></row><row><cell></cell><cell>arrangements</cell><cell>GSO</cell><cell>algorithm has fantastic performance in terms of joining</cell><cell>[34]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>rate, achievable, common sense, and prevalence in</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>structure ideal plan</cell><cell></cell></row><row><cell cols="2">GSOICLW Optimal power</cell><cell>GSO with interspecific</cell><cell>The obtained results illustrated the precision and unwavering</cell><cell>Li et al. [35]</cell></row><row><cell></cell><cell>flow</cell><cell>competition and Le ´vy</cell><cell>quality of the proposed algorithm, compared with other</cell><cell></cell></row><row><cell></cell><cell></cell><cell>walk</cell><cell>EAs</cell><cell></cell></row><row><cell>SEGSO</cell><cell>Benchmark</cell><cell>A new method to solve</cell><cell>The obtained results showed that SEGSO got better</cell><cell>Zheng et al.</cell></row><row><cell></cell><cell>functions</cell><cell>the weaknesses of the</cell><cell>outcomes compared with others</cell><cell>[36]</cell></row><row><cell></cell><cell></cell><cell>GSO</cell><cell></cell><cell></cell></row><row><cell>GSO</cell><cell>Dynamic</cell><cell>GSO with versatile</cell><cell>The proposed plan can understand the energetic financial</cell><cell>Chen et al.</cell></row><row><cell></cell><cell>economic</cell><cell>techniques</cell><cell>celerity issue effectively</cell><cell>[37]</cell></row><row><cell></cell><cell>dispatch</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FGGSO</cell><cell>Benchmark</cell><cell cols="2">Enhanced GSO algorithm The obtained results designated a remarkable enhancement</cell><cell>Kang and</cell></row><row><cell></cell><cell>functions</cell><cell></cell><cell>in the performance of certain problems</cell><cell>Gu [38]</cell></row><row><cell>QGSO</cell><cell>Benchmark</cell><cell>The QGSO algorithm in</cell><cell>The obtained results revealed that the QGSO algorithm</cell><cell>Jin et al.</cell></row><row><cell></cell><cell>functions</cell><cell>the seismic</cell><cell>received better output matched with the PSO</cell><cell>[39]</cell></row><row><cell></cell><cell></cell><cell>investigation</cell><cell></cell><cell></cell></row><row><cell>GSO</cell><cell>Optimal power</cell><cell>GSO with interspecific</cell><cell>The outcomes illustrated the adequacy and legitimacy of the</cell><cell>Yuanzheng</cell></row><row><cell></cell><cell>flow</cell><cell>competition and Le ´vy</cell><cell>proposed demonstration and the optimization algorithm</cell><cell>et al. [40]</cell></row><row><cell></cell><cell></cell><cell>walk</cell><cell></cell><cell></cell></row><row><cell>RCHTUC</cell><cell>Optimal power</cell><cell>Self-learning GSO</cell><cell>The results are compared with those obtained by other</cell><cell>Zheng et al.</cell></row><row><cell></cell><cell>flow</cell><cell></cell><cell>procedures on distinctive aqueous frameworks over the</cell><cell>[41]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>planning skyline. The results illustrated the productivity of</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>the SLGSO for handling the RCHTUC issue</cell><cell></cell></row><row><cell>GSO</cell><cell>Engineering</cell><cell>self-learning GSO</cell><cell>The proposed method got better results in comparison with</cell><cell>Abdollah</cell></row><row><cell></cell><cell>problems</cell><cell></cell><cell>others</cell><cell>et al. [42]</cell></row><row><cell>GSO</cell><cell>Optimization</cell><cell>An opposition-based</cell><cell>The proposed crossover GSO algorithm performed</cell><cell>Chengwang</cell></row><row><cell></cell><cell>problems</cell><cell>learning approach with</cell><cell>preferences over past GSO and DE approaches in merging</cell><cell>et al. [43]</cell></row><row><cell></cell><cell></cell><cell>GSO</cell><cell>speed and precision of arrangement</cell><cell></cell></row><row><cell cols="2">CMOGSO Multi-objective</cell><cell>A cooperative co-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>optimization</cell><cell>evolutionary multi-</cell><cell></cell><cell></cell></row><row><cell></cell><cell>problems</cell><cell>objective GSO</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>(continued)    </figDesc><table><row><cell>Proposed</cell><cell>Application</cell><cell>Description</cell><cell>Results and conclusion</cell><cell>Year Authors/</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Ref)</cell></row><row><cell>GSO</cell><cell>Networking</cell><cell>Multi-objective GSO</cell><cell>The proposed strategy claims the excellent performance in</cell><cell>2015 Ya-zhou</cell></row><row><cell></cell><cell></cell><cell></cell><cell>terms of the income and acknowledgement proportion</cell><cell>et al. [45]</cell></row><row><cell>DGSO-</cell><cell>Networking</cell><cell>Discrete GOS (DGSO-</cell><cell>The capability of the proposed algorithm to successfully</cell><cell>2016 Ahmed</cell></row><row><cell>MDNet</cell><cell></cell><cell>MDNet)</cell><cell>detect the structure hidden within these networks</cell><cell>et al. [46]</cell></row><row><cell>DGSO</cell><cell>Networking</cell><cell>Discrete GSO algorithm</cell><cell>The proposed DGSO algorithm to robustly detect the</cell><cell>2016 Mahmoud</cell></row><row><cell></cell><cell></cell><cell>(DGSO)</cell><cell>construction hidden within heterogeneous networks</cell><cell>et al. [46]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>matched with other high-performance optimization</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>algorithms</cell><cell></cell></row><row><cell>GSO</cell><cell>Fuzzy time</cell><cell>Modified GSO</cell><cell>The obtained results revealed that the proposed model</cell><cell>2017 Chin-Ling</cell></row><row><cell></cell><cell>series</cell><cell></cell><cell>achieves the smallest forecast error</cell><cell>et al. [47]</cell></row><row><cell>HGSO</cell><cell>Excessive</cell><cell>Combining genetic</cell><cell></cell><cell></cell></row><row><cell></cell><cell>dimension</cell><cell>algorithm (GA) and</cell><cell></cell><cell></cell></row><row><cell></cell><cell>interleaved</cell><cell>GSO</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>The applications of the group searching optimizer algorithm</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Neural Computing and Applications</cell></row><row><cell cols="2">Proposed Application</cell><cell>Description</cell><cell>Results and conclusion</cell><cell>Year Authors/</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Ref)</cell></row><row><cell cols="3">GSOANN Neural network The GSO with artificial</cell><cell>The proposed for ANN making in later a long time, counting</cell><cell>Shan et al.</cell></row><row><cell></cell><cell></cell><cell>neural organize</cell><cell>a few ANN outfits; GSOANN has way better meeting and</cell><cell>[60]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>generalization exhibitions on the two benchmark issues</cell><cell></cell></row><row><cell>GSO</cell><cell cols="2">Neural network A new optimization</cell><cell>The proposed GSO got better merging rate and generalization</cell><cell>Wu et al.</cell></row><row><cell></cell><cell></cell><cell>algorithm: a GSO</cell><cell>exhibitions for the breast cancer conclusion issue</cell><cell>[61]</cell></row><row><cell cols="2">QGSOPC Pin-connected</cell><cell>A fast GSO with inactive</cell><cell>The results show that the QGSOPC algorithm not only has</cell><cell>Guang</cell></row><row><cell></cell><cell>structure</cell><cell>assemblage (QGSOPC)</cell><cell>ideal joining rate and precision, but it has the most excellent</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>solidness of joining scale and accuracy</cell><cell>[62]</cell></row><row><cell>GSO</cell><cell>Truss structure</cell><cell>GSO with two</cell><cell>The results show that the approach with moved forward GSO</cell><cell>Haobin</cell></row><row><cell></cell><cell>topology</cell><cell>advancements</cell><cell>is doable and strong for truss topology optimization</cell><cell>et al.</cell></row><row><cell></cell><cell>optimization</cell><cell></cell><cell></cell><cell>[63]</cell></row><row><cell>iGSO</cell><cell>Plan</cell><cell>An improved GSO</cell><cell>The results show that iGSO has many ways better merging</cell><cell>Hai et al.</cell></row><row><cell></cell><cell>optimization</cell><cell>algorithm</cell><cell>execution and is less demanding to actualize in comparison</cell><cell>[56]</cell></row><row><cell></cell><cell>problems</cell><cell></cell><cell>with other existing developmental algorithms</cell><cell></cell></row><row><cell>GSO</cell><cell>Truss structure</cell><cell>A novel optimization</cell><cell>The proposed algorithm results show that the GSO has best</cell><cell>Li-Juan</cell></row><row><cell></cell><cell>design</cell><cell>algorithm called GSO</cell><cell>joining rate and exactness. Results from the three tried cases</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>outline the competitive capacity of the GSO to discover the</cell><cell>[64]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>ideal comes about</cell><cell></cell></row><row><cell>QGSO</cell><cell>Structure</cell><cell cols="2">Quick GSO called (QGSO) The results show that the QGSO has ideal meeting rate and</cell><cell>Qin et al.</cell></row><row><cell></cell><cell>optimization</cell><cell></cell><cell>precision. It is wanted for QGSO to be utilized viably for</cell><cell>[65]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>down to earth underlying whole plan issues</cell><cell></cell></row><row><cell>GSO</cell><cell>Structure</cell><cell>A novel GSO algorithm</cell><cell>Two numerical cases were utilized to test the improved GSO.</cell><cell>Xie et al.</cell></row><row><cell></cell><cell>optimization</cell><cell></cell><cell>The obtained results show that the improved GSO is</cell><cell>[66]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>attainable and strong for truss topology optimization</cell><cell></cell></row><row><cell>LGSO</cell><cell cols="2">Neural network Basic GSO with Le ´vy</cell><cell>The proposed algorithm produced better convergence and</cell><cell>Shan [67]</cell></row><row><cell></cell><cell></cell><cell>flight</cell><cell>generalization execution</cell><cell></cell></row><row><cell>GSO</cell><cell>Benchmark</cell><cell>An improved GSO</cell><cell>The improved GSO encompasses a prevalent look execution</cell><cell>Wen-fen</cell></row><row><cell></cell><cell>functions</cell><cell></cell><cell>on low-dimensional issues and high-dimensional issues</cell><cell>and</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Zhao-hui</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[68]</cell></row><row><cell>IGSO</cell><cell>Engineering</cell><cell>The GSO blended with the</cell><cell>The IGSO algorithm program explanation is briefer and more</cell><cell>Zeng and</cell></row><row><cell></cell><cell>problems</cell><cell>inactive assemblage</cell><cell>comfortable to be modified</cell><cell>Li [69]</cell></row><row><cell>QGSO</cell><cell>Engineering</cell><cell>Improved GSO algorithm</cell><cell>The proposed QGSO got a better convergence rate and</cell><cell>Feng et al.</cell></row><row><cell></cell><cell>problems</cell><cell>(QGSO)</cell><cell>accuracy rate</cell><cell>[70]</cell></row><row><cell>MGSO</cell><cell>Engineering</cell><cell>Combined GSO algorithm</cell><cell>The obtained results confirmed the probability and advantage</cell><cell>Feng-ming</cell></row><row><cell></cell><cell>problems</cell><cell>with Pareto solutions</cell><cell>of MGSO in addressing structure optimal design</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell>theory</cell><cell></cell><cell>[71]</cell></row><row><cell>IGSO</cell><cell>Benchmark</cell><cell>An improved version of the</cell><cell>The proposed QGSO got better results using four benchmark</cell><cell>Guohua</cell></row><row><cell></cell><cell>functions</cell><cell>GSO</cell><cell>functions</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[72]</cell></row><row><cell>GSO</cell><cell cols="2">Neural network Two half-breed agreeable</cell><cell>The GSO approaches utilizing participation could attain</cell><cell>Danielle</cell></row><row><cell></cell><cell></cell><cell>GSO approaches</cell><cell>superior generalization execution than Levenberg-</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Marquardt (LM) conventional GSO</cell><cell>[73]</cell></row><row><cell>GSO</cell><cell>Classification</cell><cell>A modern GSO-based</cell><cell>The outcomes show that the GSO-based highlighted</cell><cell>Cooper</cell></row><row><cell></cell><cell>problems</cell><cell>biomarker disclosure</cell><cell>determination algorithm is competent in selecting a stingy</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell>strategy</cell><cell>set of biomarkers to attain superior classification execution</cell><cell>[74]</cell></row><row><cell>FGSO</cell><cell>Economic</cell><cell>A fast GSO algorithm</cell><cell>The proposed FGSO achieved more accurate outcomes with</cell><cell>Junpeng</cell></row><row><cell></cell><cell>dispatch</cell><cell>(FGSO)</cell><cell>less computational time</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[75]</cell></row><row><cell>IDGSO</cell><cell>Continuous</cell><cell>The GSO incorporated</cell><cell>The GSO obtained a better result in the high-dimensional</cell><cell>Guo-Hua</cell></row><row><cell></cell><cell>optimization</cell><cell>with interactive dynamic</cell><cell>optimization problems</cell><cell>et al.</cell></row><row><cell></cell><cell></cell><cell>neighborhood</cell><cell></cell><cell>[76]</cell></row><row><cell>MQGSO</cell><cell>Engineering</cell><cell>A new multi-objective</cell><cell>The proposed MQGSO algorithm got the right balance, high</cell><cell>Jing et al.</cell></row><row><cell></cell><cell>problems</cell><cell>GSO algorithm based on</cell><cell>convergence rate compared with others</cell><cell>[77]</cell></row><row><cell></cell><cell></cell><cell>a quick group</cell><cell></cell><cell></cell></row><row><cell>GSO</cell><cell>Multi-model</cell><cell>An improved GSO based</cell><cell>The obtained results issued the viability of the made strides</cell><cell>Zhao et al.</cell></row><row><cell></cell><cell>problems</cell><cell>on the system of the</cell><cell>algorithm</cell><cell>[78]</cell></row><row><cell></cell><cell></cell><cell>social algorithm</cell><cell></cell><cell></cell></row><row><cell>123</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Several studies have been done using the GSO algorithm to solve different optimization problems, especially in the machine learning domain such as [89-91].</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>(continued)    </figDesc><table><row><cell cols="3">Neural Computing and Applications</cell><cell></cell><cell></cell></row><row><cell cols="2">Proposed Application</cell><cell>Description</cell><cell>Results and conclusion</cell><cell>Year Authors/</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(Ref)</cell></row><row><cell>GSO</cell><cell cols="2">Radio spectrum Improved GSO</cell><cell>The discovery execution gets to be higher with the increment</cell><cell>2013 Hui et al.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>of CR clients</cell><cell>[79]</cell></row><row><cell>DGSO</cell><cell>Flow shop</cell><cell>A random breakdown</cell><cell>The proposed DGSO algorithm significantly increases the</cell><cell>2014 Zhe and</cell></row><row><cell></cell><cell>scheduling</cell><cell>called with a discrete</cell><cell>performances matched with other algorithms</cell><cell></cell></row><row><cell></cell><cell></cell><cell>GSO (DGSO)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Xingsheng</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>[53]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>GSO</cell><cell>Flow shop</cell><cell>A multi-objective discrete</cell><cell>The proposed algorithm is predominant to two existing meta-</cell><cell>2016 Deng et al.</cell></row><row><cell></cell><cell>scheduling</cell><cell>GSOr</cell><cell>heuristics in terms of both modified generational remove</cell><cell>[52]</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and set scope</cell><cell></cell></row><row><cell>RGSO</cell><cell>Classification</cell><cell>Refined GSO called</cell><cell>The proposed methods are connected for good time datasets</cell><cell>2018</cell></row><row><cell></cell><cell>problems</cell><cell>(RGSO)</cell><cell>and benchmark datasets taken from dataset stores</cell><cell></cell></row><row><cell></cell><cell>Balakrishnan</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>and Thirunavu</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>[80]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Advantages and disadvantages of GSO algorithm</figDesc><table><row><cell>Advantages</cell></row><row><cell>-Combining with other operators is surprisingly gratifying</cell></row><row><cell>-An operative convergence speed</cell></row><row><cell>-Accelerated process in finding best agents</cell></row><row><cell>-Adjusting for various kinds of problems</cell></row><row><cell>-A suitable global method to explore</cell></row><row><cell>-Fit for large search area (continuous and discrete)</cell></row><row><cell>-Outstanding neighborhood exploration style</cell></row><row><cell>-Adjustability, robustness, and scalability are found as fundamental</cell></row><row><cell>features</cell></row><row><cell>-Active in controlling a vast number of decisions</cell></row><row><cell>-Have a higher probability and energy in making global optima</cell></row><row><cell>-Lower evenly of stuck in local optima</cell></row><row><cell>-Less dependence on initial agents</cell></row><row><cell>-GSO algorithm is straightforward in its idea and implementation</cell></row><row><cell>linked to other heuristic optimization procedures</cell></row><row><cell>-Cheap execution time</cell></row><row><cell>-No parameter tuning</cell></row><row><cell>Disadvantages</cell></row><row><cell>-The first presentation of GSO has been introduced for continuous</cell></row><row><cell>optimization problems</cell></row><row><cell>-Suffer from premature convergence</cell></row><row><cell>-No converging technical nature</cell></row><row><cell>-Likelihood configuration settings by reproductions</cell></row><row><cell>-No parameters tuning in the GSO algorithm</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>The average results for solving benchmark functions</figDesc><table><row><cell cols="4">Function Comparative algorithms</cell><cell></cell><cell></cell></row><row><cell></cell><cell>PSO</cell><cell>GA</cell><cell>BA</cell><cell>FA</cell><cell>GSA</cell><cell>GSO</cell></row><row><cell>F1</cell><cell cols="6">0.0003 0.8078 1.0000 0.0004 0.0000 0.0000</cell></row><row><cell>F2</cell><cell cols="6">0.0693 0.5406 1.0000 0.0177 0.0100 0.0000</cell></row><row><cell>F3</cell><cell cols="6">0.0157 0.5323 1.0000 0.0000 0.0016 0.0393</cell></row><row><cell>F4</cell><cell cols="6">0.0936 0.8837 1.0000 0.0000 0.1177 0.0934</cell></row><row><cell>F5</cell><cell cols="6">0.0000 0.6677 1.0000 0.0000 0.0000 0.0007</cell></row><row><cell>F6</cell><cell cols="6">0.0004 0.7618 1.0000 0.0000 0.0000 0.0002</cell></row><row><cell>F7</cell><cell cols="6">0.0398 0.5080 1.0000 0.0009 0.0021 0.0000</cell></row><row><cell>F8</cell><cell cols="6">1.0000 1.0000 0.0000 1.0000 1.0000 1.0000</cell></row><row><cell>F9</cell><cell cols="6">0.3582 1.0000 0.4248 0.0190 0.0222 0.0010</cell></row><row><cell>F10</cell><cell cols="6">0.1045 0.8323 0.8205 0.0000 0.1569 0.3804</cell></row><row><cell>F11</cell><cell cols="6">0.0521 0.7679 1.0000 0.0074 0.4011 0.0000</cell></row><row><cell>F12</cell><cell cols="6">0.0000 0.4573 1.0000 0.0000 0.0000 0.0000</cell></row><row><cell>F13</cell><cell cols="6">0.0000 0.6554 1.0000 0.0000 0.0000 0.0000</cell></row><row><cell>F14</cell><cell cols="6">0.1816 0.4201 1.0000 0.0000 0.0961 0.3965</cell></row><row><cell>F15</cell><cell cols="6">0.3016 0.0000 1.0000 0.4395 0.2926 0.0230</cell></row><row><cell>F16</cell><cell cols="6">0.0427 0.0000 0.3572 0.5298 1.0000 0.0497</cell></row><row><cell>F17</cell><cell cols="6">0.0294 0.1093 0.8189 0.7093 0.7887 0.0000</cell></row><row><cell>F18</cell><cell cols="6">0.1772 0.0000 1.0000 0.0723 0.8018 0.0129</cell></row><row><cell>F19</cell><cell cols="6">0.7727 0.0192 1.0000 0.8176 0.9950 0.0000</cell></row><row><cell>Sum</cell><cell cols="6">3.2346 9.9634 16.421 3.6134 5.6858 1.9936</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>The obtained results of the Friedman ranking test</figDesc><table><row><cell>Function</cell><cell cols="3">Comparative algorithms</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>PSO</cell><cell>GA</cell><cell>BA</cell><cell>FA</cell><cell>GSA</cell><cell>GSO</cell></row><row><cell>F1</cell><cell>3</cell><cell>5</cell><cell>6</cell><cell>4</cell><cell>1</cell><cell>1</cell></row><row><cell>F2</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>3</cell><cell>2</cell><cell>1</cell></row><row><cell>F3</cell><cell>3</cell><cell>5</cell><cell>6</cell><cell>1</cell><cell>2</cell><cell>4</cell></row><row><cell>F4</cell><cell>2</cell><cell>5</cell><cell>6</cell><cell>1</cell><cell>4</cell><cell>3</cell></row><row><cell>F5</cell><cell>1</cell><cell>5</cell><cell>6</cell><cell>1</cell><cell>1</cell><cell>4</cell></row><row><cell>F6</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>1</cell><cell>1</cell><cell>3</cell></row><row><cell>F7</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>2</cell><cell>3</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>54. Junning C, Wentao H, Dacheng R (2013) An improved algorithm of glowworm swarm optimization based on group search optimizer. J Guilin Univ Electron Technol 16 55. Wang L-J, Zhong Y-W, Hu X-X (2013) An improved group search optimizer for multi-dimensional function optimization problems. J Chin Comput Syst 34:611-616 56. Shen H, Zhu Y, Niu B, Wu Q (2009) An improved group search optimizer for mechanical design optimization problems. Prog Nat Sci 19:91-97 57. Lin C-J, Huang M-L (2019) Efficient hybrid group search optimizer for assembling printed circuit boards. AI EDAM 33:259-274 58. Xue Z, Chen Z, Ji T, Li M, Wu Q (2019) Estimation of low frequency oscillation parameters using singular value decomposition combined group search optimizer. Electric Power Comp Syst 47:275-287 59. Li L, Liu F (2011) Group search optimizer and its applications on multi-objective structural optimal design. In: Group search optimization for applications in structural design. Springer, New York, pp 207-246 60. He S, Wu Q, Saunders J (2006) A group search optimizer for neural network training. In: International conference on computational science and its applications, Springer, New York, pp 934-943 61. He S, Wu Q, Saunders J (2009) Breast cancer diagnosis using an artificial neural network trained by group search optimizer. Trans Inst Meas Control 31:517-531 62. Qin G, Liu F, Li L (2009) A quick group search optimizer with passive congregation and its convergence analysis. In: 2009 International conference on computational intelligence and security, volume 1, IEEE, pp 249-253 63. Xie H, Liu F, Li L (2009) A topology optimization for truss based on improved group search optimizer. In: 2009 International conference on computational intelligence and security, volume 1, IEEE, pp 244-248 64. Li L-J, Xu X-T, Liu F, Wu Q (2010) The group search optimizer and its application to truss structure design. Adv Struct Eng 13:43-51 65. Guang Q, Feng L, Lijuan L (2010) A quick group search optimizer and its application to the optimal design of double layer grid shells. In: AIP conference proceedings, volume 1233, American Institute of Physics, pp 718-723 66. Haobin X, Feng L, Lijuan L, Chun W (2010) Research on topology optimization of truss structures based on the improved group search optimizer. In: AIP conference proceedings, volume 1233, American Institute of Physics, pp 707-712 L 67. He S (2010) Training artificial neural networks using Le ´vy group search optimizer. J Multiple-Valued Logic Soft Comput 16 68. Zhang W-F, Zhu Z-H (2010) Group search optimizer algorithm with predictive model. Inf Technol 6 69. Shi-Kai Z, Li-Juan L (2010) Application of improved group search optimizer in shape optimization of truss structures. J Guangdong Univ Technol 2 70. Liu F, Qin G, Li L (2010) A quick group search optimizer and its application research. Eng Mech 27:38-44 71. Ren F-M, Wang C, Li L-J (2010) A multi-objective group search optimizer and its application in structural optimal design. J Guangxi Univ (Nat Sci Edn) 2 72. He G, Cui Z, Zeng J (2011) Group search optimizer with interactive dynamic neighborhood. In: International conference on artificial intelligence and computational intelligence, Springer, New York, pp 212-219 73. Silva DN, Pacifico LD, Ludermir TB (2011) Improved group search optimizer based on cooperation among groups for feedforward networks training with weight decay. In: 2011 IEEE international conference on systems, man, and cybernetics, IEEE, pp 2133-2138 74. He S, Cooper H, Ward D, Yao X, Heath J (2012) Analysis of premalignant pancreatic cancer mass spectrometry data for biomarker selection using a group search optimizer. Trans Inst Meas Control 34:668-676 75. Zhan J, Guo C, Wu Q, Wen B (2012) Fast group search optimizer and its application to the economic dispatch of power systems. In: Proceedings of the CSEE S1: 76. He G-H, Cui Z-H, Tan Y (2012) Interactive dynamic neighborhood differential evolutionary group search optimizer. J Chin Comput Syst 33:809-814 77. Jin J, Li L, He J, Liu F (2013) Quick group search optimizer applied to the multi-objective optimization of truss structures. Spatial Struct 8 78. Zhao Z, Yan X, Shi H (2013) Group search optimizer algorithm based on cultural evolution. J East China Univ Sci Technol 39:95-101 79. Jiang H, Chen F-F, Du W-F (2013) Cooperative cognitive radio spectrum sensing based on improved group search optimizer. J Circuits Syst 1 80. Balakrishnan R, Karthikeyan T (2019) Microarray gene expression and multiclass cancer classification using extreme learning machine (ELM) with refined group search optimizer (RGSO). Int Sci J Sci Eng Technol 18 81. Junaed A, Akhand M, Murase K, et al. (2013) Multi-producer group search optimizer for function optimization. In: 2013 international conference on informatics, electronics and vision (ICIEV), IEEE, pp 1-4 82. Ghosh S, Nandi K, Dar RA (2015) Gbest-guided group search optimizer algorithm 83. Wang L, Hu X, Ning J, Jing L (2012) A modified group search optimizer algorithm for high dimensional function optimization. In: International conference on information computing and applications, Springer, New York, pp 219-226 84. Xie Y, Zhao C, Zhang H, Chen D (2014) Degso: hybrid group search optimizer with differential evolution operator. Int J Signal Process Image Process Pattern Recognit 7:285-296 85. Zhang W-F (2015) Simplified group search optimizer algorithm for large scale global optimization. J Shanghai Jiaotong Univ (Sci) 20:38-43 86. Wang D, Xiong C, Zhang X (2015) An opposition-based group search optimizer with diversity guidance. Math Problems Eng 87. Li Y, Wu Q, Li M (2015) Group search optimizer with intraspecific competition and Le ´vy walk. Knowl-Based Syst 73:44-51 88. Chen J-J, Ji T, Wu P, Li M (2016) A variant of group search optimizer for global optimization. J Comput Methods Sci Eng 16:219-230 89. Ravishankkar A, Amudhavalli P (2017) Feature selection using group search optimizer for plant leaf classification. Asian J Inf Technol 16:810-815 90. Magatrao D, Ghosh S, Valadi J, Siarry P (2013) Simultaneous gene selection and cancer classification using a hybrid group search optimizer. In: Proceedings of the 15th annual conference companion on Genetic and evolutionary computation, pp 7-8 91. Rafi DM, Bharathi CR (2016) Optimal fuzzy min-max neural network (fmmnn) for medical data classification using modified group search optimizer algorithm. Int J Intell Eng Syst 9:1-10 92. Zhang W-F, Lu W-K, Luo Y-L (2009) Application of group search optimizer algorithm in optimization of truss structure. Modern Comput 12 93. Li L, Liu F (2011) Improvements and applications of group search optimizer in structural optimal design. In: Group search optimization for applications in structural design, Springer, New York, pp 97-159 Neural Computing and Applications</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Neural Computing and Applications</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of interest</head><p>The author declares that he has no conflict of interest.</p><p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comprehensive review: Krill herd algorithm (kh) and its applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bolaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al-Betar</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Soft Comput</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="437" to="446" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hybridizing cuckoo search algorithm with hill climbing for numerical optimization problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International conference on information technology (ICIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">b-hill climbing technique for the text document clustering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sawaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashaideh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><forename type="middle">-</forename><surname>Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno>NTIT)-2017. p 60</idno>
	</analytic>
	<monogr>
		<title level="j">New Trends in Information Technology</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Critical event tabu search for multidimensional knapsack problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Kochenberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meta-heuristics</title>
		<imprint>
			<biblScope unit="page" from="407" to="427" />
			<date type="published" when="1996">1996</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Salp swarm algorithm: a comprehensive survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alshinwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alabool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput Appl</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-verse optimizer algorithm: a comprehensive survey of its results, variants, and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Abualigah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput Appl</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Quantum-inspired evolutionary algorithm for a class of combinatorial optimization</title>
		<author>
			<persName><forename type="first">K-H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evolut Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="580" to="593" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A novel hybrid Antlion optimization algorithm for multi-objective task scheduling problems in cloud computing environments</title>
		<author>
			<persName><forename type="first">L</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diabat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cluster Comput</title>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Feature selection and enhanced krill herd algorithm for text document clustering</title>
		<author>
			<persName><forename type="first">Lmq</forename><surname>Abualigah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hybrid strategy for krill herd algorithm with harmony search algorithm to improve the data clustering</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Hanandeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell Decision Technol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Brain storm optimization algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference in swarm intelligence</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="303" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Salp swarm algorithm: a bio-inspired optimizer for engineering design problems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Gandomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Faris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mirjalili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Eng Softw</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="163" to="191" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised text feature selection technique based on hybrid particle swarm optimization algorithm with genetic operators for the text clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rashaideh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sawaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Al-Laham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ra'ed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Braik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="4773" to="4795" />
			<date type="published" when="2017">2018. 2017</date>
		</imprint>
	</monogr>
	<note>J Supercomput</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moth-flame optimization algorithm: variants and applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><surname>Hamad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alabool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alshinwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khasawneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput Appl</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gsa: a gravitational search algorithm</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rashedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nezamabadi-Pour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saryazdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Sci</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="2232" to="2248" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The whale optimization algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Eng Softw</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification by combining minimum redundancy maximum relevancy and bat-inspired algorithm</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Alomari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al-Betar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Data Min Bioinform</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="32" to="51" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ant lion optimizer: a comprehensive survey of its variants and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alshinwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abd</forename><surname>Elaziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch Comput Methods Eng</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hybridising cuckoo search algorithm for extracting the ODF maxima in spherical harmonic representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Almimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Khader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Bio-Inspired Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="190" to="199" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Symbiotic organisms search: a new metaheuristic optimization algorithm</title>
		<author>
			<persName><forename type="first">M-Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prayogo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Struct</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="98" to="112" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Group search optimizer: an optimization algorithm inspired by animal searching behavior</title>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Evol Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="973" to="990" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Numerical integration over the n-dimensional spherical shell</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mustard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="578" to="589" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exchangeable producer and scrounger roles in a captive flock of feral pigeons: a case for the skill pool effect</title>
		<author>
			<persName><forename type="first">L-A</forename><surname>Giraldeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anim Behav</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="797" to="803" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Producers and scroungers: a general model and its application to captive flocks of house sparrows</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Sibly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anim Behav</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="543" to="550" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Group search optimizer algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovative computational intelligence: a rough guide to 134 clever algorithms</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A hybrid group search optimizer with metropolis rule</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 international conference on modelling, identification and control</title>
		<meeting>the 2010 international conference on modelling, identification and control</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="556" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Group search optimizer algorithm for constrained optimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on computer science for environmental engineering and ecoinformatics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">New group search optimizer algorithm based on chaotic searching</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Appl</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="657" to="660" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Group search optimizer for power system economic dispatch</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bazargan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference in swarm intelligence</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An improved group search optimizer with operation of quantum-behaved swarm and its application</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Soft Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="712" to="725" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A novel group search optimizer for multi-objective optimization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2939" to="2946" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-objective optimal design of frame structures with group search optimizer</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied mechanics and materials</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="968" to="975" />
			<date type="published" when="2012">2012</date>
			<publisher>Trans Tech Publ</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Optimal power flow using group search optimizer with intraspecific competition and Le ´vy walk</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE symposium on swarm intelligence (SIS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="256" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A self-adaptive group search optimizer with elitist strategy</title>
		<author>
			<persName><forename type="first">X-W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D-J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z-H</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>IEEE congress on evolutionary computation (CEC). IEEE</publisher>
			<biblScope unit="page" from="2033" to="2039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dynamic economic dispatch with wind power penetration using group search optimizer with adaptive strategies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE PES innovative smart grid technologies</title>
		<meeting><address><addrLine>Europe, IEEE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A fast global group search optimizer algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on information and automation (ICIA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="59" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Investigation of seismic performance of steel frames based on a quick group search optimizer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iran Univ Sci Technol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimal reactive power dispatch with wind power integrated using group search optimizer with intraspecific competition and le ´vy walk</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuanzheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mengshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qinghua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mod Power Syst Clean Energy</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="308" to="318" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reliability constrained unit commitment with combined hydro and thermal generation embedded using self-learning group search optimizer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Energy</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="245" to="254" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comment on &apos;reliability constrained unit commitment with combined hydro and thermal generation embedded using selflearning group search optimizer by</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaymanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Agelidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jing ZX [energy</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1103" to="1105" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>Energy</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A hybrid group search optimizer with opposition-based learning and differential evolution</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International symposium on computational intelligence and intelligent systems</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A study on cooperative multiobjective group search optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><forename type="middle">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 27th Chinese control and decision conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="3776" to="3781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Virtual network embedding based on multi-objective group search optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 10th International conference on broadband and wireless computing, communication and applications (BWCCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="598" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Discrete group search optimizer for community detection in multidimensional social network</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Elwakil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International computer engineering conference</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An efficient forecasting model based on an improved fuzzy time series and a modified group search optimizer</title>
		<author>
			<persName><forename type="first">C-L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Intell</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="641" to="651" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Interleaver with high dimensional encoding principle using hybrid group search optimizer</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Deshmukh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Panat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International conference on wireless communications, signal processing and networking</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2629" to="2635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Comparative results: group search optimizer and central force optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Formato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1002.2798</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An improved group search optimizer algorithm and its application</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Structures</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A novel group search optimizer inspired by animal behavioural ecology</title>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saunders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<biblScope unit="page" from="1272" to="1278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A discrete group search optimizer for blocking flow shop multi-objective scheduling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Guanlong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shuning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Mech Eng</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1687814016664262</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A discrete group search optimizer for hybrid flowshop scheduling problem with random breakdown</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Math Probl Eng Neural Computing and Applications</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Total flow time minimization in no-wait job shop using a hybrid discrete group search optimizer</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl Soft Comput</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">105480</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Reactive power optimization based on group search optimizer</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Power Syst Protect Control</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="93" to="99" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Erratum to &apos;&apos;continuous quick group search optimizer for solving non-convex economic dispatch problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moradi-Dalvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mohammadi-Ivatloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electr. Power Syst. Res</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page">275</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Electric Power Syst Res</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Discussion of &apos;&apos;solving non-convex economic dispatch problem with valve point effects using modified group search optimizer method</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vaisakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaccaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kazem Zare. Electr Power Syst Res</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="353" to="355" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Continuous quick group search optimizer for solving non-convex economic dispatch problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moradi-Dalvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mohammadi-Ivatloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electr Power Syst Res</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="93" to="105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Dynamic economic emission dispatch based on group search optimizer with multiple producers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electr Power Syst Res</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Solving non-convex economic dispatch problem with valve point effects using modified group search optimizer method</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davoodi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electr Power Syst Res</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="83" to="89" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Discussion of &apos;&apos;solving non-convex economic dispatch problem with valve point effects using modified group search optimizer method&apos;&apos; by Kazem Zare &apos;&apos;electric power systems research</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vaisakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaccaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="83" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Group search optimizer for economic load dispatch</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chishti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Gangwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Res Electr Electron Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Power system dispatch with wind power integrated using mean-variance model and group search optimizer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE PES general meeting|conference and exposition. IEEE pp</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Improved group search optimizer algorithm for design optimization of structures</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen-Fen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Knowl Technol</title>
		<imprint>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Optimum design of structures with group search optimizer algorithm</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Group search optimization for applications in structural design</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="69" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Distribution network reconfiguration based on group search optimizer</title>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Power Syst Technol</title>
		<imprint>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Social group search optimizer algorithm for ad hoc network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Optimal allocation of distributed generation units based on two different objectives by a novel version group search optimizer algorithm in unbalanced loads system</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Nezhadnaeini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hajivand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohajeryami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revue Roumaine des Sci Tech</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="338" to="342" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Group search optimizer algorithm in wireless sensor network localization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnaprabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aloor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 International conference on advances in computing, communications and informatics (ICACCI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1953" to="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A new internet of things group search optimizer</title>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Commun Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="535" to="552" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">An, Power distribution network planning based on group search optimizer algorithm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">W</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced materials research</title>
		<imprint>
			<biblScope unit="volume">971</biblScope>
			<biblScope unit="page" from="1284" to="1287" />
			<date type="published" when="2014">2014</date>
			<publisher>Trans Tech Publ</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Group search optimizer for the mobile location management problem</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Sci World J</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Group search optimizer based optimal location and capacity of distributed generations</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="55" to="63" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">An integrated Xbee arduino with group search optimizer approach for localization in wireless sensor networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Harikrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vjs</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Indian J Sci Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Ogso-dr: oppositional group search optimizer based efficient disaster recovery in a cloud environment</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Ambient Intell Humaniz Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1885" to="1895" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Location and penetration of distributed generation based on group search optimizer</title>
		<author>
			<persName><forename type="first">Y-X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Chinese society of universities for electric power system and its automation 5</title>
		<meeting>the Chinese society of universities for electric power system and its automation 5</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A novel realization algorithm of group search optimizer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D-L</forename><surname>Qing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Nantong Univ (Nat Sci Edn)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A comprehensive survey: whale optimization algorithm and its applications</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Gharehchopogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gholizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut Comput</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">On the application of search-based techniques for software engineering predictive modeling: a systematic review and future directions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Raje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="85" to="109" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Noisy evolutionary optimization algorithms-a comprehensive survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rakshit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut Comput</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18" to="45" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Swarm and evolutionary computing algorithms for system identification and filter design: a comprehensive review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Patidar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swarm Evolut Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="68" to="84" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Grasshopper optimisation algorithm: theory and application</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Eng Softw</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="30" to="47" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MHS&apos;95 Proceedings of the sixth international symposium on micro machine and human science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Applying genetic algorithms to information retrieval using vector space model</title>
		<author>
			<persName><forename type="first">Lmq</forename><surname>Abualigah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Hanandeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Comput Sci Eng Appl</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A new metaheuristic bat-inspired algorithm</title>
		<author>
			<persName><forename type="first">X-S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature inspired cooperative strategies for optimization</title>
		<imprint>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="2010">2010. 2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName><forename type="first">X-S</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1003.1409</idno>
		<title level="m">Firefly algorithm, stochastic test functions and design optimisation</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
