<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial Attack on Large Scale Graph</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-09-08">8 Sep 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jintang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tao</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fenfang</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zibin</forename><surname>Zheng</surname></persName>
						</author>
						<title level="a" type="main">Adversarial Attack on Large Scale Graph</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-09-08">8 Sep 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2009.03488v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Node classification</term>
					<term>Adversarial attack</term>
					<term>Graph neural networks</term>
					<term>Efficient attack</term>
					<term>Network robustness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent studies have shown that graph neural networks are vulnerable against perturbations due to lack of robustness and can therefore be easily fooled. Most works on attacking the graph neural networks are currently mainly using the gradient information to guide the attack and achieve outstanding performance. Nevertheless, the high complexity of time and space makes them unmanageable for large scale graphs. We argue that the main reason is that they have to use the entire graph for attacks, resulting in the increasing time and space complexity as the data scale grows. In this work, we propose an efficient Simplified Gradient-based Attack (SGA) framework to bridge this gap. SGA can cause the graph neural networks to misclassify specific target nodes through a multi-stage optimized attack framework, which needs only a much smaller subgraph. In addition, we present a practical metric named Degree Assortativity Change (DAC) for measuring the impacts of adversarial attacks on graph data. We evaluate our attack method on four real-world datasets by attacking several commonly used graph neural networks. The experimental results show that SGA is able to achieve significant time and memory efficiency improvements while maintaining considerable performance in the attack compared to other state-of-the-art methods of attack.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>R ECENTLY, with the enormous advancement of deep learning, many domains like speech recognition <ref type="bibr" target="#b0">[1]</ref> and visual object recognition <ref type="bibr" target="#b1">[2]</ref>, have achieved a dramatic improvement out of the state-of-the-art methods. Despite the great success, deep learning models have been proved vulnerable against perturbations. Specifically, Szegedy et al. <ref type="bibr" target="#b2">[3]</ref> and Goodfellow et al. <ref type="bibr" target="#b3">[4]</ref> have found that deep learning models may be easily fooled, when a small perturbation (usually unnoticeable for humans) is applied to the images. The perturbed examples are also termed as "adversarial examples".</p><p>Graph structures are ubiquitous in nature and society and there are a great deal of research interest in studying graph data <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Undoubtedly, graph plays a crucial role in many high impact applications in the world <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. Therefore, the importance of the robustness of deep learning models on graph data must not be emphasized too much. However, the adversarial examples do have a significant effect on graph data, which is still a major obstacle to be overcome. So far, much of the current work on attacking graph neural networks has concentrated on node classification task <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. In order to fool a classifier and misclassify specific nodes, attackers may use two attack strategies to achieve the adversarial goals: direct attack and influence attack. For the direct attack, an attacker can perturb the target node without restriction while the influence attack is limited to a few attacker nodes (usually the neighboring nodes of the target node) <ref type="bibr" target="#b11">[12]</ref>. Figure <ref type="figure">1</ref> demonstrates a toy example of how deep learning models are fooled by attackers with small perturbations on the graph structure. In this case, the influence attack strategy is adopted.</p><p>In this paper, we focus on the targeted attack that aims to make a specific node (e.g., a person in social networks) misclassified. In this scenario, Dai et al. <ref type="bibr" target="#b12">[13]</ref> study the adversarial attack on graph structure data and propose a gradient-based method, namely GradArgmax, which modifies links based on gradients of a surrogate model so as to fool the classifiers. In addition, Zügner et al. <ref type="bibr" target="#b11">[12]</ref> propose Nettack, which is capable of perturbing the Fig. <ref type="figure">1</ref>: Adversarial attacks on the graph structure. Attackers tend to flip the edges of attacker nodes and lead to the misclassification of the target node. graph structure as well as node features to spoof the classifiers. Despite great success, there are some challenges for the attackers.</p><p>Challenges: (i) Scalability. Most methods of attack have to store unnecessary graph information and thus suffer from the rising time and memory costs as the data scale increases. Naturally, they fail to efficiently conduct attack on a larger graph. However, multi-million-scale graph networks are common in real-world, so existing methods need to be improved and scaled to larger graphs. (ii) Evaluation. A further challenge is to quantify the effects of adversarial attacks on graph data. As the graph data is unable and meaningless to be converted to continuous form, the impacts on the graph data are unable to be measured with 2 -norm or ∞norm <ref type="bibr" target="#b15">[16]</ref>, which is distinct from that on image data. This makes the evaluation of the attack impacts a difficult problem to solve.</p><p>In this work, we aim to tackle these challenges through our proposed methods. Specifically, our methods include two parts: (i) SGA framework. We argue that it is unnecessary to use the entire graph to attack since attackers simply focus on misclassifying several nodes (the target nodes). Besides, due to the lack of time and space efficiency, Graph Convolution Network (GCN) <ref type="bibr" target="#b7">[8]</ref> is unfit to serve as a surrogate model despite being used frequently in previous works. Inspired by Simplified Graph Convolutional Network (SGC) <ref type="bibr" target="#b16">[17]</ref> and gradient-based attack methods <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b14">[15]</ref>, we propose a novel Simplified Gradient-based Attack (SGA) framework for effective and efficient adversarial attacks. SGA only needs a much smaller subgraph consisting of k-hop neighbors of the target node (k depends on the number of SGC layers and typically set to 2), and sequentially flips edges with the largest magnitude of gradients in this subgraph by leveraging the surrogate model SGC. In addition, We introduce a scale factor for dealing with the gradient vanishing during attacks (See section <ref type="bibr">4.3.1)</ref>. Notably, our experimental evaluation suggests that the simplifications can hardly affect the attack performance. Moreover, the resulting model can remarkably improve the time and space efficiency -even yields up to 1,976 and 5,753 times speedup over Nettack on Pubmed dataset in the direct attack and influence attack settings, respectively. Naturally SGA can scale to very large datasets easily. (ii) Degree Assortativity Change (DAC). Previous studies focus primarily on the intrinsic properties of graph <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, but measuring the impact of graph adversarial attacks is however left unexplored so far. To address this problem, we also propose a practical metric named Degree Assortativity Change (DAC), which can measure the intensity of the impact after perturbations being performed.</p><p>The main contributions of our works are summarized as follows:</p><p>• We propose a novel adversarial attack framework SGA, which extracts a much smaller subgraph centered at the target node, thereby addressing the difficulty of conducting attacks on a large scale graph. • We notice the problem of gradient vanishing for gradientbased attack methods and solve it by introducing a scale factor to calibrate the model. • We emphasize the importance of unnoticeability of adversarial attacks on graph data and propose, first of all, a practical metric DAC to measure the attack impacts conveniently. This work can also be further developed in the graph domains. • We conduct extensive experiments on four datasets by attacking several widely adopted graph neural networks. The experimental results show that our attack method has achieved significant improvements in both time and space efficiency while maintaining a significant attack performance compared to other state-of-the-art attack methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work consists of two parts: adversarial attack on graph data and evaluation of the attack impact. In this section, we begin with the introduction of previous works of adversarial attacks on graph data and then discuss the details of ensuring the unnoticeability of adversarial attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Adversarial Attacks on Graph Data</head><p>Increasing attention has been paid on the robustness and security of deep learning models, there has been a surge of interests in the adversarial attacks <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. The obtained results suggest that deep learning models are prone to adversarial examples and could be easily fooled by them even under restricted black-box attack scenarios (attackers conduct attacks without any prior knowledge about the target model <ref type="bibr" target="#b22">[23]</ref>).</p><p>While previous works focus mostly on non-graph structure data (e.g., images and texts), adversarial attacks on graph structure data are considerably less studied because of the discreteness, which means that attackers must limit the attacks in order to maintain the graph property and allow only a few edges to be flipped in the graph. To conduct a practical black-box attack on graph data with limited information, attackers often train a surrogate model locally to generate adversarial examples (perturbed graphs) and transfer them to fool the target models.</p><p>To be specific, we are concentrating on the task of node classification in this work. By referring to <ref type="bibr" target="#b22">[23]</ref>, we divide current approaches of adversarial attacks on the graph into two categories:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Gradient-based attack</head><p>This is the most commonly used method. Gradients have been successfully used to perform attacks in other domains <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b23">[24]</ref>. Since most of the existing models are optimized with gradient, along or against the direction of it is an efficient way to generate destructive adversarial examples. Focusing on the targeted attack, Dai et al. <ref type="bibr" target="#b12">[13]</ref> propose GradArgmax, which extracts gradients of the surrogate model, and flips edges with the largest magnitude of the gradient to generate adversarial examples. However, they restrict the attacks to edge deletion only because the whole graph is stored with a sparse matrix (results in the lack of gradients information of non-edges). For the non-targeted attack that is undifferentiated and global <ref type="bibr" target="#b22">[23]</ref>, Zügner et al. <ref type="bibr" target="#b14">[15]</ref> utilize the metagradients to solve the bi-level problem underlying the challenge of poisoning attacks (a.k.a, training-time attacks). Similarly, Xu et al. <ref type="bibr" target="#b24">[25]</ref> propose PGD structure attack that conducts gradient attacks from a perspective of first-order optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Non-gradient-based attack</head><p>As well as methods focused on gradients, attackers prefer to explore other heuristic algorithms to conduct attacks. Waniek et al. <ref type="bibr" target="#b25">[26]</ref> propose "Disconnect Internally, Connect Externally" (DICE), conducting attack by dropping edges between nodes with high correlation and connecting edges with low correlation. Moreover, Zügner et al. <ref type="bibr" target="#b11">[12]</ref> study both poisoning attacks and evasion attacks (a.k.a test-time attack), based on a linear GCN model and further propose Nettack, which maximizes the misclassification loss of the surrogate model greedily and perturbs the graph structure and node features to fool the classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Unnoticeability of Adversarial Attacks</head><p>Typically, in an adversarial attack scenario, attackers not only concentrate on the attack performance but also seek to be concealed to avoid the detection. However, previous works usually conduct attacks under a fixed budget and thought it would be unnoticeable as if the budget is small enough. We argue that it is not sufficient to preserve the properties of graphs and ensure the unnoticeability in most cases.</p><p>To bridge this gap, Zügner et al. <ref type="bibr" target="#b11">[12]</ref> enforce the perturbations to ensure its unnoticeability by preserving the graph's degree distributions and feature co-occurrences, restricting them to be marginally modified before and after attacks. However, there is still no practical metric to measure the impact of attacks on graph data.</p><p>On the other hand, researches on the graph (or network) structure have yielded several results with respect to certain important properties, including "small-world effect" <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> and degree distributions <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. Unlike previous works, Newman et al. <ref type="bibr" target="#b17">[18]</ref> and Foster et al. <ref type="bibr" target="#b18">[19]</ref> focus on another important network feature, i.e., assortativity, and propose a number of measures of assortative mixing appropriate to various mixing types. Generally speaking, assortativity can be defined as the tendency of nodes to connect to each other, it is generally viewed as a metric to probe the properties of a specific graph, and also to some extent reflects the graph structure. Despite its popularity in network analysis and worthy of further study, it has not yet been used to measure the impact of such adversarial attacks on graphs. Therefore, we aim to bridge the gap and apply it to graph adversarial learning. The k-hop subgraph V (sub) , E (sub)  Set of nodes, edges in the subgraph A (sub)  Adjacency matrix of the subgraph E (exp)  Set of expanded edges in the subgraph</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY</head><p>Before presenting our proposed methods, we will first give the notations of graph data formally, and then introduce the surrogate models of the GCN family, finally clarify the details of other proposed adversarial attack methods. See Table <ref type="table" target="#tab_0">1</ref> for frequently used notations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations</head><p>Specifically, we focus on the task of semi-supervised node classification task in a single, undirected, attributed graph. Formally, we define G = (A, X) as an attributed graph, where A ∈ {0, 1} N ×N is a symmetric adjacency matrix denoting the connections of the N nodes, and X ∈ {0, 1} N ×F or X ∈ R N ×F represent the binary or continuous node features with F dimension. We use V to denote the set of nodes and E ⊆ V × V the connected edges of the graph G; C = {c i } denotes a set of class labels where c i indicates the ground-truth label of node i, and we define C as the number of classes in C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Convolution Network Family</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Vanilla Graph Convolution Network (GCN)</head><p>Since a number of existing works <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b24">[25]</ref> use vanilla GCN <ref type="bibr" target="#b7">[8]</ref> as a surrogate model to conduct attacks, thus we first introduce GCN and further draw attention on SGC <ref type="bibr" target="#b16">[17]</ref> -a simplified variant of GCN. Refer to this work <ref type="bibr" target="#b7">[8]</ref>, GCN is recursively defined as</p><formula xml:id="formula_0">H (l+1) = σ( D− 1 2 Ã D− 1 2 H (l) W (l) ) ,<label>(1)</label></formula><p>where Ã = A+I N is the adjacency matrix with self-loops. I N is a N by N identity matrix, and Dii = j Ãij is a diagonal degree matrix. W (l) ∈ R F l ×F l+1 is a trainable input-to-hidden weight matrix and H (l) ∈ R N ×F l is the matrix of hidden representation (activation), both of which are related to the l th layer. Particularly,</p><formula xml:id="formula_1">F 0 = F , H (0) = X is the input of neural network. σ(•)</formula><p>represents the element-wise activation function of network and is usually defined as ReLU (•) = max (•, 0). For node classification task, consider GCN with one hidden layer, and let Â = D− 1 2 Ã D− 1 2 , then the forward of GCN with pre-processing step could be taken as</p><formula xml:id="formula_2">Z = f θ (A, X) = softmax ( Â ReLU ( ÂXW (0) ) W (1) ) , (2)</formula><p>where Z ∈ R N ×C is the output matrix of GCN indicates the prediction probability of nodes belonging to different classes, and the softmax activation function, defined as softmax(</p><formula xml:id="formula_3">x i ) = 1 z exp(x i ) with z = i exp(x i ), is applied row-wise.</formula><p>Given a set of labeled nodes V L ⊆ V with ground-truth labels C L ⊆ C, the goal of GCN is to learn a mapping function g : V → C by minimizing the cross-entropy loss:</p><formula xml:id="formula_4">L(θ; A, X) = − i∈V L ln Z i,ci , Z = f θ (A, X) ,<label>(3)</label></formula><p>where c i ∈ C L is the class label of node i and θ = {W (0) , W (1) } denotes the trainable weights of model. After being optimized with Gradient Descent <ref type="bibr" target="#b30">[31]</ref>, the weights are learned to predict nodes in an unlabeled set</p><formula xml:id="formula_5">V U = V − V L .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Simplified Graph Convolutional Network (SGC)</head><p>The drawback of vanilla GCN is the excessive computational cost of message aggregation between nodes and their neighboring nodes, which is repeatedly and unnecessarily computed during training. To address this problem, Wu et al. <ref type="bibr" target="#b16">[17]</ref> theoretically analyze the structure of GCN and further propose a linear variant, namely SGC. SGC replaces the nonlinear activation function ReLU (•) with identity function and collapses weight matrices between consecutive layers. In this way, the forward of GCN can be simplified as</p><formula xml:id="formula_6">Z = f θ (A, X) = softmax ( Â ReLU ( ÂXW (0) ) W (1) ) = softmax ( Â ÂXW (0) W (1) ) = softmax ( Â2 XW ) ,<label>(4)</label></formula><p>where W = W (0) W (1) is a collapsed weight matrix. With precomputing Ŝ = Â2 X, the complicated GCN structure can be simplified as an input-to-output fully-connected neural network (FNN) <ref type="bibr" target="#b31">[32]</ref> without any hidden units, thereby avoiding redundant computation and greatly reducing training time and memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SOTA Adversarial Targeted Attack Methods</head><p>For adversarial attacks on graphs, attackers may conduct structure attack or feature attack <ref type="bibr" target="#b22">[23]</ref> to modify the graph structure or node features, respectively. Following the work <ref type="bibr" target="#b11">[12]</ref>, we assume that attackers have prior knowledge about the graph structure and node features, including ground-truth labels of nodes. Beyond that, attackers are not allowed to access any additional information about the target models, neither model architecture nor parameters. In this case, attackers often train a transferable surrogate model locally, perform perturbations to fool it to achieve the best result of misclassification, and eventually transfer to other target models.</p><p>Since we focus on the targeted attack in node classification task, here we briefly introduce other proposed state-of-the-art targeted attack methods: Nettack <ref type="bibr" target="#b11">[12]</ref> and GradArgmax <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Nettack</head><p>Similar to SGC, Nettack uses a linear variant of two-layer GCN as a surrogate model to conduct targeted attack. Given a target node t and a budget ∆ ∈ N, Nettack modifies the graph structure and node features aiming to maximize the misclassification loss of the surrogate model:</p><formula xml:id="formula_7">arg max A ,X</formula><p>(max</p><formula xml:id="formula_8">c t =ct ln Z t,c t − ln Z t,ct ), t ∈ V s.t. i j |X i,j − X i,j | + u&lt;v |A u,v − A u,v | ≤ ∆<label>(5)</label></formula><p>where Z = f θ (A , X ) is the output of the surrogate model, A and X are the perturbed adjacency matrix and feature matrix, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">GradArgmax</head><p>GradArgmax uses vanilla GCN as a surrogate model to maximize the cross-entropy loss described in Eq.( <ref type="formula" target="#formula_4">3</ref>) by gradient ascent. As the loss function L and target node t are specified, GradArgmax computes the partial derivative of L t with respect to each connected edge of the adjacency matrix:</p><formula xml:id="formula_9">∇ G = ∇ A L t = ∂L t ∂A ,<label>(6)</label></formula><p>where L t denotes the targeted loss w.r.t node t.</p><p>To preserve the discreteness of adjacency matrix A, GradArgmax greedily flips those edges with ∆-largest magnitude of gradients. In addition, the adjacency matrix is stored as a sparse one in order to avoid excessive computational costs, but only gradients of the connected edges could be extracted, which means that attacks are restricted to the deletion of edges only, and information on surrogate gradients is not fully utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SIMPLIFIED GRADIENT-BASED ATTACK</head><p>In this work, we simply focus on the structure attack<ref type="foot" target="#foot_0">1</ref> , our method can be easily extended to the feature attack (either binary or continuous features) as well, just by taking into account the gradients of the input features. In the node classification scenario detailed in section 3.1, the goal of an attacker is to perturb the original graph G = (A, X) with limited budgets ∆ and further lead to a misclassification of target models.</p><p>To conduct attacks on the target models without additional prior knowledge, inspired by the adversarial methods mentioned above, the proposed SGA follows these steps: (i) Train a surrogate model locally. (ii) Extract a k-hop subgraph. (iii) Choose to add or remove edges based on the surrogate gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Train a Surrogate Model</head><p>The most frequently used surrogate model is vanilla GCN, however, it has significant drawbacks as described in section 3.2, we use a k-layer SGC as our surrogate model instead. The output of a k-layer SGC can be formulated as</p><formula xml:id="formula_10">Z = f θ (A, X) = softmax ( Âk XW ) ,<label>(7)</label></formula><p>First and foremost, we train SGC on the input graph until convergence with fine-tuned hyper-parameters. In fact, the goal is to obtain the final weight matrix θ = {W }, which will be used later to guide the attack in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extract a k-hop Subgraph</head><p>Given a target node t, it should to be classified as another class to achieve our goal. Therefore, we design the targeted misclassification loss function as follows:</p><formula xml:id="formula_11">Lt = max c t =ct ln Z t,c t − ln Z t,ct , t ∈ V ,<label>(8)</label></formula><p>where Z t,ct indicates the predicted probability that node t belongs to class c t . According to Eq.( <ref type="formula" target="#formula_11">8</ref>), to compute the targeted loss Lt , we only need to compute Z t , a row-vector of Z. Therefore, computing {Z u | u ∈ V and u = t} is unnecessary and redundant. This motivates us to simplify the computation. Theorem 1. Given a normalized adjacency matrix Â with selfloops, i.e., Âu,u = 0, ∀u ∈ V . let D(u, v) denotes the shortest distance between u and v, thus</p><formula xml:id="formula_12">[ Âk ] u,v = 0, if D(u, v) &gt; k = 0, if D(u, v) ≤ k<label>(9)</label></formula><p>Proof 4.1. The detailed proof is omitted for the sake of brevity.</p><p>Given a specific target node t ∈ V , it is clear that Lt depends on Z t only, where</p><formula xml:id="formula_13">Z t = [ Âk ] t XW . So what we need is to compute [ Âk ] t , a row-vector of Âk . According to Theorem 1, we can construct a k-hop subgraph G (sub) = (A (sub) , X) consisting of: V s = {u | D(t, u) ≤ k}, E s = {(u, v) | D(t, u) ≤ k and D(t, v) ≤ k}<label>(10)</label></formula><p>The set of nodes V s can also be considered as the k-hop neighbors of target node t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Fast Gradient Computation with the Subgraph</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Vanilla SGA</head><p>Gradient-based algorithm is an efficient and effective method for attack. Similar to GradArgmax, the gradient matrix w.r.t the subgraph will be computed as follows:</p><formula xml:id="formula_14">∇ G (sub) = ∇ A (sub) L(sub) t ,<label>(11)</label></formula><p>where</p><formula xml:id="formula_15">L(sub) t = max c t =ct ln Z (sub) t,c t − ln Z (sub) t,ct</formula><p>denotes the targeted loss computed using subgraph and it is derived from Eq.( <ref type="formula" target="#formula_11">8</ref>), Z probability vector of target node t using subgraph. Note that, to ensure Â(sub)</p><formula xml:id="formula_16">(sub) t = f (A (sub) , X) ∈ R 1×C denotes the prediction</formula><formula xml:id="formula_17">u,v</formula><p>= Âu,v , ∀u, v ∈ V s , we must add self-loop for each node u ∈ V s , and normalize Ã(sub) using D the same as Ã. Following this, apparently Z (sub) t = Z t according to theorem 1. As described in Eq.( <ref type="formula" target="#formula_14">11</ref>), the partial derivative of Lt w.r.t the adjacency matrix A (sub) is computed for each edge e = (u, v) ∈ E s .</p><p>However, as stated by Guo et al. <ref type="bibr" target="#b32">[33]</ref>, most of the modern neural networks are poorly calibrated, and the probability associated with the predicted class label doesn't reflect its groundtruth correctness likelihood. On the contrary, a neural network appears to be overconfident on the predictions. As shown in the top of Figure <ref type="figure" target="#fig_0">2</ref>, the model is so confident that it gives very high probability for the predicted class (Z t,ct → 1), but for other classes even the next most probable one, it gives an extremely low probability (max c t =ct Z t,c t → 0). As a result, the first term of targeted loss L(sub) t rounds to minus infinity while the second term rounds to zero. This results in the gradients vanishing and thus the attack performance is negatively affected. To overcome the gradient vanishing problem, a scale factor &gt; 1 is introduced to calibrate the output, and the targeted loss is redefined as follows:</p><formula xml:id="formula_18">Z (sub) t = f θ (A (sub) , X, ) = softmax ( Â(sub)k XW ), L(sub) t = max c t =ct ln Z (sub) t,c t − ln Z (sub) t,ct , t ∈ V<label>(12)</label></formula><p>By introducing a scale factor , the output of the model will no longer reach the extreme value 0 or 1 (See the bottom of Figure <ref type="figure" target="#fig_0">2</ref>), and the gradients will be calculated as normal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">SGA with nodes reduction</head><p>Furthermore, there is another crucial problem that only the gradients of connected edge e i ∈ E s will be computed, resulting in edges deletion only the same as GradArgmax. To solve this problem, it is also important to consider the gradients of the non-edges that might be connected later. Unfortunately, the possible number of non-edges is almost N 2 and the computation of gradients is very costly. Inspired by DICE <ref type="bibr" target="#b33">[34]</ref>, a straightforward way to attack is "Disconnect Internally, Connect Externally". Following this, we will only consider those nodes that belong to different classes to construct a non-edge set. However, there are a large number of nodes that meet this criteria. To avoid excessive computation, we empirically add nodes and edges fulfill</p><formula xml:id="formula_19">V p = {u | c u = c t , u ∈ V } , E p = A × V p ,<label>(13)</label></formula><p>where c t = arg max c =ct Z t,c is the next most probable class obtained from surrogate model SGC, A ⊆ V is the set of attacker nodes and the perturbations are constrained to these nodes <ref type="bibr" target="#b11">[12]</ref>.</p><p>In particular, we set A = {t} for direct attack and A = N (t) for influence attack where N (t) is the set of neighboring nodes adjacent to t. We term these nodes in V p as "potential nodes" and edges in E p as "potential edges" since they may be included in this subgraph later. Eq.( <ref type="formula" target="#formula_19">13</ref>) shows that we prefer to connect attacker nodes in A with potential nodes to influence the target node t.</p><p>Therefore, the targeted loss can be also simplified as</p><formula xml:id="formula_20">L(sub) t = ln Z (sub) t,c t − ln Z (sub) t,ct , t ∈ V<label>(14)</label></formula><p>Figure <ref type="figure">3</ref> shows the simplified gradient-based attack using a subgraph, where we not only extract the k-hop subgraph centered at the target node, but also add some potential nodes to extend the subgraph. By doing so, we can compute the gradients of potential edges in this extended subgraph, and our method is available to add adversarial edges as well.</p><p>As discussed above, it is clear that |V p | = N C . As an extreme case suppose there are only a few classes in the dataset, i.e., C is small enough. In this case, it can be derived that |V p | = N C ≈ N , the scale of potential nodes comes larger as unbearable. Consider that we only have a budget ∆ for a target node, which means that we can add ∆ edges at most. To further improve the efficiency, we will eventually leave ∆ potential nodes Vp ⊆ V p , where the gradients of potential edges between t and them are ∆-largest, i.e.</p><formula xml:id="formula_21">Vp = {u | ∇ G (sub) t,u is ∆ -largest, u ∈ V p }, Êp = A × Vp<label>(15)</label></formula><p>Let V (sub) = V s ∪ Vp , E (sub) = E s ∪ Êp , the scale of the subgraph G (sub) comes smaller. We only need to compute</p><formula xml:id="formula_22">∇ G (sub) u,v</formula><p>for each (non-)edge (u, v) ∈ E (sub) . Either the input graph is sparse or not, it's obvious that |E (sub) | |E|. Besides, computing Z (sub) t using A (sub) can be done in constant time and it further improves the efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Iterative Gradient-based Attack</head><p>To better capture the actual change of the surrogate loss, we will sequentially compute the gradients after adding or removing an edge <ref type="bibr" target="#b14">[15]</ref>. Let Z (i) t and Z (subi) t denote the prediction of target node t at the i th time using the whole graph and subgraph, respectively. A (subi) , V (subi) , E (subi) are defined in the same way. Specifically,</p><formula xml:id="formula_23">A (sub0) = A (sub) , V (sub0) = V (sub) , E (sub0) = E (sub) .</formula><p>At each time i+1, we flip one edge e = (u, v) ∈ E (subi) with largest magnitude of gradient that fullfils the constraints <ref type="bibr" target="#b34">[35]</ref>: the edges connected to it should be considered as well.</p><formula xml:id="formula_24">Connect (u, v), if ∇ G (sub i ) &gt; 0 and A (subi) u,v = 0 Disconnect (u, v), if ∇ G (sub i ) &lt; 0 and A (subi) u,v = 1<label>(16)</label></formula><p>To conclude, we define the structure score as follows to simplify Eq.( <ref type="formula" target="#formula_24">16</ref>):</p><formula xml:id="formula_25">S = ∇ G (sub i ) (−2A (subi) + 1) ,<label>(17)</label></formula><p>where denotes Hadamard product. The adversarial edge (u, v) is selected based on the largest structure score. After an edge is selected, we update the subgraph G (subi+1) as follows:</p><formula xml:id="formula_26">V (subi+1) = V (subi) , E (subi+1) = E (subi) − {e}, A (subi+1) = A (subi) ⊕ e,<label>(18)</label></formula><p>where ⊕ denotes the "exclusive or" operation, for e = (u, v), if</p><formula xml:id="formula_27">A (subi) u,v = 0 then A (subi+1) u,v</formula><p>= 1 and vice versa. However, it will results in Z</p><formula xml:id="formula_28">(subi) t = Z (i)</formula><p>t , ∀i &gt; 0. We explain it with Figure <ref type="figure">4</ref>, when a potential is connected, if a node becomes closer to the target node within k-distance, the edges adjacent to it should be considered as well, so as to preserve the k-order message aggregation of graph convolution. Therefore, if an edge Algorithm 1 Simplified gradient-based attack (SGA) Initialize the subgraph G (sub) = (A (sub) , X) via node reduction with Eq.( <ref type="formula" target="#formula_21">15</ref>); 5: A (sub0) , E (sub0) , V (sub0) ← A (sub) , E (sub) , V (sub) ; 6: for i = 0 to ∆ − 1 do Update A (subi+1) , E (subi+1) , V (subi+1) with Eq.( <ref type="formula" target="#formula_30">19</ref>); 12: end for 13: return G t ; e = (u, v) ∈ E (subi) is connected (assume that v is a potential node), we must expand the subgraph as follows:</p><formula xml:id="formula_29">Input: Graph G = (A, X),</formula><formula xml:id="formula_30">V (subi+1) = V (subi) ∪ {v | v ∈ N (v) if D(t, v ) ≤ k}, E (subi+1) = E (subi) ∪ (E (exp) − {e}), A (subi+1) = A (subi) ⊕ (E (exp) ∪ {e}),<label>(19)</label></formula><p>where</p><formula xml:id="formula_31">E (exp) = {(v, v ) | v ∈ N (v) if D(t, v ) ≤ k}</formula><p>is the expended edges set where nodes become closer within k-distance.</p><p>Since the scale of potential nodes is small enough after the nodes reduction, the subgraph expansion does not negatively affect the efficiency 2 . The details of iterative SGA is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis of Time and Space Complexity</head><p>In order to better describe our method, we compare the complexity of time and space with other state-of-the-art methods: Nettack and GradArgmax.</p><p>2. In contrast, if an edge is disconnected from the subgraph, the message aggregation will be blocked automatically for those nodes beyond k-distance. </p><formula xml:id="formula_32">O(|E|) O(∆ • |A| • N • d 2 ) GradArgmax O(|E|) or O(N 2 ) O(∆ + |E|d 2 ) or O(∆ + N 2 d 2 ) SGA O(d k + ∆ • |A|) O(∆ • (d k + ∆ • |A|) • d k )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Nettack</head><p>Due to store the entire graph (as a sparse matrix), the space complexity of Nettack comes to O(|E|). Besides, Nettack computes the misclassification loss sequentially w.r.t the perturbed graph for each edge in the candidate set, the time complexity is up to</p><formula xml:id="formula_33">O(∆ • |A| • N • d 2 )</formula><p>without considering feature attack, where d denotes the average degrees of nodes in the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">GradArgmax</head><p>While storing the entire graph with a sparse matrix, the space complexity of GradArgmax will be O(|E|). If a dense instantiation of the adjacency matrix is used, the space complexity comes to O(N 2 ). It's worth mentioning that, for the adjacency matrix in sparse form, the algorithm is only capable for edge deletion, while both adding and deleting edges are available for the dense one. Besides, GradArgmax only computes gradients once, so the major time complexity depends on the computation of gradients and it is approximate</p><formula xml:id="formula_34">O(∆ + |E|d 2 ) or O(∆ + N 2 d 2 )</formula><p>for sparse or dense matrix 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">SGA</head><p>Our method only stores the subgraph with a sparse matrix, thus the space complexity is only O(|E (sub) |). After the nodes reduction, E (sub) consists of edges of k-hop subgraph and a few potential edges, which comes to</p><formula xml:id="formula_35">|E (sub) | = d k + ∆ • |A|, apparently |E (sub) |</formula><p>|E| for a sparse graph. Moreover, the time complexity depends on the message aggregation between the k-hop neighbors of the target node in A (sub) , thereby the time complexity leads to</p><formula xml:id="formula_36">O(∆ • |E (sub) | • d k ). Given |E (sub) | = d k + ∆ • |A|, it can be simplified as O(∆ • (d k + ∆ • |A|) • d k ).</formula><p>The complexity of the three methods is summarized in Table <ref type="table" target="#tab_2">2</ref>, where the use of memory refers to the use of graph (subgraph). It is clear that SGA theoretically achieves both time and space efficiency compared to Nettack and GradArgmax.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">UNNOTICEABLE ADVERSARIAL ATTACK ON GRAPH DATA</head><p>Specifically, in the scenario of adversarial attack, attackers would attempt to perform perturbations by modifying the input data while guaranteeing unnoticeability to avoid the detection. Unlike the continuous data that lies in Euclidean Space, attackers can evaluate the attack impacts by measuring the changes before and after attack via 2 norm or ∞ norm <ref type="bibr" target="#b15">[16]</ref>. However, it is difficult to quantify the attack impacts on graph data that lies in such a non-Euclidean Space.</p><p>An important property of a graph is the degree distribution, which often appears as a power-law distribution <ref type="bibr" target="#b36">[37]</ref>, i.e., <ref type="bibr">3.</ref> Refer to <ref type="bibr" target="#b35">[36]</ref>, the time complexity of GCN is O(|E|d 2 ), and the computation of gradients can be accelerated by parallel computing, which is also suitable for SGA. p(x) ∝ x −q , where q is the scaling parameter. It is easy to tell if two graphs have similar degree distributions after q is given. However, there is no solution for estimating q exactly yet. To this end, Zügner et al. <ref type="bibr" target="#b11">[12]</ref> derive an efficient way to check for violations of the degree distribution after attacks. Specifically, they estimate q for a clean graph and q for a perturbed graph to ensure that the attack is unnoticeable if the following equation is fulfilled:</p><formula xml:id="formula_37">Λ (q, q ; G, G ) &lt; τ ≈ 0.004 ,</formula><p>where Λ is a discriminate function defined in <ref type="bibr" target="#b11">[12]</ref>, G denotes the original graph and G the perturbed one.</p><p>In this section, we refer to another solution and apply it to measure the attack impacts, degree assortativity coefficient <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, it measures the tendency of nodes connected to each other. To clarify this, we first define the degree mixing matrix M , where M i,j denotes the tendency of nodes with degree i connected to nodes with degree j, the value can be counts, joint probability, or occurrences of node degree. Let α, β ∈ {in, out} denote the type of in-degree and out-degree, respectively. We first ensure that M fulfills the following rules:</p><formula xml:id="formula_38">ij M i,j = 1, j M i,j = α i , i M i,j = β j ,<label>(20)</label></formula><p>Particularly, in an undirected graph, α i = β j , ∀i = j. Then we define the degree assortativity coefficient by using Pearson Correlation <ref type="bibr" target="#b37">[38]</ref>:</p><formula xml:id="formula_39">r(α, β) = ij ij(M i,j − α i β j ) σ α σ β ,<label>(21)</label></formula><p>where σ α and σ β are the standard deviations of the distributions α and β, respectively. The value of r lies in the range of −1 ≤ r ≤ 1, and r = −1 for disassortativity while r = 1 for assortativity. Figure <ref type="figure" target="#fig_3">5</ref> shows the four degree-degree correlations in a directed network, which reflects the correlation between nodes in the network as well.</p><p>Degree assortativity coefficient r is easier to compute than degree distribution coefficient q, and better reflects the graph structure. Based on this, we propose Degree Assortativity Change (DAC), which is defined as</p><formula xml:id="formula_40">DAC = E r ( |r G − r G t i | ) r G , ∀t i<label>(22)</label></formula><p>where G ti denotes the perturbed graph w.r.t target node t i . Attackers will conduct attack for each target node t i by performing perturbations on the original graph G. DAC measures the average impacts on attacking a group of target nodes {t i }, and the smaller the DAC is, the less noticeable the attack will be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>In this section, we conduct extensive experiments aiming to answer the following research questions: RQ1 How much can SGA improve in terms of time and space efficiency and how does it work for the proposed metric DAC? RQ2 Can SGA achieve a comparable attack performance while using only a certain part of nodes to attack the graph? RQ3 Can SGA scale to larger datasets and retain its attack performance? In what follows, we first detail the experimental settings, followed by answering the above three research questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings</head><p>Datasets. We evaluate the performance of our method on four well-known datasets: Citeseer, Cora, Pubmed <ref type="bibr" target="#b38">[39]</ref> and Reddit <ref type="bibr" target="#b39">[40]</ref>. The first three are commonly citation networks on node classification tasks, where nodes are documents and edges among them are citation relations. The last one is a large scale dataset of online discussion forums where user posts and comments on content in different topical communities. We follow the setting of Nettack <ref type="bibr" target="#b11">[12]</ref> and only consider the largest connected component of the graph for each dataset. In addition, we randomly select 20% of nodes to constitute the training set (half of them are treated as the validation set), and treat the remaining as the testing set. Table <ref type="table" target="#tab_3">3</ref> is an overview of the datasets.</p><p>Target Model. We consider poisoning attack, i.e., models are retrained until the convergence after attacks <ref type="bibr" target="#b22">[23]</ref>, which is more challenging for attackers but reflects real-world scenarios better. To evaluate the transferability of our method, we conduct attack on several commonly used graph neural networks: GCN <ref type="bibr" target="#b7">[8]</ref>, SGC <ref type="bibr" target="#b16">[17]</ref>, GAT <ref type="bibr" target="#b40">[41]</ref>, GraphSAGE <ref type="bibr" target="#b39">[40]</ref>, ClusterGCN <ref type="bibr" target="#b41">[42]</ref>. For each target model, our method is compared with other adversarial attack methods.</p><p>• GCN <ref type="bibr" target="#b7">[8]</ref>. GCN is one of the most representative graph neural networks that learns hidden representations by encoding both local graph structure and node features.</p><p>• SGC <ref type="bibr" target="#b16">[17]</ref>. SGC is a linear variant of GCN that has been proposed recently, which achieves competitive results and even significantly improves the training efficiency.</p><p>• GAT <ref type="bibr" target="#b40">[41]</ref>. GAT enhances GCN by leveraging a masked self-attention mechanism to specifying different weights to different neighbor nodes.</p><p>• GraphSAGE <ref type="bibr" target="#b39">[40]</ref>. GraphSAGE is a general inductive framework, which uniformly samples a set of neighbors with a fixed size, instead of using a full-neighborhood set during training.</p><p>• ClusterGCN <ref type="bibr" target="#b41">[42]</ref>. This is the state-of-the-art mini-batch GCN framework. It samples n subgraphs whose nodes have high correlations under a graph clustering algorithm and restricts the message aggregation within these subgraphs.</p><p>Evaluation Protocols. In the task of node classification, we aim to perform perturbations and further cause misclassification of target models. To this end, we evaluate the classification accuracy and classification margin (CM). Given a target node t, CM is defined as the probability margin between ground-truth label c t and the next most probable class label c t , which lies in the range of [−1, 1]. The smaller CM means better attack performance. In particular, a successful attack is often with CM less than zero.</p><p>Baselines. We compare our method with four other baseline methods and conduct attack using two strategies respectively (i.e., direct attack and influence attack). For a fair comparison, all methods will use the same surrogate model SGC (if necessary), and share the same weights θ. Follow the setting of Nettack <ref type="bibr" target="#b11">[12]</ref>, the attack budget ∆ is set to the degrees of target node t.</p><p>• Random Attack (RA). RA randomly adds or removes edges between attacker nodes and other nodes in the graph with probability p 1 . This is the simplest way to conduct attacks. • DICE <ref type="bibr" target="#b33">[34]</ref>. DICE is originally a heuristic algorithm for disguising communities. In our experiment, DICE randomly decides whether to connect or disconnect an edge with probability p 2 between attacker nodes and other nodes in the graph. Besides, there is a constraint that only nodes belonging to the same class/different classes will be disconnected/connected. • GradArgmax <ref type="bibr" target="#b12">[13]</ref>. Since the attack budget ∆ is defined as the degrees of target node t, the original GradArgmax will remove all edges connected with t for direct attack, which is unreasonable and unfair to compare. Therefore, we use the variant of GradArgmax, which requires a dense instantiation of the adjacency matrix and computes the gradients of all N 2 edges.</p><p>• Nettack <ref type="bibr" target="#b11">[12]</ref>. Nettack is the strongest baseline that can modify the graph structure and node features. As we focus on the structure attack, we restrict Nettack to modify the graph structure with budget ∆ only. Parameter Settings. The hyper-parameters of target models are fine-tuned in the clean graph for each dataset. Particularly, the radius k = 2 and the scale factor = 5.0 for each dataset. We adopt the node reduction when generating adversarial examples, where the number of added potential nodes is set to ∆. For RA and DICE, p 1 and p 2 are both fixed at 0.5. All models are implemented in Tensorflow 4 , running on a NVIDIA RTX 2080Ti GPU.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance on Generating Adversarial Examples (RQ1)</head><p>As described in Table <ref type="table" target="#tab_2">2</ref>, our method is highly efficient in terms of time and space complexity compared to other methods. For running time, here we theoretically analyze how much improvement our method can achieve over Nettack, the state-of-theart adversarial attack method. Following the parameter settings described in section 6.1, i.e., k = 2 and ∆ = d, the relative time complexity can be approximated as</p><formula xml:id="formula_41">O(d • |A| • N • d 2 ) O(d • (d 2 + d • |A|) • d 2 ) = O( |A| • N d 2 + d • |A| ) ,<label>(23)</label></formula><p>This means that SGA can theoretically achieve</p><formula xml:id="formula_42">|A|•N d 2 +d</formula><p>•|A| times speedup compared to Nettack, and it will be higher for larger and sparser graphs.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the performance of generating adversarial examples with direct and influence attack strategies. Here the training time of the surrogate model is excluded and memory usage refers to the usage of storing the graph (subgraph). Please note that we do not compare the running time and memory usage with RA and DICE since they both are random algorithms and comparison doesn't make sense. Because the three datasets are sparse enough with small degrees on average (see Table <ref type="table" target="#tab_3">3</ref>), the two-hop subgraph is much smaller and SGA has a remarkable improvement in efficiency. Intuitively, we plot the performance of Nettack and GradArgmax over their running time relative to that of SGA on three datasets in Figure <ref type="figure" target="#fig_4">6</ref>. Considering the Citeseer dataset (statistics are in Table <ref type="table" target="#tab_3">3</ref>) and the direct attack setting (i.e., |A| = 1), the theoretical speedup comes to 134 times according to Eq.( <ref type="formula" target="#formula_41">23</ref>), which is approximately consist with the experimental results (120 times).</p><p>Table <ref type="table" target="#tab_5">4</ref> indicates that our method is much more efficient than GradArgmax and Nettack in terms of time and space complexity. Even if the dataset grows in size, SGA still remains high efficiency as if the graph is sparse enough. On Pubmed dataset, our method can even yield up to three orders of magnitude speedup over Nettack, also, SGA is much more memory efficient. On the contrary, Nettack becomes less efficient, especially when performing influence attacks on a larger dataset, the reason is that the larger scale of attacker nodes A and candidate edges set. As for GradArgmax, the running time and memory usage are similar between direct and influence attacks, since it computes the gradients of the entire graph all the time and the candidate edges set are always the same. In addition, both of them failed on Reddit dataset, a large and dense graph, but SGA still achieves high efficiency.</p><p>In respect to the metric DAC, Table <ref type="table" target="#tab_5">4</ref> shows that: (i) Direct attacks have greater impacts than influence attacks, it is clear and interpretable since perturbations are restricted in the neighborhood of the target node, leading to the significant degree changes especially the target node. Naturally, the concentrated perturbations will exert a greater influence; (ii) Nettack achieves the most unnoticeable influence because it is enforced to preserve the graph's degree distribution during attacks. Our method leverages the subgraph instead of the entire graph without any constraints on the degree distribution, thus achieving a slightly worse result but still better than GradArgmax. Note that, GradArgmax considers all N 2 edges as a candidate set to flip, it will largely affect the degree distribution of nodes in the graph, and the attack becomes more noticeable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Performance on Attacking Graph Neural Networks (RQ2)</head><p>For the target model SGC, whose details of the architecture are transparent (but not for its weights), it can be approximately treated as a white-box attack if it is used as a surrogate model.  However, for other graph neural network models, this is a complete black-box attack without any prior knowledge.</p><p>As shown in Table <ref type="table" target="#tab_6">5</ref>, we report the percentages of nodes that are correctly classified, where clean stands for results in the original graph. The classification performance of SGC drops significantly against direct attacks. Even against influence attacks, SGC is more vulnerable than other classifiers. Unlike SGC, other models are more robust even in the direct attack setting. There are four possible reasons to explain this: (i) The nonlinear activation function. SGC and GCN are similar except for activation functions. SGC drops the nonlinear activation in the hidden layer and collapses weight matrices between consecutive layers. Although SGC behaves more efficient during training, the simplification leads to the lower robustness than GCN. (ii) The details of model architectures are not exposed to attackers like SGC, and the performance depends on the transferability of attacks; (iii) The message aggregation methods are more robust than simple graph convolution. For instance, GAT introduces the attention mechanism and enables (implicitly) to specify different weights to different nodes in a neighborhood. For GraphSAGE, the most robust one in most of the datasets, we argue that it is probably on account of the concatenate operation on the node's message and the neighborhoods', which is aggregated with mean operation. By doing so, the influence of attacker nodes will be largely alleviated. (iv) Pre-processing of the input graph. For Cluster-GCN, it samples several subgraphs whose nodes have high correlations using a graph clustering algorithm and restricts the message aggregation within these subgraphs, which also reduces the influence of attacker nodes.</p><p>In Figure <ref type="figure" target="#fig_5">7</ref>, we can see that SGA achieves a considerable performance in most cases by comparing the results with different attack methods. Nettack, a strong baseline, also yields a significant performance as reported in <ref type="bibr" target="#b11">[12]</ref>. Most remarkably, even in attacking other robust graph neural networks (GAT, GraphSAGE, Cluster-GCN), most of the classifiers are strongly affected by perturbations especially performed by SGA and Nettack. The obtained results have proved the vulnerability of graph neural networks and are consistent with the previous studies. Not surprisingly, influence attacks achieve a worse performance compared with direct attacks, and random algorithms RA and DICE both have a slight attack effect on attacking different graph neural networks as expected. Both GradArgmax and SGA are gradientbased methods, we can also see that GradArgmax performs worse than our method SGA although the whole graph is used to attack. The possible explanations for the results are as follows: (i) The misclassification loss designed in Eq.( <ref type="formula" target="#formula_18">12</ref>) considers the loss of the next most probable class label as well as the ground-truth label, which is available to better exploit the vulnerability of graph As a result, the generated perturbations will be more concentrated and cause the misclassification of target classifiers much easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Scalability for Larger Datasets (RQ3)</head><p>As illustrated above, SGA achieves a considerable performance on attacking most of graph neural networks on three small-scale datasets and also ensures the time and space efficiency. To evaluate the scalability of SGA, we extend our experiments to two larger datasets -Pubmed and Reddit, the data statistics are described in Table <ref type="table" target="#tab_3">3</ref>. Particularly, Reddit is a relatively dense graph with node degrees up to 99.65 on average, which means that the attack budgets are much higher than other datasets in our settings, and naturally brings more challenges on time and memory usage.</p><p>As shown in Table <ref type="table" target="#tab_5">4</ref>, GradArgmax and Nettack become slower and more memory usage is required on larger datasets. Especially for the Reddit dataset, both GradArgmax and Nettack have failed due to high time and space complexity. On the contrary, SGA has similar time and memory usage on Pubmed dataset as it is sparse like Citeseer and Cora. Even on Reddit dataset, SGA has high efficiency in the direct attack (12.236s) and the influence attack (14.571s) settings.</p><p>Furthermore, we conduct attacks on the same target models by the generated adversarial examples. As shown in Table <ref type="table" target="#tab_7">6</ref>, SGA achieves state-of-the-art results in all cases, a significant performance decrease is observed on most of the target models especially SGC. As data scale grows, random algorithms RA and DICE have little or no effect on target models. On the largest dataset Reddit, GradArgmax and Nettack have failed to conduct attacks. But for SGA, the obtained results show that only a small part of target nodes are correctly classified by SGC and GCN in the direct attack setting. In the influence attack setting, SGA also has an obvious effect on the target models compared to RA and DICE. Results on Pubmed and Reddit datasets suggest that our method can easily scale to larger datasets and significantly reduce the performance of target models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Ablation Study</head><p>In order to explore the effect of different radius on SGA, we report the ablation test on Citeseer and Cora datasets from the various   In Figure <ref type="figure" target="#fig_8">8</ref>, it can be observed that k = 2 achieves the best performance on attacking SGC and GCN on both datasets. But for other target models, a better performance is achieved when k = 1 or k = 3.</p><p>However, if k = 1 the subgraph includes only the immediate neighboring nodes the target node (except for potential nodes), SGA can only delete the edges that are directly connected to the target node and it is not permitted in the influence attack setting. As the radius of the subgraph gets larger, the number of nodes and edges increases exponentially, and it would require more time and memory usage to perturb the graph. So we need to make a trade-off between efficiency and performance. Given that the best classification performance can be achieved by a two-layer GCN or SGC in most datasets, SGA can exploit the vulnerability of graph neural network models with only a two-hops subgraph, and the efficiency of attack is also preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>In this work, we study the adversarial attacks on the (attributed) graph and present a novel simplified gradient-based attack framework focusing on the node classification task. Specifically, we aim to poison the input graph and lead to the misclassification of graph neural networks for several target nodes. Based on the extensive experiments, our method SGA, which simply leverages a k-hop subgraph of the target node, has achieved high efficiency in terms of time and memory and also obtained comparable performance in attacking different graph neural networks compared to other stateof-the-art adversarial attack methods. It can be also observed that SGA scales to larger datasets and achieves a remarkable performance in the attack. In addition, we emphasize the importance of measuring the attack impacts on graph data and further propose DAC as a measure. The results show that DAC works as a practical metric and SGA can also achieve a relatively unnoticeable attack impact.</p><p>Our works mainly focus on the node classification task and the targeted attack. For future work, we aim to extend our method and generalize it to other graph analysis tasks with more flexibility. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The prediction probability of the first and next most probable (second) class of SGC on Citeseer and Cora before and after calibration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>Fig. 3: Simplified gradient-based attack using subgraph. A two-hop subgraph centered at target node is extracted and potential nodes (dotted-line nodes) outside the subgraph are added as well to compute the gradients of potential edges. The values within nodes denote the gradients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>= 9 :</head><label>9</label><figDesc>f θ (A (subi) , X, ); 8: Compute ∇ G (sub i ) with Eq.(11); Compute structure score S with Eq.(17); 10: Select e = (u, v) with largest structure score S u,v ; 11:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Typical Example of Assortative or Disassortative networks. The fuzzy edges indicate that nodes can have any number of edges of this type. (Image Credit: Foster et al. [19])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: Performance over running time on three datasets for direct and influence attack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig.7: Results on Cora dataset using direct attack (top) and influence attack (-In, bottom). "NTK" is short for Nettack and "GA" is short for GradArgmax.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Performance of SGA on attacking different graph neural network models with various radius on Citeseer and Cora datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Teams (2017ZT07X355), and the Key Research and Development Program of Guangdong Province of China (2018B030325001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 :</head><label>1</label><figDesc>Frequently used notations in this paper.</figDesc><table><row><cell cols="2">Notations</cell><cell>Descriptions</cell></row><row><cell></cell><cell>G</cell><cell>Graphical representation of the data</cell></row><row><cell></cell><cell>V</cell><cell>Set of vertices in the graph</cell></row><row><cell></cell><cell>E</cell><cell>Set of edges in the graph</cell></row><row><cell></cell><cell>C</cell><cell>Set of class labels of nodes</cell></row><row><cell cols="2">N , C, F</cell><cell>Number of nodes, classes and dimensions</cell></row><row><cell></cell><cell>A</cell><cell>Adjacency matrix of the graph, N × N</cell></row><row><cell></cell><cell>X</cell><cell>Feature matrix of the nodes, N × F</cell></row><row><cell></cell><cell>D</cell><cell>Diagonal matrix of the degree of each vertex, N × N</cell></row><row><cell></cell><cell>f θ</cell><cell>Graph neural networks model</cell></row><row><cell></cell><cell>W</cell><cell>Trainable weight matrix, F l × F l+1</cell></row><row><cell></cell><cell>Z</cell><cell>Prediction probability of nodes, N × C</cell></row><row><cell></cell><cell>t</cell><cell>Target node to attack</cell></row><row><cell></cell><cell></cell><cell>Scale factor to calibrate the model</cell></row><row><cell cols="2">D(u, v)</cell><cell>The shortest distance between u and v</cell></row><row><cell cols="2">N (t)</cell><cell>Set of nodes adjacent to node t</cell></row><row><cell></cell><cell>k</cell><cell>Radius of the subgraph</cell></row><row><cell></cell><cell></cell><cell>Set of attacker nodes,</cell></row><row><cell></cell><cell>A</cell><cell>A = {t} for direct attack,</cell></row><row><cell></cell><cell></cell><cell>A = N (t) for influence attack</cell></row><row><cell></cell><cell>M</cell><cell>Degree mixing matrix</cell></row><row><cell></cell><cell>r</cell><cell>Degree assortativity coefficient</cell></row><row><cell></cell><cell>∆</cell><cell>Attack budget</cell></row><row><cell cols="2">G , A , X</cell><cell>Perturbed graph, adjacency matrix, feature matrix</cell></row><row><cell>Lt,</cell><cell>L(sub) t</cell><cell>Targeted misclassification loss on the graph or subgraph</cell></row><row><cell></cell><cell>S</cell><cell>Structure score matrix</cell></row><row><cell cols="2">G (sub)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>attack budget ∆, target node t, groundtruth label c t , labeled nodes V L , hyper-parameter k for surrogate model SGC; Output: Perturbed graph G t w.r.t target node t; 1: θ ← train the surrogate model on labeled nodes V L ; 2: c t = arg max c =ct Z t,c ← predict the next most probable class of t ;</figDesc><table /><note>3: Extract the k-hop subgraph centered at t ; 4:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 :</head><label>2</label><figDesc>Time and Space Complexity of Adversarial Attack Algorithms.</figDesc><table><row><cell>Methods</cell><cell>Space complexity</cell><cell>Time complexity</cell></row><row><cell>Nettack</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 :</head><label>3</label><figDesc>Dataset statistics. Only consider the largest connected component of the graph for each dataset.</figDesc><table><row><cell>Statistics</cell><cell>Citeseer</cell><cell>Cora</cell><cell>Pubmed</cell><cell>Reddit</cell></row><row><cell>#Nodes</cell><cell>2,110</cell><cell>2,485</cell><cell>19,717</cell><cell>232,965</cell></row><row><cell>#Edges</cell><cell>3,668</cell><cell>5,069</cell><cell>44,324</cell><cell>11,723,402</cell></row><row><cell>#Density</cell><cell>0.082%</cell><cell>0.082%</cell><cell>0.011%</cell><cell>0.022%</cell></row><row><cell>#Average Degrees</cell><cell>3.50</cell><cell>4.08</cell><cell>4.50</cell><cell>99.65</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4 :</head><label>4</label><figDesc>Average time (s), memory usage, and DAC to generate adversarial examples using both attack strategies. The statistics of random algorithms RA and DICE are omitted. OOM stands for a method that could not be used to attack due to the limitations of GPU RAM.</figDesc><table><row><cell cols="2">Methods</cell><cell></cell><cell cols="2">Citeseer</cell><cell></cell><cell></cell><cell>Cora</cell><cell></cell><cell></cell><cell>Pubmed</cell><cell></cell><cell></cell><cell>Reddit</cell></row><row><cell cols="2">Direct Attack</cell><cell>Time</cell><cell cols="2">Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell></row><row><cell cols="2">GradArgmax</cell><cell>0.188</cell><cell></cell><cell>17MB</cell><cell>7.9E-2</cell><cell>0.297</cell><cell>23MB</cell><cell>2.9E-3</cell><cell>13.856</cell><cell cols="2">1483MB 4.2E-3</cell><cell>N/A</cell><cell>OOM</cell><cell>-</cell></row><row><cell cols="2">Nettack</cell><cell>0.722</cell><cell></cell><cell>66KB</cell><cell>3.2E-2</cell><cell>1.151</cell><cell>89KB</cell><cell>1.4E-3</cell><cell>39.526</cell><cell>769KB</cell><cell>1.3E-3</cell><cell>N/A</cell><cell>180MB</cell><cell>-</cell></row><row><cell></cell><cell>SGA</cell><cell>0.006</cell><cell></cell><cell>2KB</cell><cell>3.4E-2</cell><cell>0.011</cell><cell>2KB</cell><cell>1.7E-3</cell><cell>0.020</cell><cell>4KB</cell><cell>1.8E-3</cell><cell>12.236</cell><cell>14MB</cell><cell>2.5E-6</cell></row><row><cell cols="2">Influence Attack</cell><cell>Time</cell><cell cols="2">Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell><cell>Time</cell><cell>Memory</cell><cell>DAC</cell></row><row><cell cols="2">GradArgmax</cell><cell>0.239</cell><cell></cell><cell>17MB</cell><cell>1.7E-2</cell><cell>0.321</cell><cell>23MB</cell><cell>1.1E-3</cell><cell>14.412</cell><cell cols="2">1483MB 9.2E-4</cell><cell>N/A</cell><cell>OOM</cell><cell>-</cell></row><row><cell cols="2">Nettack</cell><cell>2.104</cell><cell></cell><cell>89KB</cell><cell>1.6E-2</cell><cell>3.969</cell><cell>66KB</cell><cell>9.4E-4</cell><cell>120.821</cell><cell>769KB</cell><cell>8.1E-4</cell><cell>N/A</cell><cell>180MB</cell><cell>-</cell></row><row><cell></cell><cell>SGA</cell><cell>0.008</cell><cell></cell><cell>5KB</cell><cell>1.7E-2</cell><cell>0.012</cell><cell>6KB</cell><cell>1.0E-3</cell><cell>0.021</cell><cell>7KB</cell><cell>8.7E-4</cell><cell>14.571</cell><cell>14MB</cell><cell>1.9E-6</cell></row><row><cell>Pubmed-In.</cell><cell>1x</cell><cell></cell><cell></cell><cell></cell><cell>686x</cell><cell>5753x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pubmed</cell><cell>1x</cell><cell></cell><cell></cell><cell></cell><cell cols="2">692x 1976x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cora-In.</cell><cell>1x</cell><cell></cell><cell>26x</cell><cell></cell><cell>330x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cora</cell><cell>1x</cell><cell></cell><cell>27x</cell><cell>104x</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Citeseer Citeseer-In.</cell><cell>10 0 1x 1x</cell><cell>10 1</cell><cell cols="3">10 2 Relative Time 10 3 31x 120x 29x 263x</cell><cell cols="2">10 4 GradArgmax 10 5 Nettack SGA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5 :</head><label>5</label><figDesc>Accuracy(%) of direct attack and influence attack on two small scale datasets. Here the best results are boldfaced.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell></cell><cell>Citeseer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cora</cell><cell></cell></row><row><cell>Direct Attack</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell></row><row><cell>Clean</cell><cell>71.8</cell><cell>71.6</cell><cell>72.1</cell><cell>71.0</cell><cell>71.4</cell><cell>83.1</cell><cell>83.5</cell><cell>84.2</cell><cell>82.0</cell><cell>83.2</cell></row><row><cell>RA</cell><cell>62.0</cell><cell>63.6</cell><cell>59.0</cell><cell>61.9</cell><cell>62.8</cell><cell>67.5</cell><cell>68.8</cell><cell>69.7</cell><cell>68.8</cell><cell>68.1</cell></row><row><cell>DICE</cell><cell>55.0</cell><cell>57.8</cell><cell>54.6</cell><cell>56.6</cell><cell>57.1</cell><cell>58.4</cell><cell>60.2</cell><cell>61.8</cell><cell>59.7</cell><cell>59.5</cell></row><row><cell>GradArgmax</cell><cell>12.2</cell><cell>13.2</cell><cell>21.5</cell><cell>32.4</cell><cell>34.8</cell><cell>25.2</cell><cell>32.6</cell><cell>34.5</cell><cell>30.9</cell><cell>45.6</cell></row><row><cell>Nettack</cell><cell>3.7</cell><cell>6.0</cell><cell>20.5</cell><cell>27.9</cell><cell>30.9</cell><cell>1.0</cell><cell>2.4</cell><cell>17.6</cell><cell>27.2</cell><cell>17.8</cell></row><row><cell>SGA</cell><cell>1.8</cell><cell>3.8</cell><cell>20.3</cell><cell>30.2</cell><cell>19.9</cell><cell>1.5</cell><cell>2.1</cell><cell>15.9</cell><cell>25.8</cell><cell>17.6</cell></row><row><cell>Influence Attack</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell></row><row><cell>RA</cell><cell>71.2</cell><cell>71.1</cell><cell>71.4</cell><cell>68.8</cell><cell>70.8</cell><cell>80.9</cell><cell>83.0</cell><cell>86.0</cell><cell>81.4</cell><cell>83.0</cell></row><row><cell>DICE</cell><cell>69.4</cell><cell>71.1</cell><cell>70.2</cell><cell>67.5</cell><cell>68.4</cell><cell>80.5</cell><cell>82.4</cell><cell>85.4</cell><cell>79.8</cell><cell>82.7</cell></row><row><cell>GradArgmax</cell><cell>47.8</cell><cell>48.1</cell><cell>51.2</cell><cell>46.7</cell><cell>55.4</cell><cell>65.1</cell><cell>70.8</cell><cell>73.8</cell><cell>74.7</cell><cell>72.9</cell></row><row><cell>Nettack</cell><cell>31.4</cell><cell>39.2</cell><cell>49.3</cell><cell>41.9</cell><cell>49.8</cell><cell>48.4</cell><cell>56.4</cell><cell>63.2</cell><cell>63.5</cell><cell>60.0</cell></row><row><cell>SGA</cell><cell>33.1</cell><cell>38.5</cell><cell>45.2</cell><cell>40.2</cell><cell>48.1</cell><cell>46.2</cell><cell>56.2</cell><cell>62.6</cell><cell>62.8</cell><cell>57.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 6 :</head><label>6</label><figDesc>Accuracy(%) of direct attack and influence attack on two large scale datasets. Here the best results are boldfaced. As detailed in section 4.3.1, the surrogate model appears to make an overconfident output and it causes the vanishing of gradients. SGA introduces a scale factor to calibrate the surrogate model, the gradient vanishing is alleviated and achieves a performance gain. (iii) SGA focuses on a part of nodes -the k-hop subgraph of the target node and some potential nodes.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell></cell><cell>Pubmed</cell><cell></cell><cell cols="2">Reddit</cell></row><row><cell>Direct Attack</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell><cell cols="2">SGC GCN</cell></row><row><cell>Clean</cell><cell>84.2</cell><cell>86.5</cell><cell>85.3</cell><cell>86.1</cell><cell>85.7</cell><cell>93.8</cell><cell>93.6</cell></row><row><cell>RA</cell><cell>76.6</cell><cell>78.2</cell><cell>75.0</cell><cell>81.5</cell><cell>75.8</cell><cell>88.6</cell><cell>89.4</cell></row><row><cell>DICE</cell><cell>65.0</cell><cell>67.1</cell><cell>57.8</cell><cell>72.3</cell><cell>64.0</cell><cell>84.2</cell><cell>88.2</cell></row><row><cell>GradArgmax</cell><cell>14.8</cell><cell>15.8</cell><cell>16.9</cell><cell>42.7</cell><cell>48.3</cell><cell>-</cell><cell>-</cell></row><row><cell>Nettack</cell><cell>2.0</cell><cell>3.4</cell><cell>10.9</cell><cell>32.4</cell><cell>19.9</cell><cell>-</cell><cell>-</cell></row><row><cell>SGA</cell><cell>1.6</cell><cell>2.0</cell><cell>9.3</cell><cell>30.6</cell><cell>15.7</cell><cell>1.2</cell><cell>5.4</cell></row><row><cell>Influence Attack</cell><cell cols="5">SGC GCN GAT GraphSAGE Cluster-GCN</cell><cell cols="2">SGC GCN</cell></row><row><cell>RA</cell><cell>84.1</cell><cell>86.2</cell><cell>85.3</cell><cell>87.2</cell><cell>84.6</cell><cell>93.6</cell><cell>93.5</cell></row><row><cell>DICE</cell><cell>83.6</cell><cell>85.9</cell><cell>84.7</cell><cell>85.8</cell><cell>84.4</cell><cell>93.7</cell><cell>93.7</cell></row><row><cell>GradArgmax</cell><cell>73.2</cell><cell>77.8</cell><cell>72.7</cell><cell>84.0</cell><cell>76.2</cell><cell>-</cell><cell>-</cell></row><row><cell>Nettack</cell><cell>61.4</cell><cell>72.0</cell><cell>70.1</cell><cell>85.4</cell><cell>69.2</cell><cell>-</cell><cell>-</cell></row><row><cell>SGA</cell><cell>63.4</cell><cell>70.7</cell><cell>70.0</cell><cell>82.6</cell><cell>67.8</cell><cell>78.9</cell><cell>83.6</cell></row><row><cell cols="2">neural networks. (ii)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">. We follow the attack settings of Nettack<ref type="bibr" target="#b11">[12]</ref> which modifies graph structure and node features by flipping them from 0 to 1 or vice verse. Since node features in the real-world dataset may be continuous (not binary), it is difficult to constrain attacks within a given budget ∆ ∈ N.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The paper was supported by the National Natural Science Foundation of China (61702568, U1711267), the Guangdong Basic and Applied Basic Research Foundation (2020A1515010831), the Program for Guangdong Introducing Innovative and Entrepreneurial</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Jintang Li received the bachelor's degree at Guangzhou Medical University, Guangzhou, China, in 2018. He is currently pursuing the master's degree with the School of Electronics and Communication Engineering, Sun Yat-sen University, Guangzhou, China. His main research interests include graph representation learning, adversarial machine learning and data mining techniques.</p><p>Tao Xie received the bachelor's degree at Sun Yat-sen University, Guangzhou, China, in 2020. He is currently pursuing the master's degree with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China. His main research interests include recommendation systems, machine learning and data mining techniques. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Liang</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-05-26">2013. May 26-31, 2013. 2013</date>
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC 2015</title>
				<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="41" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
				<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno>ICLR 2014</idno>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">April 14-16, 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A weighted meta-graph based approach for mobile application recommendation on heterogeneous information networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<idno>Novem- ber 12-15</idno>
	</analytic>
	<monogr>
		<title level="m">Service-Oriented Computing -16th International Conference, ICSOC 2018</title>
		<title level="s">Proceedings, ser. Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Hangzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="volume">11236</biblScope>
			<biblScope unit="page" from="404" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Factorization machine based service recommendation on heterogeneous information networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Web Services, ICWS 2018</title>
				<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">July 2-7, 2018. 2018</date>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Matching user with item set: Collaborative bundle recommendation with deep attention network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019</title>
				<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 10-16, 2019. ijcai.org, 2019</date>
			<biblScope unit="page" from="2095" to="2101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
				<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24">2017. April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Heterogeneous neural attentive factorization machine for rating prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM 2018</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying influential individuals on large-scale social networks: A community based approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="240" to="247" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Community detection in location-based social networks: An entropy-based approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Computer and Information Technology, CIT 2016</title>
				<meeting><address><addrLine>Nadi, Fiji</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016">December 8-10, 2016. 2016</date>
			<biblScope unit="page" from="452" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial attacks on neural networks for graph data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akbarnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-08-19">2018. August 19-23. 2018. 2018</date>
			<biblScope unit="page" from="2847" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial attack on graph structured data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan</title>
				<meeting>the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">July 10-15, 2018. 2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1123" to="1132" />
		</imprint>
	</monogr>
	<note>ser. Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial attacks on node embeddings via graph poisoning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
				<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA, ser</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-06-15">9-15 June 2019. 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="695" to="704" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial attacks on graph neural networks via meta learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zügner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<idno>ICLR 2019</idno>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
				<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">May 6-9, 2019. OpenReview.net, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H D</forename><surname>Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mixing patterns in networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">26126</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Edge direction and the structure of networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grassberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paczuski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">820</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Manipulating machine learning: Poisoning attacks and countermeasures for regression learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nita-Rotaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Symposium on Security and Privacy (SP)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="19" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Property inference attacks on fully connected neural networks using permutation invariant representations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ganju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Borisov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGSAC</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="619" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy (SP)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A survey of adversarial learning on graph</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.05730</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deepfool: A simple and accurate method to fool deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016</title>
				<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016">June 27-30, 2016. 2016</date>
			<biblScope unit="page" from="2574" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Topology attack and defense for graph neural networks: An optimization perspective</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019</title>
				<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">August 10-16, 2019. ijcai.org, 2019</date>
			<biblScope unit="page" from="3961" to="3967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hiding individuals and communities in a social network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Waniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An experimental study of the small world problem</title>
		<author>
			<persName><forename type="first">J</forename><surname>Travers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Milgram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Networks</title>
				<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="179" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collective dynamics of &quot;small-world&quot; networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="issue">6684</biblScope>
			<biblScope unit="page">440</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="issue">5439</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Classes of small-world networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
				<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page">152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Conference on Computational Statistics, COMPSTAT 2010</title>
				<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>Physica-Verlag</publisher>
			<date type="published" when="2010">August 22-27, 2010. 2010</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
	<note>-Keynote, Invited and Contributed Papers</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Principles of neurodynamics. perceptrons and the theory of brain mechanisms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cornell Aeronautical Lab Inc Buffalo NY</title>
		<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
				<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11">2017. 6-11 August 2017. 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mining hidden community in heterogeneous social networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international workshop on Link discovery</title>
				<meeting>the 3rd international workshop on Link discovery</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Link prediction adversarial attack via iterative gradient attack</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1081" to="1094" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Graph embedding techniques, applications, and performance: A survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="78" to="94" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Two samples test for discrete power-law distributions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bessi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00643</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The human disease network</title>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Cusick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="8685" to="8690" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
				<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09">2017, 4-9 December 2017. 2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Clustergcn: An efficient algorithm for training deep and large graph convolutional networks</title>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
