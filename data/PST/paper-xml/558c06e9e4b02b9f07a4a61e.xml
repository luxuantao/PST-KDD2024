<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Compositional Syntax From Cultural Transmission</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Henry</forename><surname>Brighton</surname></persName>
							<email>henryb@ling.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Evolution and Computation Research Unit Department of Theoretical and Applied Linguistics University of Edinburgh Adam Fergusen Building</orgName>
								<address>
									<postCode>EH8 9LL</postCode>
									<settlement>George Square Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Compositional Syntax From Cultural Transmission</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7AA861BBE67C2107D334028D76995D4C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>language</term>
					<term>evolution</term>
					<term>syntax</term>
					<term>learning</term>
					<term>compression</term>
					<term>culture</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A growing body of work demonstrates that syntactic structure can evolve in populations of genetically identical agents. Traditional explanations for the emergence of syntactic structure employ an argument based on genetic evolution: Syntactic structure is specified by an innate language acquisition device (LAD). Knowledge of language is complex, yet the data available to the language learner are sparse. This incongruous situation, termed the "poverty of the stimulus," is accounted for by placing much of the specification of language in the LAD. The assumption is that the characteristic structure of language is somehow coded genetically. The effect of language evolution on the cultural substrate, in the absence of genetic change, is not addressed by this explanation. We show that the poverty of the stimulus introduces a pressure for compositional language structure when we consider language evolution resulting from iterated observational learning. We use a mathematical model to map the space of parameters that result in compositional syntax. Our hypothesis is that compositional syntax cannot be explained by understanding the LAD alone: Compositionality is an emergent property of the dynamics resulting from sparse language exposure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Children master complex features of language on the basis of surprisingly little evidence. This phenomenon, termed the poverty of the stimulus, has been taken as evidence for innate linguistic knowledge <ref type="bibr" target="#b5">[6]</ref>. How can such a rich body of linguistic knowledge be induced from an impoverished body of linguistic evidence? The traditional explanation appeals to an innate language acquisition device (LAD) <ref type="bibr" target="#b4">[5]</ref>. The LAD is a languagespecific module encapsulating the knowledge of language that cannot be induced from primary linguistic data. This explanation attributes the bulk of the specification of language to the human biological endowment, rather than the linguistic stimulus. In short, when considering the origins of language, humans, and possibly other hominids, developed language directly as a result of the biological evolution of the LAD <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. If the syntactic structure of language can be explained in terms of the LAD alone, the fundamentals of the story of how language emerged, and why language has the structure it does, are in place.</p><p>An important linguistic dynamic is missing from this explanation: Language itself can evolve, on a cultural substrate, among genetically homogeneous language users. By investigating the degree to which this dynamic can result in language evolution, recent agent-based simulations have questioned the primacy of innatist accounts of linguistic structure. For example, Kirby <ref type="bibr" target="#b8">[9]</ref> and Batali <ref type="bibr" target="#b0">[1]</ref> demonstrate that recursive and compo-sitional syntax can emerge in the absence of genetic change. These experiments raise important questions. Can we explain why language has its characteristic structure by analyzing the LAD alone? How much of the structure of language is determined by the dynamics resulting from evolution on a cultural substrate? The situation characterized by the poverty of the stimulus poses a design problem. One solution is an innate, structure-specifying LAD. Using a mathematical model, we propose an alternative to this solution. The poverty of the stimulus introduces a strong pressure for compositional structure when we take into account cultural evolution: Our hypothesis is that much of the characteristic structure of language, of which compositionality is one distinctive feature, emerges as a result of pressures on transmission. It is important to stress that to some degree, an innate LAD is required for language, but the syntactic structure of language need not be explicitly specified by this LAD.</p><p>Previous work can be characterized as establishing that compositional and recursive syntax, two of the hallmarks of language, can emerge relative to a population of genetically homogeneous language users <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. We build on this work, first by mapping the space of model parameters that lead to linguistic structure, and second by introducing a model that accounts for statistical effects during the language acquisition process. Instead of aiming to demonstrate that linguistic structure can emerge in the absence of genetic change, our methodology focuses on establishing the range of conditions for emergence. Our results show that instead of characterizing the poverty of the stimulus as a constraint on transmission, overcome by the LAD, it is best conceived of as a determinant in the evolution of compositional syntax. We argue that compositional structure is best explained in terms of the dynamics of language evolution, rather than the internals of the LAD.</p><p>To model language evolution we use the iterated learning model, an agent-based model of cultural evolution where language change results from repeated observational learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. In Section 2 the details of the iterated learning model are presented. In this model, each agent has the ability to generalize from observed examples of language. The generalization bias of each agent determines how language changes from generation to generation. In Section 3 we introduce a generalization procedure based on the minimum description length principle. An abstracted form of this generalization procedure is developed in Section 4 and is used to form part of a mathematical model. This model, covered in Section 5, is used to map the parameter space. The results are discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Iterated Learning Model</head><p>The iterated learning model (ILM) provides a framework for modeling the cultural evolution of language <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref>. Language is transmitted from one generation to the next by one agent forming utterances, and the next agent observing these utterances. This process is repeated generation after generation, and in linguistic terms characterizes the translation from language performance (language use) to language competence (language knowledge) via observational learning: Agents induce their knowledge of language through observation. The ILM captures an important characteristic of language. Language is learned by language users, and the input to the learning process is based on the output of learning itself. This is an important phenomenon. The space of possible languages is restricted to contain only those languages that can be produced by an agent. The effects of any bias on either learning or production will be amplified at each generation.</p><p>The ILM is an agent-based model where each agent represents a language user. Given the most basic population model, where each generation comprises one agent, the ILM proceeds as follows. The first generation agent, A 1 , forms utterances. The second generation agent A 2 observes these utterances and forms a hypothesis to account for them. The next generation proceeds by A 2 producing utterances that the next agent A 3 observes. This process is repeated, often for thousands of generations. How, for example, does the language of A 233 differ to that of A 1047 ? Does the system reach a steady state? What kind of languages emerge and characterize steady states? The ILM allows us to answer questions like these. By exploring the properties of an agent, along with certain pressures on information transmission, we can try to attack the issue of how certain language structures evolve. The key idea is that language itself evolves; each agent in the model is initially identical. Agents arrive at different hypotheses only when they are exposed to different bodies of linguistic evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Simplifying Assumptions</head><p>Before examining the ILM in more detail, it is worth making explicit the simplifying assumptions we have made in the construction of the model.</p><p>1. Agents have the ability to "mind read." When an agent observes a signal, the intended meaning of that signal is also given. This simplification avoids the problem of modeling the ascription of a meaning to a signal. An agent must associate a signal with a meaning somehow, but we regard this as a separate, nontrivial problem <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>. In short, we assume meaning transmission occurs over a noiseless channel.</p><p>2. Issues of communication are not considered. For example, communicative accuracy, the agents' intentions, or any model of success or failure in language use is not considered. How much of the structure of language is due to pressures on learning? To begin to answer this question, we must strip the model of any assumptions about the functional aspects of communication. Part of our hypothesis is that issues relating to communication are not the principle determinants of language structure.</p><p>3. Population effects are not considered. Each agent learns from the output of only one other agent. Similarly, utterances produced by an agent are only observed by a single infant agent.</p><p>From a modeling perspective, these simplifications are crucial. Ultimately we seek the minimal set of assumptions and hypotheses with which linguistic structure can be explained. By employing such a minimal model, the degree of similarity between the resulting languages and natural language will be negligible. Properties of natural language, such as parts of speech and tense, will not occur. However, by introducing additional details to the model, certain aspects of natural language can emerge. For example, the occurrence of regular/irregular forms emerge in the ILM when we introduce a pressure for small signals in conjunction with a nonuniform distribution over meanings <ref type="bibr" target="#b10">[11]</ref>.</p><p>It is important to note that although elements of language structure can evolve through iterated learning, biological evolution must form the backbone of any story of language evolution (see, for example, <ref type="bibr" target="#b6">[7]</ref>). The structure of the agents, how they learn, and how they conceptualize communicatively relevant situations, is taken to be biologically determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Iterated Learning in Detail</head><p>Each agent senses an external environment that contains n objects {ω 1 , ω 2 , . . . , ω n }. Each object ω i represents some communicatively relevant situation. We do not attempt</p><formula xml:id="formula_0">ω 1 ω n ω 2 ω 3 F F F 1 3 2 Meaning Space Agent Environment Figure 1.</formula><p>The relationship between the environment and an agent. The environment contains a set of n objects {ω 1 , ω 2 , . . . , ω n } that represent communicatively relevant situations. These objects are perceived by the agent in terms of a semantic space. In this example, a three-dimensional meaning space is used to represent the objects internally.</p><p>to specify the details of these situations. The important point is that objects are conceptualized in terms of a meaning space internal to the agent. To an agent, an object corresponds to a point in its meaning space. The distinction between an object and a meaning is important. In previous work, every meaning in a meaning space is an object; during a simulation, all meanings represent communicatively relevant situations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>. We introduce the object/meaning distinction as it allows different meaning space structures to be used for a given environment. For example, given an environment containing 100 objects, we can use one from any number of meaning spaces to conceptualize (label) the objects. Figure <ref type="figure">1</ref> illustrates the relationship between the external environment and the internal meaning space. More formally, a meaning is a vector drawn from a space defined by two parameters: F , the number of features, and V , the cardinality of the set from which feature values are drawn. A simplifying assumption is made that each feature has the same number of possible values, V . We make this assumption as it simplifies the mathematics of the model. In short, meanings are points in an F -dimensional space, with each dimension having V discrete values. The environment remains constant over time, and we assume that different agents sense the same object in the same way: The correspondence between object and meaning is identical for different agents. The mapping from objects to meanings is random. From the point of view of the agent some objects will be indistinguishable if the same meaning is used to label more than one object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Language as a Mapping Between Meanings and Signals</head><p>Agents, on the basis of their linguistic competence, utter signals that stand for meanings. A language defines the relationship between meanings and signals. More formally, a language is a mapping between meanings and signals. We define it as follows. First, signals are defined as strings of symbols drawn from some alphabet . The maximum length of a signal is l max . Given a meaning m and signal s, a meaning/signal pair is denoted by m, s such that m is drawn from the meaning space M:</p><formula xml:id="formula_1">M = {( f 1 , f 2 , . . . , f F ): 1 ≤ f i ≤ V and 1 ≤ i ≤ F }</formula><p>and the signal s is drawn from the signal space S:</p><formula xml:id="formula_2">S = {w 1 w 2 . . . w l : w i ∈ and 1 ≤ l ≤ l max }</formula><p>A language L is defined as a set of meaning/signal, m, s , pairs. From the space of all languages, two classes of language structure will be considered: holistic languages and compositional languages. Central to this distinction is the relationship between meaning structure and signal structure. A holistic language exhibits no structural relationship between meanings and signals: The whole signal stands for the whole meaning, rather than parts of the signal referring to parts of the meaning. A compositional language is one where a relationship does exist between meaning and signal: The meaning of a signal is a function of the meaning of its parts, and how they are assembled <ref type="bibr" target="#b14">[15]</ref>. Holistic languages and compositional languages are constructed as follows:</p><p>• To construct a holistic language L holistic given a set of meanings M , a random signal is assigned to each meaning. Each signal is of some random length l (1 ≤ l ≤ l max ) and is composed of symbols drawn randomly from .</p><p>• To construct a compositional language L comp given a set of meanings M , we use a dictionary of subsignals. Each subsignal is used to represent a feature value. For simplicity, the assumption is made that each feature value, for each feature, has a unique entry in the dictionary, that is, a subsignal refers to one and only one feature value, for one feature. For each meaning in M a signal is constructed on the basis of the dictionary: A signal is formed by concatenating the corresponding subsignal for each feature value in the meaning. For simplicity, the order of subsignals occurring in the complete signal reflects the order of feature values in the meaning. This simplification is made for language construction only and does not restrict the class of compositional languages we account for in the model.</p><p>In a compositional language similar meanings will map to similar signals. Similar meanings, by definition, must have elements in common and so their corresponding signals will also have elements in common. The mapping from meanings to signals will be neighborhood preserving: Groups of similar meanings always map to groups of similar signals. This kind of regularity does not occur, unless by chance, when constructing holistic languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Learning, Production, and Language Change</head><p>After observing some language L an agent selects a hypothesis H that best describes L. When called upon to express objects, which appear as meanings, the agent then uses the hypothesis H to find an appropriate signal for each of these meanings. The linguistic competence of the agent is defined as the ability to express signals for meanings. The set of possible hypotheses, the process by which the hypothesis is selected, and the manner in which appropriate signals are chosen for meanings are collectively termed the generalization process. Consider the case when the observed language L is a subset of some larger language L. We say the agent observes L subject to a transmission bottleneck. This situation resembles what Chomsky <ref type="bibr" target="#b5">[6]</ref> termed the poverty of the stimulus. The language L is an impoverished version of L. Depending on the effectiveness of the generalization process, and the structure in L, it is possible for an agent to reproduce all the meaning/signal pairs in L after only observing L. Learners of natural language are placed in exactly this situation: Nobody learns English by observing all English sentences.</p><p>The behavior of an agent can be thought of as a function that maps the language of generation t, L t , to the language of generation L t+1 : Under certain conditions L t = L t+1 , in which case L t is a stable language. The iterated learning process rests on the fact that the input to an agent is the output of another agent. In linguistic terms, an infant learns language by observing the linguistic behavior of an adult. In this model, we show that language evolution will only occur when agents suffer from the poverty of the stimulus. In the iterated learning model the poverty of the stimulus occurs as a result of the transmission bottleneck: Language learners never learn from a complete exposure to the language of the previous generation. Figure <ref type="figure">2</ref> depicts this process in more detail. The first agent A 1 observes a language best described by the hypothesis H 1 . Objects in the environment are then presented to A 1 , at random, some number of times. The agent must utter a signal for each of these objects. This process is termed production. The next agent A 2 then observes these meaning/signal pairs. This process is repeated; each agent is presented with a random series of object observations. Random meanings, along with the induced hypothesis, are then used to produce the language for the next generation to observe. The first agent in the model observes utterances drawn from a holistic language.</p><formula xml:id="formula_3">f : L t → L t+1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Language Evolution</head><p>In this model, language evolves when an agent attempts to reconstruct the language of the previous generation on the basis of sparse language exposure. Inconsistencies between the two languages are introduced because either the structure of language makes generalization impossible, or the generalization procedure is inadequate. In this article we are principally interested in steady states, rather than the transitions a language passes through before stability results. Before focusing on steady states, this section will clarify the factors that drive language change.</p><p>To arrive at and maintain a steady state requires specific conditions. In the absence of a transmission bottleneck all language structures are stable because all objects are observed in conjunction with a signal. Providing the hypothesis is consistent with the data, no uncertainty can arise when an object needs to be expressed. As soon as a learner forms a hypothesis on the basis of a subset of the whole language, instability can result; some of the objects may not have been observed during the lifetime of the agent. In this situation the agent must use knowledge of what it has observed to postulate solutions to what it has not observed. For this reason, the set of language structures that result in stability will depend on the size of the transmission bottleneck.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Unstable States and Language Evolution</head><p>How exactly does the language of one generation get transformed into the language of the next generation? Consider the meaning/signal pair m, s , that occurs in some language L n . One of three mechanisms will be responsible for the association of m with some signal s in the next generation, L n+1 :</p><p>1. Memorization. Here, s = s as the learner uses the signal that accompanied the meaning when it was observed. The mapping between m and s does not change.</p><p>Memorization can only occur when m, s is observed.</p><p>2. Generalization. In the case that the learner has never observed m, s , but enough is known about the relationship between the observed meanings and their signals, an appropriate signal can be arrived at by induction. In this situation, either s = s , and the association remains stable, or via a progressive induction decision, s = s . The latter change is progressive in that it will reinforce any structure occurring in the mapping between meanings and signals.</p><p>3. Invention. The learner has not observed m, s , and the learner cannot discern any structure in the observed language that will help in finding a signal for m. In this situation, an inventive production decision is required. Some random element must be used in the production of m. Alternatively, the learner can choose not to produce a signal for m at all. Either way, we assume s = s , and any existing association between m and s is broken. The case when s = s will only occur by chance.</p><p>These three mechanisms define when an association between meaning and signal will change from one generation to the next. Only some combinations of these processes can maintain a stable language. The language of one generation is transformed into the language of the next generation by using one of four combinations of production mechanisms (invention/memory, invention/generalization/memory, generalization/memory, memory). Figure <ref type="figure">3</ref> illustrates the relationship between the production mechanisms and the occurrence of divergence. Divergence is shown in Figure <ref type="figure">3c,</ref><ref type="figure">d</ref>, where invention is required. Stability can only result when invention is not used; Figure <ref type="figure">3a</ref>, b illustrates this fact.</p><p>Invention, which only occurs in the presence of a transmission bottleneck, serves an important purpose. When the language is unstructured, invention will occur more frequently. By chance, an invented signal could introduce some structure to the language of the next generation where this structure was absent in the language of the previous generation. Critically, a structured relation between meanings and signals is more likely to survive the transmission bottleneck than an unstructured relation <ref type="bibr" target="#b9">[10]</ref>. Consider some region of the mapping between meanings and signals that is structured. Not all the parts of this structured region need to be observed for the structured relation to survive the transmission bottleneck. Contrast this with an unstructured (random) region. For this region to be represented in the language of the next generation requires that all the meaning/signal pairs representing that region be observed. Structure is compressible.</p><p>It is these stochastic inventions, which introduce structure where it was previously absent, that drive the language evolution toward regions of stability. The more structure the mapping contains, the less frequently invention will occur. Rather like simulated annealing <ref type="bibr" target="#b11">[12]</ref>, iterated learning can be seen as a search strategy. Providing the language is unstructured and a transmission bottleneck is in place, the initial temperature will be high; invention will occur frequently. In time the temperature decreases, and invention will occur less frequently. The search follows a trajectory toward language that best fits the combined biases of hypothesis selection and production.</p><p>(a)</p><formula xml:id="formula_4">L 1 L 1 L 1 Memory (b) L 1 L 1 L 1 Memory Generalisation (c) L 1 Memory Generalisation Invention L L 2 3 (d) Memory Invention L 1 L L 2 3</formula><p>Figure 3. The four ways in which a language L 1 can evolve. These diagrams show how the mechanism used to produce a signal can effect a change in the language from generation to generation. Inward arrows signify the reinforcement of the language structure. Outward arrows indicate divergence from the current language structure. First, a language can only persist when one of two combinations of production mechanism is in play: (a) memory, and (b) memory and generalization. Divergence will occur when either (c) memory, generalization, and invention occur, or (d) when memory and invention occur. Invention always causes divergence.</p><p>So, iterated learning can effect a cumulative evolution toward structure. This process is the linguistic equivalent of what Tomasello <ref type="bibr" target="#b27">[28]</ref> terms the ratchet effect in cultural evolution. However, only when certain conditions are met will iterated learning reliably converge to a stable state. We aim to understand and formalize these conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The Parameter Space</head><p>Six parameter groups define the behavior of the iterated learning model. In the context of the model developed here, they are as follows:</p><p>1. The meaning space. The space of possible meanings. The meaning space is defined by the number of features, F , and the cardinality of the set from which feature values are drawn, V .</p><p>2. The signal space. Signals are constructed by drawing symbols from some alphabet . The maximum length of a signal is l max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The transmission bottleneck.</head><p>The number of random object observations, R. The value of R is related to the degree of language exposure. Some probability distribution over objects specifies how likely an object is to be observed. We assume this distribution is uniform, unless otherwise stated.</p><p>4. The perceptual bias. Utterances may not be perceived accurately. For example, the transmission channel might be noisy, or there may be limits on the working memory of an agent, thereby restricting the set of perceivable utterances <ref type="bibr" target="#b7">[8]</ref>. In the model developed here, we assume all utterances are transmitted noise free; no restrictions on perception are modeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>The learning bias. The learning bias defines the space of possible hypotheses, and which hypothesis is chosen given some data.</p><p>6. The production bias. Given a meaning and a hypothesis, the production bias defines which signal is chosen to express the meaning.</p><p>Stable language only occurs for certain parameter combinations. Recall that without a transmission bottleneck, all languages are stable. As soon as a transmission bottleneck is in place, only certain languages are stable, and these rely on certain combinations of learning and production bias. Before mapping this parameter space, we consider the role of learning and production.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Compression, Learning, and Generalization</head><p>Agents act as a conduit for language. An agent observes a subset of the language of the previous generation. The process of learning from this subset, and then producing utterances for the next generation, is a complex one. At one level an agent simply maps one language onto another. At a more detailed level, the function that defines this mapping is composed of a learning mechanism and a production mechanism. Learning, in this context, is the process of arriving at a hypothesis that explains the observed language. Production is the process that, given a hypothesis, completes the mapping from meanings to signals. The production mechanism defines how the hypothesis is interrogated to yield signals. Because the chosen hypothesis might reflect some regular structure existing in the observed language, unobserved regions of the language could be recovered by the production mechanism exploiting the structure in the hypothesis. The combination of learning and production is termed generalization. In this section we propose a candidate computational model of generalization based on the minimum description length (MDL) principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Minimum Description Length Learning</head><p>Ranking potential hypotheses by minimum description length is a principled and elegant approach to hypothesis selection <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b20">21]</ref>. The MDL principle can be derived from Bayes's rule, and in short states that the best hypothesis for some observed data is the one that minimizes the sum of (a) the encoding length of the hypothesis, and (b) the encoding length of the data, when represented in terms of the hypothesis. A tradeoff then exists between small hypotheses with a large data encoding length and large hypotheses with a small data encoding length. When the observed data contains no regularity, the best hypothesis is one that represents the data verbatim, as this minimizes the data encoding length. However, when regularity does exist in the data, a smaller hypothesis is possible that describes the regularity, making it explicit, and as result the hypothesis describes more than just the observed data. For this reason, the cost of encoding the data increases. MDL tells us the ideal trade-off between the length of the hypothesis encoding and the length of the data encoding described relative to the hypothesis. More formally, given some observed data D and a hypothesis space H the best hypothesis h MDL is defined as</p><formula xml:id="formula_5">h MDL = min h∈H {L C 1 (h) + L C 2 (D|h)} (1)</formula><p>where L C 1 (h) is the length in bits of the hypothesis h when using an optimal coding scheme over hypotheses. Similarly, L C 2 (D|h) is the length, in bits, of the encoding of the observed data using the hypothesis h. We use the MDL principle to find the most likely hypothesis for an observed set of meaning/signal pairs passed to an agent. When regularity exists in the observed language, the hypothesis will capture this regularity, when justified, and allow for generalization beyond what was observed. By employing MDL we have a theoretically solid justification for generalization. The next section will clarify the MDL principle-we introduce the hypothesis space and coding schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">The Hypothesis Space</head><p>We introduce a novel model for mapping strings of symbols to meanings, which we term a finite state unification transducer (FSUT). This model extends the scheme used by Teal and Taylor <ref type="bibr" target="#b26">[27]</ref> to include variable length signals and, more importantly, meanings. Given some observed data, the hypothesis space consists of all FSUTs that are consistent with the observed data. Both compositional and noncompositional languages can be represented using the FSUT model. A FSUT is specified by a 7-tuple (Q, , F, V , δ, q 0 , q F ) where Q is the set of states used by the transducer, and is the alphabet from which symbols are drawn. F and V define the structure of the meaning space. The transition function δ maps state/symbol pairs to a new state, along with the (possibly underspecified) meaning corresponding to that part of the transducer. Two states, q 0 and q F need to be specified; they are the initial and final state, respectively. Consider an agent A that receives a set of meaning/signal pairs during language acquisition. For example, an observed language might be the set</p><formula xml:id="formula_6">L = { {1, 2, 2}, adf , {1, 1, 1}, ace , {2, 2, 2}, bdf , {2, 1, 1}, bce , {1, 2, 1}, ade , {1, 1, 2}, acf }</formula><p>This language is compositional. It was constructed using the following dictionary:</p><formula xml:id="formula_7">Value 1 Value 2 Feature 1 a b Feature 2 c d Feature 3 e f</formula><p>So, for example, the subsignal corresponding to feature value 2 for the first feature is "b". Figure <ref type="figure">4a</ref> depicts a FSUT that models L. We term this transducer the prefix tree transducer -the observed language and only the observed language is represented by the prefix tree transducer. The power of the FSUT model only becomes apparent when we consider possible generalizations made by merging states and edges:</p><p>1. State merge. Two states q 1 and q 2 can be merged to form a new state if the transducer remains consistent. All edges that mention q 1 or q 2 now mention the new state.</p><formula xml:id="formula_8">L = { {1, 2, 2}, adf , {1, 1, 1}, ace , {2, 2, 2}, bdf , {2, 1, 1}, bce , {1, 2, 1}, ade , {1, 1, 2}, acf } (a) d/{1 2 2} a /{ 1 2 2 } f/ {1 2 2 } c/{1 1 1} a / { 1 1 1 } e / { 1 1 1 } d/{2 2 2} b /{ 2 2 2 } f/ {2 2 2 } c/{2 1 1} e /{ 2 1 1 } b /{ 2 1 1 } d/{1 2 1} a / { 1 2 1 } e / { 1 2 1 } c/{1 1 2} a /{ 1 1 2 } f/ {1 1 2 } (b) d/{1 2 2} a /{ 1 2 2 } f/ {1 2 2 } c/{1 1 1} a / { 1 1 1 } e / { 1 1 1 } d/{2 2 2} b /{ 2 2 2 } f/ {2 2 2 } c/{2 1 1} e /{ 2 1 1 } b /{ 2 1 1 } d/{1 2 1} a / { 1 2 1 } e / { 1 2 1 } c/{1 1 2} a /{ 1 1 2 } f/ {1 1 2 } (c) f/ {1 2 2 } e / { 1 1 1 } f/ {2 2 2 } a / { 1 2 1 } c/{1 1 2} a /{ 1 1 2 } d /{ 2 2 2 } b/{2 ? ?} c/{1 1 1} d/{1 2 2} a /{ 1 ? ? } e / { ? ? 1 } d /{ 1 2 1 } c /{ 2 1 1 } f/ {1 1 2 } (d) b/{2 ? ?} a /{ 1 ? ? } e / { ? ? 1 } c /{ 2 1 1 } a /{ 1 ? ? } c /{ 1 1 2 } d / { 1 2 1 } c/{1 1 1} e / { 1 1 1 } f/ { ? 2 2 } d / { 2 2 2 } d /{ 1 2 2 } f/ {1 1 2 } Figure 4.</formula><p>Given the compositional language L, the prefix tree transducer shown in (a) is constructed. By performing edge and state merge operations, outlined in (b) and (c), the transducer can be compressed. The transducer shown in (d) is compressed but does not lead to any generalizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Edge merge.</head><p>Two edges e 1 and e 2 can be merged if they share the same source and target states and accept the same symbol. The result of merging the two edges is a new edge with a new meaning label. Meanings are merged by finding the intersection of the two component meanings. Those features that do not have values in common take the value "?"-a wild card that matches all values. As fragments of the meanings may be lost, a check for transducer consistency is also required. Without this consistency check, some observed meaning/signal pairs will not be accounted for by the resulting transducer.</p><p>Figure <ref type="figure">4b</ref> and c illustrates some possible state and edge merge operations. The transducer resulting from these merge operations is shown in in Figure <ref type="figure">4d</ref>. Figure <ref type="figure">5</ref>   <ref type="figure">4</ref>, result in the compressed transducer shown here. As a result of compression, the transducer can express more meanings than those contained in L. All members of language L + can be expressed.</p><p>a fully compressed transducer, which is found by performing additional state and edge merge operations. The fully compressed transducer can express meanings that are not present in L. The language L + , shown in Figure <ref type="figure">5</ref>, contains all the meaning/signal pairs that can be expressed by the fully compressed transducer. By compressing the prefix tree transducer, the structure in the compositional language has been made explicit, and as result, generalization can occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Encoding Lengths</head><p>To apply the MDL principle we need an appropriate coding scheme for (a) the hypotheses, and (b) the data using the given hypothesis. These schemes correspond to C 1 and C 2 introduced in Equation <ref type="formula">1</ref>. The requirement for the coding scheme C 1 is that some machine can take the encoding of the hypothesis and decode it in such a way that a unique transducer results. Similarly, the coding of the data with respect to the transducer must describe the data uniquely. To encode a transducer T = (Q, , F, V , δ, q 0 , q F ) containing n states and e edges we must calculate the space required, in bits, of encoding a state (S state = log 2 (n)), a symbol (S symbol = log 2 (| |)), and a feature value (S fvalue = log 2 (V )). The number of bits required to encode a meaning relies not only on S fvalue , but also the cost of encoding the wild-card specifier. The number of bits used to encode an arbitrary meaning m = {f 1 , . . . , f F } is given by</p><formula xml:id="formula_9">S meaning (m) = F i=1 Z ( f i )</formula><p>where f i denotes the value of the ith feature, and</p><formula xml:id="formula_10">Z ( f i ) = 1 : when f i = ? 1 + S fvalue : otherwise</formula><p>That is, Z ( f i ) represents the number of bits required to encode either a feature value or the wild-card specifier. The initial bit is used to differentiate between these two possibilities. Denoting the meaning associated with the ith edge by m i , the encoding length of the transducer is then</p><formula xml:id="formula_11">S T = e i=1</formula><p>{2S state + S symbol + S meaning (m i )} + S state which corresponds to encoding the transition function δ along with the identity of the accepting state. For the transducer T to be uniquely decoded, we must also specify the lengths of constituent parts of the transducer. We term this part of the encoding the prefix block:</p><formula xml:id="formula_12">S prefix = S state + 1 + S symbol + 1 + S fvalue + 1 + S F + 1</formula><p>Where S F is the encoding length, in bits, required to define the number of features in a meaning: S F = log 2 (F ). To calculate L C 1 (h) we then use the expression:</p><formula xml:id="formula_13">L C 1 (h) = S prefix + S T<label>(2)</label></formula><p>Recall that L C 1 (h) defines the length of the encoding of the hypothesis h using the coding scheme C 1 . This quantity is termed the grammar encoding length (GEL) <ref type="bibr" target="#b26">[27]</ref>.</p><p>Similarly, the length of the encoding of the data, in terms of the hypothesis h, L C 2 (D|h), is termed the data encoding length (DEL). The DEL is far simpler to calculate than the GEL. For some string s composed of symbols w 1 w 2 . . . w |s| we need to detail the transition we choose after accepting each symbol with respect to the given transducer.</p><p>The list of choices made describes a unique path through the transducer. Additional information is required when the transducer enters an accepting state as the transducer could either accept the string or continue parsing characters, as the accepting state might contain a loop transition. Given some data D composed of p meaning/signal pairs, L C 2 (D|h) is calculated by</p><formula xml:id="formula_14">L C 2 (D|h) = p i=1 |s i | j =1 {log 2 z ij + F (s ij )} (3)</formula><p>where s i is the signal of the ith meaning/signal pair, and z ij is the number of outward transitions from the state reached after parsing j symbols of the signal of the ith meaning/signal pair. The state reached after parsing j symbols of the signal of the ith meaning/signal pair is denoted by s ij . The function F handles the extra information for accepting states:</p><formula xml:id="formula_15">F (s ij ) = 1 :</formula><p>when the transducer is in q F 0 : otherwise Prefix tree transducers are compressed by applying the merge operators described above. We use a beam search <ref type="bibr" target="#b13">[14]</ref>. The merge operators are chosen at random and applied to a random point in the transducer. The resulting transducer must be consistent with the observed data to enter the beam. Transducers with the smallest encoding lengths are most likely to remain in the beam, as new transducers, formed by applying the merge operations, replace the transducer with the largest encoding length. Smaller transducers are therefore more likely to be used in further exploration of the hypothesis space. When no operator can be applied, the search stops, and the transducer with the smallest encoding length is chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MDL, Hypothesis Selection, and Generalization</head><p>With respect to some observed data, MDL provides a ranking over candidate hypotheses. Identifying the hypothesis that yields the smallest encoding length is a practical problem that can be addressed by employing a search strategy. But the selection of the hypothesis solves only half the problem of mapping a meaning to a signal. To complete the mapping a production mechanism is required that interrogates the hypothesis. With respect to our implementation of MDL, a procedure is required that takes a FSUT and a meaning and produces a signal for that meaning. One such mechanism proceeds by performing a depth-first search for a path through the FSUT such that no transition is taken that has a meaning label that is inconsistent with the target meaning. Providing the set of transitions result in the correct meaning being parsed, and the final transition leads to the accepting state, the resulting signal is formed by concatenating the symbols found on each transition. Using this procedure, generalization can occur. This model of generalization was used in an agent-based simulation reported by Brighton and Kirby <ref type="bibr" target="#b2">[3]</ref>.</p><p>Here, we only consider two FSUT structures: prefix tree machines and compressed machines. These machines correspond to the hypotheses chosen when the observed language is either holistic or compositional, respectively. The FSUT model defines a space of hypotheses. The application of the MDL principle over this space of hypotheses, in conjunction with the iterated learning model, can account for the evolution of all gradations of language type: from holistic language to fully compositional language, and mixtures of both structures. In the model developed here, we simplify the issue and only consider stability conditions for holistic and fully compositional language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Optimal Generalization</head><p>Assume an agent knows, before observing any utterances, that the observed language will have compositional structure. Recall that a compositional language is totally defined by the dictionary used to construct it. Given the expectation of a compositional language, what degree of exposure to the language is required before the dictionary can be derived? The earliest point at which the dictionary could be constructed is when all feature values have been observed. Disregarding the details of the procedure for reconstructing the dictionary, this is the minimum degree of exposure before reconstruction is possible at all. We term the ability to express all the meanings for which all the feature values have been observed the optimal generalization bias.</p><p>In this section we aim to formalize the notion of the optimal generalization bias. We show that this degree of bias is paralleled in the MDL model of generalization discussed above. In short, we aim to show that given a compositional language, in all but a few circumstances, the compressed transducer outlined in the previous section will have the smallest encoding length. Relating the optimal generalization bias to the MDL model allows us to model language stability without the need to perform lengthy agent-based simulations.</p><p>The strongest possible generalization bias is one that results in some fixed compositional language L C being expressed, whatever the input. But any such scheme would be inconsistent with all observed languages other than L C . We consider only hypotheses that are consistent with the observed data. Compositional languages, for our purposes, are those where the feature values appearing in the meaning are associated with unique subsignals. A dictionary relating every feature value to a subsignal totally defines the compositional language. This is a slight simplification of the problem as the dictionary does not define the order in which subsignals are assembled. We assume the ordering of the feature values in the meaning is reflected in the construction of the signal. To express a meaning, the subsignal corresponding to each feature value in the meaning is located in the dictionary. The signal is formed by concatenating these subsignals. Now, if not enough evidence to build the whole dictionary is observed, expressivity will be suboptimal. Some objects that need to be expressed will be represented by meanings that contain unobserved feature values: The entry in the dictionary will be missing. The optimal generalization bias is the ability to express all meanings that are built from observed feature values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1 (Optimal generalization):</head><p>Given a compositional language L C , and a learner with the optimal generalization bias, a meaning m ∈ L C :</p><formula xml:id="formula_16">m = (v 1 , v 2 , . . . , v F )</formula><p>can be expressed providing each value v i has been observed at least once. Given that some v i has been observed, the optimal generalization bias makes the assumption that the subsignal corresponding to v i can always be deduced.</p><p>The optimal generalization bias serves as an upper bound on the degree of inductive bias over compositional language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MDL and the Optimal Generalization Bias</head><p>Imagine that the dictionary used to construct a compositional language can also act as a hypothesis for that language. Under which circumstances will the MDL hypothesis selection result in such in hypothesis? The compressed FSUT illustrated in Figure <ref type="figure">5</ref> corresponds to the notion of a dictionary. Each feature used to construct the meaning space is represented as a separate region in the transducer. Within these regions, each feature value is also represented. Meanings constructed from all combinations of the feature values are expressible given such a transducer structure. Figure <ref type="figure" target="#fig_0">6</ref> depicts the general structure of a compressed transducer.</p><p>For a compositional language, under what circumstances will MDL choose a compressed transducer? We show that given certain assumptions about the distribution of meanings, compressed machines are always chosen by MDL, given a compositional language as input. Bear in mind this is a statement concerning the ranking of hypotheses with respect to the the FSUT model and the MDL principle. How one performs the search through the space of hypotheses to verify this fact is a practical issue. We assume an exhaustive search. Our claim is that applying the MDL principle over the space of FSUTs results in a hypothesis equivalent to that characterized by the optimal generalization bias. To demonstrate this fact, first we present an analytic argument, then we illustrate the argument using data extracted from a simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">The Relationship Between DEL and GEL</head><p>The compressed machine yields the smallest grammar encoding length possible. Smaller machines do exist, but they will not be consistent with the observed data. We therefore rule them out. If hypotheses were selected solely on the basis of their size, then compressed machines would always be chosen for compositional language, and our analytic demonstration would be complete. This policy is known as Occam's razor (see, for example, <ref type="bibr" target="#b13">[14]</ref>). However, as we are using the MDL principle, we must also consider the size of the data represented in terms of the hypothesis. The following analysis demonstrates that under two assumptions, a uniform distribution over meanings and the presence of a transmission bottleneck, the impact of the data encoding length is negligible. As a result MDL hypothesis selection can be simplified to the policy of Occam's razor: Always pick the smallest hypothesis. The hypothesis chosen by MDL will only differ from that picked using Occam's razor when nonuniform statistical effects are present in the data.</p><p>A series of meaning/signal pairs are presented to an agent. This series can be represented as a set of p distinct meaning/signal pairs. The number of times some arbitrary meaning/signal pair i is observed is denoted as K (i). It is useful to specify the size, or severity, of the transmission bottleneck in terms of the expected number of distinct objects observed, rather than the number of object observations. The expected object coverage, denoted as c, after R random observations of N objects is defined as</p><formula xml:id="formula_17">c = log 2 (1 -R) log 2 (1 -1 N ) (4)</formula><p>The value of c represents the proportion of the objects that we expect to observe. For a compositional language, we know that p ≤ V F as V F is the maximum number of unique meaning/signal pairs. Consider using a prefix tree transducer to encode this language: It will require log 2 (p) bits to encode a single meaning/signal pair, because, in a prefix tree transducer, each meaning/signal pair is represented by a unique nonbranching path through the transducer. In total, for some compositional language L,</p><formula xml:id="formula_18">DEL prefix (L) = p i=1 {K (i) • log 2 (p)}</formula><p>bits are required to encode all the meaning/signal pairs in L. Now consider how many bits are required to encode a single meaning/signal pair, given that a compressed transducer is used. Assuming all the feature values have been observed, this will be log 2 (V F ) We arrive at this expression as follows. Each feature in the meaning is represented by a different section of the transducer. A path through one of these sections can take one of V possible routes. Specifying a single feature value therefore requires log 2 (V ) bits. As there are F features, to encode a whole meaning/signal pair requires</p><formula xml:id="formula_19">F • log 2 (V ) = log 2 (V F )</formula><p>bits. In total a compressed machine, given a compositional language L, will require</p><formula xml:id="formula_20">DEL comp (L) = p i=1 {K (i) • log 2 (V F )}</formula><p>bits to encode the p meaning/signal pairs. The difference between DEL comp (L) and DEL prefix (L) is important. Only when this difference is greater than the size difference between the grammar encoding lengths will prefix tree machines be chosen. More formally, the encoding length of a prefix tree transducer, EL prefix , is defined as:</p><formula xml:id="formula_21">EL prefix (L) = GEL prefix (L) + DEL prefix (L)</formula><p>and similarly for a compressed transducer</p><formula xml:id="formula_22">EL comp (L) = GEL comp (L) + DEL comp (L)</formula><p>Now, only when EL prefix (L) &lt; EL comp (L) <ref type="bibr" target="#b4">(5)</ref> will prefix tree transducers be selected over a compressed transducer, given a compositional language as input. This situation requires that the difference in the grammar encoding lengths is less than the difference in the data encoding lengths. This situation is discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">A Nonuniform Distribution Over Meanings</head><p>The difference between DEL prefix (L) and DEL comp (L) is usually much smaller than the difference between GEL prefix (L) and GEL comp (L). This is because transducer compression results in the removal of many transducer states, but the degree to which this loss of states increases the cost of encoding the data is usually small. The upshot of this disparity is that, given a compositional language, for a prefix tree transducer to be preferred over a compressed transducer, the number of occurrences of each meaning/signal pair, K (i), for 1 ≤ i ≤ p, must be large. Assuming a uniform distribution over meanings, this situation will not occur unless each meaning/signal pair is observed many times. For this to happen c ≈ 1.0, that is, the whole language is observed. This situation is not modeled here-we assume there is a transmission bottleneck. In terms of MDL, the justification for this relationship rests on the assumption that the more evidence we have for a set of observations, the less likely novel observations are to occur.</p><p>Figure <ref type="figure" target="#fig_2">7</ref> illustrates how, for a compositional language, hypothesis selection depends on the probability distribution over meanings (and hence objects). First, given a transmission bottleneck (c &lt; 1.0) and a uniform distribution over meanings, compressed machines are always chosen as EL prefix -EL comp &gt; 0 holds irrespective of coverage. Contrast this with a situation where we fix K (i) = 100 for 1 ≤ i ≤ p, also shown in Figure <ref type="figure" target="#fig_2">7</ref>. For low coverage values, the inequality EL prefix -EL comp &gt; 0 no longer holds-prefix tree transducers are preferred for low coverage values. In practice, given a uniform distribution over meanings, this situation cannot occur unless c ≈ 1.0.</p><p>However, if we consider a distribution such as that resulting from Zipf's law, then this situation can occur when c &lt; 1.0. A Zipfian distribution, in this context, would mean that the frequencies of meanings decay as a power function of their rank <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">30]</ref>. In this case, as c increases, K (i), for some values of i, will become huge. In this situation,  . When EL prefix -EL comp &lt; 0, prefix transducers are chosen by MDL for compositional language. With a uniform distribution and a transmission bottleneck, this does not occur. Only when, for example, we fix K(i) = 100 will prefix tree transducers be chosen over compressed machines.</p><p>the rule that compressed transducers are always selected for compositional language no longer holds. By introducing strong statistical effects into the data, hypothesis selection by MDL begins to diverge from that of Occam's razor. The occurrence of communicatively relevant situations are unlikely to conform to a uniform distribution <ref type="bibr" target="#b3">[4]</ref>.</p><p>The assumption of a uniform distribution made in the model analysis therefore restricts the structure of languages we consider. The introduction of a nonuniform distribution would be an important extension to the model: We are currently investigating Zipfian distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Summary</head><p>Short of knowing the language in advance, the optimal generalization bias describes the least amount of evidence required before generalization can occur. We have demonstrated that, assuming a uniform distribution over meanings, compressed transducers are preferable to prefix tree transducers for all compositional languages. As compressed transducers are a model of optimal generalization, we reduce the problem of generalization over compositional language to that of optimal generalization. In the next section, a mathematical model is developed that relates the stability advantage conferred by compositional language to the parameters of the iterated learning model. The model relies on the notion of the optimal generalization bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Modeling the Conditions for Stability</head><p>Understanding the conditions for stability requires an analysis of the interaction between generalization bias, the transmission bottleneck, and the structure of the meaning space.</p><p>The following analysis employs a mathematical model, based on the agent-based simulation reported by Brighton and Kirby <ref type="bibr" target="#b2">[3]</ref>. Modeling by simulation has disadvantages when the parameter space is large. Parts of the parameter space that were intractable to map using the Monte Carlo simulations outlined in previous work are no longer intractable. Mathematical models of cultural evolution have been proposed before <ref type="bibr" target="#b1">[2]</ref>, but mathematical models of language evolution typically focus on arguments appealing to natural selection <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>The model developed here estimates the stability advantage offered by compositional language. By varying the severity of the transmission bottleneck and the degree of structure in the meaning space, the conditions for which compositional language offers the greatest stability advantage can be established. We conjecture that it is precisely these regions of the parameter space from which compositional language is most likely to emerge. In contrasting one language structure with another, we are pitting one type of hypothesis, prefix tree transducers in the case of holistic language, against another, compressed transducers in the case of compositional language. The model estimates the likelihood of a language type emerging on the basis of the expressivity of the corresponding hypothesis. For a given language type, the appropriate hypothesis structure was found using the MDL principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Expressivity of a Prefix Tree Transducer</head><p>Using a prefix tree transducer, only meanings that have been observed in conjunction with a signal can be expressed. Given a holistic language, a prefix tree transducer is the best we can do: There is no principled way of expressing a novel meaning on the basis of previously observed meanings. To calculate the expected expressivity of an agent using a prefix tree transducer we need to calculate the probability of observing some arbitrary meaning m drawn from the meaning space. For a meaning m to be observed by an agent it must first be used to label an object, as there is no guarantee that m will be used at all (recall Figure <ref type="figure">1</ref>). Second, the object(s) labeled with m need to be observed at least once by the agent. The likelihood of observing a meaning/signal pair (representing an object) depends on the severity of the transmission bottleneck.</p><p>After observing a series of objects, each of which is represented by a meaning, the agent will have accumulated a set of observed meanings. We denote this set as O. The probability of observing some arbitrary meaning m, that is, Pr(m ∈ O), is determined by the number of objects in the environment (N ), the number of meanings in the meaning space (M , where M = V F ), and the number of random object observations during an agent's lifetime (R). The probability of observing the meaning m is defined as</p><formula xml:id="formula_23">Pr(m ∈ O) = N x=0 x N • R r =1 N -x N r -1 • (M -1) N -x M N • N x<label>(6)</label></formula><p>This expression takes into account that first m must be used to label an object, and second, that after R observations of the objects, m is observed at least once. The Appendix provides an explanation for Equation <ref type="formula" target="#formula_23">6</ref>. To estimate the number of distinct meanings observed, and therefore the number of distinct meanings that can be expressed, we simply multiply this probability by the number of possible meanings, V F . The expressivity of an agent using a prefix tree transducer as a hypothesis is denoted as E prefix :</p><formula xml:id="formula_24">E prefix = Pr(m ∈ O) • V F (7)</formula><p>To summarize, we first calculate the probability of the meaning being used to label an object and that object being observed. This probability, multiplied by the number of possible meanings, yields the expected number of meanings observed by an agent. As no generalization can occur, the expressivity of the agent using a prefix tree transducer is equivalent to the number of meanings observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The Expressivity of a Compressed Transducer</head><p>Given a compositional language the compressed transducer structure maximizes the expressivity of an agent: Expressivity becomes a function of the number of feature values observed, rather than a function of the number of meanings observed. Recall that given the optimal generalization bias, to express a meaning m requires that all the feature values in m have been observed. The rate at which feature values are observed is at least the rate at which whole meanings are observed. As a result, the expressivity achieved by a compressed transducer is always at least the degree of expressivity achieved when using a prefix tree transducer.</p><p>To estimate the expressivity of an agent using optimal generalization we need to calculate the probability of observing some arbitrary feature value. Recall that this probability will be greater than the probability of observing some arbitrary meaning, because fewer entities need to be seen, given the same number of observations. More formally, for some arbitrary feature f i (1 ≤ i ≤ F ), f i can take on a value drawn from the set of possible values {1, 2, . . . , V }. We require the probability that some arbitrary feature value drawn from this set is observed after R object observations. As before, this is a two-stage process. First, we must take into account that the arbitrary feature value must be used in at least one of the meanings chosen to label the objects. The feature value may be used once or more, or not at all. Given that for some arbitrary feature there are V possible values, N objects are labeled, and R random samples of these objects are taken, we can use an expression similar to Equation <ref type="formula" target="#formula_23">6</ref>to estimate the probability of observing some arbitrary feature value v one or more times. After R observations, for the arbitrary feature f i , the set O f i of feature values is observed. We denote the probability of observing an arbitrary feature value as Pr(v ∈ O f i ) and define it as</p><formula xml:id="formula_25">Pr(v ∈ O f i ) = N x=0 x N • R r =1 N -x N r -1 • (V -1) N -x V N • N x (8)</formula><p>Now, for some meaning m = (v 1 , v 2 , . . . , v F ) the ability to express m requires that each feature value v i has been observed. We can therefore express the probability of expressing m as the combined probability of expressing each of the feature values of m. We denote this probability as Pr(</p><formula xml:id="formula_26">v 1 ∈ O f i ∧ • • • ∧ v F ∈ O f i ) and define it as Pr(v 1 ∈ O f i ∧ • • • ∧ v F ∈ O f i ) = Pr(v ∈ O v i ) F (9)</formula><p>This is the probability of being able to express some arbitrary meaning m. Contrast this probability with that represented in Equation <ref type="formula" target="#formula_23">6</ref>. For some meaning m, Equation 9 tells us the probability of being able to express m. Equation 6 tells us the probability of observing an arbitrary m. This is an important distinction, as to estimate the expressivity of an agent using a compressed transducer we need to multiply the probability of expressing a meaning m with the expected number of expressible meanings. The expected number of distinct meanings used when labeling N objects is</p><formula xml:id="formula_27">N used = 1 -1 - 1 V F N • V F (10)</formula><p>To find the expected number of objects for which a signal can be derived we then multiply the probability of expressing a meaning by the number of expressible meanings:</p><formula xml:id="formula_28">E generalization = Pr(v ∈ O f i ) F • N used<label>(11)</label></formula><p>Compressed transducers are derived from prefix tree transducers by means of state and edge merging operations. Compression can only increase expressivity because consistency with the observed data is always maintained. The minimum expressivity for a compressed transducer is therefore E prefix . We can now define the expressivity of a compressed transducer as</p><formula xml:id="formula_29">E compressed = max{E generalization , E prefix }<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Language Stability</head><p>The above analysis relates transducer structure to expressivity. Given a compositional language, hypothesis selection using the MDL principle results in a compressed transducer. The expressivity in this case is defined by the expression for E compressed . A holistic language results in a prefix tree transducer being chosen. The expressivity in this case is defined by E prefix .</p><p>Next, we relate expressivity to stability. In the ILM, language stability is the degree to which the hypotheses induced by subsequent agents maintain the mapping between meanings and signals. The entire set of associations between meanings and signals may not be externalized as utterances. They may exist by virtue of the hypothesis alone. The stability of a language is therefore related to the proportion of the objects that can be expressed without resorting to invention. Invention either introduces or maintains unstructured areas of the mapping between meanings and signals. Stability is therefore related to expressivity. The notion of stability used here corresponds to the probability of a language being transmitted from one generation to the next without change. The stability value of a language is the proportion of the objects that can be expressed through generalization. We can now characterize the degree of stability for a language type. The degree of stability of a compositional language, S compositional , and of a holistic language S holistic can be defined as</p><formula xml:id="formula_30">S compositional ∝ E compressed N (<label>13</label></formula><formula xml:id="formula_31">)</formula><formula xml:id="formula_32">S holistic ∝ E prefix N (<label>14</label></formula><formula xml:id="formula_33">)</formula><p>An important measure we employ is that of relative stability. We denote relative stability as S and define it as</p><formula xml:id="formula_34">S = S compositional S compositional + S holistic (<label>15</label></formula><formula xml:id="formula_35">)</formula><p>For a coverage value and a meaning space structure (defined by c, F , and V , respectively), the S value tells us the degree to which compositional language is more stable than holistic language. S reflects how much larger S compositional is than S holistic , (0.0 ≤ S ≤ 1). When S &gt; 0.5 compositional language is more stable than holistic language. The case when S &lt; 0.5, which does not occur in these experiments, corresponds to the situation when holistic language is more stable than compositional language. There is no stability advantage to either language type when S = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Model Analysis</head><p>The key measurement used in the model is the relative stability, S , of compositional language over holistic language. The value of S is dependent on four variables:</p><p>1. The number of features used to construct the meaning space, F .</p><p>2. The number of values used by each feature in the meaning space, V .</p><p>3. The bottleneck size, represented as the expected object coverage, c (see Equation <ref type="formula">4</ref>).</p><p>4. The number of objects in the environment, N .</p><p>The value of S indicates more than just the relative stability of compositional language over holistic language; S also reflects the likelihood of compositional language emerging. When, as a result of invention, compositional structure is introduced, the relative stability of compositional language tells us how likely this compositional structure is to persist (recall Section 2.3.1). Figures <ref type="figure" target="#fig_3">8</ref> and<ref type="figure" target="#fig_4">9</ref> show the relationship, for different degrees of coverage, between S and the structure of the meaning space. The parameter N is not of any real consequence, as changing it will just shift the landscape away from the origin: Larger meaning spaces are required to represent more objects. In contrast, the model reveals that several important relationships exist between F , V , c, and S : 1. S is at a maximum for small bottleneck sizes. In Figure <ref type="figure" target="#fig_3">8a</ref> S nears the maximum value of 1 for certain meaning space structures. This result demonstrates that compositional language can still be learned even though exposure is limited. In contrast, holistic language will not persist over generations when only a small subset is observed. This result is important, as it demonstrates that the poverty of the stimulus is an important determinant of compositional language.</p><p>2. High S values only occur once a certain degree complexity in the meaning space has been reached. This means that the conceptual space of the agent must be broken up into multiple features and values for compositionality to become an option. For meaning spaces with only a few features, S cannot reach a high value.</p><p>In short, there must be a certain degree of feature structure before compositional language can become advantageous.</p><p>3. Most clearly illustrated in Figure <ref type="figure" target="#fig_3">8a</ref>, the largest meaning spaces, those that contain more than approximately 2 million meanings, lead to small values of S. In all the examples (Figures <ref type="figure" target="#fig_3">8</ref> and<ref type="figure" target="#fig_4">9</ref>), a very high degree of structure leads to low S values. Beyond a certain point, the more highly structured the meaning space, the less likely different meanings are to share feature values. Consider the most extreme case where each object will be labeled with a meaning containing feature values not present in labeling of any other object.</p><p>4. When labeling N objects there is a trade-off between the number of features used and the number of values per feature used. The more features used, the fewer the number of feature values required to represent N objects. When a meaning is observed, F feature values are observed. This means that all feature values will be observed sooner if the N objects are conceptualized more in terms of features than feature values. This is a relationship most strikingly illustrated by the surface shown in Figure <ref type="figure" target="#fig_3">8a</ref>. Here, compositional language is far more stable when many features are used. Before relating these results to language and its evolution, it is worth considering the interactions between F , V , c, and S in more detail.</p><p>Figure <ref type="figure" target="#fig_3">8a</ref> would indicate that a meaning space M 1 with F = 10 and V = 2 results in higher relative stability than a meaning space M 2 with F = 2 and V = 10. Why is the number of features so important? First, there is an order of magnitude more meanings in M 2 that in M 1 . From looking at the surfaces shown in Figures <ref type="figure" target="#fig_3">8</ref> and<ref type="figure" target="#fig_4">9</ref>, it is not easy to discern the size difference between the meaning spaces. The number of meanings found in M 1 fits the other parameters well for high S ; the number of meanings found in M 2 , on the other hand, is large enough that the likelihood of objects sharing feature values is relatively low.</p><p>Recall that F feature values are observed when a single object is observed. As more objects are observed, the likelihood of full feature value coverage increases rapidly in comparison to the degree of object coverage. This discrepancy in feature value coverage and object coverage is greatest for small c (bottleneck) values. This is why compositional language is relatively more stable in comparison to holistic language in this region of the parameter space. Expressivity is a function of object coverage for holistic language. Expressivity is a function of feature value coverage for compositional language. Figure <ref type="figure" target="#fig_5">10</ref> illustrates this relationship: The expressivity achieved, represented as a proportion of the objects, reaches a maximum for much lower coverage values when a compressed transducer is chosen.</p><p>As the degree of object coverage increases the set of meaning spaces for which S &gt; 0.5 increases. The higher the coverage the greater the number of objects observed. This relationship allows larger meaning spaces to be used, as enough observations are occurring such that previously rare co-occurrences of feature values now become more likely. . The rate at which expressivity increases as a function of object coverage. For compressed transducers the increase in expressivity is much faster than that found with prefix tree transducers. The proportion of the objects which can be expressed, P, is plotted against the degree of coverage of the object space, c. Compressed transducers quickly reach high expressivity. Prefix tree transducers can only express those objects they have observed, hence the linear relationship between c and E. The value of E is shown for two different meaning spaces (F = 3, V = 4 and F = 6, V = 4). The more features used, the fewer the number of observations required before all feature values are observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Summary</head><p>By pairing compositional language with the compressed transducer structure, and holistic language with the prefix tree transducer structure, language stability can be reduced to the issue of transducer expressivity. The model does exactly this. The relative stability measure reflects the degree of stability advantage conferred by compositional language. Using the model, the parameter combinations that yield high S were found to occupy the part of the parameter space characterized by a combination of low object coverage and high, but not outrageously high, meaning space complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>How much of the characteristic structure of language is explicitly coded in the LAD? If we neglect the pressures of language evolution on the cultural substrate, and take seriously the claim of the poverty of the stimulus, the LAD must explicitly code much of language structure. Rather than neglecting the role of language evolution on the cultural substrate, we treat it as the fundamental determinant of language evolution. Our hypothesis is that compositional structure is a function of the dynamics of cultural evolution.</p><p>In the model presented here, agents have the innate ability to produce compositional language. One could criticize this model, and other models of the cultural evolution of language, on the grounds that compositional structure is built in: The emergence of structure is not surprising. Any evolutionary model operates within a space of possible solutions: a space of genomes in the case of genetic evolution, and a space of languages in the case presented here. The possibility of a design does not imply its occurrence.</p><p>What makes the case of language evolution so problematic is the interaction between the two evolutionary substrates. When examining this interaction, any explanation for language structure must appeal, to some degree, to a genetic component. It is far from clear how much of the structure of language is specified innately: The "argument from the poverty of the stimulus" is a prima facie explanation for linguistic nativism <ref type="bibr" target="#b18">[19]</ref>. Consider the other extreme, where we entertain the possibility that the innate basis for language is not entirely language specific. For example, a bias toward the compression of representations is clearly not language specific. A domain-specific evolutionary argument is not required to account for all uses of learning. In short, the work presented here should be seen as exploring the possibility of a weak form of linguistic nativism: The interaction between any innate basis for language and a general ability to learn is complex, and certainly not well understood.</p><p>We argue that compositional structure is an emergent property of iterated observational learning. Several parameters control the behavior of the iterated learning model. Importantly, the role of learning has been framed as a search for the hypothesis with the smallest encoding length, according to the MDL principle. This approach to learning is motivated by the need for organisms to compress observed data <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref>, specifically, linguistic data <ref type="bibr" target="#b28">[29]</ref>. Using a mathematical model of language stability, in conjunction with the view of learning as compression, we have mapped a large part of the parameter space of the iterated learning model.</p><p>The most important parameter is the severity of the transmission bottleneck, denoted by c in the model. This parameter controls the degree of exposure an agent has to the language of the previous generation. Without a transmission bottleneck-when c approaches the maximum value of 1-all languages are equally stable. Introducing a bottleneck, by decreasing the value of c, leads to the set of stable languages being restricted to contain only those that are learnable from limited exposure. These are compositional languages. We draw a parallel between the presence of a transmission bottleneck and the situation of the poverty of the stimulus. The poverty of the stimulus, when we take into account iterated observational learning, results in compositional language structure constituting a steady state.</p><p>The structure of the meaning space, defined by F and V , is another determinant of compositional structure in our model. There is a trade-off. Low structural complexity in the meaning space means that compositionality offers little advantage over holistic language. This occurs when few feature values are used, and objects are discriminated primarily in terms of feature values. With low structural complexity, the components (feature values) of the meanings co-occur too infrequently. The biological evolution of semantic complexity, which is assumed in our model, has been proposed by Schoenemann <ref type="bibr" target="#b22">[23]</ref> as a necessary determinant in the emergence of syntax. The model supports this conclusion. Furthermore, we found that too much complexity in the meaning space is counterproductive. There is a limit to the stability payoff gained from increased structural complexity, as the feature values used in constructing the meanings will co-occur too infrequently for generalization to function.</p><p>The findings presented here strengthen the compelling argument that iterated learning, the process of information transmission via observational learning, is a candidate explanatory mechanism for the emergence of syntactic structure. We have taken the foundational work of Kirby <ref type="bibr" target="#b9">[10]</ref> and Batali <ref type="bibr" target="#b0">[1]</ref>, which establishes the ability to evolve structured language, and have built on this work by identifying the key requisite conditions. We focused on the transmission bottleneck, the most salient model parameter, and drew a parallel with the the poverty of the stimulus. The poverty of the stimulus is traditionally characterized as a problem, overcome by innately specified compositional syntax, but we argue it is in fact a fundamental determinant of the emergence of compositional syntax on a cultural substrate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The general structure of a compressed transducer. Each feature is represented by a section of the transducer. Within a section, individual feature values are represented by a unique path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7</head><label>7</label><figDesc>Figure 7. When EL prefix -EL comp &lt; 0, prefix transducers are chosen by MDL for compositional language. With a uniform distribution and a transmission bottleneck, this does not occur. Only when, for example, we fix K(i) = 100 will prefix tree transducers be chosen over compressed machines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. The relationship between meaning space structure, low coverage, and relative stability. In these examples, the number of objects, N, is 40. The two surfaces demonstrate the relation between meaning space structure and S for low coverage values: (a) c = 0.1, (b) c = 0.2. The highest S values (S ≈ 1.0) occur for low coverage (c ≈ 0.1) and medium complexity, illustrated in (a). The number of features plays a more significant role than the number of values per feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. The relationship between meaning space structure, mid and high coverage, and relative stability. Each surface demonstrates the relation between meaning space structure and S for mid and high coverage values: (a) c = 0.5, and (b) c = 0.9. The maximum S value decreases rapidly when coverage is increased. The size of the region in which S &gt; 0.5 grows as the coverage increases. This indicates that for smaller values of S, more meaning space structures lead to an advantage for compositionality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10</head><label>10</label><figDesc>Figure 10. The rate at which expressivity increases as a function of object coverage. For compressed transducers the increase in expressivity is much faster than that found with prefix tree transducers. The proportion of the objects which can be expressed, P, is plotted against the degree of coverage of the object space, c. Compressed transducers quickly reach high expressivity. Prefix tree transducers can only express those objects they have observed, hence the linear relationship between c and E. The value of E is shown for two different meaning spaces (F = 3, V = 4 and F = 6, V = 4). The more features used, the fewer the number of observations required before all feature values are observed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure2. The first three generations of the iterated learning model. The first agent in the chain, A 1 , is presented with example utterances (meaning/signal pairs) from some holistic language. A hypothesis H 1 is then chosen to account for this linguistic evidence. A 1 is given a set of meanings M 1 that correspond to objects drawn randomly from the set of objects. For each of these meanings, an appropriate signal is deduced and uttered by A 1 . A 2 observes these utterances and forms a hypothesis H 2 to explain the set of meaning/signal pairs. The process is repeated: A 2 utters a signal for each of those meanings in M 2 for agent A 3 to observe. A hypothesis corresponds to an agent's linguistic knowledge. Utterances (meaning/signal pairs) represent the agents' linguistic performance.</figDesc><table><row><cell>Meanings</cell><cell cols="2">Random</cell><cell cols="2">Language Change</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">M 1</cell><cell cols="2">M 2</cell><cell cols="2">M 3</cell></row><row><cell>Signals</cell><cell></cell><cell cols="2">produce observe</cell><cell cols="2">produce observe</cell><cell>produce</cell></row><row><cell>observe</cell><cell>H</cell><cell>1</cell><cell>H</cell><cell>2</cell><cell>H</cell><cell>3</cell></row><row><cell></cell><cell cols="2">A 1</cell><cell cols="2">A 2</cell><cell cols="2">A 3</cell></row><row><cell></cell><cell cols="2">Generation 1</cell><cell cols="2">Generation 2</cell><cell cols="2">Generation 3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>depicts L = { {1, 2, 2}, adf , {1, 1, 1}, ace , {2, 2, 2}, bdf , {2, 1, 1}, bce , {1, 2, 1}, ade , {1, 1, 2}, acf } Figure 5. Given the compositional language L a series of state and edge merge operations, beginning with those shown in Figure</figDesc><table><row><cell>a/{1 ? ?}</cell><cell>c/{? 1 ?}</cell><cell>e/{? ? 1}</cell></row><row><cell>b/{2 ? ?}</cell><cell>d/{? 2 ?}</cell><cell>f/{? ? 2}</cell></row><row><cell cols="3">L + = { {1, 2, 2}, adf , {1, 1, 1}, ace , {2, 2, 2}, bdf ,</cell></row><row><cell cols="3">{2, 1, 1}, bce , {1, 2, 1}, ade , {1, 1, 2}, acf ,</cell></row><row><cell cols="2">{2, 1, 2}, bcf , {2, 2, 1}, bde }</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Artificial Life Volume 8, Number 1</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Artificial Life Volume 8, Number 1</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author would like to thank Simon Kirby, T. Mark Ellison, Caroline Round, Kenny Smith, and all the members of the LEC research unit. The input provided by the anonymous reviewers is greatly appreciated.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Objects, Meanings, Feature Values, and the Transmission Bottleneck</head><p>Part of the model developed in Section 5 requires a calculation that estimates the likelihood of observing an entity. The calculation appears in two guises: first, where the entities are meanings, and second, where entities are feature values. We gloss the problem in terms of the first interpretation:</p><p>Given N objects and M meanings, a random meaning is assigned to each object. After R random object observations, what is the probability of observing some arbitrary meaning?</p><p>Abstracting from the details of the model, the problem can be generalized as follows:</p><p>Given N balls and M colors, first, all the balls are assigned a color. For each ball, a color is chosen at random, with every color being equi-probable. Second, balls are sampled at random with replacement, R times. The question is then, for some particular N , M , and R, what is the probability of observing some arbitrary color at least once?</p><p>First, given M colors, we assign a random color to each of the N balls. What is the probability that a single ball is colored A?</p><p>The probability that the ball is not colored A is then</p><p>We denote the event that p balls are colored A as X (p), where A is an arbitrary color. Now, after allocating colors to all N balls we can say</p><p>Now we consider sampling R balls at random, with replacement. First, we observe that Pr(1st ball sampled has color</p><p>Let the event that the nth ball sampled has color C , given that x balls are colored C , be denoted by the term color(n) = C . To simplify matters, we also write color(n 1 , n 2 , . . .) = C to denote the event that each of n 1 , n 2 , . . . balls sampled are colored C . We are interested in the event that at least one ball sampled has color C and denote this event as O. We can represent Pr(O|X (x)) as follows:</p><p>More formally, in terms of x, N , and R,</p><p>We can express Pr(O) in the following manner:</p><p>And then, using Equation <ref type="formula">16</ref>, we can express Pr(O) as follows:</p><p>To summarize, given N balls, and for some arbitrary color A, the probability of observing at least one ball colored A after R observations is given by Equation <ref type="formula">17</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The negotiation and acquisition of recursive communication systems as a result of competition among exemplars</title>
		<author>
			<persName><forename type="first">J</forename><surname>Batali</surname></persName>
		</author>
		<editor>E. Briscoe</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note>Linguistic evolution through language acquisition: Formal and computational models</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Culture and the evolutionary process</title>
		<author>
			<persName><forename type="first">R</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richerson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>University of Chicago Press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The survival of the smallest: Stability conditions for the cultural evolution of compositional language</title>
		<author>
			<persName><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in artificial life</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kelemen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Sosík</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1704</biblScope>
			<biblScope unit="page" from="592" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Made to measure</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bullock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ecological rationality in structured environments. Minds and Machines</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="497" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
		<title level="m">Reflections on language</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Temple Smith</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
		<title level="m">Rules and representations</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Basil Blackwell</publisher>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coevolution of neocortical size, group size and language in humans</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I M</forename><surname>Dunbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="681" to="735" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Function, selection and innateness: The emergence of language universals</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Syntax without natural selection: How compositionality emerges from vocabulary in a population of learners</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The evolutionary emergence of language: Social function and the origins of linguistic form</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Knight</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Studdert-Kennedy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hurford</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="303" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Linguistic evolution through language acquisition: Formal and computational models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
		<editor>E. Briscoe</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note>Learning, bottlenecks and the evolution of recursive syntax</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spontaneous evolution of linguistic structure: An iterated learning model of the emergence of regularity and irregularity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An introduction to Kolmogorov complexity and its applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vitányi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<title level="m">Machine learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Formal philosophy: Selected papers of Richard Montague</title>
		<author>
			<persName><forename type="first">R</forename><surname>Montague</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974">1974</date>
			<publisher>Yale University Press</publisher>
			<pubPlace>New Haven, CT</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evolution of universal grammar</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Komarova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page" from="114" to="118" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The evolution of syntactic communication</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Plotkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A A</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">404</biblScope>
			<biblScope unit="page" from="495" to="498" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Natural language and natural selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="707" to="784" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Pullum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Scholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical assessment of stimulus poverty arguments</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Analysis of the language of ants by information-theoretical methods. Problems of Information Transmission</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">I</forename><surname>Reznikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Ryabko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="245" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling by shortest data description</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="465" to="471" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using Shannon entropy and Kolmogorov complexity to study the communicative system and cognitive capacities in ants</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ryabko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Reznikova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complexity</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="37" to="42" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Syntax as an emergent property of the evolution of semantic complexity</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Schoenemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Minds and Machines</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="309" to="346" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Establishing communication systems without explicit meaning transmission</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in artificial life</title>
		<title level="s">Lecture notes in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kelemen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Sosík</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1704</biblScope>
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Constructing and sharing perceptual distinctions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Van Someren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">G</forename><surname>Widmer</surname></persName>
		</editor>
		<meeting>the European Conference on Machine Learning<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The origins of syntax in visually grounded robotic agents</title>
		<author>
			<persName><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="133" to="156" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effects of acquisition on language evolution</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Teal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="129" to="143" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The cultural origins of human cognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Language acquisition, data compression and generalization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Communication</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="57" to="89" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The psycho-biology of language</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Zipf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936">1936</date>
			<publisher>Routledge</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
