<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Gary</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
							<email>gyen@okstate.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">A Particle Swarm Optimization-Based Flexible Convolutional Autoencoder for Image Classification</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Victoria University of Wellington</orgName>
								<address>
									<postCode>6140</postCode>
									<settlement>Wellington</settlement>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Oklahoma State University-Stillwater</orgName>
								<address>
									<postCode>74078</postCode>
									<settlement>Stillwater</settlement>
									<region>OK</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">175BD04136672A0FD41C82E803C88E1C</idno>
					<idno type="DOI">10.1109/TNNLS.2018.2881143</idno>
					<note type="submission">received February 11, 2018; revised June 26, 2018 and October 21, 2018; accepted November 9, 2018.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional autoencoder (CAE)</term>
					<term>deep learning</term>
					<term>image classification</term>
					<term>neural networks</term>
					<term>particle swarm optimization (PSO)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional autoencoders (CAEs) have shown their remarkable performance in stacking to deep convolutional neural networks (CNNs) for classifying image data during the past several years. However, they are unable to construct the state-of-the-art CNNs due to their intrinsic architectures. In this regard, we propose a flexible CAE (FCAE) by eliminating the constraints on the numbers of convolutional layers and pooling layers from the traditional CAE. We also design an architecture discovery method by exploiting particle swarm optimization, which is capable of automatically searching for the optimal architectures of the proposed FCAE with much less computational resource and without any manual intervention. We test the proposed approach on four extensively used image classification data sets. Experimental results show that our proposed approach in this paper significantly outperforms the peer competitors including the state-of-the-art algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A UTOENCODERS (AEs) [1]- [4] are the building blocks of Stacked AE (SAE) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> that is one of the trimainstream deep learning algorithms <ref type="bibr" target="#b6">[7]</ref> (i.e., others are deep belief networks (DBNs) <ref type="bibr" target="#b7">[8]</ref> and convolutional neural networks (CNNs) <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>). An AE is a three-layer neural network comprising one input layer, one hidden layer, and one output layer, where the number of units in the input layer is identical to that in the output layer. Typically, the transformation from the input layer to the hidden layer is called the encoder, and that from the hidden layer to the output layer refers to the decoder. The encoder extracts the features/representations from the input data, while the decoder reconstructs the input data from the features/representations. By minimizing the divergences between the input data and the reconstruction, one AE is trained. An SAE is stacked by multiple trained AEs for learning hierarchical representations that have gained more remarkable performance than ever before in the field of image classification <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>.</p><p>When image data are fed to the SAE, they must be transformed into the vector-form beforehand, which will change their inherent structures and reduce the consecutive performance in turn. For instance, one image is with the form I ∈ R n×n , where the pixel I j,k (1 &lt; j &lt; n, 0 &lt; k &lt; n) has the close distance to the pixel I j -1,k . When I is vectorized to V ∈ R n 2 , the relationship between I j,k and I j -1,k will be changed and may not be neighbors anymore in V . Extensive literatures have shown that adjacent information is a key factor in addressing images related problems <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b14">[15]</ref>. To address this issue, Masci et al. <ref type="bibr" target="#b15">[16]</ref> proposed the convolutional AEs (CAEs), where the image data are directly fed in 2-D form. In CAEs, the encoder is composed of one convolutional layer followed by one pooling layer, and the decoder comprises only one deconvolutional layer. Multiple trained CAEs are stacked to a CNN for learning the hierarchical representations that enhance the final classification performance. Inspired by the advantages of CAEs in addressing data with the original 2-D form, variants of CAEs have been proposed subsequently. For example, Norouzi et al. <ref type="bibr" target="#b16">[17]</ref> proposed the convolutional restricted Boltzmann machines (RBMs) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b17">[18]</ref> (CRBM). Lee et al. <ref type="bibr" target="#b18">[19]</ref> proposed the convolutional DBN by stacking a group of trained CRBMs. In addition, Zeiler et al. <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref> proposed the inverse convolutional ones based on the sparse coding schema <ref type="bibr" target="#b21">[22]</ref>, which inspired Kavukcuoglu et al. <ref type="bibr" target="#b22">[23]</ref> to design the convolutional stacked sparse coding for solving object recognition tasks. Recently, Du et al. <ref type="bibr" target="#b23">[24]</ref> proposed the convolutional denoising AE (CDAE) by using DAE <ref type="bibr" target="#b24">[25]</ref> to learn the convolutional filters.</p><p>Although experimental results from the CAE and its variants have shown benefits in diverse applications, one major limitation exists in that the architectures of their stacked CNNs are inconsistent with those of state-of-the-art CNNs, such as ResNet <ref type="bibr" target="#b25">[26]</ref> and VGGNet <ref type="bibr" target="#b26">[27]</ref>. To be specific, because one CAE has one convolutional layer and one pooling layer in the encoder part, the stacked CNN has the same numbers of convolutional layers and pooling layers. However, state-of-the-art CNNs are with nonidentical numbers of convolutional layers and pooling layers. Because the architecture of CNN is one key ingredient contributing to the final performance, the restriction on the numbers of convolutional layers and pooling layers of CAEs should be removed. However, choosing the appropriate numbers of convolutional layers and pooling layers is intractable due to the nondifferentiable and nonconvex characteristics in practice, which is related to the architecture optimization for neural networks.</p><p>Algorithms for automatically searching for the optimal architectures of neural networks can be classified into three different categories. The first refers to the algorithms based on the stochastic system, including random search (RS) <ref type="bibr" target="#b27">[28]</ref>, Bayesian-based Gaussian process (BGP) <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, tree-structured Parzen estimators (TPEs) <ref type="bibr" target="#b30">[31]</ref>, sequential model-based global optimization <ref type="bibr" target="#b31">[32]</ref>, evolving unsupervised deep neural network (EUDNN) <ref type="bibr" target="#b32">[33]</ref>, structure learning <ref type="bibr" target="#b33">[34]</ref>, and sparse feature learning <ref type="bibr" target="#b34">[35]</ref>. The second covers the algorithms that are designed specifically for CNNs where multiple different building blocks exist. The Metamodeling algorithm (MetaQNN) <ref type="bibr" target="#b35">[36]</ref> and the large evolution for image classification (LEIC) algorithm <ref type="bibr" target="#b36">[37]</ref> belong to this category. The third refers to the NeuroEvolution of Augmenting Topologies (NEAT) <ref type="bibr" target="#b37">[38]</ref> algorithm and its diverse variants, such as <ref type="bibr" target="#b38">[39]</ref>- <ref type="bibr" target="#b40">[41]</ref>. Above all, there is one method that does not belong to these categories, i.e., the grid search method (GS), which tests every combination of the related parameters.</p><p>Particle swarm optimization (PSO) is a population-based stochastic evolutionary computation algorithm, motivated by the social behavior of fish schooling or bird flocking <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, commonly used for solving optimization problems without requiring domain knowledge. Compared with other heuristic algorithms, PSO is enriched with the features of the simple concept, easy implementation, and computational efficiency. In PSO, the individuals are called particles, each particle maintains the best solution (denoted by pBest i for the i th particle) from the memory of itself, and the population records the best solution (denoted by gBest) from the history of all particles. During the process, particles expectedly cooperate and interact with the pBest i and gBest, enhancing the search ability and pursuing the optimal solutions. Due to the characteristics of no requirements (e.g., convex or differentiable) imposed on the problems to be optimized, PSO has been widely applied to various real-world applications <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b45">[46]</ref>, naturally including the architecture design of neural networks, such as <ref type="bibr" target="#b46">[47]</ref>- <ref type="bibr" target="#b51">[52]</ref>. In the optimization of neural network architectures, these algorithms employ an implicit method to encode each connection of the neural networks and take PSO or its variants to search for the optimum. However, they cannot be utilized for CAEs and CNNs, even SAEs and DBNs, which are deep learning algorithms, where tremendous numbers of connection weights exist, causing the unaffordable cost for implementation and effective optimization in these existing PSO-based architecture optimization (PSOAO) algorithms <ref type="bibr" target="#b52">[53]</ref>. As have discussed, CAEs without the constraints on the numbers of the convolutional layer and pooling layers would be greatly preferred for stacking the state-of-the-art CNNs. However, the absolute numbers of these layers are unknown before the architecture is identified. When PSO is employed for the architecture optimization, particles will need to have different lengths. The reasons are that: 1) the length of the particle refers to the number of decision variables of the problem to be solved by PSO and 2) in the architecture optimization problems, a set of different architectures are involved, and different architectures have different numbers of decision variables. However, the canonical PSO did not provide any way to update the velocity of particles with nonidentical lengths. In addition, evaluating particles each of which represents a deep learning algorithm is time consuming, and will become even more intractable for the population-based updating process. A common way to solve this problem is to employ intensive computational resources and utilize parallel-computation techniques.</p><p>The objective of this paper is to design and develop an effective and efficient PSO method to automatically discover the architecture of the flexible CAE (FCAE) without manual intervention. To achieve this goal, we have specified the four aims as follows.</p><p>1) Propose an FCAE where multiple convolutional layers and pooling layers can exist. The FCAE has no requirement on the particular numbers of the convolutional layers and the pooling layers, and have the potential for stacking to different types of CNNs. 2) Design a PSOAO algorithm for the proposed FCAE.</p><p>In PSOAO, we will propose an efficient encoding strategy to represent the FCAE architectures, which involve hundreds of thousands of parameters, into each particle, and we will also develop an effective velocity updating mechanism for particles with variable lengths. 3) Investigate the performance of the proposed FCAE when its architecture is optimized by the designed PSOAO on image classification benchmark data sets (i.e., the CIFAR-10 data set <ref type="bibr" target="#b53">[54]</ref>, the MNIST data set <ref type="bibr" target="#b8">[9]</ref>, the STL-10 data set <ref type="bibr" target="#b54">[55]</ref>, and the Caltech-101 data set <ref type="bibr" target="#b55">[56]</ref>.), compare the classification accuracy to peer competitors and examine the evolution effectiveness of PSOAO. 4) Investigate the effectiveness of the designed velocity updating method through quantitative experiments on the comparisons to its opponents. The remainder of this paper is organized as follows. Background of the CAE and PSO is reviewed in Section II. This is followed by the details of the proposed PSOAO algorithm in Section III. Then, the experiment design and the result analysis are documented in Sections IV and V, respectively. Finally, the conclusions and future work are drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. LITERATURE REVIEW</head><p>This work will build FCAE and PSOAO based on CAE and PSO, respectively. Therefore, we would like to provide the skeletons of CAE and PSO as well as their limitations for FCAE in Sections II-A-II-C, respectively, which could help the readers to conveniently understand our work in this paper. In addition, related works are also reviewed and commented, which helps the readers to easily appreciate the importance of our work in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Convolutional Autoencoder</head><p>For the convenience of the development, assuming CAEs are utilized for image classification tasks, and each image X ∈ R w×h×c , where w, h, c refer to the image width, height, and number of channels, respectively. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the architecture of one CAE <ref type="bibr" target="#b15">[16]</ref>.</p><p>1) Convolution: Given the input data, the convolution operation employs one filter to slide with one defined stride, and outputs the element that is the sum of the products of the filter and the input data with which this filter overlaps. All elements generated by one filter construct one feature map, and multiple feature maps are allowed in the convolution operations. The convolution operation has the SAME type and the VALID type. The parameters related to the convolutional operation are the filter size (width and height), the stride size (width and height), the convolutional type, and the number of feature maps.</p><p>2) Pooling: Pooling operation resembles the convolution operation, in addition to the filter and the way to generate the elements of the corresponding feature map. Specifically, the filter in a pooling operation is called a "kernel," and no value exists in the kernel. There are two types of statistical indicators in the pooling operation: mean and maximal. Typically, maximal pooling is preferred in CAEs. The pooling operation requires the parameters: the kernel size (width and height), the stride size (width and height), and the pooling type.</p><p>3) Deconvolution: The deconvolutional operation is equivalent to the corresponding convolutional operation with inverse parameter settings. Specifically, the deconvolutional operation performs the convolutional operation with the filter and stride, which has been used in the corresponding convolutional operation, on the feature map that is resulted from the corresponding convolutional operation. In order to assure the output of the deconvolutional operation to have the same size as the input of the corresponding convolutional operation, extra zeros may be padded to the input of the deconvolutional operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Learning of CAE:</head><p>The mathematical form of the CAE is represented by <ref type="bibr" target="#b0">(1)</ref>, where the conv(•), pool(•), and de_conv(•) denote the convolution, pooling, and deconvolution operations, respectively, F(•) and G(•) refer to the elementwise nonlinear activation functions, b 1 and b 2 are the corresponding bias terms, r and X are the learned features and reconstruction of X, l(•) measures the differences between X and X , and is the regularization term to improve the feature quality. By minimizing L, the CAE is trained, and then parameters in convolution operation, bias terms, and deconvolutional operation are identified. Encoders with these parameters from multiple trained CAEs are composed to be a CNN for learning hierarchical features that benefit the final classification performance <ref type="bibr" target="#b6">[7]</ref> ⎧</p><formula xml:id="formula_0">⎨ ⎨ ⎨ ⎨ ⎨ ⎨ ⎨ ⎩ r = pool(F(conv(X) + b 1 )) X = G(de_conv(r ) + b 2 ) min L = l(X, X) +<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Motivation of FCAE</head><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, a CAE is composed of a convolutional layer followed by a pooling layer and then a deconvolutional layer. The transformation through the convolutional layer and then the pooling layer is called the encoder. The transformation through the deconvolutional layer is called the decoder. During the construction of a CNN by using CAEs, encoders from multiple CAEs are stacked together based on their training orders, and the input data of the current encoder is the output data of the previous one. However, this architecture is not able to form the state-of-the-art CNNs nor the common deep CNNs. Next, we will describe them in detail.</p><p>The architectures of a CNN stacked by CAEs and a state-of-the-art CNN named VGGNet <ref type="bibr" target="#b26">[27]</ref> are shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a) and (b), respectively. From these two examples, it is evident that CAEs are incapable of stacking into VGGNet. The reason is that the CNN stacked by CAEs are with the same building blocks, i.e., the two-layer network including a convolutional layer followed by a pooling layer. Consequently, the stacked CNN is composed of a series of such building blocks and with the same number of the convolutional layers to that of the pooling layers. In addition, a convolutional layer must be followed by a pooling layer in the CNNs stacked by CAEs. As can be observed in Fig. <ref type="figure" target="#fig_1">2(b)</ref>, there are multiple convolutional layers and pooling layers with identical numbers, and also a convolutional layer is not necessarily followed by a pooling layer.</p><p>The pooling layer is typically used to reduce the dimension of the input data to decrease the computational complexity. The most commonly used configuration for a pooling layer is with the kernel size of 2 × 2 and the stride of 2 × 2. Based on the working mechanism introduced in Section II-A, one pooling layer with such a configuration will reduce half size of the input data. For example, for an image from the CIFAR-10 data set <ref type="bibr" target="#b53">[54]</ref> that is with the dimension of 32 × 32, the output size will become 1 × 1 with five pooling layers, i.e., the CNN designed to process CIFAR-10 with CAEs is at most up to 10 layers. However, the state-of-the-art designs on this benchmark have more than 100 layers <ref type="bibr" target="#b56">[57]</ref>.</p><p>Based on the above-mentioned description, the root of the limitations from CAE exists in its architectures that the encoder of a CAE is composed one convolutional layer and then one pooling layer. Therefore, the concern is naturally raised that the architecture of CAE should be revised, which motivates the design of FCAE, i.e., in the encoder part of an FCAE, nonidentical numbers of convolutional layers and pooling layers are allowed, and a pooling layer can follow a series of convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Particle Swarm Optimization</head><p>A typical PSO has the procedure as follows:</p><p>Step 1: Initialize the particles, predefine a maximal generation number max t , and initialize a counter t = 0.</p><p>Step 2: Evaluate the fitness of particles.</p><p>Step 3: For each particle, choose the best one, pBest i , from its memory. </p><formula xml:id="formula_1">v i ← inertia w • v i + global search c 1 • r 1 • ( p g -p i ) + local search c 2 • r 2 • ( p p -p i ) (<label>2</label></formula><formula xml:id="formula_2">)</formula><formula xml:id="formula_3">p i ← p i + v i .<label>(3)</label></formula><p>In <ref type="bibr" target="#b1">(2)</ref>, w denotes the inertia weight, c 1 and c 2 are the acceleration constants, r 1 and r 2 are the random numbers between 0 and 1, and p g as well as p p denotes the positions of gBest as well as pBest i , respectively. v i and p i denote the velocity and position of the i th particle x i , respectively. By integrating the "inertia," "global search," and "local search" terms into the velocity updating, the best position is expected to be found by particles.</p><p>Noting in (2) that there are two subtraction operations existing in the "global search" and "local search." In order to better understand how such a subtraction operation works, we will describe the details by taking the term p gp i in "global search" as an example. Supposing the minimization problem to be solved is formulated as f (z 1 , z 2 , . . . , z n ) where there are n decision variables {z 1 , z 2 , . . . , z n } ∈ . When PSO is used to solve this problem, the i th particle x i will be randomly sampled from , and its position is determined by a particular value p i = {z i 1 , z i 2 , . . . , z i n } ∈ . Through the interaction formulated by ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_3">3</ref>), the position of x i is updated toward the position of the optimal solution. After a number of iterations, the optimization is solved and the final solution is the position of the global best particle, gBest. In this example, the length of a particle is n, i.e., the number of decision variables and also the dimension of the position. Obviously, p g -</p><formula xml:id="formula_4">p i = {z g 1 -z i 1 , z g 2 -z i 2 , . . . , z g n -z i n }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation of Using PSO for Architecture Design in FCAE:</head><p>The velocity updating requires the particle x i , gBest, and pBest i to have the same/fixed length. When PSO is used for the architecture optimization of FCAE, particles represent the potential optimal architectures of FCAE. Because the optimal architecture of FCAE for solving the task at hand is unknown, particles with different variable lengths will emerge. Therefore, a novel velocity updating method needs to be designed in this regard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Related Works</head><p>As we have discussed in Section I, algorithms for optimizing the architectures of deep neural networks fall into four different categories.</p><p>For the algorithms in the first category, RS <ref type="bibr" target="#b27">[28]</ref> evaluates the randomly selected architectures with a predefined maximal trial number, and uses the best one in performance. RS has been reported that it only works under the condition when optimum is in a subspace of the whole search space <ref type="bibr" target="#b57">[58]</ref>. However, it is not clear whether this fact equally applies to CNNs or not. Compared to RS, BGP <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref> utilizes more knowledge on choosing the potential optimal architecture based on Bayesian inference <ref type="bibr" target="#b29">[30]</ref>. However, BGP has extra parameters, such as the kernels, which are hard to tune. TPE <ref type="bibr" target="#b30">[31]</ref> works with the assumption that the parameters related to the architecture are independent, while most parameters in CNNs are indeed dependent such as the convolutional layer size and the strides. In addition, EUDNN is designed for unsupervised deep neural networks that are with different architectures from CNNs. Furthermore, methods in <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b34">[35]</ref> are only used for optimizing the particular network connections with the given architectures, such as the sparsity. To this end, algorithms in this category cannot be used to optimize the architectures of CNNs. Consequently, they are not suitable for FCAEs of which the architectures are based on CNNs.</p><p>For the algorithms in the second category, i.e., MetaQNN <ref type="bibr" target="#b35">[36]</ref> and LEIC <ref type="bibr" target="#b36">[37]</ref>, both of them are designed specifically for optimizing the architectures of CNNs. Specifically, MetaQNN uses the reinforcement learning technique <ref type="bibr" target="#b58">[59]</ref> to heuristically exploit the potential optimal architectures of CNNs, thoroughly evaluate them, and then Algorithm 1 Framework of the PSOAO Algorithm choose the one that has the best fitness. LEIC employs nearly the same strategy to MetaQNN except for that LEIC used the genetic algorithm as the heuristic method. Due to the complete training on each candidate in both algorithms, their deficiencies are also obvious, i.e., their training relies on the extensive computational resources. For instance, MetaQNN employed 10 graphics processing unit (GPU) cards for 8-10 days, while LEIC employed 250 high-performance computers for 20 days on the CIFAR-10 test problem <ref type="bibr" target="#b53">[54]</ref>. Unfortunately, sufficient computational resource is not necessarily available to all interested researchers.</p><p>Because the algorithms in the third category are all based on NEAT, their working flows are nearly the same. Specifically, the input layer and the output layer are assigned first, and then neurons between these two layers and connections from arbitrary two neurons are heuristically generated. With the fitness evaluation upon each situation, the better ones are selected and the best one is expected to be found with genetic algorithm. In addition to the limitations occurred in the algorithms from the second category, other limitations from NEAT-based algorithms are that hybrid connections (i.e., the weight connections between the layers which are not adjacent) would be produced, and the configurations of the input layer and the output layer must be specified in advance, which are not allowed or applicable in CAEs.</p><p>Theoretically, GS can find the optimal architecture because of its exhaustive nature to try each candidate. However, it is impossible for GS to try each candidate in practice. Recently, experimental investigation <ref type="bibr" target="#b59">[60]</ref> shows that GS is only suitable for the problems with no more than four parameters in practice. As have been shown in Section II-A, a CAE will have more than 10 parameters even it contains only one convolutional layer and one pooling layer. In addition, GS cannot well handle parameters with continuous values because of the "interval" problems <ref type="bibr" target="#b59">[60]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED PSOAO ALGORITHM FOR FCAE</head><p>In this section, the details of the proposed PSOAO algorithm for FCAE will be provided. We will describe the encoding strategy which involves the FCAE representation, the particle initialization, the fitness evaluation, and the velocity and position updating mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Algorithm Overview</head><p>Algorithm 1 outlines the framework of the designed PSOAO algorithm. First, particles are randomly initialized based on the proposed encoding strategy (line 1). Then, particles start to evolve until the generation number exceeds the predefined one (lines 3-9). Finally, the gBest particle is picked up for obtaining the final performance through the deep training <ref type="foot" target="#foot_0">1</ref> to solve tasks at hand (line 10).</p><p>During the evolution, the fitness of each particle is evaluated (line 4) first, and then the pBest i and gBest are updated based on the fitness (line 5). Next, the velocity of each particle is calculated (line 6) and their positions are updated (line 7) for the next generation of evolution. In the following sections, the key aspects of PSOAO are detailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Encoding Strategy</head><p>For the convenience of the development, the definition of FCAE is given in Definition 1 by generalizing the building blocks in all CNNs. Obviously, the CAE is a special form of FCAE when the numbers of convolutional layers and pooling layers are both set to be 1.</p><p>Definition 1: A FCAE encompasses one encoder and one decoder. The encoder is composed of the convolutional layers and pooling layers, where these two types of layers are not mixed and their numbers are flexible. The decoder part is the inverse form of the encoder.</p><p>We design an encoding strategy through variable-length particles to encode the potential architecture of one FCAE into one particle. Because the decoder part in an FCAE is the inverse form of the encoder, the particle in the proposed variable-length encoding strategy only encodes the encoder part for the reason of reducing the computational complexity. Each particle contains different numbers of convolutional layers and pooling layers. Based on the introduction of the convolution operation and pooling operation in Section II-A, all the encoded information of PSOAO for FCAE are summarized in Table <ref type="table" target="#tab_2">I</ref> where the l 2 denotes the weight decay regularization term for preventing from the overfitting problem <ref type="bibr" target="#b60">[61]</ref>. Because only the convolutional layers involve weight parameters, this regularization term is applied only to the convolutional layers. Furthermore, because the output size will not change from the input size with the SAME convolutional layers, which is easy to control in automatic architecture discovering, the designed encoding strategy will not encode the type of the convolutional layers but default to the SAME type. As have mentioned in Section II-A that CAE prefers to the max pooling layer, we also do not need to encode this parameter. In addition, three examples of the generally encoded particles in PSOAO are illustrated in Fig. <ref type="figure">3</ref>. In the following, we will detail the rationale of this encoding strategy.</p><p>In the proposed PSOAO algorithm, a variable-length encoding strategy is designed for the particles representing FCAEs with different architectures. The major reason is that the optimal architecture is unknown prior to the optimization, and the fixed-length encoding strategy often imposing constraints on architectures does not work under this occasion. Specifically, if the traditional fixed-length encoding strategy is employed, the maximal length should be specified in advance. However, the maximal length is not easy to set and needs to be carefully tuned for the best performance. A too small number denoting the maximal length would be inefficient for the optimized architecture of FCAE to solve complex problems.</p><p>A too large number would consume much more unnecessary computation, and also results in worse performance within the same predefined evolution generation number. Furthermore, two types of layers exist in each particle, which increases the difficulty of employing the fixed-length encoding strategy.</p><p>With the designed variable-length encoding strategy, all the information of potential optimal architecture for FCAE can be flexibly represented for exploitation and exploration during the search process without manual intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Particle Initialization</head><p>Algorithm 2 shows the procedure of the particle initialization with the given population size, and maximal numbers of the convolutional layers and the pooling layers. Particularly, lines 3-8 demonstrate the initialization of the convolutional layers, while lines 9-14 show the initialization of the pooling layers, where the random settings refer to the settings of the information encoded in these two types of layers. Because the decoder part of FCAE can be explicitly derived from its encoder part, each particle in the proposed PSOAO algorithm contains only the encoder part for reducing the computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Fitness Evaluation</head><p>Algorithm 3 shows the fitness evaluation for the particles in PSOAO. As we have introduced in Section II-A, the reconstruction error added by the loss of the regularization term is identified as the objective function for training CAE.  In the proposed PSOAO algorithm, a small number of training epochs is employed to conduct the fitness evaluation of particles. With the evaluated fitness, the gBest and pBest i are selected to guide the search toward the optimum. When the evolution is terminated, the gBest is selected and one-time deep training is performed for reaching the optimal performance. We have shown that this setting can largely speed up PSOAO yet with less computational resources, while the promising performance of PSOAO is still maintained. Specifically, the running time on the investigated benchmark data sets are given in Table <ref type="table" target="#tab_2">II</ref>, the adopted computational resources for the investigated benchmark data sets are given in Section IV-C, and the experimental results regarding the performance are shown in Sections V-A and V-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Velocity Calculation and Position Update</head><p>In PSOAO, the particles are with different lengths, and (2) cannot be directly used. To solve this problem, we design a method named "x-reference" to update the velocity. In x-reference, the lengths of gBest and pBest i refer to the length of the current particle x, i.e., gBest and pBest i keep the same length to that of x. Because the pBest i is selected from the memory of each particle, and the gBest is chosen from all particles, the current particle x is always with the same length of pBest i and the x-reference is applied only to the "global search" part of (2). Algorithm 4 shows the details of the x-reference method.</p><p>Specifically, the x-reference method is applied twice in the same manner in the velocity updating for the "global search" part of (2). The first is on the convolutional layer part of gBest and x (lines 2-14), and the second is on the pooling layer part (line 15). For the convolutional layer part, if the number of convolutional layers, cg, from gBest is smaller than that from x, new convolutional layers initialized with zero values are padded to the tail of cg. Otherwise, extra convolutional layers are truncated from the tail of cg. After the "global search" part is derived by Algorithm 4, the "inertia" and "local search" parts in (2) are calculated as normal, then the complete velocity is calculated and the particle position is updated by <ref type="bibr" target="#b2">(3)</ref>.</p><p>For an intuitive understanding, the proposed x-reference velocity updating method, an example is provided in Fig. <ref type="figure" target="#fig_3">4</ref>. Specifically, Fig. <ref type="figure" target="#fig_3">4</ref>(a) displays the gBest and x that are used to do the "global search" part in the velocity updating. In Fig. <ref type="figure" target="#fig_3">4(b)</ref>, the convolutional layers and pooling layers are collected from gBest and x. Because the lengths of convolutional layers and pooling layers from x are 2 and 4, and those from gBest are 3 and 2, the last convolutional layer from the convolutional layer part from gBest is truncated, and the other two pooling layers are padded to the tail of the pooling layer part of gBest. In particular, the padded pooling layers are created with the values of encoded information equal to 0. Fig. <ref type="figure" target="#fig_3">4(c</ref>) demonstrates the updating between the convolutional layer part and pooling layer part from gBest and x. Fig. <ref type="figure" target="#fig_3">4(d)</ref> shows the results of this updating.</p><p>No matter whether padding or truncating is operated in the designed x-reference velocity updating method, the goal is to make the same length of convolutional layers and pooling layers in gBest to that in x, respectively. The mechanism behind this design is discussed as follows. In PSOAO, there are a group of particles with different lengths in the population, with the same goal of searching for the optimal architectures of FCAEs for solving image classification tasks. If we have each particle follow the length of gBest (i.e., the gBest-reference velocity updating method), all the particles will have the same length to that of gBest from the second generation. Because the pBest i is chosen from the memory of each particle, the gBest, pBest i , and current particle x may all have the same length from the third generation. Consequently, all particles participate in the optimization with one particular depth of FCAE and only change the encoded information. Indeed, the variation of length regarding gBest can be seen as an exploration search behavior, while that of the encoded information is viewed as an exploitation search behavior. When all particles are in the same length, the length of gBest will be constant until it terminates. In this regard, the exploration search ability is lost if we employ the gBest-reference velocity updating method. In addition, keeping the length of x equal to gBest can also be viewed as the losses of diversity, which would easily lead to the premature convergence in population-based algorithms. Both the loss of exploration search and the premature phenomenon will result in a poor performance. An experiment is conducted in Section V-D to further quantitatively investigate this velocity updating design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Deep Training on gBest</head><p>When the evolution of PSOAO is finished, the best particle, gBest, is picked for deep training. As stated in Section III-D that each particle is trained with only a few epochs, which is not the optimal performance for solving real-world applications. To solve this concern, the deep training is necessary.</p><p>Typically, the process of the deep training is the same to the fitness evaluation in Section III-D except for a larger epoch number, say 100 or 200.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL DESIGN</head><p>In this section, the benchmark data sets, peer competitors, and the parameter settings are detailed for the experiments investigating the performance of the proposed FCAE in which its architecture is optimized by the proposed PSOAO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmark Data sets</head><p>The experiments are conducted on four image classification benchmark data sets, which are widely used and specifically for investigating the performance of AEs. They are the CIFAR-10 data set <ref type="bibr" target="#b53">[54]</ref>, the MNIST data set <ref type="bibr" target="#b8">[9]</ref>, the STL-10 data set <ref type="bibr" target="#b54">[55]</ref>, and the Caltech-101 data set <ref type="bibr" target="#b55">[56]</ref>. Fig. <ref type="figure" target="#fig_4">5</ref> shows examples from these benchmark data sets. In the following, these chosen data sets are briefly introduced.</p><p>1) CIFAR-10 Data Set: It contains 50 000 training images and 10 000 test images Each one is a three-channel RGB image in the size of 32 × 32, and belongs to one of 10 categories of natural objectives (i.e., truck, ship, horse, frog, dog, deer, cat, bird, automobile, and airplane). Each category is with roughly the same number of images. In addition, different objects occupy different areas of the images.</p><p>2) MNIST Data Set: It is a handwritten digit recognition data set to classify the numeral numbers of 0 . . . 9, including 60 000 training images and 10 000 test images. Each one is a one-channel gray image in the size of 28 × 28, and the samples in each category are with different variations, such as rotations. Each category is composed of the same number of image samples.</p><p>3) STL-10 Data Set: It is a widely used data set for unsupervised learning, containing 100 000 unlabeled images, 5000 training images, and 8000 test images from 10-category natural image object recognition (i.e., airplane, bird, car, cat, deer, dog, horse, monkey, ship, and truck). Each one is a three-channel RGB image in the size of 96 × 96. In addition, the unlabeled images contain images that are beyond the 10 categories. Due to the small number of training samples, this data set challenges the feature learning ability of CAEs/AEs and PSOAO.</p><p>4) Caltech-101 Data Set: It is a 101-category image classification data set where the weights and heights of images vary from 80 to 708 pixels. Most images are three-channel RGB while occasionally gray, and with different images in each category from 31 to 800. In addition, most images only display a small part of the image, and other areas are occupied by noises for increasing the difficulty in classification. Due to the quite small number of images, and the nonidentical numbers of images in each category, this data set also challenges the feature learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Peer Competitors</head><p>Peer competitors for the proposed FCAE, which have been introduced in Section I, are employed for performing the comparisons on the chosen image classification benchmark data sets. They are the CAE <ref type="bibr" target="#b15">[16]</ref>, convolutional RBM (CRBM) <ref type="bibr" target="#b18">[19]</ref>, and the state-of-the-art CDAE <ref type="bibr" target="#b23">[24]</ref>. In addition, two widely used variants of AEs are also employed as peer competitors for a comprehensive comparison. They are the sparse AE (SAE) <ref type="bibr" target="#b61">[62]</ref> and DAE <ref type="bibr" target="#b24">[25]</ref>.</p><p>Because this paper aims at proposing an FCAE that could be stacked to the state-of-the-art CNNs, peer competitors for comparisons here also include the stacked forms of these CAEs/AEs, i.e., the stacked CAE (SCAE), the stacked CRBM (SCRBM), the stacked CDAE (SCDAE), the stacked SAE (SSAE), and the stacked DAE (SDAE). The stacked form of the proposed FCAE is SFCAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Parameter Settings</head><p>The peer competitors SCAE, SCRBM, SSAE, and SDAE have been investigated very recently on the chosen benchmark data sets, and their architectures have been manually tuned with domain expertise <ref type="bibr" target="#b23">[24]</ref>. Their classification results are directly cited from the original publications, thus none of their parameter settings needs to be specified. In addition, the stateof-the-art SCDAE provides the classification results with the usage of only one and two building blocks on the chosen benchmark data sets. In order to do a fair comparison, we also perform experiments on SFCAE with at most two building blocks. Note that the SFCAE is tested on the chosen benchmark data sets without the preprocessing of data augmentation for keeping consistency to its peer competitors. In the following, the parameter settings of PSOAO are provided in detail.</p><p>In the designed PSOAO algorithm, PSO related parameters are specified based on their conventions <ref type="bibr" target="#b62">[63]</ref>, i.e., the inertia weight w is set to be 0.72984, the acceleration constants c 1 and c 2 are both set to be 1.496172, and the initial velocity is set to be 0. The training sets of MNIST and CIFAR-10, the unlabeled data of STL-10 are naturally used for their fitness evaluations. Due to the nonidentical and a quite small number of images in each category of the Caltech-101 data set, 30 images randomly selected from each category are used for the fitness evaluations and also as the training set based on the suggestions in <ref type="bibr" target="#b23">[24]</ref>. Because inappropriate settings of convolutional operations and pooling operations would lead to an unaffordable computational cost and make FCAE being incompetitive, in the exploration of each particle, the number of feature maps is set to be <ref type="bibr" target="#b19">[20,</ref><ref type="bibr">100]</ref>, the kernel with the same size of width and height is set to be <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>, the maximal number of pooling layers is set to be 1, and that of convolutional layer is set to be 5. Note that only the square convolutional filters and pooling kernels are investigated in the experiments, which is based on the conventions from state-ofthe-art CNNs <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b56">[57]</ref>. In addition, the coefficient of l 2 term is set to be [0.0001, 0.01], which is a commonly utilized range for training neural networks in practice.</p><p>FCAE with the architecture determined by PSOAO and the weights initialized by the widely used Xavier method <ref type="bibr" target="#b63">[64]</ref>, by adding one full connection layer with 512 units and 50% Dropout <ref type="bibr" target="#b64">[65]</ref> from the conventions of deep learning community, are used for the deep training. We investigate the classification results by feeding the trained model with the corresponding test set,<ref type="foot" target="#foot_1">2</ref> employing the widely used rectifier linear unit <ref type="bibr" target="#b65">[66]</ref> as the activation function, the Adam <ref type="bibr" target="#b66">[67]</ref> optimizer with its default settings as the training algorithm for weight optimization, and the BatchNorm <ref type="bibr" target="#b67">[68]</ref> technique for speeding up the training. For keeping consistency in the results The proposed PSOAO algorithm is implemented by Tensorflow <ref type="bibr" target="#b68">[69]</ref>, and each copy of the source code runs on one GPU card with the same model number of GTX1080. For reproducing the experimental results reported in this paper, the codes are released in https://github.com/sunkevin1214/psoao. In addition, the architecture configurations of FCAEs optimized by PSOAO for the benchmark data sets in these experiments are provided in Section V-E. Training time of the proposed PSOAO algorithm on the benchmark data sets are given in Table <ref type="table" target="#tab_2">II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview Performance</head><p>Table <ref type="table" target="#tab_5">III</ref> shows the mean and standard derivations of the classification accuracies of the proposed FCAE method, whose architecture is optimized by the designed PSOAO algorithm, and the peer competitors on the benchmark data sets. Because literatures do not provide the standard derivations of SCAE on CIFAR-10 and MNIST, SCRBM on CIFAR-10, and SDAE on MNIST, only their mean classification accuracies are shown. The references in Table <ref type="table" target="#tab_5">III</ref> denote the sources of the corresponding mean classification accuracies, and the best mean classification results are highlighted in bold. The terms "SFCAE-1" and "SFCAE-2" refer to the SFCAE with one and two building blocks, respectively, which is the same meaning as the terms "SCDAE-1" and "SCDAE-2."</p><p>It is clearly given in Table <ref type="table" target="#tab_5">III</ref> that FCAE outperforms the traditional AEs (i.e., the SSAE and the SDAE) and traditional CAEs (i.e., the SCAE and the SCRBM) on all benchmark data sets. In addition, FCAE also outperforms the state-of-the-art CAEs (i.e., the SCDAE-1 and the SCDAE-2) on these benchmark data sets. Furthermore, the best results on CIFAR-10 and MNIST are reached by SFCAE-2, and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evolution Trajectory of PSOAO</head><p>In order to intuitively investigate the efficacy of the designed PSOAO algorithm in optimizing the architectures of the proposed FCAE method, its evolution trajectories on the chosen benchmark data sets during the training phases are plotted in Fig. <ref type="figure" target="#fig_5">6</ref>, where the horizontal axis denotes the number of generations in the evolution, and the vertical axis denotes the fitness values of the gBest.</p><p>As can be seen in Fig. <ref type="figure" target="#fig_5">6</ref>(a)-(d), PSOAO has converged within the specified maximal generation number. Specifically, it has converged since about the 15th generation on all benchmark data sets for both SFCAE-1 and SFCAE-2, and about the 5th generation on the CIFAR-10 and Caltech-101 data sets for SFCAE-2. Note that the reconstruction error of SFCAE-2 is smaller than that of SFCAE-1 on STL-10 data set [shown in Fig. <ref type="figure" target="#fig_5">6(c)]</ref>, which is caused by the different input data for them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance on Different Numbers of Training Examples</head><p>In this section, we investigate the classification performance of the proposed FCAE method whose architecture is optimized by the designed PSOAO algorithm on different numbers of training samples. The peer competitors on the MNIST data set are SCRBM <ref type="bibr" target="#b18">[19]</ref>, ULIFH <ref type="bibr" target="#b70">[71]</ref>, SSAE <ref type="bibr" target="#b71">[72]</ref>, and SCAE <ref type="bibr" target="#b15">[16]</ref>, and those for the CIFAR-10 data set are SCAE <ref type="bibr" target="#b15">[16]</ref>, Meancov. RBM <ref type="bibr" target="#b69">[70]</ref>, and K-means (4k feat) <ref type="bibr" target="#b54">[55]</ref>. The reason for choosing these benchmark data sets and peer competitors is that the literature has provided their corresponding information that is widely used by the comparisons between various variants of CAEs. Tables IV and V show the experimental results of FCAE-2 with the architecture confirmed in Section V-A on different numbers of training samples of the MNIST and CIFAR-10 benchmark data sets. The symbol "-" denotes that there is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Investigation on x-Reference Velocity Calculation</head><p>To further investigate the superiority of the proposed x-reference velocity updating method, we replace it from the proposed PSOAO algorithm with the gBest-reference velocity updating method, to compare the performance on the chosen benchmark data sets introduced in Section IV-A. To achieve this, we first let the length of pBest i equal to that of gBest. If the length of the convolutional layers in pBest i is less than that of gBest, zeros are padded. Otherwise, truncating the corresponding parts from pBest i . We use this method in the pooling layers of pBest i and these two types of layers in x. Then, we use ( <ref type="formula" target="#formula_1">2</ref>) and (3) to update the position of each particle. The experimental results are shown in Fig. <ref type="figure" target="#fig_6">7</ref>, where Fig. <ref type="figure" target="#fig_6">7</ref>(a) displays the results of FSCAE-1 while Fig. <ref type="figure" target="#fig_6">7</ref>(b) displays those of FSCAE-2.</p><p>As can be seen from Fig. <ref type="figure" target="#fig_6">7</ref>(a), with the x-reference velocity updating method, SFCAE-1 achieves the classification accuracy improvements of 5.7%, 8.8%, 5.9%, and 7.9% on the CIFAR-10, MNIST, STL-10, and Caltech-101 benchmark data sets, respectively. The same promising performance of SFCAE-2 can also be observed with the classification accuracy improvements of 7.7%, 10.6%, 5.6%, and 9.6% on these chosen benchmark data sets, as shown in Fig. <ref type="figure" target="#fig_6">7(b)</ref>.</p><p>In summary, the analysis and experimental results convincely justify the effectiveness of the proposed x-reference velocity updating method in the proposed PSOAO algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Investigation on the Obtained Architectures</head><p>Tables VI, VIII, X, and XII show the architecture configurations of SFCAE-1 for the CIFAR-10, MNIST, STL-10 and Caltech-101 data sets, respectively. In addition, Tables VII, IX, XI, and XIII show the architecture configurations of SFCAE-2 for the CIFAR-10, MNIST,    composed of several blocks, and each block is composed of several convolutional layers followed by the pooling layer. Unsurprisingly, these obtained architectures follow the architectures of the traditional CNNs and the architectures of known and manually designed network, such as the VGGNet <ref type="bibr" target="#b26">[27]</ref>.</p><p>Recently, there are two famous types of CNNs, i.e., ResNet <ref type="bibr" target="#b25">[26]</ref> and DensNet <ref type="bibr" target="#b56">[57]</ref>. Because these two networks are different from the architectures of the traditional CNNs due to the skip and dense connections, the obtained architectures are different to these networks. Due to the promising performance of ResNet and DenseNet on large-scale image classification tasks shown in their experiments, we will in the future investigate a new encoding strategy that is capable of encoding the skip connections of ResNet and dense connections of DensNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>The goal of this paper is to develop a novel PSO algorithm (namely, PSOAO) to automatically discover the optimal architecture of the FCAE for image classification problems without manual intervention. This goal has been successfully achieved by defining the FCAE that has the potential to construct the state-of-the-art deep convolutional neural networks, designing an efficient encoding strategy that is capable of representing particles with nonidentical lengths in PSOAO, and developing an effective velocity updating mechanism for these particles. The FCAE with the "optimal" architecture is achieved by PSOAO, and compared with five peer competitors including the most state-of-the-art algorithms on four benchmark data sets, specifically used by AEs for image classification. The experimental results show that FCAE remarkably outperforms all the compared algorithms on all adopted benchmark data sets in term of their classification accuracies. Furthermore, FCAE with only one building block can surpass the state of the art with two building blocks on the STL-10 and Caltech-101 benchmark data sets. In addition, FCAE reaches the best classification accuracies compared with the four peer competitors when only 1K, 2K, 3K, 5K, and 10K training images of the MNIST benchmark data set are used, and significantly outperforms three peer competitors when only 1K and 10K training images of the CIFAR-10 benchmark data set are used. Moreover, the proposed PSOAO algorithm also shows the excellent characteristic of fast convergence by investigating its evolution trajectories, and the effective velocity updating mechanism through the quantitative comparison to its opponents.</p><p>Although deep CNNs have achieved the current state-ofthe-art results for image classification, the architectures and hyperparameters are largely determined by manual tuning based on domain expertise/knowledge. This paper provides a direction, which shows that such manual work can be replaced by automatic learning through evolutionary approaches. In the future, we will investigate simpler evolutionary methods on more complex CNN models with using much less computational resources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustrative architecture of CAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Architecture stacked by CAEs. (b) Architecture of VGGNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2 5 while← 15 UseAlgorithm 3</head><label>25153</label><figDesc>Particle Initialization Input: The population size N, the maximal number of convolutional layers N c , and the maximal number of pooling layers N p . Output: Initialized population x 0 . 1 x ← ∅; 2 while |x| ≤ N do 3 conv_li st ← ∅; 4 n c ← Uniformaly generate an integer between [1, N c ]; conv_li st ≤ n c do 6 conv_uni t ← Initialize a convolutional layer with random settings; 7 conv_li st ← conv_li st ∪ conv_uni t; Uniformaly generate an integer between [1, N p ]; 11 while | pool_li st| ≤ n p do 12 pool_uni t ← Initialize a pooling layer with random settings; 13 pool_li st ← pool_li st ∪ pool_uni t; 14 end conv_li st and pool_li st to generate a particle x;16 x ← x ∪ x; Fitness Evaluation Input: The population x, the training set D train , the number N train of training epoch. Output: The population x with fitness. 1 Calculate the reconstruction error and l 2 loss of the FCAE encoded by each particle in x, and train the weights with N train epochs; 2 Calculate the reconstruction error of each batch data in D train and set the mean reconstruction error as the fitness of the corresponding particle; 3 Return x. However, the loss of the regularization term used in FCAE (i.e., l 2 loss) is highly affected by the weight numbers and weight values, and different architectures have different weight numbers and weight values. In order to investigate when only the architecture is reflected by the particle quality, the l 2 loss is discarded and only the reconstruction error is employed as the fitness. Supposing the batch training data is {d 1 , d 2 , . . . , d n } [d j k i ∈ R w×h denotes the pixel value at the position of ( j, k) of the i th image in the batch training data, and each image has the dimension of w × h], the weights in the FCAE is {w 1 , w 2 , . . . , w m }, the reconstructed data are { d1 , d2 , . . . , dn }. The l 2 is calculated by m i=1 w 2 i , while the reconstruction error is calculated by (1/n) n k=1 w l=1 h m=1 ( d lm kd lm k ) 2 . Typically, a deep learning algorithm requires a training epoch number in the magnitude of 10 2 -10 3 to train its weight parameters by gradient-based algorithms. This high computational issue is even worsen in population-based algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Example to illustrate the proposed x-reference velocity updating method. (a) Selected particles for velocity updating. (b) Collection of the convolutional layers and pooling layers. (c) Velocity updating between the convolutional layers and pooling layers. (d) Resulted particles after the velocity updating.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Examples from the chosen benchmark data sets. (a) Examples from the CIFAR-10 data set. From left to right, they are from the categories of truck, ship, horse, frog, dog, deer, cat, bird, automobile, and airplane, respectively. (b) Examples from the MNIST data set. From left to right, they are from the categories of 0 . . . 9, respectively. (c) Examples from the STL-10 data set. From left to right, they are from categories of airplane, bird, car, cat, deer, dog, horse, monkey, ship, and truck, respectively. (d) Examples from the Caltech-101 data set. From left to right, they are from categories of accordio, bass, camera, dolphin, elephant, ferry, gramophone, headphone, lamp, and sunflower, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Trajectories of the PSOAO algorithm in automatically discovering the architectures of FCAE on the chosen benchmark data sets. (a) Evolution trajectories on the CIFAR-10 data set. (b) Evolution trajectories on the MNIST data set. (c) Evolution trajectories on the STL-10 data set. (d) Evolution trajectories on the Caltech-101 data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Classification accuracy comparisons between the x-reference and gBest-reference velocity updating strategy in the designed PSOAO method. (a) Classification accuracy of SFCAE-1 by truncating gBest and x. (b) Classification accuracy of SFCAE-2 by truncating gBest and x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Update the pBest i and g Best;</figDesc><table><row><cell cols="2">1 x ←Initialize the particles based on the proposed encoding</cell></row><row><cell></cell><cell>strategy;</cell></row><row><cell cols="2">2 t ← 0;</cell></row><row><cell cols="2">3 while t &lt; the maximal generation number do</cell></row><row><cell>4</cell><cell>Evaluate the fitness of each particle in x;</cell></row><row><cell>6</cell><cell>Calculate the velocity of each particle;</cell></row><row><cell>7</cell><cell>Update the position of each particle;</cell></row><row><cell>8</cell><cell>t ← t + 1;</cell></row><row><cell cols="2">9 end</cell></row><row><cell cols="2">10 Return g Best for deep training.</cell></row></table><note><p>5</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I ENCODED</head><label>I</label><figDesc>INFORMATION IN THE CONVOLUTIONAL LAYERS AND THE POOLING LAYERS OF FCAE Fig. 3. Three particles with different encoded information from PSOAO.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Algorithm 4 x-Reference Velocity Calculation Method Input: The partilce x, the g Best, the acceleration constant c 1 . Output: The gloabl search part of velocity updating. 1 r 1 ← Randomly sample a number from [0, 1]; 2 cg ← Extract the convolutional layers from g Best; 3 cx ← Extract the convolutional layers from x; , p x i ← Extract the position of the i -th convolution layer from cg and cx; 13 pos_c ← pos_c ∪ c 1 • r 1 • ( p cg ip x i ); 14 end 15 pos_ p ← Analogy the operations in lines 2-14 on the pooling layers of g Best and x;</figDesc><table><row><cell cols="2">4 pos_c ← ∅;</cell></row><row><cell cols="2">5 if |cg| &lt; |cx| then</cell></row><row><cell>6</cell><cell>c ← Initialize |cx| -|cg| convolutional layers with</cell></row><row><cell></cell><cell>encoded information of zeros;</cell></row><row><cell>7</cell><cell>cg ← Pad c to the tail of cg;</cell></row><row><cell cols="2">8 else</cell></row><row><cell>9</cell><cell>cg ← Truncate the last |cg| -|cx| convolutional layers</cell></row><row><cell></cell><cell>from cg;</cell></row><row><cell cols="2">10 end</cell></row><row><cell cols="2">11 for i = 1 to |cx| do</cell></row><row><cell>12</cell><cell>p cg i</cell></row></table><note><p><p><ref type="bibr" target="#b15">16</ref> </p>Return pos_c ∪ pos_ p.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III CLASSIFICATION</head><label>III</label><figDesc>ACCURACY OF THE PROPOSED FCAE METHOD AGAINST ITS PEER COMPETITORS ON THE CHOSEN BENCHMARK DATA SETS to be compared, the experiments with the trained model on each benchmark data set are also independently performed five times. Due to the extreme imbalance training data exist in the Caltech-101 data set, we investigate this data set based on its convention<ref type="bibr" target="#b18">[19]</ref>, i.e., investigating the classification accuracy on each category of the images, and then reporting the mean and standard derivations over the whole data set.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV CLASSIFICATION</head><label>IV</label><figDesc>ACCURACY OF FCAE-2 AGAINST PEER COMPETITORS ON THE DIFFERENT NUMBERS OF TRAINING SAMPLES FROM MNIST those on STL-10 and Caltech-101 are by SFCAE-1. Note that SFCAE-2 performs worse on STL-10 and Caltech-101 than SFCAE-1, which is caused by the much smaller numbers of training instances in these two benchmark data sets, and deeper architectures are suffered from the overfitting problem.Because CIFAR-10 and MNIST are with many more training samples (50 000 in CIFAR-10 and 60 000 in MNIST), a deeper architecture naturally results in the promising classification accuracy. In summary, when the architecture of the proposed FCAE method is optimized by the designed PSOAO algorithm, FCAE shows superior performance among its peer competitors on all the four image classification benchmark data sets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI ARCHITECTURE</head><label>VI</label><figDesc>CONFIGURATION OF SFCAE-1 ON THE CIFAR-10 DATA SETTABLE VII ARCHITECTURE CONFIGURATION OF SFCAE-2 ON THE CIFAR-10 DATA SET STL-10 and Caltech-101 data sets, respectively. Note that the SAME convolutional layers, the max pooling layers and the strides with 1 × 1 are used based on the experimental settings, therefore, these configurations are not shown in these tables. The obtained architectures are based on our designed encoding strategy. The encoding strategy in this paper is designed based on the architectures of the traditional CNNs that are</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VIII ARCHITECTURE</head><label>VIII</label><figDesc>CONFIGURATION OF SFCAE-1 ON THE MNIST DATA SET TABLE IX ARCHITECTURE CONFIGURATION OF SFCAE-2 ON THE MNIST DATA SET TABLE X ARCHITECTURE CONFIGURATION OF SFCAE-1 ON THE STL-10 DATA SET TABLE XI ARCHITECTURE CONFIGURATION OF SFCAE-2 ON THE STL-10 DATA SET</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE XII ARCHITECTURE</head><label>XII</label><figDesc></figDesc><table><row><cell>CONFIGURATION OF SFCAE-1 ON</cell></row><row><cell>THE CALTECH-101 DATA SET</cell></row><row><cell>TABLE XIII</cell></row><row><cell>ARCHITECTURE CONFIGURATION OF SFCAE-2 ON</cell></row><row><cell>THE CALTECH-101 DATA SET</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Supposing the optimal performance of a neural network-based model is achieved through T * training epochs. The deep training refers to the model has experienced T training epochs, where T is equal to or greater than T * .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The test data of Caltech-101 data set are the entire data set excluding from the training set.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the Marsden Fund of New Zealand Government under Contract VUW1209, Contract VUW1509, and Contract VUW1615, in part by Huawei Industry Fund under Grant E2880/3663, in part by the University Research Fund of Victoria University of Wellington under Grant 209862/3580 and Grant 213150/3662, in part by the National Natural Science Fund of China for Distinguished Young Scholar under Grant 61625204, and in part by the National Natural Science Foundation of China under Grant 61803277.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bing Xue (M'10) received the B.Sc. degree from the Henan University of Economics and Law, Zhengzhou, China, in 2007, the M.Sc. degree in management from Shenzhen University, Shenzhen, China, in 2010, and the Ph.D. degree in computer science from the Victoria University of Wellington, Wellington, New Zealand, in 2014.</p><p>She is currently an Associate Professor with the School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand. She has published over 100 papers published in fully refereed international journals and conferences and most of them are on evolutionary feature selection and construction. Her current research interests include evolutionary computation, feature selection, feature construction, multiobjective optimization, image analysis, transfer learning, data mining, and machine learning. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit. Model</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Auto-association by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Autoencoders, minimum description length and Helmholtz free energy</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transformation invariant autoassociation with application to handwritten character recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Milgram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="992" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Greedy layerwise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1915" to="1929" />
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis</title>
		<meeting>IEEE Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2015-06">Jun. 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mutualinformation-based registration of medical images: A survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P W</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B A</forename><surname>Maintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="986" to="1004" />
			<date type="published" when="2003-08">Aug. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing images using color coherence vectors</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM Int. Conf. Multimedia, 1997</title>
		<meeting>4th ACM Int. Conf. Multimedia, 1997</meeting>
		<imprint>
			<biblScope unit="page" from="65" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bag of events: An efficient probability-based feature extraction method for AER image sensors</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="791" to="803" />
			<date type="published" when="2017-04">Apr. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stacks of convolutional Restricted Boltzmann Machines for shift-invariant feature learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranjbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="2735" to="2742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Information processing in dynamical systems: Foundations of harmony theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
		<idno>CU-CS-321-86</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. Colorado Boulder</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>Boulder, CO, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Annu. Int. Conf. Mach. Learn</title>
		<meeting>26th Annu. Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010-06">Jun. 2010</date>
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive deconvolutional networks for mid and high level feature learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="2018" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparse coding with an overcomplete basis set: A strategy employed by V1?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3311" to="3325" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning convolutional feature hierarchies for visual recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1090" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Stacked convolutional denoising auto-encoders for feature representation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1017" to="1027" />
			<date type="published" when="2016-04">Apr. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1409.1556" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Gaussian Processes for Machine Learning</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On Bayesian methods for seeking the extremum</title>
		<author>
			<persName><forename type="first">J</forename><surname>Močkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Optim. Techn. IFIP Tech. Conf</title>
		<meeting>Optim. Techn. IFIP Tech. Conf<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="400" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Algorithms for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2546" to="2554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sequential model-based optimization for general algorithm configuration</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LION</title>
		<meeting>LION</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolving unsupervised deep neural networks for learning meaningful representations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<idno type="DOI">10.1109/TEVC.2018.2808689</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput., to be published</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Structure learning for deep neural networks based on multiobjective optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2450" to="2463" />
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A multiobjective sparse feature learning model for deep neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3263" to="3277" />
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<ptr target="https://openreview.net/pdf?id=S1c2cvqee" />
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Learning Represent</title>
		<meeting>Int. Conf. Learning Represent</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1703.01041" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A hypercube-based encoding for evolving large-scale neural networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>. D'ambrosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gauci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Life</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="212" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Evolving multimodal controllers with HyperNEAT</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Pugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Annu</title>
		<meeting>15th Annu</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep clustered convolutional kernels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rigazio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Feature Extraction, Modern Questions Challenges</title>
		<meeting>Feature Extraction, Modern Questions Challenges</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="160" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Convolution by evolution: Differentiable pattern producing networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Genet</title>
		<meeting>Genet</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int Conf</title>
		<meeting>IEEE Int Conf</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="760" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th Int. Symp. Micro Mach. Hum. Sci. (MHS)</title>
		<meeting>6th Int. Symp. Micro Mach. Hum. Sci. (MHS)</meeting>
		<imprint>
			<date type="published" when="1995-10">Oct. 1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Particle swarm optimization for feature selection in classification: A multi-objective approach</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1656" to="1671" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Particle swarm optimization based AdaBoost for face detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Mohemmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint>
			<date type="published" when="2009-05">May 2009</date>
			<biblScope unit="page" from="2494" to="2501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A novel particle swarm optimisation approach to detecting continuous, thin and smooth edges in noisy images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Setayesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">246</biblScope>
			<biblScope unit="page" from="28" to="51" />
			<date type="published" when="2013-10">Oct. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Evolving artificial neural networks using an improved PSO and DPSO</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1054" to="1060" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Comparison of genetic algorithm and particle swarm optimizer when evolving a recurrent neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rodebaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Soule</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation-GECCO</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">200</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An improved PSO-based ANN with simulated annealing technique</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xiurun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="527" to="533" />
			<date type="published" when="2005-01">Jan. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A hybrid of genetic algorithm and particle swarm optimization for recurrent network design</title>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Juang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="997" to="1006" />
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Application of evolutionary neural network method in predicting pollutant levels in downtown area of Hong Kong</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="387" to="400" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Using the particle swarm optimization technique to train a recurrent neural model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Salerno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Tools Artif. Intell</title>
		<meeting>Int. Conf. Tools Artif. Intell</meeting>
		<imprint>
			<date type="published" when="1997-11">Nov. 1997</date>
			<biblScope unit="page" from="45" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cooperative co-evolution with differential grouping for large scale optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Omidvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="393" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. Toronto</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Toronto, ON, Canada</pubPlace>
		</imprint>
	</monogr>
	<note>Tech. Rep. 2009-TR-learning-features</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Int. Conf</title>
		<meeting>14th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="70" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Tuning the generation of Sobol sequence with Owen scrambling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Atanassov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karaivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ivanovska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Large-Scale Scientific Computing</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="459" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning: An Introduction</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An experimental study on hyper-parameter optimization for stacked auto-encoders</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yen</surname></persName>
		</author>
		<idno type="DOI">10.1109/CEC.2018.8477921</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Congr</title>
		<meeting>IEEE Congr</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="950" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Orton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1943" />
			<date type="published" when="2013-08">Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Defining a standard for particle swarm optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bratton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Swarm Intell. Symp</title>
		<meeting>IEEE Swarm Intell. Symp<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-04">Apr. 2007</date>
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Int. Conf</title>
		<meeting>13th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Int. Conf</title>
		<meeting>14th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1603.04467" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Convolutional deep belief networks on cifar-10</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/~kriz/conv-cifar10-aug2010.pdf" />
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Unsupervised learning of invariant feature hierarchies with applications to object recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2007-06">Jun. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">His current research interests include evolutionary algorithms, deep learning, and evolutionary deep learning. Dr. Sun is the Leading Organizer of the First Workshop on Evolutionary Deep Learning and the Special Session on Evolutionary Deep Learning and Applications in CEC19</title>
	</analytic>
	<monogr>
		<title level="m">Yanan Sun (S&apos;15-M&apos;18) received the Ph.D. degree in engineering from Sichuan University</title>
		<meeting><address><addrLine>Chengdu, China; Wellington, New Zealand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>He is currently a Research Fellow with the School of Engineering and Computer Science, Victoria University of Wellington. He is the Founding Chair of the IEEE CIS Task Force on Evolutionary Deep Learning and Applications</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
