<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Histograms of Oriented Gradients for Landmine Detection in Ground-Penetrating Radar Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Torrione</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engi-neering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Kenneth</forename><forename type="middle">D</forename><surname>Morton</surname><genName>Jr</genName></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engi-neering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Rayn</forename><surname>Sakaguchi</surname></persName>
							<email>rayn.sakaguchi@duke.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engi-neering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Leslie</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
							<email>lcollins@duke.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engi-neering</orgName>
								<orgName type="institution">Duke University</orgName>
								<address>
									<postCode>27708</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Histograms of Oriented Gradients for Landmine Detection in Ground-Penetrating Radar Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">55BCEFC3A347F27EFE80427398334A40</idno>
					<idno type="DOI">10.1109/TGRS.2013.2252016</idno>
					<note type="submission">received October 2, 2012; revised February 6, 2013; accepted March 4, 2013.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T04:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computer vision</term>
					<term>edge histogram descriptors</term>
					<term>ground-penetrating radar (GPR)</term>
					<term>histogram of oriented gradients (HOG)</term>
					<term>random forest</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ground-penetrating radar (GPR) is a powerful and rapidly maturing technology for subsurface threat identification. However, sophisticated processing of GPR data is necessary to reduce false alarms due to naturally occurring subsurface clutter and soil distortions. Most currently fielded GPR-based landmine detection algorithms utilize feature extraction and statistical learning to develop robust classifiers capable of discriminating buried threats from inert subsurface structures. Analysis of these techniques indicates strong underlying similarities between efficient landmine detection algorithms and modern techniques for feature extraction in the computer vision literature. This paper explores the relationship between and application of one modern computer vision feature extraction technique, namely histogram of oriented gradients (HOG), to landmine detection in GPR data. The results presented indicate that HOG features provide a robust tool for target identification for both classification and prescreening and suggest that other techniques from computer vision might also be successfully applied to target detection in GPR data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE detection of buried explosives is of significant con- cern in both military and humanitarian applications. In the military sphere, recent events have illustrated the destructive efficacy of buried improvised and classical explosives (e.g., landmines), and both the humanitarian and military scope of these threats continues to grow <ref type="bibr" target="#b0">[1]</ref>. Unlike classic landmines, which are produced en masse and usually contain at least small amounts of metal, modern homemade explosives are typically constructed in an ad hoc manner, and may contain no metal content whatsoever.</p><p>Electromagnetic induction (EMI) based sensing of buried threats is an efficient technique for subsurface threat detection, and improved modeling and related signal processing have illustrated the potential for EMI to detect very small amounts of metal <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref>. However, the increase in the use of purely nonmetallic threats and the prevalence of metallic anthropic clutter in conflict and post-conflict regions renders detection based solely on EMI sensing difficult.</p><p>Ground-penetrating radar (GPR) <ref type="bibr" target="#b5">[6]</ref> is a highly complementary phenomenology to EMI modeling. Unlike EMI, which detects eddy currents induced in buried conductors, GPR measures reflections from changes in the electromagnetic properties of the subsurface environment. As a result, GPR sensing is suitable for finding nonmetallic threats as long as the electromagnetic properties of the buried object are sufficiently different from the surrounding soil. However, the sensitivity of GPR to changing subsurface properties results in additional responses from buried roots, rocks, pockets of moisture, and other subsurface changes. As a result, without proper additional processing, GPR detection of buried threats can be subject to high false alarm rates. A significant body of research has previously been undertaken to successfully detect buried threats in GPR data while reducing false alarm rates. This previous research can roughly be divided into three broad categories: model inversion, explicit hyperbola detection, and statistical feature-based techniques.</p><p>Physics-and model-inversion-based techniques for GPR processing are very popular in the research community due to strong underlying theoretical foundations (e.g., Maxwell's equations, Green's functions) and the wide variety of techniques available to solve the resulting propagation equations. Recent developments in the field of physics-based inversion include novel techniques for subsurface object shape and size estimation, even under rough surfaces using iterative optimization methods <ref type="bibr" target="#b6">[7]</ref>. Significant work has also been investigated to automatically determine the properties of the subsurface, including layer identification and electromagnetic propagation properties <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Inversion techniques and their specific application in demining techniques have also been explored in <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>. Despite these advances, physicsbased inversions of GPR signals are not widely utilized in fielded or real-time data collection systems for several reasons. First, many physics-based inversion models rely on accurate estimates (or computationally expensive iterative estimation) of the subsurface electromagnetic properties of the soil. These properties are difficult to estimate, and even when accurate large-scale estimates are available, the properties of most soils of interest can change drastically over small regions, making large-scale estimates irrelevant. Furthermore, despite recent advances, the computational expense associated with physics-based GPR data inversion is significant, and precludes most real-time operation. IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING Hyperbola-based landmine detection methods are another popular technique for object identification in GPR data. Hyperbola-based techniques can be motivated by considering a simplification of the general GPR propagation problem wherein objects of interest are modeled as point-scatterers, and the transmission medium is assumed to be homogeneous. Under these simplifying assumptions, the time of arrival for responses from buried objects constitute a hyperbola as the sensor moves across the object, and the parameters of the resulting hyperbola contain information about relevant object depth and soil properties. Typical approaches to hyperbola identification in GPR make use of modifications to the Hough transform <ref type="bibr" target="#b12">[13]</ref> or alternative fitting techniques <ref type="bibr" target="#b13">[14]</ref>, to avoid computational complexity issues, account for uncertain numbers of reflectors, and mitigate variations due to unknown parameters. Additional modifications to account for refraction can also be considered <ref type="bibr" target="#b14">[15]</ref>. However hyperbola-based techniques also face significant shortcomings for fielded operations. First, as discussed above, assumptions of homogeneous transmission media are routinely violated in soils of any complexity, which significantly obscures the theoretical hyperbolic responses. Also, at the sampling rates of interest, most buried threats are not well represented by point sources, and responses from nonmetal objects contain constructive and destructive interference which also obscure idealized hyperbolic responses.</p><p>Since responses from buried objects are highly variable, most effective fielded algorithms for landmine identification in GPR data use statistical feature extraction (often motivated implicitly or explicitly from the roughly hyperbolic nature of target responses) combined with machine learning techniques to develop algorithms to classify new responses as threats or nonthreats <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b21">[22]</ref>. In our opinion, these techniques should not be seen as a rejection of the physics-based or hyperbolic modeling of target responses, but should be considered a natural extension of these techniques that take into account the noise and uncertainty inherent in realistic operational conditions. In actuality, many of the most successful techniques for fielded target identification in GPR data are based on exploiting spatial variations in target responses that are best understood by recourse to the underlying physics. For example, one of the first large-scale explorations of statistical learning for target detection in GPR data resulted in the application of hidden Markov models (HMMs) to detect and classify landmine responses based on a statistical representation of their characteristic hyperbolic shape <ref type="bibr" target="#b20">[21]</ref>. Another equally efficient technique exploits the same rising/flat/falling structure as the HMM, but uses windows of fixed length for feature extraction <ref type="bibr" target="#b21">[22]</ref>. These techniques have been shown to have very robust performance over very large data collections containing difficult GPR target populations <ref type="bibr" target="#b22">[23]</ref>.</p><p>The success of techniques such as in <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b21">[22]</ref> illustrate the potential for statistical modeling and machine learning to provide robust results for object detection in GPR data. In a parallel vein, modern advances in the field of computer vision also make use of statistical object descriptors coupled with machine learning to develop accurate algorithms for both instance and category recognition (see <ref type="bibr" target="#b23">[24]</ref> for recent summary and extensive bibliography). Notable examples include: 1) the scale invariant feature transform (SIFT) and a related method; 2) speeded up robust features (SURF) <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> which provide a low-dimensional representation of visual images for instance matching with images; 3) Viola-Jones' cascade of simple features used for robust face detection <ref type="bibr" target="#b26">[27]</ref>; and 4) histogram of oriented gradients (HOG) which has been successfully used for pedestrian detection <ref type="bibr" target="#b27">[28]</ref>.</p><p>In the context of subsurface threat detection, HOG features are particularly interesting since analysis of <ref type="bibr" target="#b21">[22]</ref> and <ref type="bibr" target="#b27">[28]</ref> illustrate that effective feature extraction techniques from two disparate image processing fields (MPEG encoding and pedestrian detection in images) share very similar underlying mathematical and theoretical structure. These features are also widely utilized in the field of computer vision and video processing, so are necessarily computationally inexpensive and efficient. This observation naturally leads to the question: can HOG and other tools from the computer vision literature be successfully brought to bear on the problem of landmine detection in GPR data?</p><p>The size and scope of modern computer vision techniques is enormous, so this paper focuses only on the specific case of HOG features. The rationale for an initial focus on HOG features is motivated by the similarity of HOG to preexisting feature extraction techniques [e.g., edge histogram descriptor (EHD)], and also to several aspects of HOG features which make them particularly well suited to landmine detection in GPR. For example, unlike SIFT, SURF, and others, HOG features are typically applied as a dense feature extraction technique. This enables HOG features to be extracted without previous interest point identification, which is an unsolved though interesting problem in the GPR literature <ref type="bibr" target="#b28">[29]</ref>. Furthermore, unlike many modern feature descriptors, HOG features are fairly robust to moderate changes in object location within a HOG window. This enables the use of preexisting techniques for depth-binning in GPR classification. This paper shows how HOG features, coupled with off-the-shelf classification techniques, can enable significant improvements in target classification. Although this paper focuses on HOG features, we believe that, with additional research, other techniques from computer vision literature may have an important role to play in GPR-based subsurface threat detection.</p><p>Historically, for vehicle-mounted GPR processing to maintain speeds commensurate with operationally relevant rates of advance, computationally simple algorithms were utilized to rapidly process large volumes of GPR data and down-select locations of interest, alarms, which were then utilized in more advanced feature-based processing. This separation between prescreening and classification has always seemed artificial, as it could be advantageous to incorporate advanced statistical models into prescreening if feature extraction and classification could both be accomplished in a computationally tractable manner. This paper is the first to develop a technique for threat identification in vehicle-mounted GPR data that is fast enough and robust enough to operate as a prescreener (on every pixel) versus only at previously flagged locations of interest. The primary novel advances contained in this paper include the first application of techniques explicitly developed for feature extraction and object classification techniques from the The remainder of this paper is organized as follows. Section II describes the ground penetrating radar used in this paper, and the GPR data under consideration. Section III describes the HOG features used in this paper. Section IV describes the application of HOG features to GPR data and how these features can be used for object classification as well as during pre-screening. Section V presents results from the HOG prescreener as well as HOG-based classification using cross validation on a large number of prescreener flagged objects of interest, and extends the preprocessing approaches described in Section IV for application to EHD features. Section VI presents conclusions, and describes several possible avenues for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. GPR SYSTEM AND DATA UNDER CONSIDERATION</head><p>All of the data considered in this work were collected with a pulsed, time-domain, bi-static antenna, with a very wide bandwidth, and very low radar self-signature. A-scan's from each antenna are time-gated to sense approximately 1 m in air, using 512 temporal samples.</p><p>This work focusses on a vehicle-mounted array with 51 antenna pairs spaced approximately 5 cm apart. As the vehicle on which the antenna array is mounted moves (down-track) each of the 51 antenna pairs is sampled (approximately simultaneously) once every 5 cm of vehicle motion. This collection procedure creates a 3-D data set of size 512 × 51 × n dt samples where ndt represents the number of down-track scans collected.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates sample data collected with the GPR at a western U.S. test site. The dark red band at time sample 150 represents the response from the air/ground interface. Time samples before the interface correspond to the GPR signal propagating through air, and time samples after the interface represent propagation and reflection in the soil. A response from an antitank landmine buried at 3 can be seen between time samples 200 and 250 and down-track samples 30-40. The characteristic hyperbolic response of the object is visible as the antenna moves across it. The goal of this research is to successfully identify responses such as the one in Fig. <ref type="figure" target="#fig_0">1</ref> and discriminate these from other similar responses from subsurface clutter such as rocks, roots, and other possible confounding objects.</p><p>For the purposes of applying computer vision approaches to GPR data, it will be convenient to treat a GPR image like the one in Fig. <ref type="figure" target="#fig_0">1</ref> as a 2-D matrix of data. Throughout the following sections, let I represent an image (or 2-D block of GPR data, in which case I (i, j ) may represent the received field, often in volts, or units proportional to volts) of size [n i , n j ], and let I (i, j ) represent the image intensity value (or amplitude of the GPR signal) at location i, j . For time-domain GPR data, typically the first dimension of I corresponds to propagation time, or (roughly) depth into the transmission media, and the second dimension may represent distance traveled (downtrack) or channel (cross-track), e.g, [n i , n j ] = [n t , n dt ]. In the following, when HOG features are extracted from a point near an image boundary, pixels outside the bounds of the image are generated via symmetric padding, e.g., I (-5, 1) = I (5, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. COMPUTER-VISION-BASED FEATURE EXTRACTION TECHNIQUES</head><p>A large number of very different techniques have previously been proposed for extracting low-dimensional representations of images and image patches (see <ref type="bibr" target="#b23">[24]</ref> for detailed examples and bibliography). Many of these techniques were designed for the problem of instance recognition, or identifying the exact same object in two different images. For example, techniques such as SIFT <ref type="bibr" target="#b24">[25]</ref> and SURF <ref type="bibr" target="#b25">[26]</ref> were developed to enable rapid automatic matching between image patches which have undergone transformations between images, including rotations and scaling. Typically, the instance recognition problem is approached by extracting descriptors from a sparse set of interest points (e.g., <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b29">[30]</ref>) and then matching descriptors across different images. In instance recognition, interest point extraction can significantly simplify processing by ignoring regions which are not identifiable, flagging regions which are interesting, and by reducing the overall computation time.</p><p>In contrast to instance recognition, the more challenging problem of object class recognition requires classifying distinct objects within an image as either belonging to or not belonging to a certain class. Category recognition is more complicated than instance recognition since robust classification requires modeling the wide statistical variability of objects within a class (e.g., chairs) compared to the instance recognition problem which only requires identifying changes due to transformations of a particular chair. For example, a commonly studied and challenging class recognition problem in computer vision is the robust identification of pedestrians from vehicle-mounted video data (see <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref> for a recent review). In contrast to instance recognition, most algorithms for class recognition utilize feature descriptors extracted densely throughout the image, since it is difficult to a priori discriminate between informative and noninformative regions for the class-recognition problem.</p><p>The landmine detection problem in GPR can be seen as an example of object class recognition, where the system is presented with a series of responses from the subsurface and must identify which GPR images contain landmine responses. With this insight, a wide number of possible algorithms from the computer vision literature could be brought to bear on the landmine detection problem in GPR. To bound the problem and our current research, this paper focuses on the application of HOG features to target classification in GPR data, though as we specify in the conclusions, the computer vision literature provides ample opportunities for alternative feature extraction and object classification approaches.</p><p>This section outlines the basic implementation of HOG features, describes their application to GPR data, and discusses classification algorithms suitable for processing HOG features. Section IV presents details for applying these techniques to GPR data, and Section V presents results obtained from each of the techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Histogram of Oriented Gradients</head><p>HOG features <ref type="bibr" target="#b27">[28]</ref> provide a concise but powerful image representation for general object classification. They have found significant application in the field of pedestrian identification <ref type="bibr" target="#b27">[28]</ref>, where they have continued to provide one of the more robust feature extraction techniques even in recent analyses <ref type="bibr" target="#b31">[32]</ref>.</p><p>HOG features are based on gradient angle and magnitude distributions, and in visual data they are robust due to the gradient's natural invariance to slight changes in ambient lighting and color variations. Consider an image I and gradient estimation filters h x = [ -1, 0, 1], and h y = [ -1, 0, 1] T . Let g x and g y represent the gradient images generated by</p><formula xml:id="formula_0">g x = I * h x and g y = I * h y</formula><p>where * represents convolution. The magnitude of the gradient at each pixel can be calculated as</p><formula xml:id="formula_1">G(i, j ) = g x (i, j ) 2 + g y (i, j ) 2</formula><p>and the dominant gradient angle at each pixel can be estimated by</p><formula xml:id="formula_2">θ(i, j ) = tan -1 g y (i, j ) g x (i, j ) . (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>For some applications, the sign of the gradients, and thus values of θ between 0°and 360°, may be germane to the detection problem. For example, in detection problems where objects of interest can be assumed to always be darker than the background regions, gradients will always tend to flow toward background regions. In most applications, however, the sign of the gradients g x and g y provides little or no discriminative power, so θ(i, j ) can be calculated in the range 0 and π radians (versus 0 to 2π). HOG features can then be generated entirely on the basis of the gradient magnitude G and gradient angles θ at each pixel. The primary insight provided by HOG feature extraction is that, while individual G(i, j ) and θ(i, j ) are highly variable and subject to significant variations across nearby (i, j ) locations, even for very similar images, the aggregate statistics of the spatial distribution of the gradient angles and magnitudes over small regions in similar images provide quite robust descriptors of those regions.</p><p>Consider n θ angle bins between 0°and 180°(or as discussed above, potentially, between 0°and 360°). HOG descriptors encapsulate the local statistics of the gradient angles and magnitude by allowing each pixel to vote for a specific angle bin, with a vote magnitude proportional to the gradient magnitude at that pixel. Let the edges of the n θ bins correspond to n θ + 1 edge values, {φ k } = {180k/n θ } k = 0 . . . n θ , then a 3-D vote matrix of size n x × n y × n θ can be defined as</p><formula xml:id="formula_4">V (i, j, k) = G(i, j )δ(φ k-1 &lt; θ(i, j ) ≤ φ k ), k = 1 . . . n θ</formula><p>where δ(x) takes value 1 when the input argument is true, and 0 when the input argument is false.</p><p>Resulting individual pixel votes can be smoothed using bilinear interpolation and are then aggregated across subregions of the image referred to as cells, which can be rectangular or radial. Aggregating across a particular cell c is accomplished by</p><formula xml:id="formula_5">H 1 (c, k) = (i, j )∈c V (i, j, k).</formula><p>In many computer vision application areas, local changes in ambient lighting can have a significant effect on the magnitudes of feature responses, and this holds true for the gradient magnitudes used in HOG descriptors. Similarly, signal magnitudes in GPR data vary drastically as a function of propagation distance. As a result, normalizing HOG descriptors is fundamental to achieving robust performance. HOG descriptors can be normalized using groups of neighboring cells, also called blocks. Let N(c) represent the set of cells immediately surrounding the cell of interest; then the normalized HOG values can be calculated using</p><formula xml:id="formula_6">H (c, k) = H 1 (c, k)/ ⎛ ⎝ c i ∈N(c) H 1 (c i ) 2 2 + ∈ 2 ⎞ ⎠<label>(2)</label></formula><p>where</p><formula xml:id="formula_7">H 1 (c) represents the rasterized vector [H 1 (c, 1), H 1 (c, 2), . . . , H 1 (c, n θ )] T .</formula><p>In <ref type="bibr" target="#b31">[32]</ref>, the authors utilize feature descriptors v, consisting of concatenations of H (c, k) over each N(c), and normalize these vectors by their local cell regions. The resulting complete descriptor vector then consists of multiple repeated H (c, k), each normalized with respect to a different set of cells. In this paper, for application to GPR processing that step was found to not significantly affect performance, so the complete feature vector is simply a rasterized vector of H (c, k), as calculated in <ref type="bibr" target="#b1">(2)</ref>. For more information about the HOG feature descriptors and a more detailed description of the HOG extraction process, the interested reader is referred to <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relationship to Edge Histogram Descriptors</head><p>EHD features <ref type="bibr" target="#b32">[33]</ref> are a technique used in the MPEG codec to identify and contrast regions of varying texture, which were originally applied to landmine detection in GPR data in <ref type="bibr" target="#b21">[22]</ref>, and have continued to perform well over a wide range of operating conditions <ref type="bibr" target="#b22">[23]</ref>. Like HOG features, EHD features are also based on describing an image through a histogram of gradients (edges). However there are several important distinctions to be made between the EHD and HOG techniques. First, EHD features rely on a global threshold on gradient magnitudes to determine whether a particular pixel's gradient has an opportunity to vote for its corresponding edge bin. These global thresholds can be difficult to set and tune, and require data normalization prior to feature extraction. Second, unlike the case with HOG features, where each pixel votes with strength proportional to the local (normalized) gradient, in EHD features the each pixel receives equal vote regardless of gradient magnitude. HOG features also introduce the notions of bins and cells (see above) which enable additional spatial information to be encoded in HOG features that is not present in EHD features (e.g., temporal as well as downtrack information). Finally, the actual bins used in EHD are typically fixed to correspond to "diagonal," "anti-diagonal," "vertical," "horizontal," and "nonedge" orientations, whereas in HOG features the number and size of the individual bins is a parameter available for tuning. Extension of EHD features to arbitrary angle orientations requires the development of new edge extraction filters, which is not straightforward. This adds significant flexibility to HOG features for applications where the inter sample spacing in different orientations is not known a priori, and/or subtle shifts in gradient magnitude may be important for classification.</p><p>On a more practical level, the preprocessing steps developed in this paper for application with HOG features can significantly simplify algorithm development, training, and implementation for fielded application compared to current implementations of EHD features. For example, in <ref type="bibr" target="#b21">[22]</ref> it was necessary to manually label the specific depth regions where target responses appeared in a very large body of GPR images to obtain prototype GPR segments for algorithm training. Manual labeling of GPR images is time consuming, error prone, and subject to variations between individual user preferences. In contrast, this paper shows how features can be reliably extracted from automatically flagged GPR depth segments (Section IV-B). This significantly simplifies algorithm training which often requires data from thousands landmine responses, and streamlines algorithm modifications as new data becomes available. Finally, <ref type="bibr" target="#b21">[22]</ref> used a specialpurpose classification algorithm based on a combination of self-organizing maps <ref type="bibr" target="#b33">[34]</ref>, and fuzzy K-NN classification. Results from this paper based on HOG features shows that both HOG and EHD features are more easily separated using standard off-the-shelf classification techniques such as random forests <ref type="bibr" target="#b34">[35]</ref>, and can even be well separated with linear classifiers, such as partial-least-squares discriminant analysis (PLS-DA) <ref type="bibr" target="#b35">[36]</ref>. Linear classification is particularly of interest, since extremely fast classification algorithms are required for techniques like HOG features to be applicable in GPR-based prescreening, and as the remainder of this paper illustrates, HOG features coupled with PLS-DA classifiers provide the first such example of a feature-based prescreening algorithm capable of operating in realtime on the large volumes of data generated by vehicle mounted GPR arrays.</p><p>IV. APPLICATION OF HOG FEATURES TO GPR DATA GPR-based object classification using HOG features requires incorporating additional information from our knowledge of GPR signals and propagation to understand how to best extract target and nontarget examples of subsurface responses, which subset of imagery at an alarm location to extract, proper data preprocessing, and combinations of downand cross-track imagery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Spatial Locations for Feature Extraction</head><p>Developing a classification algorithm based on HOG features to detect possible threats in GPR data requires a large body of data from both target [e.g., landmines, other buried explosives] and nontarget responses. For the data considered here, it is relatively simple to identify target spatial locations since their GPS coordinates are known a priori and the GPR data is collected with accurate GPS locations.</p><p>Determining which nontarget responses to use during training offers more options. One approach to generate nontarget responses might be to randomly sample the remaining nontarget portions of the large volume of GPR data available. One could then undertake a bootstrapping approach to identify interesting regions of the subsurface for training (see <ref type="bibr" target="#b36">[37]</ref> for an example of this process applied to video data). However, the vast majority of GPR data collected over testing lanes is relatively homogeneous, and the majority of randomly sampled points are therefore uninteresting from a machine learning perspective.</p><p>As discussed previously, prescreening algorithms are computationally inexpensive algorithms designed to achieve high probability of detection at moderate to high false alarm rates. False alarms from prescreening algorithms are typically due to surface or subsurface nontarget anomalies, rapid changes in sensor height, radar-ground coupling, or changes in the subsurface structure. As a result, prescreener false alarms provide a rich source of anomalous data likely to confuse classification algorithms, and these provide a good source of training data for machine learning algorithms. The remainder of this paper extracts nontarget data for training using spatial locations false alarms from a prescreener developed at and based on <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Temporal Locations for Feature Extraction</head><p>Given a spatial location around a target or prescreener false alarm, one can easily extract a cube of data corresponding to that location. However, significant portions of a GPR response around a location of interest typically contain little to no information about the object (Fig. <ref type="figure" target="#fig_0">1</ref>). As a result, it is typically necessary to extract regions of interest from within a typical B-scan (collection of A-scans) that are believed to contain information regarding the object underconsideration. For the HOG features, additional preprocessing must be used to select different subwindows of the sensor data for further processing.</p><p>In the computer vision literature, the localization of an object or point of interest is often achieved using keypoint identification methods which seek to identify corner or bloblike regions <ref type="bibr" target="#b23">[24]</ref>. However, based on some initial investigations, corners and blobs do not appear to be particularly well suited for interest point identification in GPR data <ref type="bibr" target="#b28">[29]</ref>. Although GPR-specific keypoint identification is an interesting field for further study, it is beyond the scope of this paper. Instead, since subsurface objects typically result in larger magnitude GPR responses than the surrounding homogeneous soils (since responses from dielectric discontinuities cause reflections of significant magnitude), this paper uses a smoothed local signal energy metric to identify the three largest energy peaks in the central A-scan closest to an anomalous response as locations around which to extract HOG features. Each extracted window is of size 54 × 24 image pixels, though this is later reduced to 18 × 24 pixels (Section IV-C). The original window size of 54 × 24 pixels was chosen based on visual analysis of multiple target responses. Responses from the targets of interest often span 50 or so samples temporally, and larger targets (e.g., buried shells) often have responses spanning 24 samples (about 1.2 m) spatially. Although for general application these parameters should be selected based on typical responses from the radar under consideration, investigations undertaken during algorithm development indicated only slight performance sensitivity to the precise size of the windows utilized. This process is shown visually in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>The process described above is used during training to determine temporal locations at which to extract data representative of target and nontarget responses. During testing, the HOG features are extracted from a fixed set of windows of size 54 × 24, which overlap 50% in the vertical along the A-scan corresponding to the prescreener alarm. The final decision at each spatial location is made by first processing each depth window along the A-scan of interest, and then taking the average of the top three confidences to create a final statistic. This process was developed based on empirical results, and agrees closely with other approaches used in the literature, e.g., <ref type="bibr" target="#b21">[22]</ref>. As with many GPR-processing applications, both the training and testing procedures used here are beset by logistical problems necessitating ad hoc solutions, e.g., the selection of positive examples with smoothed energy, and aggregating over classifier confidences using order statistics. In actuality these problems can be seen as symptoms of the underlying multipleinstance nature of the target identification problem <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>; see Section VI for further discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image Resampling</head><p>Because of the nature of typical image acquisition in visual imagery it is common to assume a priori that pixel values are likely to be equally variable in any of the cardinal directions (e.g., in the classic four-element neighborhood). This assumption does not carry over to processing GPR data since GPRs often use radically different spatial and temporal sampling rates, so variation along the y-axis (time) and the x-axis (space) cannot be assumed to be commensurate. For example, in the top left image in Fig. <ref type="figure" target="#fig_2">3</ref>, the temporal sampling rate (y-axis) is much higher than the spatial sampling rate (x-axis), so derivatives calculated along the y-axis will have much smaller magnitudes than those calculated along the Fig. <ref type="figure">4</ref>. Sample distribution of features in HOG histogram bins after different amounts of GPR temporal downsampling. For highly temporally sampled GPR data, the gradients are dominated by horizontal or spatial differences (Bin 5). For highly downsampled GPR data, the gradients are dominated by vertical gradients (Bins 1 and 9). For this particular radar, a downsampling rate of 3 achieved approximately uniform bin histograms.</p><p>x-axis, where single pixel differences correspond to much larger changes in signal magnitude.</p><p>Since the sampling in GPR data is unequal, some spatial derivatives are artificially enhanced or reduced, certain angle estimates (1) will be overrepresented in the resulting HOG descriptors, resulting in reduced feature fidelity. It is possible to use the physics of electromagnetic propagation to analytically estimate the reduction in temporal sampling required to achieve equity between spatial and temporal sampling given known soil parameters. However, soil parameters are rarely known precisely, and can change rapidly over the course of a few meters in real data. Furthermore, simplistic analysis and downsampling ignores important factors for target identification such as the transmitted pulse width, which has significant impact since reflections of the transmitted pulse determine the data used to calculate gradients.</p><p>Instead of a physics-based approach, this paper utilizes a statistically motivated approach to determine the proper image downsampling. To achieve this we exploit the fact that, for optimal performance, the HOG feature descriptors should be approximately uniformly distributed across the histogram bins. For temporal sampling rates that are too high, the HOG feature vectors will tend toward descriptors with a great deal of weight in the horizontal bins, since derivatives along the time axis will be artificially smaller in magnitude. Similarly, for sampling rates that are too low, the HOG feature vectors will tend toward descriptors with a great deal of weight in the vertical bins, since the gradient estimates along the A-scan will be artificially large. Fig. <ref type="figure">4</ref> shows an example of this for HOG descriptors calculated from images like those shown in Fig. <ref type="figure" target="#fig_2">3</ref>. Fig. <ref type="figure">4</ref> illustrates how changing the temporal sampling rate in a GPR image alters the distribution of gradient magnitude in the resulting HOG descriptors. Based on these results, the remainder of this paper uses a temporal downsampling of three time samples, since that amount of  (a) Sample GPR subimage and (b) resulting HOG descriptor representation extracted around a target response. The HOG representation is generated by taking the resulting gradient bins and gradient magnitudes within each cell and generating lines at the appropriate angle with the appropriate magnitude. This visualization was inspired by those in <ref type="bibr" target="#b27">[28]</ref>.</p><p>downsampling provides a roughly flat distribution of HOG features for the GPR under consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Down-Track and Cross-Track Information</head><p>Although GPR data is easiest to visualize as a B-scan in two dimensions, vehicle mounted sensor arrays generate 3-D volumes of data as they move down-track. Although the HOG implementation described in this paper does not directly account for the 3-D nature of the data volume (but see Section IV), incorporating information from both the downtrack and cross-track B-scans at an object of interest significantly improves performance compared to using either Bscan orientation alone. As a result, the process described in Sections IV-A to IV-C is repeated in both the down-and crosstrack orientations, and the resulting feature descriptors are concatenated to generate a single feature vector for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Sample GPR Data and HOG Feature Descriptors</head><p>Fig. <ref type="figure" target="#fig_4">5</ref> shows an example region of interest (after downsampling) from a subsurface buried target (a) and a visual representation of the HOG votes for each subsurface block (b). The top image is of size n i × n j = 18 × 24 pixels after downsampling (Section IV-C). For each 18 × 24 image flagged for feature extraction, this application uses a grid of cells of size 3 × 4 (e.g., each cell consists of a region of 6 × 6 GPR data pixels). During cell-based normalization, overlapping regions of 3 × 3 cells are used to constitute each block. These parameter settings were chosen for numerical convenience, but results are relatively insensitive to exact parameter settings.</p><p>The example target response in Fig. <ref type="figure" target="#fig_4">5</ref> shows a clear hyperbolic response, which is exactly what the application of HOG to GPR data seeks to exploit and identify in subimages containing target responses. The bottom image in Fig. <ref type="figure" target="#fig_4">5</ref> represents the HOG histogram votes corresponding to each  The HOG representation is generated by taking the resulting gradient bins and gradient magnitudes within each cell and generating lines at the appropriate angle with the appropriate magnitude. This visualization was inspired by those in <ref type="bibr" target="#b27">[28]</ref>.</p><p>of the 12 cells in the image. For each cell, each region in the bottom plot shows the resulting HOG feature vector as an image consisting of total vote magnitude-weighted lines at the angles corresponding to each bin center, (φ k + φ k-1 )/2. In this paper, n θ = 9, so there are nine unique possible lines in each block. The resulting histogram bins clearly indicate the dominant downward-sloping gradients as a function of proximity to the target center.</p><p>Conversely, Fig. <ref type="figure" target="#fig_6">6</ref> illustrates a high-energy response from a nontarget. This response has significantly less structure than the response in Fig. <ref type="figure" target="#fig_4">5</ref>, and the resulting HOG descriptors illustrate a much less coherent distribution of HOG feature votes compared to the HOG descriptor shown in Fig. <ref type="figure" target="#fig_4">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Prescreening Versus Classification</head><p>As described in the introduction, the proposed HOG features can be utilized in both a post-prescreener anomalyclassification role, or directly as a prescreening algorithm. When used as a classification algorithm, the feature extraction during training proceeds as described in Sections IV-A-IV-D, and during testing the trained classifier is used to classify data from alarms generated by the same or a similar prescreener to the one used during training.</p><p>When HOG is used as a prescreener, the training procedure follows the same approach as above. During prescreener testing, however, HOG features are extracted from every pixel in the GPR volume, and a separate faster classification algorithm is used to classify each pixel. The resulting confidence volume is then summed along the time or depth axis to form a 2-D confidence map, which is then smoothed and normalized prior to alarm declaration <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head><p>This section presents results for both the HOG prescreening algorithm as well as postprocessing alarms using both HOG and EHD feature extraction and classification. Classification results for prescreening, HOG, EHD, and HMM algorithms. HOG performance on this dataset is very robust, dominating both the HMM and EHD algorithms. Note that, to show detail, the PD axes start at 70%, and the FAR axis only extends to 0.005 FA/m 2 . See text for additional information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>The data used in this paper was collected with the vehiclemounted GPR described in Section II. All data were collected at a western U.S. testing site with ground conditions varying between dirt, asphalt, and concrete. The data collected spans approximately 195 000 m 2 , and contains 2960 target encounters (landmine or other explosive) over 740 unique targets (the vehicle was driven over the same testing roads four times). The target populations include a mix of buried shells in varying orientations and combinations, buried explosive simulants, pressure plates, and both metallic and nonmetallic landmines. Overall, the target population is biased toward more difficult targets such as low-metal antitank landmines and low-metal pressure plates. All the targets under consideration are buried at operationally relevant depths. When the standard prescreener is run on this data, it finds about 93.5% of all targets, and generates approximately 1000 false alarms. This dataset provides a large and comprehensive body of data to enable statistical learning for both target and false alarm responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. HOG Feature Classification and Comparison ROC Curves</head><p>For target classification using HOG features, a random forest <ref type="bibr" target="#b34">[35]</ref> was iteratively trained and tested on varying subsets of the available data. Careful cross validation is crucial to obtaining robust performance estimates, and significant care must be taken when working with multiple passes over the same spatial regions, as with the GPR data considered here. Software developed at the University of Florida <ref type="bibr" target="#b22">[23]</ref> provides the capability to automatically infer distinct training and testing folds during spatial cross validation by ensuring that spatial clusters of false alarms and unique target emplacements are properly divided during cross validation. Fig. <ref type="figure" target="#fig_7">7</ref> shows the results obtained from evaluating a random forest (100 trees, 2 variable splits at nodes, central axis projection classifier; see <ref type="bibr" target="#b34">[35]</ref>) on HOG features Fig. <ref type="figure">8</ref>. Classification results comparing HOG with modified EHD features. HOG performance remains slightly better than EHD performance. The use of EHD features in the framework outlined in Section IV, along with retraining and cross validation, yields a significant improvement in algorithm performance over current fielded versions. using the cross-validation procedure outlined in the preceding paragraph. The current implementations of EHD <ref type="bibr" target="#b21">[22]</ref> and the HMM algorithm <ref type="bibr" target="#b20">[21]</ref> are shown in cyan and green, respectively.</p><p>Clearly, on this very large dataset, HOG features provide performance benefits when compared to both EHD and HMM features, although two caveats are important to note. First, the HOG algorithm used in this paper was trained in cross validation on the current dataset, while the EHD and HMM implementations correspond to the current, fixed fielded implementations and therefore were not retrained. Furthermore, on other datasets, or under other weather or soil considerations, the relative performance of these algorithms is always subject to change (see <ref type="bibr" target="#b22">[23]</ref> for a review, and <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> for options to mitigate performance variability across contexts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance Utilizing Modified EHD Features</head><p>The results in Fig. <ref type="figure" target="#fig_7">7</ref> show performance for the HOG algorithm compared to a fielded version of the EHD algorithm. However, several modifications make direct comparison of these algorithms difficult. For example, as noted previously, the algorithm described in <ref type="bibr" target="#b27">[28]</ref> makes use of several steps which were avoided during the HOG feature extraction process, including manual determination of target locations during training and the application of special-purpose classification algorithms. To more directly compare the HOG and EHD feature extraction approaches, a new version of the EHD algorithm was developed using the same EHD feature descriptor approach, but using locations and preprocessing as described in Sections IV-A, IV-B, and IV-D. Furthermore, in contrast to the special purpose algorithms developed in <ref type="bibr" target="#b21">[22]</ref>, EHD classification was performed using a random forest with the same parameters used for HOG classification. Results from this performance comparison can be seen in Fig. <ref type="figure" target="#fig_7">7</ref>.</p><p>The results in Fig. <ref type="figure" target="#fig_7">7</ref> show that, when the same preprocessing and classification approaches are used, both EHD and HOG methods perform comparably, with HOG performing slightly better at several operating points of interest. Comparison of Figs. 7 and 8 illustrate how direct comparison of feature extraction methodologies in GPR data is significantly complicated by a large number of preprocessing approaches undertaken during algorithm development. These results indicate that the preprocessing techniques developed in this paper (Section IV) can provide robust performance and simplify algorithm training and implementation. These results also suggest that HOG features provide a robust technique for feature extraction and target classification in GPR data. Furthermore, as the next sections show, the HOG feature descriptors can also be used to develop prescreening algorithms, removing the artificial divide between alarm generation and final classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. HOG Prescreener Performance and Fusion</head><p>In contrast to postprocessing alarm responses, HOG feature extraction is computationally simple enough so that it is feasible to perform HOG feature extraction at every GPR pixel as a vehicle moves down-track, which enables the HOG features to be used in prescreening. Unfortunately, for our application, the random forest classification approach is too slow to be used at every pixel, though parallelization of the RF, as well as cascade-like classifiers, could be used to overcome these limitations. Instead, during prescreening, this paper makes use of a PLS-DA classifier <ref type="bibr" target="#b35">[36]</ref>. PLS-DA is an effective technique for linear object classification, and has an extremely fast (linear) runtime, so it is more applicable to prescreener processing compared to other more complicated classifiers. From a computational perspective, the dominant sources of complexity in the HOG feature extraction process are the gradient calculation and binning of angle votes, both of which are linear in the number of pixels or number of bins under consideration.</p><p>Since prescreening algorithms process entire data collections at once, training and testing is complicated for prescreening algorithms; it is difficult to do leave-one-targetout cross validation, for example. Instead, in this paper, the prescreening version of HOG was trained using data from the large data collection outlined above, and then run on a separate data collection (taken several months later) over some of the same regions. The second validation dataset consists of 47700 m 2 and 654 target encounters.</p><p>Results from the on-board prescreening algorithm, HOGbased prescreening, and a fusion of the prescreening algorithms are shown in Fig. <ref type="figure">8</ref>.</p><p>The current system prescreener is an energy-based prescreening algorithm that searches for anomalies based on a whitened energy metric and successive stages of smoothing and CFAR processing <ref type="bibr" target="#b37">[38]</ref>. The algorithm has been successively optimized to detect target-like anomalies over several years, and is extremely welltuned for detecting anomalies of approximate target size and shape whose energy varies even slightly from nearby background. In contrast, the HOG Fig. <ref type="figure">9</ref>. Comparison of different pre-screening algorithms and pre-screener fusion. HOG pre-screening was trained on the data set explained previously, and tested on a separate data set for this experiment. Overall performance of HOG prescreening does not match the performance of the on-board prescreener operating alone, but simple fusion of the two prescreeners significantly improves performance.</p><p>prescreening algorithm presented here does not make use of multiple CFAR steps and has not been fully optimized for overall performance due to the risks of overtraining; as a result, the HOG prescreener performs slightly worse than the on-board prescreener. However, since the HOG prescreener and on-board prescreener are sensitive to different aspects of the underlying data (HOG is sensitive to edge shapes, and relatively invariant to energy, while the on-board prescreener is primarily an energy detector), it is natural to wonder if the fusion of the on-board and HOG prescreening functions can provide additional performance improvements. The dashed black line in Fig. <ref type="figure">8</ref> illustrates a simple prescreener proximity fusion (if two alarms are within 0.25 m of one another, create a new alarm at the center of the alarm locations, with confidence equal to the sum of the individual alarm's confidences, otherwise retain the original alarm locations and confidences). The fusion of the two algorithms dominates either of the algorithms operating in isolation, and achieves 95% Pd at 0.0048 FA/m 2 , a 50% improvement in FAR compared to the HOG prescreener alone, and a significant improvement over the on-board processor, since, at the current operating threshold, 95% Pd is not achieved with the original prescreener.</p><p>Overall, both the HOG classification using a random forest and the HOG prescreener using PLS-DA enable significant improvements for subsurface threat identification in GPR data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This paper explored the application of a particular technique from the computer vision literature, namely HOG features, to the problem of landmine and explosive detection in GPR data. Our results indicated that the performance of the HOG algorithms derived in this paper enable significant performance improvements over existing methods, and that HOG might provide a useful technique to help break down the artificial divide between prescreening and target classification used in GPR systems due to computational bottlenecks.</p><p>This paper also developed a number of preprocessing and classification steps that enabled modifications to the EHD algorithm to overcome some previous limitations (e.g., manual target localization, special-purpose classification algorithms) and enabled simpler algorithm retraining. A comparison of EHD and HOG performance in Figs. <ref type="figure" target="#fig_7">7</ref> and<ref type="figure">8</ref> illustrated the importance that preprocessing steps have on algorithm performance and the difficulty in providing accurate featureto-feature performance comparisons.</p><p>From a computational perspective, the HOG feature extraction procedure is quite tractable; for example, HOG features are widely used in image and video processing, where algorithms using these features are capable of achieving realtime performance. Furthermore, several open-source implementations of the HOG feature extraction code are available (e.g., <ref type="bibr" target="#b42">[43]</ref>).</p><p>Based on the work presented in this paper, interesting avenues for further research and development are possible. First, throughout the training process, a rather ad hoc energybased technique to localize actual responses of interest was utilized. Optimal extraction of locations of interest to identify and classify target versus nontarget responses is an unsolved problem in GPR processing. In the computer vision literature, corner points are often used to find regions of interest for additional processing-could a similar motivation be used to identify interesting locations in GPR data? Also, during classifier development and execution, other ad hoc techniques to aggregate decision metrics from sets of images are required (e.g., average the top three confidences as in Section IV-B). This process is necessary because the underlying problem being solved is not a simple pattern recognition problem but can instead be well represented as a multiple-instance learning (MIL) problem (e.g., <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b45">[46]</ref>). Treating the learning problem in GPR as an MIL problem is a young but active area of research that is currently being explored.</p><p>At a bigger picture level, HOG is certainly not the only technique available from the computer vision literature that might have implications for target classification in GPR data. It is possible that the work described in this paper will lead to significant leveraging of other alternative approaches for class identification from the computer vision literature being applied to solve problems in GPR data.</p><p>For example, numerous powerful and computationally simple feature extraction techniques such as BRIEF <ref type="bibr" target="#b46">[47]</ref>, random features <ref type="bibr" target="#b47">[48]</ref>, combinations of features <ref type="bibr" target="#b48">[49]</ref>, and others may enable faster and more robust target classification. Other approaches to prescreening are also possible-the Viola-Jones algorithm <ref type="bibr" target="#b26">[27]</ref> is of particular interest due to simple computational requirements and the inclusion of cascade detectors to help maintain rapid rates of advance.</p><p>As mentioned previously, HOG is related to (but distinct from) previous approaches to target classification in GPR data, such as the EHD algorithm. As more and more image processing techniques are brought to bear on target classification, an interesting question is what properties of different techniques make them successful for processing GPR data. Figs. 7 and 8 in this paper make it clear that direct headto-head comparison of feature extraction approaches with different preprocessing steps is quite difficult, so care should be taken to ensure that the same preprocessing steps are utilized when attempting to make direct comparisons of feature performance.</p><p>In terms of classical machine vision properties and their relevance toward landmine detection in GPR, we hypothesize that invariance to exact target (or interest point) location and invariance to received energy will be shown to be useful properties, while in variances to rotations or affine transformations can be safely ignored or discarded. Also, novel techniques in image processing and understanding, including part-based models <ref type="bibr" target="#b36">[37]</ref>, may enable much more robust modeling of target response variations due to changing soil properties, target sizes, and target emplacements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample GPR data from a western test site, collected over a buried plastic antitank landmine at 3 overburden. The dark wavy band near timesample 150 corresponds to the response at the air/ground interface. The target is visible near down-track sample 35, time sample 225.</figDesc><graphic coords="3,60.11,50.69,228.14,179.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Sample down-track GPR image and subimage extraction. The top left image shows a target response after time-gating to remove air/ground interface. The top right image shows a smoothed energy profile of the image on the left. Local maxima are marked with black stars. The bottom rows of images show subsets of data extracted around the three black star locations in the top left image in both the down-and cross-track orientations. In the bottom rows, the leftmost image corresponds to data extracted around the largest maxima peak in the top right, the middle image to the second highest peak, and the third image to the lowest magnitude peak. The six images in the bottom are enlarged to illustrate detail compared to the top left image.</figDesc><graphic coords="6,69.59,52.73,209.65,176.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Sample GPR images using different amounts of temporal downsampling. The time axis is along the y-axis and spatial location is along the x-axis. Each image corresponds to a different amount of downsampling in the time axis. The goal is to make the distribution of features in the HOG histogram bins approximately uniform (see Fig. 4 for additional information and results).</figDesc><graphic coords="6,332.15,52.37,210.61,173.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5.(a) Sample GPR subimage and (b) resulting HOG descriptor representation extracted around a target response. The HOG representation is generated by taking the resulting gradient bins and gradient magnitudes within each cell and generating lines at the appropriate angle with the appropriate magnitude. This visualization was inspired by those in<ref type="bibr" target="#b27">[28]</ref>.</figDesc><graphic coords="7,332.27,52.85,210.13,173.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) Sample GPR subimage and (b) resulting HOG descriptor representation extracted around a false alarm response.The HOG representation is generated by taking the resulting gradient bins and gradient magnitudes within each cell and generating lines at the appropriate angle with the appropriate magnitude. This visualization was inspired by those in<ref type="bibr" target="#b27">[28]</ref>.</figDesc><graphic coords="8,76.67,53.33,195.73,160.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7.Classification results for prescreening, HOG, EHD, and HMM algorithms. HOG performance on this dataset is very robust, dominating both the HMM and EHD algorithms. Note that, to show detail, the PD axes start at 70%, and the FAR axis only extends to 0.005 FA/m 2 . See text for additional information.</figDesc><graphic coords="8,324.23,51.77,230.30,177.98" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. H. Frigui for several important suggestions and the anonymous reviewers for their insightful comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by the U.S. Army RDECOM CERDEC Night Vision and Electronic Sensors Directorate, via a Grant Administered by the Army Research Office under Grant W911NF-09-1-0487 and Grant W911NF-06-1-0357.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Please be aware that the authors are required to pay overlength page charges ($200 per page) if the paper is longer than 6 pages. If you cannot pay any or all of these charges please let us know. This pdf contains 2 proofs. The first half is the version that will appear on Xplore. The second half is the version that will appear in print. If you have any figures to print in color, they will be in color in both proofs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Counter-Improvised Explosive Devices: Multiple DOD Organizations are Developing Numerous Initiatives, Government Accountability Office</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Washington, DC, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the wideband EMI response of a rotationally symmetric permeable and conducting target</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dalichaouch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Czipott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1206" to="1212" />
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A combined NSMC and pole series expansion approach for UXO discrimination</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shubitidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Barrowes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shamatava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2007-04">Apr. 2007</date>
			<biblScope unit="volume">6553</biblScope>
			<biblScope unit="page" from="1" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Autonomous mine detection system (AMDS) incorporating SFCW GPR and CWMD sensors for discrimination</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">O</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Duvoisin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><surname>Trishaun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2010-04">Apr. 2010</date>
			<biblScope unit="volume">7664</biblScope>
			<biblScope unit="page">766414</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance Comparison of Automated Induction-Based Algorithms for Landmine Detection in a Blind Field Test</title>
		<author>
			<persName><forename type="first">P</forename><surname>Torrione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Subsurf. Sens. Technol. Appl</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="121" to="150" />
			<date type="published" when="2004-07">Jul. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>David</surname></persName>
		</author>
		<title level="m">Ground Penetrating Radar</title>
		<meeting><address><addrLine>London, U.K.</addrLine></address></meeting>
		<imprint>
			<publisher>Institution of Electrical Engineers</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Subsurface sensing of buried objects under a randomly rough surface using scattered electromagnetic field data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Firoozabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Rappaport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Morgenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="104" to="117" />
			<date type="published" when="2007-01">Jan. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measurement of layer thickness and permittivity using a new multilayer model from GPR data</title>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2463" to="2470" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling of ground-penetrating radar for accurate characterization of subsurface electric properties</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lambot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Slob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Den Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stockbroeckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanclooster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2555" to="2568" />
			<date type="published" when="2004-11">Nov. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Soil surface water content estimation by full-waveform GPR signal inversion in the presence of thin layers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Minet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lambot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Slob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vanclooster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1138" to="1150" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Filtering soil surface and antenna effects from GPR data to enhance landmine detection</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lopera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Slob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Milisavljevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lambot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="707" to="717" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combination of advanced inversion techniques for an accurate target localization via GPR for demining applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Soldovieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lopera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lambot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="451" to="461" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The detection of buried pipes from time-of-flight radar data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Borgioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Capineri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Falorni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2254" to="2266" />
			<date type="published" when="2008-08">Aug. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic robust hyperbola mixture model for interpreting ground penetrating radar data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Joint Conf. Neural Netw</title>
		<meeting>Int. Joint Conf. Neural Netw</meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accurate determination of underground GPR wavefront and B-scan shape from above-ground point sources</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Rappaport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2429" to="2434" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic analysis of GPR images: A pattern-recognition approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pasolli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Donelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2206" to="2217" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classification of buried targets using ground penetrating radar: Comparison between genetic programming and neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Kobashigawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Youn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Iskander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Antennas Wireless Propag. Lett</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="971" to="974" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Frequency subband processing and feature analysis of forward-looking groundpenetrating radar signals for land-mine detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Gader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sjahputera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="718" to="729" />
			<date type="published" when="2007-03">Mar. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mine classification with imbalanced data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Silvious</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="528" to="532" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A least squares approach to buried object detection using ground penetrating radar</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Yoldemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sezgin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sens. J</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1337" to="1341" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Landmine detection with ground penetrating radar using hidden Markov models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Gader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mystkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1231" to="1244" />
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detection and discrimination of land mines in ground-penetrating radar based on edge histogram descriptors and a possibilistic K -nearest neighbor classifier</title>
		<author>
			<persName><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="199" />
			<date type="published" when="2009-02">Feb. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A largescale systematic evaluation of algorithms using ground-penetrating radar for landmine detection and discrimination</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2560" to="2572" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<title level="m">Computer Vision : Algorithms and Applications</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004-11">Nov. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SURF: Speeded up robust features</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008-06">Jun. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="511" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
			<date type="published" when="2005-06">Jun. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Keypoint-based image processing for landmine detection in GPR data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Torrione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="volume">8357</biblScope>
			<biblScope unit="page">83571</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A combined corner and edge detector</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Alvey Vis. Conf</title>
		<meeting>4th Alvey Vis. Conf</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="147" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Survey of pedestrian detection for advanced driver assistance systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gerónimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1239" to="1258" />
			<date type="published" when="2010-07">Jul. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Pedestrian detection: An evaluation of the state of the art</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wojek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="743" to="761" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Salembier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<title level="m">Introduction to MPEG 7: Multimedia Content Description Language</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The self-organizing map</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-09">Sep. 1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1464" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Random Forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001-01">Jan. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PLS-regression: A basic tool of chemometrics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sjöström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eriksson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics Intell. Lab. Syst</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="130" />
			<date type="published" when="2001-10">Oct. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Performance of an adaptive feature-based processor for a wideband ground penetrating radar system</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Torrione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Throckmorton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Aerosp. Electron. Syst</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="644" to="658" />
			<date type="published" when="2006-04">Apr. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997-01">Jan. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiple instance learning for landmine detection using GPR</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Torrione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="volume">8357</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploiting groundpenetrating radar phenomenology in a context-dependent framework for landmine detection and discrimination</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Ratto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Torrione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1689" to="1700" />
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Context-dependent multisensor fusion and its application to land mine detection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Gader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2528" to="2543" />
			<date type="published" when="2010-06">Jun. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The OpenCV Library</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr. Dobb&apos;s J. Softw. Tools</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="125" />
			<date type="published" when="2000-11">Nov. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adaptive p-posterior mixture-model kernels for multiple instance learning</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Int. Conf. Mach. Learn</title>
		<meeting>25th Int. Conf. Mach. Learn<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1136" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Random set framework for multiple instance learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torrione</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2061" to="2070" />
			<date type="published" when="2011-06">Jun. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Robust, high-speed interest point matching for real-time applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Calonder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<publisher>Swiss Federal Institute of Technology</publisher>
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Texture classification from random features</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="574" to="586" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An HOG-LBP human detector with partial occlusion handling</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 12th Int. Conf. Comput. Vis</title>
		<meeting>IEEE 12th Int. Conf. Comput. Vis</meeting>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">He is currently an Assistant Research Professor with Duke University with research focused on the use of Bayesian methods for a variety of applications including acoustic signal processing and landmine detection</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S E E</forename><surname>Medford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Usa</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S E E D</forename><surname>Ph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2004, and the M.S. and Ph.D. degrees in electrical and computer engineering from Duke University</title>
		<editor>
			<persName><forename type="first">Kenneth</forename><forename type="middle">D (</forename><surname>Morton</surname><genName>Jr</genName></persName>
		</editor>
		<meeting><address><addrLine>Durham, NC, USA; York, PA, USA; Pittsburgh, PA, USA; Durham, NC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1999. 2002 and 2008. 2002. 2004. 2008 to 2009. 2009. 1982. 2006 and 2010</date>
		</imprint>
		<respStmt>
			<orgName>degree from Tufts University ; Duke University ; University of Pittsburgh</orgName>
		</respStmt>
	</monogr>
	<note>His current research interests include physics-based statistical signal processing, pattern recognition, and machine learning. Dr. Morton is a member of Tau Beta Pi and Eta Kappa Nu</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">and became an Associate Professor in ECE in 2002, and is currently a Professor with the ECE Department. Her current research interests include incorporating physics-based models into statistical signal processing algorithms, and she is pursuing applications in subsurface sensing as</title>
		<author>
			<persName><forename type="first">Rayn</forename><surname>Sakaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Leslie M. Collins (M&apos;96-SM&apos;01) was born in Raleigh, NC, USA. She received the B.S.E.E. degree from the University of Kentucky</title>
		<meeting><address><addrLine>Honolulu, Hawaii; Hartford, CT, USA; Durham, NC, USA; Stratford, CT; Lexington, KY, USA; Ann Arbor, MI, USA; Pittsburgh, PA, USA; Durham, NC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984">1984. 2007. 2007 to 2010. 1986 and 1995. 1986. 1990. 1995</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical and Computer Engineering (ECE), Duke University</orgName>
		</respStmt>
	</monogr>
	<note>He is currently pursuing the Ph.D. degree in electrical and computer engineering with Duke University. well as enhancing speech understanding by hearing-impaired individuals. Dr. Collins is a member of Tau Beta Pi, Eta Kappa Nu, and Sigma Xi</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
