<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating test data from state-based specifications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Offutt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ISE Department</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<postCode>22030</postCode>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shaoying</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Information Sciences</orgName>
								<orgName type="institution">Hosei University</orgName>
								<address>
									<addrLine>3-7-2 Kajino-cho Koganei-shi</addrLine>
									<postCode>184-8584</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aynur</forename><surname>Abdurazik</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ISE Department</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<postCode>22030</postCode>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Ammann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ISE Department</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<postCode>22030</postCode>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Information &amp; Software Engineering Department</orgName>
								<orgName type="institution">George Mason University</orgName>
								<address>
									<postCode>22030-4444</postCode>
									<settlement>Fairfax</settlement>
									<region>VA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Generating test data from state-based specifications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EAA0B2402798865F9718AD346958FD99</idno>
					<idno type="DOI">10.1002/stvr.264)</idno>
					<note type="submission">Received 29 April 2002 Accepted 5 February 2003</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>formal methods</term>
					<term>specification-based testing</term>
					<term>software testing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although the majority of software testing in industry is conducted at the system level, most formal research has focused on the unit level. As a result, most system-level testing techniques are only described informally. This paper presents formal testing criteria for system level testing that are based on formal specifications of the software. Software testing can only be formalized and quantified when a solid basis for test generation can be defined. Formal specifications represent a significant opportunity for testing because they precisely describe what functions the software is supposed to provide in a form that can be automatically manipulated.</p><p>This paper presents general criteria for generating test inputs from state-based specifications. The criteria include techniques for generating tests at several levels of abstraction for specifications (transition predicates, transitions, pairs of transitions and sequences of transitions). These techniques provide coverage criteria that are based on the specifications and are made up of several parts, including test prefixes that contain inputs necessary to put the software into the appropriate state for the test values. The test generation process includes several steps for transforming specifications to tests. These criteria have been applied to a case study to compare their ability to detect seeded faults.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>There is an increasing need for effective testing of software for safety-critical applications, such as avionics, medical and other control systems. These software systems usually have clear high-level descriptions, sometimes in formal representations. Unfortunately, most system-level testing techniques are only described informally. This paper is part of a project that is attempting to provide a solid foundation for generating tests from system-level software specifications via new coverage criteria. Formal coverage criteria offer testers ways to decide what test inputs to use during testing, making it more likely that the testers will find faults in the software and providing greater assurance that the software is of high quality and reliability. Such criteria also provide stopping rules and repeatability. The eventual goal of this project is a general model for generating test data from formal specifications; this paper presents results for generating test data from state-based formal specifications. Formal specifications represent a significant opportunity for testing because they precisely describe what functions the software is supposed to provide in a form that can easily be manipulated by automated means.</p><p>This paper presents a model for developing test inputs from state-based specifications and formal criteria for test data selection. These criteria are meant to be general enough to be applied to a variety of specification languages that use a state-based representation. They have been applied to Software Cost Reduction (SCR) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, CoRE <ref type="bibr" target="#b2">[3]</ref>, Unified Modelling Language (UML) Statecharts <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> and the Structured Object-oriented Formal Language (SOFL) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. The test data generation model includes techniques for generating tests at several levels of detail, with views moving from clauses in predicates on transitions, to single transitions, to pairs of transitions and finally to sequences of transitions. These techniques provide coverage criteria that are based on the specifications and the test generation process details steps for transforming functional specifications to tests.</p><p>A common source for tests is the program code. In code-based test generation, a testing criterion is imposed on the software to produce test requirements. For example, if the criterion of branch testing is used, the tests are required to cover each branch in the program. An abstract view of part of a typical test process that might be used for code-based test generation is summarized by the diagram in Figure <ref type="figure" target="#fig_0">1</ref>(a). The specification S (which can be formal or informal) is used as a basis for writing the program P , which is used to generate the tests T , according to some coverage criterion such as branch or data flow. The computer C executes T on P to create the actual output, which must be compared with the expected output. The expected output is produced with some knowledge of the specification. Thus, code-based generation uses the specification to generate the code and check the output of the tests.</p><p>This is in contrast to specification-based testing, an abstract view of which is shown in Figure <ref type="figure" target="#fig_0">1</ref>(b). Here, the specifications are used to produce test cases, as well as to produce the program. The arc from S to P is labelled 'refine' because if specifications are formal, a refinement process may be used.</p><p>Specification-based test data generation has several advantages, particularly when compared with code-based generation. Tests can be created earlier in the development process and be ready for execution before the program is finished. Thus, testing activities can be shifted to an earlier part of the development process, allowing for more effective planning and utilization of resources. Additionally, the process of generating tests from the specifications will often help the test engineer find inconsistencies and ambiguities in the specifications when the tests are generated, allowing the specifications to be improved before the program is written (hence the feedback arc from T to S). Another advantage is that the essential part of the test data can be independent of any particular implementation of the specifications. Requirements/specifications can also be used as a basis for output checking, significantly reducing one of the major costs of testing. The arcs from S to T and from S to Expected Output are labelled with a '?', because these are currently active areas of research. Software functional specifications have been incorporated into testing in several ways. They have been used as a basis for test case generation, to check the output of software on test inputs <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>, and as a basis for formalizing test specifications (as opposed to functional specifications) <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. This paper is primarily concerned with the first use, that of generating test cases from specifications, commonly referred to as specification-based testing.</p><p>Specification-based testing is currently immature, which means formalized criteria and automated tool support are scarce. It is this problem that this research is attempting to address. System-level testing has the potential to benefit from formal specifications by using the formal specifications as the input to formalizable, automatable test generation processes. Another advantage of specification-based testing is that it can support the automation of testing result analysis by using specifications as test oracles.</p><p>Code-based and specification-based approaches are sometimes used in combination. The most common approach in industry is to generate tests based on the specifications and then use code-based coverage analysis to measure the quality of the tests. For example, the tests might be measured by how many branches in the software are covered. It is difficult to construct system-and subsystem-level tests that cover detailed code-level requirements (such as branches). This is why code-based test generation is often thought of as useful for unit testing, when individual functions or modules are tested, and specification-based test generation is often thought of as useful for system testing, when entire working systems are tested.</p><p>These are really orthogonal issues, however. Specification-based testing techniques can be and are used at the unit level. One way to differentiate specification-based testing from code-based testing is to consider the questions that are being posed. Specification-based testing can be thought of as addressing the question 'are the functionalities correct?', whereas code-based testing addresses the question of 'how much software is being covered during testing?'.</p><p>At the same time, both code-based testing and specification-based testing often use coverage criteria and some sort of representation of the system. Moreover, these coverage criteria are often identical or at least similar, including covering nodes in graphs or exercising clauses in predicates. At an abstract level, these are very similar for both code-based and specification-based testing; the difference is primarily in where the structures (graphs, clauses, etc.) come from. This paper first presents criteria for generating tests from state-based specifications. Applications of these criteria to three different specification languages are discussed; examples are presented using SCR specifications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> and CoRE <ref type="bibr" target="#b2">[3]</ref> and a case study is used to illustrate the test derivation process and to evaluate these criteria in terms of their ability to detect seeded faults. This paper also includes a review of the small but growing body of work on using formal specifications as a basis for producing test cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SPECIFICATION-BASED TESTING CRITERIA</head><p>An important problem in software testing is deciding when to stop. Test cases are run on software to find failures and gain some confidence in the software. Unfortunately, the entire domain of the software (which in most cases is effectively infinite) cannot be exhaustively searched. Adequacy criteria are therefore defined for testers to decide whether software has been adequately tested for a specific testing criterion <ref type="bibr" target="#b13">[14]</ref>.</p><p>Test requirements are specific things that must be satisfied or covered; for example, reaching statements are the requirements for statement coverage, killing mutants are the requirements for mutation and executing DU pairs are the requirements in data flow testing. A testing criterion is a rule or collection of rules that impose requirements on a set of test cases. Test engineers measure the extent to which a criterion is satisfied in terms of coverage, which is the percentage of requirements that are satisfied. This paper presents several criteria for system-level testing. These criteria are expected to be used both to guide the testers during system testing and to help the testers find rational, mathematicallybased points at which to stop testing. These criteria assume that the software's functionality is described in terms of states and transitions (that is, not algebraic or model-based specifications). Typical statebased specifications define preconditions on transitions, which are values that specific variables must have for the transition to be enabled, and triggering events, which are changes in variable values that cause the transition to be taken. A trigger event 'triggers' the change in state. For example, SCR <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> calls these WHEN conditions and triggering events. The values the triggering events have before the transition are sometimes called before-values and the values after the transition are sometimes called after-values. The state immediately preceding the transition is the pre-state and the state after the transition is the post-state.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> illustrates this model with a simple transition that opens an elevator door. If the elevator button is pressed (the trigger event), the door opens only if the elevator is not moving (the precondition elevSpeed = 0).</p><p>In these criteria, tests are generated as multi-part, multi-step, multi-level artifacts.  relational operators). The multi-level aspect means that tests are generated to test the software at several levels of abstraction on the specifications.</p><p>A test case value is the essential part of a test case, the values that come from the test requirements. It may be a command, user inputs, or a software function and values for its parameters. In state-based software, test case values are usually derived directly from triggering events and preconditions for transitions. A test case prefix value includes all inputs necessary to reach the pre-state and to give the triggering event variables their before-values. Any inputs that are necessary to show the results are verify values and exit commands may be needed to terminate execution in some programs. Expected outputs are created from the after-values of the triggering events and any postconditions that are associated with the transition.</p><p>This paper defines four different test criteria at different levels of abstraction on the specifications, each of which requires a different amount of testing: (1) transition coverage; (2) full predicate coverage;</p><p>(3) transition-pair coverage; and (4) complete sequence. These are defined in the following four sections. To apply these, a state-based requirement/specification is viewed as a directed graph, called the specification graph. Each node represents a state (or mode) in the requirement/specification, and edges represent possible transitions among states. Many state-based specification languages are fairly easy to translate into a specification graph as they have natural graph representations. Unfortunately, model-based specification languages such as Z are difficult to use in this way, in part because the state space would be very large. Other researchers have proposed ways to develop tests from Z specifications <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>.</p><p>It is possible to apply all criteria, or to choose a criterion based on a cost/benefit tradeoff. The first two are related; the transition coverage criterion requires many fewer test cases than the full predicate coverage criterion, but if the full predicate coverage criterion is used, the tests will also satisfy the transition coverage criterion (full predicate coverage subsumes transition coverage). Thus only one of these two should be used. The latter two criteria are meant to be independent; transition-pair coverage is intended to check the interfaces among states, and complete sequence testing is intended to check the software by executing the software through complete execution paths. As it happens, transitionpair coverage subsumes transition coverage, but they are designed to test the software in very different ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Transition coverage criterion</head><p>It is felt that the minimum a tester should test is every precondition in the specification at least once. This philosophy is defined in terms of the specification graph by requiring that each transition is taken. In the criteria definitions, T is a set of test cases and SG is a specification graph.</p><p>Transition coverage. The test set T must include tests that cause every transition in the SG to be taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Full predicate coverage criterion</head><p>One question during testing is whether the predicates in the specifications are formulated correctly. Small inaccuracies in the specification predicates can lead to major problems in the software. The full predicate coverage criterion takes the philosophy that to test the software, testers should provide inputs derived from each clause in each predicate. This criterion requires that each clause in each predicate on each transition is tested independently, thus attempting to address the question of whether each clause is necessary and is formulated correctly. This paper restricts itself to Boolean logic using the operators AND (∧), OR (∨) and NOT (¬). There are straightforward ways to extend this analysis to other operators, including exclusive-OR (⊕), implication (→) and equivalence (↔), and any other Boolean algebras. This paper defines predicates and clauses as follows.</p><p>• A Boolean expression is an expression whose value can be either True or False.</p><p>• A clause is a Boolean expression that contains no Boolean operators. For example, relational expressions and Boolean variables are clauses. ('Clause' is the term typically used in mathematics texts, DO-178B <ref type="bibr" target="#b23">[24]</ref> uses the term 'conditions'.) • A predicate is a Boolean expression that is composed of clauses and zero or more Boolean operators. A predicate without a Boolean operator is also a clause. If a clause appears more than once in a predicate, each occurrence is a distinct clause.</p><p>Full predicate coverage is based on the philosophy that each clause should be tested independently; that is, while not being influenced by the other clauses. In other words, each clause in each predicate on every transition must independently affect the value of the predicate. This is similar to the code-based testing criterion of modified condition/decision coverage (MC/DC) <ref type="bibr" target="#b24">[25]</ref>, as described in Section 2.5. Before defining full predicate coverage, it is necessary to clarify this notion of 'independently affecting the value of the predicate'. This is done with the notion of a clause 'determining' the value of the predicate.</p><p>Determination. Given a test clause c i in predicate p, it is said that c i determines p if the remaining minor clauses c j ∈ p, j = i have values so that changing the truth value of c i changes the truth value of p.</p><p>Note that this definition explicitly does not require that c i = p. Some papers in the literature require the test clause and the predicate to have the same value and many leave the question ambiguous, which can lead to confusion when implementing criteria for logical expressions. This definition also imposes constraints on all clauses in the predicate, not just the test clause.</p><p>Full predicate coverage. For each predicate P on each transition and each test clause c i in P , T must include tests that cause each clause c i in P to determine the value of P , where c i has both the values true and false.</p><p>Note that the use of the 'determines' definition implies that P will also have the values true and false. That is, if full predicate coverage is achieved, transition coverage will also be achieved. To satisfy the 'determination' requirement for the test clause, the other minor clauses must have specific values. For example, if the predicate is (X ∧ Y ) and the test clause is X, Y must be True. Likewise, if the predicate is (X ∨ Y ), Y must be False.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Satisfying full predicate coverage</head><p>There are several ways to find values that satisfy full predicate coverage, including Aker's Boolean derivative method <ref type="bibr" target="#b25">[26]</ref>, as adapted by Kuhn <ref type="bibr" target="#b26">[27]</ref>, and Chilenski and Miller's pairs table method <ref type="bibr" target="#b24">[25]</ref>. This paper presents a prescriptive approach that uses an expression parse tree. An expression parse tree is a binary tree that has binary and unary operators for internal nodes and variables and constants at leaf nodes. The relevant binary operators are and (∧) and or (∨); the relevant unary operator is not. For example, the expression parse tree for</p><formula xml:id="formula_0">(A ∨ B) ∧ C is A B C C (A B)</formula><p>Given a parse tree, full predicate coverage is satisfied by walking the tree. First, a test clause is chosen. Then the parse tree is walked from the test clause up to the root, then from the root down to each clause. While walking up a tree, if a given clause's parent is or, its sibling must have the value of False. If its parent is and, its sibling must have the value of True. If a node is the inverse operator not, the parent node is given the inverse value of the child node. This is repeated for each node between the test clause and the root.</p><p>Once the root is reached, values are propagated down the unmarked subtrees using a simple tree walk. If an and node has the value True, then both children must have the value True; if an and node has the value of False, then at least one child must have the value False (which one is arbitrary). If an or node has the value of False, then both children must have the value False; if an or node has the value of True, then at least one child must have the value True (which one is arbitrary). If a node is the inverse operator not, the child node is given the inverse value of the parent node.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> illustrates the process for the expression above, showing both B and C as test clauses. In the top sequence, B is the test clause (shown with a dashed box). In tree 2, its sibling, A, is assigned the value False and in tree 3, C is assigned the value True. In the bottom sequence, C is the test clause. In tree 2, C's sibling is an or node and is assigned the value True. In tree 3, A is assigned the value True. Note that in tree 3, either A or B could be given the True value; the choice is arbitrary.</p><p>These test cases sample from both valid and invalid transitions, with only one transition being valid at a time. Invalid transitions are tested by violating the appropriate preconditions. In addition, the test engineer may choose semantically meaningful combinations of conditions. Testing with invalid inputs can help find faults in the implementation as well as in the formulation of the specifications.</p><p>As a concrete example, consider the formula whose parse tree was given above, (A ∨ B) ∧ C. The following partial truth table provides the values for the test clauses in bold face. To ensure the requirement that the test clause must determine the final result, the partial truth table must be filled out as follows (for the last two entries, either A or B could have been True, both were assigned the value True):</p><formula xml:id="formula_1">(A ∨ B) ∧ C 1 T F T 2 F F T 3 F T T 4 F F T 5 T T T 6 T T F</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Handling triggering events</head><p>As defined in Section 2, a triggering event is a change in a value for a variable, expression, or expressions that causes the software to undergo a transition from one state to another. In SCR and CoRE, triggering event variables have a different format from other variables in transition predicates. A triggering event actually specifies two values, a before-value and an after-value. To fully test predicates with triggering events, test engineers must distinguish between them by controlling values for both before-values and after-values. This paper suggests implementing this by assuming two versions of the triggering event variable, A and A , where A represents the before-value of A and A represents its after-value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Transition-pair coverage criterion</head><p>Many mistakes in software can arise because the engineers do not fully understand the complex interactions among sequences of states in the specifications. The previous criteria test transitions independently, but do not test sequences of state transitions; thus some types of faults may not be adequately tested. Some faults may occur because an invalid sequence of transitions is allowed, or a valid sequence is not allowed. To check for these types of faults, this criterion requires that pairs of transitions be taken.</p><p>Transition-pair coverage. For each pair of adjacent transitions S i : S j and S j : S k in SG, T must contain a test that traverses each transition of the pair in sequence.</p><p>Transition-pair subsumes transition coverage. An example of a transition-pair is illustrated by the following state:  <ref type="formula">6</ref>) 2 to iii. These tests require inputs that satisfy the following ordered pairs of predicates: (P 1 :P i ), (P 1 :P ii ), (P 1 :P iii ), (P 2 :P i ), (P 2 :P ii ) and (P 2 :P iii ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Complete sequence criterion</head><p>It seems very unlikely that any successful test method could be based on purely mechanical methods; at some point the experience and knowledge of the test engineer must be used. In particular, at the system level, effective testing probably requires detailed domain knowledge. The complete sequence criterion is not automatable or measurable like the other three criteria and this idea is certainly not new, but it is included here as an attempt at completeness. The definition is formulated so that this idea can be put into the same form and terminology as the previous criteria. A complete sequence is a sequence of state transitions that form a complete practical use of the system. This use of the term is similar to that of use cases in UML. In most realistic applications, the number of possible sequences is too large to choose all complete sequences. In many cases, the number of complete sequences is infinite.</p><p>Although the tests are intended to be executed on an implementation of the specification, a test is said to traverse a transition to indicate that, from a modelling perspective, the test causes the transition's predicate to be true and the implementation will change from the transition's pre-state to its post-state.</p><p>Complete sequence. T must contain tests that traverse 'meaningful sequences' of transitions on the SG, where these sequences are chosen by the test engineer based on experience, domain knowledge and other human-based knowledge.</p><p>Which sequences to choose is something that can only be determined by the test engineer with the use of domain knowledge and experience. This is the least automatable level of testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Summary</head><p>This section has introduced four criteria to guide the testers during system-level testing. While these criteria are black-box in nature and only depend on the specifications, not the implementation, they are partly motivated by structural coverage test criteria. Transition coverage is similar to branch coverage. Full predicate coverage relies on definitions from DO-178B <ref type="bibr" target="#b23">[24]</ref> and the definition is similar to that of MC/DC <ref type="bibr" target="#b24">[25]</ref>, which requires that every decision and every condition within the decision has taken every outcome at least once and every condition has been shown to affect its decision independently. Although similar, the full predicate criterion is more restrictive and allows the satisfying procedure defined in Section 2.2.1. It should be emphasized, however, that the notion of coverage for the criteria in this paper is based on the specifications and there is no guarantee of code coverage. These criteria are designed to provide a range of test strengths; thus a contribution of this paper is to provide a practical range of cost/benefit choices for test engineers to construct tests from specifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">AUTOMATICALLY DERIVING TEST CASES</head><p>Figure <ref type="figure">4</ref> illustrates the overall process used by a proof-of-concept tool built at George Mason University, SPECTEST. SPECTEST is implemented in Java and parses specifications into a general format (the specification graph), then generates test requirements for the appropriate criterion or criteria and then generates the actual test values. SPECTEST currently has parsers for SCR specifications created using the SCRTool developed at the Naval Research Laboratory <ref type="bibr" target="#b27">[28]</ref>, and UML Statecharts created by using Rational Software Corporation's Rational Rose tool <ref type="bibr" target="#b3">[4]</ref>.</p><p>The step of translating test specification values into program inputs (Script Generator in Figure <ref type="figure">4</ref>) is not included in the SPECTEST tool. Testers need to relate variables that appear in the specifications to program variables or inputs. The simplest way is to assume that the variable names are the same (called 'testable software specifications' by Binder <ref type="bibr" target="#b28">[29]</ref>), but a more general approach is to require that some sort of mapping function from specification variables to program variables exists. While this is a challenging and important problem, solving it would not contribute to the current research results and this is left as future research. The dashed line encloses the test generation steps that SPECTEST implements.</p><p>The following list describes each step that SPECTEST follows. Since some of the process steps are identical for each of the four criteria, they are presented together when possible. The criteria are differentiated after step 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Parse functional specifications. Transition conditions are predicates that define under what</head><p>conditions each transition will be taken. With some specification languages (e.g. SCR and CoRE), the transition conditions are encoded directly into the specifications; otherwise, they have to be derived. SPECTEST reads transition conditions directly from SCR tables and from UML tables. For languages that do not directly encode transition conditions, the transition conditions could be derived by hand or generated by a separate pre-processing tool. 2. Develop specification graph. The specification graph can be directly derived from the transition conditions and edges annotated with the conditions derived in step 1. At this point, the process separates for the four testing criteria, as shown in the four Spec Analyzer boxes in Figure <ref type="figure">4</ref>. The user selects which criterion to apply. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Develop full predicate test requirements.</head><p>(a) Construct truth tables for all predicates in the specification graph. If all the logical connectors are the same (all ANDs or all ORs), it is a simple matter to modify the values for the clauses in the predicates directly. If ANDs and ORs are mixed freely, however, it is less error-prone to construct the expression tree. SPECTEST creates explicit parse trees. Some specification languages differentiate between trigger events and preconditions; in this case, the trigger events must be specially marked so that the trigger event values appear after the precondition inputs (that is, they are ordered).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Develop transition-pair test requirements.</head><p>(a) Identify all pairs of transitions. Transition-pair tests are ordered pairs of condition values, each representing an input to the state and an output from the state. These are formed by enumerating all the input transitions (M), all the output transitions (N), then creating M × N pairs of transitions. (b) Construct predicate pairs. These pairs of transitions are then replaced by the predicates from the specification graph.</p><p>6. Develop complete sequence test requirements.</p><p>(a) Identify complete lists of states. The complete sequence tests are created by the tester.</p><p>Although not implemented in SPECTEST, this could be done by choosing sequences of states from the specification graph to enter. (b) Construct sequence of predicates. The sequences of states are transformed into sequences of conditions that will cause those states to be entered.</p><p>At this point, test requirements for the four criteria will be in a uniform format-truth assignments for predicates. These truth assignments form the test requirements for the testing. 7. Test values generator. For each unique test requirement, generate test specifications that consist of prefix values, test case values, verify conditions, exit conditions and expected outputs. Note that there may be a fair amount of overlap among the test requirements, thus the 'unique' restriction. Before test specifications are generated, duplicate test requirements are removed.</p><p>Generating the actual values involves solving some algebraic equations. For example, if a condition is A &gt; B, values for A and B must be chosen to give the predicate the appropriate value. It is also at this point that some 'invalid' tests might be discovered. For example, it may be impossible or meaningless to pair all incoming and outgoing transitions for each state. Such test specifications are discarded. 8. Script generator. Each test specification is used to construct one test script. The actual scripts must reflect the input syntax of the program and have not been automated in SPECTEST.</p><p>The script generator needs information about the inputs to the program. Specifically, it must solve the mapping problem and convert test specifications that are in terms of the specifications to executable test scripts that the software understands. Note that this is the only step that requires any knowledge of the implementation; all preceding steps depend solely on the functional specifications.</p><p>SPECTEST currently has the restriction that it processes only one mode class for SCR specifications at a time and one statechart class for UML specifications <ref type="bibr" target="#b4">[5]</ref>. Although this imposes some burden on the tool user, in practice it makes no functional difference because testers usually test one mode or statechart class at a time. The tool is being expanded to handle other UML diagrams, most currently including collaboration diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CASE STUDY</head><p>As a preliminary demonstration of the feasibility of these criteria, an empirical study has been undertaken. A full experiment is planned for the future. The goal was to demonstrate that the specification-based criteria can be effectively used; the authors hope to evaluate them more fully in the future. The methodology and empirical subjects are described first, then the processes used to generate tests for each criterion are described in detail. Then the implementation used in this study is described, the faults that were generated are listed and, finally, the results and analysis are given.</p><p>SPECTEST was used to generate test specifications from SCR mode tables for full predicate and transition-pair tests. For this implementation, the specification variables and program variables are the same and inputs are pairs of variables and values. This simplification means that the test specifications are also the test scripts. The tests include expected outputs (that is, the post-states); thus the output checking was done automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Methodology</head><p>Two measurements of the criteria have been carried out. Tests were created and then measured on the basis of the structural coverage criterion of branch testing and then the tests were measured in terms Table <ref type="table">I</ref>. SCR specifications for the cruise control system.</p><p>Previous mode Ignited Running Toofast Brake Activate Deactivate Resume New mode</p><formula xml:id="formula_2">Off @T - - - - - - Inactive Inactive @F - - - - - - Off Inactive t t - f @T - - Cruise Cruise @F - - - - - - Off Cruise t @F - - - - - Inactive Cruise t - @T - - - - Inactive Cruise t t f @T - - - Override Cruise t t f - - @T - Override Override @F - - - - - - Off Override t @F - - - - - Inactive Override t t - f @T - - Cruise Override t t - f - - @T Cruise</formula><p>of their fault-detection abilities. One moderately sized program was used, representative faults were seeded (by Offutt) and test cases were generated by hand (by Abdurazik). Cruise control is a common example in the literature <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>, and specifications are readily available. This case study used the SCR specification exactly as given by Atlee <ref type="bibr" target="#b0">[1]</ref>, shown in Table <ref type="table">I</ref>. This version of cruise control does not model the throttle and has four states: OFF (the initial state), INACTIVE, CRUISE and OVERRIDE. Cruise is in INACTIVE if the engine is on (Ignited) and the cruise control has not been activated (Activate). Cruise can be activated only if the engine is on (Ignited), the engine is running (Running) and the brake is not currently being pressed (Brake). When the system is in CRUISE mode the computer controls the speed of the car. OVERRIDE mode is entered if the brake is pressed or the system is turned off.</p><p>The system's environmental conditions indicate whether the automobile's ignition is on (Ignited), the engine is running (Running), the automobile is going too fast for the speed to be controlled (Toofast), the brake pedal is being pressed (Brake) and whether the cruise control level is set to Activate, Deactivate or Resume.</p><p>Each row in the table specifies a conditioned event that activates a transition from the mode on the left to the mode on the right. A table entry of @T or @F under a column header C represents a triggering event @T(C) or @F(C). This means that the value of C must change for the transition to be taken; that is, '@T(C)' means C must change from false to true and '@F(C)' means C must change from true to false. A table entry of t or f represents a WHEN condition. WHEN[C] means the transition can only be taken if C is true and WHEN[¬C] means it can only be taken if C is false. If the value of a condition C does not affect a conditioned event, the table entry is marked with a '-' (do not care condition). Table <ref type="table" target="#tab_2">II</ref> shows the transitions of the specification with the trigger events expanded in predicate form, numbered P 1 through P 12 . Figure <ref type="figure">5</ref> shows the specification graph, with edges labelled by the predicate numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Test generation</head><p>The full predicate, transition, and transition-pair tests were generated by SPECTEST. The random tests referred to in Table <ref type="table" target="#tab_4">III</ref> were generated by hand. To avoid bias, tests were created independently from the faults and by different people. Each test case was executed against each buggy version of Cruise. After each execution, failures (if any) were identified. The number of faults detected was recorded and used in the analysis. The rest of this subsection discusses how tests were generated in detail.</p><p>This serves both to elaborate on the empirical methodology, as well as to illustrate the criteria defined previously. Because the transition coverage criterion is subsumed by full predicate coverage, it is not described separately. Transition coverage test cases can be taken from the 'valid' specifications in the full predicate criterion, which are listed first for each transition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Full predicate coverage criterion</head><p>There are nine transitions in the cruise control specifications and 12 disjunctive predicates. For convenience, the technique is applied by considering each predicate specification separately. As described in Section 2.2, both the before-values and after-values of the triggering event should be separately tested. For SCR, this is handled by treating @ as an operator and expanding it algebraically. If X represents a before-value and X an after-value, the relevant expansions are:</p><formula xml:id="formula_3">• @T (X) ≡ NOT X ∧ X ; • @T (X ∧ Y ) ≡ ¬(X ∧ Y ) ∧ (X ∧ Y ) ≡ (¬X ∨ ¬Y ) ∧ X ∧ Y ; • @T (X ∨ Y ) ≡ ¬(X ∨ Y ) ∧ (X ∨ Y ) ≡ ¬X ∧ ¬Y ∧ (X ∨ Y ).</formula><p>There are 54 separate test case requirements for the full predicate coverage level (they are listed in Appendix A). The third transition, P 3 , is used to illustrate the test case requirement derivation. The variable values are taken from the predicates and are shown as T, F, t, f and -. T or F means the clause is triggering and the table contains a before-value and after-value. The values for the test case are the new value for the triggering clause (T or F) and the t and f values from the WHEN conditions. The expected output for the test specification is derived from the triggering event, the post-state and any terms or variables that are defined as a result of the transition. P 3 has four clauses: @T Activate ∧ Ignited ∧ Running ∧ ¬Brake and expanding the triggering clause @T Activate to include its before-value and after-value yields: There are several interesting points to note about these test specifications. First, it should be clear that there is some redundancy; some of the condition variables do not need to be explicitly set, as they will already have the appropriate values. Algorithms that can decide what values need to be explicitly set are found in a technical report <ref type="bibr" target="#b30">[31]</ref>; these algorithms are implemented in SPECTEST.</p><formula xml:id="formula_4">¬Activate ∧ Ignited ∧ Running ∧ ¬Brake ∧</formula><p>Another interesting point is the derivation of the prefix part of the test specification. Reaching the prestate is essentially a reachability problem. Given a control flow graph of a program, it is an undecidable problem to find a test case that reaches a particular statement. The state-based specifications considered by this research have finite and deterministic specification graphs, so this problem is solvable for specification graphs derived from state-based systems. An algorithm for doing this is also in a technical report <ref type="bibr" target="#b30">[31]</ref> and prefixes are generated automatically by SPECTEST.</p><p>Test scripts are simple rewrites of test specifications with modifications made for the input requirements of the program being tested. The test script for the first test specification above is:</p><formula xml:id="formula_5">Ignited = True Activate = False Running = True Brake = False Activate = True</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Transition-pair coverage criterion</head><p>At the transition-pair level, each state is considered separately. Each input transition into the state is matched with each transition out of the state and the combination is used to create test requirements, which are ordered pairs of predicates. The ordered pairs are turned into ordered pairs of inputs to form test specifications.</p><p>The following are the test requirements for the four states. These ordered pairs are transformed into predicates from Table <ref type="table" target="#tab_2">II</ref>. The 'OR' entries result from the transitions that have two conditions; either condition could be satisfied to take that transition. The complete set of resulting predicates are shown in Appendix B; they result in 36 additional test cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test specifications</head><p>The actual test specifications and test scripts are automatically derived from the above test requirements and are too numerous to list. The requirements for the OFF state are chosen as an illustrative example. OFF has three transition-pair coverage level tests. For the first test case for OFF, the test case must reach the INACTIVE state; this forms the Prefix. Then the test case must pass through transitions P 2 and then P 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Complete sequence criteria</head><p>At the complete sequence level, test engineers must use their experience and judgment to develop sequences of states that should be tested. To do this well requires experience with testing, experience with programming and knowledge of the domain. These tests are omitted in this case study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Implementation and faults</head><p>A model of the cruise control problem was implemented in about 400 lines of C. Cruise has seven functions, 184 blocks and 174 branches. The program accepts pairs of variables and values, where a value can be 't', 'f', 'T' or 'F'. Uppercase inputs signify a triggering event. For convenience, the program was implemented so that the pre-state could be either set with a test case Prefix, or explicitly by entering the name of a state.</p><p>Twenty-five faults were created by hand and each was inserted into a separate version of the program. Most of these faults are based on mutation-style modifications and were in the logic that implemented the state machine. Four were naturally occurring faults, made during initial implementation. Faults were inserted by the first author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results and analysis</head><p>As a way to measure the quality of these tests, block and branch coverage was computed using the 54 full predicate test cases (created by the third author). The coverage was measured using Atac <ref type="bibr" target="#b31">[32]</ref>. Five of the 174 branches were infeasible, leaving 169, and all of the blocks were feasible. The results are shown in Figure <ref type="figure" target="#fig_6">6</ref>. The 54 test cases covered 163 of the blocks (89%) and 155 of the branches (95%). Of the 14 uncovered branches that were feasible, 11 were related to input parameters that were not used during testing. That is, these 11 branches were not related to the functional specifications.  Resume are only used as triggering events in the specifications, not condition variables. Thus, there are statements in the software that handle assignments to these variables as WHEN conditions that are never executed. Although there have been very few published studies on the ability of specificationbased tests to satisfy code-based coverage criteria, these results seem very promising. The other measurement was for the fault-detection ability of the tests. Twelve test cases were generated for transition coverage, an additional 42 for full predicate (making 54 total) and 34 were generated for the transition-pair criterion. As a control comparison, 54 additional test cases were generated randomly. Although 25 versions of Cruise were created, each one containing one fault, one was such that the program goes into an infinite loop on any input. Since this fault was so trivial, it was discarded. Results from the four sets of test data are shown in Table <ref type="table" target="#tab_4">III</ref>.</p><p>Detailed analysis of the faults showed that three of the four faults that the full predicate tests missed could not have been found with the methodology used. The implementation runs in one of two modes. In one mode, the test engineer explicitly sets a pre-state by entering the state name. In the other mode, the software always starts at the initial state and a test case prefix must be included as part of the test case. The prefix should include inputs to reach the pre-state. All of the tests that were used in this study explicitly set the pre-state and three of the four faults that were missed could not be found if the prestate is explicitly set. These faults were in statements that were not executed if the prefix was explicitly set. None of the four sets of tests found these three faults. The other fault that the full predicate tests missed was not found by either of the other three sets of inputs. The other two faults that were missed by the transition-pair tests were also missed by the transition and random tests. The other three faults missed by the random and the transition tests were all different. All of the naturally occurring faults were found by all four sets of tests.</p><p>The goals of this empirical pilot study were twofold. The first goal was to see if the specificationbased testing criteria could be practically applied. The second was to make a preliminary evaluation of their merits by evaluating the branch coverage and fault coverage. Both goals were satisfied; the criteria were applied and worked well. They performed better than the random generation of test cases. However, there are several limitations to the interpretation of the results. First, Cruise is of moderate size; longer and more complicated programs are needed. Second, the 25 faults inserted into Cruise were generated intuitively. More studies should be carried out to reveal the types of faults that can be detected by system testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>The current research literature reports on specific tools for specific formal specification languages <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref>, manual methods for deriving tests from specifications <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref>, case studies on using specifications to check the output of the software on specifications <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref> and formalizations of test specifications <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43]</ref>. The term specification-based testing is used in the narrow sense of using specifications as a basis for deciding what tests to run on software. This section reviews some of these techniques, dividing them into approaches that use model-based, algebraic and state-based specifications. It should be noted that this review is not complete; only a sampling of the most relevant research can fit into this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Model-based approaches</head><p>Model-based specification languages, such as Z and VDM, attempt to derive formal specifications of the software based on mathematical models. One of the earlier papers on model-based testing was by Zweben et al. <ref type="bibr" target="#b43">[44]</ref>. They started with control-flow and data-flow testing techniques and applied them to abstract data types (ADTs). A graph was created where nodes represented functions from the ADT and an edge was created from f 1 to f 2 if f 2 can be called after f 1. The data flow analysis was based on the function pre-and post-conditions and criteria such as branch testing and all-uses were defined. A similar approach is applied in this paper, although the specification graph is very different. The specification graph defined in this paper is based on states in the software system behaviour, thus the tests are at the system level instead of for individual ADTs, as the tests from Zweben et al. were.</p><p>Spence and Meudec <ref type="bibr" target="#b44">[45]</ref> and Dick and Faivre <ref type="bibr" target="#b39">[40]</ref> suggested using specifications to produce predicates and then using predicate satisfaction techniques to generate test data. Given a set of predicates that reflect pre-conditions, invariants and post-conditions, test cases are generated to satisfy individual clauses. Their work was for VDM specifications and primarily focused on state-based specifications, using finite-state automata representations. Dick and Faivre discussed straightforward translations of VDM pre-and post-conditions into disjunctive normal form predicates. Their paper did not fully address techniques for solving predicates, but suggested using Prolog theorem proving techniques and finite-state machines to sequence tests of operations. Although their work was based on completely different types of specifications (VDM), some of their ideas influenced the full predicate testing criterion in this paper. Their work does not include testing with invalid inputs, specifically testing for faults, or comprehensive criteria for test selection and measurement. Derrick and Boiten <ref type="bibr" target="#b18">[19]</ref> adapted Dick and Faivre's ideas to Z and proposed a solution for how to recreate tests when specifications change.</p><p>Stocks and Carrington <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, Amla and Ammann <ref type="bibr" target="#b14">[15]</ref> and Ammann and Offutt <ref type="bibr" target="#b15">[16]</ref> proposed using a form of domain partitioning to generate test cases. Given a description of an input domain, the idea is to use specifications to partition the input domain into subsets. This approach is based on a modification of the category-partition method for test generation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b36">37]</ref>. Hierons <ref type="bibr" target="#b20">[21]</ref> presented algorithms that rewrite Z specifications into a form that can be used to partition the input domain. From this, states of a finite-state automaton are derived, which is then used to control the test process.</p><p>Hayes <ref type="bibr" target="#b19">[20]</ref> has suggested a dynamic scheme that uses run-time verification of the program. The idea is to add code to the program to check predicates from the specifications, such as type invariants, preconditions and input-output pairs.</p><p>Chang and Richardson <ref type="bibr" target="#b45">[46]</ref> presented techniques to derive test conditions from an ADL specification, a predicate logic-based language that is used to describe the relationships between inputs and outputs of a program unit. The idea is to use test selection strategies to partition both input and output domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Algebraic approaches</head><p>Algebraic specification languages describe software by making formal statements, called axioms, about relationships among operations and the functions that operate on them. Gannon et al. <ref type="bibr" target="#b34">[35]</ref> used a script derivation approach. They treated the axioms as a language description and generated strings on that language to serve as test cases. Doong and Frankl <ref type="bibr" target="#b40">[41]</ref> used a similar approach to test object-oriented software.</p><p>Bernot <ref type="bibr" target="#b38">[39]</ref> proposed a similar scheme, with more formalization of the process and the test cases. Bougé et al. <ref type="bibr" target="#b33">[34]</ref> suggested a logic programming approach to generating test cases from algebraic specifications. Tsai et al. <ref type="bibr" target="#b22">[23]</ref> used a similar approach, but started with relational algebra queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">State-based approaches</head><p>Specification-mutation testing is defined with respect to a model-checking specification <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>. Mutation analysis of specifications yields mutants from which a model checker generates counterexamples that can be used as test cases. A specification for model checking has two parts. One part is a state machine defined in terms of variables, initial values for the variables and a description of the conditions under which variables may change value. The other part is temporal logic constraints on valid execution paths. Conceptually, a model checker visits all reachable states and verifies that the invariants and temporal logic constraints are satisfied. Model checkers exploit clever ways to avoid brute force exploration of the state space.</p><p>Blackburn and Busser <ref type="bibr" target="#b48">[49]</ref> used state-based functional specifications of the software, expressed in the language T-Vec, to derive disjunctive normal form constraints, similar to Dick and Faivre's method. These constraints are then solved to generate test cases, using special-purpose heuristic algorithms. There is a strong similarity between Blackburn and Busser's algorithms and the algorithms used by Offutt's test data generator for mutation <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>, the key difference being that Blackburn and Busser's is specification-based, whereas Offutt's constraints are code-based.</p><p>Weyuker et al. <ref type="bibr" target="#b37">[38]</ref> present a method to generate test data from Boolean logic specifications of software. They applied their techniques to the FAA's Traffic Collision and Avoidance System (TCAS) and used a few mutation-style faults to measure the quality of the test cases. Their method is very similar to the full predicate criterion described here, but is restricted to Boolean variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Test generation via finite-state machines</head><p>Using finite state machines (FSM) for test generation has a long history. In the 1970s, Chow <ref type="bibr" target="#b51">[52]</ref> used FSMs to generate tests for telecommunication systems. Arcs of the FSM are annotated with inputs and expected outputs. A spanning tree is generated from the FSM and test sequences are based on paths through this tree.</p><p>Test generation methods based on FSMs include tour <ref type="bibr" target="#b52">[53]</ref>, the W-method <ref type="bibr" target="#b51">[52]</ref> and the partial-W method <ref type="bibr" target="#b53">[54]</ref>. Their objective is to detect output errors based on state transitions driven by inputs. FSM-based test generation has been used to test a variety of types of applications including lexical analysers, real-time process control software, protocols, data processing and telephony.</p><p>FSMs have also been used to test object-oriented programs <ref type="bibr" target="#b54">[55]</ref> and designs <ref type="bibr" target="#b55">[56]</ref>. Kung et al. <ref type="bibr" target="#b54">[55]</ref> extracted the FSM from the code using symbolic execution, while Turner and Robson <ref type="bibr" target="#b55">[56]</ref> derived the FSM from the design of a class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Summary</head><p>Most of the current specification-based testing techniques use manual methods that cannot be generalized or automated. Goals of the current research include generalizing the currently known techniques, defining measurable criteria and developing automated tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>This paper introduces a new technique for generating test data from formal software specifications. Formal specifications represent a significant opportunity for testing because they precisely describe the functionality of the software in a form that can be easily manipulated by automated means. This research addresses the problem of developing formalizable, measurable criteria for generating test cases from specifications. Criteria based on requirements/specifications and a derivation process for generating the test cases were presented. Results from applying the criteria and process to a small example were presented. This case study was evaluated using Atac to measure branch coverage and the technique was found to achieve a high level of coverage. It was also used to detect a large percentage of faults successfully. These results indicate that this technique can benefit software developers who construct formal specifications during development.</p><p>Although these criteria are introduced as being general and independent of language, both the specification language and the implementation language used have subtle impacts on how the criteria are interpreted and applied. To as much an extent as possible, test specifications are described in terms of simple algebraic predicates and the specification graph is developed as a languageindependent intermediate representation. The predicates use variables that appear in the specifications and operators that are legal on these variables (primarily equality, assignment and relational operators).</p><p>Most languages have some form of algebraic predicate representation. The SPECTEST tool needs parsers to translate from the specification languages to the specification graph, a model that has been used successfully for three different specification languages.</p><p>One interesting result from the branch coverage is that only the functional specifications related to the cruise control state machine itself were covered. While this was certainly the focus of the study, several branches having to do with the input were left out. For the testing of real systems, the input specifications must be considered as well, either by adapting the method presented here or by using another testing method.</p><p>The immediate goal of this research was to develop formal criteria for generating tests from statebased specifications. Short term goals are to develop mechanical procedures and an automatic test data generation tool. Longer term goals include applying these criteria to industrial software and to expand SPECTEST to handle other UML diagrams and other specification languages. The advantage of this automation is that it allows large systems to be tested.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (a) Code-based test generation and (b) specification-based test generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Elevator door open transition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Constructing test case requirements from an expression parse tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>To test the state S at the transition-pair criterion six tests are required, from: (1) 1 to i; (2) 2 to i; (3) 1 to ii; (4) 2 to ii; (5) 1 to iii and (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>P11 OR P12) : (P5 OR P6) 6. (P11 OR P12) : (P7 OR P8) OVERRIDE 1. (P7 OR P8) : P9 2. (P7 OR P8) : P10 3. (P7 OR P8) : (P11 OR P12) P5 OR P6) : P2 6. (P5 OR P6) : P3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 .</head><label>1</label><figDesc>Test specification OFF-1: Prefix: Ignited = True -Reach INACTIVE state Test case values: Ignited = False -P2 Triggering event Ignited = True -P1 Triggering event Expected outputs: INACTIVE 2. Test specification OFF-2: Prefix: Ignited = True -Reach INACTIVE state Ignited = True -P3 Condition variable Running = True -P3 Condition variable Brake = False -P3 Condition variable Activate = True -Reach CRUISE state Test case values: Ignited = False -P4 Triggering event Ignited = True -P1 Triggering event Expected outputs: INACTIVE 3. Test specification OFF-3: Prefix: Ignited = True -Reach INACTIVE state Ignited = True -P3 Condition variable Running = True -P3 Condition variable Brake = False -P3 Condition variable Activate = True -Reach CRUISE state Ignited = True -P7 Condition variable Running = True -P7 Condition variable Toofast = False -P7 Condition variable Brake = True -Reach OVERRIDE state Test case values: Ignited = False -P9 Triggering event Ignited = True -P1 Triggering event Expected outputs: INACTIVE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Branch and block coverage results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>False CRUISE P9 OVERRIDE T ------Ignited = False OFF OVERRIDE F ------Ignited = False OVERRIDE OVERRIDE T ------Ignited = True OVERRIDE --Running = True OVERRIDE P11</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>APPENDIX B: TRANSITION-PAIR TEST REQUIREMENTS FOR CRUISERather than list before-values and after-values for the triggering events in this table, only the aftervalues are shown; the before-values are assumed to be the inverse.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The multi-part aspect means that a test case is composed of several components: test case values, prefix values, verify values, exit commands and expected outputs. Test case values directly satisfy the test requirements and the other components supply supporting values. The multi-step aspect means that tests are generated in several steps from the functional specifications by a refinement process. The functional specifications are first refined into test specifications, which are then refined into test scripts. The test specifications are described in terms of simple algebraic predicates. The predicates use variables that appear in the specifications and operators that are legal on these variables (primarily equality, assignment and</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>3. Develop transition coverage test requirements. Derive transition predicates. The conditions from step 1 are listed one at a time to form test requirements.</figDesc><table><row><cell></cell><cell></cell><cell>Program</cell></row><row><cell></cell><cell></cell><cell>Input Description</cell><cell>Script Generator</cell><cell>Test Scripts</cell></row><row><cell>Functional Specifications</cell><cell>Parser Parser</cell><cell>Specification Graph</cell></row><row><cell></cell><cell></cell><cell>Test Values</cell><cell>Test</cell></row><row><cell></cell><cell></cell><cell>Generator</cell><cell>Specifications</cell></row><row><cell cols="4">Analyzer Spec Analyzer Spec Analyzer Spec Analyzer (a) Spec User Selection Figure 4. SPECTEST: general process for generating test cases. Test Requirements</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table II .</head><label>II</label><figDesc>Expanded cruise control specification predicates.</figDesc><table><row><cell>P 1</cell><cell>OFF</cell><cell cols="2">¬Ignited ∧ Ignited</cell><cell></cell><cell></cell><cell>INACTIVE</cell></row><row><cell>P 2</cell><cell>INACTIVE</cell><cell cols="2">Ignited ∧ ¬Ignited</cell><cell></cell><cell></cell><cell>OFF</cell></row><row><cell>P 3</cell><cell>INACTIVE</cell><cell cols="5">¬Activate ∧ Ignited ∧ Running ∧ ¬Brake ∧ Activate</cell><cell>CRUISE</cell></row><row><cell>P 4</cell><cell>CRUISE</cell><cell cols="2">Ignited ∧ ¬Ignited</cell><cell></cell><cell></cell><cell>OFF</cell></row><row><cell>P 5</cell><cell>CRUISE</cell><cell cols="2">Running ∧ Ignited ∧ ¬Running</cell><cell></cell><cell></cell><cell>INACTIVE</cell></row><row><cell>P 6</cell><cell>CRUISE</cell><cell cols="2">¬Toofast ∧ Ignited ∧ Toofast</cell><cell></cell><cell></cell><cell>INACTIVE</cell></row><row><cell>P 7</cell><cell>CRUISE</cell><cell cols="5">¬Brake ∧ Ignited ∧ Running ∧ ¬Toofast ∧ Brake</cell><cell>OVERRIDE</cell></row><row><cell>P 8</cell><cell>CRUISE</cell><cell cols="5">¬Deactivate ∧ Ignited ∧ Running ∧ ¬Toofast ∧ Deactivate</cell><cell>OVERRIDE</cell></row><row><cell>P 9</cell><cell cols="3">OVERRIDE Ignited ∧ ¬Ignited</cell><cell></cell><cell></cell><cell>OFF</cell></row><row><cell cols="4">2 P INACTIVE P 4 P OFF 1 P</cell><cell></cell><cell></cell><cell>P</cell><cell>3</cell><cell>CRUISE</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5 P P</cell><cell>6</cell></row><row><cell></cell><cell></cell><cell></cell><cell>10 P</cell><cell>P</cell><cell>11</cell><cell>12 P</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>9</cell><cell></cell><cell></cell><cell>P</cell><cell>7</cell><cell>P</cell><cell>8</cell></row><row><cell></cell><cell></cell><cell></cell><cell>OVERRIDE</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">Figure 5. Specification graph for cruise control.</cell></row></table><note><p>10 OVERRIDE Running ∧ Ignited ∧ ¬Running INACTIVE P 11 OVERRIDE ¬Activate ∧ Ignited ∧ Running ∧ ¬Brake ∧ Activate CRUISE P 12 OVERRIDE ¬Resume ∧ Ignited ∧ Running ∧ ¬Brake ∧ Resume CRUISE</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The first row is the predicate as it appears in the specification; every clause is True. This corresponds to a valid test input (and is also the transition coverage test case for this transition). The subsequent rows make each clause False in turn, corresponding to invalid inputs. Because there are no OR operators, the full predicate coverage criterion is satisfied by holding all other clauses True. The post-states are the expected values. Five of them represent invalid transitions and it is assumed that the software will remain in the same state.</figDesc><table><row><cell></cell><cell cols="4">Activate = True -Triggering event</cell><cell></cell><cell></cell></row><row><cell cols="3">Expected outputs: INACTIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">5. Test specification P 3 -5:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Prefix:</cell><cell cols="5">Ignited = True -Reach INACTIVE state</cell><cell></cell></row><row><cell>Test case value:</cell><cell cols="4">Activate = True -Trigger before-value</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Running = True -Condition variable</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Brake</cell><cell cols="3">= False -Condition variable</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Activate = True -Triggering event</cell><cell></cell><cell></cell></row><row><cell cols="3">Expected outputs: INACTIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">6. Test specification P 3 -6:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Prefix:</cell><cell cols="5">Ignited = True -Reach INACTIVE state</cell><cell></cell></row><row><cell>Test case value:</cell><cell cols="4">Activate = False -Trigger before-value</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Running = True -Condition variable</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Brake</cell><cell cols="3">= False -Condition variable</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">Activate = False -Triggering event</cell><cell></cell><cell></cell></row><row><cell cols="3">Expected outputs: INACTIVE</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Activate</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">The six test case requirements for transition P 3 are:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pre-state</cell><cell cols="6">Activate Ignited Running Brake Activate Post-state</cell></row><row><cell>1. INACTIVE</cell><cell>F</cell><cell>t</cell><cell>t</cell><cell>f</cell><cell>T</cell><cell>CRUISE</cell></row><row><cell>2. INACTIVE</cell><cell>F</cell><cell>f</cell><cell>t</cell><cell>f</cell><cell>T</cell><cell>INACTIVE</cell></row><row><cell>3. INACTIVE</cell><cell>F</cell><cell>t</cell><cell>f</cell><cell>f</cell><cell>T</cell><cell>INACTIVE</cell></row><row><cell>4. INACTIVE</cell><cell>F</cell><cell>t</cell><cell>t</cell><cell>t</cell><cell>T</cell><cell>INACTIVE</cell></row><row><cell>5. INACTIVE</cell><cell>T</cell><cell>t</cell><cell>t</cell><cell>f</cell><cell>T</cell><cell>INACTIVE</cell></row><row><cell>6. INACTIVE</cell><cell>F</cell><cell>t</cell><cell>t</cell><cell>f</cell><cell>F</cell><cell>INACTIVE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table III .</head><label>III</label><figDesc>Faults detected.</figDesc><table><row><cell></cell><cell cols="4">Random Transition Transition-pair Full predicate</cell></row><row><cell>Number of test cases</cell><cell>54</cell><cell>12</cell><cell>34</cell><cell>54</cell></row><row><cell>Faults found</cell><cell>15</cell><cell>15</cell><cell>18</cell><cell>20</cell></row><row><cell>Faults missed</cell><cell>9</cell><cell>9</cell><cell>6</cell><cell>4</cell></row><row><cell>Percentage coverage</cell><cell>62.5%</cell><cell>62.5%</cell><cell>75.0%</cell><cell>83.3%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Copyright c 2003 John Wiley &amp; Sons, Ltd. Softw. Test. Verif. Reliab. 2003; 13:25-53</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work is supported in part by Rockwell Collins, Inc., in part by the U.S. National Science Foundation under grant CCR-98-04111 and in part by the Ministry of Education, Culture, Sports, Science and Technology of Japan under a Grant-in-Aid for Scientific Research on Priority Areas (No. 14019081).</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Contract/grant sponsor: Rockwell Collins, Inc., U.S. National Science Foundation; contract/grant number: CCR-98-04111 Contract/grant sponsor: Ministry of Education, Culture, Sports, Science and Technology of Japan; contract/grant number: Grant-in-Aid for Scientific Research on Priority Areas (No.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test specifications</head><p>The actual test specifications and test scripts are automatically derived from the test requirements. The predicate P 3 is chosen as an illustrative example. P 3 has six full predicate level tests. For the first test case for P 3 , the test case must reach the INACTIVE state; this forms the Prefix. The Test case values set the before-value for the triggering event and the WHEN condition variables of Inactive, Running and Brake, and then sets Activate to be True as the triggering event. The Verify and Exit parts of the specifications are not shown, as they depend on the software. The software can safely be assumed to automatically print the current state and to not require an exit.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">State-based model checking of event-driven system requirements</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Atlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="40" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Specifying software requirements for complex systems: New techniques and their applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Henninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="12" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The CoRE method for real-time requirements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Faulk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brackett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="22" to="33" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Rational Rose 98: Using Rational Rose</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Rational Rose Corporation</publisher>
			<pubPlace>Cupertino, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Rational Software Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating tests from UML specifications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Offutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdurazik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on the Unified Modeling Language (UML &apos;99) Fort Collins</title>
		<title level="s">Springer Lecture Notes in Computer Science</title>
		<meeting>the Second International Conference on the Unified Modeling Language (UML &apos;99) Fort Collins</meeting>
		<imprint>
			<publisher>CO</publisher>
			<date type="published" when="1999-10">October 1999</date>
			<biblScope unit="volume">1723</biblScope>
			<biblScope unit="page" from="416" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SOFL: A formal engineering methodology for industrial applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Offutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ho-Stuart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ohba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="337" to="344" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Special Issue on Formal Methods</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generating test data from SOFL specifications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Offutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An approach to automatic detection of software failures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hlady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kovacevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Pekilis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Prairie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Savor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Seviora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vorobiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE 6th International Symposium on Software Reliability Engineering (ISSRE)</title>
		<meeting>IEEE 6th International Symposium on Software Reliability Engineering (ISSRE)<address><addrLine>Toulouse, France; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995-10">October 1995. 1995</date>
			<biblScope unit="page" from="314" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic failure detection with conditional-belief supervisors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Seviora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE 7th International Symposium on Software Reliability Engineering (ISSRE 96)</title>
		<meeting>IEEE 7th International Symposium on Software Reliability Engineering (ISSRE 96)<address><addrLine>White Plains, NY; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996-10">October 1996. 1996</date>
			<biblScope unit="page" from="4" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Constructing an automated testing oracle: An effort to produce reliable software</title>
		<author>
			<persName><forename type="first">Yang</forename><forename type="middle">H</forename><surname>Luqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Conference on Computer Software and Applications (COMPSAC)</title>
		<meeting>IEEE Conference on Computer Software and Applications (COMPSAC)<address><addrLine>Taipei, Taiwan; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994-11">November 1994. 1994</date>
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The ISDM case study: A dependency management system (specification-based testing)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carrington</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>The University of Queensland, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Test Templates: A specification-based testing framework</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 15th International Conference on Software Engineering</title>
		<meeting>15th International Conference on Software Engineering<address><addrLine>Baltimore, MD; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1993-05">May 1993. 1993</date>
			<biblScope unit="page" from="405" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A framework for specification-based testing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Stocks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="777" to="793" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An applicable family of data flow testing criteria</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Frankl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Weyuker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1483" to="1498" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using Z specifications in category partition testing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Amla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ammann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Seventh Annual Conference on Computer Assurance (COMPASS 92)</title>
		<meeting>Seventh Annual Conference on Computer Assurance (COMPASS 92)<address><addrLine>Gaithersburg, MD; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1992-06">June 1992. 1992</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using formal methods to derive test frames in category-partition testing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ammann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Offutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Ninth Annual Conference on Computer Assurance (COMPASS 94)</title>
		<meeting>Ninth Annual Conference on Computer Assurance (COMPASS 94)<address><addrLine>Gaithersburg, MD; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994-06">June 1994. 1994</date>
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic generation of test scripts from formal test specifications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balcer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hasling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ostrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Symposium on Software Testing, Analysis, and Verification</title>
		<meeting>the Third Symposium on Software Testing, Analysis, and Verification<address><addrLine>Key West, FL; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1989-12">December 1989. 1989</date>
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From Object-Z specifications to ClassBench test suites</title>
		<author>
			<persName><forename type="first">D</forename><surname>Carrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Maccoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Strooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Testing, Verification, and Reliability</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="137" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Testing refinements of state-based formal specifications. Software Testing, Verification, and Reliability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Derrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Boiten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="27" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Specification directed module testing</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="133" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Testing from a Z specification</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hierons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Testing, Verification, and Reliability</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="33" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Formal specification and testing: A case study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Laycock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Testing, Verification, and Reliability</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="23" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automated test case generation for programs specified by relational algebra queries</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Volovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="316" to="324" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">RTCA-DO-178B. Software considerations in airborne systems and equipment certification, December 1992. Radio Technical Commission for Aeronautics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Applicability of modified condition/decision coverage to software testing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Chilenski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Engineering Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On a theory of boolean functions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Akers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="487" to="498" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fault classes and error detection capability of specification-based testing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Software Engineering and Methodology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="411" to="424" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tools for formal specification, verification, and validation of requirements</title>
		<author>
			<persName><forename type="first">C</forename><surname>Heitmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Labaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1997 Annual Conference on Computer Assurance (COMPASS 97)</title>
		<meeting>1997 Annual Conference on Computer Assurance (COMPASS 97)<address><addrLine>Gaithersburg, MD; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997-06">June 1997. 1997</date>
			<biblScope unit="page" from="35" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Testing Object-oriented Systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Binder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Addison-Wesley Publishing Company Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deriving mode invariants from SCR specifications</title>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Second IEEE International Conference on Engineering of Complex Computer Systems</title>
		<meeting>Second IEEE International Conference on Engineering of Complex Computer Systems<address><addrLine>Montréal, Canada; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996-10">October 1996. 1996</date>
			<biblScope unit="page" from="514" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Generating test data from requirements/specifications: Phase II final report</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Offutt</surname></persName>
		</author>
		<idno>ISE-TR-99- 01</idno>
		<ptr target="http://www.ise.gmu.edu/techrep/" />
		<imprint>
			<date type="published" when="1999-01">January 1999</date>
			<pubPlace>Fairfax, VA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Information and Software Engineering, George Mason University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">ATAC: A data flow coverage testing tool for C</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>London</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Symposium of Quality Software Development Tools</title>
		<meeting>Symposium of Quality Software Development Tools<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1992-05">May 1992. 1992</date>
			<biblScope unit="page" from="2" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Software testing based on formal specifications: A theory and a tool</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Gaudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Marre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software Engineering Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="387" to="405" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Test sets generation from algebraic specifications using logic programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bougé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Choquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fribourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-C</forename><surname>Gaudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="343" to="360" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Data-abstraction implementation, specification, and testing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcmullin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hamlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="223" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Specification and testing of abstract data types</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jalote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Language</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="82" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Design for a tool to manage specification-based testing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Ostrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Weyuker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Software Testing</title>
		<meeting>the Workshop on Software Testing<address><addrLine>Banff, Alberta; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1986-07">July 1986. 1986</date>
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatically generating test data from a boolean specification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Weyuker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goradia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Testing against formal specifications: A theoretical view</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bernot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Distributed Computing (ADC) and Colloquium on Combining Paradigms for Software Development (CCPSD)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Brighton, U.K.; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1991-04">April 1991. 1991</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="99" to="119" />
		</imprint>
	</monogr>
	<note>TAPSOFT&apos;91: Proceedings of the International Joint Conference on Theory and Practice of Software Development</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Automating the generation and sequencing of test cases from model-based specifications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Faivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FME &apos;93: Industrial-Strength Formal Methods</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>FME &apos;93: Industrial-Strength Formal Methods<address><addrLine>Odense, Denmark; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">670</biblScope>
			<biblScope unit="page" from="268" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Case studies on testing object-oriented programs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Doong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Frankl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Fourth Symposium on Software Testing, Analysis, and Verification</title>
		<meeting>Fourth Symposium on Software Testing, Analysis, and Verification<address><addrLine>Victoria, British Columbia, Canada; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1991-10">October 1991. 1991</date>
			<biblScope unit="page" from="165" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Testing formal specifications to detect design errors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kemmerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="43" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Test data generation using a Prolog with constraints</title>
		<author>
			<persName><forename type="first">N</forename><surname>Choquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Workshop on Software Testing</title>
		<meeting>Workshop on Software Testing<address><addrLine>Banff, Alberta; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1986-07">July 1986. 1986</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Systematic testing of data abstractions based on software specifications. Software Testing, Verification, and Reliability</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Zweben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Heym</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kimmich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="39" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generation of software tests from specifications</title>
		<author>
			<persName><forename type="first">I</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meudec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SQM&apos;94</title>
		<meeting>SQM&apos;94<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>Computational Mechanics Publications</publisher>
			<date type="published" when="1994-07">July 1994. 1994</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="517" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Structural specification-based testing with ADL</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 International Symposium on Software Testing, and Analysis</title>
		<meeting>the 1996 International Symposium on Software Testing, and Analysis<address><addrLine>San Diego, CA; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996-01">January 1996. 1996</date>
			<biblScope unit="page" from="62" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A specification-based coverage metric to evaluate test sets</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Ammann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth IEEE International Symposium on High Assurance Systems</title>
		<meeting><address><addrLine>Washington, DC; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999-11">November 1999. 1999</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Using model checking to generate tests from specifications</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Ammann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Majurski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second IEEE International Conference on Formal Engineering Methods (ICFEM&apos;98)</title>
		<meeting><address><addrLine>Brisbane, Australia; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998-12">December 1998. 1998</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A tool for developing critical systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Busser</surname></persName>
		</author>
		<author>
			<persName><surname>T-Vec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1996 Annual Conference on Computer Assurance (COMPASS 96)</title>
		<meeting>1996 Annual Conference on Computer Assurance (COMPASS 96)<address><addrLine>Gaithersburg, MD; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996-06">June 1996. 1996</date>
			<biblScope unit="page" from="237" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">An extended overview of the Mothra software testing environment</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Demillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Guindi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Mccracken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Offutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Second Workshop on Software Testing, Verification, and Analysis</title>
		<meeting>Second Workshop on Software Testing, Verification, and Analysis<address><addrLine>Banff, Alberta; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1988-07">July 1988. 1988</date>
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Constraint-based automatic test data generation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Demillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Offutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="900" to="910" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Testing software designs modeled by finite-state machines</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fault detection for sequential machines by transition tours</title>
		<author>
			<persName><forename type="first">S</forename><surname>Naito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tsunoyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Fault Tolerant Computing Systems</title>
		<meeting>Fault Tolerant Computing Systems</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="page" from="238" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Test selection based on finite state models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bochman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khendek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amalou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghedasmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="591" to="603" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A test strategy for object-oriented programs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Toyoshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th Computer Software and Applications Conference (COMPSAC 95)</title>
		<meeting><address><addrLine>Dallas, TX</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995-08-19">19. August 1995. 1995</date>
			<biblScope unit="page" from="239" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The state-based testing of object-oriented programs</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Robson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1993 IEEE Conference on Software Maintenance (CSM-93)</title>
		<meeting>1993 IEEE Conference on Software Maintenance (CSM-93)<address><addrLine>Montréal, Quebec, Canada; Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1993-09">September 1993. 1993</date>
			<biblScope unit="page" from="302" to="310" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
