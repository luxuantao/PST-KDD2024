<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MapReduce Program Synthesis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Calvin</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aws</forename><surname>Albarghouthi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MapReduce Program Synthesis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C07FDBD74146EEF9B14EF6E28BD90D5F</idno>
					<idno type="DOI">10.1145/(tocome</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T05:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.2.2 [Automatic Programming]: Program synthesis Keywords program synthesis</term>
					<term>data analysis</term>
					<term>verification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>By abstracting away the complexity of distributed systems, large-scale data processing platforms-MapReduce, Hadoop, Spark, Dryad, etc.-have provided developers with simple means for harnessing the power of the cloud. In this paper, we ask whether we can automatically synthesize MapReduce-style distributed programs from input-output examples. Our ultimate goal is to enable end users to specify large-scale data analyses through the simple interface of examples. We thus present a new algorithm and tool for synthesizing programs composed of efficient data-parallel operations that can execute on cloud computing infrastructure. We evaluate our tool on a range of real-world big-data analysis tasks and general computations. Our results demonstrate the efficiency of our approach and the small number of examples it requires to synthesize correct, scalable programs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Over the past decade, we have witnessed a transformational rise in distributed computing platforms that allowed us to seamlessly harness the power of cloud and cluster computing infrastructure. Distributed programming platformssuch as Google's original MapReduce <ref type="bibr" target="#b22">[25]</ref>, Hadoop <ref type="bibr" target="#b55">[58]</ref>, Spark <ref type="bibr" target="#b59">[62]</ref>, and Dryad <ref type="bibr" target="#b58">[61]</ref>-equipped average developers with tools that instantly transformed them into distributed systems developers. Specifically, these platforms provided developers with abstract data-parallel operators-forms of map and reduce-that shielded them from the monstrous complexity of distributed computing, e.g., node failures, load balancing, network topology, distributed protocols, etc.</p><p>By adding a layer of abstraction on top of distributed systems and providing developers with a restricted API, large-scale data processing platforms have become household names and indispensable tools for the modern software developer and data analyst. In this paper, we ask whether we can raise the level of abstraction even higher than what state-of-the-art platforms provide, but this time with the goal of unleashing the power of cloud computing for the average computer user. To that end, we present a novel program synthesis technique that is capable of synthesizing programs in the general MapReduce paradigm. Our technique uses the simple interface of input and output examples as the means for specifying a computation. With this synthesis technology and the simplicity of its example-based interface, we make a step forward towards enabling end users to perform large-scale data analyses and general computations, without knowledge of programming and distributed computing frameworks.</p><p>Our contributions are inspired by, and bring together, a number of seemingly disparate threads of development:</p><p>Program synthesis Recent developments in end-user program synthesis and synthesis from examples <ref type="bibr" target="#b10">[13,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b26">29,</ref><ref type="bibr" target="#b37">40,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b43">46]</ref> demonstrated the power of input-output examples as a means for describing non-trivial computation at a level accessible by users with no programming knowledge. A success story in this space is the work on spreadsheet manipulation, FlashFill <ref type="bibr" target="#b27">[30]</ref>, which quickly made the transition from research into Microsoft Excel.</p><p>Data-parallel systems Distributed computing platforms <ref type="bibr" target="#b22">[25,</ref><ref type="bibr" target="#b55">58,</ref><ref type="bibr" target="#b58">61,</ref><ref type="bibr" target="#b59">62]</ref> have supplied us with powerful yet simple abstractions for large-scale data analysis and general computation. Frameworks like Spark and Hadoop have a large user base, commercial support, and are part of the modern developer's toolkit.</p><p>Large-scale data analysis We are witnessing an explosive growth in big-data analytics, with across-the-board interest from industry, governments, journalists, and even techsavvy individuals. This wide interest in data analysis, coupled with the rise in public cloud infrastructure <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">5,</ref><ref type="bibr">7]</ref>, has made writing large-scale data analyses a standard task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthesis challenges</head><p>In its simplest form, a MapReducelike program <ref type="foot" target="#foot_0">1</ref> is composed of a mapper, which applies an operation in parallel to each element in a (potentially very large) list of elements, and a reducer, which aggregates the results computed by the mapper to produce a final output. The question we ask here is how can we synthesize a MapReduce program from input-output examples? This raises a number of challenges:</p><p>-There are many ways to define a data-parallel program for some desired task. How do we partition the computation between different data-parallel operators?</p><p>-While the MapReduce paradigm shields us from many complexities of distributed systems, it does not shield us from network non-determinism (the shuffle phase <ref type="bibr" target="#b22">[25]</ref>). So, how do we synthesize deterministic programs in this setting?</p><p>-How do we synthesize two or more data-parallel functions (e.g., map and reduce) whose composition is the desired program?</p><p>Functional synthesis technique To tackle these challenges, first, we notice that MapReduce-style programming readily provides us with a common structure for our program: a composition of data-parallel operations, e.g., map followed by reduce, or a sequence of map and reduce. This restricts the space of possible programs, as we are not searching for an arbitrary piece of code to realize the given input-output examples. In a sense, the MapReduce paradigm provides us with a program template in which we need to fill the missing pieces. We make the key observation that restricting synthesis to MapReduce-like programs forces discovery of inherently parallel implementations of a desired computation.</p><p>Capitalizing on this insight, we designed our program synthesis technique to be parameterized by a set of higher-order sketches (HOS): templates that dictate a data-parallel structure on the synthesized program. For instance, if we want to find a program composed of a map followed by a reduce, we simply instantiate our algorithm with the following HOS:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>map</head><p>. reduce where map and reduce are higher-order functions, as typically defined in functional programming languages; the symbol signifies the missing pieces of the template-in this case, functions to be applied by the mapper and reducer; and the . symbol is reverse function composition, i.e., (f. g)(x) denotes g(f (x)). Alternatively, if we seek a more complex function, perhaps a post-processing step after the reduce, we can instantiate our technique with the following HOS:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>map</head><p>. reduce .</p><p>where the final signifies the missing computation that is applied to the results of the reducer. By instantiating our algorithm with various HOSs, we guide it towards synthesizing programs following data-parallel programming patterns. Our synthesis algorithm is compositional, parallelizable, and synthesizes programs in typed λ-calculus equipped with predefined functions and data-parallel operators that closely mimic those in Apache Spark's API <ref type="bibr" target="#b1">[3]</ref>. We chose Spark due to its functional nature, which allows us to design an elegant synthesis algorithm and leverage developments in functional program synthesis <ref type="bibr" target="#b7">[11,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b35">38,</ref><ref type="bibr" target="#b42">45]</ref>. We carefully chose the set of data-parallel components to be generic across cluster programming frameworks. Thus, our approach is not tied to Spark, and our synthesized programs can be easily translated to other platforms. It is important to note that we do not consider low-level features (like persistence) that are exposed by cluster-programming frameworks for maximizing performance (see <ref type="bibr">Section 8)</ref>.</p><p>Dealing with shuffles In a distributed setting, the results of the mapper-a list of elements-may be shuffled along the way to the reducer; that is, an arbitrary permutation of the results of the mapper will be processed by the reducer. As a result, we need to synthesize reducers that are deterministic despite non-determinism introduced by the network. Specifically, the argument r to a reducer is a binary function of type τ → τ → τ . To ensure that the reducer is deterministic, we need to synthesize programs where (τ, r) form a commutative semigroup; that is, r needs to be commutative, associative, and closed on the set of elements of type τ . This ensures that the reducer (i) is deterministic in the face of network non-determinism and (ii) can apply the binary function r in parallel on elements of the input list and as a combiner <ref type="bibr" target="#b22">[25]</ref>. Our technique employs a hyperproperty verification phase that utilizes SMT solvers to prove that binary functions applied by reducers form commutative semigroups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation and evaluation</head><p>We have implemented our algorithm in BIGλ, a modular tool that synthesizes Apache Spark programs that can seamlessly execute on a single machine or on the cloud. We have used BIGλ to synthesize a range of parallel programs, including data-analysis tasks on real-world datasets-Twitter streams <ref type="bibr" target="#b4">[8]</ref>, Wikipedia dumps <ref type="bibr" target="#b5">[9]</ref>, cycling data <ref type="bibr" target="#b3">[6]</ref>-and other non-trivial dataparallel programs. Our evaluation demonstrates the (i) efficiency of our technique, (ii) its ease of use with a small number of examples, and (iii) its wide-ranging applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions We summarize our contributions below:</head><p>-We present a compositional program synthesis algorithm that enables synthesis of data-parallel programs under the MapReduce programming paradigm, broadly construed.</p><p>-We address the problem of synthesizing distributed programs in the presence of network-induced non-determinism, and use hyperproperty verification techniques to prove that reduce operations form commutative semigroups.</p><p>-We present BIGλ, a modular data-parallel program synthesis tool that is built on top of the Apache Spark API and the Z3 SMT solver.</p><p>-We demonstrate BIGλ's efficiency, its usability, and its applicability to synthesizing a range of programs, including distributed data analysis tasks on real-world datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Motivation</head><p>We now provide background on MapReduce frameworks and demonstrate our synthesis approach with examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data-parallel Programming Frameworks</head><p>Since the introduction of Google's MapReduce system in Dean and Ghemawat's seminal paper <ref type="bibr" target="#b22">[25]</ref>, a number of powerful systems that implement and extend the MapReduce paradigm have been proposed, e.g., Hadoop <ref type="bibr" target="#b55">[58]</ref>, Spark <ref type="bibr" target="#b59">[62]</ref>,</p><p>and Dryad <ref type="bibr" target="#b58">[61]</ref>, amongst others [2, <ref type="bibr" target="#b8">12,</ref><ref type="bibr" target="#b29">32]</ref>. For the purposes of our work here, we present a generic view of data-parallel programs as functional programs.</p><p>In its simplest form, a MapReduce program contains an application of map followed by an application of reduceByKey: map m . reduceByKey r where the types of m and r are</p><formula xml:id="formula_0">m : τ → (k, v) r : v → v → v</formula><p>That is, given a list of elements of type τ , the mapper applies m in parallel to each element, producing a key-value pair of type (k, v). Then, for each key produced by the mapper, reduceByKey receives a list of elements of type v-all values associated with the key-and proceeds to aggregate (or fold) each such list using the function r. Thus, the result of this computation is a list of key-value pairs of type (k, v), where each key appears once in the list.</p><p>Let us illustrate MapReduce computation with a very simple example. Suppose we are given a list of words and we would like to count the number of occurrences of each word in the list. We can do this with the following function: For each input word w, the mapper emits the key-value pair (w, 1); the reducer then sums the values associated with each word w, producing a list [(w 1 , v 1 ), . . . , (w n , v n )] containing each unique word w i and its corresponding count v i . So far, this is good old functional programming. In a distributed environment, however, execution and data are partitioned amongst many nodes. This is illustrated and described in Figure <ref type="figure">1</ref>, where count is applied to a list of words [w 1 , . . . , w n ]. Notice how the shuffle phase routes key-value pairs, of the form (w i , 1), to their respective reducers. In this process, values of a given key w i may arrive out of order.</p><p>In a sense, the reducer views the list as an unordered collection, and therefore may produce different results depending on the order in which it applies the binary reduce function r.</p><p>To ensure that the reducer produces the same value regardless of the shuffle phase, we need to ensure that the binary function passed to the reducer-in this example, addition-is both associative, commutative, and closed on the type the reducer operates on. Indeed, this is what, for instance, the Apache Spark <ref type="bibr" target="#b1">[3]</ref> and Twitter Summingbird <ref type="bibr" target="#b17">[20]</ref> APIs expect from the binary reduce function. Commutativity and associativity ensure determinism despite the shuffle phase. They also allow the runtime environment to apply the function r in parallel and at the mappers before transferring results to the reducers, in order to reduce the amount of transferred data, which might be a bottleneck for large workloads.</p><p>We presented a simple data-parallel program: a mapper followed by a reducer. In many modern frameworks, e.g., Spark and Dryad, we can have more sophisticated combinations of mappers and reducers (e.g., iterative MapReduce) and various forms of data-parallel operations (e.g., flatMap). Here, we will focus on programs made of arbitrary compositions of data-parallel operations presented as higher-order sketches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Examples</head><p>We now illustrate synthesis of two simplified data analyses. Wordcount: The Fibonacci of MapReduce Suppose that you want to compute the number of occurrences of each word appearing in Wikipedia. With many gigabytes of articles, the only way to do this efficiently is via distribution. To synthesize this task, you can supply our algorithm with a fairly simple example describing word counting, e.g.:</p><p>["hello pldi", "hello popl"] → [("hello",2),("popl",1),("pldi",1)]</p><p>where the left side of → is the input (two strings representing simple documents) and the right side is the output (the list of words appearing in the input and their counts).</p><p>The fascinating aspect here is that even with a very simple example that can fit in one line, we can synthesize a wordcounting program that can easily scale to gigabytes of documents. Specifically, our technique synthesizes the following: let wc = flatMap ms . map mp . reduceByKey r where ms doc = split doc " " mp word = (word,1)</p><formula xml:id="formula_1">r c1 c2 = c1 + c2</formula><p>The synthesized program is a composition of three dataparallel operations: (i) a flatMap that maps each document into the list of words appearing in it (using split), and flattens (concatenates) lists of words from all documents into a single list; (ii) a map that transforms each word w into the string-integer pair (w, 1); and (iii) a reduceByKey that computes a count of occurrences of each word.</p><p>. . . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>}</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reduce phase</head><p>In parallel, reducers iteratively apply a binary function r to values of each key to compute a single value-in our example, the sum of all values. . . . . . . The shuffle phase routes key-value pairs with the same key to the reducers. For instance, w 1 = w 3 , and therefore both (w 1 , 1) and (w 3 , 1) are routed to the same reducer. Results may arrive out of order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input a list of words</head><p>Output of mappers a list of word-number pairs Figure <ref type="figure">1</ref>. High-level view of a MapReduce computation on a simple example Note that for our input-output example, the following argument to reduceByKey would suffice:</p><formula xml:id="formula_2">r c1 c2 = c1 + 1</formula><p>However, this will be rejected by our algorithm, since this reduce function does not form a commutative semigroup over integers. Specifically, using this function results in a nondeterministic program that may produce incorrect results for larger inputs. Suppose, for instance, that our input has four occurrences of "hello". Then, for the key "hello", the reducer would receive the list of values <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1]</ref>. Applying the binary function r in parallel (or as a combiner) could yield the wrong results, e.g., by applying r as follows:</p><formula xml:id="formula_3">1 1 1 1 2 2 3 r 1 1 = 2 r 2 2 = 3</formula><p>Our algorithm ensures that synthesized programs are deterministic, despite the shuffle phase and parallel applications of binary reduce functions (see Section 5). Figure <ref type="figure" target="#fig_1">2</ref> provides two additional examples to illustrate the effects of noncommutative or non-associative reduce functions.</p><p>Histograms Now, suppose that you would like to plot a histogram of the page views of Wikipedia articles 2 using three bins: less than 100 views, 100-10,000 views, and greater than 10,000 views. Such histogram might look as follows:</p><p>&gt;10,000 100-10,000 &lt;100</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of pages</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of views</head><p>To construct a histogram, we need a procedure that finds out the number of articles in each bin. To synthesize such procedure, we can supply the following example: 2 Note: this information is available in Wikipedia log dumps <ref type="bibr" target="#b5">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>String concatenation</head><p>Associative but not commutative "a" "b" "ab" "a" "b" "ba"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Arithmetic mean</head><p>Commutative but not associative The inputs specify a set of pages (by title) and their views; the outputs specify each of the three bins in the histogram (&lt;100, 100-10,000, and &gt;10,000) as bin1, bin2, and bin3.</p><p>Here, our technique would synthesize the following:<ref type="foot" target="#foot_1">3</ref> let hist = map m . reduceByKey r where m p = if (snd p) &lt; 100 then (bin1,1)</p><p>else if (snd p) &lt; 10000 then (bin2,1)</p><formula xml:id="formula_4">else (bin3,1) r c1 c2 = c1 + c2</formula><p>where snd, as is standard, returns the second element of a pair and bini are values of an enumerated type. Observe that map places each page in the appropriate bin and reduceByKey counts the number of pages in each bin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>We now formalize our program model and synthesis tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Programs</head><p>The language in which we synthesize programs is a restricted, typed λ-calculus that is parameterized by a set of components (predefined functions) with fixed arities. We </p><formula xml:id="formula_5">: (α → β) → mset[α] → mset[β]</formula><p>Applies a function f in parallel to each element in a multiset, producing a new multiset.</p><formula xml:id="formula_6">map (λx. x + 1) {1,2,3} → * {2,3,4} flatMap : (α → mset[β]) → mset[α] → mset[β]</formula><p>Applies a function f (that produces a multiset) to each element in a multiset and returns union of all multisets.</p><formula xml:id="formula_7">flatMap (λx. {x,x}) {1,2,3} → * {1,1,2,2,3,3} reduce : (α → α → α) → mset[α] → α</formula><p>Continuously applies a binary function f in parallel to pairs of elements in a multiset, producing a single element as a result. reduce (λx,y. x + y) {1,2,3} → * 6</p><formula xml:id="formula_8">reduceByKey : (α → α → α) → mset[(β, α)] → mset[(β, α)]</formula><p>Similar to reduce, but applies the binary function f to the multiset of values of a given key, resulting in a multiset of key-value pairs, with one value per key. reduceByKey (λx,y. x + y) {(a,1),(b,2),(a,3)} → * {(a,4),(b,2)}</p><formula xml:id="formula_9">filter : (α → bool) → mset[α] → mset[α]</formula><p>In parallel, removes elements of multiset that do not satisfy a Boolean predicate. filter (λx. upperCase x) {"PLDI","pldi","POPL"} → * {"POPL","PLDI"} Table <ref type="table">1</ref>. Set of data-parallel components ΣDP from Apache Spark (variables α and β are implicitly universally quantified)</p><p>first fix an ML-like type system. Let ι 1 , ι 2 , . . . be countably many base types, and let α 1 , α 2 , . . . be countably many type variables. Then, a type can be a monotype or a polytype:</p><formula xml:id="formula_10">monotype τ := ι base type | α type variable | τ 1 → τ 2 function construction | τ 1 × τ 2 product construction | mset[τ ]</formula><p>multiset construction polytype σ := ∀α. τ polymorphic construction</p><p>We use Σ to denote a set of components. The arity of a component f ∈ Σ is denoted arity(f ) ∈ N, where if arity(f ) = n, then f has type τ 1 → . . . → τ n → τ . A program term p over a set of components Σ is defined below:</p><formula xml:id="formula_11">p := wildcard | v variable | f f ∈ Σ and arity(f ) = 0 | f p 1 . . . p n f ∈ Σ and arity(f ) = n &gt; 0 | λv. p 1 v is free in p 1</formula><p>where a variable is free in a program if it is not captured by a λ abstraction. We assume there are countably many variables, v 1 , v 2 , . . ., and wildcards, 1 , 2 , . . . (defined later in this section). For purposes of synthesis, we restrict applications to the form f p 1 . . . p n , where f ∈ Σ and arity(f ) = n.</p><p>We say that a program term (or program, for short) is closed if it has no free variables; otherwise, it is open. Given the simplicity of our type system, we elide type checking and inference rules. We shall use p 1 → * p 2 to denote that p 1 evaluates to p 2 in zero or more reductions.</p><p>We will often use . to denote reverse function composition. For example, given three unary functions f, g, h, the term λi. (f . g . h) i is equivalent to λi. h (g (f i)).</p><p>Higher-order sketches A higher-order sketch (HOS) is an incomplete, well-typed, closed program. A program is incomplete if it contains wildcards. Given a program p, wild(p) is the set of all wildcards appearing in p. Thus, a program p is complete iff wild(p) = ∅. We shall use ∈ p to denote ∈ wild(p). We assume the same wildcard appears at most once in a HOS. Semantically, wildcards are treated the same as free variables.</p><p>Given a HOS h and a complete, closed, well-typed program p, we say that p is a completion of h if there exists a mapping µ from wild(h) to complete programs such that if we replace each i ∈ wild(h) with µ( i ), we get the program p. We use µh to denote the completion of h with µ. Intuitively, a completion of a HOS h replaces all wildcards with terms that have no wildcards to produce a complete program.</p><p>Data-parallel components As defined above, a HOS can be any program with wildcards. However, for practical purposes, a HOS will typically be a composition of data-parallel components, such as map and reduce. Formally, a HOS is a program over some set of components Σ such that Σ DP ⊆ Σ, where Σ DP is a set of data-parallel components.</p><p>We curated Σ DP using data-parallel components that mimic the primary operations offered by Apache Spark <ref type="bibr" target="#b1">[3]</ref>. Σ DP components are described and exemplified in Table <ref type="table">1</ref>. Note that our restricted language does not exploit advanced cluster-programming features needed to maximize performance for complex workloads (see <ref type="bibr">Section 8)</ref>. An important point to make here is that Spark operates over Resilient Distributed Datasets (RDDs) <ref type="bibr" target="#b59">[62]</ref>, a data abstraction that represents a collection of elements partitioned and replicated amongst various nodes in a cluster. Such data representation is incredibly important for scalability of systems like Spark; however, for our purposes-program synthesis-it suffices to model an RDD of elements of a given type τ simply as a multiset (or bag) of τ , denoted mset[τ ]. Intuitively, a synthesis task solution is a deterministic program p that, when applied to any input example I i , produces the corresponding output example O i . Further, p is a completion of one of the HOSs H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthesis tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Compositional Synthesis Algorithm</head><p>We now present our synthesis algorithm and its properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Algorithm Description</head><p>Given a synthesis task S = (E, Σ, H), our goal is to complete one of the HOSs in H such that the result is a solution of S. For practical purposes, we assume that input-output examples in E are monotyped (with no type variables).</p><p>To compute a solution of S, our algorithm employs two cooperating phases, synthesis and composition, that act as producers and consumers, respectively.</p><p>Synthesis phase (producers) Initially, the algorithm infers the type of terms that may appear for each wildcard in H. For instance, it may infer that needs to be replaced by a term of type int → int. Thus, for each inferred type τ , the synthesis phase will produce terms of type τ .</p><p>Composition phase (consumers) For each HOS h ∈ H, the composition phase attempts to find a map µ, from wildcards to complete programs, such that µh is a solution of S. To construct the map µ, this phase consumes results produced by the synthesis phase.</p><p>To implement the two phases, the algorithm maintains two data structures: (i) M , a map from types and typing contexts to sets of (potentially incomplete) programs of the given type; and (ii) C, a set of complete, well-typed programs that are candidate solutions to the synthesis task. Informally, the synthesis phase populates M with programs of inferred types; the composition phase scavenges M to construct candidate solutions and place them in C. This algorithm is best illustrated through an example.</p><p>Example 1 (High-level illustrative example). Suppose that our goal is to synthesize the wordcount example from Section 2.2, and that we have the following two HOSs, {h 1 , h 2 }:</p><formula xml:id="formula_12">h1 = λi. (map 1 . reduceByKey 2) i h2 = λj. (flatMap 3 . map 4 . reduceByKey 5) j</formula><p>The types of the input and output examples are mset <ref type="bibr">[int]</ref> and mset[(string,int)]. Accordingly, the algorithm determines the types of programs that need to be synthesized for the various wildcards i . Specifically, it will determine that</p><formula xml:id="formula_13">1 : string → (string,int) 4 : α → (string, int) 2 : int → int → int 5 : int → int → int 3 : string → mset[α]</formula><p>Observe that, for 4 , we will be looking for programs of type τ → (string,int), where τ is any variable-free monotype. In other words, we know that 4 should be replaced by a function that returns a string-integer pair, but we do not know what type of argument it should take, so we need to consider all possibilities.</p><p>The algorithm detects that the type of 5 is the same as that of 2 , and thus will create one item for that type in the map M . This ensures that we do not duplicate work for wildcards of the same type, even if they appear in different HOSs. <ref type="foot" target="#foot_3">4</ref><ref type="foot" target="#foot_5">4</ref>Figure <ref type="figure" target="#fig_3">3</ref> shows the map M , where each key corresponds to the inferred type of one or more of the wildcards in the HOSs. Each value in M is a set of programs of a given type. For instance, we see that for int → int → int, M contains two programs.</p><p>Producers populate each set M (τ Γ ) with programs in τ Γ (where Γ is the typing context-described later). Consumers query M with the goal of replacing the wildcards in H with complete programs. For instance, consumers might complete the HOS h 2 as follows, using programs from appropriate locations in M to fill the wildcards {3,4,5} :</p><p>This results in the same program we saw in Section 2.2, which is a solution to the wordcount task.</p><p>The algorithm is presented in Figure <ref type="figure" target="#fig_4">4</ref> as a set of rules that update M and C if the premise holds. The algorithm uses the rules INIT and INIT M to initialize the map M as follows: For each wildcard appearing in a HOS h ∈ H, the algorithm infers a type τ for , along with a typing context Γ. The typing context contains all f ∈ Σ, as well as all variables in scope at . For example, consider the following HOS h: λi. map i, and suppose that our input-output examples are both of type mset[int]. Then, the function infer( , h) detects that must have the type int → int, and that the variable i of type mset[int] is in its context. Note that infer can be implemented using Hindley-Milner type inference.</p><p>Type checking notation Given a program p, we will use p ∈ τ Γ to denote that there exists a typing context Γ ⊇ Γ such that σΓ p : στ , where the notation X Y : T , as usual, means that program Y is typable as T under context X, and where σ is a map that replaces all free type variables with variable-free monotypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthesis phase</head><p>The synthesis rules-PVAR, PAPP, and PABS-construct programs of a given type τ under context Γ. This is a top-down synthesis process: it starts with an incomplete program and gradually replaces its wildcards with complete terms. Being type-directed, synthesis rules maintain the invariant that, for any p in M (τ Γ ), we have p ∈ τ Γ . As we shall see, these rules can synthesize every possible complete program for a given type and context.</p><p>Rule PVAR replaces a wildcard in some program p with a variable that is in scope at the location of . For instance, suppose p is the program λx. f , then PVAR may replace with x, or another variable that is in scope. We use the auxiliary function scope( , p) to denote the set of variables in scope at in p (which include variables in context Γ).</p><p>Rule PAPP replaces a wildcard with a function application f from components Σ. The arguments of f are fresh wildcards. Finally, the rule PABS introduces a λ abstraction.</p><p>Example 2. Suppose that we wanted to synthesize a program of type τ = int → int and that the program p = λx. is in M (τ Γ ). Then, using p, PVAR can construct p = λx. x, which can be of the desired type int → int.</p><p>Example 3. Suppose that we want a program of type τ = τ 1 → τ 2 → τ 3 . Suppose also that p = λx. is in M (τ Γ ). Then, PABS can construct a new program p = λx. λy. , from p, by adding an additional λ abstraction. Now, to complete p , we need to replace with a term of type τ 3 .</p><p>Composition phase This phase composes programs in M to synthesize a program p that is a solution to the synthesis task. We use two rules to define this phase. First, for a HOS h ∈ H, the rule CONS attempts to find a completion of h by finding a program p ∈ M (τ Γ ) for each wildcard of type τ and context Γ in h. If this results in a program that is consistent with the type τ I → τ O (type of input-output examples), then we consider it a candidate solution and add it to the set C.</p><p>The rule VERIFY picks a candidate program p from C and checks that (i) p |= E and (ii) p is deterministic, using the function DETERM. If the rule applies, then p is a solution to the synthesis task (Definition 1). For this section, we assume that DETERM is an oracle that determines whether, for every input, the program produces the same output for any order of application of the binary reduce functions in reduce and reduceByKey, if used in p. In Section 5, we present a sound implementation of DETERM. Initialization rules</p><formula xml:id="formula_14">INIT M ← ∅ ← ∅ ∈ H Γ = , h) τ Γ ∈ dom(M ) INIT M M ← M Γ → }]</formula><p>Synthesis phase (producers)</p><formula xml:id="formula_15">p ∈ M Γ ) p v ∈ scope( , p) p = p[ ← v] τ Γ PVAR M ← M [τ Γ → M Γ ) ∪ p ] p M (τ Γ ) ∈ p f : τ 1 → . . . → τ n → τ ∈ Σ p = p[ ← f 1 . . . n ] ∈ τ Γ { i } i are fresh PAPP M ← M [τ Γ → M (τ Γ ) ∪ p ] p ∈ M (τ Γ ) ∈ p p = p[ ← λv. ] ∈ τ Γ and v are fresh PABS M ← M [τ Γ → M (τ Γ ) ∪ p ] Composition phase µ = { → p | ∈ h, τ, Γ = infer( , h), complete p ∈ M (τ Γ )} h ∈ H µh : τ I → τ O CONS C ← C ∪ µh p ∈ C p |= E DETERM(p)</formula><p>VERIFY p is a solution to synthesis task </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Soundness and Completeness</head><p>The following theorem states that the algorithm is sound.</p><p>Theorem 1 (Soundness). Given a synthesis task S = (E, Σ, H), if the synthesis algorithm returns a program p, then p is a solution to S (as per Definition 1).</p><p>The algorithm, as presented, is non-deterministic. To ensure completeness, we need to impose a notion of fairness on rule application. A fair schedule is an infinite sequence of rules c 1 , c 2 , c 3 , . . . , where if at any point i in the sequence some rule c is applicable on some set of parameters, and c has not appeared before, then c eventually appears in the sequence. A fair execution is an application of the rules under a fair schedule. The following theorem states completeness of the algorithm, relative to existence of an oracle DETERM and existence of a solution.</p><p>Theorem 2 (Relative completeness). Given a task S = (E, Σ, H) with a solution, a fair execution will find some solution p of S in finitely many rule applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Determinization and Optimality</head><p>In practice, we are often interested in synthesizing programs that optimize a given objective function. For instance, program size has been found to be desirable in inductive synthesis <ref type="bibr" target="#b7">[11,</ref><ref type="bibr" target="#b23">26,</ref><ref type="bibr" target="#b42">45]</ref>, as smaller programs are considered more likely to generalize to any input-output example. We now show how our algorithm can be enhanced with optimality criteria. We define a weight function ω from programs to natural numbers, where each component f is assigned a weight k f , and a single weight k is assigned to all variables.</p><formula xml:id="formula_16">ω( ) = 0 = k &gt; 0 ω(f ) = k f &gt; 0 ω(λx. p) = ω(x) + ω(p) ω(f p 1 . . . p n ) = ω(f ) + i ω(p i )</formula><p>To ensure that the algorithm returns the solution p with the smallest possible ω(p), we need to impose the following restriction on fair executions. An optimal execution is a fair execution where (i) synthesis rules produce programs in M in order of of increasing weight, and (ii) composition rules compose candidate solutions in C and check them in order of increasing size. In practice, following the above conditions is made feasible by the fact that the weight of function application is additive-not an arbitrary function of the weights of f . By ensuring that any execution is optimal, we ensure that we always synthesize a solution with minimal weight if a solution exists. In Section 6, we describe how we practically implement an optimal schedule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Commutative Semigroup Reducers</head><p>We now address the problem of ensuring that synthesized programs are deterministic. Specifically, we provide a sound implementation of the oracle DETERM used in Section 4. Key idea To ensure that synthesized programs are deterministic, a sufficient condition is that each binary function r : τ → τ → τ , synthesized as an argument to reduce or reduceByKey, forms a commutative semigroup over τ .</p><p>Definition 2 (Commutative semigroup (CSG)). A semigroup is a pair (S, ⊗), where S is set of elements, ⊗ : S × S → S is an associative binary operator over elements of S, and S is closed over ⊗. A commutative semigroup (CSG) is a semigroup (S, ⊗) where ⊗ is also commutative. We say that ⊗ forms a CSG over S if (S, ⊗) is a CSG.</p><p>Note that this is a sufficient but not necessary condition, meaning that a reduce function that does not form a CSG may still result in a deterministic program. Consider, for instance, the following function over integers: let r s1 s2 = max (abs s1) s2</p><p>where max returns the larger of two integers and abs returns the absolute value of an integer. This is not a commutative function: e.g., r -3 2 → * 3, but r 2 -3 → * 2. However, suppose we know that the reducer will only operate on positive integers, perhaps as an artifact of the mapper, then we know that r forms a CSG over positive integers, and can thus operate deterministically in a distributed environment.</p><p>Here, we choose to check the sufficient condition for the following reasons: To check the necessary conditions, we would need a fine-grained type for the reducer, e.g., using refinement types <ref type="bibr" target="#b24">[27]</ref>, that specifies the range of values on which it is invoked, e.g., positive integers. This requires a heavyweight type system and reasoning about all operations of the synthesized program, and not only reducers-which, in our experience, is unnecessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High-level proof technique</head><p>To prove that a binary reduce function forms a CSG, we employ a two-tiered strategy:</p><p>1. Dynamic analysis: First, using the input-output examples, we run the synthesized program simulating every possible shuffle and order of application of binary reduce functions. This provides a lightweight mechanism for rejecting non-CSG reduce functions before resorting to a heavyweight static analysis. This requires exploring an exponential number of possible executions per example; however, we are typically given a small set of examples, allowing us to feasibly explore all possible executions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Static analysis:</head><p>If dynamic analysis cannot show that the reduce function does not form a CSG, we apply a verification phase that checks whether the reduce function is a CSG by encoding it as a first-order SMT formula.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperproperty verification condition</head><p>In what follows, we describe our static analysis technique. Commutativity and associativity are considered hyperproperties <ref type="bibr" target="#b20">[23]</ref>: they require reasoning about multiple executions of a function. Specifically, commutativity is a 2-safety property, as it requires two executions, and associativity is a 4-safety property, as it requires four executions. We exploit this fact to encode CSG checking into a single verification problem, using the self-composition technique <ref type="bibr" target="#b13">[16,</ref><ref type="bibr" target="#b60">63]</ref>. We encode a binary reduce function r as a ternary relation R(i 1 , i 2 , o), where i 1 and i 2 represent the parameters of r, and o represents its return value. Then, we know that r forms a CSG over its input type iff the following formula is valid:</p><formula xml:id="formula_17">∀V. ϕ com ∧ ϕ assoc ⇒ ψ CSG (1)</formula><p>where</p><formula xml:id="formula_18">ϕ com R(i 1 , i 2 , o 1 ) ∧ R(i 2 , i 1 , o 2 ) ϕ assoc R(o 1 , i 3 , o 3 ) ∧ R(i 2 , i 3 , o 4 ) ∧ R(i 1 , o 4 , o 5 ) ψ CSG o 1 = o 2 ∧ o 3 = o 5 V = {i 1 , i 2 , i 3 , o 1 , . . . , o 5 }</formula><p>The formula ϕ com encodes two executions of r with flipped arguments, i 1 and i 2 , for checking commutativity. Formula ϕ assoc encodes three executions of r, for checking associativity, despite associativity being a 4-safety property; this is because ϕ assoc reuses one of the executions in ϕ com . Finally, ψ CSG encodes the correctness condition for r to form a CSG.</p><p>Theorem 3 (VC correctness). Given a binary function r : τ → τ → τ and its encoding R as a ternary relation, then (τ, r) is a CSG if and only if Formula 1 is valid.</p><p>Encoding verification conditions We now discuss how to take a binary function r and construct a corresponding ternary relation R. Since r is binary, it is of the form λi 1 , i 2 . p, where p is a program. We make the simplifying assumption that p uses no higher-order components. As is standard <ref type="bibr" target="#b26">[29,</ref><ref type="bibr" target="#b31">34,</ref><ref type="bibr" target="#b35">38,</ref><ref type="bibr" target="#b53">56]</ref>, we assume that each component f ∈ Σ has a corresponding encoding R f (a 1 , . . . a n , o). We now encode p using the function ENC, defined below. We note that our encoding is analogous to other encodings of functional and imperative programs <ref type="bibr" target="#b35">[38,</ref><ref type="bibr" target="#b53">56]</ref>.</p><formula xml:id="formula_19">ENC(p) = match p with | i i → R ii (o), where R ii (o) ≡ o = i i | f → R f (o) | f p 1 . . . p n → R f (a 1 , . . . , a n , o)∧ i ENC(p i ) ∧ a i = o i , where ENC(p i ) = R pi (. . . , o i )</formula><p>where {a 1 , . . . , a n , o} are fresh variables, constructed uniquely in every recursive call to ENC. All variables other than i 1 , i 2 and the top-most o are implicitly existentially quantified.</p><p>Example 4. The algorithm ENC traverses a program p recursively, constructing a logical representation R f for each component f . Consider, for example, the following binary reduce function: λi 1 , i 2 . max i 1 i 2 , where max returns the larger of its two integer operands. We use ENC(max i 1 i 2 ) to construct the logical representation of this function. Here, the third case of ENC matches and we get the following relation over the variables i 1 , i 2 , and o:</p><formula xml:id="formula_20">∃a 1 , a 2 , o 1 , o 2 . R max (a 1 , a 2 , o) ∧ i∈{1,2} a i = o i ∧ o i = i i Component name Description general pair : α → β → (α, β) create pair cons : α → mset[α] → mset[α]</formula><p>add element to a multiset emit : α → mset <ref type="bibr">[α]</ref> create singleton multiset where</p><formula xml:id="formula_21">arithmetic</formula><formula xml:id="formula_22">R max (a 1 , a 2 , o) ≡ a 1 &gt; a 2 ⇒ o = a 1 ∧ a 1 a 2 ⇒ o = a 2</formula><p>Observe that the above formula can only by satisfied if o is set to the value of the larger of i 1 or i 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Implementation and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Implementation</head><p>We implemented our algorithm in a modular tool we call BIGλ. Components in BIGλ are represented as annotated functions in a separate extensible library. These annotations provide typing information and a logical encoding of each component. Producers generate an infinite list of programs in increasing weight order, for each type in the map M , while consumers lazily combine these programs with the appropriate HOSs. Each producer and consumer runs in a separate process, with one producer process per key of M and one consumer process per HOS. Communication is managed by Python's multiprocessing library. Candidate solutions are checked for determinism by a separate CSG checker, which invokes the Z3 SMT solver <ref type="bibr" target="#b21">[24]</ref>. Synthesized programs are converted into Apache Spark code and are ready to be executed on an appropriate platform.</p><p>Optimal execution We ensure that BIGλ always generates an optimal program with respect to the weight function ω.</p><p>Producers generate infinitely many programs in increasing weight order; by exploiting additivity of our weight function, consumers can efficiently explore the Cartesian products of these infinite lists in increasing weight order. If a consumer produces a solution p, we are guaranteed that p is an optimal solution (with respect to that consumer). In practice, we have multiple consumers; when the first consumer reports a solution p of weight w, we continue executing all other consumers until they produce a solution p of weight w &lt; w or a candidate solution p of weight w w.</p><p>Weight selection BIGλ allows for arbitrary definitions of the weight function. Uniform weights over components optimize for smaller programs. To prevent producers from getting lost down expansions of irrelevant types, we start with uniform weights and automatically inject a bias towards components over types present in the given examples.</p><p>Type checking BIGλ employs incremental type inference, where sets of typing constraints are maintained with each program. Since producers do not communicate during synthesis, different wildcards with the same type variables might specialize to different variable-free monotypes. In order to resolve these inconsistencies, producers keep track of constraints over type variables as they generate programs.</p><p>The consumers then ensure that the intersection of the constraints are satisfiable before producing a candidate solution.</p><p>Limitations Cluster programming platforms like Apache Spark offer a range of low-level features for maximizing performance of a given workload on a given cluster configuration. BIGλ is currently not workload-or configuration-aware, and synthesizes compositions of dataparallel operators without, for instance, broadcasting or persisting data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Synthesis Tasks</head><p>We curated a set of synthesis tasks with data-analysis problems and general MapReduce programs (see Table <ref type="table" target="#tab_3">3</ref>).</p><p>Data-analysis tasks Nowadays, data is generated at an incredible pace, and not only by large organizations, but also by our always-on personal and home devices. We believe that, in the very near future, analyzing data will be of great interest to the average individual with no or little programming knowledge. We have thus collected a number of datasets, with unstructured and semi-structured data, on which we applied our approach to synthesize MapReduce programs that compute useful information.</p><p>Our datasets include a large set of tweets from Twitter that we collected via its streaming API <ref type="bibr" target="#b4">[8]</ref>. We have synthesized programs that extract hashtags and compute their occurrence as well as their co-occurrence frequencies (which are often used in topic modelling <ref type="bibr" target="#b16">[19]</ref>).</p><p>We also acquired a cycling dataset generated by a bike computer. The owner of this data (a cyclist and computer scientist) has used Apache Spark to perform a series of complex analyses <ref type="bibr" target="#b3">[6]</ref>. We have used this dataset to synthesize programs that generate a number of histograms of interest to cyclists, e.g., amount of time spent in a speed range and maximum power output in ten-minute intervals.</p><p>Our datasets also include Shakespeare's full works, where, for example, we synthesized a program that detects and counts the number of lines said by each character in Shakespeare's plays. We also synthesized programs that analyzed Yelp reviews <ref type="bibr" target="#b6">[10]</ref>, English Wikipedia dumps and log files <ref type="bibr" target="#b5">[9]</ref>, and Enron emails <ref type="bibr" target="#b2">[4]</ref>.</p><p>General MapReduce tasks These tasks represent the most common MapReduce tasks seen in tutorials and demonstrations, as well as tasks that can be parallelized in the MapReduce paradigm. In addition, we include (relational algebra) database operations-join, union, etc.-that are often compiled to MapReduce for application to large databases <ref type="bibr" target="#b38">[41]</ref>.</p><p>Components and sketches Each synthesis task uses a set of core components for common base types (such as integers, strings, pairs, lists) along with several higher-order components representing maps and filters. Each task also has more domain-specific components for the input data. For example, when dealing with our Twitter dataset, we add components to handle the metadata and manipulate hashtags. Table <ref type="table" target="#tab_2">2</ref> lists and describes a sample of the components appearing in our synthesis tasks.</p><p>For all tasks, we fix a set of eight HOSs with various compositions of the data-parallel operations in Table <ref type="table">1</ref> and an average of 2-3 wildcards per sketch. These compositions are commonly used in Spark programs and represent most common MapReduce-like patterns <ref type="bibr" target="#b41">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation</head><p>Experimental design We designed our experiments to primarily investigate the following questions:</p><p>1. Efficiency: How fast is the synthesis process? 2. Usability: How many examples do we need for synthesis? 3. Quality: Are the synthesized programs scalable?</p><p>To address these questions, we perform two sets of experiments. The first set involves synthesis of our collected tasks, which we conducted on a Linux machine with a 4-core Intel i7-4790k processor and 16GBs of memory. The second set of experiments takes the solution of synthesized tasks (in the form of executable Apache Spark code) and determines parallel scalability by applying them to gigabytes of data on Google Cloud clusters with n1-standard-8 nodes [5].</p><p>Results Table <ref type="table" target="#tab_3">3</ref> describes the synthesis tasks we collected and results of applying BIGλ on these tasks. All tasks were successfully synthesized under a time limit of 90 seconds and a memory limit of 8GBs. For each task, the table shows (i) the amount of wall and CPU time (aggregate time over all cores) taken by BIGλ; (ii) the size of the synthesized programs (measured by AST nodes); (iii) the number of examples needed for generating a desired solution; (iv) the number of candidate solutions examined for each task (applica- The results show that BIGλ can synthesize all tasks in a few seconds at most, with only a single benchmark exceeding 5 seconds. To demonstrate the difficulty of these benchmarks, we show runtime results for a (sequential) typedirected, top-down synthesis algorithm that maintains a single worklist that initially contains all HOSs. The algorithm, which we call WL, uses the worklist to explore all well-typed completions of the HOSs. This is analogous to Feser et al.'s technique <ref type="bibr" target="#b23">[26]</ref>, but without the deduce step, which is inapplicable in our generic setting. The results show that BIGλ outperforms WL, which exceeds time limit in many instances. WL keeps a single worklist with a HOS h and partial completions for each ∈ wild(h) as elements. Due to this, if h has two wildcards with n completions each, WL might require n 2 elements in the worklist. BIGλ breaks up h into two producers, one for each wildcard, both of which maintain a separate worklist of at most size n. By breaking h into subproblems, BIGλ turns a multiplicative cost into an additive one and saves on space and time.</p><p>Our results indicate that BIGλ can synthesize desired programs with a very small set of examples, despite the complex nature of the programs we synthesize (with solutions consisting of anywhere between 9 and 20 AST nodes). For example, BIGλ correctly synthesizes the following program, which computes hashtag co-occurrence patterns in tweets with only a single example multiset. Throughout our benchmarks, each example is relatively small, consisting of an input multiset of between 3 and 8 elements and an output value of approximately the same size. We checked correctness of synthesized programs manually against our own solutions (which we constructed in the process of collecting the tasks). We attribute the fact that a small number of examples is needed to (i) the restricted structure programs can take, as imposed by HOSs, and (ii) the optimality criterion that favours smaller programs.</p><p>Our evaluation shows that restricting search to higherorder sketches resembling common data-parallel programming patterns indeed results in scalable implementations. For most tasks, synthesized programs closely resembled our own solutions. Figure <ref type="figure" target="#fig_5">5</ref> shows the time it took for three of our synthesized analyses to run on Twitter data, Wikipedia log files, and Wikipedia page dumps, respectively. The plots show the decreasing running time as we increase the number of available compute nodes, from 2 to 10, in our Google cloud cluster. All data sets are on the order of ∼20GBs. We see an expected log-like increase in speedup as we increase the number of nodes (reducers need to apply a binary function log n times on n items), indicating that our synthesized solutions are indeed data-parallel, and thus fit naturally on distributed architectures. Summary In summary, our implementation and evaluation indicate our technique's ability to efficiently synthesize nontrivial data-parallel programs. Our evaluation also shows that, despite the rich language we have and the size of the data we wish to analyze, a small number of examples suffices for synthesizing powerful programs that can scalably execute on cloud infrastructure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Related Work</head><p>Functional program synthesis A number of works have addressed synthesis of functional programs <ref type="bibr">[11, 26, 31, 37-39, 45, 55]</ref>. The works of Feser et al. <ref type="bibr" target="#b23">[26]</ref>, Osera and Zdancewic <ref type="bibr" target="#b42">[45]</ref>, and Frankle et al. <ref type="bibr" target="#b32">[35]</ref>, like our work, utilize both examples and types to search the space of programs.</p><p>The works of Kneuss et al. <ref type="bibr" target="#b35">[38]</ref>, Kuncak et al. <ref type="bibr" target="#b36">[39]</ref>, and Polikarpova and Solar-Lezama <ref type="bibr" target="#b44">[47]</ref>, synthesize functional programs from logical specifications or refinement types. Gvero et al. <ref type="bibr" target="#b28">[31]</ref> synthesize code snippets from types, by enumerating all terms inhabiting a type (similar to what producers do in our algorithm). In comparison with these works, our work addresses the question of synthesizing functional programs that (i) utilize data-parallel operations and (ii) are robust to network non-determinism and reducer parallelization. Our work also introduces higher-order sketches to direct synthesis towards efficient, parallel implementations. Algorithmically, our work is inspired by the approaches of ESCHER <ref type="bibr" target="#b7">[11]</ref>, λ syn <ref type="bibr" target="#b42">[45]</ref>, and λ 2 <ref type="bibr" target="#b23">[26]</ref>. Data transformation synthesis Gulwani's FlashFill <ref type="bibr" target="#b26">[29]</ref> initiated a promising line of work on program synthesis for data manipulation by end users, particularly for spreadsheets. The work has been extended to string and number transformations <ref type="bibr" target="#b50">[53,</ref><ref type="bibr" target="#b51">54]</ref>, table transformations <ref type="bibr" target="#b30">[33]</ref>, and data extraction from spreadsheets <ref type="bibr" target="#b10">[13,</ref><ref type="bibr" target="#b37">40]</ref>. The techniques have also been cast into a generic synthesis framework <ref type="bibr" target="#b45">[48]</ref>.</p><p>The aforementioned works are primarily targeted at data extraction and transformation. Our work differs in two ways: (i) our primary goal is to synthesize programs that can run on large clusters; (ii) our work is also suited for data aggregation tasks-e.g., counting, compressing, building histograms-and not only data transformation tasks. We believe that combining our program synthesis technique with domain-specific data transformation synthesis, data wrangling <ref type="bibr" target="#b33">[36]</ref>, and query synthesis <ref type="bibr" target="#b54">[57,</ref><ref type="bibr" target="#b61">64]</ref> is a promising direction towards enabling end-user data analysis. Synthesis of parallel programs Numerous works have addressed the problem of synthesizing parallel programsfor high-performance applications <ref type="bibr" target="#b56">[59]</ref>, automatic vectorization <ref type="bibr" target="#b11">[14]</ref>, and graph algorithms <ref type="bibr" target="#b46">[49,</ref><ref type="bibr" target="#b47">50]</ref>. Our work is fairly different both in application and technique: we synthesize data-parallel programs for MapReduce-like systems using input-output examples, as opposed to reference implementations or high-level specifications. Data-parallel programming and compilation A range of communities have studied data-parallel programming. We address the most related works. Radoi et al. <ref type="bibr" target="#b48">[51]</ref> studied the problem of compiling sequential loops into MapReduce programs by translating Java loops into a λ-calculus with fold and then, using rewrite rules, attempting to create mappers. Our domain here is different: synthesis from examples. However, our approach opens the door to blackbox parallelization, in which a sequential program is queried for input-output examples and a synthesis engine proposes candidate data-parallel programs.</p><p>Raychev et al. <ref type="bibr" target="#b49">[52]</ref> recently proposed parallelizing sequential user-defined aggregations (over lists) by symbolically executing aggregations on chunks of the input list in parallel. This development is interesting from our perspective as we might be able to (if needed) synthesize sequential reducers that can be run in parallel. Yu et al. also looked at the problem of parallelizing aggregations by detecting that an aggregation is associatively decomposable <ref type="bibr" target="#b57">[60]</ref>.</p><p>Hyperproperty verification Hyperproperty-verification techniques include self-composition <ref type="bibr" target="#b13">[16]</ref>, product programs <ref type="bibr" target="#b12">[15,</ref><ref type="bibr" target="#b14">17,</ref><ref type="bibr" target="#b60">63]</ref> and relational Hoare logic <ref type="bibr" target="#b15">[18,</ref><ref type="bibr" target="#b18">21]</ref>. Our CSG verification can be seen as a self-composition encoding of programs into SMT formulas. Recently, Chen et al. <ref type="bibr" target="#b19">[22]</ref> studied decidability of the problem of verifying determinism of Hadoop-style reducers (over lists), and proposed a reduction to sequential assertion checking. Our problem is different in that our setting is functional, and we need to only consider binary reduce functions to prove determinism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion</head><p>We presented a novel program synthesis technique that, using input-output examples, synthesizes data-parallel programs that can run on cloud infrastructure. Our evaluation demonstrates the power of our approach for synthesizing big-data analyses, amongst other tasks. Our work is a first step towards synthesizing data-parallel programs, and there are many interesting problems that we need to address to help our technique reach its full potential. We discuss two such problems: (i) forms of user interaction and (ii) optimality of synthesized programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User interaction</head><p>In our exposition, we assumed that the user supplies input-output examples describing the desired computation. This form of interaction might be complicated and time consuming, as the user is expected to construct input examples as well as output ones. However, in a real setting, the user likely has access to the data on which they would like to perform the analysis (e.g., a large set of tweets). Therefore, we can use a small slice of that data as a representative input example, and have the user describe the output. From a graphical interaction perspective, the closest work to this proposal is Kandel et al.'s work on Wrangler <ref type="bibr" target="#b33">[36]</ref> and Barowy et al.'s work on FlashRelate <ref type="bibr" target="#b10">[13]</ref>.</p><p>Optimized data-parallel programs Our domain of synthesized programs uses a restricted subset of the data-parallel components available in a cluster computing framework like Apache Spark. Whereas this allows us to harness the parallelism offered by Spark, our synthesized programs do not exploit the various knobs needed to maximize performance. For instance, Spark offers the ability to broadcast data to all nodes in a computation, in order to reduce communication overhead. An interesting problem for future exploration is that of synthesizing programs that are optimized for a given workload and cluster, e.g., by detecting when to broadcast, what data to broadcast, whether to use disk or memory, etc.</p><p>In addition to the aforementioned points, our work opens the door for a range of research opportunities, which we plan on addressing in the near future.</p><p>Automatic parallelization through synthesis We would like to investigate our technique's applicability to transforming sequential programs into data-parallel programs. Specifically, using a CEGIS-like synthesis strategy, we can produce input-output examples from the sequential program and use them to synthesize a parallel version that utilizes data-parallel operations.</p><p>Synthesizing parallel graph algorithms Motivated by our results, we would like to investigate a similar synthesis technique for parallel, vertex-centric graph algorithms as used in distributed graph processing systems like Pregel <ref type="bibr" target="#b40">[43]</ref>, GraphLab <ref type="bibr" target="#b39">[42]</ref>, GraphX <ref type="bibr" target="#b25">[28]</ref>, etc.</p><p>Hyperproperty-aware synthesis To ensure that reduce functions form commutative semigroups, we employed a posthoc verification phase-after the synthesis algorithm detects a program. We would like to investigate whether we can design synthesis algorithms that exploit the fact that we would like to synthesize a program satisfying a hyperproperty (such as associativity or commutativity) to direct the synthesis strategy and prune the search space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>let count = map m . reduceByKey r where m w = (w,1) r a b = a + b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Non-associative/commutative reduce functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. High-level illustration of synthesis algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Synthesis algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Scalability experimental results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>A synthesis task S is a triple (E, Σ, H):1. E is a finite set of input-output examples: pairs of programs {(I 1 , O 1 ), . . . , (I n , O n )}. We assume all programs in E are closed, complete, and well-typed. We assume that all input examples I i have the same type and all output examples O i have the same type. 2. Σ is a set of components. We assume that all functions f ∈ Σ are terminating and referentially transparent. 3. H is a set of HOSs over the signature Σ ∪ Σ DP . Definition 1 (Synthesis task solution). A solution of a synthesis task S = (E, Σ, H) is a program p such that: 1. There is h ∈ H such that p is a completion of h using components Σ. 2. ∀(I, O) ∈ E. p(I) → * O; we denote this as p |= E. 3. The program p is deterministic, regardless of how reduce and reduceByKey operate (see Section 5).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>: int → int → int integer addition eq? : int → int → Bool check two ints for equality mult : int → int → int integer multiplication max : int → int → int return maximal integer factors : int → mset[int] return list of factors of int div : int → int → float integer division to float round : float → int round float to int string pattern : string → Bool string selector (e.g. regex) chars : string → mset[string] convert to list of chars split : string → mset[string] split text by whitespace lower : string → string convert to lowercase len : string → int get length of string Bool checks if left right get tag : Json → string → Json get value of tag in JSON file find tags : Json → mset[string] get top-level tags in JSON file gen perms: mset[α] → mset[(α, α)]convert multiset into all pairs A sample of the used components</figDesc><table /><note><p>one : int integer constant 1 add order : string → string orders the chars of a string data-based hashtag : string → Bool regex selecting hashtags canonical : (α, α) →</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Synthesis task descriptions and results ( indicates a timeout)</figDesc><table><row><cell>Set:task</cell><cell>Description</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We shall use MapReduce to generically refer to the large family of distributed programming frameworks, and not only Google's MapReduce system<ref type="bibr" target="#b22">[25]</ref> or its open source implementation, Hadoop<ref type="bibr" target="#b55">[58]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Assuming the tool is instantiated with appropriate constants</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>← λx. split x " "</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>← λx. (x,1)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>← λx. x + y</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>Note that we can rename variables in both sketches to get the same typing context for both 2 and</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_6"><p>.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Anshul Purohit for setting up and running our cloud experiments. We would like to thank Will Benton for fruitful discussions at this project's outset and for providing us access to his cycling data. We would like to thank Eran Yahav, our shepherd, for helping us improve and clarify the paper. We would also like to thank Zachary Kincaid, Loris D'Antoni, Paris Koutris, and Sam Blackshear for comments on an earlier version of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Amazon web services. aws.amazon.com</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Apache spark. spark.apache.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">Enron emails dataset</title>
		<imprint/>
	</monogr>
	<note>cs.cmu.edu/ ˜enron</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improving spark application performance</title>
		<ptr target=".chapeau.freevariable.com/2014/09/improving-spark-application-performance.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m">Twitter streaming apis. dev.twitter.com/streaming</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m">Wikipedia dumps. dumps.wikimedia.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m">Yelp dataset challenge. yelp.com/dataset_challenge</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recursive program synthesis</title>
		<author>
			<persName><forename type="first">Aws</forename><surname>Albarghouthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Kincaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yasser</forename><surname>Sattam Alsubaiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hotham</forename><surname>Altowim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Altwaijry</surname></persName>
		</author>
		<author>
			<persName><surname>Behm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vinayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingyi</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inci</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madhusudan</forename><surname>Cetindil</surname></persName>
		</author>
		<author>
			<persName><surname>Cheelangi</surname></persName>
		</author>
		<imprint>
			<publisher>Khurram</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rares Vernica, Jian Wen, and Till Westmann. Asterixdb: A scalable, open source BDMS</title>
		<author>
			<persName><forename type="first">Eugenia</forename><surname>Faraaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raman</forename><surname>Gabrielova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Seok</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><forename type="middle">Mahn</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Ok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pouria</forename><surname>Onose</surname></persName>
		</author>
		<author>
			<persName><surname>Pirzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vassilis</surname></persName>
		</author>
		<author>
			<persName><surname>Tsotras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Flashrelate: extracting relational data from semi-structured spreadsheets using examples</title>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">W</forename><surname>Barowy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">G</forename><surname>Zorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From relational verification to SIMD loop synthesis</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Manuel Crespo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">César</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Marron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PPOPP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relational verification using product programs</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Manuel Crespo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">César</forename><surname>Kunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FM</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Secure information flow by self-composition</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">R</forename><surname>D'argenio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><surname>Rezk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSFW</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Proving differential privacy in hoare logic</title>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gaboardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Jesús</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gallego</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">César</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Yves</forename><surname>Strub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CSF</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple relational correctness proofs for static analyses and program transformations</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Benton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Summingbird: A framework for integrating batch and online mapreduce computations</title>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Boykin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian O'</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1441" to="1451" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sasa Misailovic, and Martin C. Rinard. Proving acceptability properties of relaxed nondeterministic approximate programs</title>
		<author>
			<persName><forename type="first">Deokhwan</forename><surname>Michael Carbin</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Commutativity of reducers</title>
		<author>
			<persName><forename type="first">Yu-Fang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Duo</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishant</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bow-Yaw</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACAS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><forename type="middle">B</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hyperproperties. JCS</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Leonardo Mendonc ¸a de Moura and Nikolaj Bjørner. Z3: an efficient SMT solver</title>
	</analytic>
	<monogr>
		<title level="m">TACAS</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Synthesizing data structure transformations from input-output examples</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">K</forename><surname>Feser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swarat</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isil</forename><surname>Dillig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Refinement types for ML</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Pfenning</surname></persName>
		</author>
		<editor>David S. Wise</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>PLDI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graphx: Graph processing in a distributed dataflow framework</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reynold</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Crankshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automating string processing in spreadsheets using input-output examples</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Spreadsheet data manipulation using examples</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CACM</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Complete completion using types and weights</title>
		<author>
			<persName><forename type="first">Tihomir</forename><surname>Gvero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Kuraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruzica</forename><surname>Piskac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Demonstration of the myria big data management service</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Halperin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Teixeira De Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><forename type="middle">Lee</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shumo</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paraschos</forename><surname>Koutris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaspol</forename><surname>Ruamviboonsuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Balazinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<editor>
			<persName><forename type="first">Curtis</forename><forename type="middle">E</forename><surname>Dyreson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Feifei</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">Tamer</forename><surname>Özsu</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spreadsheet table transformations from examples</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Oracle-guided component-based program synthesis</title>
		<author>
			<persName><forename type="first">Susmit</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanjit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Example-directed synthesis: A typetheoretic interpretation</title>
		<author>
			<persName><forename type="first">David</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter-Michael</forename><surname>Osera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Zdancewic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Wrangler: interactive visual specification of data transformation scripts</title>
		<author>
			<persName><forename type="first">Sean</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Paepcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Desney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Saleema</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bo</forename><surname>Amershi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wendy</forename><forename type="middle">A</forename><surname>Begole</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Manas</forename><surname>Kellogg</surname></persName>
		</editor>
		<editor>
			<persName><surname>Tungare</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3363" to="3372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Inductive synthesis of functional programs: An explanation based generalization approach</title>
		<author>
			<persName><forename type="first">Emanuel</forename><surname>Kitzelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ute</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Synthesis modulo recursive functions</title>
		<author>
			<persName><forename type="first">Etienne</forename><surname>Kneuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Kuraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Complete functional synthesis</title>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikaël</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruzica</forename><surname>Piskac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Flashextract: a framework for data extraction by examples</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<title level="m">Mining of Massive Datasets, 2nd Ed</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graphlab: A new framework for parallel machine learning</title>
		<author>
			<persName><forename type="first">Yucheng</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Bickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Naty Leiser, and Grzegorz Czajkowski. Pregel: a system for large-scale graph processing</title>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Malewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">H</forename><surname>Austern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilan</forename><surname>Dehnert</surname></persName>
		</author>
		<author>
			<persName><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">MapReduce Design Patterns: Building Effective Algorithms and Analytics for Hadoop and Other Systems</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Shook</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>O&apos;Reilly</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Type-andexample-directed program synthesis</title>
		<author>
			<persName><forename type="first">Peter-Michael</forename><surname>Osera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Zdancewic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Test-driven synthesis</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Daniel Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Program synthesis from polymorphic refinement types</title>
		<author>
			<persName><forename type="first">Nadia</forename><surname>Polikarpova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<idno>CoRR, abs/1510.08419</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Flashmeta: A framework for inductive program synthesis</title>
		<author>
			<persName><forename type="first">Oleksander</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Elixir: a system for synthesizing concurrent graph programs</title>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Prountzos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Manevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Synthesizing parallel graph programs via automated planning</title>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Prountzos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Manevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Translating imperative code to mapreduce</title>
		<author>
			<persName><forename type="first">Cosmin</forename><surname>Radoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodric</forename><forename type="middle">M</forename><surname>Rabbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manu</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<editor>
			<persName><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Black</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Todd</forename><forename type="middle">D</forename><surname>Millstein</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Parallelizing user-defined aggregations using symbolic execution</title>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Raychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madanlal</forename><surname>Musuvathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Mytkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning semantic string transformations from examples</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Synthesizing number transformations from input-output examples</title>
		<author>
			<persName><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAV</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A methodology for lisp program construction from examples</title>
		<author>
			<persName><forename type="first">D</forename><surname>Phillip</surname></persName>
		</author>
		<author>
			<persName><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL</title>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Satisfiability modulo recursive programs</title>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Suter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Sinan Köksal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kuncak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Query by output</title>
		<author>
			<persName><forename type="first">Chee-Yong</forename><surname>Quoc Trung Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><surname>Parthasarathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<editor>
			<persName><forename type="first">Stanley</forename><forename type="middle">B</forename><surname>Ugur C ¸etintemel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donald</forename><surname>Zdonik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nesime</forename><surname>Kossmann</surname></persName>
		</editor>
		<editor>
			<persName><surname>Tatbul</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="535" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Hadoop -The Definitive Guide: Storage and Analysis at Internet Scale</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>White</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">MSL: A synthesis enabled language for distributed implementations</title>
		<author>
			<persName><forename type="first">Zhilei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoaib</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Distributed aggregation for data-parallel computing: interfaces and implementations</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Kumar Gunda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SOSP</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dryadlinq: A system for general-purpose distributed dataparallel computing using a high-level language</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Fetterly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Úlfar</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Kumar Gunda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Currey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing</title>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mosharaf</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tathagata</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murphy</forename><surname>Mccauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Covac: Compiler validation by program analysis of the cross-product</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Zaks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Pnueli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FM</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Automatically synthesizing SQL queries from input-output examples</title>
		<author>
			<persName><forename type="first">Sai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASE</title>
		<editor>
			<persName><forename type="first">Ewen</forename><surname>Denney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tevfik</forename><surname>Bultan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andreas</forename><surname>Zeller</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="224" to="234" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
