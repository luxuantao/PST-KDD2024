<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at super.gluebenchmark.com.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently there has been notable progress across many natural language processing (NLP) tasks, led by methods such as ELMo <ref type="bibr" target="#b48">(Peters et al., 2018)</ref>, OpenAI GPT <ref type="bibr" target="#b52">(Radford et al., 2018)</ref>, and BERT <ref type="bibr" target="#b16">(Devlin et al., 2019)</ref>. The unifying theme of these methods is that they couple self-supervised learning from massive unlabelled text corpora with effective adapting of the resulting model to target tasks. The tasks that have proven amenable to this general approach include question answering, textual entailment, and parsing, among many others <ref type="bibr" target="#b16">(Devlin et al., 2019;</ref><ref type="bibr">Kitaev et al., 2019, i.a.)</ref>.</p><p>In this context, the GLUE benchmark <ref type="bibr" target="#b62">(Wang et al., 2019a)</ref> has become a prominent evaluation framework for research towards general-purpose language understanding technologies. GLUE is a collection of nine language understanding tasks built on existing public datasets, together with private test data, an evaluation server, a single-number target metric, and an accompanying expertconstructed diagnostic set. GLUE was designed to provide a general-purpose evaluation of language understanding that covers a range of training data volumes, task genres, and task formulations. We believe it was these aspects that made GLUE particularly appropriate for exhibiting the transferlearning potential of approaches like OpenAI GPT and BERT.</p><p>The progress of the last twelve months has eroded headroom on the GLUE benchmark dramatically. While some tasks (Figure <ref type="figure">1</ref>) and some linguistic phenomena (Figure <ref type="figure">2</ref> in Appendix B) measured in GLUE remain difficult, the current state of the art GLUE Score as of early July 2019 (88.4 from <ref type="bibr" target="#b67">Yang et al., 2019)</ref> surpasses human performance (87.1 from <ref type="bibr" target="#b45">Nangia and Bowman, 2019)</ref>  Figure <ref type="figure">1</ref>: GLUE benchmark performance for submitted systems, rescaled to set human performance to 1.0, shown as a single number score, and broken down into the nine constituent task performances.</p><p>For tasks with multiple metrics, we use an average of the metrics. More information on the tasks included in GLUE can be found in <ref type="bibr" target="#b62">Wang et al. (2019a)</ref> and in <ref type="bibr">Warstadt et al. (2019, CoLA)</ref>, <ref type="bibr">Socher et al. (2013, SST-2)</ref>, <ref type="bibr">Dolan and Brockett (2005, MRPC)</ref>, <ref type="bibr">Cer et al. (2017, STS-B)</ref>, and <ref type="bibr">Williams et al. (2018, MNLI)</ref>, and <ref type="bibr" target="#b53">Rajpurkar et al. (2016,</ref> the original data source for QNLI).</p><p>remains substantial scope for improvement towards GLUE's high-level goals, the original version of the benchmark is no longer a suitable metric for quantifying such progress.</p><p>In response, we introduce SuperGLUE, a new benchmark designed to pose a more rigorous test of language understanding. SuperGLUE has the same high-level motivation as GLUE: to provide a simple, hard-to-game measure of progress toward general-purpose language understanding technologies for English. We anticipate that significant progress on SuperGLUE should require substantive innovations in a number of core areas of machine learning, including sample-efficient, transfer, multitask, and unsupervised or self-supervised learning.</p><p>SuperGLUE follows the basic design of GLUE: It consists of a public leaderboard built around eight language understanding tasks, drawing on existing data, accompanied by a single-number performance metric, and an analysis toolkit. However, it improves upon GLUE in several ways:</p><p>More challenging tasks: SuperGLUE retains the two hardest tasks in GLUE. The remaining tasks were identified from those submitted to an open call for task proposals and were selected based on difficulty for current NLP approaches.</p><p>More diverse task formats: The task formats in GLUE are limited to sentence-and sentence-pair classification. We expand the set of task formats in SuperGLUE to include coreference resolution and question answering (QA).</p><p>Comprehensive human baselines: We include human performance estimates for all benchmark tasks, which verify that substantial headroom exists between a strong BERT-based baseline and human performance.</p><p>Improved code support: SuperGLUE is distributed with a new, modular toolkit for work on pretraining, multi-task learning, and transfer learning in NLP, built around standard tools including PyTorch <ref type="bibr" target="#b46">(Paszke et al., 2017)</ref> and AllenNLP <ref type="bibr" target="#b20">(Gardner et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Refined usage rules:</head><p>The conditions for inclusion on the SuperGLUE leaderboard have been revamped to ensure fair competition, an informative leaderboard, and full credit assignment to data and task creators.</p><p>The SuperGLUE leaderboard, data, and software tools are available at super.gluebenchmark.com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Much work prior to GLUE demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks  <ref type="bibr" target="#b10">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b14">Dai and Le, 2015;</ref><ref type="bibr" target="#b28">Kiros et al., 2015;</ref><ref type="bibr" target="#b23">Hill et al., 2016;</ref><ref type="bibr" target="#b11">Conneau and Kiela, 2018;</ref><ref type="bibr" target="#b39">McCann et al., 2017;</ref><ref type="bibr" target="#b48">Peters et al., 2018)</ref>. GLUE was presented as a formal challenge affording straightforward comparison between such task-agnostic transfer learning techniques. Other similarly-motivated benchmarks include SentEval <ref type="bibr" target="#b11">(Conneau and Kiela, 2018)</ref>, which specifically evaluates fixed-size sentence embeddings, and DecaNLP <ref type="bibr" target="#b40">(McCann et al., 2018)</ref>, which recasts a set of target tasks into a general question-answering format and prohibits task-specific parameters. In contrast, GLUE provides a lightweight classification API and no restrictions on model architecture or parameter sharing, which seems to have been well-suited to recent work in this area.</p><p>Since its release, GLUE has been used as a testbed and showcase by the developers of several influential models, including GPT <ref type="bibr" target="#b52">(Radford et al., 2018)</ref> and BERT <ref type="bibr" target="#b16">(Devlin et al., 2019)</ref>. As shown in Figure <ref type="figure">1</ref>, progress on GLUE since its release has been striking. On GLUE, GPT and BERT achieved scores of 72.8 and 80.2 respectively, relative to 66.5 for an ELMo-based model <ref type="bibr" target="#b48">(Peters et al., 2018)</ref> and 63.7 for the strongest baseline with no multitask learning or pretraining above the word level. Recent models <ref type="bibr" target="#b37">(Liu et al., 2019d;</ref><ref type="bibr" target="#b67">Yang et al., 2019)</ref> have clearly surpassed estimates of non-expert human performance on GLUE <ref type="bibr" target="#b45">(Nangia and Bowman, 2019)</ref>. The success of these models on GLUE has been driven by ever-increasing model capacity, compute power, and data quantity, as well as innovations in model expressivity (from recurrent to bidirectional recurrent to multi-headed transformer encoders) and degree of contextualization (from learning representation of words in isolation to using uni-directional contexts and ultimately to leveraging bidirectional contexts).</p><p>In parallel to work scaling up pretrained models, several studies have focused on complementary methods for augmenting performance of pretrained models. <ref type="bibr" target="#b49">Phang et al. (2018)</ref> show that BERT can be improved using two-stage pretraining, i.e., fine-tuning the pretrained model on an intermediate data-rich supervised task before fine-tuning it again on a data-poor target task. <ref type="bibr">Liu et al. (2019d,c)</ref> and <ref type="bibr" target="#b0">Bach et al. (2018)</ref> get further improvements respectively via multi-task finetuning and using massive amounts of weak supervision. <ref type="bibr" target="#b9">Clark et al. (2019b)</ref> demonstrate that knowledge distillation <ref type="bibr" target="#b24">(Hinton et al., 2015;</ref><ref type="bibr" target="#b19">Furlanello et al., 2018)</ref> can lead to student networks that outperform their teachers. Overall, the quantity and quality of research contributions aimed at the challenges posed by GLUE underline the utility of this style of benchmark for machine learning researchers looking to evaluate new application-agnostic methods on language understanding.</p><p>Limits to current approaches are also apparent via the GLUE suite. Performance on the GLUE diagnostic entailment dataset, at 0.42 R 3 , falls far below the average human performance of 0.80 R 3 reported in the original GLUE publication, with models performing near, or even below, chance on some linguistic phenomena (Figure <ref type="figure">2</ref>, Appendix B). While some initially difficult categories saw gains from advances on GLUE (e.g., double negation), others remain hard (restrictivity) or even adversarial (disjunction, downward monotonicity). This suggests that even as unsupervised pretraining produces ever-better statistical summaries of text, it remains difficult to extract many details crucial to semantics without the right kind of supervision. Much recent work has made similar observations about the limitations of existing pretrained models <ref type="bibr" target="#b25">(Jia and Liang, 2017;</ref><ref type="bibr" target="#b44">Naik et al., 2018;</ref><ref type="bibr">McCoy and Linzen, 2019;</ref><ref type="bibr">McCoy et al., 2019;</ref><ref type="bibr">Liu et al., 2019a,b)</ref>. The goal of SuperGLUE is to provide a simple, robust evaluation metric of any method capable of being applied to a broad range of language understanding tasks. To that end, in designing SuperGLUE, we identify the following desiderata of tasks in the benchmark:</p><p>Task substance: Tasks should test a system's ability to understand and reason about texts in English.</p><p>Task difficulty: Tasks should be beyond the scope of current state-of-the-art systems, but solvable by most college-educated English speakers. We exclude tasks that require domain-specific knowledge, e.g. medical notes or scientific papers.</p><p>Evaluability: Tasks must have an automatic performance metric that corresponds well to human judgments of output quality. Some text generation tasks fail to meet this criteria due to issues with automatic metrics like ROUGE and BLEU <ref type="bibr" target="#b4">(Callison-Burch et al., 2006;</ref><ref type="bibr">Liu et al., 2016, i.a.)</ref>.</p><p>Public data: We require that tasks have existing public training data in order to minimize the risks involved in newly-created datasets. We also prefer tasks for which we have access to (or could create) a test set with private labels.</p><p>Task format: We prefer tasks that had relatively simple input and output formats, to avoid incentivizing the users of the benchmark to create complex task-specific model architectures. Still, while GLUE is restricted to tasks involving single sentence or sentence pair inputs, for SuperGLUE we expand the scope to consider tasks with longer inputs. This yields a set of tasks that requires understanding individual tokens in context, complete sentences, inter-sentence relations, and entire paragraphs.</p><p>License: Task data must be available under licences that allow use and redistribution for research purposes.</p><p>To identify possible tasks for SuperGLUE, we disseminated a public call for task proposals to the NLP community, and received approximately 30 proposals. We filtered these proposals according to our criteria. Many proposals were not suitable due to licensing issues, complex formats, and insufficient headroom; we provide examples of such tasks in Appendix D. For each of the remaining tasks, we ran a BERT-based baseline and a human baseline, and filtered out tasks which were either too challenging for humans without extensive training or too easy for our machine baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Selected Tasks</head><p>Following this process, we arrived at eight tasks to use in SuperGLUE. See Tables <ref type="table" target="#tab_2">1 and 2</ref>  We use a subset of the data that had inter-annotator agreement above 80%. The data is imbalanced (relatively fewer neutral examples), so we evaluate using accuracy and F1, where for multi-class F1 we compute the unweighted average of the F1 per class.</p><p>COPA (Choice of Plausible Alternatives, <ref type="bibr" target="#b54">Roemmele et al., 2011</ref>) is a causal reasoning task in which a system is given a premise sentence and must determine either the cause or effect of the premise from two possible choices. All examples are handcrafted and focus on topics from blogs and a photography-related encyclopedia. Following the original work, we evaluate using accuracy.</p><p>MultiRC (Multi-Sentence Reading Comprehension, <ref type="bibr" target="#b26">Khashabi et al., 2018</ref>) is a QA task where each example consists of a context paragraph, a question about that paragraph, and a list of possible answers. The system must predict which answers are true and which are false. While many QA tasks exist, we use MultiRC because of a number of desirable properties: (i) each question can have multiple possible correct answers, so each question-answer pair must be evaluated independent of other pairs, (ii) the questions are designed such that answering each question requires drawing facts from multiple context sentences, and (iii) the question-answer pair format more closely matches the API of other tasks in SuperGLUE than the more popular span-extractive QA format does. The paragraphs are drawn from seven domains including news, fiction, and historical text. The evaluation metrics are F1 over all answer-options (F1 a ) and exact match of each question's set of answers (EM).</p><p>ReCoRD (Reading Comprehension with Commonsense Reasoning Dataset, <ref type="bibr" target="#b70">Zhang et al., 2018</ref>) is a multiple-choice QA task. Each example consists of a news article and a Cloze-style question about the article in which one entity is masked out. The system must predict the masked out entity from a list of possible entities in the provided passage, where the same entity may be expressed with multiple different surface forms, which are all considered correct. Articles are from CNN and Daily Mail. We evaluate with max (over all mentions) token-level F1 and exact match (EM).</p><p>RTE (Recognizing Textual Entailment) datasets come from a series of annual competitions on textual entailment. RTE is included in GLUE, and we use the same data and format as GLUE: We merge data from RTE1 <ref type="bibr" target="#b13">(Dagan et al., 2006</ref><ref type="bibr">), RTE2 (Bar Haim et al., 2006)</ref>, RTE3 <ref type="bibr" target="#b21">(Giampiccolo et al., 2007)</ref>, and RTE5 <ref type="bibr" target="#b2">(Bentivogli et al., 2009)</ref>. All datasets are combined and converted to two-class classification: entailment and not_entailment. Of all the GLUE tasks, RTE is among those that benefits from transfer learning the most, with performance jumping from near random-chance (∼56%) at the time of GLUE's launch to 86.3% accuracy <ref type="bibr" target="#b37">(Liu et al., 2019d;</ref><ref type="bibr" target="#b67">Yang et al., 2019)</ref> at the time of writing.</p><p>Given the nearly eight point gap with respect to human performance, however, the task is not yet solved by machines, and we expect the remaining gap to be difficult to close.</p><p>WiC (Word-in-Context, Pilehvar and Camacho-Collados, 2019) is a word sense disambiguation task cast as binary classification of sentence pairs. Given two text snippets and a polysemous word that appears in both sentences, the task is to determine whether the word is used with the same sense in both sentences. Sentences are drawn from WordNet <ref type="bibr" target="#b43">(Miller, 1995)</ref>, VerbNet <ref type="bibr" target="#b58">(Schuler, 2005)</ref>, and Wiktionary. We follow the original work and evaluate using accuracy.</p><p>WSC (Winograd Schema Challenge, <ref type="bibr" target="#b32">Levesque et al., 2012</ref>) is a coreference resolution task in which examples consist of a sentence with a pronoun and a list of noun phrases from the sentence.</p><p>The system must determine the correct referrent of the pronoun from among the provided choices.</p><p>Winograd schemas are designed to require everyday knowledge and commonsense reasoning to solve.</p><p>GLUE includes a version of WSC recast as NLI, known as WNLI. Until very recently, no substantial progress had been made on WNLI, with many submissions opting to submit majority class predictions. <ref type="foot" target="#foot_0">2</ref> In the past few months, several works <ref type="bibr" target="#b30">(Kocijan et al., 2019;</ref><ref type="bibr" target="#b37">Liu et al., 2019d)</ref> have made rapid progress via a hueristic data augmentation scheme, raising machine performance to 90.4% accuracy.</p><p>Given estimated human performance of ∼96%, there is still a gap between machine and human performance, which we expect will be relatively difficult to close. We therefore include a version of WSC cast as binary classification, where each example consists of a sentence with a marked pronoun and noun, and the task is to determine if the pronoun refers to that noun. The training and validation examples are drawn from the original WSC data <ref type="bibr" target="#b32">(Levesque et al., 2012)</ref>, as well as those distributed by the affiliated organization Commonsense Reasoning. <ref type="foot" target="#foot_1">3</ref> The test examples are derived from fiction books and have been shared with us by the authors of the original dataset. We evaluate using accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Scoring</head><p>As with GLUE, we seek to give a sense of aggregate system performance over all tasks by averaging scores of all tasks. Lacking a fair criterion with which to weight the contributions of each task to the overall score, we opt for the simple approach of weighing each task equally, and for tasks with multiple metrics, first averaging those metrics to get a task score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tools for Model Analysis</head><p>Analyzing Linguistic and World Knowledge in Models GLUE includes an expert-constructed, diagnostic dataset that automatically tests models for a broad range of linguistic, commonsense, and world knowledge. Each example in this broad-coverage diagnostic is a sentence pair labeled with a three-way entailment relation (entailment, neutral, or contradiction) and tagged with labels that indicate the phenomena that characterize the relationship between the two sentences. Submissions to the GLUE leaderboard are required to include predictions from the submission's MultiNLI classifier on the diagnostic dataset, and analyses of the results were shown alongside the main leaderboard. Since this diagnostic task has proved difficult for top models, we retain it in SuperGLUE. However, since MultiNLI is not part of SuperGLUE, we collapse contradiction and neutral into a single not_entailment label, and request that submissions include predictions on the resulting set from the model used for the RTE task. We estimate human performance following the same procedure we use for the benchmark tasks (Section C). We estimate an accuracy of 88% and a Matthew's correlation coefficient (MCC, the two-class variant of the R 3 metric used in GLUE) of 0.77.</p><p>Analyzing Gender Bias in Models Recent work has identified the presence and amplification of many social biases in data-driven machine learning models <ref type="bibr" target="#b38">(Lu et al., 2018;</ref><ref type="bibr">Zhao et al., 2018, i.a.)</ref>. To promote the detection of such biases, we include Winogender <ref type="bibr" target="#b55">(Rudinger et al., 2018)</ref> as an additional diagnostic dataset. Winogender is designed to measure gender bias in coreference resolution systems. We use the Diverse Natural Language Inference Collection <ref type="bibr" target="#b51">(Poliak et al., 2018)</ref> version that casts Winogender as a textual entailment task.Each example consists of a premise sentence with a male or female pronoun and a hypothesis giving a possible antecedent of the pronoun. Examples occur in minimal pairs, where the only difference between an example and its pair is the gender of the pronoun in the premise. Performance on Winogender is measured with accuracy and the gender parity score: the percentage of minimal pairs for which the predictions are the same. A system can trivially obtain a perfect gender parity score by guessing the same class for all examples, so a high gender parity score is meaningless unless accompanied by high accuracy. We collect non-expert annotations to estimate human performance, and observe an accuracy of 99.7% and a gender parity score of 0.99.</p><p>Like any diagnostic, Winogender has limitations. It offers only positive predictive value: A poor bias score is clear evidence that a model exhibits gender bias, but a good score does not mean that the model is unbiased. More specifically, in the DNC version of the task, a low gender parity score means that a model's prediction of textual entailment can be changed with a change in pronouns, all else equal. It is plausible that there are forms of bias that are relevant to target tasks of interest, but that do not surface in this setting <ref type="bibr" target="#b22">(Gonen and Goldberg, 2019)</ref>. Also, Winogender does not cover all forms of social bias, or even all forms of gender. For instance, the version of the data used here offers no coverage of gender-neutral they or non-binary pronouns. Despite these limitations, we believe that Winogender's inclusion is worthwhile in providing a coarse sense of how social biases evolve with model performance and for keeping attention on the social ramifications of NLP models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Using SuperGLUE</head><p>Software Tools To facilitate using SuperGLUE, we release jiant <ref type="bibr" target="#b63">(Wang et al., 2019b</ref>),<ref type="foot" target="#foot_2">4</ref> a modular software toolkit, built with PyTorch <ref type="bibr" target="#b46">(Paszke et al., 2017)</ref>, components from AllenNLP <ref type="bibr" target="#b20">(Gardner et al., 2017)</ref>, and the transformers package.<ref type="foot" target="#foot_3">5</ref> jiant implements our baselines and supports the evaluation of custom models and training methods on the benchmark tasks. The toolkit includes support for existing popular pretrained models such as OpenAI GPT and BERT, as well as support for multistage and multitask learning of the kind seen in the strongest models on GLUE.</p><p>Eligibility Any system or method that can produce predictions for the SuperGLUE tasks is eligible for submission to the leaderboard, subject to the data-use and submission frequency policies stated immediately below. There are no restrictions on the type of methods that may be used, and there is no requirement that any form of parameter sharing or shared initialization be used across the tasks in the benchmark. To limit overfitting to the private test data, users are limited to a maximum of two submissions per day and six submissions per month.</p><p>Data Data for the tasks are available for download through the SuperGLUE site and through a download script included with the software toolkit. Each task comes with a standardized training set, development set, and unlabeled test set. Submitted systems may use any public or private data when developing their systems, with a few exceptions: Systems may only use the SuperGLUE-distributed versions of the task datasets, as these use different train/validation/test splits from other public versions in some cases. Systems also may not use the unlabeled test data for the tasks in system development in any way, may not use the structured source data that was used to collect the WiC labels (sense-annotated example sentences from WordNet, VerbNet, and Wiktionary) in any way, and may not build systems that share information across separate test examples in any way.</p><p>To ensure reasonable credit assignment, because we build very directly on prior work, we ask the authors of submitted systems to directly name and cite the specific datasets that they use, including the benchmark datasets. We will enforce this as a requirement for papers to be listed on the leaderboard. ) with an initial learning rate of 10 −5 and fine-tune for a maximum of 10 epochs.</p><p>For classification tasks with sentence-pair inputs (BoolQ, CB, RTE, WiC), we concatenate the sentences with a [SEP] token, feed the fused input to BERT, and use a logistic regression classifier that sees the representation corresponding to <ref type="bibr">[CLS]</ref>. For WiC, we also concatenate the representation of the marked word. For COPA, MultiRC, and ReCoRD, for each answer choice, we similarly concatenate the context with that answer choice and feed the resulting sequence into BERT to produce an answer representation. For COPA, we project these representations into a scalar, and take as the answer the choice with the highest associated scalar. For MultiRC, because each question can have more than one correct answer, we feed each answer representation into a logistic regression classifier.</p><p>For ReCoRD, we also evaluate the probability of each candidate independent of other candidates, and take the most likely candidate as the model's prediction. For WSC, which is a span-based task, we use a model inspired by <ref type="bibr" target="#b60">Tenney et al. (2019)</ref>. Given the BERT representation for each word in the original sentence, we get span representations of the pronoun and noun phrase via a self-attention span-pooling operator <ref type="bibr" target="#b31">(Lee et al., 2017)</ref>, before feeding it into a logistic regression classifier.</p><p>BERT++ We also report results using BERT with additional training on related datasets before fine-tuning on the benchmark tasks, following the STILTs style of transfer learning <ref type="bibr" target="#b49">(Phang et al., 2018)</ref>. Given the productive use of MultiNLI in pretraining and intermediate fine-tuning of pretrained language models <ref type="bibr" target="#b12">(Conneau et al., 2017;</ref><ref type="bibr">Phang et al., 2018, i.a.)</ref>, for CB, RTE, and BoolQ, we use MultiNLI as a transfer task by first using the above procedure on MultiNLI. Similarly, given the similarity of COPA to SWAG <ref type="bibr" target="#b69">(Zellers et al., 2018)</ref>, we first fine-tune BERT on SWAG. These results are reported as BERT++. For all other tasks, we reuse the results of BERT fine-tuned on just that task.</p><p>Other Baselines We include a baseline where for each task we simply predict the majority class,<ref type="foot" target="#foot_4">6</ref> as well as a bag-of-words baseline where each input is represented as an average of its tokens' GloVe word vectors (the 300D/840B release from <ref type="bibr" target="#b47">Pennington et al., 2014)</ref>. Finally, we list the best known result on each task as of May 2019, except on tasks which we recast (WSC), resplit (CB), or achieve the best known result (WiC). The outside results for COPA, MultiRC, and RTE are from <ref type="bibr" target="#b56">Sap et al. (2019</ref><ref type="bibr" target="#b61">), Trivedi et al. (2019</ref><ref type="bibr" target="#b37">), and Liu et al. (2019d)</ref> respectively.</p><p>Human Performance Pilehvar and Camacho-Collados (2019), <ref type="bibr" target="#b26">Khashabi et al. (2018)</ref>, <ref type="bibr">Nangia and</ref><ref type="bibr">Bowman (2019), and</ref><ref type="bibr" target="#b70">Zhang et al. (2018)</ref> respectively provide estimates for human performance on WiC, MultiRC, RTE, and ReCoRD. For the remaining tasks, including the diagnostic set, we estimate human performance by hiring crowdworker annotators through Amazon's Mechanical Turk platform to reannotate a sample of each test set. We follow a two step procedure where a crowd worker completes a short training phase before proceeding to the annotation phase, modeled after the method used by <ref type="bibr" target="#b45">Nangia and Bowman (2019)</ref> for GLUE. See Appendix C for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Table <ref type="table" target="#tab_3">3</ref> shows results for all baselines. The most frequent class and CBOW baselines do not perform well overall, achieving near chance performance for several of the tasks. Using BERT increases the average SuperGLUE score by 25 points, attaining significant gains on all of the benchmark tasks, particularly MultiRC, ReCoRD, and RTE. On WSC, BERT actually performs worse than the simple baselines, likely due to the small size of the dataset and the lack of data augmentation. Using MultiNLI as an additional source of supervision for BoolQ, CB, and RTE leads to a 2-5 point improvement on all tasks. Using SWAG as a transfer task for COPA sees an 8 point improvement.</p><p>Our best baselines still lag substantially behind human performance. On average, there is a nearly 20 point gap between BERT++ and human performance. The largest gap is on WSC, with a 35 point difference between the best model and human performance. The smallest margins are on BoolQ, CB, RTE, and WiC, with gaps of around 10 points on each of these. We believe these gaps will be challenging to close: On WSC and COPA, human performance is perfect. On three other tasks, it is in the mid-to-high 90s. On the diagnostics, all models continue to lag significantly behind humans. Though all models obtain near perfect gender parity scores on Winogender, this is due to the fact that they are obtaining accuracy near that of random guessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We present SuperGLUE, a new benchmark for evaluating general-purpose language understanding systems. SuperGLUE updates the GLUE benchmark by identifying a new set of challenging NLU tasks, as measured by the difference between human and machine baselines. The set of eight tasks in our benchmark emphasizes diverse task formats and low-data training data tasks, with nearly half the tasks having fewer than 1k examples and all but one of the tasks having fewer than 10k examples.</p><p>We evaluate BERT-based baselines and find that they still lag behind humans by nearly 20 points. Given the difficulty of SuperGLUE for BERT, we expect that further progress in multi-task, transfer, and unsupervised/self-supervised learning techniques will be necessary to approach human-level performance on the benchmark. Overall, we argue that SuperGLUE offers a rich and challenging testbed for work developing new general-purpose machine learning methods for language understanding.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>for details and specific examples of each task.BoolQ (Boolean Questions,<ref type="bibr" target="#b8">Clark et al., 2019a</ref>) is a QA task where each example consists of a short passage and a yes/no question about the passage. The questions are provided anonymously and unsolicited by users of the Google search engine, and afterwards paired with a paragraph from a Wikipedia article containing the answer. Following the original work, we evaluate with accuracy.CB (CommitmentBank, de Marneffe et al., 2019) is a corpus of short texts in which at least one sentence contains an embedded clause. Each of these embedded clauses is annotated with the degree to which it appears the person who wrote the text is committed to the truth of the clause. The resulting task framed as three-class textual entailment on examples that are drawn from the Wall Street Journal, fiction from the British National Corpus, and Switchboard. Each example consists of a premise containing an embedded clause and the corresponding hypothesis is the extraction of that clause.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>by 1.3 points, and in fact exceeds this human performance estimate on four tasks. Consequently, while there</figDesc><table><row><cell>1.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.7 0.8 0.5 0.6</cell><cell>BiLSTM+ELMo+Attn</cell><cell>OpenAI GPT</cell><cell>BERT + Single-task Adapters</cell><cell>BERT (Large)</cell><cell>BERT on STILTs</cell><cell>BERT + BAM GLUE Score Human Performance CoLA SST-2</cell><cell>SemBERT</cell><cell>Snorkel MeTaL MRPC STS-B QQP MNLI</cell><cell>ALICE (Large) QNLI RTE WNLI</cell><cell>MT-DNN (ensemble)</cell><cell>XLNet-Large (ensemble)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The tasks included in SuperGLUE. WSD stands for word sense disambiguation, NLI is natural language inference, coref. is coreference resolution, and QA is question answering. For MultiRC, we list the number of total answers for 456/83/166 train/dev/test questions.</figDesc><table><row><cell>Corpus</cell><cell cols="3">|Train| |Dev| |Test| Task</cell><cell cols="2">Metrics Text Sources</cell></row><row><cell>BoolQ</cell><cell>9427</cell><cell>3270</cell><cell>3245 QA</cell><cell>acc.</cell><cell>Google queries, Wikipedia</cell></row><row><cell>CB</cell><cell>250</cell><cell>57</cell><cell>250 NLI</cell><cell>acc./F1</cell><cell>various</cell></row><row><cell>COPA</cell><cell>400</cell><cell>100</cell><cell>500 QA</cell><cell>acc.</cell><cell>blogs, photography encyclopedia</cell></row><row><cell>MultiRC</cell><cell>5100</cell><cell>953</cell><cell>1800 QA</cell><cell cols="2">F1a/EM various</cell></row><row><cell>ReCoRD</cell><cell>101k</cell><cell>10k</cell><cell>10k QA</cell><cell>F1/EM</cell><cell>news (CNN, Daily Mail)</cell></row><row><cell>RTE</cell><cell>2500</cell><cell>278</cell><cell>300 NLI</cell><cell>acc.</cell><cell>news, Wikipedia</cell></row><row><cell>WiC</cell><cell>6000</cell><cell>638</cell><cell cols="2">1400 WSD acc.</cell><cell>WordNet, VerbNet, Wiktionary</cell></row><row><cell>WSC</cell><cell>554</cell><cell>104</cell><cell cols="2">146 coref. acc.</cell><cell>fiction books</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Development set examples from the tasks in SuperGLUE. Bold text represents part of the example format for each task. Text in italics is part of the model input. Underlined text is specially marked in the input. Text in a monospaced font represents the expected model output. Barq's -Barq's is an American soft drink. Its brand of root beer is notable for having caffeine. Barq's, created by Edward Barq and bottled since the turn of the 20th century, is owned by the Barq family but bottled by the Coca-Cola Company. It was known as Barq's Famous Olde Tyme Root Beer until 2012. My body cast a shadow over the grass. Question: What's the CAUSE for this? Alternative 1: The sun was rising. Alternative 2: The grass was cut. Susan wanted to have a birthday party. She called all of her friends. She has five friends.Her mom said that Susan can invite them all to the party. Her first friend could not go to the party because she was sick. Her second friend was going out of town. Her third friend was not so sure if her parents would let her. The fourth friend said maybe. The fifth friend could go to the party for sure. Susan was a little sad. On the day of the party, all five friends showed up. Each friend had a present for Susan.</figDesc><table><row><cell>BoolQ</cell><cell>Passage: Correct Alternative: 1</cell></row><row><cell>MultiRC</cell><cell>Paragraph:</cell></row></table><note>Question: is barq's root beer a pepsi product Answer: No CB Text: B: And yet, uh, I we-, I hope to see employer based, you know, helping out. You know, child, uh, care centers at the place of employment and things like that, that will help out. A: Uh-huh. B: What do you think, do you think we are, setting a trend? Hypothesis: they are setting a trend Entailment: Unknown COPA Premise: Susan was happy and sent each friend a thank you card the next week Question: Did Susan's sick friend recover? Candidate answers: Yes, she recovered (T), No (F), Yes (T), No, she didn't recover (F), Yes, she was at Susan's party (T) ReCoRD Paragraph: (CNN) Puerto Rico on Sunday overwhelmingly voted for statehood. But Congress, the only body that can approve new states, will ultimately decide whether the status of the US commonwealth changes. Ninety-seven percent of the votes in the nonbinding referendum favored statehood, an increase over the results of a 2012 referendum, official results from the State Electorcal Commission show. It was the fifth such vote on statehood. "Today, we the people of Puerto Rico are sending a strong and clear message to the US Congress ... and to the world ... claiming our equal rights as American citizens, Puerto Rico Gov. Ricardo Rossello said in a news release. @highlight Puerto Rico voted Sunday in favor of US statehood Query For one, they can truthfully say, "Don't blame me, I didn't vote for them, " when discussing the &lt;placeholder&gt; presidency Correct Entities: US RTE Text: Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation. Hypothesis: Christopher Reeve had an accident. Entailment: False WiC Context 1: Room and board. Context 2: He nailed boards across the windows. Sense match: False WSC Text: Mark told Pete many lies about himself, which Pete included in his book. He should have been more truthful. Coreference: False</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Baseline performance on the SuperGLUE test sets and diagnostics. For CB we report accuracy and macro-average F1. For MultiRC we report F1 on all answer-options and exact match of each question's set of correct answers. AX b is the broad-coverage diagnostic task, scored using Matthews' correlation (MCC). AX g is the Winogender diagnostic, scored using accuracy and the gender parity score (GPS). All values are scaled by 100. The Avg column is the overall benchmark score on non-AX * tasks. The bolded numbers reflect the best machine performance on task. *MultiRC has multiple test sets released on a staggered schedule, and these results evaluate on an installation of the test set that is a subset of ours. Our main baselines are built around BERT, variants of which are among the most successful approach on GLUE at the time of writing. Specifically, we use the bert-large-cased variant. Following the practice recommended in<ref type="bibr" target="#b16">Devlin et al. (2019)</ref>, for each task, we use the simplest possible architecture on top of BERT. We fine-tune a copy of the pretrained BERT model separately for each task, and leave the development of multi-task learning models to future work. For training, we use the procedure specified in<ref type="bibr" target="#b16">Devlin et al. (2019)</ref>: We use Adam<ref type="bibr" target="#b27">(Kingma and Ba, 2014</ref></figDesc><table><row><cell>Model</cell><cell cols="2">Avg BoolQ</cell><cell>CB</cell><cell cols="6">COPA MultiRC ReCoRD RTE WiC WSC AX b</cell><cell>AXg</cell></row><row><cell>Metrics</cell><cell></cell><cell cols="3">Acc. F1/Acc. Acc.</cell><cell>F1a/EM</cell><cell cols="4">F1/EM Acc. Acc. Acc. MCC GPS Acc.</cell></row><row><cell cols="10">Most Frequent 47.1 62.3 21.7/48.4 50.0 61.1 / 0.3 33.4/32.5 50.3 50.0 65.1 0.0 100.0/ 50.0</cell></row><row><cell>CBoW</cell><cell cols="4">44.3 62.1 49.0/71.2 51.6</cell><cell cols="5">0.0 / 0.4 14.0/13.6 49.7 53.0 65.1 -0.4 100.0/ 50.0</cell></row><row><cell>BERT</cell><cell cols="9">69.0 77.4 75.7/83.6 70.6 70.0 / 24.0 72.0/71.3 71.6 69.5 64.3 23.0 97.8 / 51.7</cell></row><row><cell>BERT++</cell><cell cols="9">71.5 79.0 84.7/90.4 73.8 70.0 / 24.1 72.0/71.3 79.0 69.5 64.3 38.0 99.4 / 51.4</cell></row><row><cell>Outside Best</cell><cell>-</cell><cell>80.4</cell><cell>-/ -</cell><cell cols="3">84.4 70.4*/24.5* 74.8/73.0 82.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-/ -</cell></row><row><cell cols="10">Human (est.) 89.8 89.0 95.8/98.9 100.0 81.8*/51.9* 91.7/91.3 93.6 80.0 100.0 77.0 99.3 / 99.7</cell></row><row><cell cols="2">5 Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5.1 Baselines</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BERT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">WNLI is especially difficult due to an adversarial train/dev split: Premise sentences that appear in the training set often appear in the development set with a different hypothesis and a flipped label. If a system memorizes the training set, which was easy due to the small size of the training set, it could perform far below chance on the development set. We remove this adversarial design in our version of WSC by ensuring that no sentences are shared between the training, validation, and test sets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1">http://commonsensereasoning.org/disambiguation.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">https://github.com/nyu-mll/jiant</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">https://github.com/huggingface/transformers</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">For ReCoRD, we predict the entity that has the highest F1 with the other entity options.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>We thank the original authors of the included datasets in SuperGLUE for their cooperation in the creation of the benchmark, as well as those who proposed tasks and datasets that we ultimately could not include. This work was made possible in part by a donation to NYU from Eric and Wendy Schmidt made by recommendation of the Schmidt Futures program. We gratefully acknowledge the support of the NVIDIA Corporation with the donation of a Titan V GPU used at NYU for this research, and funding from DeepMind for the hosting of the benchmark platform. AW is supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE 1342536. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Snorkel drybell: A case study in deploying weak supervision at industrial scale</title>
		<author>
			<persName><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yintao</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haidong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cassandra</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Souvik</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Braden</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houman</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Alborzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Kuchhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName><surname>Malkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The second PASCAL recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Roy</forename><surname>Bar Haim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<ptr target="http://u.cs.biu.ac.il/~nlp/RTE2/Proceedings/01.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment</title>
				<meeting>the Second PASCAL Challenges Workshop on Recognising Textual Entailment</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The fifth PASCAL recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoa</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<ptr target="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.232.1231" />
	</analytic>
	<monogr>
		<title level="m">Textual Analysis Conference (TAC)</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling empathy and distress in reaction to news stories</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Buechel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anneke</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Slaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Sedoc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Re-evaluation the role of bleu in machine translation research</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/E06-1032" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter</title>
				<meeting>the Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S17-2001</idno>
		<ptr target="https://www.aclweb.org/anthology/S17-2001" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">SemEval-2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">QuAC: Question answering in context</title>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ultra-fine entity typing</title>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P18-1009" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics (ACL)</title>
				<meeting>the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Boolq: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019a</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2924" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Born-again multi-task networks for natural language understanding</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Bam!</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/1907.04829.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association of Computational Linguistics (ACL)</title>
				<meeting>the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<ptr target="https://dl.acm.org/citation.cfm?id=1390177" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning (ICML)</title>
				<meeting>the 25th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SentEval: An evaluation toolkit for universal sentence representations</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/L18-1269" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Language Resources and Evaluation Conference. European Language Resource Association</title>
				<meeting>the 11th Language Resources and Evaluation Conference. European Language Resource Association</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1070</idno>
		<ptr target="https://www.aclweb.org/anthology/D17-1070" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The PASCAL recognising textual entailment challenge</title>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<idno type="DOI">10.1007/11736790_9</idno>
		<ptr target="https://link.springer.com/chapter/10.1007/11736790_9" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Textual Entailment</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The CommitmentBank: Investigating projection in naturally occurring discourse</title>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandy</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Tonhauser</surname></persName>
		</author>
		<ptr target="https://github.com/mcdm/CommitmentBank/" />
	</analytic>
	<monogr>
		<title level="m">To appear in Proceedings of Sinn und Bedeutung 23. Data can be</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1810.04805" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWP</title>
				<meeting>IWP</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifying well-formed natural language questions</title>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1091" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v80/furlanello18a.html" />
		<title level="m">International Conference on Machine Learning (ICML)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">AllenNLP: A deep semantic natural language processing platform</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W18-2501" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop for NLP Open Source Software</title>
				<meeting>Workshop for NLP Open Source Software</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The third PASCAL recognizing textual entailment challenge</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
				<meeting>the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them</title>
		<author>
			<persName><forename type="first">Hila</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1061" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="609" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1162</idno>
		<ptr target="https://www.aclweb.org/anthology/N16-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno>1503.02531</idno>
		<ptr target="https://arxiv.org/abs/1503.02531" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1215</idno>
		<ptr target="https://www.aclweb.org/anthology/D17-1215" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/papers/N/N18/N18-1023/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno>1412.6980</idno>
		<ptr target="https://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Ruslan R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multilingual constituency parsing with self-attention and pre-training</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1340</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1340" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="3499" to="3505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A surprisingly robust trick for the Winograd schema challenge</title>
		<author>
			<persName><forename type="first">Ana-Maria</forename><surname>Vid Kocijan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oana-Maria</forename><surname>Cretu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yordan</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Yordanov</surname></persName>
		</author>
		<author>
			<persName><surname>Lukasiewicz</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1478</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1478" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="4837" to="4842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1018</idno>
		<ptr target="https://www.aclweb.org/anthology/D17-1018" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09">September 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Winograd schema challenge</title>
		<author>
			<persName><forename type="first">Hector</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leora</forename><surname>Morgenstern</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3031843.3031909" />
	</analytic>
	<monogr>
		<title level="m">Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1230</idno>
		<ptr target="https://www.aclweb.org/anthology/D16-1230" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Linguistic knowledge and transferability of contextual representations</title>
		<author>
			<persName><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1903.08855" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Inoculation by fine-tuning: A method for analyzing challenge datasets</title>
		<author>
			<persName><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1904.02668" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Improving multi-task deep neural networks via knowledge distillation for natural language understanding</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno>1904.09482</idno>
		<ptr target="http://arxiv.org/abs/1904.09482" />
		<imprint>
			<date type="published" when="2019">2019c</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno>1901.11504</idno>
		<title level="m">Multi-task deep neural networks for natural language understanding</title>
				<imprint>
			<date type="published" when="2019">2019d</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Kaiji</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Mardziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangjing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preetam</forename><surname>Amancharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anupam</forename><surname>Datta</surname></persName>
		</author>
		<idno>1807.11714</idno>
		<ptr target="http://arxiv.org/abs/1807.11714" />
		<title level="m">Gender bias in neural natural language processing</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The natural language decathlon: Multitask learning as question answering</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>1806.08730</idno>
		<ptr target="https://arxiv.org/abs/1806.08730" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Thomas</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1902.01007" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics (ACL)</title>
				<meeting>the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Non-entailed subsequences as a challenge for natural language inference</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">T</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<ptr target="https://scholarworks.umass.edu/scil/vol2/iss1/46/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Society for Computational in Linguistics (SCiL) 2019</title>
				<meeting>the Society for Computational in Linguistics (SCiL) 2019</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">WordNet: a lexical database for english</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/H94-1111" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Stress test evaluation for natural language inference</title>
		<author>
			<persName><forename type="first">Aakanksha</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">M</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolyn</forename><forename type="middle">Penstein</forename><surname>Rosé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Linguistics (COLING)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Muppet: A conservative estimate of human performance on the GLUE benchmark</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://woollysocks.github.io/assets/GLUE_Human_Baseline.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association of Computational Linguistics (ACL)</title>
				<meeting>the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Human vs</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<ptr target="https://openreview.net/pdf?id=BJJsrmfCZ" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
		<ptr target="https://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-1202" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Févry</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<idno>1811.01088</idno>
		<ptr target="https://arxiv.org/abs/1811.01088" />
		<title level="m">Sentence encoders on STILTs: Supplementary training on intermediate labeled-data tasks</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">WiC: The word-in-context dataset for evaluating context-sensitive meaning representations</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pilehvar</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1808.09121" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Collecting diverse natural language inference problems for sentence representation evaluation</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Edward</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Steven White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1007" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://blog.openai.com/language-unsupervised/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Unpublished ms</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
		<ptr target="http://aclweb.org/anthology/D16-1264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmin</forename><surname>Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">S</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 AAAI Spring Symposium Series</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution</title>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2002</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-2002" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">SocialIQa: Commonsense reasoning about social interactions</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Lebras</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1904.09728" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A corpus and model integrating multiword expressions and supersenses</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N15-1177" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Verbnet: A Broad-coverage, Comprehensive Verb Lexicon</title>
		<author>
			<persName><forename type="first">Karin Kipper</forename><surname>Schuler</surname></persName>
		</author>
		<ptr target="http://verbs.colorado.edu/~kipper/Papers/dissertation.pdf" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D13-1170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">What do you learn from context? probing for sentence structure in contextualized word representations</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berlin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJzSgnRcKX" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Repurposing entailment for multi-hop question answering tasks</title>
		<author>
			<persName><forename type="first">Harsh</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heeyoung</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1302</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1302" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2948" to="2958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJ4km2R5t7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">F</forename><surname>Tenney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghu</forename><surname>Pappagari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Shuning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Thomas</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roma</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Najoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mon</forename><surname>Phu</surname></persName>
		</author>
		<author>
			<persName><surname>Htut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berlin</forename><surname>Thibault F'evry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anhad</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Mohananey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shikha</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Bordia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName><surname>Benton</surname></persName>
		</author>
		<ptr target="http://jiant.info/" />
	</analytic>
	<monogr>
		<title level="m">A software toolkit for research on general-purpose text understanding models</title>
				<imprint>
			<date type="published" when="2019">2019b</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><surname>Samuel R Bowman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1805.12471" />
		<title level="m">Neural network acceptability judgments. Transactions of the Association of Computational Linguists</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Mind the GAP: A balanced corpus of gendered ambiguous pronouns</title>
		<author>
			<persName><forename type="first">Kellie</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vera</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/Q18-1042" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N18-1101" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">XLNet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Have you lost the thread? discovering ongoing conversations in scattered dialog blocks</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Massimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zanzotto</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Ferrone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">SWAG: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1009" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno>arXiv preprint 1810.12885</idno>
		<title level="m">ReCoRD: Bridging the gap between human and machine commonsense reading comprehension</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">PAWS: Paraphrase adversaries from word scrambling</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1904.01130" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
				<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution: Evaluation and debiasing methods</title>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2003</idno>
		<ptr target="https://www.aclweb.org/anthology/N18-2003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
				<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies. Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
