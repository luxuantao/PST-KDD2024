<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Approximate Models for General Cache Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Elisha</forename><forename type="middle">J</forename><surname>Rosensweig</surname></persName>
							<email>elisha@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jim</forename><surname>Kurose</surname></persName>
							<email>kurose@cs.umass.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Don</forename><surname>Towsley</surname></persName>
							<email>towsley@cs.umass.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<postCode>01003-9264</postCode>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Approximate Models for General Cache Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">86458A88890800C4E49F2A89DD6E3EC9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many systems employ caches to improve performance. While isolated caches have been studied in-depth, multicache systems are not well understood, especially in networks with arbitrary topologies. In order to gain insight into and manage these systems, a low-complexity algorithm for approximating their behavior is required. We propose a new algorithm, termed a-NET, that approximates the behavior of multi-cache networks by leveraging existing approximation algorithms for isolated LRU caches. We demonstrate the utility of a-NET using both per-cache and network-wide performance measures. We also perform factor analysis of the approximation error to identify system parameters that determine the precision of a-NET.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Many systems employ caching as a means to reduce the load on access links and shorten access time to selected content. While the basic caching unit is a single cache, equipped with management policies, some systems make use of several caches linked together, allowing each cache to also forward requests to its neighbors when needed. Common examples of such systems are hierarchical web and file system caches. Recently <ref type="bibr" target="#b0">[1]</ref> [2] <ref type="bibr" target="#b2">[3]</ref>, there have been proposals for multi-cache designs over networks of Internet-like scale and structure.</p><p>Determining the performance of a specific multi-cache system is extremely difficult. Even for the single, isolated cache using the popular LRU replacement policy, the complexity of exact models of cache contents and performance grow exponentially as a function of cache size and the number of files in the system <ref type="bibr" target="#b3">[4]</ref>, making them ineffective as exact modeling tools. For this reason, a more useful approach is to approximate the behavior of the caching system, allowing some measure of inaccuracy in return for simpler modeling techniques. This has been done for isolated caches and for some cache networks, namely cache hierarchies <ref type="bibr" target="#b4">[5]</ref>.</p><p>The main drawback of existing models for networked caches is their limited scope. They address hierarchical topologies (i.e., trees), in which the source of content is connected to a node at the top of the hierarchy (i.e., the root of the tree), and rely heavily on this structure when constructing the approximation. Furthermore, due to the complexity of these systems, the models are developed for small topologies (e.g., 2-level trees), and do not easily scale up for use in larger topologies. These limitations make existing solutions inapplicable when dealing with arbitrary topologies or largescale cache networks. Instead, what is needed is an approach that can be applied to any topology.</p><p>In this paper we present a-NET, an algorithm for approximating the rate of incoming and miss streams for each file at every node in a network using LRU caches. We refer to the output of a-NET as a multi-cache approximation, or MCA for short. The approach taken by a-NET is to decompose the problem and compute a single-cache approximation (SCA) for each individual cache in the network, where the request misses for each file at each cache are forwarded towards a content source. The incoming request stream at each cache is thus reevaluated as a combination of both exogenous requests as well as portions of the miss stream of each cache's neighbors. a-NET is an iterative process, updating the incoming request stream at each cache and recomputing its miss stream (which then becomes part of the input stream to neighboring caches) using an SCA generating algorithm, until the entire network converges to a fixed point. Unlike existing models, that can generate MCAs for specific topologies, a-NET can compute an MCA for any topology, regardless of structure or scale, as long as the routing tables remain constant.</p><p>The contributions of this paper are:</p><p>• We develop a-NET, a novel MCA generating algorithm for general-topology cache networks, that utilizes the SCA algorithm described in <ref type="bibr" target="#b3">[4]</ref> for approximating LRU caches.</p><p>• We demonstrate the behavior of a-NET for multiple topologies, and identify key parameters that affect its performance. Specifically, we show that dependencies within the reference stream are the main cause of inaccuracy for a-NET, and that an increase in network connectivity can greatly reduce this problem. • We construct a Markov model that expresses the interrequest distances in a cache miss stream for a range of arrival distributions. Since the miss stream of one cache becomes part of the incoming stream of its neighbors, we use this model to demonstrate the effects of non-IRM miss streams on the hit-ratio at neighboring caches. • We evaluate the accuracy of a-NET, in terms of both per-cache and system-wide metrics. Individual caches are evaluated using the miss probability of each cache, while the performance of the entire system is measured in terms of the average number of hops a request traverses till content is located. The structure of this paper is as follows. In Section II we present a-NET, and motivate our topics of focus in this paper with an example of its performance. In Section III we develop a general approach for factor analysis of the prediction errors of a-NET. We apply this approach to tree topologies, and show how this analysis can assist in determining how a-NET will perform in specific settings. Next (Section IV), we analyze one of the most likely causes for approximation error in a-NET, namely the IRM-violation in the cache miss stream, using a Markov chain model to explain certain properties of the prediction error in a-NET. Section V presents the performance of a-NET over a wide range of topologies, for both cache-specific performance metrics as well as networkwide metrics. Section VI presents a survey of related work on cache approximations and cache networks, and we conclude with a summary of our findings, and future work, in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. APPROXIMATING CACHE NETWORKS USING a-LRU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model Description and Problem Statement</head><p>We begin by describing the system of interest in this paper, namely cache networks.</p><formula xml:id="formula_0">Let G = (V, E) be a network of caches, V = {v 1 , ...v n }, E ⊆ V × V . The cache size at node v ∈ V is denoted |v|. Additionally, let F = {f 1 , ..., f N }</formula><p>be the set of files in the system. Each file is stored permanently at one or more servers S = {s 1 , ..., s m } that are attached to the network, each to one or more v ∈ V . For all s ∈ S define files(s) ⊆ {1, ..., N } to be the file indices stored at the server, s.t. s∈S files(s) = N . Also, for all s ∈ S and v ∈ V let χ(s, v) = 1 iff source s is attached directly to v, and otherwise χ(s, v) = 0. For simplicity of presentation, we assume for the rest of the paper that each file source is attached only to a single cache in the network, denoted v s .</p><p>In this paper we address networks with routing tables that do not change over time. For presentation purposes, we assume shortest path routing is used. Let a path P be an ordered set of nodes P = (v P1 , ..., v Pj ) such that for all</p><formula xml:id="formula_1">1 ≤ i &lt; j, (v Pi , v Pi+1 ) ∈ E. Given a node v and a file f i s.t. i ∈ files(s), let P v i = (v P1 = v, ..., v Pj = v s )</formula><p>be the shortest path from v to the source of f i , v s , where distance is measured in the number of hops. In case of a tie, one path is selected at random and is maintained hereafter.</p><p>At each node in this system, a Poisson stream of file access requests arrives exogenously. A request for f i is denoted req i . For all 1 ≤ i ≤ N, v ∈ V, λ i,v is the rate of exogenous requests for file f i at node v. When a request for file f i arrives at a cache v, it generates a hit if the file is located at the cache and a miss if not. In the event of a miss, the request is forwarded to the next-hop cache along P v i , or to s if χ(s, v) = 1 ∧ i ∈ files(s). In the event of a hit, the file is forwarded along the reverse path taken by the request, and cached at each node along the way. If the cache is full, one of the files in the cache is evicted to make room for the new file. Following common practice (e.g., <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>), we assume that all files have the same size, and so the cache size |v| can be expressed in terms of the number of files it can hold.</p><p>For a given path P v i , let P v i [j] be the j-th node in the path, s.t. P v i [1] = v and P v i <ref type="bibr" target="#b1">[2]</ref> is the next hop from the originating node v. Given two nodes v, v ∈ V , define</p><formula xml:id="formula_2">R(v, v ) = {i : v = P v i [2]</formula><p>}. This is the set of all request ids i for which v is on the next hop from v along the shortest path to source s s.t. i ∈ files(s). Let r i,v be the combined incoming rate of requests for f i at node v, and let m i,v be the miss rate of f i at node v. Then the rate of requests for f i at node v can be expressed as</p><formula xml:id="formula_3">r i,v = λ i,v + v :i∈R(v ,v) m i,v<label>(1)</label></formula><p>Note that while λ i,v is a Poisson stream of exogenous requests, the miss stream of a cache is not, and so when we refer to r i,v as the incoming rate at the node we are referring to the average rate of requests. The miss rates at each node depend on several factors, in addition to the cache management policies. One of these is the time it takes to load content to the cache after a cache miss. In this paper, we follow common practice <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b4">[5]</ref>, and assume that the file download time after a cache miss is significantly smaller than the inter-request. Thus, once a cache miss occurs, the file is assumed to be instantaneously downloaded into the cache.</p><p>Our goal in this paper is to develop an algorithm that can predict, with high accuracy, the incoming and miss streams at each of the caches, given the exogenous incoming rates. With such an algorithm, cache network developers can evaluate the performance of the cache network itself efficiently. To determine the incoming and miss streams, we must solve the system of equations <ref type="bibr" target="#b0">(1)</ref>, for all i and v, and this in turn requires determining the miss rate for each file at each node. To this end we develop a-NET, our MCA generating algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. From a-LRU to a-NET</head><p>In <ref type="bibr" target="#b3">[4]</ref>, Dan and Towsley developed an SCA algorithm for LRU and FIFO caches. As explained shortly, a-NET uses the LRU SCA algorithm, denoted a-LRU, to compute an MCA for the entire network. We begin, therefore, with a short description of a-LRU.</p><p>Let p v = (p 1,v , . . . , p N,v ) be the steady-state incoming request distribution for files in F at a certain cache v. a-LRU can be thought of as a function contents( p v , |v|) = q v , where q v = (q 1,v , . . . , q N,v ) is the vector consisting of the probability for each file to be present in the cache at a random point in time.</p><p>a-LRU was developed for request streams that conform to the Independent Reference Model, or IRM for short, which means that the probability that the j-th request will be req i , given past requests, is still p i,v . For a request stream conforming to IRM, we prove in <ref type="bibr" target="#b6">[7]</ref> that</p><formula xml:id="formula_4">m i,v = r i,v • (1 -q i,v ).<label>(2)</label></formula><p>Given our discussion thus far, we can now define the MCA generating algorithm, a-NET, an algorithm for solving the following set of equations, for each v ∈ V and i s.t. f i ∈ F :</p><formula xml:id="formula_5">r i,v = λ i,v + v :i∈R(v ,v) m i,v<label>(3)</label></formula><formula xml:id="formula_6">p i,v = r i,v N j=1 r j,v<label>(4)</label></formula><formula xml:id="formula_7">q v = contents( p v , |v|) (5) m i,v = r i,v • (1 -q i,v )<label>(6)</label></formula><p>Eq. ( <ref type="formula" target="#formula_5">3</ref>) is identical to Eq. ( <ref type="formula" target="#formula_3">1</ref>), which combines the exogenous request stream with the miss streams of the neighbors of v to get the incoming request stream at each cache. Eq. ( <ref type="formula" target="#formula_6">4</ref>) defines p i,v as the relative portion of requests for f i at v. Eq. ( <ref type="formula">5</ref>) repeats the definition of the contents(•, •) function, and Eq. ( <ref type="formula" target="#formula_7">6</ref>) is identical to Eq. ( <ref type="formula" target="#formula_4">2</ref>). Note that Eq. ( <ref type="formula" target="#formula_7">6</ref>) has only been established for IRM streams. When the request streams consist also of the miss streams of neighbors, that do not conform to IRM, the equation may not accurately predict the miss rate. This issue is studied in detail in Sections III and IV.</p><p>a-NET solves these equations iteratively. Initially, we set m i,v = 0 for all i and v. Note that in the order these equations are presented, each equation relies only the values of the exogenous rates λ i,v , which we assume are given, and information available from previous equations. In each iteration, a-NET solves equations ( <ref type="formula" target="#formula_5">3</ref>) through <ref type="bibr" target="#b5">(6)</ref> in order, for all caches, using the output of the previous iteration as input to the next. a-NET halts when a predefined precision threshold is met. In our implementation, we used the mean-square distance between the request rates of all files at all nodes as the halting criterion. While we have not established convergence, the algorithm converged in all cases that we tested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. a-NET performance -an example</head><p>To motivate the issues we discuss in the coming sections, we present here an example of the performance of a-NET over a simple topology. When using an isolated cache, a commonly used performance metric is the miss probability of the cache. Approximations for these caches are then evaluated by observing the Miss Probability Ratio (MPR) between the predicted and actual behavior <ref type="bibr" target="#b3">[4]</ref>.</p><p>We simulated the behavior of a 10-by-10 torus cache network. The exogenous request distribution and rate is the same for all caches, and requests are distributed according to Zipf distribution with parameter 1 (i.e., the i-th most popular file has p i = 1/i N j=1 1/j ), as has been observed in real web access traces <ref type="bibr" target="#b7">[8]</ref>. There are |F | = 500 files in the system, cache sizes are |v| = 50, and there are 4 sources of content s 1s 4 with each file stored at exactly one source. We compared the behavior of the system to that of the approximation generated by a-NET, the results presented in Figure <ref type="figure" target="#fig_1">1</ref>. The top plot shows the MPR per node. The bottom plot shows the standard deviation of the incoming file request distribution at each cache node, approximation vs. simulation.  Three main features are evident in Fig. <ref type="figure" target="#fig_1">1</ref>. First, focusing on the MPR, a-NET consistently under-estimates the number of misses that occur at each cache. Second, the MCA produced by a-NET does not err by more than 13%, with a median error of 7% . These results indicate that, even though the IRM assumptions are invalid for cache networks, a-NET predictions are close to the actual behavior. Finally, the STD of the approximated incoming distribution is almost identical to that in the simulation. This suggests that the approximation is using as input at each node a steady-state distribution that is close to the actual distribution observed at that node, and so the cause for increased MPR must lie elsewhere. Thus, we next more closely investigate what factors cause the errors we see here, and study under what conditions are these errors minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. a-NET ERROR DECOMPOSITION</head><p>In this section we analyze the sources of errors in a-NET. Our goals here are (a) to determine the possible causes of error; (b) to show how these errors can be distinguished; and (c) to use this information to determine in which scenarios a-NET will provide accurate predictions.</p><p>We consider three potential causes for a-NET inaccuracies:</p><p>1) Inherent Prediction Error in the underlying SCA algorithm. Since a-LRU only approximates cache behavior, even with the correct request distribution the results may differ from the actual system behavior. 2) Violation of IRM assumption. The violation of IRM may adversely affect the performance of a-NET in two ways. First, a-LRU was designed for and evaluated only under the IRM assumptions. Second, the miss rate of each file is calculated using Eq. ( <ref type="formula" target="#formula_4">2</ref>), which may not hold for IRM streams. 3) Input Error (or: Propagated Error). The input given to a-LRU for cache v during a-NET execution includes outputs predicted by a-LRU for all of v's neighbors.</p><p>Since the prediction of a-LRU is inaccurate, the request distribution given as input to a-LRU at each cache may not be the actual distribution at that cache. This can produce inaccurate predictions.</p><p>We therefore examine the contributions of each of the errors in a given scenario, comparing a simulation (denoted SIM) to the a-NET approximation (denoted APP). We disentangle the different errors from each other via factor analysis, extracting from the simulation results the probability of a request for each file at each node, and then evaluating the per-cache performance in two additional scenarios: 1) Per-cache simulation with IRM traffic, denoted SIM-IRM. Here, we simulate the behavior at each cache using the file request distribution extracted from SIM, but with file requests being generated from this distribution according to IRM. 2) Per-cache approximation with simulation-driven traffic, denoted APP-DRIVEN. Here we evaluate the cache performance using a-LRU at each cache, using the file request distribution extracted from SIM. Recall that the a-LRU algorithm assumes IRM arrivals.</p><p>We shall refer to these as the pseudo-simulation and pseudoapproximation respectively. In <ref type="bibr" target="#b3">[4]</ref> the authors demonstrate that a-LRU gives close to optimal results for common scenarios, and so our goal here is to determine what part of the approximation error is due to IRM violation, and what part is due to input error, as defined above. We do so by comparing the predictions of a-NET in these different scenarios. Specifically,</p><p>• Comparing SIM to APP provides the MPR performance of a-NET, as in Fig. <ref type="figure" target="#fig_1">1</ref>. • Comparing SIM to APP-DRIVEN isolates the influence of IRM violation on the performance of a-NET, since the input at each cache is the same for both simulation and pseudo-approximation. • Comparing SIM-IRM to APP-DRIVEN removes both the effects of IRM violation and input error, since the input at each cache is the same and the arrival streams at caches in SIM-IRM conform to IRM.</p><p>Factoring a-NETs approximation error in into its components can help develop improved prediction algorithms, that address these errors, as well as determine which cases will be more prone to prediction errors. We demonstrate this second point next for the case of cache trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cache Trees</head><p>When using shortest path routing, cache trees form in a cache network with a single source of content. Each node forwards its entire miss stream along a single link, the one on the shortest path to the source. Leaves are therefore nodes whose input stream does not include the miss stream of any neighboring cache. For the purpose of this case study, we consider only complete k-ary trees. As in the example case from Section II, we assume that (a) all caches are of the same size, and (b) the exogenous request stream at each cache is the same. These assumptions are maintained throughout this paper.</p><p>We initially consider the case of a linked list of h caches v 0 , . . . , v h-1 , with cache v h-1 linked to the single source (Fig. <ref type="figure" target="#fig_2">2</ref>). We simulated the behavior of the system with parameters h = 10, |v| = 50, N = 500, where the exogenous request distribution is Zipf with parameter 1. We generated, additionally, the pseudo-simulation and pseudo-approximation as described above, and plotted the pair-wise MPR between each of the simulations (standard (SIM) and pseudo (SIM-IRM)), and each of the approximations. The results of these comparisons are presented in Figure <ref type="figure">3</ref>. Several conclusions may be drawn from Figure <ref type="figure">3</ref>. First, we note that when both the input error and IRM-violation errors are removed, the performance of the algorithms is close to optimal (a ratio of 1.0), a strong indication that there are no additional hidden causes for error. Second, as in the example from Section II, the error leads a-NET to consistently underestimate the probability of misses. Finally, it is clear that the input error is negligible in the case portrayed in Fig. <ref type="figure" target="#fig_2">2</ref>, and that IRM-violation is the main source of error, which increases at caches closer to the source. This supports the observation made at the end of Section II, that a-NET provides a good estimate of the incoming request distribution at each node. Thus, one would expect that in scenarios where IRM is violated to a lesser degree, the performance of a-NET would improve.</p><p>Support for this last hypothesis can be obtained from the performance of a-NET for larger trees, as we increase the branch factor k of the tree. As k grows, the incoming request stream at upper-level caches become more IRM-like. To understand why, consider a node A with two child nodes B and C, each of which is the root of its own sub-tree. Requests Fig. <ref type="figure">3</ref>. Miss probability ratio for standard (SIM / APP), driven (SIM / APP-DRIVEN), IRM-Sim (SIM-IRM / APP) and driven + IRM-Sim (SIM-IRM / APP-DRIVEN). Performance is better when closer to 1.0. When IRMviolation is removed, the performance of a-NET at all caches is close to optimal arriving at B are independent of those arriving at C since their respective sub-trees do not have any node in common. Therefore, the miss streams of B and C are independent of each other. However, the miss stream of B at each epoch depends on the state of cache B in that epoch. It is expected, therefore, that the aggregate of these two streams is in some sense closer to IRM than each of them would be on its own. As k goes to infinity, we get closer to a purely IRM request stream at A.</p><p>Based on this insight, we expect the performance of a-NET to improve as k grows. The results of testing this hypothesis for k = 2, 3, 4, 5 are shown in Figure <ref type="figure" target="#fig_3">4</ref>. For each level in the tree, we calculated the MPR for each cache in that level, then plotted the mean MPR at that level with a 95% confidence interval. Our results clearly show that as the branch factor increases, so too does the accuracy of a-NET. We tested the error composition for additional distributions over tree topologies -uniform, truncated arithmetic and geometricand consistently observed this behavior. When we turn our attention to general topologies, similar behavior occurs as the average node degree grows. This is demonstrated and discussed in detail in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. UNDERSTANDING IRM VIOLATION IN CACHE NETWORKS</head><p>As we've just seen, IRM-violation can cause a-NET prediction errors. In this section we present insight derived from an analytical model supporting the observation that a-NET generally underestimates the miss probability.</p><p>Let us begin with some intuition. It has been shown (for example, see <ref type="bibr" target="#b8">[9]</ref>) that a chain of LRU caches performs poorly. One of the reasons for this is the lack of locality of reference in the miss streams of caches. When a cache miss occurs at v for file f , the file is downloaded into the cache, and so in order for another cache miss to occur it first must be evicted from the cache. Until this eviction occurs, the miss stream will not see another request for this file. This causes requests for file f to be, on average, farther apart in the miss stream than they are in the incoming stream, reducing the effectiveness of next-hop caches. This behavior can also help explain why a-NET consistently tends to underestimate the miss probability of caches. The inter-arrival distance between requests for f i are likely to be greater in non-IRM miss-streams than in IRM streams. Since a-NET predicts misses assuming IRM, the miss probability it predicts will be lower than actually exhibited.</p><p>While the behavior just described is intuitive, and has been demonstrated empirically for many scenarios, to the best of our knowledge there is little analytical support for it. In Section IV-A we present a Markov model for the simple (and tractable) case of an IRM request stream with a distribution close to uniform, as defined shortly. Next (Section IV-B), we use this model to demonstrate the effects of IRM-violation on the miss stream, and extrapolate from our results here to the effects of LRU caches on arbitrary distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Description of Markov chain</head><p>We use a discrete Markov chain, to model the behavior of a tagged file f * at cache v. We assume the arrival stream is IRM, that p * ,v = α, and for all other files p i,v = β, s.t.</p><formula xml:id="formula_8">β = 1 -α N -1</formula><p>We are interested in the non-IRM traffic characteristics of the miss stream. Following <ref type="bibr" target="#b8">[9]</ref>, we do so by measuring the distribution of the number of requests between two req * , termed here the inter-miss distances.</p><p>Our Markov chain consists of states (i, j), where</p><formula xml:id="formula_9">• 0 ≤ i &lt; ∞.</formula><p>This variable represents the number of cache misses that have occurred for files other than f * , since f * entered the cache. • j ∈ {1, . . . , |v|, E(vict), M(iss), A(bsorb)}. This represents the state of f * . For i ≤ |v|, f * is said to be in the i-th location of the cache. Otherwise, the file might be evicted (state E) or requested after eviction, generating a cache miss (state M). Finally, once a cache miss occurs, we go into the absorbing state (state A). The transition matrix T can be derived from the transition diagrams, shown in Figure <ref type="figure">5</ref>. We assume that the system starts in state (0, 1), the state of the system after a cache miss for f * , with f * at the top of the cache. Each new request at the cache causes a transition in the Markov chain. Denote by T k the state of the system after k transitions. For each state s, the probability that the system is in state s after k arrivals is expressed by T k [(0, 1), s]. Therefore, the probability of an inter-miss distance being h for some h ∈ N is</p><formula xml:id="formula_10">P (distance = h) = ∞ k=1 T k [(0, 1), (h, M )]. (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>For all practical purposes, we need to set a cap for the distances h we are interested in computing, as otherwise the transition matrix is of infinite size. We denote that cap M max . Fig. <ref type="figure">5</ref>. Top: Transition diagram for 1 ≤ j ≤ |v|. For the case of i = Mmax + 1, because state (i + 1, j + 1) does not exist we give the transition to (i, j + 1) a probability of (N -j)β. Bottom: Transition diagram for j = E, M, A. The probability of being in state (i, M ) is the probability that the inter-miss distance is i. Because state (i + 1, E) does not exist, for the case of i = Mmax + 1 we give the transition to (i, E) a probability of (N -1)β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Characterizing the miss stream using the Markov Model</head><p>Using the model described in Section IV-A, we analyzed several scenarios in order to understand how the passing of requests through the cache affected the inter-request distance of the stream. For example, for the case of uniform distribution with N = 30, |v| = 5, M max = 80, we compared the interrequest distance distribution of the tagged file, as computed by the Markov model, to the matching distribution for an IRM stream with the same request distribution for file request IDs. The cdf of these distributions is shown in Figure <ref type="figure" target="#fig_4">6</ref>.</p><p>Let G M (x) be the inter-request distance distribution cdf for the non-IRM miss stream, as computed by the Markov chain. Furthermore, let G I (x) be the cdf for an IRM request stream with the same distribution of files requested as the miss stream. As can be seen from Fig. <ref type="figure" target="#fig_4">6</ref>, G M (x) &lt; G I (x) for all x &lt; N -1. More generally, we make the following conjecture:</p><p>Conjecture 1: When the incoming request stream at a cache conforms to IRM, G M (x) ≤ G I (x) for all x ≤ |v|. This conjecture is motivated by the observation that the tagged file f * needs to be evicted from the cache before it can appear again in the miss stream, and so we expect the first |v| misses following a miss for f * to have a smaller probability of being requests for f * , compared to an IRM model. We now proceed to use this Markov model to understand the effects IRM-violation in the miss stream will have on the performance of the next-hop cache. We present the following Theorem, proven in <ref type="bibr" target="#b6">[7]</ref>:</p><p>Theorem 1: Let f * , G M (k) and G I (k) be defined as above, and assume that each of the remaining files arrives with probability β. Additionally, let Z M (k) be the the inter-arrival distance distribution (IADD) cdf for all other files<ref type="foot" target="#foot_1">1</ref> , and Z I (k) be the IADD cdf for an IRM request stream with request probability β. Finally, let h M * and h I * be the hit probability of f * at cache v for each model. Then, if</p><formula xml:id="formula_12">Z M (k) ≤ Z I (k) for all k ≤ |v|, then h M * -→ N →∞ G M (|v| -1) h I * -→ N →∞ G I (|v| -1).</formula><p>Based on Theorem 1 and Conjecture 1, the inter-arrival distance distribution generated by the model can be used to estimate how the hit probability changes for a miss stream which is non-IRM.</p><p>We present here our results from testing the case of N = 50, |v| = 3, for varying values of α, ranging from 0.05 to 0.8, and compare the resulting inter-miss distribution to the IRM equivalent in two ways. First, based on Theorem 1 we estimate the difference in hit probability between an IRM stream and the miss stream, by computing G I (|v| -1) -G M (|v| -1) . Second, we took the mean-square difference between the pdfs of both streams, to see how the hit probability is linked to overall distributional difference. The results are shown in Fig. <ref type="figure" target="#fig_5">7</ref>. Figure <ref type="figure" target="#fig_5">7</ref> indicates that there is a clear correlation between, the popularity of req * in the miss stream, the hit probability difference and the mean-square error of the inter-arrival PDFs. As the popularity of the file in the miss stream grows (y axis in Fig. <ref type="figure" target="#fig_5">7</ref>.(a)), so too does the difference between IRM and non-IRM distributions in terms of hit probability (Fig. <ref type="figure" target="#fig_5">7</ref>.(b)). Also, the changes in the distribution reflect this effect (Fig.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.(c)).</head><p>It is important to note that the error of a-NET in predicting the miss probability is proportional to the popularity of the file. Specifically, in the case presented here, we get that 0.0224 ≤ G M (|v|-1) G I (|v|-1) ≤ 0.0272. Though popular files are on the high end of this range, the ratios are very similar. This proportionality leads us to conjecture that the prediction error of a-NET, in terms of MPR, is mainly one of scale, but files retain their relative weight in the request streams at each cache. This conjecture is supported by the results presented in Fig. <ref type="figure" target="#fig_1">1</ref>. We saw there that even though the MPR can reach 1.16, the standard deviation in the incoming request streams is approximated with high accuracy by a-NET.</p><p>Another important conclusion to be derived from these results is that the performance of a-NET might differ for different files. Files on the two extremes of the popularity scale in the arrival stream will tend to suffer less from the imprecisions of a-NET, compared to files in the middle range. It is therefore reasonable to assume that metrics that break down performance based on content attributes, such as popularity, might be more suitable for analyzing MCA generating algorithms than cache-centric metrics, such as MPR. We present one such additional metric next, in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. NUMERICAL RESULTS</head><p>In this section we present additional numerical evaluation of the accuracy of a-NET. There are many parameters that affect the accuracy of a-NET, and so here we focus on several key parameters: network connectivity, cache size, request distribution and source clustering. In all of our experiments, a-NET converged quickly to a fixed point, the exact number of iterations determined by the network diameter and required precision (i.e., the threshold after which changes between iterations were considered negligible). Regarding the latter, we consistently assumed that the total exogenous rate at each node is 10 and halted when the mean-square distance between the results of two iterations was less than 10 -10 .</p><p>Connectivity. In section III-A we saw that an increase in the branch factor improves performance. We tested the effects of increasing the node degree in a cache network on the MPR performance of a-NET. We generated random, 400-node graphs with each edge existing in the graph with probability 0.01 ≤ p ≤ 0.9, with 500 files distributed according to Zipf distribution with parameter 1. Files were distributed between 10 sources randomly, and sources were randomly placed in each graph. The results are presented in Fig. <ref type="figure">8</ref>. As expected, the MPR of a-NET gets closer to 1 as the connectivity of the graph increases. Note however that this improvement might be a result of the shorter distances between nodes, which limits the aggregation of errors in the prediction of a-NET. Further experimentation is required to determine the relative effect of these two factors. Whatever the exact cause, however, increasing connectivity clearly improves the accuracy of a-NET.</p><p>Source Clustering. Another parameter that might affect performance is the clustering of the sources. When all sources are tightly clustered, the shortest path to each of the sources is the same for the most part from other nodes in the network. This creates a similar behavior to cache trees; specifically, the network contains few cross streams -situations where a link or an entire path contains request streams flowing in opposite directions. In our work, we have observed that such occurrences tend to cause a-NET to have increased prediction error, and we are currently examining possible explanations for this phenomenon. We demonstrate it here over a 10-by-10 torus with 4 sources, and observed the mean MPR as the distance between sources grew. |F | = 1000, |v| = 50, files were assigned randomly to sources, and their arrival process was distributed using Zipf with parameter 1. The effects of clustering on the MPR metric are shown in Fig. <ref type="figure">9</ref>. As can be seen here, there is a slight but gradual increase in MPR as the average distance between sources grows.</p><p>Realistic topologies, request distributions, cache size. For evaluation over realistic topologies, we generated transit-stub topologies modeled after the AT&amp;T network, as suggested by Heckmann et al <ref type="bibr" target="#b9">[10]</ref>, using the GT-ITM tool for topology generation. Here, we compared the prediction of a-NET to the actual system using per-file average number of hops per request. This measure can be considered a system-wide metric, as it takes into account the interactions between caches. For several reasons, it is expected that a-NET will predict the number of hops with high accuracy for files on both extremes of the popularity scale, and less so for those in the middle. First, in Section IV we noted that the difference in hit probability is low on both of these extremes. Second, popular requests will mostly require a single hop, while unpopular requests will traverse the shortest path all the way to the source. Such performance can be clearly seen in Figure <ref type="figure" target="#fig_1">10</ref>.</p><p>We considered the following scenarios, observing the effects of cache size and request distribution: The results are presented in Figure <ref type="figure" target="#fig_7">11</ref>. As can be seen here, a-NET performs better when the distribution is skewed to a larger degree, i.e. when the Zipf parameter is larger. However, in the examples shown here, the number of files in the system and the cache size seem to have little effect on performance.</p><p>For the topologies considered here, the mean error is within range 10 -15%. The diameter of the networks used here was ≤ 10, and so the errors seen here for hop count indicate predicting 1-2 hops less than actually occurs. Further experiments are required to determine how sensitive a-NET will be to an increase in network size.</p><p>We also observed the arrival distribution at all nodes for these simulations, and calculated the mean square difference of the predicted vs. actual values. As expected, our results show that the mean-square error, averaged over all nodes, is ≤ 10 -6, regardless of request distribution. This gives strong support to our conjecture that a-NET can provide reliable predictions for the incoming request distribution at each node. Fig. <ref type="figure">8</ref>. Mean MPR for random graphs over 400 nodes, as a function of p, the probability that each edge is in the network. The mean is taken over 10 simulations for each p, with 95% confidence intervals showing. Fig. <ref type="figure">9</ref>. Mean MPR for 10-by-10 torus networks, as a function of the source clustering. There were 4 sources positioned at the corners of a square, and the x-axis specifies the length of the square side in terms of no. of hops. The mean is taken over 6 simulations for each clustering, with 95% confidence intervals showing. Fig. <ref type="figure" target="#fig_1">10</ref>. Ratio of no. of hops for files stored at a given source (Sim/Approx). Files are ordered by popularity. As can be seen, highly-popular and highlyunpopular files are approximated with greater accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORK</head><p>The approach we pursued here draws much of its inspiration from Kelly's well-known reduced-load approximation for computing blocking probabilities in circuit-switched networks <ref type="bibr" target="#b10">[11]</ref>. The reduced load approximation computes this blocking probability by assuming, similar to our approach here, that the call arrival process to a link j behaves as an independent process. This allows the network to be analyzed as a set of independent links, coupled only through the blocking rates at each link.</p><p>Exogenous request streams were assumed throughout the paper to conform to IRM. However, there are alternative models for request patterns at single caches. Panagakis et. al. <ref type="bibr" target="#b11">[12]</ref> present approximate analysis for streams that have short term correlations for requests. In their model, the arrival process is IRM, with the exception that the k most recent requests have a higher probability of arriving next at the cache than other requests. The justification for this model is that such correlations have been found in web-traces. However, as we have seen, cache networks experience the opposite effect, with recent requests less likely to arrive next.</p><p>Another alternative is Stack Depth Distribution (SDD) (for example, see <ref type="bibr" target="#b12">[13]</ref>). With this model, the stream of requests is characterized as a distribution h = (h i ) ∞ i=1 over the cache slots in a cache of infinite capacity, where h i is the probability that the next cache hit will be at slot i. In this model, all information regarding the individual files being requested is ignored or unavailable.</p><p>For IRM traffic, there are additional algorithms of equal complexity to a-LRU that compute the hit probability at a single cache, but these are not as easily used or as informative. For example, Flajolet et. al. <ref type="bibr" target="#b13">[14]</ref> presented an integral solution for the cache approximation problem, which can be solved numerically to produce the hit ratio. However, there is no straight-forward manner by which to observe the behavior of each file with this approach.</p><p>Che et. al. developed a model for a two-level LRU-based cache hierarchy <ref type="bibr" target="#b4">[5]</ref>, by using a "mean field" approximation of each cache. They associate each file in each cache with a constant time, representing "the maximum inter-arrival time between two adjacent requests for [the] document without a cache miss". They justify this model by claiming that as the number of files in the system goes to infinity, this assumption becomes reasonable. This technique was subsequently leveraged in <ref type="bibr" target="#b5">[6]</ref> to analyze cache coordination policies for cache hierarchies. Neither paper provides much simulation support for this model, and the approach is limited to 2-level cache hierarchies, and cannot be easily extended to larger tree sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS AND FUTURE RESEARCH</head><p>In this paper we presented a-NET, our MCA generating algorithm, designed to evaluate performance measures such as miss probability per cache and system-wide hops per request. In general, a-NET under-estimates the miss probability of caches, for which we have presented analytical support. The accuracy of our approximation is affected primarily by IRMviolations in the cache miss streams, making the approximation most accurate with cache trees with large branch factors and, in general, with highly connected topologies. We have also seen that a-NET is highly accurate in predicting the incoming distribution at all nodes, even when the MPR is large.</p><p>a-NET is designed to approximate the behavior of a cache network with static routing tables, while a more realistic model would consider dynamic routing as well. Adapting a-NET to such a model is a challenging task we plan to address next. a-NET was presented here for LRU caches, but can be used with any SCA algorithm that receives the steady state distribution of request arrivals, and returns the probability of each file to be in the cache. The Markov model presented in section IV can also be adapted, with minimal changes, to other replacement policies, such as FIFO. We are currently working on several ways in which to leverage these properties to expand our understanding of cache networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Top: MPR for 10-by-10 torus, with file requests distributed using Zipf distribution, |F | = 500, and all caches of size |v| = 50. Nodes are sorted by increasing MPR. Bottom: Standard deviation of incoming request distribution at each node. The solid line (sim inc) is for STD in the simulation, while the x's (approx inc) are for the approximation. Nodes are sorted according to increasing STD in the simulation. As can be seen, our model correctly captures the trend of the STD curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. k-ary tree for k=1, with request streams arriving exogenously at each node.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Miss probability ratio for trees with branch factor k = 2, 3, 4, 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. CDF of inter-arrival distance, for both incoming (IRM) and miss (non-IRM) streams. The distance N -1 marks the point after which the negative effects of the cache on the cumulative distribution are no longer felt.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Evaluating the effects of IRM violation on the inter-request distance distribution, as a function of the incoming probability of the tagged file (p * = α). (a) The fraction of requests for f * in the miss stream. (b) G I (|v| -1) -G M (|v|-1). (c) the mean-square difference between the two PDFs, indicating how different the distributions are.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>•</head><label></label><figDesc>|F | = 500, |v| = 50, distrib. = Zipf with parameter 1.0. • |F | = 500, |v| = 50, distrib. = Zipf with parameter 0.6. • |F | = 500, |v| = 20, distrib. = Zipf with parameter 1.0. • |F | = 250, |v| = 50, distrib. = Zipf with parameter 1.0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Mean ratio of no. of hops per request. |F | = 500 unless specified otherwise, and |C| is the cache size. Results were obtained by random placement of 4 sources and random association of files with sources, over 6 simulation. Error bars represent 95% confidence intervals.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM 2010 proceedings This paper was presented as part of the main Technical Program at IEEE INFOCOM 2010.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>We assume that these files have the same inter-arrival distribution. If not, Z M (k) takes the maximal value for each k over all the files.This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE INFOCOM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2010" xml:id="foot_2"><p>proceedings This paper was presented as part of the main Technical Program at IEEE INFOCOM 2010.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science Foundation under CNS-0626874 and CNS-0519922. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Design considerations for a network of information</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ahlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dambrosio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marchisio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dannewitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ohlman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pentikousis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Strandberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rembarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vercellone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
	<note>in ReArch&apos;08 Workshop</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Networking named content</title>
		<author>
			<persName><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Smetters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Plass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Braynard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNEXT</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A data-oriented (and beyond) network architecture</title>
		<author>
			<persName><forename type="first">T</forename><surname>Koponen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-G</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ermolinskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An approximate analysis of the LRU and FIFO buffer replacement schemes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Towsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMETRICS</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis and design of hierarchical web caching systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<biblScope unit="page" from="1416" to="1424" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The LCD interconnection of LRU caches and its analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Laoutaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stavrakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="609" to="634" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Approximate models for general cache networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Rosensweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kurose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<idno>UM-CS- 2009-037</idno>
	</analytic>
	<monogr>
		<title level="j">UMass Amherst</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
	<note>MA</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Web caching and zipf-like distributions: Evidence and implications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breslau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="126" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the intrinsic locality properties of web reference streams</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Abrahao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On realistic network topologies for simulation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Heckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steinmetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM workshop on Models, methods and tools for reproducible network research</title>
		<meeting>the ACM SIGCOMM workshop on Models, methods and tools for reproducible network research</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="28" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Loss networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="319" to="378" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Approximate analysis of LRU in the case of short term correlations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stavrakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1142" to="1152" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exact analysis of Bernoulli superposition of streams into a least recently used cache</title>
		<author>
			<persName><forename type="first">H</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J T</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Softw. Eng</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="682" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Birthday paradox, coupon collectors, caching algorithms and self-organizing search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Flajolet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thimonier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="229" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
