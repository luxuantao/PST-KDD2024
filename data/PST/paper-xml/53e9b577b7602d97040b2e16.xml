<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C1D8CD84F2BAD47E262DA39D7D623A76</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Study of Logarithmic Image Processing Model and Its Application to Image Enhancement</head><p>G. Deng, L. W. Cahill, and G. R. Tobin Abstruct-This correspondence describes a new implementation of Lee's image enhancement algorithm [SI. This approach, based on the logarithmic image processing (LIP) model, can simultaneously enhance the overall contrast and the sharpness of an image. A normalized complement transform has been proposed to simplify the analysis and the implementation of the LIP model-based algorithms. This new implementation has been compared with histogram equalization and Lee's original algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Traditionally, spatial-domain methods for contrast and dynamic range modification have been limited largely to linear contrast stretching, unsharp masking, histogram modeling, and homomorphic image filtering <ref type="bibr">[I]</ref>. <ref type="bibr">Lee</ref>  <ref type="bibr" target="#b7">[8]</ref> proposed a simple algorithm for image enhancement, which can be expressed as where F ( i . j ) and F'( i . j ) represent the pixel brightness value of the original and the processed images and -A( i . j ) is the arithmetic mean brightness value of an ( 12 x t ) ) window that is centered on the pixel position ( i , j ) . The parameters C I , J and '1 are real numbers. It has been pointed out that the spatial-domain methods can be improved by incorporating properties of the human visual system <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b2">[3]</ref>.</p><p>Recently, Jourlin and Pinoli [4]-[5] developed a mathematical structure for logarithmic image processing (LIP). In the LIP framework, a set of special nonlinear operations is defined in the spatial domain. These operations lead to new techniques that can be applied to image processing. Brailean et ul. <ref type="bibr">[6]</ref> have compared the LIP model with other existing models of the human visual system. They have shown that the LIP model is consistent with Xie and Stockham's unified vision model [7], in that it satisfies Weber's law <ref type="bibr">[ l ]</ref> and the saturation characteristics of the human visual system. This correspondence is concerned with a new approach to modify the contrast and dynamic range of an image using a spatial-domain method. In Section I1 of this correspondence, the LIP model is introduced. A new implementation of Lee's image enhancement algorithm using the LIP model is then described. A normalized complement transform is proposed to simplify the analysis and implementation of LIP model-based image processing algorithms. In Section 111, the proposed algorithm is shown to be capable of enhancing the details in the dark area of a digital image and improving the overall contrast. Section IV presents the simulation results of the new implementation using different kinds of images. These results are compared with those using Lee's original algorithm and the histogram equalization method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">AN IMAGE ENHANCEMENT ALGORITHM BASED ON THE LIP MODEL</head><p>In the LIP model, the intensity of an image is completely modeled by its gray tone function f <ref type="bibr">[4]</ref>. A physical example of a gray tone Manuscnpt received October E, 1992; revised December 13, 1993. The associate editor coordinating the review of this paper and approving it for publication was Prof. Nikolas P. Galatsanos.</p><p>The authors are with the Department of Electronic Engineering, La Trobe University, Bundoora, Victoria, Australia.</p><p>IEEE Lop Number 9409182. </p><p>Jourlin and Pinoli <ref type="bibr">[4]</ref> have proved that if the gray tone function is defined on (--x.. AI ). then the subtraction of gray tone functions can be defined as (4)</p><p>Jourlin and Pinoli have also defined the contrast between neighboring pixels f and y as c ( f . g ) = M a x ( f . g l h i n ( f . g ) .</p><p>( 5 )</p><p>However, it is possible to use an alterative definition c ( f . 9 ) = P(f n -  average value of the gray tone function of an ( 1 1 x 1 ) ) window centered at pixel position ( j . j ) . The term u ( i . j ) is defined as</p><formula xml:id="formula_1">/ + ? ! / 2 1(=, -0 / 2</formula><p>where the symbol addition operation A.</p><p>The above algorithm can be simplified by the following simple transformation, which is motivated by Jourlin and Pinoli's "invariant" formulation [4] for the addition and multiplication operations in the gray tone function domain. The transformation of a gray tone function f, denoted as f, is defined as A stands for summation using the special (10) Since this transform changes the gray tone function to the normalized negative gray tone function, it will be called the normalized complementtransjorm. -Using this traflsfiF"n, it can easily be shown that f&amp; = fg. o&amp; = f ' and f ~&amp; j = f / q . The normalized complement transform is useful for simplifying both the analysis and the implementation of the LIP model-based algorithms. A practical example of its usefulness is found in the analysis of the above f = 1 ---.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>f -If</head><p>algorithm, which will be discussed in the next section. Another example is the implementation of the above algorithm as described below.</p><p>Since the normalized negative gray tone function is always greater than zero, it is obvious that a further logarithmic transformation will change the operations of multiplication and power into the usual addition and multiplication. Therefore, the algorithm expressed in <ref type="bibr" target="#b7">(8)</ref> can be implemented by l o g ( F ( j . j ) ) = n l o g ( c ( i . j ) ) In our experiments, we used a look-up-table to implement the logarithmic operation. Table <ref type="table" target="#tab_0">I</ref> presents the numbers of various operations needed to process one pixel by either the usual LIP operation or the implementation shown in Fig. <ref type="figure">1</ref>. It is obvious that using the new implementation, the computational complexity of the proposed algorithm is decreased drastically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ ; j [ I o g ( f ( i . j ) ) -I o g ( i i ( i . j ) ) ]</head><p>In practical image processing problems, a digital image is usually represented by the pixel brightness denoted as F(i.,j). It is natural to relate the pixel brightness and the gray tone function by F ( i . j ) = \If ( i , j ) . For an X-bit image, Jf = 256. Therefore, the intensity image is first changed to the gray tone function, then, by means of the normalized complement transform and the logarithm. operations on the gray tone function are changed to the usual addition and multiplication. Using the inverse transforms, we get the negative normalized gray tone function, the gray tone function and the intensity image, in that order. Although the block diagram shown in Fig. <ref type="figure">1</ref> is derived from the above algorithm, it serves as a general configuration for the implementation of the LIP model-based image processing algorithm, which only involves the operations defined by (2&amp;(4). It is noted in Fig. <ref type="figure">1</ref> that by using the normalized complement transform the LIP model-based image processing algorithm can now be implemented using the same structure as a multiplicative homomorphic tilter. This clearly explains the logarithmic nature of the LIP model and suggests a fast implementation algorithm. However, it can also be seen from Fig. <ref type="figure">1</ref> that the structure of the multiplicative homomorphic filter is just one part of the LIP model-based algorithm. While the contrast of an image is well defined in the LIP model [SI, it is not included in homomorphic tiltering. Since the contrast is one of the most important features of an image. the LIP model opens up new approaches for image processing. For example. the LIP model-based approach permits the extraction of a contrast image, and this approach has been applied to edge detection [SI and image restoration 161.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">ANALYSIS OF THE PROPOSED ALGORITHM</head><p>One unique feature of the proposed algorithm is that the term c i ( i . j ) can effectively enhance the details in the very dark</p><formula xml:id="formula_2">TABLE 11 PARAMETER SETTINGS FOR THE PROPOSED ALGORITHM</formula><p>or very bright areas of an image. If -4(i.,j) is the intensity image corresponding to the gray tone function U ( ; . j ) , then using the normalized complement transform, it can be shown that</p><formula xml:id="formula_3">n ( i , j )</formula><p>is equivalent to the following processing on an intensity image: where -A'( i . j ) is the processed intensity image. When (I &lt; 1 ( n &gt; l ) , the above operation is actually a nonlinear rescaling process that expands the dynamic range of the dark (bright) area of an image. This is useful for enhancing an underexposed (overexposed) image. Since o ( i . , j ) is the average value of an 01 x I ) ) window, then it can be proved that .4( i . j ) is the geometric mean pixel brightness value of an ( t t x I I ) window. Therefore. the term ( I A u ( i . .j j is equivalent to a cascade of a lowpass filter that uses the geometric mean brightness value and a nonlinear rescaling of the lowpass filter output. It can also be shown that this is equivalent to the following processing on an intensity image: ( F i i . j i . j ) )".</p><p>When J &gt; I, the difference between the current pixel brightness value and the mean brightness value of its neighboring pixels is nonlinearly amplified, and thus, the edges are crisped in a similar way to the unsharp masking technique, which produces overshoots at both sides of the edge. The larger parameter j gives rise to stronger overshoots, and thus a sharper output image. On the other hand, when j &lt; 1, an image is blurred.</p><p>The enhancement of contrast can be analyzed by means of the average contrast C( i . J ) between a pixel f ( i . . j ) and its eight neighbors. which is defined as <ref type="bibr">[ 5 ]</ref> ,+I , + I gives the contrast between two neighboring pixels, then C ( i. j ) is called the average contrast of a pixel at location ( i . j ) . Using this definition and the normalized complement transform. it can be shown that for the above algorithm using a i 3 x 3 ) window. the average contrast of a pixel in the processed image is</p><formula xml:id="formula_4">C1Ci.j) E j A C ( i . , j )<label>(14)</label></formula><p>where C'!;.;) is the contrast of a pixel in the enhanced image.</p><p>Therefore, the parameters (I and ,j modify the dynamic range and the sharpness of an image, respectively. However, a basic restriction of the parameter , j is that the dynamic range of the processed image must be within [O. 2551 for an 8-bit image. It is easy to show that at pixel location ( i . j ) the parameter j must satisfy Another restriction for the parameter is that the above proposed algorithm will nonlinearly enhance the noise pixels as well as the details of an image. The effect of noise enhancement is even stronger in the dark area of an image. To see this, let us consider a (3 x 3) area with the central pixel F ( i . , j ) added with noise, that is expressed ;IS F i i . j ) = .4(i.,j) + h. Then, the sharpness enhancement can be expressed as ( F ( ; . J ) / -I ( i . j ) ) '</p><formula xml:id="formula_5">= ( I + h / A 4 ( i . , j ) ~" .</formula><p>For the same noise level 6, a smaller value .4( i . J ) . which corresponds to a darker area of an image, will have a stronger noise enhancement. This problem arises because image sharpening and noise suppression are conflicting requirements. Recently, we have tackled this problem by modifying this algorithm for multiscale processing 191. which can achieve effective enhancement of image contrast and improvement of edge sharpness without enhancing noise. Still another factor that affects image sharpening is the size of the window. Our experiments have shown that a window size of (3 x 3) or ( 5 x 5 ) is large enough to carry out image enhancement. Using a larger window size, although a sharper image is obtained, spurious features and undesired noises are also generated, and it is also more computationally time consuming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iv. SIMULATION RESULTS AND COMPARISONS</head><p>The proposed algorithm has been tested on four different types of images: I ) the CT image, 2) the digital subtraction angiogram (DSA) image, 3) the LANDSAT image. and 4) the DMR image of a man's portrait. Each image has 512 x 512 pixels with 256 gray levels. Figs. 2-5 illustrate the original images and the experimental results. Each figure has four images: the original and the enhanced images by the proposed algorithm, by histogram equalization, and by Lee's original algorithm. In the proposed algorithm, the window size is set to three, and the settings of (I and , j for different test images are listed in Table <ref type="table">11</ref>.</p><p>It is observed from the experimental results shown in Figs. <ref type="figure" target="#fig_0">2(b)-S(b</ref>) that the proposed enhancement algorithm can effectively enhance the overall contrast and the sharpness of the test images. A lot of details that could not be seen in the original images have been clearly revealed. Thus, the proposed algorithm holds the potential for many applications, such as real time medical image enhancement, in which these two parameters can be adjusted by the clinician to meet his or her specific requirements.</p><p>The comparison of different image enhancement methods is difficult, since it requires that each method be "tuned" to its best state, but there seems to be no criterion for such "tuning." Further, a specific enhancement method may best fit one application but may completely fail in another. Therefore, emphasis now will be given to a discussion of the advantages and the disadvantageb of typical image enhancement techniques in manipulating the dynamic range and in improving the sharpness of an image.</p><p>Histogram equalization is useful in stretching low-contrast images with narrow histograms. It has been applied to the four test images. The resultant images are shown in Figs. <ref type="figure" target="#fig_0">2(c)-S(c</ref>). It can be seen from these images that although the CT and the LANDSAT images are enhanced by histogram equalization, the details in the dark areas of these two images are still invisible. The histogram equalization also failed to enhance the DMR and the DSA images. Therefore, the histogram equalization technique is not suitable for revealing the dark details in an image with a broad histogram.</p><p>The proposed algorithm is similar to Lee's algorithm in that they both generate overshoots at both sides of the edges to sharpen an image. However, these two algorithms use totally different ways to modify the dynamic range and the sharpness of an image. While the proposed algorithm uses the nonlinear mapping function to enhance the contrast of an image, Lee's algorithm uses linear brightness stretching to modify the dynamic range of an image. Linear brightness stretching is only effective for an image where the histogram is narrow. For example, when enhancing the contrast of the dark area of an image whose histogram spans a broad range of the display, the bright area of the image will be out of the display range as a result of linear stretching. Therefore, a hard-limiting or other rescaling process is needed to map the output image back into the display range. The simple hard-limiting method is only suitable for an output image with only a few pixels of which the brightness values are outside [0, 2551. The linear rescaling process described below also has a shortcoming in that it cancels the linear contrast enhancement of Lee's algorithm. Let uiax and mill represent the maximum and minimum values of the pixel brightness of an image, and let ; represent a scaling factor, then the rescaling process is expressed as <ref type="figure">,</ref><ref type="figure">( ,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">,</ref><ref type="figure">i ,</ref><ref type="figure">t l</ref> . t . -w, where .I' and I/ are the input and the output of the rescaling process. It can be seen that if -, = 1, the above process is just the usual linear function that maps the range of the output image from [niiu. mas] to [0,255]. The parameter ; is usually set less than one, so that the process will not be "fooled" by a few pixels with extreme values. It is easy to see that when -, &lt; 1, there are some pixels with brightness values that are still out of the range of [O, 2551. Thus, a further hard-limiting process is needed. Therefore, the performance of Lee's algorithm is greatly constrained by the .,--.</p><formula xml:id="formula_6">I I = -</formula><p>-I , ,11111 (d) result rescaling process. The proper parameters for Lee's algorithm, together with the proper rescaling process, are essential for desirable results.</p><p>Thus, the proposed algorithm has an advantage over Lee's algorithm in that it does not need the rescaling process. To compare the performance of Lee's algorithm with the proposed algorithm, the four test images are first processed by Lee's algorithm, then the outputs are rescaled to [0, 2551 by a linear rescaling method. The parameters for Lee's algorithm and the rescaling factor are determined through a trial and error process for the four test images. The results are shown in Figs. <ref type="figure" target="#fig_0">2(dt5(d)</ref>.</p><p>It can also be seen from the previous sections that the proposed algorithm is more sensitive to noise than Lee's algorithm. This is confirmed by the experiment using the original "peppers" image, which is shown in Fig. <ref type="figure">6(a)</ref>. The resultant images using the proposed algorithm with the parameter settings &lt; 1 and d &gt; 1 are shown in Fig. <ref type="figure">6(b</ref>) and (c), respectively. It can be observed that when s j &lt; 1, the output image is blurred, and when ,j &gt; 1, the edges as well as the noise (especially those in the dark areas) are enhanced. The resultant image using Lee's original algorithm is shown in Fig. <ref type="figure">6(d)</ref>. which is less noisy and less sharp than Fig. <ref type="figure">6(c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this correspondence, a new implementation of Lee's image enhancement algorithm that is based on the LIP model has been proposed and studied. The new approach has been shown to achieve effective improvement in both the overall contrast and the enhancement of details in the dark area of an image. A normalized complement transform has been proposed to simplify the analysis and implementation of LIP model-based image processing algorithms. transform (DCT) domain while encapsulating the process within a pyramidal data structure. Proposed as the 2-D DCT pyramid code, it involves the use of the lower set of DCT coefficients to decimate a lower spatial resolution layer while the remaining higher order coefficients are quantized and coded for transmission. The decoding process reverses this cycle and makes use of the lower set of DCT coefficients to serve as the predictor for the original image while the higher order set is reinserted to serve as the error source to correct the image. Iterating this procedure on the decimated layer would generate the pyramidal data structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Layered Image Coding Using the DCT Pyramid</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Kuan Hui Tan and Mohammad Ghanbari</head><p>The coding scheme outlined above will be shown to produce better quality images at low bit rates than JPEG [3] coded ones. In particular, the blocking artifacts, which are degradations that are inherent in block-based coding at high compression ratios, will be reduced drastically. Attention will be focused on presenting the DCT pyramid as a compact intraframe codec.</p><p>This paper is structured in the following order. Section I1 outlines the techniques of decimation employing the DCT domain. Section I11 describes the coding concept of the proposed DCT and cosine pyramids. Two concepts for the reduction and eradication of blocking artifacts are introduced in Section IV. A set of three guidelines are summarized in Section V to improve the coding efficiency. Section VI gives some experimental results with discussiona, and conclusions follow in Sections VI1 and VIII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. ~NTKODUCTION</head><p>The advent of broadband integrated services network (B-ISDN) will usher in a host of sophisticated demands for video services of varying fidelities, dimensions, and aspect ratios. Establishing a framework that allows these various video classes to interoperate and new services to evolve will offer significant advantages in both the effective utilization of networks' bandwidth and resource usage of terminal transmitters and receivers. This approach of enabling video layers to interwork is a concept espoused by layered coding, and the ability to represent an image in a pyramidal data structure would facilitate such a concept <ref type="bibr">[I]</ref>. 121.</p><p>This paper aims to introduce a new image coding technique that motivates the philosophy of layered coding. The technique capitalizes on the ability to perform decimation using the discrete cosine Manuscript received December 19, 1992; revised February 28, 1994. The associate editor coordinating the review of this paper and approving it for publication was Prof. Nasser M. Nasrabddi.</p><p>K. H. Tan is with the Information Technology Institute, Singapore. M. Ghanbari is with the Department of Electronic Systems Engineering.</p><p>IEEE Log Number 9409280.</p><p>Universitj of Essex, Colchester, UK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">DCT DOMAIN DECIMATION</head><p>Fundamental to the technique of manifesting DCT within a pyramidal data structure is the ability to perform decimation and interpolation in the transform domain. To decimate an image that is segmented into sample blocks of size : Y x -1-by a ratio of AI/.\, where 31 &lt; S. an S x 2;-point DCT forward transform is applied followed by an .If x .If -point DCT inverse transform using the lower order coefficients <ref type="bibr">[I]</ref>. Decimation via this procedure is realisable because a different set of basis vectors is used during the synthesis transform. Both integer and noninteger ratios of .If/Aare possible. This process will hereafter be denoted by 2'</p><p>It should be noted that the normalizing term of the DCT transform pair for : Y -+ AI is .I-. This is to ensure that the dc level is synthesized correctly. Central to the design of decimators is the need for a filtering operation to minimize aliasing artifacts. The removal of bands in orthogonal transforms provides implicit filtering. This filtering process can be analyzed by deriving its equivalent impulse -If.</p><p>1057-7149/95$04.00 0 1995 IEEE</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. ( a ) Original CT image; (b) result of the proposed algorithm; (c) result of histogram equalization; (d) result of Lee's original algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(;. j ) ) = &amp; ( x ~~~~~, 2 x{z,:',L,2 ,I 12 log(f(k. I ) ) ) . The implementation of the above algorithm can be expressed by the block diagram shown in Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Original DSA image; (b) result of the proposed algorithm: (c) result o f histogram equalization: (d) result of Lee's original algorithm,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig</head><label></label><figDesc>Fig. 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Original DMR image; (b) result of the proposed algorithm; (c) result of histogram equalization; (d) result of Lee's original algorithm. Fig. 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig 6 of Lee's algonthm (a) Onginal "Peppers" image, (b) result of the propo5ed algonthm with ? &lt; 1, (c) result of the proposed algonthm with j. &gt; 1,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. I. Four-level 2-D DCT pyramid coder and decoder outline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISOV</head><label>I</label><figDesc>OF THE NUMBERS OF VARIOUS OPERATIONS NEEDED TO PROCESS A PIXEL USING THE ORIGINAL LIP OPERATIONS AND USING THE BLWK DIAGRAM SHOWN IN FIG. 1</figDesc><table><row><cell>f</cell><cell>-f</cell></row><row><cell cols="2">Fig. I. Block diagram for the implementation of the LIP model-based</cell></row><row><cell>algorithms.</cell><cell></cell></row><row><cell cols="2">function is the absorption function of a light filter whose opacity is</cell></row><row><cell cols="2">known at each position. Therefore, a gray tone function f is defined</cell></row><row><cell></cell><cell>defined in terms</cell></row><row><cell cols="2">of the usual operations as [4]</cell></row><row><cell>and</cell><cell></cell></row></table><note><p><p>on a spatia1 support D , with values in the real interval [O. A I ) , where .U is strictly positive. The value 0 of the gray tone function represents the "glare limit" of the eye, while the value of . \ I corresponds to complete darkness.</p>In the LIP model, the addition of two gray tone functions f and y and multiplication of f by a real number o are</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Fundamentals of Digital Image Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The role of human visual models in image processing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Granrath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1981-05">May 1981</date>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="552" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image processing for quality improvement</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pmc. IEEE</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="1640" to="1651" />
			<date type="published" when="1978-12">Dec. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A model for logarithmic image processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jourlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Pinoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J . Mimscopy</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="21" to="35" />
			<date type="published" when="1988-01">Jan. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Contrast definition and contour detection for logarithmic images</title>
	</analytic>
	<monogr>
		<title level="j">J . Microscopy</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1989-10">Oct. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluating the EM algorithm for image processing using a human visual fidelity criterion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Brailean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Giger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP-YI</title>
		<meeting>ICASSP-YI</meeting>
		<imprint>
			<date type="published" when="1991-04">Apr. 1991</date>
			<biblScope unit="page" from="2957" to="2960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Toward the unification of three visual laws and two visual models in brightness perception</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Stockham</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Sysr.. Man Cyber</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="379" to="387" />
			<date type="published" when="1989-03">Mar. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Digital image enhancement and noise filtering by use of local statistics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">fEEE Trans. Pattern Anal. Muchine Inrell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="165" to="168" />
			<date type="published" when="1980-03">Mar. 1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiscale image enhancement using the logarithmic image processing model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Cahill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elecfron. Left</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="803" to="804" />
			<date type="published" when="1993-04">Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
