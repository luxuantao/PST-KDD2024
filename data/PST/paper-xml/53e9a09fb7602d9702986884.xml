<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OSKI: A library of automatically tuned sparse matrix kernels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005">2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Applied Scientific Computing</orgName>
								<orgName type="institution">Lawrence Livermore National Laboratory</orgName>
								<address>
									<postBox>P.O. Box 808</postBox>
									<postCode>L-365, 94550</postCode>
									<settlement>Livermore</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
							<email>demmel@eecs.berkeley.edu</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Electrical Engineering and Computer Sciences</orgName>
								<orgName type="department" key="dep2">Department of Mathematics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>737 Soda Hall</addrLine>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
							<email>yelick@eecs.berkeley.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical Engineering and Computer Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>776 Soda Hall</addrLine>
									<postCode>94720</postCode>
									<settlement>Berkeley, Berkeley</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OSKI: A library of automatically tuned sparse matrix kernels</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005">2005</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1088/1742-6596/16/1/071</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Optimized Sparse Kernel Interface (OSKI) is a collection of low-level primitives that provide automatically tuned computational kernels on sparse matrices, for use by solver libraries and applications. These kernels include sparse matrix-vector multiply and sparse triangular solve, among others. The primary aim of this interface is to hide the complex decisionmaking process needed to tune the performance of a kernel implementation for a particular user's sparse matrix and machine, while also exposing the steps and potentially non-trivial costs of tuning at run-time. This paper provides an overview of OSKI, which is based on our research on automatically tuned sparse kernels for modern cache-based superscalar machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Goals and Motivation</head><p>We describe the Optimized Sparse Kernel Interface (OSKI), a collection of low-level primitives that provide automatically tuned computational kernels on sparse matrices, for use by solver libraries and applications. The kernels include sparse matrix-vector multiply (SpMV) and sparse triangular solve (SpTS), among others; "tuning" refers to the process of selecting the data structure and code transformations that lead to the fastest implementation of a kernel, given a machine and matrix. While conventional implementations of SpMV have historically run at 10% of machine peak or less, careful tuning can achieve up to 31% of peak and 4? speedups [1, Chap. 1]. The challenge is that we must often defer tuning until run-time, since the matrix may be unknown until then. The need for run-time tuning differs from the case of dense kernels where only install-or compile-time tuning has proved sufficient in practice <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>OSKI reflects the need for and cost of run-time tuning, as extensively documented in our recent work on automatic tuning of sparse kernels using the Sparsity framework <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref>. The 6 goals of our interface and the key findings motivating each are as follows:</p><p>(i) Provide basic sparse kernel "building blocks": We define an interface for basic sparse operations like SpMV and SpTS, in the spirit of the widely-used Basic Linear Algebra Subroutines (BLAS) <ref type="bibr" target="#b11">[12]</ref> and recent Sparse BLAS Standard <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12]</ref>. We choose the performance-critical kernels needed by sparse solver libraries and applications (particularly</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>those based on iterative solution methods). We target "users" who are sparse solver library writers, or otherwise interested in performance-aware programming at the level of the BLAS. (ii) Hide the complex process of tuning: Matrices in our interface are represented by handles, thereby enabling the library to choose the data structure. We use this indirection because the best data structure and code transformations on modern hardware may be difficult to determine, even in seemingly simple cases <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b0">1]</ref>. For example, since many sparse matrices have a natural block structure, we can enhance the spatial and temporal locality of SpMV by storing the matrix as a collection of blocks. However, we have observed cases in which SpMV on a matrix with an "obvious" block structure nevertheless runs in 38% of the time of a conventional implementation (2.6? speedup) using a different, non-obvious block structure <ref type="bibr" target="#b0">[1]</ref>. Furthermore, we have shown that if a matrix has no obvious block structure, SpMV can still execute in half the time (2? speedup) of a conventional implementation by imposing block structure through explicitly stored zeros, even though doing so results in extra work (flops) <ref type="bibr" target="#b0">[1]</ref>. (iii) Offer higher-level memory hierarchy-friendly kernels: The kernels defined in our interface are a superset of those available in similar library interfaces, including the Sparse BLAS standard <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> and the SPARSKIT library <ref type="bibr" target="#b14">[15]</ref>, among others <ref type="bibr" target="#b15">[16]</ref>. Our "higherlevel" kernels are designed for cache-based machines and can execute much faster than their equivalent implementations using "standard" kernels. For example, in addition to the SpMV operation y ? A?x, we include the kernel y ? A T A?x in which A may be read from main memory only once. Compared to a register-blocked twostep implementation, t ? A? x, y ? A T ? t, a cache-interleaved implementation can be up to 1.8? faster, and up to 4.2? faster than an unblocked two-step implementation <ref type="bibr" target="#b7">[8]</ref>. (iv) Expose the cost of tuning: We require the user to request tuning explicitly because of its potential costs. In the case of SpMV, tuning can cost 40? as much as a single SpMV operation <ref type="bibr" target="#b0">[1]</ref>. Although this cost is dominated by the time simply to copy the matrix to the new data structure (and so is comparable to just building the matrix in the first place), it should nevertheless only be done when the user expects sufficiently many SpMV calls to amortize this cost, as might be expected in iterative solvers <ref type="bibr" target="#b0">[1]</ref>. (v) Support self-profiling: The user cannot always a priori predict, say, the number of SpMV operations that will occur during an application run. We designed our interface to allow the library to monitor transparently all operations performed on a given matrix, and then use this information in deciding how aggressively to tune. Self-profiling enables the library to guess whether tuning will be profitable (see Section 2.3). (vi) Allow for user inspection and control of the tuning process: To help the user reduce the cost of tuning, the interface provides two mechanisms that allow her both to guide and to see the results of the tuning process (Section 3). First, the user may provide explicit hints about the workload (e.g., the number of SpMVs) and the kind of structure she believes the matrix possesses (e.g., uniform blocks of size 3 ? 3, or diagonals). Second, the user may retrieve string-based summaries of what tuning transformations and other performance optimizations have been applied to a given matrix. Thus, a user may see and save these results for re-application on future problems (matrices) which the user believes have similar structure to a previously tuned matrix. Moreover, a user may select and apply transformations manually.</p><p>An implementation of OSKI is available <ref type="bibr" target="#b16">[17]</ref>. The remainder of this paper highlights features of OSKI by example, and the interested reader may consult the OSKI 1.0 User's Guide for details. We use a library-based approach because it enables the use of run-time information, and because of its potential immediate impact on applications. OSKI could be integrated readily into popular solver libraries such as PETSc <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, or environments such as MATLAB <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">An Introduction to the Tuning Interface by Example</head><p>This section introduces the C version<ref type="foot" target="#foot_0">1</ref> of OSKI using several examples. OSKI uses an objectoriented calling style, where the two main object types are (1) a sparse matrix object, and (2) a dense (multiple) vector object. We anticipate that users will use the library in different ways, so this section illustrates the library's major design points by discussing three such ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Basic usage: gradually migrating applications</head><p>To ease the development effort for existing applications, OSKI supports matrix data sharing when the user's sparse matrix starts in a standard array implementation of some basic sparse matrix format, e.g., compressed sparse row (CSR) or column (CSC) formats. Furthermore, users do not have to use any of the automatic tuning facilities, or may introduce the use of tuned operations gradually over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>oski MatMult</head><p>Sparse matrix-vector multiply (SpMV)</p><formula xml:id="formula_0">y ? ? ? op(A)? x where op(A) ? {A, A T , A H }. oski MatTrisolve Sparse triangular solve (SpTS) x ? ? ? op(A) -1 ? x oski MatTransMatMult y ? ? ? op 2 (A)? x + ? ? y where op 2 (A) ? {A T A, A H A, AA T , AA H } oski MatMultAndMatTransMult Simultaneous computation of y ? ? ? A? x + ? ? y, and z ? ? ? op(A)? w + ? ? z oski MatPowMult Matrix power multiplication Computes y ? ? ? op(A) ? ? x + ? ? y</formula><p>Table <ref type="table">1</ref>. Sparse kernels available in OSKI.</p><p>The key feature of OSKI shown in the example of Listing 1 is that OSKI expects "standard representations" of the user's sparse matrix and dense vectors, to minimize changes to existing applications. Listing 1 uses OSKI to compute one SpMV without any tuning. The input matrix is 3 ? 3 lower triangular with all ones on the diagonal. The matrix is declared statically in lines 6-9 and stored in CSR format using 2 integer arrays, Aptr and Aind, to represent the non-zero pattern and one array of doubles, Aval, to store the non-zero values. This example assumes 0-based indices and does not store the diagonal explicitly, and this overall representation is a common way of implementing CSR in various sparse libraries <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b18">19]</ref>. Line 10 declares and initializes two arrays, x and y, to represent the vectors. Like the matrix, these vector declarations are "standard" implementations that the user could pass directly to, say, the dense BLAS to perform dot products or scalar-times-vector products.</p><p>Listing 1 creates a tunable matrix object from the input matrix by calling oski CreateMat-CSR (line 14). The arguments specify the untuned physical representation (arguments 1-5 in line 16), the semantics of how to interpret this representation (arguments 7-10 in line 18), and a copy mode (argument 6 in line 16) that controls the number of copies of the assembled matrix that may exist at any point in time. The matrix creation routine is the most complex of all of the available OSKI routines, but it supports the specification of a variety of input matrices, as documented fully in the User's Guide, whether the input matrix be symmetric/Hermitian, triangular, use 0-or 1-based indices.</p><p>Similarly, dense vector objects are wrappers, or views, around user arrays (lines 21-22). A vector view encapsulates basic information about an array, such as its length, or such as the stride between consecutive elements of the vector within the array. As with the BLAS, a non-unit stride allows a dense vector to be a submatrix. In addition, an object of type oski vecview t can encapsulate multiple vectors (multivector ) for kernels like sparse matrix-multiple vector multiply (SpMM) or triangular solve with multiple simultaneous right-hand sides; a blocked SpMM can be up to 2.5? faster than a blocked SpMV <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23]</ref>. The multivector object would also store the number of vectors and the memory organization (i.e., row vs. column major). Requiring the user to create a view in both the single-and multiple-vector cases helps unify and simplify some of the kernel argument lists, in addition to the potential performance improvements.</p><p>The argument lists to kernels, such as oski MatMult for SpMV in this example (line 25), follow some of the conventions of the dense BLAS. For example, a user can specify the constant OP TRANS as the second argument to apply A T instead of A, or specify other values for ? and ?. The list of available kernels appears in Table <ref type="table">1</ref>. Beyond SpMV and SpTS, this list includes higher-level kernels designed to exploit memory hierarchies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>}</head><p>That A tunable, x view, and y view are shared with the library implies the user can continue to operate on the data to which these views point as she normally would. For instance, the user can call dense BLAS operations, such as a dot products or scalar-vector multiply, on x and y. Moreover, the user might choose to introduce calls to the OSKI kernels selectively over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Providing explicit tuning hints</head><p>Any information the user can provide a priori is information the library does not need to rediscover, thereby reducing the overhead of tuning. In this case, a user may provide the library with structured hints to describe, for example, the expected workload (i.e., which kernels will be used and how frequently), or whether there is special non-zero structure (e.g., uniformly aligned dense blocks, symmetry). The user then calls a special "tune routine" to choose a new data structure performance-optimized for the specified workload. We refer to this style of OSKI usage as tuning with explicit hints.</p><p>Listing 2 shows how to provide hints. The first hint (lines 5-6) specifies the expected workload will consist of at least a total of 500 SpMV operations on the same matrix. The argument list is identical to the corresponding argument list for the kernel call, oski MatMult, except that there is one additional parameter to specify the expected frequency of SpMV operations. The frequency allows the library to decide whether there are enough SpMV operations to hide the cost of tuning. For optimal tuning, the values of these parameters should match the actual calls as closely as possible.</p><p>The constant SYMBOLIC VEC indicates that we will apply the matrix to a single vector with unit stride. Alternatively, we could use the constant SYMBOLIC MULTIVEC to indicate that we will perform sparse SpMM on at least two vectors. Better still, we could pass an actual instance of a oski vecview t object which has the precise stride and data layout information. Analagous routines exist for each of the other kernels in the system.</p><p>The second hint (line 7) is a structural hint indicating that the matrix non-zero structure may Listing 3. An example of implicit tuning. The actual tuning (i.e., possible change in data structure) occurs at the call to oski Tune-Mat. The OSKI library uses all hint information provided up to this call to tune, i.e., select a new data structure which is likely to improve performance for the specified matrix and workload. This new data structure is only used internally by OSKI at kernel calls, and so does not affect the user's original input matrix data structure. Note that the call to oski TuneMat marks the point during program execution at which tuning (and therefore, its overhead) may occur, thereby exposing the tuning step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Tuning based on implicit profiling</head><p>The library needs a workload to decide when the overhead of tuning can be amortized, but the user cannot always estimate this workload before execution as done in Section 2.2. In OSKI, a user may instead rely on the library to monitor kernel calls to determine the workload dynamically. The user must still call oski TuneMat to tune, but this call optimizes based on a workload inferred from the kernel calls executed so far. Listing 3 provides no workload hints, but calls oski TuneMat periodically (line 13). Internally, the library can monitor the calls to oski MatMult, and at each call to oski TuneMat evaluate whether there seem to be enough SpMV calls to hide the tuning cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Saving and Restoring Tuning Transformations</head><p>To promote transparency in the tuning process, OSKI allows the user to see a precise description, represented by a string, of the transformations that create the tuned data structure. In OSKI 1.0, this string is a program expressed in a procedural, high-level scripting language, OSKI-Lua (derived from the Lua language <ref type="bibr" target="#b23">[24]</ref>). The user may subsequently "execute" this program on the same or similar input matrix, thereby providing a way to save and restore tuning transformations across application runs, a la FFTW's wisdom mechanism <ref type="bibr" target="#b24">[25]</ref>. Moreover, this mechanism allows an advanced user to specify her own sequence of optimizing transformations, and allows OSKI developers to extend OSKI to include new techniques.</p><p>Listing 4 contains a code fragment which reads a transformation string (OSKI-Lua program) from a file, and applies it to a matrix using OSKI's oski ApplyMatTransforms. This call The syntax of OSKI-Lua is based on the Lua scripting language <ref type="bibr" target="#b23">[24]</ref>. The following example computes a structural splitting,</p><formula xml:id="formula_1">A = A 1 + A 2 + A 3 , where A 1 is stored in 4 ? 2 UBCSR, A 2 is stored in 2 ? 2 UBCSR,</formula><p>and A 3 is stored in CSR(comments preceeded by #). This example uses VBRas an intermediate format for determining how to split. (Structural splitting in this style yields speedups of up to 1.8? over a blocked but not split implementation <ref type="bibr" target="#b25">[26]</ref>.)</p><formula xml:id="formula_2"># Let A = A 1 + A 2 + A 3 , where A 1 is in 4 ? 2 UBCSR, # A 2 is in 2 ? 2 UBCSR, and A 3 is in CSR T = VBR(InputMat); # First, split A = A 1 + A leftover ,</formula><p>When oski ApplyMatTransforms executes, it interprets the program to carry out the transformation. The last line executed by every OSKI-Lua program returns the new data structure-here, the union of the split components A 1 , A 2 , and A 3 , represented by the symbolic summation in line 10. Garbage collection of temporaries is performed automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Other Features</head><p>OSKI provides functionality beyond the core kernels and tuning facilities:</p><p>? Support for various scalar precisions: Like the BLAS, non-zero values may be real or complex, single-or double-precision. In addition, the integer indices associated with the sparse matrix may be C int or long. ? Changing/retrieving matrix entries: As long as the pattern remains fixed, the user may change the values of any structural non-zero entries using OSKI's get/set value routines. ? Explicit representation of permutations: During tuning, the library may decide to permute the rows and columns of the matrix to improve locality, but to maintain correctness it must permute input/output vectors at every kernel call. OSKI allows the user to detect, extract, and apply these permutations herself if her algorithm can permute less frequently. ? Two error handling styles: Users can check the return value of any OSKI call for errors.</p><p>In addition, the user may supply her own error handler for logging or recovery purposes.</p><p>These features are described in complete detail in the OSKI 1.0 User's Guide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work: Approaches that Complement Libraries</head><p>The Sparse BLAS Standard <ref type="bibr" target="#b12">[13]</ref> inspired the OSKI design. The main differences are (i) we do not specify primitives for matrix construction, and instead assume that the user can provide an assembled matrix in one of a few formats, and (ii) we include explicit support for tuning.</p><p>A number of approaches complement the library approach. One is to implement a library using a language with generic programming constructs such as templates in C++ <ref type="bibr" target="#b26">[27]</ref>. Both Blitz++ <ref type="bibr" target="#b27">[28]</ref> and the Matrix Template Library (MTL) <ref type="bibr" target="#b28">[29]</ref> have adopted this approach to building generic libraries in C++ that mimic dense BLAS functionality. Templates faciliate the generation of large numbers of routines from a compact representation, and flexibly handles issues of producing libraries that can handle different precisions. Sophisticated use of templates (template metaprogramming) also allows some optimization, such as unrolling and some forms of loop fusion <ref type="bibr" target="#b27">[28]</ref>. However, this approach does not address run-time tuning.</p><p>Compiler-based sparse code generation, via restructuring compilers, extends the generic programming idea (Bik <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref>, Stodghill, et al <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, and Pugh and Shpeisman <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>). These are clean, general approaches to code generation. The user expresses separately both the kernels (as dense code with random access to matrix elements) and a specification of the sparse data structure; a restructuring compiler combines the two descriptions to produce a sparse implementation. Since any kernel can in principle be expressed, this overcomes a library approach in which all possible kernels must be pre-defined. We view this technology as complementary to the overall library approach; while sparse compilers could be used to provide the underlying implementations of sparse primitives, they do not explicitly make use of matrix structural information available, in general, only at run-time.</p><p>A third approach is to extend an existing library or system. There are a number of application-level libraries (e.g., PETSc <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, among others <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40]</ref>) and high-level application tools (e.g., MATLAB <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, Octave <ref type="bibr" target="#b40">[41]</ref>, approaches that apply compiler analyses and transformations to MATLAB code <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>) that provide high-level sparse kernel support. Integration with these systems, which have large user bases, allows complete hiding of data structure details and the tuning process from the user. The goal of OSKI is to provide building blocks in the spirit of the BLAS with the steps and costs of tuning exposed. It should be possible to integrate the OSKI library into an existing system as well, as has been done successfully with the integration of ATLAS and FFTW tuning systems into MATLAB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>OSKI is designed to provide a migration path for existing solver libraries and applications to use high-performance implementations of sparse matrix kernels. An OSKI user whose sparse matrix is already available pre-assembled in standard CSRor CSCarray representations can introduce calls to OSKI's kernels selectively and gradually over time. Tuning is automatic, but only occurs when the user explicitly requests it, thus allowing the user to decide when it is most appropriate to tune in her application.</p><p>The OSKI 1.0 implementation <ref type="bibr" target="#b16">[17]</ref> is a uniprocessor library that targets cache-based superscalar machines. We are actively pursuing shared and distributed memory versions of OSKI, as well as tuning specific to alternative architectures such as vector processor-based machines. OSKI-based applications will be performance-portable on such platforms.</p><p>In addition, OSKI has been released as open-source. The implementation is modular, so that new matrix formats and tuning heuristics can be added to an existing OSKI installation without recompiling the core library, or even the application on systems with shared library support. We are making our own sparse kernel tuning research <ref type="bibr" target="#b43">[44,</ref><ref type="bibr">Sec. 4.3]</ref> available as modules in OSKI.</p><p>To reach still larger user communities, we are also implementing an OSKI matrix type for PETSc. The OSKI 1.0 User's Guide outlines how we envision OSKI being implemented into other libraries, including the Sparse BLAS <ref type="bibr" target="#b12">[13]</ref> and MATLAB*P <ref type="bibr" target="#b44">[45]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Listing 1 .</head><label>1</label><figDesc>A usage example without tuning. // This example computes y ? ? ? A? x + ? ? y, is a sparse lower triangular matrix with a unit diagonal, and x, y are dense vectors. // User's initial matrix and data #define DIM 3 // matrix dimension #define NNZ STORED // no. of stored non-zeros int Aptr[DIM] = {0, 0, 1, 2}, Aind[NNZ STORED] = {0, 0}; double Aval[NNZ STORED] = {-2, 0.5}; double x[DIM] = {.25, .45, .65}, y[DIM] = {1, 1, 1};</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Listing 2 .</head><label>2</label><figDesc>An example of basic explicit tuning. // Create a tunable sparse matrix object. A tunable = oski CreateMatCSR (. . .); // Tell the library we expect to perform 500 SpMV operations with ? = 1, ? = 1. oski SetHintMatMult (A tunable, OP NORMAL, 1.0, SYMBOLIC VEC, 1.0, SYMBOLIC VEC, 500); oski SetHint (A tunable, HINT SINGLE BLOCKSIZE, 6, 6); oski TuneMat (A tunable); // . . . x view = oski CreateVecView (. . .); y view = oski CreateVecView (. . .); for ( i = 0; i &lt; 100; i++) { // . . . for (k = 0; k &lt; 5; k++) { // . . . oski MatMult (A tunable, OP NORMAL, 1.0, x view, 1.0, y view);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Listing 4 .</head><label>4</label><figDesc>An example of applying transformations. FILE * fp saved xforms = fopen ("./my_xform.txt", "rt"); // file containing transformation to apply oski matrix t A tunable = oski CreateMat CSR (. . .); char xforms[MAXBUFSIZE]; // transform to apply fread (xforms, ..., fp saved xforms); // read transform from file oski MatMult (A tunable, . . .); // untuned SpMV oski ApplyMatTransforms (A tunable, xforms); // change data structure oski MatMult (A tunable, . . .); // tuned SpMV is equivalent to calling oski TuneMat, except that instead of allowing the library to decide what data structure to use, we are specifying it explicitly. (OSKI has an analogous routine, oski GetMatTransforms, to retrieve the last transformation applied to a matrix.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>where A leftover is in CSRformat A1, A leftover = T.extract blocks(4, 2); # Next, split A leftover = A 2 + A 3 T = VBR(A leftover); A2, A3 = T.extract blocks(2, 2); return A1 + A2 + A3;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>oski matrix t A tunable = oski CreateMatCSR</head><label></label><figDesc></figDesc><table><row><cell>double alpha = -1, beta = 1;</cell><cell></cell></row><row><cell cols="2">// Create a tunable sparse matrix object.</cell></row><row><cell cols="2">(Aptr, Aind, Aval, DIM, DIM, // CSR arrays</cell></row><row><cell>SHARE INPUTMAT,</cell><cell>// "copy mode"</cell></row><row><cell cols="2">// remaining args specify how to interpret non-zero pattern</cell></row><row><cell cols="2">3, INDEX ZERO BASED, MAT TRI LOWER, MAT UNIT DIAG IMPLICIT);</cell></row><row><cell cols="2">// Create wrappers around the dense vectors.</cell></row><row><cell cols="2">oski vecview t x view = oski CreateVecView (x, DIM, STRIDE UNIT);</cell></row><row><cell cols="2">oski vecview t y view = oski CreateVecView (y, DIM, STRIDE UNIT);</cell></row><row><cell cols="2">// Perform matrix vector multiply, y ? ? ? A? x + ? ? y.</cell></row><row><cell cols="2">oski MatMult (A tunable, OP NORMAL, alpha,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>x view, beta, y view); // Clean-up interface objects oski DestroyMat (A tunable); oski DestroyVecView (x view); oski DestroyVecView (y view);</head><label></label><figDesc></figDesc><table><row><cell>// Print result, y. Should be "[ .75 ; 1.05 ; .225 ]"</cell></row><row><cell>printf ("Answer: y = [ %f ; %f ; %f ]\n", y[0], y[1], y[2]);</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Fortran interfaces are under development.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Automatic performance tuning of sparse matrix kernels</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-12">December 2003</date>
			<pubPlace>Berkeley, CA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimizing matrix multiply using PHiPAC: a portable, high-performance, ANSI C coding methodology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Supercomputing</title>
		<meeting>the International Conference on Supercomputing<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>ACM SIGARC</publisher>
			<date type="published" when="1997-07">July 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated empirical optimizations of software and the ATLAS project</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Clint</forename><surname>Whaley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Petitet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="25" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sparsity: Optimization framework for sparse matrix kernels</title>
		<author>
			<persName><forename type="first">Eun-Jin</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="158" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance optimizations and bounds for sparse matrix-vector multiply</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoaib</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing</title>
		<meeting>Supercomputing<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-11">November 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Performance optimizations and bounds for sparse symmetric matrix-multiple vector multiply</title>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijue</forename><surname>Michael Delorimier</surname></persName>
		</author>
		<author>
			<persName><surname>Zhong</surname></persName>
		</author>
		<idno>UCB/CSD-03-1297</idno>
		<imprint>
			<date type="published" when="2003-11">November 2003</date>
			<pubPlace>Berkeley, CA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">When cache blocking sparse matrix vector multiply works and why</title>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PARA&apos;04 Workshop on the State-of-the-art in Scientific Computing</title>
		<meeting>the PARA&apos;04 Workshop on the State-of-the-art in Scientific Computing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-06">June 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Memory hierarchy optimizations and bounds for sparse A T Ax</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Attila</forename><surname>Gyulassy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICCS Workshop on Parallel Linear Algebra</title>
		<meeting>the ICCS Workshop on Parallel Linear Algebra<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic performance tuning and analysis of sparse triangular solve</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shoaib</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS 2002: Workshop on Performance Optimization via High-Level Languages and Libraries</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Effects of block size on the block Lanczos algorithm</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
	<note>Senior thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Berkeley Benchmarking and OPtimization (BeBOP)</title>
		<imprint/>
	</monogr>
	<note>Project, 2004. bebop.cs.berkeley.edu</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An updated set of basic linear algebra subprograms (BLAS)</title>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">L</forename><surname>Blackford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><forename type="middle">S</forename><surname>Duff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Hammarling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Heroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lumsdaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Petitet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roldan</forename><surname>Pozo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karin</forename><surname>Remington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Clint</forename><surname>Whaley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An overview of the sparse basic linear algebra subprograms: The new standard from the BLAS technical forum</title>
		<author>
			<persName><forename type="first">Iain</forename><forename type="middle">S</forename><surname>Duff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Heroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Pozo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="267" />
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithm 818: A reference model implementation of the sparse BLAS in Fortran 95</title>
		<author>
			<persName><forename type="first">Iain</forename><forename type="middle">S</forename><surname>Duff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>V?mel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="283" />
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">SPARSKIT: A basic toolkit for sparse matrix computations</title>
		<author>
			<persName><forename type="first">Yousef</forename><surname>Saad</surname></persName>
		</author>
		<ptr target="www.cs.umn.edu/Research/arpa/SPARSKIT/sparskit.html" />
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">PSBLAS: A library for parallel linear algebra computation on sparse matrices</title>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Filippone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Colajanni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="550" />
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">OSKI: An interface for a self-optimizing library of sparse matrix kernels</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>bebop.cs.berkeley.edu/oski</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient management of parallelism in object oriented numerical software libraries</title>
		<author>
			<persName><forename type="first">Satish</forename><surname>Balay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">D</forename><surname>Gropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lois</forename><forename type="middle">Curfman</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern Software Tools in Scientific Computing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Arge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruaset</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Langtangen</surname></persName>
		</editor>
		<imprint>
			<publisher>Birkhauser Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="163" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">PETSc User&apos;s Manual</title>
		<author>
			<persName><forename type="first">Satish</forename><surname>Balay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kris</forename><surname>Buschelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">D</forename><surname>Gropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Knepley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lois</forename><forename type="middle">Curfman</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
		<idno>ANL-95/11 -Revision 2.1.5</idno>
		<ptr target="www.mcs.anl.gov/petsc" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Argonne National Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName><forename type="middle">The</forename><surname>Inc</surname></persName>
		</author>
		<author>
			<persName><surname>Mathworks</surname></persName>
		</author>
		<author>
			<persName><surname>Matlab</surname></persName>
		</author>
		<ptr target="www.mathworks.com" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sparse matrices in MATLAB: Design and implementation</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cleve</forename><surname>Moler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="333" to="356" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Remington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pozo</surname></persName>
		</author>
		<ptr target="gams.nist.gov/spblas" />
		<title level="m">NIST Sparse BLAS: User&apos;s Guide</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Performance models for evaluation and automatic tuning of symmetric sparse matrix-vector multiply</title>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel Processing</title>
		<meeting>the International Conference on Parallel Processing<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Lua 5.0 Reference Manual</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Ierusalimschy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Henrique De Figeiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waldemar</forename><surname>Celes</surname></persName>
		</author>
		<idno>MCC-14/03</idno>
		<ptr target="www.lua.org" />
		<imprint>
			<date type="published" when="2003-04">April 2003</date>
			<publisher>PUC-Rio</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">FFTW: An adaptive software architecture for the FFT</title>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech, and Signal Processing<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Fast sparse matrix-vector multiplication by exploiting variable block structure</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyun-Jin</forename><surname>Moon</surname></persName>
		</author>
		<idno>UCRL-TR-213454</idno>
		<imprint>
			<date type="published" when="2005-07">July 2005</date>
			<pubPlace>Livermore, CA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Applied Scientific Computing, Lawrence Livermore National Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Algorithm-oriented generic libraries. Software: Practice and Experience</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Musser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Stepanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Arrays in Blitz++</title>
		<author>
			<persName><forename type="first">Todd</forename><surname>Veldhuizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISCOPE, volume 1505 of LNCS</title>
		<meeting>ISCOPE, volume 1505 of LNCS</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A rational approach to portable high performance: the Basic Linear Algebra Instruction Set (BLAIS) and the Fixed Algorithm Size Template (fast) library</title>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">G</forename><surname>Siek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Lumsdaine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECOOP</title>
		<meeting>ECOOP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Aart Johannes Casimir Bik. Compiler Support for Sparse Matrix Codes</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Leiden University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The automatic generation of sparse primitives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Birkhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harry</forename><forename type="middle">A G</forename><surname>Knijnenburg</surname></persName>
		</author>
		<author>
			<persName><surname>Wijshoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOMS</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="225" />
			<date type="published" when="1998-07">July 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic nonzero structure analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Aart</surname></persName>
		</author>
		<author>
			<persName><surname>Bik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Harry</surname></persName>
		</author>
		<author>
			<persName><surname>Wijshoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1576" to="1587" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A Relational Approach to the Automatic Generation of Sequential Sparse Matrix Codes</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Stodghill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-08">August 1997</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A framework for sparse matrix code synthesis from high-level specifications</title>
		<author>
			<persName><forename type="first">Nawaaz</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Mateev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Stodghill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing 2000</title>
		<meeting>Supercomputing 2000<address><addrLine>Dallas, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-11">November 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Next-generation generic programming and its application to sparse matrix computations</title>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Mateev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Stodghill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Kotlyar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Supercomputing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The Bernoulli Generic Matrix Library</title>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Mateev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Stodghill</surname></persName>
		</author>
		<idno>TR-2000-1808</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generation of efficient code for sparse matrix computations</title>
		<author>
			<persName><forename type="first">William</forename><surname>Pugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Shpeisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on Languages and Compilers for Parallel Computing</title>
		<meeting>the 11th Workshop on Languages and Compilers for Parallel Computing</meeting>
		<imprint>
			<date type="published" when="1998-08">August 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Aspect-oriented programming of sparse matrix code</title>
		<author>
			<persName><forename type="first">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Loingtier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kiczales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mendhekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Shpeisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Scientific Computing in Object-Oriented Parallel Environments</title>
		<meeting>the International Scientific Computing in Object-Oriented Parallel Environments<address><addrLine>Marina del Rey, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-12">December 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The design of a user interface for a sparse matrix package</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">W H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="162" />
			<date type="published" when="1979-06">June 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">JMP: A sparse matrix library in Java</title>
		<author>
			<persName><forename type="first">Bj?rn-Ove</forename><surname>Heimsund</surname></persName>
		</author>
		<ptr target="http://www.mi.uib.no/?bjornoh/jmp" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">W</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><surname>Eaton</surname></persName>
		</author>
		<author>
			<persName><surname>Octave</surname></persName>
		</author>
		<ptr target="www.octave.org" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">MaJIC: Compiling MATLAB for speed and responsiveness</title>
		<author>
			<persName><forename type="first">George</forename><surname>Alm?si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Padua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation</title>
		<meeting>the ACM SIGPLAN Conference on Programming Language Design and Implementation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A case for source-level transformations in MATLAB</title>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Pingali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Domain-Specific Languages</title>
		<meeting>the 2nd Conference on Domain-Specific Languages<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-10">October 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Self adapting linear algebra algorithms and software</title>
		<author>
			<persName><forename type="first">James</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Eijkhout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erika</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Petitet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Clint</forename><surname>Whaley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Yelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE: Special Issue on Program Generation, Optimization, and Adaptation</title>
		<meeting>the IEEE: Special Issue on Program Generation, Optimization, and Adaptation</meeting>
		<imprint>
			<date type="published" when="2005-02">February 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sparse matrices in Matlab *P: Design and implementation</title>
		<author>
			<persName><forename type="first">Viral</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on High-Performance Computing</title>
		<meeting>the International Conference on High-Performance Computing<address><addrLine>Bangalore, India</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3296</biblScope>
			<biblScope unit="page" from="144" to="155" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
