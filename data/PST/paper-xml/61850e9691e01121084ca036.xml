<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Benedek</forename><surname>Rozemberczki</surname></persName>
							<email>benedek.rozemberczki@astrazeneca.com</email>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Scherer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yixuan</forename><surname>He</surname></persName>
							<email>yixuan.he@stats.ox.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Panagopoulos</surname></persName>
							<email>george.panagopoulos@polytechnique.edu</email>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Riedel</surname></persName>
							<email>alexander.riedel@eah-jena.de</email>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><surname>Astefanoaei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oliver</forename><surname>Kiss</surname></persName>
							<email>kiss_oliver@phd.ceu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ferenc</forename><surname>Beres</surname></persName>
							<email>beres@sztaki.hu</email>
						</author>
						<author>
							<persName><forename type="first">Guzmán</forename><surname>López</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Collignon</surname></persName>
							<email>nicolas@pedalme.co.uk</email>
						</author>
						<author>
							<persName><forename type="first">Rik</forename><surname>Sarkar</surname></persName>
							<email>rsarkar@inf.ed.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">AstraZeneca United Kingdom</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Cambridge United Kingdom</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Oxford United Kingdom</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Ernst-Abbe University for Applied Sciences</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">IT University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Central European University</orgName>
								<address>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">ELKH SZTAKI</orgName>
								<address>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<address>
									<settlement>Tryolabs</settlement>
									<country key="UY">Uruguay</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">The University of Edinburgh United Kingdom</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3459637.3482014</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>neural networks</term>
					<term>deep learning</term>
					<term>dynamic graph</term>
					<term>spatiotemporal data processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present PyTorch Geometric Temporal, a deep learning framework combining state-of-the-art machine learning algorithms for neural spatiotemporal signal processing. The main goal of the library is to make temporal geometric deep learning available for researchers and machine learning practitioners in a unified easyto-use framework. PyTorch Geometric Temporal was created with foundations on existing libraries in the PyTorch eco-system, streamlined neural network layer definitions, temporal snapshot generators for batching, and integrated benchmark datasets. These features are illustrated with a tutorial-like case study. Experiments demonstrate the predictive performance of the models implemented in the library on real-world problems such as epidemiological forecasting, ride-hail demand prediction, and web traffic management. Our sensitivity analysis of runtime shows that the framework can potentially operate on web-scale datasets with rich temporal features and spatial structure. * The project started when the author was a student of the Center for Doctoral Training in Data Science at The University of Edinburgh.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep learning on static graph-structured data has seen unprecedented success in various business and scientific application domains. Neural network layers which operate on graph data can serve as building blocks of document labeling, fraud detection, traffic forecasting, and cheminformatics systems <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b62">63]</ref>. This emergence and the widespread adaptation of geometric deep learning was made possible by open-source machine learning libraries. The high quality, breadth, user-oriented nature, and availability of specialized deep learning libraries <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b67">68]</ref> were all contributing factors to the practical success and large-scale deployment of graph machine learning systems. At the same time, the existing geometric deep learning frameworks operate on graphs that have a fixed topology and it is also assumed that the node features and labels are static. Besides limiting assumptions about the input data, these off-the-shelf libraries are not designed to operate on spatiotemporal data.</p><p>Present work. We propose PyTorch Geometric Temporal, an open-source Python library for spatiotemporal machine learning. We designed PyTorch Geometric Temporal with a simple and consistent API inspired by the software architecture of existing widely used geometric deep learning libraries from the PyTorch ecosystem <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b39">40]</ref>. Our framework was built by applying simple design principles consistently. The framework reuses existing neural network layers in a modular manner, in which models have a limited number of public methods and hyperparameters can be inspected. Spatiotemporal signal iterators ingest data memory efficiently in widely used scientific computing formats and return those in a PyTorch compatible format. The design principles in combination with the test coverage, documentation, practical tutorials, continuous integration, package indexing, and frequent releases make the framework an end-user-friendly spatiotemporal machine learning system.</p><p>The experimental evaluation of the framework entails nodelevel regression tasks on datasets released exclusively with the framework. Specifically, we compare the predictive performance of spatiotemporal graph neural networks on epidemiological forecasting, demand planning, web traffic management, and social media interaction prediction tasks. Synthetic experiments show that with the right batching strategy PyTorch Geometric Temporal is highly scalable and benefits from GPU accelerated computing.</p><p>Our contributions. The main contributions of our work can be summarized as:</p><p>• We publicly release PyTorch Geometric Temporal, the first deep learning library for parametric spatiotemporal machine learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• We provide data loaders and iterators with PyTorch Geometric</head><p>Temporal which can handle spatiotemporal datasets. • We release new spatiotemporal benchmark datasets from the renewable energy production, epidemiological reporting, goods delivery, and web traffic forecasting domains. • We evaluate the spatiotemporal forecasting capabilities of the neural and parametric machine learning models available in PyTorch Geometric Temporal on real-world datasets.</p><p>The remainder of the paper has the following structure. In Section 2 we overview important preliminaries and the related work about temporal and geometric deep learning and the characteristics of related open-source machine learning software. The main design principles of PyTorch Geometric Temporal are discussed in Section 3 with a practical example. We demonstrate the forecasting capabilities of the framework in Section 4 where we also evaluate the scalability of the library on various commodity hardware. We conclude in Section 5 where we summarize the results. The source code of PyTorch Geometric Temporal is publicly available at https://github.com/benedekrozemberczki/pytorch_geometric_ temporal; the Python package can be installed via the Python Package Index. Detailed documentation is accessible at https://pytorchgeometric-temporal.readthedocs.io/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES AND RELATED WORK</head><p>In order to position our contribution and highlight its significance, we introduce some important concepts about spatiotemporal data and discuss related literature about geometric deep learning and machine learning software.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal Graph Sequences</head><p>Our framework considers specific input data types on which the spatiotemporal machine learning models operate. Input data types can differ in terms of the dynamics of the graph and that of the modelled vertex attributes. We take a discrete temporal snapshot view of this data representation problem <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> and our work considers three spatiotemporal data types which can be described by the subplots of Figure <ref type="figure" target="#fig_1">1</ref> and the following formal definitions: Definition 1. Dynamic graph with temporal signal A dynamic graph with a temporal signal is the ordered set of graph and node feature matrix tuples D = {(G 1 , X 1 ), . . . , (G 𝑇 , X 𝑇 )} where the vertex sets satisfy that 𝑉 𝑡 = 𝑉 , ∀𝑡 ∈ {1, . . . ,𝑇 } and the node feature matrices that X 𝑡 ∈ R |𝑉 |×𝑑 , ∀𝑡 ∈ {1, . . . ,𝑇 } . Definition 2. Dynamic graph with static signal. A dynamic graph with a static signal is the ordered set of graph and node feature matrix tuples D = {(G 1 , X), . . . , (G 𝑇 , X)} where vertex sets satisfy 𝑉 𝑡 = 𝑉 , ∀𝑡 ∈ {1, . . . ,𝑇 } and the node feature matrix that X ∈ R |𝑉 |×𝑑 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resource Paper Track</head><p>CIKM '21, November 1-5, 2021, Virtual Event, Australia Definition 3. Static graph with temporal signal. A static graph with a temporal signal is the ordered set of graph and node feature matrix tuples D = {(G, X 1 ), . . . , (G, X 𝑇 )} where the node feature matrix satisfies that X 𝑡 ∈ R |𝑉 |×𝑑 , ∀𝑡 ∈ {1, . . . ,𝑇 } .</p><p>Representing spatiotemporal data based on these theoretical concepts allows us the creation of memory-efficient data structures which conceptualize these definitions in practice well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Learning with Time and Geometry</head><p>Our work provides deep learning models that operate on data that has both temporal and spatial aspects. These techniques are natural recombinations of existing neural network layers that operate on sequences and static graph-structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Temporal Deep Learning.</head><p>A large family of temporal deep learning models such as the LSTM <ref type="bibr" target="#b23">[24]</ref> and GRU <ref type="bibr" target="#b11">[12]</ref> generates in-memory representations of data points which are iteratively updated as it learns by new snapshots. Another family of deep learning models uses the attention mechanism <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b58">59]</ref> to learn representations of the data points which are adaptively recontextualized based on the temporal history. These types of models serve as templates for the temporal block of spatiotemporal deep learning models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Static Graph Representation</head><p>Learning. Learning representations of vertices, edges, and whole graphs with graph neural networks in a supervised or unsupervised way can be described by the message passing formalism <ref type="bibr" target="#b16">[17]</ref>. In this conceptual framework using the node and edge attributes in a graph as parametric function generates compressed representations (messages) which are propagated between the nodes based on a message-passing rule and aggregated to form new representations. Most of the existing graph neural network architectures such as GCN <ref type="bibr" target="#b29">[30]</ref>, GGCN <ref type="bibr" target="#b32">[33]</ref>, Cheby-Conv <ref type="bibr" target="#b13">[14]</ref>, and RGCN <ref type="bibr" target="#b49">[50]</ref> fit perfectly into this general description of graph neural networks. Models are differentiated by assumptions about the input graph (e.g. node heterogeneity, multiplexity, presence of edge attributes), the message compression function used, the propagation scheme, and the message aggregation function applied to the received messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Spatiotemporal Deep Learning.</head><p>A spatiotemporal deep learning model fuses the basic conceptual ideas of temporal deep learning techniques and graph representation learning. Operating on a temporal graph sequence, these models perform message-passing at each time point with a graph neural network block, and the new temporal information is incorporated by a temporal deep learning block. This design allows for sharing salient temporal and spatial autocorrelation information across the spatial units. The temporal and spatial layers which are fused together in a single parametric machine learning model are trained together jointly by exploiting the fact that the fused models are end-to-end differentiable. In Table <ref type="table" target="#tab_0">1</ref> we summarized the spatiotemporal deep learning models implemented in the framework which we categorized based on the temporal and graph neural network layer blocks, the order of spatial proximity, and heterogeneity of the edge set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Representation Learning Software</head><p>The current graph representation learning software ecosystem which allows academic research and industrial deployment extends open-source auto-differentiation libraries such as TensorFlow <ref type="bibr" target="#b0">[1]</ref>, PyTorch <ref type="bibr" target="#b40">[41]</ref>, MxNet <ref type="bibr" target="#b10">[11]</ref> and JAX <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>. Our work does the same as we build on the PyTorch Geometric ecosystem. We summarize the characteristics of these libraries in Table <ref type="table" target="#tab_1">2</ref> which enables for comparing frameworks based on the backend, presence of supervised training functionalities, presence of temporal models, and GPU support. Our proposed framework is the only one to date which allows the supervised training of temporal graph representation learning models with graphics card-based acceleration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Spatiotemporal Data Analytics Software</head><p>The open-source ecosystem for spatiotemporal data processing consists of specialized database systems, basic analytical tools, and advanced machine learning libraries. We summarized the characteristics of the most popular libraries in Table <ref type="table">3</ref> with respect to the year of release, the purpose of the framework, source code language, and GPU support. First, it is evident that most spatiotemporal data processing tools are fairly new and there is much space for contributions in each subcategory. Second, the database systems are written in highperformance languages while the analytics and machine learning oriented tools have a pure Python/R design or a wrapper written in these languages. Finally, the use of GPU acceleration is not </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Library</head><p>Backend Supervised Temporal GPU PT Geometric <ref type="bibr" target="#b14">[15]</ref> PT</p><formula xml:id="formula_0">✔ ✘ ✔ Geometric2DR [49] PT ✘ ✘ ✔ CogDL [9] PT ✔ ✘ ✔ Spektral [21] TF ✔ ✘ ✔ TF Geometric [27] TF ✔ ✘ ✔ StellarGraph [13] TF ✔ ✘ ✔ DGL [68] TF/PT/MX ✔ ✘ ✔ DIG [34] PT ✔ ✘ ✔ Jraph [18] JAX ✔ ✘ ✔ Graph-Learn [62] Custom ✔ ✘ ✔ GEM [19] TF ✘ ✘ ✔ DynamicGEM [20] TF ✘ ✔ ✔ OpenNE [57] Custom ✘ ✘ ✘ Karate Club [46] Custom ✘ ✘ ✘ Our Work PT ✔ ✔ ✔</formula><p>widespread which alludes to the fact that current spatiotemporal data processing tools might have a scalability issue. Our proposed framework PyTorch Geometric Temporal is the first fully opensource GPU accelerated spatiotemporal machine learning library for graph-structured data.</p><p>Table <ref type="table">3</ref>: A multi-aspect comparison of open-source spatiotemporal database systems, data analytics libraries and machine learning frameworks.</p><p>Library Year Purpose Language GPU GeoWave <ref type="bibr" target="#b59">[60]</ref> 2016 Database Java ✘ StacSpec <ref type="bibr" target="#b22">[23]</ref> 2017 Database Javascript ✘ MobilityDB <ref type="bibr" target="#b69">[70]</ref> 2019 Database C ✘ PyStac <ref type="bibr" target="#b43">[44]</ref> 2020 Database Python ✘ StaRs <ref type="bibr" target="#b41">[42]</ref> 2017 Analytics R ✘ CuSpatial <ref type="bibr" target="#b55">[56]</ref> 2019 Analytics Python ✔ PySAL <ref type="bibr" target="#b42">[43]</ref> 2017 Machine Learning Python ✘ STDMTMB <ref type="bibr" target="#b1">[2]</ref> 2018 Machine Learning R ✘ Our work 2021 Machine Learning Python ✔</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE FRAMEWORK DESIGN</head><p>Our primary goal is to give a general theoretical overview of the framework, discuss the framework design choices, give a detailed practical example and highlight our strategy for the long-term viability and maintenance of the project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural Network Layer Design</head><p>The spatiotemporal neural network layers are implemented as classes in the framework. Each of the classes has a similar architecture driven by a few simple design principles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Non-proliferation of classes.</head><p>The framework reuses the existing high-level neural network layer classes as building blocks from the PyTorch and PyTorch Geometric ecosystems. The goal of the library is not to replace the existing frameworks. This design strategy makes sure that the number of auxiliary classes in the framework is kept low and that the framework interfaces well with the rest of the ecosystem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Hyperparameter inspection and type hinting.</head><p>The neural network layers do not have default hyperparameter settings as some of these have to be set in a dataset-dependent manner. In order to help with this, the layer hyperparameters are stored as public class attributes and are available for inspection. Moreover, the constructors of the neural network layers use type hinting which helps the end-users to set the hyperparameters.</p><p>3.1.3 Limited number of public methods. The spatiotemporal neural network layers in our framework have a limited number of public methods for simplicity. For example, the auxiliary layer initialization methods and other internal model mechanics are implemented as private methods. All of the layers provide a forward method and those which explicitly use the message-passing scheme in PyTorch Geometric provide a public message method.</p><p>3.1.4 Auxiliary layers. The auxiliary neural network layers which are not part of the PyTorch Geometric ecosystem such as diffusion convolutional graph neural networks <ref type="bibr" target="#b31">[32]</ref> are implemented as standalone neural network layers in the framework. These layers are available for the design of novel neural network architectures as individual components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Structures</head><p>The design of PyTorch Geometric Temporal required the introduction of custom data structures that can efficiently store the datasets and provide temporally ordered snapshots for batching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Spatiotemporal Signal Iterators.</head><p>Based on the categorization of spatiotemporal signals discussed in Section 2 we implemented three types of Spatiotemporal Signal Iterators. These iterators store spatiotemporal datasets in memory efficiently without redundancy. For example, a Static Graph Temporal Signal iterator will not store the edge indices and weights for each time period in order to save memory. By iterating over a Spatiotemporal Signal Iterator at each step a graph snapshot is returned which describes the graph of interest at a given point in time. Graph snapshots are returned in temporal order by the iterators. The Spatiotemporal Signal Iterators can be indexed directly to access a specific graph snapshot -a design choice that facilitates the use of advanced temporal batching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Graph</head><p>Snapshots. The time period specific snapshots which consist of labels, features, edge indices and weights are stored as NumPy arrays <ref type="bibr" target="#b57">[58]</ref> in memory, but returned as a PyTorch Geometric Data object instance <ref type="bibr" target="#b14">[15]</ref> by the Spatiotemporal Signal Iterators when these are iterated on. This design choice hedges against the proliferation of classes and exploits the existing and widely used compact data structures from the PyTorch ecosystem <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Train-Validation-Test Splitting.</head><p>As part of the library we provide a temporal train-test splitting function that creates train and test snapshot iterators from a Spatiotemporal Signal Iterator given a test dataset ratio. This parameter of the splitting function decides the fraction of data that is separated from the end of the spatiotemporal graph snapshot sequence for testing. The returned iterators have the same type as the input iterator. Importantly, this splitting does not influence the applicability of widely used semi-supervised model training strategies such as node masking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Integrated Benchmark Dataset</head><p>Loaders. We provided easy-touse practical data loader classes for widely used existing <ref type="bibr" target="#b37">[38]</ref> and the newly released benchmark datasets. These loaders return Spatiotemporal Signal Iterators which can be used for training existing and custom-designed spatiotemporal neural network architectures to solve supervised machine learning problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Design in Practice Case Study: Cumulative Model Training on CPU</head><p>In the following, we overview a simple end-to-end machine learning pipeline designed with PyTorch Geometric Temporal. These code snippets solve a practical epidemiological forecasting problempredicting the weekly number of chickenpox cases in Hungary <ref type="bibr" target="#b46">[47]</ref>.</p><p>The pipeline consists of data preparation, model definition, training, and evaluation phases.</p><p>1 from torch_geometric_temporal import ChickenpoxDatasetLoader 2 from torch_geometric_temporal import temporal_signal_split Listings 1: Loading a default benchmark dataset and creating a temporal split with PyTorch Geometric Temporal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Dataset Loading and Splitting.</head><p>In Listings 1 as a first step we import the Hungarian chickenpox cases benchmark dataset loader and the temporal train test splitter function (lines 1-2). We define the dataset loader (line 4) and use the get_dataset() class method to return a temporal signal iterator (line 5). Finally, we create a train-test split of the spatiotemporal dataset by using the splitting function and retain 10% of the temporal snapshots for model performance evaluation (lines 7-8).  <ref type="bibr" target="#b31">[32]</ref> and a fully connected layer with a single neuron (lines 8-9).</p><p>In the forward pass method of the neural network, the model uses the vertex features, edges, and optional edge weights (line 11). The initial recurrent graph convolution-based aggregation (line 12) is followed by a rectified linear unit activation function <ref type="bibr" target="#b36">[37]</ref> and dropout <ref type="bibr" target="#b52">[53]</ref> for regularization (lines <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. Using the fully connected layer the model outputs a single score for each spatial unit (lines 15-16). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Model Training.</head><p>Using the dataset split and the model definition we can turn our attention to training a regressor. In Listings 3 we create a model instance (line 1), transfer the model parameters (line 3) to the Adam optimizer <ref type="bibr" target="#b28">[29]</ref> which uses a learning rate of 0.01 and set the model to be trainable (line 5). In each epoch, we set the accumulated cost to be zero (line 8), iterate over the temporal snapshots in the training data (line 9), make forward passes with the model on each temporal snapshot, and accumulate the spatial unit-specific mean squared errors (lines 10-13). We normalize the cost, backpropagate and update the model parameters (lines 14-17). Listings 4: Evaluating the recurrent graph convolutional neural network on the test portion of the spatiotemporal dataset using the time unit averaged mean squared error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Model Evaluation.</head><p>The scoring of the trained recurrent graph neural network in Listings 4 uses the snapshots in the test dataset. We set the model to be non-trainable and the accumulated squared errors as zero (lines 1-2). We iterate over the test spatiotemporal snapshots, make forward passes to predict the number of chickenpox cases, and accumulate the squared error (lines 3-7). The accumulated errors are normalized and we can print the mean squared error calculated on the whole test horizon (lines 8-10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Design in Practice Case Study: Incremental Model Training with GPU Acceleration</head><p>Exploiting the power of GPU-based acceleration of computations happens at the training and evaluation steps of the PyTorch Geometric Temporal pipelines. In this case study, we assume that the Hungarian Chickenpox cases dataset is already loaded in memory, the temporal split happened and a model class was defined by the code snippets in Listings 1 and 2. Moreover, we assume that the machine used for training the neural network can access a single CUDA compatible GPU device <ref type="bibr" target="#b47">[48]</ref>.  The optimizer registers the model parameters and the model parameters are set to be trainable (lines 5-6). We iterate over the temporal snapshot iterator 200 times and the iterator returns a temporal snapshot in each step. Importantly the snapshots which are PyTorch Geometric Data objects are transferred to the GPU (lines 8-10). The use of PyTorch Geometric Data objects as temporal snapshots enables the transfer of the time period specific edges, node features, and target vector with a single command. Using the input data a forward pass is made, the loss is accumulated and weight updates happen using the optimizer in each time period (lines <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. Compared to the cumulative backpropagation-based training approach discussed in Subsection 3.3 this backpropagation strategy is slower as weight updates happen at each time step, not just at the end of training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Model Evaluation.</head><p>During model scoring the GPU can be utilized again. The snippet in Listings 6 demonstrates that the only modification needed for accelerated evaluation is the transfer of snapshots to the GPU. In each time period, we move the temporal snapshot to the device to do the forward pass (line 4). We do the forward pass with the model and the snapshot on the GPU and accumulate the loss (lines 5-8). The loss value is averaged out and detached from the GPU for printing (lines 9-11). 9 cost = cost / (time+1) 10 cost = cost.item() 11 print("MSE: {:.4f}".format(cost))</p><p>Listings 6: Evaluating the recurrent graph convolutional neural network with GPU based acceleration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Maintaining PyTorch Geometric Temporal</head><p>The viability of the project is made possible by the open-source code, version control, public releases, automatically generated documentation, continuous integration, and near 100% test coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Open-Source Code-Base and Public</head><p>Releases. The source code of PyTorch Geometric Temporal is publicly available on GitHub under the MIT license. Using an open version control system allowed us to have a large group collaborate on the project and have external contributors who also submitted feature requests. The public releases of the library are also made available on the Python Package Index, which means that the framework can be installed via the pip command using the terminal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Documentation.</head><p>The source-code of PyTorch Geometric Temporal and Sphinx <ref type="bibr" target="#b7">[8]</ref> are used to generate a publicly available documentation of the library at https://pytorch-geometric-temporal. readthedocs.io/. This documentation is automatically created every time when the code-base changes in the public repository. The documentation covers the constructors and public methods of neural network layers, temporal signal iterators, public dataset loaders, and splitters. It also includes a list of relevant research papers, an in-depth installation guide, a detailed getting-started tutorial, and a list of integrated benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Continuous Integration.</head><p>We provide continuous integration for PyTorch Geometric Temporal with GitHub Actions which are available for free on GitHub without limitations on the number of builds. When the code is updated on any branch of the GitHub repository the build process is triggered and the library is deployed on Linux, Windows and macOS virtual machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.4">Unit Tests and Code</head><p>Coverage. The temporal graph neural network layers, custom data structures, and benchmark dataset loaders are all covered by unit tests. These unit tests can be executed locally using the source code. Unit tests are also triggered by the continuous integration provided by GitHub Actions. When the master branch of the open-source GitHub repository is updated, the build is successful, and all of the unit tests pass a coverage report is generated by CodeCov.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL EVALUATION</head><p>The proposed framework is evaluated on node-level regression tasks using novel datasets which we release with the paper. We also evaluate the effect of various batching techniques on predictive performance and runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">New Datasets</head><p>We release new spatiotemporal benchmark datasets with PyTorch Geometric Temporal which can be used to test models on node-level regression tasks. The descriptive statistics and properties of these newly introduced benchmark datasets are summarized in Table <ref type="table" target="#tab_4">4</ref>.</p><p>These newly released datasets are the following:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Predictive Performance</head><p>The forecasting experiments focus on the evaluation of the recurrent graph neural networks implemented in our framework. We compare the predictive performance under two specific backpropagation regimes which can be used to train these recurrent models:</p><p>• Incremental: After each temporal snapshot the loss is backpropagated and model weights are updated. This would need for training, we evaluated the forecasting performance on the last 10% by calculating the average mean squared error from 10 experimental runs. We used models with a recurrent graph convolutional layer which had 32 convolutional filters. The spatiotemporal layer was followed by the rectified linear unit <ref type="bibr" target="#b36">[37]</ref> activation function and during training time we used a dropout of 0.5 for regularization <ref type="bibr" target="#b52">[53]</ref> after the spatiotemporal layer. The hidden representations were fed to a fully connected feedforward layer which outputted the predicted scores for each spatial unit. The recurrent models were trained for 100 epochs with the Adam optimizer <ref type="bibr" target="#b28">[29]</ref> which used a learning rate of 10 −2 to minimize the mean squared error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Experimental findings.</head><p>Results are presented in Table <ref type="table" target="#tab_5">5</ref> where we also report standard deviations around the test set mean squared error and bold numbers denote the best performing model under each training regime on a dataset. Our experimental findings demonstrate multiple important empirical regularities which have important practical implications, namely:</p><p>(1) Most recurrent graph neural networks have a similar predictive performance on these regression tasks. In simple terms, there is not a single model which acts as a silver bullet. This also postulates that the model with the lowest training time is likely to be as good as the slowest one. (2) Results on the Wikipedia Math dataset imply that a cumulative backpropagation strategy can have a detrimental effect on the predictive performance of a recurrent graph neural network. When computation resources are not a bottleneck, an incremental strategy can be significantly better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Runtime Performance</head><p>The evaluation of the PyTorch Geometric Temporal runtime performance focuses on manipulating the input size and measuring the time needed to complete a training epoch. We investigate the runtime under the incremental and cumulative backpropagation strategies.   The runtime evaluation used the GCon-vGRU model <ref type="bibr" target="#b50">[51]</ref> with the hyperparameter settings described in Subsection 4.2. We measured the time needed for doing a single epoch over a sequence of 100 synthetic graphs. Reference Watts-Strogatz graphs in the snapshots of the dynamic graph with temporal signal iterator have binary labels, 2 10 nodes, 2 5 edges per node, and 2 5 node features. Runtimes were measured on the following hardware:</p><p>• CPU: The machine used for benchmarking had 8 Intel 1.00 GHz i5-1035G1 processors. • GPU: We utilized a machine with a single Tesla V-100 graphics card for the experiments.</p><p>4.3.2 Experimental findings. We plot the average runtime calculated from 10 experimental runs on Figure <ref type="figure" target="#fig_9">2</ref> for each input size.</p><p>Our results about runtime have two important implications about the practical application of our framework:</p><p>(1) The use of a cumulative backpropagation strategy only results in marginal computation gains compared to the incremental one. (2) On temporal sequences of large dynamically changing graphs the GPU-aided training can reduce the time needed to do an epoch by a whole magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS AND FUTURE DIRECTIONS</head><p>In this paper, we discussed PyTorch Geometric Temporal, the first deep learning library designed for neural spatiotemporal signal processing. We reviewed the existing geometric deep learning and machine learning techniques implemented in the framework. We gave an overview of the general machine learning framework design principles, the newly introduced input, and output data structures, long-term project viability and discussed a case study with source code that utilized the library. Our empirical evaluation focused on (a) the predictive performance of the models available in the library on real-world datasets which we released with the framework; (b) the scalability of the methods under various input sizes and structures. Our work could be extended and it also opens up opportunities for novel geometric deep learning and applied machine learning research. A possible direction to extend our work would be the consideration of continuous-time or time differences between temporal snapshots which are not constant. Another opportunity is the inclusion of temporal models which operate on curved spaces such as hyperbolic and spherical spaces. We are particularly interested in how the spatiotemporal deep learning techniques in the framework can be deployed and used for solving high-impact practical machine learning tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Dynamic graph with temporal signal. (b) Dynamic graph with static signal. (c) Static graph with temporal signal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The data iterators in PyTorch Geometric Temporal can provide temporal snapshots for all of the non static geometric deep learning scenarios.</figDesc><graphic url="image-3.png" coords="2,322.88,355.16,230.40,72.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 2 3Listings 3 :</head><label>23</label><figDesc>model = RecurrentGCN(node_features=8, filters=32) optimizer = torch.optim.Adam(model.parameters(), lr=0.01) + torch.mean((y_hat-snapshot.y)**2) Creating a recurrent graph convolutional neural network and training it by cumulative weight updates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1</head><label></label><figDesc>model.eval() 2 cost = 0 3 for time, snapshot in enumerate(test): + torch.mean((y_hat-snapshot.y)**2) 8 cost = cost / (time+1) 9 cost = cost.item() 10 print("MSE: {:.4f}".format(cost))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 4 5 7 8 9 for snapshot in train: 10 snapshotListings 5 :</head><label>479105</label><figDesc>model = RecurrentGCN(node_features=8, filters=32) 2 device = torch.device('cuda') 3 model = model.to(device) optimizer = torch.optim.Adam(model.parameters(), lr=0.01) 6 model.train() for epoch in range(200): Creating a recurrent graph convolutional neural network instance and training it by incremental weight updates on a GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>3. 4 . 1</head><label>41</label><figDesc>Model Training. In Listings 5 we demonstrate accelerated training with incremental weight updates. The model of interest and the device used for training are defined while the model is transferred to the GPU (lines 1-3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 6 snapshot.edge_index, 7 snapshot.edge_attr) 8 cost</head><label>678</label><figDesc>model.eval() 2 cost = 0 3 for time, snapshot in enumerate(test):4 snapshot = snapshot.to(device) 5 y_hat = model(snapshot.x, = cost + torch.mean((y_hat-snapshot.y)**2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The average time needed for doing an epoch on a dynamic graph -temporal signal iterator of Watts Strogatz graphs with a recurrent graph convolutional model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>4. 3 . 1</head><label>31</label><figDesc>Experimental settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A comparison of spatiotemporal deep learning models in PyTorch Geometric Temporal based on the temporal and spatial block, proximity order and edge heterogeneity.</figDesc><table><row><cell>Model</cell><cell>Temporal Layer</cell><cell>GNN Layer</cell><cell>Proximity Order</cell><cell>Multi Type</cell></row><row><cell>DCRNN [32]</cell><cell>GRU</cell><cell>DiffConv</cell><cell>Higher</cell><cell>False</cell></row><row><cell>GConvGRU [51]</cell><cell>GRU</cell><cell>Chebyshev</cell><cell>Lower</cell><cell>False</cell></row><row><cell>GConvLSTM [51]</cell><cell>LSTM</cell><cell>Chebyshev</cell><cell>Lower</cell><cell>False</cell></row><row><cell>GC-LSTM [10]</cell><cell>LSTM</cell><cell>Chebyshev</cell><cell>Lower</cell><cell>True</cell></row><row><cell>DyGrAE [54, 55]</cell><cell>LSTM</cell><cell>GGCN</cell><cell>Higher</cell><cell>False</cell></row><row><cell>LRGCN [31]</cell><cell>LSTM</cell><cell>RGCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>EGCN-H [39]</cell><cell>GRU</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>EGCN-O [39]</cell><cell>LSTM</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>T-GCN [66]</cell><cell>GRU</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>A3T-GCN [69]</cell><cell>GRU</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>AGCRN [4]</cell><cell>GRU</cell><cell>Chebyshev</cell><cell>Higher</cell><cell>False</cell></row><row><cell>MPNN LSTM [38]</cell><cell>LSTM</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row><row><cell>STGCN [63]</cell><cell cols="2">Attention Chebyshev</cell><cell>Higher</cell><cell>False</cell></row><row><cell>ASTGCN [22]</cell><cell cols="2">Attention Chebyshev</cell><cell>Higher</cell><cell>False</cell></row><row><cell>MSTGCN [22]</cell><cell cols="2">Attention Chebyshev</cell><cell>Higher</cell><cell>False</cell></row><row><cell>GMAN [67]</cell><cell>Attention</cell><cell>Custom</cell><cell>Lower</cell><cell>False</cell></row><row><cell>MTGNN [61]</cell><cell>Attention</cell><cell>Custom</cell><cell>Higher</cell><cell>False</cell></row><row><cell>AAGCN [52]</cell><cell>Attention</cell><cell>Custom</cell><cell>Higher</cell><cell>False</cell></row><row><cell>DNNTSP [64]</cell><cell>Attention</cell><cell>GCN</cell><cell>Lower</cell><cell>False</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>A desiderata and differentiation backend based comparison of open-source geometric deep learning libraries.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>•</head><label></label><figDesc>Chickenpox Hungary. A spatiotemporal dataset about the officially reported cases of chickenpox in Hungary. The nodes are counties and edges describe direct neighborhood relationships. The dataset covers the weeks between 2005 and 2015 without missingness. • Windmill Output Datasets. An hourly windfarm energy output dataset covering 2 years from a European country. Edge weights are calculated from the proximity of the windmills -high weights imply that two windmill stations are in close vicinity. The size of the dataset relates to the grouping of wind farms considered; the smaller datasets are more localized to a single region. • Pedal Me Deliveries. A dataset about the number of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity-based mutual adjacency relationships. • Wikipedia Math. Contains Wikipedia pages about popular mathematics topics and edges describe the links from one page to another. Features describe the number of daily visits between 2019 March and 2021 March. • Twitter Tennis RG and UO. Twitter mention graphs of major tennis tournaments from 2017. Each snapshot contains the graph of popular player or sport news accounts and mentions between them [5, 6]. Node labels encode the number of mentions received and vertex features are structural properties. • Covid19 England. A dataset about mass mobility between regions in England and the number of confirmed COVID-19 cases from March to May 2020 [38]. Each day contains a different mobility graph and node features corresponding to the number of cases in the previous days. Mobility stems from Facebook Data For Good 1 and cases from gov.uk 2 . • Montevideo Buses. A dataset about the hourly passenger inflow at bus stop level for eleven bus lines from the city of Montevideo. Nodes are bus stops and edges represent connections between the stops; the dataset covers a whole month of traffic patterns. • MTM-1 Hand Motions. A temporal dataset of Methods-Time Measurement-1 [36] motions, signaled as consecutive graph frames of 21 3D hand key points that were acquired via MediaPipe Hands [65] from original RGB-Video material. Node features encode the normalized 3D-coordinates of each finger joint and the vertices are connected according to the human hand structure.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Properties and granularity of the spatiotemporal datasets introduced in the paper with information about the number of time periods (𝑇 ) and spatial units (|𝑉 |).</figDesc><table><row><cell>Dataset</cell><cell cols="2">Signal Graph Frequency</cell><cell>𝑇</cell><cell>|𝑉 |</cell></row><row><cell cols="2">Chickenpox Hungary Temporal Static</cell><cell>Weekly</cell><cell>522</cell><cell>20</cell></row><row><cell>Windmill Large</cell><cell>Temporal Static</cell><cell>Hourly</cell><cell cols="2">17,472 319</cell></row><row><cell cols="2">Windmill Medium Temporal Static</cell><cell>Hourly</cell><cell cols="2">17,472 26</cell></row><row><cell>Windmill Small</cell><cell>Temporal Static</cell><cell>Hourly</cell><cell cols="2">17,472 11</cell></row><row><cell cols="2">Pedal Me Deliveries Temporal Static</cell><cell>Weekly</cell><cell>36</cell><cell>15</cell></row><row><cell>Wikipedia Math</cell><cell>Temporal Static</cell><cell>Daily</cell><cell cols="2">731 1,068</cell></row><row><cell>Twitter Tennis RG</cell><cell>Static Dynamic</cell><cell>Hourly</cell><cell cols="2">120 1000</cell></row><row><cell>Twitter Tennis UO</cell><cell>Static Dynamic</cell><cell>Hourly</cell><cell cols="2">112 1000</cell></row><row><cell>Covid19 England</cell><cell>Temporal Dynamic</cell><cell>Daily</cell><cell>61</cell><cell>129</cell></row><row><cell cols="2">Montevideo Buses Temporal Static</cell><cell>Hourly</cell><cell cols="2">744 675</cell></row><row><cell cols="5">MTM-1 Hand Motions Temporal Static 1/24 Seconds 14,469 21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>The predictive performance of spatiotemporal neural networks evaluated by average mean squared error. We report average performances calculated from 10 experimental repetitions with standard deviations around the average mean squared error calculated on 10% forecasting horizons. We use the incremental and cumulative backpropagation strategies. Bold numbers denote the best performance on each dataset given a training approach. When the loss from every temporal snapshot is aggregated, it is backpropagated, and weights are updated with the optimizer. This requires only one weight update step per epoch.</figDesc><table><row><cell></cell><cell cols="2">Chickenpox Hungary</cell><cell cols="2">Twitter Tennis RG</cell><cell cols="2">PedalMe London</cell><cell cols="2">Wikipedia Math</cell></row><row><cell></cell><cell>Incremental</cell><cell>Cumulative</cell><cell>Incremental</cell><cell>Cumulative</cell><cell>Incremental</cell><cell>Cumulative</cell><cell>Incremental</cell><cell>Cumulative</cell></row><row><cell>DCRNN [32]</cell><cell cols="8">1.124 ± 0.015 1.123 ± 0.014 2.049 ± 0.023 2.043 ± 0.016 1.463 ± 0.019 1.450 ± 0.024 0.679 ± 0.020 0.803 ± 0.018</cell></row><row><cell>GConvGRU [51]</cell><cell cols="8">1.128 ± 0.011 1.132 ± 0.023 2.051 ± 0.020 2.007 ± 0.022 1.622 ± 0.032 1.944 ± 0.013 0.657 ± 0.015 0.837 ± 0.021</cell></row><row><cell cols="9">GConvLSTM [51] 1.121 ± 0.014 1.119 ± 0.022 2.049 ± 0.024 2.007 ± 0.012 1.442 ± 0.028 1.433 ± 0.020 0.777 ± 0.021 0.868 ± 0.018</cell></row><row><cell>GC-LSTM [10]</cell><cell cols="8">1.115 ± 0.014 1.116 ± 0.023 2.053 ± 0.024 2.032 ± 0.015 1.455 ± 0.023 1.468 ± 0.025 0.779 ± 0.023 0.852 ± 0.016</cell></row><row><cell>DyGrAE [54, 55]</cell><cell cols="8">1.120 ± 0.021 1.118 ± 0.015 2.031 ± 0.006 2.007 ± 0.004 1.455 ± 0.031 1.456 ± 0.019 0.773 ± 0.009 0.816 ± 0.016</cell></row><row><cell>EGCN-H [39]</cell><cell cols="8">1.113 ± 0.016 1.104 ± 0.024 2.040 ± 0.018 2.006 ± 0.008 1.467 ± 0.026 1.436 ± 0.017 0.775 ± 0.022 0.857 ± 0.022</cell></row><row><cell>EGCN-O [39]</cell><cell cols="8">1.124 ± 0.009 1.119 ± 0.020 2.055 ± 0.020 2.010 ± 0.014 1.491 ± 0.024 1.430 ± 0.023 0.750 ± 0.014 0.823 ± 0.014</cell></row><row><cell>A3T-GCN[69]</cell><cell cols="8">1.114 ± 0.008 1.119 ± 0.018 2.045 ± 0.021 2.008 ± 0.016 1.469 ± 0.027 1.475 ± 0.029 0.781 ± 0.011 0.872 ± 0.017</cell></row><row><cell>T-GCN [66]</cell><cell cols="8">1.117 ± 0.011 1.111 ± 0.022 2.045 ± 0.027 2.008 ± 0.017 1.479 ± 0.012 1.481 ± 0.029 0.764 ± 0.011 0.846 ± 0.020</cell></row><row><cell cols="9">MPNN LSTM [38] 1.116 ± 0.023 1.129 ± 0.021 2.053 ± 0.041 2.007 ± 0.010 1.485 ± 0.028 1.458 ± 0.013 0.795 ± 0.010 0.905 ± 0.017</cell></row><row><cell>AGCRN [4]</cell><cell cols="8">1.120 ± 0.010 1.116 ± 0.017 2.039 ± 0.022 2.010 ± 0.009 1.469 ± 0.030 1.465 ± 0.026 0.788 ± 0.011 0.832 ± 0.020</cell></row><row><cell cols="4">as many weight updates as the number of temporal snap-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>shots.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>• Cumulative:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>4.2.1 Experimental settings. Using 90% of the temporal snapshots</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://dataforgood.fb.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://coronavirus.data.gov.uk/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A System for Large-Scale Machine Learning</title>
		<author>
			<persName><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Sean</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippina</forename><surname>English</surname></persName>
		</author>
		<ptr target="https://github.com/pbs-assess/sdmTMB" />
		<title level="m">sdmTMB: Spatial and spatiotemporal GLMMs with TMB</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Hyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Node Embeddings in Dynamic Graphs</title>
		<author>
			<persName><forename type="first">Ferenc</forename><surname>Béres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domokos</forename><forename type="middle">M</forename><surname>Kelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Róbert</forename><surname>Pálovics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Network Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Temporal Walk Based Centrality Metric for Graph Streams</title>
		<author>
			<persName><forename type="first">Ferenc</forename><surname>Béres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Róbert</forename><surname>Pálovics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Oláh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Network Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scaling Graph Neural Networks with Approximate Pagerank</title>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benedek</forename><surname>Rózemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2464" to="2473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Georg</forename><surname>Brandl</surname></persName>
		</author>
		<ptr target="http://sphinx-doc.org/sphinx.pdf" />
		<title level="m">Sphinx Documentation</title>
				<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiguang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00959</idno>
		<title level="m">CogDL: An Extensive Toolkit for Deep Learning on Graphs</title>
				<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Link Prediction</title>
		<author>
			<persName><forename type="first">Jinyin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibin</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.04206</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<title level="m">MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CSIRO&apos;s Data61</title>
		<ptr target="https://github.com/stellargraph/stellargraph" />
	</analytic>
	<monogr>
		<title level="m">StellarGraph Machine Learning Library</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast Graph Representation Learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">James</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Leary</surname></persName>
		</author>
		<title level="m">Compiling Machine Learning Programs via High-Level Tracing. Systems for Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Samuel S Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Keck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<ptr target="http://github.com/deepmind/jraph" />
		<title level="m">Jraph: A Library for Graph Neural Networks in Jax</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Palash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sujit</forename><surname>Rokka Chhetri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ninareh</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arquimedes</forename><surname>Canedo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.10734</idno>
		<title level="m">DynamicGEM: A Library for Dynamic Graph Embedding Methods</title>
				<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GEM: A Python Package for Graph Embedding Methods</title>
		<author>
			<persName><forename type="first">Palash</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Ferrara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">876</biblScope>
		</imprint>
	</monogr>
	<note>n.d.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Grattarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cesare</forename><surname>Alippi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.12138</idno>
		<title level="m">Graph Neural Networks in Tensor-Flow and Keras with Spektral</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</title>
		<author>
			<persName><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Open-Source Software Ecosystem for Leveraging Public Datasets in Spatio-Temporal Asset Catalogs (STAC)</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AGU Fall Meeting Abstracts</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="N23B" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<author>
			<persName><forename type="first">Petter</forename><surname>Holme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern Temporal Network Theory: A Colloquium</title>
				<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal Networks</title>
		<author>
			<persName><forename type="first">Petter</forename><surname>Holme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jari</forename><surname>Saramäki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics reports</title>
		<imprint>
			<biblScope unit="volume">519</biblScope>
			<biblScope unit="page" from="97" to="125" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Efficient Graph Deep Learning in TensorFlow with TF Geometric</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengsheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaiwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changsheng</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.11552</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skye</forename><surname>Wanderman-Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiao</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://github.com/google/jax" />
		<title level="m">JAX: Composable Transformations of Python+NumPy Programs</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
				<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Predicting Path Failure in Time-Evolving Graphs</title>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhichao</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lujia</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1279" to="1289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title>
		<author>
			<persName><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youzhi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaochen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shurui</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingtun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keqiang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bora</forename><surname>Oztekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12608</idno>
		<title level="m">Cong Fu, and Shuiwang Ji. 2021. DIG: A Turnkey Library for Diving into Graph Deep Learning Research</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attention-based Neural Machine Translation</title>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">G J</forename><surname>Harold B Maynard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">L</forename><surname>Stegemerten</surname></persName>
		</author>
		<author>
			<persName><surname>Schwab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods-Time Measurement</title>
		<imprint>
			<date type="published" when="1948">1948</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on International Conference on Machine Learning</title>
				<meeting>the 27th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transfer Graph Neural Networks for Pandemic Forecasting</title>
		<author>
			<persName><forename type="first">George</forename><surname>Panagopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giannis</forename><surname>Nikolentzos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michalis</forename><surname>Vazirgiannis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence</title>
				<meeting>the 35th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs</title>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Pareja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giacomo</forename><surname>Domeniconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toyotaro</forename><surname>Suzumura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Kanezashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Kaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><forename type="middle">B</forename><surname>Schardl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5363" to="5370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Edzer</forename><surname>Pebesma</surname></persName>
		</author>
		<ptr target="https://github.com/r-spatial/stars" />
		<title level="m">Spatiotemporal Arrays: Raster and Vector Datacubes</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">PySAL: A Python Library of Spatial Analytical Methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sergio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><surname>Anselin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Applied Spatial Analysis</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="175" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Rob</surname></persName>
		</author>
		<ptr target="https://github.com/stac-utils/pystac.GitHubrepository" />
		<title level="m">PySTAC: Python library for working with any SpatioTemporal Asset Catalog (STAC)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><surname>Benedek Rozemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amol</forename><surname>Englert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName><surname>Perozzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12878</idno>
		<title level="m">Pathfinder Discovery Networks for Neural Message Passing</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Karate Club: An API Oriented Open-source Python Framework for Unsupervised Learning on Graphs</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Benedek Rozemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rik</forename><surname>Kiss</surname></persName>
		</author>
		<author>
			<persName><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
				<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3125" to="3132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Paul</forename><surname>Benedek Rozemberczki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rik</forename><surname>Kiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamas</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><surname>Ferenci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.08100[cs.LG]</idno>
		<title level="m">Chickenpox Cases in Hungary: a Benchmark Dataset for Spatiotemporal Signal Processing with Graph Neural Networks</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">CUDA by Example: An Introduction to General-Purpose GPU Programming</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Kandrot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Addison-Wesley Professional</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning Distributed Representations of Graphs with Geo2DR</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Graph Representation Learning and Beyond</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Modeling Relational Data with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Structured Sequence Modeling with Graph Convolutional Recurrent Networks</title>
		<author>
			<persName><forename type="first">Youngjoo</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="362" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="12026" to="12035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Predictive Temporal Embedding of Dynamic Graphs</title>
		<author>
			<persName><forename type="first">Aynaz</forename><surname>Taheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanya</forename><surname>Berger-Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
				<meeting>the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning to Represent the Evolution of Dynamic Graphs with Recurrent Models</title>
		<author>
			<persName><forename type="first">Aynaz</forename><surname>Taheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanya</forename><surname>Berger-Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of The 2019 World Wide Web Conference (WWW &apos;19</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="301" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thompson</forename><surname>Comer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Harris</surname></persName>
		</author>
		<ptr target="https://github.com/rapidsai/cuspatial" />
		<title level="m">CUDA-Accelerated GIS and Spatiotemporal Algorithms</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changxin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://github.com/thunlp/OpenNE" />
		<title level="m">OpenNE: An Open Source Toolkit for Network Embedding</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The NumPy Array: a Structure for Efficient Numerical Computation</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gael</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in science &amp; engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Attention is All You Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
				<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">GeoWave: Utilizing Distributed Key-Value Stores for Multidimensional Data</title>
		<author>
			<persName><forename type="first">Rich</forename><surname>Michael A Whitby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Fecher</surname></persName>
		</author>
		<author>
			<persName><surname>Bennight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Spatial and Temporal Databases</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="105" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">AliGraph: A Comprehensive Graph Neural Network Platform</title>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3165" to="3166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Spatio-Temporal Graph Convolutional Networks: a Deep Learning Framework for Traffic Forecasting</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
				<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Predicting Temporal Sets with Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leilei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanren</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weifeng</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1083" to="1091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Bazarevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Vakunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Tkachenka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuo-Ling</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Grundmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10214[cs.CV]</idno>
		<title level="m">MediaPipe Hands: On-device Real-time Hand Tracking</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</title>
		<author>
			<persName><forename type="first">Ling</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3848" to="3858" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">GMAN: A Graph Multi-Attention Network for Traffic Prediction</title>
		<author>
			<persName><forename type="first">Chuanpan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1234" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Learning Graph Neural Networks with Deep Graph Library</title>
		<author>
			<persName><forename type="first">Da</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the Web Conference</title>
				<imprint>
			<publisher>WWW &apos;20</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="305" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11583</idno>
		<title level="m">A3T-GCN: Attention Temporal Graph Convolutional Network for Traffic Forecasting</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">MobilityDB: A Mobility Database Based on PostgreSQL and PostGIS</title>
		<author>
			<persName><forename type="first">Esteban</forename><surname>Zimányi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahmoud</forename><surname>Sakr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lesuisse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Database Systems (TODS)</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
