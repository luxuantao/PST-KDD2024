<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PipeRench: A Coprocessor for Streaming Multimedia Acceleration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seth</forename><forename type="middle">Copen</forename><surname>Goldstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Herman</forename><surname>Schmit</surname></persName>
							<email>herman@ece.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><surname>Moe</surname></persName>
							<email>moe@ece.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mihai</forename><surname>Budiu</surname></persName>
							<email>mihaib@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Srihari</forename><surname>Cadambi</surname></persName>
							<email>cadambi@ece.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">R</forename><forename type="middle">Reed</forename><surname>Taylor</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ronald</forename><surname>Laufer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of ECE *</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PipeRench: A Coprocessor for Streaming Multimedia Acceleration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Future computing workloads will emphasize an architecture's ability to perform relatively simple calculations on massive quantities of mixed-width data. This paper describes a novel reconfigurable fabric architecture, PipeRench, optimized to accelerate these types of computations. PipeRench enables fast, robust compilers, supports forward compatibility, and virtualizes configurations, thus removing the fixed size constraint present in other fabrics. For the first time we explore how the bit-width of processing elements affects performance and show how the PipeRench architecture has been optimized to balance the needs of the compiler against the realities of silicon. Finally, we demonstrate extreme performance speedup on certain computing kernels (up to 190x versus a modern RISC processor), and analyze how this acceleration translates to application speedup.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Workloads for computing devices are rapidly changing. On the desktop, the integration of digital media has made real-time media processing the primary challenge for architects <ref type="bibr" target="#b10">[10]</ref>. Embedded and wireless computing devices need to process copious data streaming from sensors and receivers. These changes emphasize simple, regular computations on large sets of small data elements. There are two important respects in which this need does not match the processing strengths of conventional processors. First, the size of the data elements underutilizes the processor's wide datapath. Second, the instruction bandwidth is much higher than it needs to be to perform regular, dataflow-dominated computations on large data sets.</p><p>Both of these problems are being addressed through processor architecture. Most recent ISAs have multimedia instruction set extensions that allow a wide datapath to be switched into SIMD operation <ref type="bibr" target="#b17">[17]</ref>. The instruction bandwidth issue has created renewed interest in vector processing <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b24">24]</ref>.</p><p>A fundamentally different way of addressing these problems is to configure connections between programmable logic elements and registers in order to construct an efficient, highly parallel implementation of the processing kernel. This interconnected network of processing elements is called a reconfigurable fabric, and the data set used to program the interconnect and processing elements is a configuration. After a configuration is loaded into a reconfigurable fabric, there is no further instruction bandwidth required to perform the computation. Furthermore, because the operations are composed of small basic elements, the size of the processing elements can closely match the required data size. This approach is called reconfigurable computing.</p><p>Despite reports of amazing performance <ref type="bibr" target="#b11">[11]</ref>, reconfigurable computing has not been accepted as a mainstream computing technology because most previous efforts were based upon, or inspired by, commercial FPGAs and fail to meet the requirements of the marketplace. The problems inherent in using standard FPGAs include 1. Logic granularity: FPGAs are designed for logic replacement. The granularity of the functional units is optimized to replace random logic, not to perform multimedia computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Configuration time:</head><p>The time it takes to load a configuration in the fabric is called configuration time. In commercial FPGAs, configuration times range from hundreds of microseconds to hundreds of milliseconds. To show a performance improvement this startup latency must be amortized over huge data sets, which limits the applicability of the technique. 3. Forward-compatibility: FPGAs require redesign or recompilation to gain benefit from future generations of the chip. <ref type="bibr" target="#b4">4</ref>. Hard constraints: FPGAs can implement only ker-nels of a fixed and relatively small size. This is part of the reason that compilation is difficult-everything must fit. It also causes large and unpredictable discontinuities between kernel size and performance. 5. Compilation time: Currently the synthesis, placement and routing phases of designs take hundreds of times longer than what the compilation of the same kernel would take for a general-purpose processor.</p><p>This paper describes PipeRench, a reconfigurable fabric designed to increase performance on future computing workloads. PipeRench realizes the performance promises of reconfigurable computing while solving the problems outlined above. PipeRench uses a technique called pipeline reconfiguration to solve the problems of compilability, reconfiguration time, and forward-compatibility. The architectural parameters of PipeRench, including the logic block granularity, were selected to optimize the performance of a suite of kernels, balancing the needs of a compiler against design realities in deep-submicron process technology.</p><p>PipeRench is currently used as an attached processor. This places significant limitations on the types of applications that can realize speedup, due to limited bandwidth between PipeRench, the main memory and the processor. We believe this represents the initial phase in the evolution of reconfigurable processors. Just as floating-point computation migrated from software emulation, to attached processors, to coprocessors, and finally to full incorporation into processor ISAs, so will reconfigurable computing eventually be integrated into the CPU.</p><p>In the next section, we use several examples to illustrate the advantages and architectural requirements of reconfigurable fabrics. We introduce the idea of pipeline reconfiguration in Section 3, and describe how this technique solves the practical problems faced by reconfigurable computing. Section 4 describes a class of architectures that can implement pipelined reconfiguration. We evaluate these architectures in Section 5. We cover related work in Section 6, and in Section 7 we summarize and discuss future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Reconfigurable Computing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Attributes of Target Kernels</head><p>Functions for which a reconfigurable fabric can provide a significant benefit exhibit one or more of the following features:</p><p>1. The function operates on bit-widths that are different from the processor's basic word size. 2. The data dependencies in the function allow multiple function units to operate in parallel.</p><p>for (int i=0; i&lt;maxInput; i++) { y[i] = 0; for (int j=0; j&lt;Taps; j++)</p><formula xml:id="formula_0">y[i] = y[i] + x[i+j]*w[j]; } X in * w 1 * w 2 + * w 3 + Y out Figure 1.</formula><p>C code for a FIR filter and a pipelined version for a three-tap filter.</p><p>3. The function is composed of a series of basic operations that can be combined into a single specialized operation. 4. The function can be pipelined. 5. Constant propagation can be performed, reducing the complexity of the operations. 6. The input values are reused many times within the computation.</p><p>These functions take two forms. Stream-based functions process a large data input stream and produce a large data output stream, while custom instructions take a few inputs and produce a few outputs. After presenting a simple example of each type of function to illustrate how a reconfigurable fabric can improve performance, we discuss the ways in which a fabric can be integrated into a complete system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">A Stream-Based Function: FIR</head><p>A reconfigurable fabric can be most effective when used to implement entire pipelines from applications. Here we investigate a simple but prototypical pipeline for implementing a finite-impulse response (FIR) filter. The FIR filter exhibits all but feature 3 from the requirement list in Section 2.1. Figure <ref type="figure">1</ref> shows the C code and a hardware implementation. When FIR is mapped to a reconfigurable fabric, the general-purpose multipliers shown in the hardware description are implemented as constant multipliers, where the constants are the w[i] values. This results in less hardware and fewer cycles than a general-purpose multiplier.</p><p>Figure <ref type="figure">2</ref> compares an 8-bit FIR using 12-bit coefficients running on a particular instance of PipeRench to implementations on a Xilinx FPGA using parallel distributed arithmetic (shown as Xilinx PDA in Figure <ref type="figure">2</ref>) and double-rate bit-serial distributed arithmetic (shown as Xilinx DDA). Both the PipeRench chip and Xilinx FPGA are implemented in 100mm 2 of silicon using a 0.35 micron process. The FPGA runs at approximately 60MHz for both applications, while PipeRench's clock is 100MHz. PipeRench outperforms both Xilinx implementations over a broader range of filter sizes. Similarly, PipeRench outperforms the Texas Instruments TMS320C6201, a commercial DSP that runs at 200 MHz and contains two 16x16-bit integer multipliers, on filters larger than a few taps. PipeRench exhibits the same high level of performance as the FPGA. Due to its support for hardware virtualization, as described in Section 3, PipeRench exhibits the same graceful degradations of performance as the DSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Custom Instructions: Population Count Instruction</head><p>Most processors, with the exception of vector supercomputers, do not include a native population count instruction and thus it must be implemented in software (see Figure <ref type="figure">3</ref>). Using a reconfigurable fabric, popCount() can be implemented as a custom instruction giving a raw performance improvement of more than an order of magnitude. The function exhibits three of the qualifying features <ref type="bibr">(</ref> and 3) from Section 2.1. The reconfigurable computing solution replaces the O(n) loop with an adder tree of height O(log n). Furthermore, the adders used are significantly narrower than the adders on the processor. The circuit can also be pipelined, so that when executed on a vector it retires one result every cycle.</p><p>In evaluating a reconfigurable fabric, it is important to take into account both configuration time and the communication latency and bandwidth between the processor and the fabric. If popCount() is called only once, it makes little sense to configure the fabric to perform the operation since the time to configure the fabric will be larger than the savings obtained by executing popCount() on the fabric.</p><p>When popCount() is used outside of a loop and data dependencies require that the result be used immediately after it is computed, the fabric needs direct access to the processor registers. On the other hand, if popCount() is used in a loop, where there are no immediate dependencies on the results, performance can be better if the fabric can directly access memory. In this paper we concentrate on the latter case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">The Fabric's Place</head><p>Reconfigurable fabrics provide the computational datapath with more flexibility. Their utility and applicability is influenced by the manner in which they are integrated into the datapath. We recognize three basic ways in which a fabric may be integrated into a system: as an attached processor on the I/O or memory bus, as a coprocessor, or as a functional unit on the main CPU. (See Figure <ref type="figure">4</ref>.) Attached-processor systems, e.g. PAM <ref type="bibr" target="#b0">[1]</ref>, Splash <ref type="bibr" target="#b4">[4]</ref>, and DISC <ref type="bibr" target="#b25">[25]</ref>, have no direct access to the processor. Rather, they are controlled over a bus. The primary feature of attached processors is that they are easy to add to existing computer systems. However, due to the bandwidth and latency constraints imposed by the bus they can enhance only computations that have a high computation-tomemory-bandwidth ratio. Thus, they are most suited to stream-based functions that require little or no communication with the host processor.</p><p>In coprocessor architectures, there is a low-latency, highbandwidth connection between the processor and the reconfigurable fabric, which increases the number of streambased functions that can profitably be run on the fabric. Recent examples of such systems include Garp <ref type="bibr" target="#b13">[13]</ref> and Napa-1000 <ref type="bibr" target="#b19">[19]</ref>. Further specialization occurs when the fabric is on the main processor's data path, as in functionalunit architectures like P-RISC <ref type="bibr" target="#b18">[18]</ref>, Chimaera <ref type="bibr" target="#b12">[12]</ref>, and OneChip <ref type="bibr" target="#b26">[26]</ref>. All of these allow custom instructions to be executed. The reconfigurable unit is on the processor datapath and has access to registers. However, these implementations restrict the applicability of the reconfigurable unit by disallowing state to be stored in the fabric and in some cases by disallowing direct access to memory, essentially eliminating their usefulness for stream-based processing.</p><p>In this paper we describe pipelined reconfigurable architectures, which can be used in any of the fashions described above. However, in order to describe the system we are currently building, we limit ourselves to describing how we would apply it as an attached-processor system. The natural evolution of this fabric to a coprocessor or a function unit would only enhance its applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pipelined Reconfigurable Architectures</head><p>In the previous section, we described how applicationspecific configurations of reconfigurable fabrics can be used to accelerate certain applications. The computation is embedded in a single static configuration rather than in a sequence of instructions, thereby reducing the instruction bandwidth.</p><p>The static nature of these configurations, however, causes two significant problems. First, the computation may require more hardware than is available. Second, given more hardware, there is no way that a single hardware design can exploit the additional resources that will inevitably become available in future process generations. In this section, we review a technique called pipeline reconfiguration <ref type="bibr" target="#b20">[20]</ref>, that allows a large logical design to be implemented on a small piece of hardware through rapid reconfiguration of that hardware. With this technique, the compiler is no longer responsible for satisfying fixed hardware constraints. In addition, the performance of a design improves in proportion to the amount of hardware allocated to that design; as future process technology makes more transistors available, the same hardware designs achieve higher levels of performance.</p><p>Pipeline reconfiguration is a method of virtualizing pipelined hardware application designs by breaking the single static configuration into pieces that correspond to pipeline stages in the application. These configurations are then loaded, one per cycle, into the fabric. This makes it possible to perform the computation, even if though the whole configuration is never present in the fabric at one time.</p><p>The virtualization process is illustrated in Figure <ref type="figure" target="#fig_1">5</ref>, which shows a five-stage pipeline being virtualized on a three-stage fabric. The top portion of this figure shows the five-stage application and the state of each of the stages of the pipeline in five consecutive cycles. The bottom half of the figure shows the state of the physical stages in the fabric that is executing this application. An effective metaphor for this procedure is scrolling on a text window. Once the pipeline is full, every five cycles generates two results from the pipeline. In general, when a v-stage application is virtualized on a device with a capacity of p-stages (p &lt; v), the throughput of the implementation is proportional to (p − 1)/v. Throughput is a linear function of the capacity of the device; therefore performance improves due to both increases in clock frequency and decreases in feature size, without any redesign, until p = v. Thereafter, applications' performance continues to gain only through increased clock speed.</p><p>Because the configuration of stages happens concurrently with the execution of other stages, there is no loss in performance due to reconfiguration. As the pipeline is filling with data, stages of the computation are being configured ahead of that data. Even if there is no virtualization, configuration time is equivalent to the pipeline fill time of the application and therefore does not reduce the maximum throughput of the application.</p><p>In order for this virtualization process to work, the state in any pipeline stage must be a function only of the current state of that stage and the current state of the previous stage. In other words, cyclic dependencies must fit within one stage of the pipeline. Interconnect that directly skips over one or more stages is not allowed, nor are connections from one stage to a previous stage. Fortunately, many computations on streaming data can be pipelined within these constraints. Furthermore, by including structures we call pass registers, it is possible to create virtual connections between distant stages.</p><p>The primary challenge facing pipeline reconfiguration is configuring a computationally significant pipeline stage in one clock cycle. To do this, we connect a wide on-chip configuration buffer (either SRAM or DRAM) to the nearby fabric allowing a pipeline stage to be configured in one cycle. We use the word stripe to describe both the physical stages in the fabric (the physical stripes), and the configuration words that are written into them (the virtual stripes). Any virtual stripe can be written into any physical stripe. Therefore, all physical stripes must have identical functionality and interconnect.</p><p>Before a physical stripe is reconfigured with a new virtual stripe, the state of the resident virtual stripe, if any, must be stored outside of the fabric. Conversely, when a virtual stripe is returned to the fabric, any stored state for the stripe must be restored within the physical stripe <ref type="bibr" target="#b5">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PipeRench</head><p>In this section, we describe a class of pipeline reconfigurable fabrics, called PipeRench devices, and define critical architectural parameters for this class of fabrics. These architectural parameters are the subject of the performance evaluation described in Section 5.</p><p>An abstract view of the PipeRench architectural class is shown in Figure <ref type="figure" target="#fig_2">6</ref>. The device is composed of a set of physical pipeline stages, or stripes. Each stripe is composed of interconnect and processing elements (PE), which contain registers and ALUs. An ALU is composed of look-up tables (LUTs) and extra circuitry for carry-chains, zero-detection, etc. The PEs have access to a global I/O bus. Through the interconnect network, the PEs can access operands from registered outputs of the previous stripe as well as registered or unregistered outputs of the other PEs in the stripe. There are no busses that go to a previous stripe; this is required by hardware virtualization (as discussed in <ref type="bibr" target="#b5">[5]</ref>) and makes long feedback loops impossible, since any feedback must be contained within one stripe. The global I/O busses are required because the pipeline stages in an application may be physically located in any of the stripes in the fabric; inputs to and outputs from the application must use a global bus to get to their destination. <ref type="foot" target="#foot_0">1</ref>All PipeRench devices have four global busses. Two of these busses are dedicated to storing and restoring stripe state during hardware virtualization. The other two are used for input and output. Combinational logic is implemented using using a set of N B-bit wide ALUs. The ALU operation is static while a particular virtual stripe is located in the physical stripe. The carry lines of PipeRench's ALUs may be cascaded to construct wider ALUs. Furthermore, ALUs may be chained together via the interconnect network to build complex combinational functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pass Register File</head><p>We organize each stripe as an array of processing elements (PEs). Each PE contains one ALU and a pass register file. As described in Section 3, there can be no unregistered interconnect between stripes. Furthermore, any state caused by registered feedback within the stripe must be saved and restored. The pass register is designed to provide efficient pipelined (registered) interstripe connections. Each pass register file has one dedicated register that can be used for intra-stripe feedback and therefore must have its state stored and restored.</p><p>As illustrated in Figure <ref type="figure">7</ref>, the output of the ALU can be written to any one of the P registers in the pass register file. If the register is not written by the ALU, the value in the pass register is loaded from the value in the corresponding pass register in the previous stripe. This reduces  the amount of state that can be contained in the pass register file to a single register, because data that travels through the pipeline does not need to be saved and restored. The pass register file also provides a way to route intermediate results computed on one stripe to a stripe somewhere down the pipeline, without wasting ALUs or the interconnect network within the stripe. Like the ALU operation, the specific registers that are written to and read from the pass register file are static while a virtual stripe is resident; different PEs can read and write different registers, but the registers that a particular PE accesses change only when a different virtual stripe configures the physical stripe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Interconnect Network</head><p>The pass register file provides pipelined interconnect from a PE in one stripe to the corresponding PE in subsequent stripes. If data values need to move laterally within the stripe, they must use the interconnect network, which is illustrated as a horizontal bar in Figure <ref type="figure" target="#fig_2">6</ref>. In each stripe, the interconnect network accepts inputs from the each of the PEs in that stripe, as well as one of the registered val-ues from the previous stripe. Like the ALU operations and the pass register files, the interconnect network is programmed during configuration and remains unchanged during the lifetime of the virtual stripe.</p><p>The interconnect we evaluate in Section 5 is a full crossbar. This is expensive in terms of hardware, but it makes every design easily placeable by the compiler. Furthermore, a rich network is necessary to achieve good utilization in a reconfigurable fabric <ref type="bibr" target="#b9">[9]</ref>. In fact, most fabrics use over 50% of their available area on interconnect. As shown in Section 5, even with a full crossbar we use less than 50% of the area for the interstripe interconnect. Though we use a full crossbar, it connects only PEs to PEs-i.e., it is a Bbit wide, N xN crossbar, as opposed to an (N xB)x(N xB) crossbar. A key to making this interconnect useful is that each PE has a barrel shifter that can shift its inputs up to B−1 bits to the left (see Figure <ref type="figure" target="#fig_3">8</ref>). This allows our architecture to do data alignments that are necessary for word-based arithmetic as described in <ref type="bibr" target="#b6">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Physical Implementation</head><p>Currently we are planning to design this system in 100mm 2 of silicon in a 0.25 micron process. Half of that area is for the reconfigurable fabric, while the other half is for memory to store virtual stripes, control, and chip I/O. Fifty square millimeters of silicon provides approximately 500kb of virtual configuration storage, which is adequate for very large applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Architectural Parameters</head><p>Figure <ref type="figure" target="#fig_3">8</ref> summarizes one of the N PEs in a stripe for our parameterized architecture. In the following section, we explore the following three architectural parameters:</p><p>• N : the number of PEs in the stripe;</p><p>• B: the width, in bits, of each PE;</p><p>• P : the number of B-bit wide registers in the pass register file per PE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head><p>In this section we explore the design space of pipelined reconfigurable architecures. Using a compiler and CAD tools, we look at how several kernels perform on implementations of the fabric that differ in the parameters described in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Kernels and Applications</head><p>Performance and utilization data were gathered for PipeRench implementations of various kernels. The kernels were chosen based on demand for the applications in the present and near future, their recognition as industry performance benchmarks, and their ability to fit into our computational model. ATR implements the shapesum kernel of the Sandia algorithm for automatic target recognition <ref type="bibr" target="#b22">[22]</ref>. This algorithm is used to find an instance of a template image in a larger image, and to distinguish between images that contain different templates. Cordic is a 12 stage implementation of the Honeywell timing benchmark for Cordic vector rotations <ref type="bibr" target="#b15">[15]</ref>. Given a vector in rectangular coordinates and a rotation angle in degrees, the algorithm finds a close approximation to the resultant rotation. DCT is a one-dimensional, eight-point discrete cosine transform <ref type="bibr" target="#b16">[16]</ref>. DCT-2D, a two-dimensional DCT, is an important algorithm in digital signal processing and is the core of JPEG image compression. FIR is described in Section 2.2. Here we implement a FIR filter with 20 taps and 8-bit coefficients. IDEA implements a complete eight-round International Data Encryption Algorithm with the key compiled into the configuration <ref type="bibr" target="#b21">[21]</ref>. IDEA is the heart of Phil Zimmerman's Pretty Good Privacy (PGP) data encryption. Nqueens is an evaluator for the Nqueens problem on an 8x8 board. Given the coordinates of chess queens on a chessboard, it determines whether any of the queens can attack each other. Over implements the Porter-Duff over operator <ref type="bibr" target="#b1">[2]</ref>. This is a method of joining two images based on a mask of transparency values for each pixel. PopCount is described in section Section 2.3.</p><p>We also evalute the performance of PipeRench on two complete applications, JPEG and PGP. In each of these applications we assume PipeRench is integrated into the system on the PCI bus, which has a peak memory bandwidth of 132MB/sec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Methodology</head><p>Our approach is to use CAD tools to synthesize a stripe based on the parameters N , B, and P . We join this automatically synthesized layout with a custom layout for the interconnect. Using the final layout we determine the number of physical stripes that can fit in our silicon budget of 50 mm 2 (5 mm x 10 mm) and the delay characterisitics of the components of the stripe (e.g., LUTs, carry-chain, interconnect, etc.). The delay characterisitics and number of registers are then used by the compiler to create configurations for each of the architectural instances, yielding a design of a certain number of stripes at a particular frequency. We can then determine the overall speed of the kernel, in terms of throughput, for each architectural instance.</p><p>The CAD tool flow synthesizes each design point and automatically places and routes the final design. Although the automatic tool flow does not yield the optimal design, we assume that the various points are equally non-optimal, allowing us to compare the designs. Preliminary analysis showed the CAD tools doing quite well, except for the interconnect, which we hand optimize.</p><p>The kernels are written in a single-assignment C-like language, DIL, which is intended for both programmers and as an intermediate language for a high-level language compiler that targets reconfigurable architectures. The DIL compiler automatically synthesizes and places and routes our largest designs in a few seconds <ref type="bibr" target="#b2">[3]</ref>. It is parameterizable so that we can generate configurations for any pipelined reconfigurable architecure as described in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">The Fabric</head><p>There are two main constraints that determine which parameters generate realizable fabrics: the width of a stripe and the number of vertical wires that must pass over each stripe. The width of a stripe is influenced by the size and number of the PEs and the number of registers allocated to each PE. We limit the width of a stripe to 4.9mm in order to allow two of them to be placed side by side. 2  The second constraint is to accomodate the number of vertical wires that pass over the stripes within two metal layers. These wires include those for the global busses, the pass registers, and the configuration bits.</p><p>We explore the region of the space bounded by PE bitwidths (B) of 2, 4, 8, 16, and 32 bits; stripe widths (N x B) of between 64 bits and 256 bits; and registers (P) of 2, 4, 8 and 16. 3 Figure <ref type="figure" target="#fig_4">9</ref> shows the computational density (bit-ops/area-time) of the realizable parameters when four and eight registers are allocated to each PE. Interestingly, the result is essentially independent of stripe width. The reason for this is that as the stripe width increases, the amount of area per stripe devoted to interconnect increases, but the total number of stripes decreases-yeilding a constant amount of total area devoted to interconnect. In fact, the total area devoted to interstripe interconnect is less than 50% of the area devoted to the fabric. The total delay from the output of one stripe into the PE of the next stripe remains approximately constant because the wire capacitance of the 2 Virtualization requires that data be allowed to flow between any two stripes, including the last physical one and the first physical one. To obtain consistent routing delay times we arrange the stripes in two columns: in one column the data flows down and in the other it flows up. This avoids a long path from the last to the first physical stripe.</p><p>3 Some of the wider stripes can be implemented only with eight registers.  interstripe interconnect (5mm long in all cases) dominates the transistor delays.</p><p>The computational density does not seem to have a monotonic relationship with PE width. This seems counterintuitive; as PE size increases, the overhead of configuration decreases and the ability to optimize the PE increases. Therefore, computational density should increase. But our delay metric includes the delay associated the carry chain of one PE, which increases with PE width. The increased carry chain delay counters the reduction in size per bit of the wider PEs causing the computational density to remain relatively constant. On the other hand, if we were to use only logical operations to measure delay, we would observe a near-linear increase in computational density as PE size increases.</p><p>Because registers consume substantial area, density goes down as the number of registers increases (compare the two graphs in Figure <ref type="figure" target="#fig_4">9</ref>). In fact, since we use registers mainly to implement pipelined interstripe interconnect, they contribute little to computational density. However, as we will see, they are extremely useful in compiling kernels to the fabric.</p><p>The last effect we examine is the size of the configuration word. The configuration word size approximately halves as PE widths double. On the other hand, as the width of the stripe increases, the configuration word increases slightly. For 128-bit stripes, the configuration bits for a stripe range from 1280 bits for a 4-bit PE to 164 bits for a 32-bit PE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">The Compiler</head><p>The compilation process maps source written in a dataflow intermediate language (DIL) to a particular instance of PipeRench. DIL is a single-assignment language with C operators and a type system that allows the bit-width of variable to be specified. The compiler converts the source into a dataflow graph and then, through many transformations, creates a final configuration. The important transformations for this study are operator decomposition, operator recomposition, fitting, and place-and-route.</p><p>The operator decomposition pass breaks up operators so that they can execute within the target cycle time. For example, a wide adder needs to be broken up into several smaller adders due to the carry-chain delays. The decomposition must also create new operators that handle the routing of the carry bits between the partial sums. For operations that require carry bits, the decomposed version is significantly larger and has additional routing constraints. Thus, as PE size decreases, the penalty for decomposition increases. Currently, the interaction between operator decomposition place-and-route requires each stripe to have at least six PEs.</p><p>The naive decomposition for an operator routes the carry signal on the interstripe interconnect. It also results in signextending the single carry bit to the size of the smaller adders. To compensate for this, the operator recomposition pass uses pattern matching to find subgraphs that can be mapped to parameterized modules designed to take advantage of architecture-specific routing and PE capabilities. Most importantly for this study, this slightly reduces the overhead of decomposed carry operations.</p><p>The fitting pass matches the wire and operator widths to the size of a PE. This can require the insertion of signextension operators to increase the width of wires that are not multiples of a PE width. As the PE width increases, this causes both underutilization of PEs and a larger percentage of sign-extension PEs. Furthermore, routing operations become more complex as extracting bits from wires that are not PE-aligned often involves using an extra PE.</p><p>Place-and-route is the key to the compiler. It places and routes the operators in the graph onto stripes under the timing constraint imposed by the target cycle time. Thus, as the clock rate or the delay through the PE increases, the utilization of each stripe can decrease, unless the kernel has sufficient parallelism so that independent operators can be placed in a stripe. This is particularly true of stripes with many PEs.</p><p>In addition to assigning operators to PEs and wires to the interconnect, the place-and-route pass assigns wires to the pass registers. If there are insufficient pass registers, the compiler will time-multiplex wires on registers. Timemultiplexing slows the circuit down in order to allow multiple values to reside in a single registers. For example, if two wires are assigned to a single register, then the register holds one wire on the odd cycles and another on the even ones. While time-multiplexing does not increase the circuit size significantly, it does reduce the throughput by a constant factor. For architectures with few registers this is a severe penalty, as time-multiplexing factors of more than ten may be required.</p><p>One of the goals for the DIL compiler was compilation speed. It achieves high speed compilation in part by trading off result quality for faster compilation. This affects the results by introducing more time-multiplexing than necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Compiler/Fabric Interaction</head><p>The real question, of course, is not the raw hardware performance available, but how well it can be utilized. Using the parameterizable compiler we compiled configurations for each kernel. Before evaluating the effects of overall width, number of PEs, or number of bits per PE, we narrow down the design space by examing the effect of pass registers. For a given stripe width and bits-per-PE, as the number of registers increase, the computational density decreases.</p><p>However since pass registers make up an important component of the interstripe interconnect, reducing the number of pass registers increases routing pressure, which decreases stripe utilization and causes the compiler to time-multiplex the values on the registers. As Figure <ref type="figure" target="#fig_5">10</ref> shows, the best balance of computation density with utilization is most often achieved at eight registers. The average time multiplexing factor for all the kernels average across all the fabrics ranges from over 60 for two registers, to 12 at four registers, 2 at eight registers, and 1 at sixteen registers. IDEA and Nqueens have higher factors at eight registers than the other kernels. The rest of the evaluation occurs with eight pass registers per PE, i.e. P = 8.</p><p>Figure <ref type="figure" target="#fig_6">11</ref> shows the throughput achieved for various stripe widths and PE sizes at eight registers per PE. As can be seen, though the wider PE sizes create fabrics with higher computational density, the natural data sizes of the kernels are smaller, causing 32-bit PEs to be underutilized. On the other end of the spectrum, 2-bit PEs are not competitive due to increased times for arithmetic operations, the lack of raw computational density, and the increased number of configuration bits needed per application.</p><p>If we examine the performance of the individual kernels (see Figure <ref type="figure" target="#fig_6">11</ref>) we can see that the characteristics of the kernels greatly influence which parameters are best. For example, DCT needs at least 8 PEs in the stripe 4 , ruling out 32-bit PEs for all but the widest stripe. The peak at 128 bits occurs because there is a sufficient number of PEs to eliminate time multiplexing. While wider stripes can be utilized because there is sufficient parallelism in the DCT algorithm.</p><p>FIR operates mostly on 8-bit and wider numbers. This makes 4-bit PEs less attactive due to the carry chain delay associated with crossing PEs. There is enough parallelism to keep the wider stripes busy. These stripes have fewer registers, which increases the number of stripes in the implementation, thereby reducing its overall throughput.</p><p>IDEA takes wide inputs, so stripes of less than 96-bits require substantial time-multiplexing. Unlike DCT and FIR there is not enough parallelism to utilize the wider stripes.</p><p>In summary, we need to choose a fabric that is at least 128 bits wide. We also want at least 12 PEs in the stripe. Since not all kernels have sufficient parallelism to utilize wide stripes, we want to choose the narrowest stripe to which all kernels can be compiled. Thus, we choose a 128bit wide fabric made up of eight-bit PEs with eight registers each. 4 Eight PEs are required to transpose the data for the two-dimensional DCT. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Performance Versus General-Purpose Processors</head><p>Using the eight-bit PE 128-bit stripe with eight registers we compare the performance of PipeRench to that of a general-purpose processor, the UltraSparc-II running at 300 Mhz. Figure <ref type="figure" target="#fig_7">12</ref> shows the raw speedup for all kernels. This performance is hard to achieve with PipeRench connected via the I/O bus, but a large fraction of the raw speedup is achievable.</p><p>Table <ref type="table" target="#tab_3">1</ref> shows the speedup from using PipeRench versus doing the entire application on the main processor. For PGP, we replace code for IDEA (accounting for 12% of the application) with invocations of PipeRench, reducing the time for this portion of the code to zero and yielding an average speedup of almost 12%. For JPEG, by running the twodimensional DCT kernel on PipeRench, we obtain an average improvement of about 7.2%. We also find that the PCI bus imposes no serious bottlenecks on the performance of these applications.  tors for media-centric computing workloads. The lineage of these systems derives from either FPGAs or existing computer architectures. Those decended from FPGAs are termed "reconfigurable computing systems", and include PRISC <ref type="bibr" target="#b18">[18]</ref>, DISC <ref type="bibr" target="#b25">[25]</ref>, NAPA <ref type="bibr" target="#b19">[19]</ref>, GARP <ref type="bibr" target="#b13">[13]</ref>, Chimaera <ref type="bibr" target="#b12">[12]</ref>, One-Chip <ref type="bibr" target="#b26">[26]</ref>, RAW <ref type="bibr" target="#b23">[23]</ref>, and RaPiD <ref type="bibr" target="#b8">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>None of these reconfigurable computing systems support an architectural abstraction like virtual hardware. In every case, the compiler must be aware of all the system constraints, and if it violates any constraint, it has failed. This makes compilation difficult, slow, and unpredictable. Furthermore, there is no facility in these architectures for forward-compatibility, so that every application needs to be compiled for every new chip. PipeRench offers hardware virtualization, forward compatibility, and easier compilation. Like most of the aforementioned architectures, PipeRench differs from FPGAs in that its basic word size is more than one or two bits and that its interconnect is less general and more efficient for computation. PipeRench addresses many of the problems faced by other computer architectures. We focus on uniprocessor systems because PipeRench exploits fine-grained parallelism. The most insightful comparisons are to MMX, VLIW, and vector machines.</p><p>The mismatch between application data size and native operating data size has been addressed by extending the ISAs of microprocessors to allow a wide data path to be split into multiple parallel data paths, as in Intel's MMX <ref type="bibr" target="#b17">[17]</ref>. Obtaining SIMD parallelism to utilize the parallel data paths is nontrivial, and works only for very regular computations where the cost of data alignment does not overwhelm the gain in parallelism. PipeRench has a rich interconnect to provide for alignment and allows PEs to have different configurations so that parallelism need not be SIMD.</p><p>VLIW architectures are designed to exploit dataflow parallelism that can be determined at compile time <ref type="bibr" target="#b7">[7]</ref>. VLIWs have extremely high instruction bandwidth demands. A single PipeRench stripe is similar to a VLIW processor using many small, simple functional units. But in PipeRench, after the stripe is configured, it is used to perform the same computation on a large data set, thereby amortizing the instructions over more data.</p><p>The instruction bandwidth issue has been addressed by vector microprocessors such as T0 <ref type="bibr" target="#b24">[24]</ref> and IRAM <ref type="bibr" target="#b14">[14]</ref>. The problem with vector architectures is that the vector register file is a physical or logical bottleneck that limits scalability. Allocating additional functional units in a vector processor requires an additional port on the vector register file. The physical bottleneck of the register file can be ameliorated by providing direct forwarding paths to allow chained operations to bypass the register file, as in T0 <ref type="bibr" target="#b24">[24]</ref>. This places large demands on the issue hardware. A logical bottleneck is caused by the limited namespace of the register file. This can be addressed by implementing register renaming to avoid false dependencies. Thus, vector microprocessors are subject to the same complexities in issue and control hardware design as modern superscalar processors. All connections in PipeRench are local, and there is no central logical or physical bottleneck. Therefore, the number of functional units can grow without increasing the complexity of the issue and control hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Future Work and Conclusions</head><p>In this paper we have described a new reconfigurable computing architecture, PipeRench, which emphasizes performance on future computing workloads. PipeRench uses pipelined reconfiguration to overcome many of the difficulties faced by previous attempts to use reconfigurable computing to tackle these important applications. PipeRench enables fast, robust compilers; supports forward compatibility; and virtualizes hardware, removing the fixed size constraint present in other fabrics. As a result, the designer base is broadened, development cycles are shortened, and application developers can amortize the cost of development over multiple process generations.</p><p>We first examined computational density of the fabric, by automatically synthesizing hardware based on a number of architectural parameters, including: size of the PE, the number of PEs, and the number of registers. Raw computational density is relatively flat across the space of architectures. The architectural parameters could only be tuned when we had a retargetable compiler and could measure the amount of exploitable computational power in the fabric.</p><p>Using the compiler and hardware synthesis flow in tandem, we found that PEs with bit-widths of eight are the best compromise between flexibility and efficiency across a broad range of kernels. When these PEs are arranged in moderately wide stripes (e.g. 128 bits wide) we can obtain significant performance improvements over generalpurpose processors, in some cases achieving improvement of two orders of magnitude. These performance numbers are conservative. Both hardware performance and compiler efficiency can be significantly optimized.</p><p>We are currently building a PCI-based board that will include one or more PipeRench chips. Although PipeRench is currently being built into a system as an attached processor, we are examining how to move it closer to the processor. We expect that just as the computing demands of the past decades forced floating-point processors to become floating-point units, the computing workloads of the near future will cause PipeRench to move from an attached processor to reconfigurable unit.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Performance on 8-bit FIR filters: PipeRench, Xilinx FPGA using parallel and serial arithmetic, and Texas Instruments DSP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Pipeline Reconfiguration. This diagram shows the process of virtualizing a five-stage pipeline on a three-stage device.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. PipeRench Architecture: PEs and interconnect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Complete architectural class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Computational density.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. The harmonic mean of the throughput for all fabric parameters as a function of registers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. The throughput for various kernels on a 100MHz PipeRench. The kernels use up to 8 registers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Speedup of eigth-bit PE, eight registers per PE, 128-bit wide stripe.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1, 2, CPU L2 L1 Main Memory Memory Bus I/O Bus Reconfigurable Fabric</head><label></label><figDesc></figDesc><table><row><cell>Functional Unit</cell></row><row><cell>5GB/sec</cell></row><row><cell>Tightly Coupled</cell></row><row><cell>Coproccessor</cell></row><row><cell>1.3GB/sec</cell></row><row><cell>800MB/sec</cell></row><row><cell>Loosely Coupled</cell></row><row><cell>Attached processor</cell></row><row><cell>133MB/sec</cell></row><row><cell>Figure 4. Possible locations for reconfigurable fabric</cell></row><row><cell>in memory hierarchy. Bandwidth figures are typical</cell></row><row><cell>for a 300 MHz Sun UltraSPARC-II.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Speedups for PGP and JPEG using a 100 MHz 128-bit 53-stripe PipeRench on a 32-bit 33 MHz PCI bus compared to a 330 Mhz UltraSparc-II.</figDesc><table><row><cell>Numerous other architectural research efforts are fo-</cell></row><row><cell>cused on efficiently harnessing huge numbers of transis-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">By limiting the set of physical stripes that may hold a particular virtual stripe one can eliminate the global busses. This reduces utilization, but may increase clock frequency sufficiently to make it worthwhile.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head><p>The authors wish thank the reviewers for the helpful comments. This work was supported by DARPA contract DABT63-96-C-0083. We also received financial support from Altera Corporation, and technical support from STMicroelectronics.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PAM programming environments: Practice and experience</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Touati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on FPGAs for Custom Computing Machines</title>
				<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Buell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Pocek</surname></persName>
		</editor>
		<meeting>IEEE Workshop on FPGAs for Custom Computing Machines<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-04">Apr. 1994</date>
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fugue for MMX</title>
		<author>
			<persName><forename type="first">J</forename><surname>Blinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="page" from="88" to="93" />
			<date type="published" when="1997-04">March-April 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast compilation for pipelined reconfigurable fabrics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999</title>
				<meeting>the 1999</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">ACM/SIGDA Seventh International Symposium on Field Programmable Gate Arrays (FPGA &apos;99)</title>
				<meeting><address><addrLine>Montery, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-02">Feb. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">SPLASH2: FPGAs in a custom computing machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Buell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Athanas</surname></persName>
		</author>
		<imprint>
			<date>196</date>
			<publisher>AW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Managing pipeline-reconfigurable FPGAs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cadambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schmit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 ACM/SIGDA Sixth International Symposium on Field Programmable Gate Arrays</title>
				<meeting>the 1998 ACM/SIGDA Sixth International Symposium on Field Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="1998-02">February 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A datapath oriented architecture for FPGAs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cherepacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International ACM/SIGDA Workshop on Field Programmable Gate Arrays</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A VLIW architecture for a trace scheduling compiler</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Nix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>O'donenell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Papworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Rodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ASPLOS-II</title>
				<meeting>ASPLOS-II</meeting>
		<imprint>
			<date type="published" when="1987-03">Mar. 1987</date>
			<biblScope unit="page" from="180" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Specifying and compiling applications for RaPiD</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cronquist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ebling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on FPGAs for Custom Computing Machines</title>
				<editor>
			<persName><forename type="first">K</forename><surname>Pocek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</editor>
		<meeting>IEEE Workshop on FPGAs for Custom Computing Machines<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998-04">Apr. 1998</date>
			<biblScope unit="page" from="116" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Reconfigurable Architectures for General-Purpose Computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dehon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-09">September 1996</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How multimedia workloads will change processor design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Diefendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dubey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="43" to="45" />
			<date type="published" when="1997-09">September 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The roles of FPGAs in reprogrammable systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hauck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
				<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998-04">Apr. 1998</date>
			<biblScope unit="page" from="615" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Chimaera reconfigurable functional unit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hauck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Fry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hosler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on FPGAs for Custom Computing Machines (FCCM &apos;97)</title>
				<imprint>
			<date type="published" when="1997-04">April 1997</date>
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Garp: A MIPS processor with a reconfigurable coprocessor</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wawrzynek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on FPGAs for Custom Computing Machines</title>
				<imprint>
			<date type="published" when="1997-04">April 1997</date>
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Perissakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cardwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Golbus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gribstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Keeton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Treuhaft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yelick</surname></persName>
		</author>
		<title level="m">Scalable processors in the billion-transistor era: IRAM. IEEE Computer</title>
				<imprint>
			<date type="published" when="1997-09">September 1997</date>
			<biblScope unit="page" from="75" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Timimg sensitivity stressmark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno>CDRL A001</idno>
		<ptr target="http://www.htc.honeywell.com/projects/acsbench/" />
		<imprint>
			<date type="published" when="1997-01">January 1997</date>
			<publisher>Honeywell, Inc</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Practical fast 1-d dct algorithms with 11 multiplications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Loeffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ligtenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moschytz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Acoustics Speech, and Signal Processing 1989 (ICASSP &apos;89)</title>
				<meeting>International Conference on Acoustics Speech, and Signal essing 1989 (ICASSP &apos;89)</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="9880" to="9991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Intel MMX for multimedia PCs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wilkie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Weiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="38" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A high-performance microarchitecture with hardware-programmable functional units</title>
		<author>
			<persName><forename type="first">R</forename><surname>Razdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-27</title>
				<imprint>
			<date type="published" when="1994-11">November 1994</date>
			<biblScope unit="page" from="172" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The NAPA adaptive processing architecture</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Landguth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Garverick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gomersall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gokhale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on FPGAs for Custom Computing Machines (FCCM &apos;98)</title>
				<imprint>
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Incremental reconfiguration for pipelined applications</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schmit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on FPGAs for Custom Computing Machines</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Pocek</surname></persName>
		</editor>
		<meeting>IEEE Workshop on FPGAs for Custom Computing Machines<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-04">Apr. 1997</date>
			<biblScope unit="page" from="47" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The IDEA encryption algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schneier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr. Dobb&apos;s Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="1993-12">December 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Configurable computing solutions for automatic target recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Villasenor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schoner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on FPGAs for Custom Computing Machines</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Arnold</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Pocek</surname></persName>
		</editor>
		<meeting>IEEE Workshop on FPGAs for Custom Computing Machines<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-04">Apr. 1996</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Baring it all to software: Raw machines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Waingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srikrishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="page" from="86" to="93" />
			<date type="published" when="1997-09">September 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spert-II: A vector microprocessor system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wawrzynek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1996-03">March 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A dynamic instruction set computer</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wirthlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Hutchings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on FPGAs for Custom Computing Machines</title>
				<editor>
			<persName><forename type="first">P</forename><surname>Athanas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Pocek</surname></persName>
		</editor>
		<meeting>IEEE Workshop on FPGAs for Custom Computing Machines<address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-04">Apr. 1995</date>
			<biblScope unit="page" from="99" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">OneChip: An FPGA processor with reconfigurable logic</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wittig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on FPGAs for Custom Computing Machines</title>
				<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
