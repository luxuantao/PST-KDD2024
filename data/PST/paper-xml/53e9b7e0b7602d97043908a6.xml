<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Breaking out of the Box of Recommendations: From Items to Packages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Min</forename><surname>Xie</surname></persName>
							<email>minxie@cs.ubc.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Univ. of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laks</forename><forename type="middle">V S</forename><surname>Lakshmanan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Univ. of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Wood</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Dept. of CS and Inf. Syst</orgName>
								<address>
									<settlement>Birkbeck</settlement>
									<country>U. of London</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Breaking out of the Box of Recommendations: From Items to Packages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C99D0E0EB79A4A9439DA03C1A964E3D4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval -Information Filtering Algorithms</term>
					<term>Theory Recommendation Algorithms</term>
					<term>Optimization</term>
					<term>Top-k Query Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Classical recommender systems provide users with a list of recommendations where each recommendation consists of a single item, e.g., a book or DVD. However, several applications can benefit from a system capable of recommending packages of items, in the form of sets. Sample applications include travel planning with a limited budget (price or time) and twitter users wanting to select worthwhile tweeters to follow given that they can deal with only a bounded number of tweets. In these contexts, there is a need for a system that can recommend top-k packages for the user to choose from.</p><p>Motivated by these applications, we consider composite recommendations, where each recommendation comprises a set of items. Each item has both a value (rating) and a cost associated with it, and the user specifies a maximum total cost (budget) for any recommended set of items. Our composite recommender system has access to one or more component recommender systems focusing on different domains, as well as to information sources which can provide the cost associated with each item. Because the problem of generating the top recommendation (package) is NP-complete, we devise several approximation algorithms for generating topk packages as recommendations. We analyze their efficiency as well as approximation quality. Finally, using two real and two synthetic data sets, we subject our algorithms to thorough experimentation and empirical analysis. Our findings attest to the efficiency and quality of our approximation algorithms for top-k packages compared to exact algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Recommender systems (RecSys) have become popular and have become an essential driver of many applications including web services <ref type="bibr" target="#b1">[2]</ref>. However, classical RecSys provide recommendations consisting of single items, e.g., books or DVDs. Several applications can benefit from a system capable of recommending packages of items, in the form of sets. For example, in trip planning, a user is interested in suggestions for places to visit, or points of interest (POI). There may be a cost to visiting each place (time, price, etc.). Optionally, there may be a notion of compatibility among items in a set, modeled in the form of constraints: e.g., "no more than 3 museums in a package", "not more than two parks", "the total distance covered in visiting all POIs in a package should be ≤ 10 km." etc. The user may have a limited budget and is interested in suggestions of compatible sets of POIs such that the cost of each set is under budget and its value (as judged from ratings) is as high as possible. In these applications, there is a natural need for top-k recommendation packages for the user to choose from. Some so-called "third generation" travel planning web sites, such as NileGuide<ref type="foot" target="#foot_0">1</ref> and YourTour<ref type="foot" target="#foot_1">2</ref> , are starting to provide certain of these features, although in a limited form.</p><p>As another application, in social networks like twitter, one of the important challenges is helping users with recommendations for tweeters to follow, based on the topics of their interest <ref type="foot" target="#foot_2">3</ref> . Tweeters are ranked based on how influential they are <ref type="bibr" target="#b19">[20]</ref> and currently any new user is presented with a list of influential tweeters on each topic from which they manually choose tweeters they would like to follow 3 . To automate tweeter recommendation, a tweeter's influence score can be treated as their value and the frequency with which they tweet as their cost. Compatibility may correspond to the constraint that a given set of topics should be covered. Since a user can only deal with a bounded number of tweets in a day, given a user's topics of interest, it would be useful to select compatible sets of tweeters to follow such that their total influence score is maximized and the total cost is below a budget. Once again, it would be beneficial to give the user choice by presenting them with the top-k sets of recommended tweeters to follow. We also note that some newly founded startups like Followformation<ref type="foot" target="#foot_3">4</ref> are beginning to provide services on recommending to users the top-k influential tweeters in a specific domain.</p><p>Motivated by these applications, we consider composite recommendations, where each recommendation comprises a set of items. Each item has both a value (rating or score) and a cost associated with it, and the user specifies a maximum total cost (budget) for any recommended set of items. Our composite recommender system consists of one or more recommender systems focusing on different domains. These component RecSys serve (i.e., recommend) top items in nonincreasing order of their value (explicit or predicted ratings). In addition, our composite system also has access to information sources (which could be databases or web services) which provide the cost associated with each item.</p><p>In our setting, the problem of generating the top recommendation (package) is NP-complete as it models the Knapsack problem <ref type="bibr" target="#b9">[10]</ref>. Because of this and the fact that we expect the component recommender systems to provide ratings for large numbers of items and access to these ratings can be relatively expensive, 5 we devise approximation algorithms for generating top-k packages as recommendations.</p><p>Other researchers have considered complex or composite recommendations. CARD <ref type="bibr" target="#b3">[4]</ref> and FlexRecs <ref type="bibr" target="#b11">[12]</ref> are comprehensive frameworks in which users can specify their recommendation preferences using relational query languages extended with additional features or operators. In contrast, we are concerned with developing efficient algorithms for combining recommendations from RecSys that provide only ratings for items. Closer to our work is <ref type="bibr" target="#b2">[3]</ref> which is concerned with finding packages of entities, such as holiday packages, where the entities are associated in some way. However, their packages are of fixed size, whereas we allow packages of variable size. CourseRank <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> is a system for providing course recommendations to students, based on the ratings given to courses by past students and subject to the constraints of degree requirements. While we do not capture all CourseRank constraints, in our framework we have item costs and user budgets-essential features of the application areas we consider for deployment of our system-which are not captured by CourseRank. Similarly, item costs and user budgets are not considered for team formation in <ref type="bibr" target="#b12">[13]</ref>.</p><p>In this paper, for space limitations, we restrict attention to the problem of recommending packages when there is just one component RecSys and no compatibility constraint is imposed. The problem remains intractable and still warrants approximation algorithms. We discuss in Sec. 5 how to extend our algorithms when multiple component RecSys and compatibility constraints are present.</p><p>The roadmap of the paper is as follows. After discussing related work in more detail (Sec. 2), we present the architecture of our system and give a precise definition of the problem we study (Sec. 3). We then describe the approximation algorithms we have developed for returning top-k composite recommendations (Sec. 4). We first present a 2approximation algorithm that is instance optimal <ref type="bibr" target="#b5">[6]</ref> with an optimality ratio of one. This means that any other 2approximation algorithm, that can only access items in nonincreasing order of their value, must access at least as many items as our algorithm. However, this algorithm makes repeated calls to a routine for solving exactly the problem of finding the top-rated package under budget, from those items that have been accessed from the component RecSys so far. Because this is an NP-complete problem, we then 5 Especially when the ratings need to be predicted. develop a greedy algorithm for returning top-k composite recommendations. This algorithm is also guaranteed to return a 2-approximation, but is no longer guaranteed to be instance optimal. It is interesting to note that the average value of packages returned by our approximation algorithms is higher than that returned by the exact algorithm. This is because an exact algorithm will add low-value items to a recommendation in order to maximize value. However, from a user's perspective the recommendations returned by the approximation algorithms may sometimes be preferable.</p><p>In Sec. 6 we subject our algorithms to thorough empirical analysis using two real data sets -TripAdvisor and Movie-Lens -and two synthetic data sets. We first investigate the quality of the recommendations produced by our approximation algorithms. Our findings confirm that our algorithms always produce recommendations that are 2-approximations, with many of them being close to optimal. We then compare the efficiency of our instance optimal and greedy approximation algorithms with that of an exact algorithm in terms of running time and number of items accessed. Our results indicate that our greedy algorithm is always significantly faster than the other two algorithms, while the greedy and instance optimal algorithms usually access substantially fewer items than the exact algorithm. Finally, we discuss future work and conclude the paper in Sec. 7. To the best of our knowledge, this is the first time instance optimality is established in the context of approximation algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Closest to our work is <ref type="bibr" target="#b2">[3]</ref>, where they are interested in finding top-k tuples of entities. Examples of entities include cities, hotels and airlines, while packages are tuples of entities. Instead of querying recommender systems, they query documents using keywords in order to determine entity scores. A package in their framework is of fixed size, e.g., one city, one hotel and one airline, with fixed associations among the entities essentially indicating all possible valid packages. Instead, we allow for packages (composite recommendations) of variable size, subject to a budget constraint. Associations between entities can be easily captured in our framework using the notion of compatibility of sets.</p><p>Other closely related work is <ref type="bibr" target="#b4">[5]</ref> where a novel framework is proposed to automatically generate travel itineraries from online user-generated data like picture uploads and formulate the problem of recommending travel itineraries of high quality where the travel time is under a given time budget. However, in this work, the value of each POI is determined by the number of times it is mentioned by users, whereas in our work, item value is a personalized score which comes from an underlying recommender system and accessing these items is constrained to be in value-sorted order. Unlike <ref type="bibr" target="#b4">[5]</ref>, we optimize item accesses, establish instance optimality, and provide algorithms for generating top-k packages.</p><p>CARD <ref type="bibr" target="#b3">[4]</ref> is a framework for providing top-k recommendations of composite products or services. Fine-grained control over specifying user requirements as well as how atomic costs are combined is provided by an SQL-like language extended with features for decision support. Each composite recommendation is of fixed size, making the problem simpler; thus CARD returns exact not approximate solutions.</p><p>Similarly, FlexRecs <ref type="bibr" target="#b11">[12]</ref> is a sophisticated system for defining complex recommendations from relational data. Recommendation requirements are specified by relational algebra expressions enhanced with extend, recommend and blend operators. As with <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, recommendations are of fixed size and thus solutions are exact.</p><p>In our setting of access to component RecSys (but with a restricted notion of binary boolean compatibility), the problem of finding the top-k fixed-size packages is simpler than that of finding packages of variable size; it can be solved efficiently using Rank Join <ref type="bibr" target="#b6">[7]</ref>.</p><p>CourseRank <ref type="bibr" target="#b16">[17]</ref> is a project motivated by a course planning application for students, where constraints are of the form "take ki from Si," where ki is a non-negative integer and Si is a set of courses. Similar to our work, each course in this system is associated with a score which is calculated using an underlying recommendation engine. Given a number of constraints of the form above (and others), the system finds a minimal set of courses that satisfies the requirements and has the highest score.</p><p>Later work <ref type="bibr" target="#b15">[16]</ref> extends CourseRank with prerequisite constraints, and proposes several approximation algorithms that return high-quality course recommendations which satisfy all the prerequisites. As in our work, such recommendations need not be of fixed size. However, <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> do not consider the cost of items (cf. courses) which can be important for applications like trip planning and twitter.</p><p>The problem of team formation is studied in <ref type="bibr" target="#b12">[13]</ref>. Here each person has a set of skills and pairs of people have a collaboration cost associated with them (lower cost indicates better collaboration). Given a task requiring a set of skills, the problem is to find a set of people whose skills cover those required and who have a low aggregated collaboration cost. The notion of compatibility in our framework can model their collaboration cost. Similar to CourseRank, the people (items) themselves are not rated. A further difference with our approach is that we wish to maximize the aggregate item (cf. people) ratings subject to item and compatibility costs, rather than minimize compatibility cost.</p><p>Although we do not include in our system complex constraints such as those in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>, for applications where complex constraints exist, we can leverage existing work to post-process each composite recommendation generated by our algorithms to ensure that the constraints are satisfied.</p><p>Finally, motivated by online shopping applications, <ref type="bibr" target="#b17">[18]</ref> studies the problem of recommending "satellite items" related to a given "central item" subject to a cost budget. The resulting notion of packages is quite restricted compared to our framework, and item values are not taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ARCHITECTURE AND PROBLEM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Architecture</head><p>In a traditional RecSys, users rate items based on their personal experience, and these ratings are used by the system to predict ratings for items not rated by an active user. The predicted ratings can be used to give the user a ranked recommendation (item) list.</p><p>As shown in Figure <ref type="figure" target="#fig_0">1</ref>, our composite recommendation system is composed of one or more component RecSys and has access to external sources that provide the cost of a given item. An external source can be a local database or a web service. E.g., Amazon.com can be consulted for book prices. In terms of computation, we abstract each RecSys as a system which serves items in non-increasing order of their value (rating or score) upon request. In addition, the system in-cludes a compatibility checker module, which checks whether a package satisfies compatibility constraints, if any. We assume the compatibility checker consults necessary information sources in order to verify compatibility.</p><p>The user interacts with the system by specifying a cost budget, an integer k, and optionally compatibility constraints on packages. The system finds the top-k packages of items with the highest total value such that each package has a total cost under budget and is compatible. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problem Statement</head><p>Given a set N of items and U of users, an active user u ∈ U , and item t ∈ N , we denote by vu(t) the value of item t for user u. We denote the value as v(t) when the active user is understood. A RecSys predicts v(t) when it is not available, by using the active user's past behavior and possibly that of other similar users. For t ∈ N , we denote by c(t) the cost of item t. Given a set of items R ⊂ N , we define c(R) = Σt∈R c(t) and v(R) = Σt∈R v(t). Given a cost budget B, a set of items P ⊂ N is called feasible if c(P ) ≤ B. In this paper, for space limitations, we focus on the following problem (with extensions discussed in Sec. 5):</p><p>Definition 1 (Top-k Composite Recommendations). Given an instance I of a composite recommendation system consisting of one component RecSys and an external information source, a cost budget B and an integer k, find the top-k packages P1, ..., P k such that each Pi is feasible and among all feasible packages P1, ..., P k have the k highest total values, i.e., v(P ) ≤ v(Pi) for all feasible packages P ∈ {P1, ..., P k }.</p><p>When k = 1, the top-k composite recommendation problem (CompRec) can be viewed as a variation of the classical 0/1 knapsack problem <ref type="bibr" target="#b9">[10]</ref> with the restriction that items can be accessed only in non-increasing order of their value. Without loss of generality, we assume all items have cost smaller than the cost budget B.</p><p>Note that ratings of items from the component RecSys are retrieved using sorted access, while the cost of a given item is obtained via random access. Let cs and cr be the costs associated with these accesses. Then the total access cost of processing n items is n × (cs + cr). Notice that cs and cr can be large compared to the cost of in-memory operations: for both accesses information needs to be transmitted through the Internet, and for the sorted access, v(t) may need to be computed. So, well known algorithms for knapsack which need to access all items <ref type="bibr" target="#b9">[10]</ref> may not be realistic. Thus, an efficient algorithm for top-k CompRec should minimize the total access cost, i.e., it should minimize the number of items accessed and yet ensure the top-k packages are obtained.</p><p>It can be shown that if we have no background knowledge about the cost distribution of items, in the worst case, we must access all items to find top-k packages. In order to facilitate the pruning of item accesses, we thus assume some background information about item costs is precomputed and maintained at the composite RecSys. The background cost information, which we denote generically by BG, can be a histogram collected from the external cost source or something as simple as a minimum item cost cmin. This information can be materialized in our system and be refreshed regularly by re-querying the cost source.</p><p>Our composite recommendation problem can be considered as a special case of a resource-limited knapsack problem where in addition to quality guarantee, the number of items to be accessed should also be minimized. So standard algorithms for knapsack, e.g., exact algorithms <ref type="bibr" target="#b9">[10]</ref> and approximation algorithms <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref> may not be efficient as they always need to access the entire dataset. The only known variation of knapsack which deals with resource limitation is the Online Knapsack Problem <ref type="bibr" target="#b14">[15]</ref>. However, for this problem, no access constraints are considered, only competitiveness in terms of quality is studied. And furthermore, no information about items can be inferred, which makes the problem significantly harder and difficult to approximate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">COMPOSITE RECOMMENDATIONS</head><p>In this section, we develop several approximation algorithms for top-1 CompRec, after which we extend them to handle top-k CompRec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Instance Optimal Algorithms</head><p>As identified in Section 3.2, top-1 CompRec is a variation of the 0/1 knapsack problem where the underlying items can be accessed only in non-increasing order of their value (rating). Because of the huge potential size of the sets of items and the high cost of retrieving item information from the source, it is crucial for an algorithm to find high-quality solutions while minimizing the number of items accessed. Furthermore, as the 0/1 knapsack problem is NP-Complete <ref type="bibr" target="#b9">[10]</ref>, we need to develop efficient approximation algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Top-1 Composite Recommendation</head><p>Given an instance I of top-1 CompRec, let BG denote the known background cost information and S = {t1, ..., tn} be the set of items which have been accessed or seen so far.</p><p>Let v be the value of the first accessed item, because items are accessed in the non-increasing order of their value, n • v is a trivial upperbound on the value that can be achieved by any knapsack solution for S.</p><p>For each i ∈ {1, ..., n} and v ∈ {1, ..., n • v}, let SSi,v denote a subset of {t1, ..., ti} whose total value is exactly v and whose total cost is minimized. Let C(i, v) be the cost of SSi,v (C(i, v) = ∞ if the corresponding SSi,v doesn't exist), then it is well known from previous work <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b9">10]</ref> that a pseudo-polynomial algorithm can be utilized to get the optimal knapsack solution for S by first calculating all C(i, v) using the following recursive function and then choosing the maximum value achievable by any subset SSn,v of which the total cost is bounded by budget B, i.e., max{v|C(n, v) ≤ B}.</p><formula xml:id="formula_0">C(i + 1, v) = (1) j min{C(i, v), c(ti+1) + C(i, v -v(ti+1))} if v(ti+1) ≤ v C(i, v) o t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>h e r w i s e</head><p>Let the background cost information be BG = cmin, which is the minimum cost of all items, let vmin = mint∈S v(t) be the minimum value of all accessed items, and let OP T be the true optimal solution to the underlying top-1 CompRec Instance I. We can get an upperbound V * on the value v(OP T ) of the optimal solution using the following algorithm MaxValBound. (Proofs of all lemmas and theorems can be found in [1].) Algorithm 1: MaxValBound(S, C, B, BG)</p><formula xml:id="formula_1">1 V * = B c min × vmin 2 for v ∈ {1, ..., n • v} do 3 if C(n, v) &lt; B 4 V * =max{V * , v + B-C(n,v) c min * vmin} 5 return V *</formula><p>Lemma 1. Given S, C, B, BG, the value V * returned by MaxValBound is an upperbound on v(OP T ). And V * is tight in that there exists a possible unseen item configuration for which V * is achievable by using a subset of accessed items and feasible unseen items 6 .</p><p>Given the upper bound V * on the optimal solution, we next propose a 2-approximation algorithm for top-1 Com-pRec which is guaranteed to be instance optimal (see below). The algorithm, InsOpt-CR, is shown as Algorithm 2. One item is retrieved from the source at each iteration of the algorithm (lines 3-4). After accessing this new item, we can use the pseudo-polynomial algorithm to find an optimal solution R o over the accessed itemset S (line 5). We calculate the upper bound value V * of the optimal solution using MaxValBound. If v(R o ) ≥ 1 2 ×V * , the algorithm terminates; if not, it continues to access the next item (lines 7-8). The following example shows how InsOpt-CR works.</p><p>Algorithm 2: InsOpt-CR(N , B, BG) </p><formula xml:id="formula_2">1 S ← An empty buffer 2 while TRUE do 3 t ← N .getNext() 4 S.Insert(t) 5 (R o ,C) ← OptimalKP(S, B) 6 V * = MaxValBound(S,C,B,BG) 7 if v(R o ) ≥ 1 2 × V * 8 r</formula><formula xml:id="formula_3">v(R o ) ≥ 1 2 × V * .</formula><p>Given a top-1 CompRec instance I with optimal solution OP T , because</p><formula xml:id="formula_4">V * ≥ v(OP T ), if v(R o ) ≥ 1 2 ×V * , then v(R o ) ≥ 1</formula><p>2 ×OP T , so OptIns-CR returns a correct 2-approximation of OPT. 6 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An unseen item t is feasible iff. v(t) ≤ vmin and c(t) ≥ cmin</head><p>To analyze the optimality of our proposed algorithm, we utilize the notion of instance optimality proposed in <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2. Instance Optimality: Let A be a class of algorithms, and let I be a class of problem instances. Given a non-negative cost measure cost(A, I) of running algorithm A over I, an algorithm A ∈ A is instance optimal over A and I if for every A ∈ A and every I ∈ I we have cost(A, I) ≤ c • cost(A , I)</head><p>+ c , for constants c and c . Constant c is called the optimality ratio.</p><p>To prove the instance optimality of InsOpt-CR, we first show the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2. Given any top-1 CompRec instance I and any 2-approximation algorithm A with background cost information BG and the same access constraints as InsOpt-CR, A must read at least as many items as InsOpt-CR.</head><p>Theorem 1. Let I be the class of all top-1 CompRec instances, and A be the class of all possible 2-approximation algorithms that are constrained to access items in non-increasing order of their value. Given the same background cost information BG, InsOpt-CR is instance optimal over A and I with an optimality ratio of one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Top-k Composite Recommendations</head><p>In addition to the best composite recommendation, it is often useful to provide the user with the top-k composite recommendations, where k is a small constant. In this section, we extend the algorithm proposed in Section 4.1.1 to one that returns the top-k composite recommendations. Similar to the top-1 case, due to the hardness of the underlying problem, we seek an efficient approximation algorithm which can give us high quality recommendations.</p><p>Given an instance I of top-k CompRec, assume R I is the set of all feasible composite recommendations, i.e., R I = {R | R ⊆ N ∧ c(R) ≤ B}). Following Fagin et al. <ref type="bibr" target="#b5">[6]</ref> and Kimelfeld et al. <ref type="bibr" target="#b10">[11]</ref>, we define an α-approximation of the top-k composite recommendations to be any set R k of min(k, |R I |) composite recommendations, such that, for all</p><formula xml:id="formula_5">R ∈ R k and R ∈ R I \R k , v(R) ≥ 1 α × v(R ).</formula><p>To produce top-k composite recommendations, we will apply Lawler's procedure to InsOpt-CR. Lawler's procedure <ref type="bibr" target="#b13">[14]</ref> is a general technique for enumerating optimal top-k answers to an optimization problem, which relies on an efficient algorithm to find the optimal solution to the problem.</p><p>Let InsOpt-CR-Topk be the InsOpt-CR algorithm modified using Lawler's procedure. All we need to change is that instead of returning the 2-approximation solution found in Algorithm 2 (line 8), we enumerate at this point all possible 2-approximation solutions using Lawler's procedure. If the number of 2-approximation solutions is at least k, then we can report the top-k packages found; otherwise, we continue accessing the next item.</p><p>In InsOpt-CR, the enumeration of all possible 2-approximation solutions is straightforward. Since we know the upper bound V * , we can simply utilize Lawler's procedure to enumerate candidate packages which are under cost budget and have aggregated value of at least half of V * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3. Given any instance I of top-k CompRec and any 2-approximation algorithm A with the same background cost information BG and access constraints as InsOpt-CR-Topk, A must read as many items as InsOpt-CR-Topk.</head><p>Theorem 2. Let I be the class of all top-k CompRec instances, and A be the class of all possible 2-approximation algorithms that are constrained to access items in the nonincreasing order of their value. Given the same background cost information BG, InsOpt-CR-Topk is instance optimal over A and I with an optimality ratio of one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Greedy Algorithms</head><p>Although the instance optimal algorithms presented above guarantee to return top-k packages that are 2-approximations of the optimal packages, they rely on an exact algorithm for the knapsack problem which may lead to high computational cost. To remedy this, we propose more efficient algorithms next. Instead of using an exact algorithm to get the best package for the currently accessed set of items S, we use a simple greedy heuristic to form a high quality package R G from S and then test whether R G is globally a high quality package.</p><p>Compared with InsOpt-CR, our greedy solution Greedy-CR for top-1 CompRec needs to replace OptimalKP in InsOpt-CR with GreedyKP, which uses greedy heuristics <ref type="bibr" target="#b9">[10]</ref> to find a high quality itemset in polynomial time <ref type="foot" target="#foot_4">7</ref> , and to change R o to the greedy solution R G . Furthermore, instead of using tight upperbound calculated by MaxValBound, we need to use an untight heuristic upperbound which is calculated by the following algorithm MaxHeuristicValBound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3: MaxHeuristicValBound(S, B, BG)</head><formula xml:id="formula_6">1 τ ← v min c min 2 Sort S = {t1, . . . , tn} by value/cost ratio 3 m = max{m | v(tm) c(tm) ≥ τ ∧ c(Rm) ≤ B} 4 Rm = {t1, . . . , tm} 5 if m == n 6 V * = v(Rm) + τ * (B -c(Rm)) 7 else 8 V * = v(Rm)+max{τ, v m+1 c m+1 } * (B -c(Rm)) 9 return V *</formula><p>It follows from known results about knapsack that, similar to InsOpt-CR, Greedy-CR will always generate a correct 2approximation to the optimal solution.</p><p>However, unlike InsOpt-CR, Greedy-CR is not instance optimal among all 2-approximation algorithms with the same constraints, as the following example shows. 2 × V * . So Greedy-CR will continue accessing new items and it can be easily verified that Greedy-CR needs to access another 98 items before it stops.</p><p>We note that, in practice, cases such as the above may occur rarely. In fact, in our experimental results (Sec. 6) we observed that, on a range of datasets, Greedy-CR exhibited a very low running time while achieving similar access costs and overall result quality when compared to InsOpt-CR.</p><p>Similar to Section 4.1.2, we can easily extend Greedy-CR to Greedy-CR-Topk by using Lawler's procedure <ref type="bibr" target="#b13">[14]</ref> to enumerate all possible high quality packages after one such package is identified. However, unlike InsOpt-CR-Topk which guarantees instance optimality, here we simply use Lawler's procedure to enumerate all candidate packages using the greedy algorithm instead of the exact algorithm. Similar to <ref type="bibr" target="#b10">[11]</ref>, we show in the following theorem that for top-k Com-pRec, if an α-approximation algorithm is utilized in Lawler's procedure instead of the exact algorithm which finds the optimal solution, we get an α-approximation to the top-k composite recommendations.</p><p>Theorem 3. Given an instance I of top-k CompRec, any α-approximation algorithm A for top-1 CompRec can be utilized with Lawler's procedure to generate a set R k of composite recommendations which is an α-approximation to the optimal set of top-k composite recommendations.</p><p>So the quality of the packages generated by the resulting enumeration process can be guaranteed. In this enumeration process, given a candidate package, we use the greedy algorithm to get the next candidate package for each sub-search space in Lawler's procedure, and if all of them are not guaranteed to be 2-approximations, the enumeration will stop.</p><p>However, similar to Greedy-CR, it is obvious that Greedy-CR-Topk is not instance optimal. We note that, in practice, the difference between the results generated by InsOpt-CR-Topk and Greedy-CR-Topk (in terms of the aggregate values of packages generated) may be very small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DISCUSSION</head><p>As mentioned in Sec. 3, our framework includes the notion of a package satisfying compatibility constraints. E.g., for trip planning, the user may require the returned package to contain no more than 3 museums.</p><p>To capture these constraints in our algorithms, we can define a Boolean compatibility function C over the packages under consideration. Given a package P , C(P ) = true iff all constraints on items in p are satisfied. We can add a call to C in InsOpt-CR-Topk and Greedy-CR-Topk after each candidate package has been found. If the package fails the compatibility check, we just discard it and search for the next candidate package. In terms of access cost, it can be easily verified that the modified InsOpt-CR-Topk algorithm is still instance optimal.</p><p>It is worth noting that the Boolean compatibility function defined here allows for greater generality than the constraints studied in previous work such as <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17]</ref>. However, depending on the application needs, for scenarios where only one specific type of constraint is considered, e.g., having one item from each of 3 predefined categories, more efficient algorithms like Rank Join <ref type="bibr" target="#b6">[7]</ref> can be leveraged.</p><p>Furthermore, although in the previous algorithms we assume there is only one component recommender system, it is straightforward to combine recommendation lists from several component recommender systems by creating on-the-fly a "virtual recommendation list", e.g., select at each iteration the item which has the maximum value/rating across all recommender systems. The details will appear in the full version of the paper where efficient algorithms are given for special cases of compatibility constraints as well as compatibility constraints based on continuous functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPERIMENTS</head><p>In this section, we study the performance of our proposed algorithms based on both real and synthetic datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup and Data Sets</head><p>The goal of our experiments were: (i) evaluate the relative quality of Inst-Opt-CR and Greedy-CR compared to the optimal algorithm, in terms of both the total and average values of the top-k packages returned, and (ii) evaluate the relative efficiency of the algorithms with respect to the number of items accessed and the actual run time. All experiments were done on a Xeon 2.5GHz Quad Core Windows Server 2003 machine with 16GB RAM and a 128GB SCSI hard disk. All code is in Java using JDK/JRE 1.6.</p><p>We use four datasets in our experiments. The first dataset is from MovieLens<ref type="foot" target="#foot_5">8</ref> . We use the 10 million rating MovieLens dataset which contains 1 million ratings for 3900 movies by 6040 users. In our experiments, we used the running time of movies, obtained from IMDB <ref type="foot" target="#foot_6">9</ref> , as cost and we assume users are interested in packages of movies where the total running time is under a given budget.</p><p>TripAdvisor<ref type="foot" target="#foot_7">10</ref> is a well-known website where users can share and explore travel information. For our experiments, we crawled user rating information from places of interest (POIs) in the 10 most popular cities in the US. We exclude POIs which have one or no reviews, and the dataset contains 23658 ratings for 1393 POIs by 14562 users, so it is very sparse. <ref type="foot" target="#foot_8">11</ref> We associate with each POI in the dataset, a cost which is based on log(number of reviews) and scaled to the range of 1 to 50. The intuition of this cost function is that the more popular a POI is (in terms of number of reviews), the more likely it is to be crowded or the more likely it is for the tickets to be expensive. In practice, we may also use some existing work like <ref type="bibr" target="#b4">[5]</ref> to mine from online usergenerated itineraries other cost measures, e.g., average time users spent at each POI, average cost of visiting each POI, etc.</p><p>For the MovieLens and TripAdvisor datasets, we use a simple memory-based collaborative filtering algorithm <ref type="bibr" target="#b1">[2]</ref> <ref type="foot" target="#foot_9">12</ref> to generate predicted ratings for each user. The ratings are scaled and rounded to integers ranging from 1 to 50.</p><p>For the MovieLens dataset, we randomly selected 20 users from the 23594 user pool, and the budget for each user was fixed at 500 minutes <ref type="foot" target="#foot_10">13</ref> . For the TripAdvisor dataset, because of the sparsity of the underlying user rating matrix, we selected the 10 most active users as our sample for testing the algorithms, and set the user cost budget to 50.   We also tested our algorithms on synthetic correlated and uncorrelated datasets. For both datasets, item ratings are randomly chosen from 1 to 50. For the uncorrelated dataset, item costs are also randomly chosen from 1 to 50, but for the correlated dataset, the cost of item t is randomly chosen from min{1, v(t) -5} to v(t) + 5. In both datasets, the total number of items is 1000, and the cost budget is set to 50. For all datasets, we assume the background cost information BG is simply the global minimum item cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Quality of Recommended Packages</head><p>For each dataset, Table <ref type="table" target="#tab_0">1</ref> shows the quality of the top-5 composite recommendations returned by the optimal and approximation algorithms. We use as measures of quality the aggregated value of each package (SUM column) and the average item value of each package (AVG column).</p><p>It can be verified from Table <ref type="table" target="#tab_0">1</ref> that our approximation algorithms do indeed return top-k composite packages whose value is guaranteed to be a 2-approximation of the optimal. Furthermore, from the average item value column, it is clear that our proposed approximation algorithms often recommend packages with high average value, whereas the optimal algorithm often tries to fill the package with small cost and small value items. So by sacrificing some of these lower quality items, the proposed approximation algorithms may manage to find high quality packages much more efficiently.</p><p>To better study the overall quality of returned packages, we also adopt a modified Normalized Discounted Cumulative Gain (NDCG) <ref type="bibr">[9]</ref> to measure the quality of the top-k composite packages returned by the approximation algorithms against the optimal algorithm. Let R o = {P o 1 , . . . , P o k } be the top-k packages returned by the optimal algorithm, and R a = {P a 1 , . . . , P a k } be the top-k packages returned by the approximation algorithm. The modified NDCG score is a weighted sum of aggregated package value difference at each position of the returned top-k list, and is defined as:</p><formula xml:id="formula_7">NDCG(R o , R a ) = k X i=1 log(1 + v(P o i )-v(P a i ) v(P o i ) )</formula><p>log(1 + i) The ideal value for the modified NDCG score is 0, where the top-k packages returned have exactly the same value as the optimal top-k packages. The worst possible value for the modified NDCG score is</p><formula xml:id="formula_8">P k i=1 log 2 log(1+i)</formula><p>, where each package returned has an aggregated value of 0. In Figure <ref type="figure" target="#fig_2">2</ref>, we show for the 4 datasets the NDCG score of the top-k packages (k ranging over 1 to 10) returned by the instance optimal algorithm and the greedy algorithm. It is clear that, while having a substantial run time advantage, the greedy algorithm can achieve a very similar overall top-k package quality compared to the instance optimal algorithm. We also note that both approximation algorithms have a very small NDCG score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Efficiency Study</head><p>The running times of our algorithms on the 4 datasets are shown in Figure <ref type="figure" target="#fig_6">3 (a)-(d)</ref>, while access costs are shown in Figure <ref type="figure" target="#fig_6">3</ref> (e)-(h). For MovieLens, TripAdvisor and the uncorrelated dataset, it can be seen that on average the greedy algorithm Greedy-CR-Topk has excellent performance in terms of both running time and access cost. The instance optimal algorithm InsOpt-CR-Topk also has low access cost, but its running time grows very quickly with k since it needs to solve exactly many instances of knapsack, restricted to the accessed items.</p><p>As can be seen in Figure <ref type="figure" target="#fig_6">3</ref> (h), the only dataset where both the greedy and instance optimal algorithms have a high access cost is the correlated dataset (but notice that the greedy algorithm still has good running time). The reason for this  Thus the information it provides on the unseen items is very coarse. In practice, one solution to this might be to obtain more precise background cost information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>Motivated by applications in trip planning and in finding the most effective tweeters to follow, we studied the problem of recommending packages consisting of sets of items. Our composite recommender system has one or more component RecSys, which serve item recommendations in nonincreasing order of their value. We proposed the problem of generating top-k package recommendations that are compatible and are under a cost budget, where a cost is incurred by visiting each recommended item and the budget and compatibility constraints are user specified. We focused on the case where there are no compatibility constraints and there is only one component RecSys. The problem is NPcomplete since it is a variant of the Knapsack problem with the restriction that items need to be accessed in value-sorted order. So we developed two 2-approximation algorithms that are designed to minimize the number of items accessed. The first of these, InsOpt-CR-Topk, is instance optimal in a strong sense: every 2-approximation algorithm for the problem must access at least as many items as this algorithm. The second of these, Greedy-CR-Topk, is not guaranteed to be instance optimal, but is much faster. We experimentally evaluated the performance of the algorithms and showed that in terms of the quality of the top-k packages returned both algorithms are close to each other and deliver high quality packages; in terms of the number of items accessed Greedy-CR-Topk is very close to InsOpt-CR-Topk, but in terms of running time, Greedy-CR-Topk is much faster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>e t u r nR o Example 1 .</head><label>1</label><figDesc>Let I = {t1, t2, . . . , tn} be a top-1 Com-pRec instance, where v(t1) = v(t2) = 101, c(t1) = c(t2) = 100, for i = 3, . . . , 101, v(ti) = c(ti) = 1, and for i = 102, . . . , n, v(ti) = 1 and c(ti) = 0.5. Let B = 199. Clearly, BG = cmin = 0.5. After accessing the first 101 items, S = {t1, . . . , t101}, R o = {t1} ∪ {t3, . . . , t101}, v(R o ) = 200. Because cmin = 0.5 and vmin = 1, we can calculate V * = 398 and InsOpt-CR will stop since</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Example 2 .</head><label>2</label><figDesc>Let I = {t1, t2, . . . , tn} be a top-1 CompRec instance, where v(t1) = v(t2) = 101, c(t1) = c(t2) = 100, for i = 3, . . . , 101, v(ti) = c(ti) = 1, and for i = 102, . . . , n, v(ti) = 1 and c(ti) = 0.5. Let B = 199, BG = cmin = 0.5 and approximation ratio α = 2. From Example 1, we know that after accessing the first 101 items, S = {t1, . . . , t101}, v(R o ) = 200, V * = 398 and InsOpt-CR will stop. However, at this moment R G = {t1}, and v(R G ) = 101 &lt; 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: NDCG Score for Top-k Packages</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a)-(d) Running Time for Different Datasets; (e)-(h) Access Cost for Different Datasets is that, for the correlated dataset, the global minimum cost corresponds only to items which also have the least value.Thus the information it provides on the unseen items is very coarse. In practice, one solution to this might be to obtain more precise background cost information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Quality Comparison for Different Composite Recommendation Algorithms</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="8">1st Package 2nd Package 3rd Package 4th Package</cell><cell cols="2">5st Package</cell></row><row><cell></cell><cell></cell><cell cols="10">SUM AVG SUM AVG SUM AVG SUM AVG SUM AVG</cell></row><row><cell></cell><cell>Optimal</cell><cell>427</cell><cell>46.7</cell><cell>426</cell><cell>46.6</cell><cell>425</cell><cell>46.7</cell><cell>424</cell><cell>46.7</cell><cell>423</cell><cell>46.6</cell></row><row><cell>MovieLens</cell><cell>InsOpt-CR-Topk</cell><cell>386</cell><cell>47.5</cell><cell>385</cell><cell>47.4</cell><cell>385</cell><cell>47.3</cell><cell>384</cell><cell>47.2</cell><cell>383</cell><cell>47.2</cell></row><row><cell></cell><cell>Greedy-CR-Topk</cell><cell>384</cell><cell>47</cell><cell>381</cell><cell>47</cell><cell>380</cell><cell>46.8</cell><cell>379</cell><cell>46.7</cell><cell>379</cell><cell>46.7</cell></row><row><cell></cell><cell>Optimal</cell><cell>300</cell><cell>50</cell><cell>300</cell><cell>50</cell><cell>300</cell><cell>50</cell><cell>300</cell><cell>50</cell><cell>300</cell><cell>50</cell></row><row><cell>TripAdvisor</cell><cell>InsOpt-CR-Topk</cell><cell>185</cell><cell>50</cell><cell>175</cell><cell>50</cell><cell>165</cell><cell>50</cell><cell>160</cell><cell>50</cell><cell>155</cell><cell>50</cell></row><row><cell></cell><cell>Greedy-CR-Topk</cell><cell>220</cell><cell>50</cell><cell>210</cell><cell>50</cell><cell>210</cell><cell>50</cell><cell>205</cell><cell>50</cell><cell>205</cell><cell>50</cell></row><row><cell></cell><cell>Optimal</cell><cell>1092</cell><cell>36.4</cell><cell>1091</cell><cell>36.4</cell><cell>1090</cell><cell>36.3</cell><cell>1090</cell><cell>36.3</cell><cell>1089</cell><cell>36.5</cell></row><row><cell cols="2">Uncorrelated Data InsOpt-CR-Topk</cell><cell>929</cell><cell>43.6</cell><cell>926</cell><cell>43.6</cell><cell>925</cell><cell>43.6</cell><cell>925</cell><cell>43.6</cell><cell>924</cell><cell>43.5</cell></row><row><cell></cell><cell>Greedy-CR-Topk</cell><cell>945</cell><cell>42.9</cell><cell>939</cell><cell>42.8</cell><cell>938</cell><cell>42.8</cell><cell>936</cell><cell>42.7</cell><cell>931</cell><cell>42.8</cell></row><row><cell></cell><cell>Optimal</cell><cell>122</cell><cell>5.3</cell><cell>122</cell><cell>5.2</cell><cell>122</cell><cell>5.2</cell><cell>122</cell><cell>5.1</cell><cell>122</cell><cell>5.2</cell></row><row><cell>Correlated Data</cell><cell>InsOpt-CR-Topk</cell><cell>110</cell><cell>6.7</cell><cell>110</cell><cell>6.7</cell><cell>110</cell><cell>6.7</cell><cell>110</cell><cell>6.6</cell><cell>110</cell><cell>6.5</cell></row><row><cell></cell><cell>Greedy-CR-Topk</cell><cell>110</cell><cell>6.6</cell><cell>110</cell><cell>6.6</cell><cell>109</cell><cell>7.6</cell><cell>109</cell><cell>6.5</cell><cell>109</cell><cell>7.15</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.nileguide.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.yourtour.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://blog.twitter.com/2010/01/power-of-suggestions.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>http://followformation.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>Note that any approximation algorithm for knapsack<ref type="bibr" target="#b9">[10]</ref> can be plugged in here while correctness of the resulting algorithm and the instance optimality result won't change.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>http://www.movielens.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6"><p>http://www.imdb.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7"><p>http://www.tripadvisor.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_8"><p>Pruning more aggressively rendered it too small.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_9"><p>Our algorithms don't depend on a specific recommendation algorithm; in practice, our framework assumes ratings come from existing recommender systems.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_10"><p>For all datasets, we tested our algorithms under various cost budgets with very similar results, so other budgets are omitted for lack of space.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENTS</head><p>Part of this work was done during Peter Wood's visit to UBC in January, 2010. This research was supported by a grant from NSERC (Canada).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TKDE</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ranking objects based on relationships and fixed associations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="910" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CARD: a decision-guidance framework and application for recommending composite alternatives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brodsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Henshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="171" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic construction of travel itineraries using social breadcrumbs</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amer-Yahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Golbandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lempel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Hypertext</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="614" to="656" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust and efficient algorithms for rank join evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Finger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="415" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast approximation algorithms for the knapsack and sum of subset problems</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">H</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="463" to="468" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Knapsack Problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kellerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Pferschy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pisinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Finding and approximating top-k answers in keyword proximity search</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kimelfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sagiv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">FlexRecs: expressing and combining flexible recommendations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koutrika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bercovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="745" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finding a team of experts in social networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Terzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="467" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A procedure for computing the k best solutions to discrete optimization problems and its application to the shortest path problem</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Man. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="401" to="405" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic on-line knapsack problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marchetti-Spaccamela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vercellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="73" to="104" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recommendations with prerequisites</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Recommender Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="353" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Recommendation systems with complex constraints: A CourseRank perspective</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Venetis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Constructing and exploring composite items</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amer-Yahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Approximation Algorithms</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TwitterRank: finding topic-sensitive influential twitterers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-P</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
