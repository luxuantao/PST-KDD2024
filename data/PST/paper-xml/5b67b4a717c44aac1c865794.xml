<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structured AutoEncoders for Subspace Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member IEEE</roleName><forename type="first">Xi</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shijie</forename><surname>Xiao</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Wei-Yun</forename><forename type="middle">Y</forename><surname>Yau</surname></persName>
							<email>wyyau@i2r.a-star.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Songfan</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><surname>Peng</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<postCode>610065</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>119077</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Institute for Infocomm Research</orgName>
								<orgName type="institution">A*STAR</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Institute of High Performance Computing, A*STAR</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">AI Lab, TAL Education Group and College of Elec-tronics and Information Engineering</orgName>
								<orgName type="institution">Sichuan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structured AutoEncoders for Subspace Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">80B16F6C5AF954866E915F63E81726C2</idno>
					<idno type="DOI">10.1109/TIP.2018.2848470</idno>
					<note type="submission">This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2018.2848470, IEEE Transactions on Image Processing This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2018.2848470, IEEE Transactions on Image Processing 2 Neural Network Structure Prior Results Clustering</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised deep learning</term>
					<term>locality preservation</term>
					<term>globality preservation</term>
					<term>spectral clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing subspace clustering methods typically employ shallow models to estimate underlying subspaces of unlabeled data points and cluster them into corresponding groups. However, due to the limited representative capacity of the employed shallow models, those methods may fail in handling realistic data without the linear subspace structure. To address this issue, we propose a novel subspace clustering approach by introducing a new deep model-Structured AutoEncoder (StructAE). The StructAE learns a set of explicit transformations to progressively map input data points into nonlinear latent spaces while preserving the local and global subspace structure. In particular, to preserve local structure, the StructAE learns representations for each data point by minimizing reconstruction error w.r.t. itself. To preserve global structure, the StructAE incorporates a prior structured information by encouraging the learned representation to preserve specified reconstruction patterns over the entire data set. To the best of our knowledge, StructAE is one of first deep subspace clustering approaches. Extensive experiments show that the proposed StructAE significantly outperforms 15 state-of-the-art subspace clustering approaches in terms of five evaluation metrics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S UBSPACE clustering aims at seeking a collection of implicit subspaces to fit a given unlabeled data set and segmenting them into different groups <ref type="bibr">[1]</ref>. During past years, spectral clustering based approaches <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref> have achieved remarkable performance, which are conducted in two steps: 1) building an affinity matrix (i.e., similarity graph) C to describe the affinity of data points, where C ij quantizes the closeness between data points x i and x j ; 2) clustering data by grouping the eigenvectors of L = D -1 2 AD -1 2 . Here, L is termed as graph Laplacian. The diagonal matrix D is with the entry D ii = j A ij and A = |C| + |C T |. In general, the performance of these approaches critically depends on the quality of A.</p><p>Although those subspace clustering approaches <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b20">[21]</ref> have achieved encouraging performance, we found that they may suffer from some limitations as follows. First, most of existing algorithms strive to build the affinity matrix A but ignore obtaining a good representation using A. Actually, almost all of them directly use top eigenvectors (w.r.t. largest eigenvalues) of L as the low-dimensional data representation.</p><p>In essence, such a method is exactly Laplacian Eigenmap (LE) <ref type="bibr" target="#b21">[22]</ref>. In other words, those approaches achieve subspace clustering through 1) building an affinity matrix using the selfexpression, 2) getting low dimensional representations of X by performing LE on the affinity matrix, and 3) obtaining clustering membership by conducting the k-means algorithm on the representations. Until now, it is still an open and challenging issue whether there is a better way to embed the affinity matrix into low-dimensional spaces and discover the clustering membership therein. The second limitation can attribute to the linearity assumption adopted by those methods.</p><p>The assumption leads to failure in handling data that cannot be linearly reconstructed. To overcome this disadvantage, some kernel methods have been proposed, e.g., kernel low rank representation (KLRR) <ref type="bibr" target="#b22">[23]</ref> and kernel sparse subspace clustering (KSSC) <ref type="bibr" target="#b23">[24]</ref>. They obtain results by first mapping the input into a pre-specified kernel space and then performing subspace clustering therein. One disadvantage of these kernel subspace clustering methods is that their performance heavily depends on the used kernel function. In practice, however, it remains unclear to choose the appropriate kernel function. The third limitation is that those methods will suffer from out-ofsample and large scale clustering issues because they have to perform general eigen-decomposition over L of the whole data set. To solve these issue, out-of-sample and large scale extensions are required <ref type="bibr" target="#b18">[19]</ref>, usually at the cost of clustering quality.</p><p>From the above, ones could conclude that data representation plays an important role in subspace clustering. Motivated by the huge success achieved by deep representation learning <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b28">[29]</ref>, we propose a new deep subspace clustering method, namely, Structured AutoEncoder (StructAE) to overcome the aforementioned limitations. The proposed method achieves subspace clustering through calculating the structured reconstruction relation from raw data, training a neural network with the formulation of self-supervision based locality and self-expression based globality, and grouping the compact representation given by the propose method.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the basic idea of StructAE, which shows that StructAE significantly differs from existing subspace clustering methods. More specifically, 1) StructAE directly obtains data representation of X rather than relying on the affinity matrix A; 2) StructAE is a multi-layer nonlinear model which gives a stronger ability to capture the nonlinearity of data; 3) Comparing with the stacked AutoEncoder (SAE), StructAE not only incorporates the locality for reconstructing each data point, but also considers the structured globality w.r.t. the entire data set; 4) Comparing with kernel-based approaches, StructAE offers explicit transformations and a better scalability because it does not load the entire data set into the memory; 5) StructAE is compatible with both the k-means algorithm and most of existing subspace clustering approaches. When performing k-means on the representation learned by StructAE, we theoretically show that under some mild conditions, StructAE performs like the spectral clustering. When combined with subspace clustering, StructAE can be regarded as a latent subspace clustering method like <ref type="bibr" target="#b29">[30]</ref>.</p><p>The paper is a substantial extension of our conference work <ref type="bibr">[31]</ref> with further improvements given below. First, we design a new algorithm by incorporating 2 -norm based structure prior besides 1 -norm based sparsity. Second, we present theoretical analysis to show the connections of our StructAE with some existing methods including spectral clustering <ref type="bibr" target="#b2">[3]</ref>, sparse subspace clustering (SSC) <ref type="bibr" target="#b6">[7]</ref>, low rank representation (LRR) <ref type="bibr" target="#b7">[8]</ref>, and their variants. Third, the experimental evaluations are totally different, which involve new baselines and new data sets. More specifically, in the conference version, YaleB and COIL20 with DSIFT and HOG features are used for comparisons. In contrast, this paper carries out experiments using YaleB, COIL20, and mnist with SDSIFT and LPQ features, as well as CIFAR10 with these four features and BF0502 raw data. Fourth, this paper presents the 2D visualization to show that our method could learn a distinct and compact representation which further boost the clustering performance. Fifth, besides the depth, we also investigate the influence of width and parameters of our method. Sixth, we evaluate the time cost of our method for training and inference for extensive investigations.</p><p>Notations: Lower-case bold letters denote column vectors and UPPER-CASE BOLD ONES denote matrices, unless otherwise stated. A T and A ij denote the transpose and an element of the matrix A, and I denotes the identity matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In recent years, many subspace clustering works <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> have devoted to building a high quality affinity matrix by using self-expression of the inputs X ∈ R d×n . More specifically, these algorithms represent X as its linear combination by:</p><formula xml:id="formula_0">min C 1 2 X -XC 2 F + λR(C),<label>(1)</label></formula><p>where d is the dimension of X, n is the number of data points,</p><p>• F denotes the Frobenius norm, C ∈ R n×n denotes the self-expression of X, and R(C) denotes a desirable prior on C. Those methods differ from each other in the choice of R(C). For example, LRR <ref type="bibr" target="#b7">[8]</ref>, SSC <ref type="bibr" target="#b6">[7]</ref>, and least square regression (LSR) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b33">[34]</ref> assume that C is low rank, sparse, and dense, respectively. Accordingly, nuclear-, 1 -, and Frobenius-norm are formulated into R(•). Once getting C, the affinity matrix is obtained via A = |C| + |C T | and clustering membership is achieved by applying spectral clustering <ref type="bibr" target="#b2">[3]</ref> over A.</p><p>To further boost the performance of subspace clustering, we propose a deep neural network based method. Our work is complementary to existing works in deep learning and subspace clustering, since it incorporates the merits (i.e. structure prior) of subspace clustering into deep neural network. Thus, it is well expected that StructAE can obtain satisfactory results in clustering unlabeled data. Unlike existing subspace clustering approaches, the proposed StructAE learns a set of nonlinear transformations to obtain the low-dimensional representation using a neural network instead of the manifold learning (e.g., LE). Benefiting from stronger nonlinearity and representational capacity of deep neural networks, our method could achieve a better clustering performance. Comparing with existing deep learning methods <ref type="bibr" target="#b34">[35]</ref>- <ref type="bibr" target="#b36">[37]</ref>, the proposed StructAE is a novel neural network for subspace clustering by preserving both globality and locality of the data set. To be exact, StructAE guarantees the globality by minimizing the reconstruction error of embedding structure prior, and the locality by minimizing the reconstruction error between each data point and the reconstruction given by our neural network. One of pioneer works in deep subspace clustering is <ref type="bibr" target="#b37">[38]</ref> which is remarkably different from our method. In brief, our method uses the structured globality including affinity (e.g., sparsity) as a prior to learn a compact representation, whereas <ref type="bibr" target="#b37">[38]</ref> learns the sparsity in the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STRUCTURED AUTOENCODERS FOR SUBSPACE CLUSTERING</head><p>StructAE consists of following three steps: first calculating the structure prior from inputs, then training a neural network to project the input into another space, and finally clustering the representation into multiple subspaces. In this section, we will first elaborate on the detail of StructAE for these three steps and then introduce how to optimize the StructAE model. Moreover, we also give some theoretical analysis to show the connections between StructAE and existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The Deep Model of StructAE</head><p>StructAE employs a neural network (M +1 layers) to perform M nonlinear transformations, where the first layer corresponds to input, the first M/2 hidden layers perform as an encoder to learn a compact representation and the last M/2 layers perform as a decoder to reconstruct the input X. For ease of presentation, some of the used notations are defined given below. We use h</p><formula xml:id="formula_1">(0) i = x i ∈ R d to denote a data point and h (m) i = g(W (m) h (m-1) i + b (m) ) ∈ R dm<label>(2)</label></formula><p>to denote the output of the m-th layer. Here, m = 1, 2, • • • , M is the index of layer, d m is the number of neurons of the corresponding layer, and g(•) denotes the used activation function. For a given input x i , the corresponding reconstruction and low-dimensional representation are h (M ) i and h</p><formula xml:id="formula_2">( M 2 ) i</formula><p>, respectively. Moreover, for the data set X = [x 1 , . . . , x n ] ∈ R d×n , the corresponding reconstructions are:</p><formula xml:id="formula_3">H (M ) = [h (M ) 1 , h (M ) 2 , • • • , h (M ) n ].<label>(3)</label></formula><p>StructAE aims to simultaneously preserve self-supervision based locality J 1 (i.e. data reconstruction) and self-expression based globality J 2 (i.e. the global structure prior C<ref type="foot" target="#foot_0">1</ref> .) in learning representation. With the aforementioned definitions, we propose the following objective function:</p><formula xml:id="formula_4">min W (m) ,b (m) 1 2 X -H (M ) 2 F J1, Locality + λ 1 2 H ( M 2 ) -H ( M 2 ) C 2 F J2, Globality + λ 2 2 M m=1 W (m) 2 F + b (m) 2 2 J3, Regularization ,<label>(4)</label></formula><p>where λ 1 and λ 2 are positive tradeoff parameters. We design the terms {J i } 3 i=1 for different goals. To be exact, the first term J 1 aims to keep the locality by minimizing the errors between the input X and the reconstruction H (M ) . Clearly, each data point actually performs as its supervisor to learn a compact representation H ( M 2 ) . J 2 is derived from the manifold learning <ref type="bibr" target="#b38">[39]</ref> which assumes that some properties on manifold are invariant to different projection spaces <ref type="foot" target="#foot_1">2</ref> . Based on the assumption, ones could learn representation by preserving the specific property from input space into another space. Clearly, the key of manifold learning is to seek the invariance. In this paper, the reconstruction relationship (i.e., the structure prior) is regarded as a type of invariance, which has shown effectiveness in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b39">[40]</ref>. In particular, we adopt two popular cases, i.e. the sparsity prior by</p><formula xml:id="formula_5">min C n i=1 x i -Yc i 2 2 + λ c i 1 s.t. c ii = 0,<label>(5)</label></formula><p>and the non-sparse prior by</p><formula xml:id="formula_6">min C n i=1 x i -Yc i 2 2 + λ c i 2 s.t. c ii = 0,<label>(6)</label></formula><p>where • 1 and • 2 denote 1 -and 2 -norm, and the corresponding StructAE is denoted by StructAE-L1 and StructAE-L2, respectively. c ii denotes to the i-th element of the vector c i , and the constraint is used to avoid degenerated solutions. Note that the 2 -norm based reconstruction coefficient is provable to give low-rank property <ref type="bibr" target="#b39">[40]</ref>, and it is more computationally efficient than the nuclear-norm based objective function. In Eq.( <ref type="formula" target="#formula_6">6</ref>), Y denotes a dictionary, which can be pre-determined using dictionary learning methods or simply specified to be the data set itself. For simplicity, we directly let Y = X in this paper.</p><p>With the optimal solution of Eq. ( <ref type="formula" target="#formula_5">5</ref>) or Eq. ( <ref type="formula" target="#formula_6">6</ref>), J 2 guarantees the globality since the reconstruction relation of using the entire data set is kept from input space into the hidden representation. J 3 is a popular regularization, which is used to avoid over-fitting. It should be pointed out that, the objective function Eq. ( <ref type="formula" target="#formula_4">4</ref>) with the nonlinear function will not give the trivial solution W (m) = 0 and W m = I thanks to the existence of J 1 and the updating rule Eq. ( <ref type="formula" target="#formula_9">10</ref>)-( <ref type="formula" target="#formula_13">13</ref>), where 0 and I denote an all-zero matrix and identity matrix, respectively. Clearly, either all-zero matrix or identity matrix will not give the minimal J 1 .</p><p>StructAE enforces the learned representation to keep the global structure prior and simultaneously uses the input as the supervisor to learn a compact data representation. These global and local structures are integrated into the data representation, and thus resulting in favorable clustering results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimization</head><p>In this subsection, we show how efficiently optimize our StructAE using the stochastic sub-gradient descent algorithm (SGD). For convenience, Eq. ( <ref type="formula" target="#formula_4">4</ref>) is rewritten in the following sample-wise form:</p><formula xml:id="formula_7">J = 1 2 n i=1 x i -h (M ) i 2 2 + λ 1 h ( M 2 ) i -H ( M 2 ) c i 2 2 + λ 2 2 M m=1 W (m) 2 F + b (m) 2 2 .<label>(7)</label></formula><p>Recall the definition of h (m) i in Eq. ( <ref type="formula" target="#formula_1">2</ref>) and use the backpropagation algorithm, the sub-gradients of Eq. ( <ref type="formula" target="#formula_7">7</ref>) w.r.t. W (m) and b (m) is as follows:</p><formula xml:id="formula_8">∂J ∂W (m) = ∆ (m) + λ 1 Λ (m) (h (m-1) i ) T + λ 2 W (m) (8) ∂J ∂b (m) = ∆ (m) + λ 1 Λ (m) + λ 2 b (m) ,<label>(9)</label></formula><p>where ∆ (m) is given by:</p><formula xml:id="formula_9">   -x i -h (M ) i g (z (M ) i ), m = M (W (m+1) ) T ∆ (m+1) g (z (m) i ), otherwise<label>(10)</label></formula><p>and Λ (m) is defined by</p><formula xml:id="formula_10">             (W m+1 ) T Λ (m+1) g (z (m) i ), m = 1, • • • , M -2 2 h ( M 2 ) i -H ( M 2 ) c i g (z ( M 2 ) i ), m = M 2 0, m = M + 2 2 , • • • , M<label>(11) Here</label></formula><p>is the element-wise multiplication, g (•) denotes the derivative of the activation g(•), h</p><formula xml:id="formula_11">(0) i = x i , and z (m) i = W (m) h (m-1) i + b (M ) .</formula><p>Using the SGD algorithm, {W (m) , b (m) } M m=1 are updated as follows:</p><formula xml:id="formula_12">W (m) = W (m) -µ ∂J ∂W (m) ,<label>(12) b</label></formula><formula xml:id="formula_13">(m) = b (m) -µ ∂J ∂b (m) .<label>(13)</label></formula><p>Algorithm 1 summarizes the optimization procedure of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation Details</head><p>In our implementation, g(•) = tanh(•) is used as the activation function. To initialize our neural network, the pretraining and fine-tuning strategy <ref type="bibr" target="#b24">[25]</ref> is adopted. More specifically, the entire neural network is decomposed into multiple smaller ones and then lay-wise pre-training is performed on these single hidden layer network. In our experiments, for a five-layer neural network 300-200-150-200-300, we first train the shallow networks of 300-200-300 and 200-150-200, respectively. After that, we use the pretrained weights to initialize the deeper network.</p><p>It should be pointed out that the fully connected layers in StructAEs could be replaced with other neural networks including but not limited to convolutional neural networks, restricted Boltzmann machines, long short term memory Au-toEncoders. With such a new module, our method may give a Algorithm 1: Structured AutoEncoders for Subspace Clustering Input: A input data X, and the parameters λ 1 , λ 2 . // Initialization: Let H 0 = X and initialize our neural network {W (m) , b (m) } M m=1 . // Compute the structure prior: Obtain the structured prior C of X by solving Eq.( <ref type="formula" target="#formula_5">5</ref>) or Eq. <ref type="bibr" target="#b5">(6)</ref>.</p><formula xml:id="formula_14">for m = 1, 2 • • • , M do Get {H (m) } M m=1 via Eq.(2). // Optimizations: while not converge do for i = 1, 2, • • • , n do Randomly select a data point x i and let h 0 i = x i , // Forward propagation: for m = 1, 2 • • • , M do Compute h (m) i</formula><p>via Eq.( <ref type="formula" target="#formula_1">2</ref>). // Compute gradients:</p><formula xml:id="formula_15">for m = M, M -1 • • • , 1 do</formula><p>Compute the gradient via Eqns.( <ref type="formula">8</ref>)- <ref type="bibr" target="#b10">(11)</ref>. // Update neural network:</p><formula xml:id="formula_16">for m = 1, 2, • • • , M do</formula><p>Update W (m) and b (m) via Eqns.( <ref type="formula" target="#formula_12">12</ref>)-( <ref type="formula" target="#formula_13">13</ref>).</p><p>// Clustering: Obtain the clustering membership by clustering H ( M 2 ) . Output: The clustering membership and the parametric neural network</p><formula xml:id="formula_17">{W (m) , b (m) } M m=1 .</formula><p>better performance. In our implementation, however, we adopt the fully connected layers (i.e., the classic AutoEncoder) due to following reasons: 1) we experimentally found that even with such a simple neural network, our method could remarkably outperform many popular subspace clustering methods; 2) it is relatively easy to tune parameters for the classic AutoEncoder comparing with other neural networks; 3) the classic AutoEncoder is computationally efficient, which is more friendly to our hardware environment than other networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Connection to Previous Works</head><p>In this subsection, we discuss the relationship between our StructAE and previous works from two different angles. First, we show that StructAE can be treated as a variant of the classical AutoEncoder (AE). Moreover, with several simplifications, StructAE can be deemed as a deep extension of spectral clustering (SC) algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Connection between StructAE and AE:</head><p>The well-known AE utilizes each data point as the supervisor to guide representation learning, which ignores the relationship with other data. Our StructAE will reduce to AE if λ 1 (Eq. ( <ref type="formula" target="#formula_4">4</ref>)) is fixed to 0, i.e. the structure prior is not incorporated into our objective function. In this sense, StructAE augments AE with formulation of the valuable relationships among different data points (i.e. structure global prior) and such relationships can give encouraging performance as shown in previous subspace clustering works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>2) Connection between StructAE and SC: Most spectral clustering based methods obtain the segmentation of data by conducting the k-means algorithm on leading eigenvectors (w.r.t. largest eigenvalues) of the Laplacian matrix L as aforementioned. StructAE can be regarded as providing a deep framework to generalize existing SCs.</p><p>Theorem 1. Let g(z) = z, λ 1 → +∞, M = 2 in Eq. ( <ref type="formula" target="#formula_4">4</ref>) and with the following mild constraint for avoiding trivial solutions, then the compact representation H learnt by StructAE will be the solution to</p><formula xml:id="formula_18">min H 1 2 H -HC 2 F s.t. HH T = I. (<label>14</label></formula><formula xml:id="formula_19">)</formula><p>Interestingly, H * is also optimal to</p><formula xml:id="formula_20">max H HLH T HH T ,<label>(15)</label></formula><p>which is exactly the objective of spectral clustering based methods. The only one difference is the choice of L. To be exact, L = C + C T -CC T for our method, whereas</p><formula xml:id="formula_21">L = D -1 2 AD -1 2 (D ii = j A ij )</formula><p>for the spectral clustering method <ref type="bibr" target="#b2">[3]</ref>.</p><p>Proof. The optimal solution of Eq. ( <ref type="formula" target="#formula_18">14</ref>) is achieved by solving the following eigen-decomposition problem:</p><formula xml:id="formula_22">H * = argmin H(I -C -C T + CC T )H T HH T<label>(16)</label></formula><p>which is identical to</p><formula xml:id="formula_23">H * = argmax H(C + C T -CC T )H T HH T ,<label>(17)</label></formula><p>as desired.</p><p>Based on Theorem 1, we can further bridge StructAE and some existing subspace clustering methods as below:</p><p>Remark 1. StructAE is a deep framework of most existing spectral clustering based subspace clustering methods if the same structure prior is adopted. With the simplifications shown in Theorem 1, for example, StructAE will degrade to SSC <ref type="bibr" target="#b6">[7]</ref> with the sparsity prior, to LRR <ref type="bibr" target="#b7">[8]</ref> with the low rank prior, to LSR <ref type="bibr" target="#b5">[6]</ref> and L2graph <ref type="bibr" target="#b13">[14]</ref> with the L2-norm based prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we report the performance of the proposed StructAE comparing with 15 popular subspace clustering methods regarding to five evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Settings</head><p>Baseline Algorithms: We compare the proposed Struc-tAEs with SSC <ref type="bibr" target="#b6">[7]</ref>, LRR <ref type="bibr" target="#b7">[8]</ref>, low rank based subspace clustering (LRSC) <ref type="bibr" target="#b40">[41]</ref>, LSR <ref type="bibr" target="#b5">[6]</ref>, smooth representation clustering (SMR) <ref type="bibr" target="#b41">[42]</ref>, kernel SSC (KSSC) <ref type="bibr" target="#b23">[24]</ref>, kernel LRR (KLRR) <ref type="bibr" target="#b22">[23]</ref>, latent subspace sparse subspace clustering (LS3C) <ref type="bibr" target="#b29">[30]</ref> and stacked sparse autoencoders (SAE) <ref type="bibr" target="#b42">[43]</ref>. Among the compared approaches, KSSC, LS3C, and KLRR have two variants that are based on the radial basis function / the polynomial function, denoted by KSSC-R / KSSC-P, LS3C-R / LS3C-P and KLRR-R / KLRR-P, respectively. Moreover, LS3C-L denotes LS3C with the linear kernel function. LSR has also two variants which are with and without a diagonal constraint. We denote them as LSR1 and LSR2. Moreover, we examine the performance of SAEs and SAEg which are SAE with the saturating linear transfer function and the sigmoid function, respectively. All evaluated methods are implemented in MATLAB.</p><p>In our experiments, SAE and our StructAEs are fivelayer neural networks which consist of 300-200-150-200-300 neurons and use tanh as the activation function. This structure is introduced in <ref type="bibr" target="#b43">[44]</ref>, which has shown efficacy in face verification. Like <ref type="bibr" target="#b43">[44]</ref>, we train our network by adopting the standard SGD with the batch-size of 1 and using different learning rate for different data sets as elaborated latter. In we employ the Homotopy algorithm <ref type="bibr" target="#b44">[45]</ref> to solve 1 -minimization problem of SSC, KSSC, and StructAE (in the case of sparsity). For a fair comparison, we compare the best performance of all the tested approaches with the tuned parameters. In other words, we do not split the data into different subsets for training, validation, and testing as supervised works did. Instead, we tune parameters for all tested methods using the whole data set, as <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> did. Regarding to the baselines, we seek optimal parameters by referring to the setting in the corresponding paper. Regarding to our StructAE, we fix λ 2 = 10 -3 in all cases and experimentally determine the value of λ 1 . In details, we choose an optimal λ 1 from {10 -4 , 5 × 10 -4 , 10 -3 , 5 × 10 -3 , 10 -2 , 5 × 10 -2 }. Moreover, SAE and StructAEs are regarded to achieve convergence if the their loss is less than 10 -3 or the training epoch reaches to 100.</p><p>Data Sets: We perform experiments using five different data sets, i.e. the COIL20 image data set <ref type="bibr" target="#b45">[46]</ref>, the Extended Yale database B (YaleB) <ref type="bibr" target="#b46">[47]</ref>, the BF0502 data set <ref type="bibr" target="#b47">[48]</ref>, the CIFAR10 image database <ref type="bibr" target="#b48">[49]</ref>, and the mnist handwritten digits <ref type="bibr" target="#b49">[50]</ref>. The COIL20 data set consists of 1,440 object images distributed over 20 subjects, where the dimension of each image is 32×32. The YaleB data set contains 2,414 facial images captured from 38 persons, where the dimension of each image is 192 × 168. The used BF0502 data set <ref type="bibr" target="#b22">[23]</ref> includes 1,200 facial images cropped from the TV series "Buffy the Vampire Slayer", where each subject contains 200 data points. The CIFAR10 data set includes 60,000 32 × 32 color images of which the first 200 images for each class are converted into gray images and used in our experiments. The used mnist is a subset by following the setting of <ref type="bibr" target="#b29">[30]</ref>.</p><p>For comprehensive studies, we conduct experiments not only using raw data (i.e. gray value), but also using the following four different features, i.e. dense scale-invariant feature transform (DSIFT) <ref type="bibr" target="#b50">[51]</ref>, square root of DSIFT (SDSIFT) <ref type="bibr" target="#b51">[52]</ref>, the histogram of oriented gradients (HOG) <ref type="bibr" target="#b52">[53]</ref>, and local phase quantization (LPQ) <ref type="bibr" target="#b53">[54]</ref>. To present more new results comparing with our conference paper <ref type="bibr">[31]</ref>, in this paper, we carry out experiments using YaleB and COIL20 with SDISFT and LPQ, and CIFAR10 with these four features. The details for extracting these features are introduced as follows:   <ref type="bibr" target="#b43">[44]</ref>, we perform dimension reduction using PCA on all the tested data sets and the reduced dimension is fixed to 300 for computational efficiency.</p><p>Evaluation Criteria: To evaluate the clustering quality of our method, five measurements are adopted, including Accuracy (or called Purity), normalized mutual information (denoted by NMI), the adjusted rand index (denoted by ARI), Precision, and Fscore. Moreover, we repeat all evaluated methods five times and report their mean and the standard deviation regarding to these metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Investigation on Different Variants of StructAE</head><p>StructAE can incorporate various structured priors as discussed above. In this subsection, we compare the clustering    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparison with State-of-the-art</head><p>this subsection, we compare StructAE with some stateof-the-art approaches using COIL20, YaleB, and mnist. Moreover, we have also illustrated the 2D-visualization of COIL20 and YaleB by conducting t-sne <ref type="bibr" target="#b54">[55]</ref> on the input data and features learned by our StructAE.</p><p>1) Results on COIL20: The results of StructAE on COIL20 are reported in Table <ref type="table" target="#tab_2">III</ref>. In experiments, we set λ 1 = 10 -4 and µ = 2 -10 of StructAE for the SDSIFT feature, and λ 1 = 5 × 10 -3 and µ = 2 -11 for the LPQ feature.</p><p>From the results, we can observe that:</p><p>• StructAE outperforms the other methods by a considerable margin in terms of the five evaluation metrics. When using the LPQ feature, for example, its performance is at least 6.50%, 1.08%, 5.39%, 9.66%, and 6.55% higher than the second best result regarding to these five metrics.  all tests, StructAE achieves the best performance. When using the SDISFT feature, for example, it outperforms the second best method with a performance gain of 6.38% in Accuracy, 3.43% in NMI, 7.61% in ARI, 9.50% in Precision, and 7.40% in Fscore; 2) All the investigated methods achieve the worst results on the LPQ features. Especially, the performance of SAEg and SAEs decreases more than a half. 3) Fig. <ref type="figure">3</ref> provides a visualized evidence for the superior performance of our method. 3) Results on mnist In the experiments, λ 1 and µ of StructAE are fixed to 0.05 and 2 -10 , respectively. Table V reports the results which show the proposed StructAE consistently outperforms the evaluated methods on the mnist and LS3C-R achieves the second best result in most cases. Noted that, <ref type="bibr" target="#b29">[30]</ref> has experimentally shown that the highest Accuracy of SSC, LRR, LS3C, and nonlinear LS3C is about 41.41%, 24.52%, 41.32%, and 45.37% on the mnist. Clearly, these four methods remarkably improve their performance in our experimental setting.:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison with Deep Features</head><p>In this section, we show that our method with handcrafted features could significantly outperform state-of-the-art subspace clustering approaches with deep features. Specifically, we first resize each image to 224 × 224 so that the images could be passed through the pretrained VGG16 <ref type="bibr" target="#b55">[56]</ref> and ResNet50 <ref type="bibr" target="#b56">[57]</ref>. After obtaining deep features, we conduct SSC and LRR to achieve data clustering. For simplicity, here, we report the best result achieved by our method in the above setting and use the Accuracy as the evaluation metric. Table VI demonstrates that the proposed StructAE is superior to the baselines by a considerable performance margin. To be exact, it is 4.36%, 14.96%, 39.56%, and 1.35% higher than the best baseline on these four data sets. Furthermore, one could observe that LRR+VGG16 does not give an acceptable result on CIFAR10 and mnist. The possible reason is that VGG16 features do not show low rank property. From Fig. <ref type="figure">4</ref><ref type="figure">5</ref>, some observations are summarized as follows:</p><p>• Deeper network leads to better clustering results for our method. For example, StructAE4 is 3.75% higher than StructAE2 in Accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Performance with Different Activation Functions</head><p>We examine the clustering performance of StructAE with four nonlinear functions by conducting experiments on the YaleB database with DSIFT and HOG. The investigated activation functions include tanh, sigmoid, non-saturating sigmoid (nssigmoid), and softplus (i.e. ReLU). For extensive investigations, we again investigate the performance of StructAE in the case of clustering in subspace (denoted by StructAE-S) and latent subspace (denoted by StructAE-L).</p><p>From Fig. <ref type="figure" target="#fig_4">6</ref>, ones could observe that:</p><p>• By comparing StructAE-S and StructAE-L, the sigmoid function gives a remarkable performance change, i.e., the second best result with StructAE-S versus the worst result with StructAE-L. The possible reason is that clustering in latent space makes the sigmoid function saturated, and lead to barely learning of StructAE-L. In contrast, with the non-saturating version of sigmoid (i.e. nssigmoid), StructAE-L performs stable in different settings. • Discarding the sigmoid function, the activation with stronger nonlinearity gives better performance. From Fig. <ref type="figure" target="#fig_4">6</ref>, ones could see that the tanh function is with the strongest nonlinearity which may result in its superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Time Cost Analysis</head><p>In this subsection, we investigate the computational efficiency of our method using the CIFAR10 data set with the DSIFT feature. The inference time denotes the cost taken by StructAEs and SAEs to perform representation learning and clustering after the networks converging. Table <ref type="table" target="#tab_8">VII</ref> shows that the proposed StructAEs are less efficient than the baselines. The training time of StructAEs consists of three parts, i.e., for training AutoEncoder, for computing the structure prior, and for training StructAEs by solving Eq.(4). In fact, the first part is the most time-consuming, which takes about 60% of the entire cost. Noticed that, once StructAE converges, it will achieve clustering result quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>This paper proposed a novel neural network for subspace clustering by simultaneously preserving the locality and globality of data sets. Extensive experimental results have demonstrated that our method is remarkably superior to 15 recently- </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The architectures of subspace clustering approaches and StructAE. In (a), H (0) denotes inputs, C (0) is the structure prior calculated based on H (0) and H (m) corresponds to the output of the m-th layer of our neural network, where m = 1, 2, • • • , M . (b) a symbolic illustration, where the locality denotes the minimization of the reconstruction error between inputs and H (M ) , and the globality is achieved by minimizing the reconstruction error of H M 2 over the whole data set with C (0) .</figDesc><graphic coords="2,392.57,57.46,169.64,102.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Visualization on the COIL20 data set. See the electronic version for a better look.</figDesc><graphic coords="8,38.58,206.13,143.52,120.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. The performance of StructAE with different depths and widths on the BF0502 raw data set, where StructAE2 denotes the network with 2 hidden layers, and StructAE4 denotes the 4-hidden-layer network. StructAE100 and StructAE50 denote the networks with 100 and 50 neurons at the middle layer, respectively.</figDesc><graphic coords="9,74.91,530.10,197.12,116.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>E</head><label></label><figDesc>. Influence of Depths, Widths, and Parameter In this subsection, we examine the clustering results of our StructAE with different depths, widths, and λ 1 using the BF0502 raw data set in terms of clustering Accuracy. Regarding evaluation on depths and widths, two variants of StructAE (λ 1 = 10 -3 and µ = 2 -10 ) are investigated, i.e. StructAE4 and StructAE2, which correspond to fivelayer case (M = 4) and three-layer case (M = 2). For M = 2, the used neural network is with 300-150-300 neurons. Moreover, StructAE100 and StructAE50 have similar structure with StructAE4. The only one difference is that the middle layer of StructAE100 and StructAE50 consists of 100 and 50 neurons, respectively. In experiments, λ 1 is set as 10 -2 for StructAE2 and 10 -3 for StructAE4, StructAE100 and Struc-tAE50. Regarding the evaluation on parameters, StructAE-S and StructAE-L are investigated, which correspond to StructAE-L1S and StructAE-L1L, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The clustering results of StructAE with four nonlinear activation functions on the YaleB database, where StructAE-S denotes clustering in subspace and StructAE-L denotes clustering in the latent subspace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I RESULTS</head><label>I</label><figDesc>ON CIFAR10. THE NUMBERS IN BOLDFACE INDICATE THE BEST RESULT ACCORDING TO THE T-TEST, WHERE THE SIGNIFICANCE LEVEL IS 0.05. STRUCTAE-L1 AND STRUCTAE-L2 DENOTE THE VARIANT WITH 1 -AND 2 -NORM BASED PRIOR, RESPECTIVELY. STRUCTAE-L*S AND STRUCTAE-L*L DENOTE ACHIEVING CLUSTERING WITH K-MEANS AND SSC (OR LSR1), RESPECTIVELY. IN OTHER WORDS, STRUCTAE-L*S PERFORMS CLUSTERING IN SUBSPACE, AND STRUCTAE-L*L PERFORMS CLUSTERING IN THE LATENT SUBSPACE.</figDesc><table><row><cell>Features</cell><cell></cell><cell></cell><cell>DSIFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>HOG</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell></row><row><cell>StructAE-L1S</cell><cell>18.05±0.07</cell><cell>4.63±0.19</cell><cell>1.89±0.05</cell><cell>11.67±0.04</cell><cell>11.76±0.05</cell><cell>25.92±0.95</cell><cell>12.85±0.53</cell><cell>6.62±0.37</cell><cell>15.88±0.35</cell><cell>16.02±0.31</cell></row><row><cell>StructAE-L1L</cell><cell>18.00±0.08</cell><cell>4.10±0.07</cell><cell>1.76±0.04</cell><cell>11.55±0.03</cell><cell>11.67±0.03</cell><cell>15.50±0.02</cell><cell>1.69±0.02</cell><cell>0.51±0.01</cell><cell>10.42±0.01</cell><cell>10.75±0.01</cell></row><row><cell>StructAE-L2S</cell><cell>17.53±0.15</cell><cell>4.31±0.32</cell><cell>1.74±0.11</cell><cell>11.53±0.10</cell><cell>11.63±0.11</cell><cell>23.32±1.38</cell><cell>11.33±0.84</cell><cell>5.59±0.58</cell><cell>14.95±0.50</cell><cell>15.11±0.55</cell></row><row><cell>StructAE-L2L</cell><cell>17.09±0.14</cell><cell>4.17±0.12</cell><cell>1.60±0.03</cell><cell>11.40±0.03</cell><cell>11.58±0.02</cell><cell>15.35±0.43</cell><cell>2.42±0.33</cell><cell>0.84±0.23</cell><cell>10.72±0.20</cell><cell>10.82±0.24</cell></row><row><cell>SAEg</cell><cell>12.75±0.00</cell><cell>0.93±0.00</cell><cell>0.03±0.00</cell><cell>9.95±0.00</cell><cell>11.07±0.01</cell><cell>17.54±0.15</cell><cell>4.58±0.02</cell><cell>1.90±0.01</cell><cell>11.67±0.01</cell><cell>11.76±0.01</cell></row><row><cell>SAEs</cell><cell>13.25±0.08</cell><cell>1.13±0.02</cell><cell>0.10±0.01</cell><cell>10.06±0.01</cell><cell>11.15±0.02</cell><cell>17.80±0.00</cell><cell>4.54±0.00</cell><cell>1.94±0.00</cell><cell>11.72±0.00</cell><cell>11.76±0.00</cell></row><row><cell>SSC</cell><cell>15.92±0.08</cell><cell>3.93±0.04</cell><cell>1.54±0.02</cell><cell>11.32±0.02</cell><cell>11.66±0.02</cell><cell>18.40±0.07</cell><cell>4.66±0.03</cell><cell>2.01±0.02</cell><cell>11.66±0.01</cell><cell>12.45±0.07</cell></row><row><cell>KSSC-R</cell><cell>17.00±0.00</cell><cell>4.12±0.01</cell><cell>1.52±0.01</cell><cell>11.30±0.01</cell><cell>11.66±0.00</cell><cell>23.60±0.00</cell><cell>11.22±0.01</cell><cell>6.04±0.01</cell><cell>14.01±0.01</cell><cell>14.57±0.01</cell></row><row><cell>KSSC-P</cell><cell>16.68±0.06</cell><cell>3.90±0.01</cell><cell>1.57±0.00</cell><cell>11.37±0.00</cell><cell>11.55±0.01</cell><cell>23.70±0.00</cell><cell>11.86±0.00</cell><cell>6.47±0.00</cell><cell>14.26±0.00</cell><cell>15.00±0.00</cell></row><row><cell>LS3C-L</cell><cell>14.46±0.02</cell><cell>3.86±0.01</cell><cell>1.38±0.01</cell><cell>11.20±0.01</cell><cell>11.34±0.01</cell><cell>14.83±0.15</cell><cell>2.30±0.11</cell><cell>0.75±0.06</cell><cell>10.64±0.05</cell><cell>10.72±0.05</cell></row><row><cell>LS3C-P</cell><cell>16.80±0.00</cell><cell>4.05±0.00</cell><cell>1.74±0.00</cell><cell>11.51±0.00</cell><cell>11.68±0.01</cell><cell>20.55±0.00</cell><cell>10.57±0.00</cell><cell>4.80±0.00</cell><cell>13.22±0.00</cell><cell>14.46±0.00</cell></row><row><cell>LS3C-R</cell><cell>16.73±0.24</cell><cell>3.50±0.05</cell><cell>1.46±0.04</cell><cell>11.28±0.03</cell><cell>11.40±0.04</cell><cell>21.30±0.00</cell><cell>11.39±0.00</cell><cell>5.59±0.00</cell><cell>13.94±0.00</cell><cell>15.24±0.00</cell></row><row><cell>LRR</cell><cell>16.35±0.00</cell><cell>4.25±0.00</cell><cell>1.53±0.00</cell><cell>10.99±0.00</cell><cell>11.44±0.00</cell><cell>15.25±0.11</cell><cell>2.06±0.03</cell><cell>0.69±0.02</cell><cell>10.58±0.02</cell><cell>10.86±0.02</cell></row><row><cell>KLRR-R</cell><cell>16.85±0.00</cell><cell>3.93±0.00</cell><cell>1.37±0.00</cell><cell>11.15±0.00</cell><cell>11.63±0.00</cell><cell>23.35±0.00</cell><cell>11.90±0.00</cell><cell>0.70±0.00</cell><cell>14.09±0.00</cell><cell>15.14±0.00</cell></row><row><cell>KLRR-P</cell><cell>16.84±0.02</cell><cell>4.28±0.02</cell><cell>1.74±0.01</cell><cell>11.53±0.01</cell><cell>11.57±0.01</cell><cell>23.30±0.00</cell><cell>12.00±0.00</cell><cell>6.66±0.00</cell><cell>14.24±0.00</cell><cell>14.32±0.00</cell></row><row><cell>LRSC</cell><cell>16.44±0.13</cell><cell>3.24±0.01</cell><cell>1.21±0.03</cell><cell>11.03±0.02</cell><cell>11.43±0.03</cell><cell>15.51±0.40</cell><cell>2.45±0.26</cell><cell>0.86±0.20</cell><cell>10.74±0.18</cell><cell>10.83±0.21</cell></row><row><cell>LSR1</cell><cell>16.21±0.05</cell><cell>3.97±0.02</cell><cell>1.49±0.01</cell><cell>11.29±0.01</cell><cell>11.53±0.01</cell><cell>15.61±0.33</cell><cell>2.50±0.12</cell><cell>0.89±0.06</cell><cell>10.77±0.06</cell><cell>10.84±0.05</cell></row><row><cell>LSR2</cell><cell>16.16±0.15</cell><cell>3.66±0.04</cell><cell>1.32±0.02</cell><cell>11.14±0.02</cell><cell>11.10±0.02</cell><cell>15.52±0.49</cell><cell>2.43±0.14</cell><cell>0.85±0.10</cell><cell>10.74±0.09</cell><cell>10.81±0.09</cell></row><row><cell>SMR</cell><cell>15.15±0.00</cell><cell>2.16±0.00</cell><cell>0.57±0.00</cell><cell>10.48±0.00</cell><cell>10.63±0.00</cell><cell>20.92±0.04</cell><cell>6.18±0.02</cell><cell>3.02±0.02</cell><cell>12.54±0.02</cell><cell>13.23±0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II RESULTS</head><label>II</label><figDesc>ON CIFAR10.</figDesc><table><row><cell>Features</cell><cell></cell><cell></cell><cell>SDSIFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LPQ</cell><cell></cell></row><row><cell>Methods</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell cols="2">Fscore</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell></row><row><cell cols="6">• DSIFT and SDISFT: We divide each image into multiple</cell><cell></cell><cell cols="5">concatenating the features of all patches of each image,</cell></row><row><cell cols="6">patches and then densely sample SIFT descriptors from</cell><cell></cell><cell cols="5">the dimension of each feature is 12,288 for CIFAR10 and</cell></row><row><cell cols="6">each patch. The patch size of YaleB is 12 × 12. For</cell><cell></cell><cell cols="3">COIL20 and 101,376 for YaleB.</cell><cell></cell></row><row><cell cols="6">CIFAR10, COIL20, and mnist, the patch size is set as</cell><cell>Like</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">4 × 4. By concatenating these SIFT descriptors of all</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">patches of each image, we obtain a feature vector with</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">the dimension of 32,256 for YaleB, 2,048 for CIFAR10,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">and 2,048 for COIL20, respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">• HOG: We first divide each image into multiple blocks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">with two scales, i.e. 4 × 4 and 2 × 2 for CIFAR10. Then,</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">we extract a 9-dimensional HOG feature vector from each</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">block. After concatenating the features of all patches of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">each image, the feature dimension is 2,880 for CIFAR10.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>• LPQ: We first divide each image into multiple nonoverlapping blocks and then extract the LPQ feature from each patch. The patch size is set as 8 × 8 for CIFAR10 and COIL20 and 15×15 for YaleB. For all the tested data sets, we set the size of LPQ window as 3, 5, and 7. By</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III RESULTS</head><label>III</label><figDesc>ON COIL20.</figDesc><table><row><cell>Features</cell><cell></cell><cell></cell><cell>SDSIFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LPQ</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell></row><row><cell>StructAE</cell><cell>91.04±2.23</cell><cell>94.67±0.99</cell><cell>88.61±1.95</cell><cell>85.90±2.36</cell><cell>89.19±1.83</cell><cell>84.38±1.67</cell><cell>89.72±0.57</cell><cell>81.51±2.02</cell><cell>81.65±2.83</cell><cell>82.43±1.90</cell></row><row><cell>SAEg</cell><cell>79.71±2.86</cell><cell>91.90±1.05</cell><cell>78.09±2.10</cell><cell>70.36±2.84</cell><cell>79.31±1.97</cell><cell>60.42±1.14</cell><cell>70.71±0.86</cell><cell>50.64±1.39</cell><cell>49.74±1.51</cell><cell>53.26±1.33</cell></row><row><cell>SAEs</cell><cell>78.94±1.15</cell><cell>91.85±0.04</cell><cell>78.43±1.19</cell><cell>70.77±3.27</cell><cell>79.63±1.09</cell><cell>54.35±1.63</cell><cell>65.63±1.05</cell><cell>42.99±1.79</cell><cell>41.77±1.64</cell><cell>46.09±1.68</cell></row><row><cell>SSC</cell><cell>82.17±1.59</cell><cell>91.13±0.69</cell><cell>78.86±1.52</cell><cell>70.18±3.32</cell><cell>80.05±1.40</cell><cell>75.53±1.82</cell><cell>88.01±0.85</cell><cell>74.53±1.91</cell><cell>70.86±1.63</cell><cell>75.88±1.82</cell></row><row><cell>KSSC-R</cell><cell>80.58±3.14</cell><cell>92.33±1.05</cell><cell>79.70±2.21</cell><cell>71.67±3.30</cell><cell>80.83±2.07</cell><cell>71.89±1.54</cell><cell>84.23±1.19</cell><cell>66.84±2.51</cell><cell>63.64±3.55</cell><cell>68.60±2.34</cell></row><row><cell>KSSC-P</cell><cell>85.56±1.00</cell><cell>94.27±0.13</cell><cell>83.36±0.62</cell><cell>75.58±0.31</cell><cell>84.27±0.59</cell><cell>71.39±0.51</cell><cell>84.08±0.36</cell><cell>67.85±0.72</cell><cell>63.76±1.80</cell><cell>69.59±0.66</cell></row><row><cell>LS3C-L</cell><cell>34.04±1.78</cell><cell>52.24±1.75</cell><cell>19.09±2.61</cell><cell>16.85±2.03</cell><cell>25.05±2.22</cell><cell>50.33±0.79</cell><cell>62.67±0.38</cell><cell>39.67±0.47</cell><cell>36.20±1.01</cell><cell>43.22±0.43</cell></row><row><cell>LS3C-P</cell><cell>67.28±2.95</cell><cell>80.97±1.23</cell><cell>60.30±3.34</cell><cell>55.05±4.23</cell><cell>62.53±3.09</cell><cell>57.74±2.11</cell><cell>75.14±0.74</cell><cell>53.52±1.40</cell><cell>49.04±1.67</cell><cell>56.14±1.30</cell></row><row><cell>LS3C-R</cell><cell>21.92±0.48</cell><cell>31.76±0.66</cell><cell>14.75±0.45</cell><cell>15.39±0.28</cell><cell>20.30±0.55</cell><cell>55.97±3.27</cell><cell>71.63±1.62</cell><cell>47.36±3.51</cell><cell>43.42±4.35</cell><cell>50.39±3.19</cell></row><row><cell>LRR</cell><cell>87.51±1.76</cell><cell></cell><cell></cell><cell></cell><cell>85.19±1.77</cell><cell></cell><cell>88.64±1.37</cell><cell>76.12±3.03</cell><cell>69.67±3.92</cell><cell>74.58±2.83</cell></row><row><cell>KLRR-R</cell><cell>79.94±0.88</cell><cell>89.02±0.74</cell><cell>77.75±1.32</cell><cell>75.95±2.33</cell><cell>78.89±1.24</cell><cell>68.58±0.91</cell><cell>79.64±0.60</cell><cell>61.44±1.21</cell><cell>58.33±1.12</cell><cell>63.51±1.14</cell></row><row><cell>KLRR-P</cell><cell>77.21±1.95</cell><cell>87.43±0.88</cell><cell>74.32±1.72</cell><cell>71.09±2.05</cell><cell>75.67±1.62</cell><cell>64.28±1.18</cell><cell>76.55±0.63</cell><cell>56.37±1.61</cell><cell>54.36±2.40</cell><cell>58.69±1.48</cell></row><row><cell>LRSC</cell><cell>55.08±0.12</cell><cell>71.26±0.19</cell><cell>47.95±0.40</cell><cell>45.55±0.42</cell><cell>50.81±0.38</cell><cell>61.85±1.44</cell><cell>72.85±0.96</cell><cell>53.15±1.86</cell><cell>52.04±1.95</cell><cell>55.63±1.75</cell></row><row><cell>LSR1</cell><cell>64.86±0.83</cell><cell>74.10±0.55</cell><cell>53.78±2.03</cell><cell>50.98±2.72</cell><cell>56.30±1.88</cell><cell>69.57±1.54</cell><cell>77.81±0.88</cell><cell>61.53±1.38</cell><cell>60.66±1.22</cell><cell>63.51±1.31</cell></row><row><cell>LSR2</cell><cell>65.00±1.67</cell><cell>74.34±0.73</cell><cell>54.31±1.91</cell><cell>50.91±2.80</cell><cell>56.83±1.75</cell><cell>69.82±2.66</cell><cell>77.10±1.24</cell><cell>61.20±2.33</cell><cell>60.72±2.94</cell><cell>63.20±2.19</cell></row><row><cell>SMR</cell><cell>80.22±1.07</cell><cell>89.97±0.19</cell><cell>78.27±0.26</cell><cell>75.30±1.70</cell><cell>79.40±0.22</cell><cell>77.88±1.17</cell><cell>86.80±0.12</cell><cell>73.63±1.38</cell><cell>71.99±2.30</cell><cell>74.98±1.29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV RESULTS</head><label>IV</label><figDesc>ON YALEB.</figDesc><table><row><cell>Features</cell><cell></cell><cell></cell><cell>SDSIFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LPQ</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell></row><row><cell>StructAE</cell><cell>94.70±2.50</cell><cell>96.58±0.76</cell><cell>92.29±2.44</cell><cell>89.72±3.90</cell><cell>92.50±2.37</cell><cell>45.65±1.06</cell><cell>50.24±1.45</cell><cell>20.84±0.28</cell><cell>22.25±0.28</cell><cell>26.61±0.23</cell></row><row><cell>SAEg</cell><cell>88.32±2.60</cell><cell>93.15±0.86</cell><cell>84.68±2.30</cell><cell>79.73±3.74</cell><cell>85.10±2.22</cell><cell>27.77±0.58</cell><cell>32.88±0.45</cell><cell>7.40±0.51</cell><cell>7.88±0.47</cell><cell>10.68±0.43</cell></row><row><cell>SAEs</cell><cell>85.95±0.77</cell><cell>92.77±0.52</cell><cell>83.00±1.90</cell><cell>77.28±2.76</cell><cell>83.48±1.84</cell><cell>24.95±0.37</cell><cell>32.21±0.33</cell><cell>8.52±0.20</cell><cell>9.60±0.29</cell><cell>11.32±0.16</cell></row><row><cell>SSC</cell><cell>86.35±1.13</cell><cell>92.82±0.48</cell><cell>84.04±1.06</cell><cell>80.22±1.58</cell><cell>84.47±1.03</cell><cell>37.71±0.61</cell><cell>32.46±0.81</cell><cell>9.90±0.35</cell><cell>8.89±0.27</cell><cell>13.45±0.32</cell></row><row><cell>KSSC-R</cell><cell>85.31±1.68</cell><cell>91.02±0.37</cell><cell>78.47±0.82</cell><cell>74.00±1.19</cell><cell>79.07±0.80</cell><cell>41.93±1.11</cell><cell>37.50±0.42</cell><cell>13.09±0.69</cell><cell>11.16±0.64</cell><cell>16.45±0.60</cell></row><row><cell>KSSC-P</cell><cell>62.39±1.19</cell><cell>68.07±0.56</cell><cell>38.25±3.10</cell><cell>33.27±3.79</cell><cell>40.19±2.91</cell><cell>42.39±1.17</cell><cell>38.08±1.10</cell><cell>13.85±0.85</cell><cell>11.72±0.71</cell><cell>15.23±0.77</cell></row><row><cell>LS3C-L</cell><cell>51.28±1.02</cell><cell>61.60±0.46</cell><cell>29.66±0.65</cell><cell>26.08±0.83</cell><cell>31.89±0.60</cell><cell>44.06±0.79</cell><cell>46.05±0.37</cell><cell>9.85±0.23</cell><cell>8.66±0.18</cell><cell>13.49±0.20</cell></row><row><cell>LS3C-P</cell><cell>48.82±1.39</cell><cell>54.76±0.39</cell><cell>17.08±1.42</cell><cell>13.91±1.29</cell><cell>20.22±1.26</cell><cell>14.65±0.39</cell><cell>21.11±0.40</cell><cell>0.98±0.03</cell><cell>3.14±0.02</cell><cell>5.42±0.04</cell></row><row><cell>LS3C-R</cell><cell>10.56±0.29</cell><cell>13.15±0.19</cell><cell>1.10±0.07</cell><cell>3.50±0.05</cell><cell>4.11±0.10</cell><cell>6.72±0.10</cell><cell>6.90±0.20</cell><cell>0.05±0.03</cell><cell>2.63±0.02</cell><cell>3.49±0.05</cell></row><row><cell>LRR</cell><cell>85.62±0.55</cell><cell>92.99±0.43</cell><cell>83.25±2.13</cell><cell>77.27±3.08</cell><cell>83.73±2.07</cell><cell>38.69±1.31</cell><cell>49.93±0.51</cell><cell>14.38±3.24</cell><cell>17.73±3.50</cell><cell>21.84±3.03</cell></row><row><cell>KLRR-R</cell><cell>70.27±1.10</cell><cell>75.84±0.17</cell><cell>49.12±1.15</cell><cell>43.24±1.60</cell><cell>50.67±1.10</cell><cell>36.30±0.58</cell><cell>46.49±0.53</cell><cell>13.70±0.90</cell><cell>10.97±1.12</cell><cell>15.93±0.81</cell></row><row><cell>KLRR-P</cell><cell>69.76±1.36</cell><cell>75.81±0.52</cell><cell>52.18±1.06</cell><cell>47.70±1.91</cell><cell>53.57±0.99</cell><cell>19.87±0.52</cell><cell>35.73±0.54</cell><cell>9.99±0.28</cell><cell>12.06±0.27</cell><cell>12.39±0.27</cell></row><row><cell>LRSC</cell><cell>74.74±0.62</cell><cell>79.63±0.73</cell><cell>58.06±1.67</cell><cell>53.04±2.19</cell><cell>59.28±1.60</cell><cell>45.65±0.97</cell><cell>49.64±0.62</cell><cell>17.44±0.89</cell><cell>15.74±0.83</cell><cell>20.98±0.86</cell></row><row><cell>LSR1</cell><cell>76.02±1.21</cell><cell>80.14±0.47</cell><cell>58.27±1.60</cell><cell>53.00±2.42</cell><cell>59.48±1.53</cell><cell>41.50±1.22</cell><cell>47.00±0.54</cell><cell>11.00±1.30</cell><cell>17.39±1.31</cell><cell>17.65±1.18</cell></row><row><cell>LSR2</cell><cell>74.70±1.32</cell><cell>79.39±0.80</cell><cell>56.14±0.34</cell><cell>50.41±0.64</cell><cell>57.43±0.33</cell><cell>41.40±0.89</cell><cell>47.76±0.78</cell><cell>11.93±1.67</cell><cell>18.32±1.76</cell><cell>18.10±1.53</cell></row><row><cell>SMR</cell><cell>77.76±0.44</cell><cell>83.44±0.39</cell><cell>64.71±1.03</cell><cell>59.51±1.72</cell><cell>65.72±0.99</cell><cell>44.77±0.46</cell><cell>48.12±1.00</cell><cell>18.55±2.62</cell><cell>14.04±3.42</cell><cell>19.11±2.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V RESULTS</head><label>V</label><figDesc>ON MNIST. improved if the parameters for the structure prior are specifically tuned. Furthermore, we also examine the performance of StructAE with subspace clustering and latent subspace clustering. To this end, four variants of StructAE are proposed and investigated, i.e. StructAE-L1S, StructAE-L2S, StructAE-L1L, and StructAE-L2L. The first two methods correspond to StructAE-L1 and StructAE-L2 with k-means (clustering in subspace).</figDesc><table><row><cell>Features</cell><cell></cell><cell></cell><cell>SDSIFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LPQ</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell><cell>Accuracy</cell><cell>NMI</cell><cell>ARI</cell><cell>Precision</cell><cell>Fscore</cell></row><row><cell>StructAE</cell><cell>65.70±0.00</cell><cell>68.98±0.00</cell><cell>57.99±0.00</cell><cell>57.31±0.00</cell><cell>62.60±0.00</cell><cell>61.10±0.02</cell><cell>55.95±0.06</cell><cell>45.40±0.04</cell><cell>49.12±0.04</cell><cell>51.10±0.04</cell></row><row><cell>SAEg</cell><cell>52.03±0.47</cell><cell>55.93±0.07</cell><cell>38.71±0.09</cell><cell>36.83±0.05</cell><cell>46.47±0.09</cell><cell>31.65±0.00</cell><cell>25.10±0.00</cell><cell>13.96±0.00</cell><cell>21.41±0.00</cell><cell>23.39±0.00</cell></row><row><cell>SAEs</cell><cell>48.63±1.05</cell><cell>53.73±0.31</cell><cell>37.04±1.18</cell><cell>37.21±2.32</cell><cell>44.64±0.69</cell><cell>31.65±0.00</cell><cell>25.10±0.00</cell><cell>13.96±0.00</cell><cell>21.41±0.00</cell><cell>23.39±0.00</cell></row><row><cell>SSC</cell><cell>63.85±0.00</cell><cell>65.33±0.00</cell><cell>53.36±0.00</cell><cell>54.81±0.00</cell><cell>60.48±0.00</cell><cell>58.17±0.00</cell><cell>53.98±0.00</cell><cell>42.03±0.00</cell><cell>46.78±0.00</cell><cell>49.90±0.00</cell></row><row><cell>KSSC-R</cell><cell>60.90±0.00</cell><cell>64.60±0.00</cell><cell>51.65±0.00</cell><cell>51.70±0.00</cell><cell>57.00±0.00</cell><cell>55.10±0.00</cell><cell>50.23±0.00</cell><cell>37.66±0.00</cell><cell>42.59±0.00</cell><cell>44.15±0.00</cell></row><row><cell>KSSC-P</cell><cell>61.20±0.00</cell><cell>65.06±0.00</cell><cell>52.06±0.00</cell><cell>52.08±0.00</cell><cell>57.36±0.00</cell><cell>54.93±0.00</cell><cell>49.81±0.00</cell><cell>37.35±0.00</cell><cell>42.35±0.00</cell><cell>43.86±0.00</cell></row><row><cell>LS3C-L</cell><cell>35.17±0.22</cell><cell>40.47±0.11</cell><cell>25.73±0.12</cell><cell>28.12±0.10</cell><cell>35.01±0.10</cell><cell>42.15±0.01</cell><cell>42.29±0.03</cell><cell>27.31±0.02</cell><cell>32.46±0.01</cell><cell>35.23±0.02</cell></row><row><cell>LS3C-P</cell><cell>47.01±0.50</cell><cell>48.28±0.09</cell><cell>33.46±0.07</cell><cell>37.22±0.04</cell><cell>40.78±0.08</cell><cell>41.73±0.01</cell><cell>39.09±0.01</cell><cell>25.25±0.00</cell><cell>30.77±0.00</cell><cell>33.39±0.00</cell></row><row><cell>LS3C-R</cell><cell>64.05±0.00</cell><cell>66.71±0.00</cell><cell>54.94±0.00</cell><cell>55.91±0.00</cell><cell>61.09±0.00</cell><cell>58.98±0.00</cell><cell>53.79±0.00</cell><cell>43.14±0.00</cell><cell>47.37±0.00</cell><cell>49.47±0.00</cell></row><row><cell>LRR</cell><cell>63.69±0.02</cell><cell>66.37±0.04</cell><cell>53.88±0.03</cell><cell>53.59±0.03</cell><cell>58.97±0.02</cell><cell>60.20±0.00</cell><cell>55.26±0.00</cell><cell>44.52±0.00</cell><cell>48.98±0.00</cell><cell>50.24±0.00</cell></row><row><cell>KLRR-R</cell><cell>58.67±0.00</cell><cell>57.16±0.00</cell><cell>45.06±0.00</cell><cell>49.57±0.00</cell><cell>50.70±0.00</cell><cell>54.93±0.00</cell><cell>50.31±0.00</cell><cell>38.42±0.00</cell><cell>43.49±0.00</cell><cell>44.79±0.00</cell></row><row><cell>KLRR-P</cell><cell>58.67±0.00</cell><cell>58.90±0.00</cell><cell>46.22±0.00</cell><cell>50.36±0.00</cell><cell>51.77±0.00</cell><cell>53.27±0.00</cell><cell>46.59±0.00</cell><cell>35.34±0.00</cell><cell>41.05±0.00</cell><cell>41.98±0.00</cell></row><row><cell>LRSC</cell><cell>56.96±0.02</cell><cell>56.72±0.03</cell><cell>44.58±0.04</cell><cell>46.82±0.04</cell><cell>50.60±0.04</cell><cell>50.71±0.05</cell><cell>46.42±0.06</cell><cell>34.69±0.05</cell><cell>39.49±0.04</cell><cell>41.59±0.05</cell></row><row><cell>LSR1</cell><cell>62.48±0.00</cell><cell>60.05±0.00</cell><cell>48.38±0.00</cell><cell>52.17±0.00</cell><cell>53.71±0.00</cell><cell>50.92±0.00</cell><cell>46.53±0.00</cell><cell>34.93±0.00</cell><cell>39.94±0.00</cell><cell>41.76±0.00</cell></row><row><cell>LSR2</cell><cell>62.50±0.00</cell><cell>59.95±0.00</cell><cell>48.32±0.00</cell><cell>52.13±0.00</cell><cell>53.66±0.00</cell><cell>50.88±0.00</cell><cell>46.60±0.00</cell><cell>34.96±0.00</cell><cell>39.91±0.00</cell><cell>41.80±0.00</cell></row><row><cell>SMR</cell><cell>62.77±0.00</cell><cell>67.22±0.83</cell><cell>56.19±0.00</cell><cell>56.83±0.00</cell><cell>61.62±0.00</cell><cell>51.20±0.00</cell><cell>49.01±0.00</cell><cell>36.21±0.00</cell><cell>40.65±0.00</cell><cell>42.98±0.00</cell></row><row><cell cols="6">results of StructAE with sparse (denoted by StructAE-L1) and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p><p>non-sparse prior (denoted by StructAE-L2) on the CIFAR10 data set. Specifically, StructAE-L1 adopts the sparsity by solving Eq. (</p>5</p>), and StructAE-L2 utilizes the prior derived from Eq. (</p>6</p>). In our experiments, we directly use the tuned parameters from SSC for StructAE-L1 and from LSR2 for StructAE-L2. This implies that the performance of StructAEs might be further</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Fig.2shows that our method could learn a compact and distinctive representation which makes it superior to the tested methods.2) Results on YaleB: We set λ 1 = 10 -4 and µ = 2 -10 for StructAE in this experiment. TableIVreports results of the tested methods on the YaleB data set, which shows that: 1) In</figDesc><table><row><cell>• Considering different features, the best performance is</cell></row><row><cell>achieved by our StructAE on SDSIFT. The Accuracy of</cell></row><row><cell>StructAE increases from 84.38% (using the LPQ features)</cell></row><row><cell>to 91.04%.</cell></row><row><cell>• Among the tested approaches, StructAE and LS3C are</cell></row><row><cell>only two methods to perform subspace clustering in</cell></row><row><cell>the learned latent space. The results show that LS3C is</cell></row><row><cell>inferior to our StructAE. This may be because LS3C is</cell></row><row><cell>a shallow model while ours are deep models.</cell></row><row><cell>• StructAE also remarkably outperforms SAE. This result</cell></row><row><cell>is not surprising because our model incorporates locality</cell></row><row><cell>and globality together, while SAE only considers the</cell></row><row><cell>locality and ignores the relations among data points.</cell></row></table><note><p>•</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI COMPARISON</head><label>VI</label><figDesc>WITH DEEP FEATURES. THE NUMBERS IN BOLDFACE INDICATE THE BEST RESULT ACCORDING TO THE T-TEST, WHERE THE SIGNIFICANCE LEVEL IS 0.05.</figDesc><table><row><cell>Methods</cell><cell>CIFAR10</cell><cell>COIL20</cell><cell>YaleB</cell><cell>mnist</cell></row><row><cell>StructAE</cell><cell>25.92±0.95</cell><cell>91.04±2.23</cell><cell>94.70±2.50</cell><cell>65.70±0.00</cell></row><row><cell>SSC+VGG16</cell><cell>20.40±0.10</cell><cell>28.49±0.53</cell><cell>35.85±2.64</cell><cell>56.55±0.00</cell></row><row><cell>SSC+ResNet50</cell><cell>21.56±0.10</cell><cell>41.01±0.57</cell><cell>40.47±1.49</cell><cell>62.87±0.01</cell></row><row><cell>LRR+VGG16</cell><cell>11.68±0.16</cell><cell>76.08±1.87</cell><cell>55.14±1.99</cell><cell>11.81±0.09</cell></row><row><cell>LRR+ResNet50</cell><cell>12.75±0.15</cell><cell>64.42±2.65</cell><cell>6.55±0.11</cell><cell>64.35±0.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII TIME</head><label>VII</label><figDesc>COST ON THE CIFAR10 DATA SET WITH THE DSIFT FEATURE.</figDesc><table><row><cell>Methods</cell><cell>Training Time (s)</cell><cell>Inference Time (s)</cell></row><row><cell>StructAE-L1S</cell><cell>16434.84±61.89</cell><cell>258.30±19.31</cell></row><row><cell>StructAE-L1L</cell><cell>31468.28±72.26</cell><cell>295.07±54.49</cell></row><row><cell>StructAE-L2S</cell><cell>13542.07±82.62</cell><cell>185.41±10.61</cell></row><row><cell>StructAE-L2L</cell><cell>21503.82±69.96</cell><cell>129.20±13.91</cell></row><row><cell>SAEg</cell><cell>11311.43±67.13</cell><cell>311.43±34.40</cell></row><row><cell>SAEs</cell><cell>11313.16±59.26</cell><cell>313.16±27.13</cell></row><row><cell>SSC</cell><cell>106.26±6.93</cell><cell>-</cell></row><row><cell>KSSC-R</cell><cell>5613.10±29.94</cell><cell>-</cell></row><row><cell>KSSC-P</cell><cell>7393.17±75.11</cell><cell>-</cell></row><row><cell>LS3C-L</cell><cell>1166.00±12.43</cell><cell>-</cell></row><row><cell>LS3C-P</cell><cell>406.62±0.55</cell><cell>-</cell></row><row><cell>LS3C-G</cell><cell>652.72±1.01</cell><cell>-</cell></row><row><cell>LRR</cell><cell>168.07±4.64</cell><cell>-</cell></row><row><cell>KLRR-R</cell><cell>4139.38±98.83</cell><cell>-</cell></row><row><cell>KLRR-P</cell><cell>25.44±0.49</cell><cell>-</cell></row><row><cell>LRSC</cell><cell>35.34±2.37</cell><cell>-</cell></row><row><cell>LSR1</cell><cell>48.11±2.23</cell><cell>-</cell></row><row><cell>LSR2</cell><cell>50.96±1.95</cell><cell>-</cell></row><row><cell>SMR</cell><cell>197.88±4.63</cell><cell>-</cell></row><row><cell cols="3">proposed approaches in terms of five clustering evaluation</cell></row><row><cell>metrics.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In this paper, we mainly investigate 1 -norm based sparsity and 1 -norm based self-expression prior as calculated in Eq. (5)-(6).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Note that, it is also feasible and quite easy to formulate the graph Laplacian into J 2 to utilize the local consistency based on pairwise distance.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1057-7149 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TIP.2018.2848470, IEEE</p><p>Transactions on Image Processing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Prof. Vishal Monga and anonymous reviewers for their valuable comments and constructive suggestions to improve the quality of this paper.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>X. Peng was partially supported by the Fundamental Research Funds for the Central Universities under Grant YJ201748, NFSC under Grant 61432012 and Grant U1435213, and the Fund of Sichuan University -Tomorrow Advancing Life (TAL). J. Feng was partially supported by NUS startup R-263-000-C08-133, MOE Tier-I R-263-000-C21-112, NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133 and MOE Tier-II R-263-000-D17-112. W. Yau was supported by Singapore's RIE2020 AME-Programmatic Grant A1687b0033. S. Yang was supported by NFSC under Grant 61501312.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Subspace clustering</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Proc. Mag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="52" to="68" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 14th Adv</title>
		<meeting>of 14th Adv<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-12">Dec. 2001</date>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral ensemble clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 21th ACM SIGKDD Int. Conf. Knowl. Dis. and Data Min</title>
		<meeting>of 21th ACM SIGKDD Int. Conf. Knowl. Dis. and Data Min<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08">Aug. 2015</date>
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised and semisupervised learning via l1-norm graph</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 12th IEEE Conf. Comput. Vis</title>
		<meeting>of 12th IEEE Conf. Comput. Vis<address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11">Nov. 2011</date>
			<biblScope unit="page" from="2268" to="2273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust and efficient subspace segmentation via least squares regression</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 12th Eur. Conf. Comput. Vis</title>
		<meeting>of 12th Eur. Conf. Comput. Vis<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-10">Oct. 2012</date>
			<biblScope unit="page" from="347" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2765" to="2781" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust subspace clustering with complex noise</title>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4001" to="4013" />
			<date type="published" when="2015-11">Nov 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust subspace clustering via thresholding ridge regression</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 29th AAAI Conf</title>
		<meeting>of 29th AAAI Conf<address><addrLine>Austin Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-01">Jan. 2015</date>
			<biblScope unit="page" from="3827" to="3833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Low-rank tensor constrained multiview subspace clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the 15th Int. Conf. on Comput. Vis</title>
		<meeting>the 15th Int. Conf. on Comput. Vis<address><addrLine>Santiago</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
			<biblScope unit="page" from="1582" to="1590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">L0-sparse subspace clustering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jojic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 14th Euro. Conf. Comput. Vis</title>
		<meeting>of 14th Euro. Conf. Comput. Vis<address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10">Oct. 2016</date>
			<biblScope unit="page" from="731" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A structured sparse plus structured low-rank framework for subspace clustering and completion</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="6557" to="6570" />
			<date type="published" when="2016-12">Dec 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Constructing the l2-graph for robust subspace learning and subspace clustering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1053" to="1066" />
			<date type="published" when="2017-04">Apr. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Oracle based active set algorithm for scalable elastic net subspace clustering</title>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 29th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 29th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="3928" to="3937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discrete nonnegative spectral clustering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">High-rank matrix completion and clustering under selfexpressive models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 28th Adv</title>
		<editor>
			<persName><surname>Neural Inf</surname></persName>
		</editor>
		<editor>
			<persName><surname>Process</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Syst</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><surname>Garnett</surname></persName>
		</editor>
		<meeting>of 28th Adv<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="73" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Shape interaction matrix revisited and robustified: Efficient subspace clustering with corrupted and incomplete data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 15th IEEE Conf. Comput. Vis</title>
		<meeting>of 15th IEEE Conf. Comput. Vis<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A unified framework for representation-based subspace clustering of out-of-sample and largescale data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2499" to="2512" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dual-clustering-based hyperspectral band selection by contextual analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1431" to="1445" />
			<date type="published" when="2016-03">Mar. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An efficient representation-based method for boundary point and outlier detection</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2018-01">Jan 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust kernel low-rank representation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Y</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural. Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kernel sparse subspace clustering</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conf. on Image Process</title>
		<meeting>of Int. Conf. on Image ess<address><addrLine>Paris</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
			<biblScope unit="page" from="2849" to="2853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Triplet-based deep hashing network for cross-modal retrieval</title>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3893" to="3903" />
			<date type="published" when="2018-08">Aug 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Yotube: Searching action proposal via recurrent and static regression networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2609" to="2622" />
			<date type="published" when="2018-06">Jun. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transfer hashing: From shallow to deep</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S M</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised deep hashing with similarity-adaptive and discrete optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Latent space sparse subspace clustering</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V N</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 14th IEEE Conf. Comput. Vis</title>
		<meeting>of 14th IEEE Conf. Comput. Vis<address><addrLine>Sydney, VIC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12">Dec. 2013</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 25th Int. Joint Conf</title>
		<meeting>of 25th Int. Joint Conf<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07">Jul. 2016</date>
			<biblScope unit="page" from="1925" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation with block-diagonal prior</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 27th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 27th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">Jun. 2014</date>
			<biblScope unit="page" from="3818" to="3825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discriminative embedded clustering: A framework for grouping high-dimensional data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural. Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1287" to="1299" />
			<date type="published" when="2015-06">Jun. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic subspace learning via principal coefficients embedding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3583" to="3596" />
			<date type="published" when="2017-11">Nov. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 33th Int. Conf. Mach. Learn</title>
		<meeting>of 33th Int. Conf. Mach. Learn<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 29th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 29th IEEE Conf. Comput. Vis. and Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cascade subspace clustering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 31th AAAI Conf. on Artif. Intell. SFO, USA: AAAI</title>
		<meeting>of 31th AAAI Conf. on Artif. Intell. SFO, USA: AAAI</meeting>
		<imprint>
			<date type="published" when="2017-02">Feb. 2017</date>
			<biblScope unit="page" from="2478" to="2484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 29th Adv</title>
		<meeting>of 29th Adv<address><addrLine>Montral, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Connections between nuclear norm and frobenius norm based representation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A closed form solution to robust subspace estimation and clustering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 24th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 24th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Colorado Springs, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06">Jun. 2011</date>
			<biblScope unit="page" from="1801" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Smooth representation clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 27th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 27th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">Jun. 2014</date>
			<biblScope unit="page" from="3834" to="3841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-07">Jul. 2014</date>
			<pubPlace>Qubec, Canada</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discriminative deep metric learning for face verification in the wild</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 27th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 27th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">Jun. 2014</date>
			<biblScope unit="page" from="1875" to="1882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fast l1-minimization algorithms and an application in robust face recognition: A review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno>UCB/EECS-2010-13</idno>
		<imprint>
			<date type="published" when="2010-02">Feb. 2010</date>
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Nene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
		<idno>CUCS-005-96</idno>
	</analytic>
	<monogr>
		<title level="m">Columbia object image library</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>coil-20</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Who are you? -learning person specific classifiers from video</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 22th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 22th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
			<biblScope unit="page" from="1145" to="1152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE</title>
		<meeting>of IEEE</meeting>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Similarity scores based on background samples</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 9th Asian Conf. Comput. Vis</title>
		<meeting>of 9th Asian Conf. Comput. Vis<address><addrLine>Xi&apos;an, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">Sep. 2010</date>
			<biblScope unit="volume">5995</biblScope>
			<biblScope unit="page" from="88" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 18th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 18th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Blur insensitive texture classification using local phase quantization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ojansivu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heikkilä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image and signal process</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<ptr target="http://arxiv.org/abs/1409.1556" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 29th IEEE Conf. Comput. Vis. and Pattern Recognit</title>
		<meeting>of 29th IEEE Conf. Comput. Vis. and Pattern Recognit<address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
