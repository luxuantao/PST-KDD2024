<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Symbolic Clustering Using a New Similarity Measure</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">K</forename><forename type="middle">Chidananda</forename><surname>Gowda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">S. J. College of Engineering</orgName>
								<address>
									<postCode>570 006</postCode>
									<settlement>Mysore</settlement>
									<region>Karnataka</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">E</forename><surname>Diday</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">S. J. College of Engineering</orgName>
								<address>
									<postCode>570 006</postCode>
									<settlement>Mysore</settlement>
									<region>Karnataka</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">France</forename><forename type="middle">K C</forename><surname>Gowda</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Institut National de Recherche en Informatique et en Automatique</orgName>
								<orgName type="department" key="dep2">Domaine de Voluceau-Rocquencourt</orgName>
								<orgName type="institution">IEEE Log Number</orgName>
								<address>
									<addrLine>B.P. 105</addrLine>
									<postCode>78153, 9104105</postCode>
									<settlement>Le Chesnay Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Symbolic Clustering Using a New Similarity Measure</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">49C3FE54770362C16AB1992C0100FC0C</idno>
					<note type="submission">received July 15, 1990; revised May 22, 1991.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T04:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>mass unknown to the control system) occurs at t = 4 s. Figs. [11]<ref type="bibr" target="#b25">[12]</ref><ref type="bibr" target="#b26">[13]</ref> show the system performance, which is, once again excellent. The inverse modeling is employed only for the first of the double steps. Note that the run was terminated before the last weights reached steady-state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Higher Degree of Freedom Manipulators</head><p>The analysis and simulation work summarized herein has been based upon a relatively simple two DOF manipulator. Extension to higher DOF manipulators posses no theoretical or conceptual problems. However, the sheer complexity of the algebra associated with the dynamic models and state representations of manipulators beyond three DOF can become cumbersome, and, in the case of a six DOF manipulator, can be truly overwhelming <ref type="bibr" target="#b29">[16]</ref>. However, from the standpoint of controller design as opposed to manipulator simulation, such complexity would probably not been needed with the methodology that has been proposed herein. Controlled designs for two or three DOF manipulators are quite manageable with the MRAC-TD filter approach, and by applying such designs to successive sets of two or three joints and neglecting the dynamic coupling from the remaining joints in the design, one could create controllers for higher DOF manipulators. It is worth pointing out that, in the last simulation example, errors of &amp;300% in the elements of the A matrix were effectively introduced by the variations in the mass m z in addition to the injection of large torque disturbances. The ability of the MRAC-TD filter system to perform well in the presence of modeling errors and noise injection of these magnitudes would support the conjecture that neglecting some dynamic coupling in controller designs may be tolerable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>The TD filter has been implemented as part of a MRAC system with the adaptive logic based upon Lyapunov stability and applied to the problem of robot trajectory control.</p><p>The TD filters allow the straightforward implementation of an inverse modeling scheme with fixed gain rate feedback to utilize available knowledge of the system. This knowledge improved system performance by providing a very useful "start up" scheme for the MRAC system. In addition, the rate feedback increases the robustness of the MRAC system by reducing the uncertainty norm.</p><p>The on-line adaptation algorithm involves little computational effort and the TD filters have been implemented with as few as five weights per robot joint. Measurement of only link angular orientation and rate were required.</p><p>The performance of the system was evaluated using a simulation of a simple, planar, two-link robot undergoing step commands in link orientation. Very large variations in payload mass and large disturbing torques were incorporated in the simulation and performance was found to be excellent.</p><p>Future research should address: 1) design parameter variations, i.e., the effect of number of weights, i1', and tap delay time At, upon robustness and performance, and 2) the effects of neglected higher-order dynamics, such as those of actuators, upon robustness and performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In the conventional data analysis, the objects are numerical vectors. The clustering of such objects is achieved by minimizing intracluster dissimilarity and maximizing intercluster dissimilarity. A good survey of cluster analysis can be found in literature [1]- <ref type="bibr">[5]</ref>.</p><p>Symbolic objects are extensions of classical data types. In conventional data sets, the objects are "individualized" whereas in symbolic data sets, they are more "unified" by means of relationships.</p><p>They are more complex than conventional data in following ways: 1) All objects of a symbolic data set may not be defined on the same variables.</p><p>2) Each variable may take more than one value or even an interval of values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3)</head><p>In complex symbolic objects, the values that the variables take may include one or more elementary objects. 4) The description of a symbolic object may depend on the relations existing between other objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">)</head><p>The values that the variables take may have typicality values that indicate frequency of occurrence, relative likelihood, level of importance of the values, and so on. Based on the complexity, the symbolic objects can be of Assertion, Hoard, or Synthetic type. Some references to clustering of symbolic objects can be found in Diday <ref type="bibr" target="#b19">[6]</ref>, <ref type="bibr" target="#b21">[8]</ref>, Diday et al. <ref type="bibr" target="#b20">[7]</ref>, and Michalski et al. <ref type="bibr">[9]</ref>.</p><p>Under the title of conceptual clustering, Michalski et al.</p><p>[9], [ 101 have developed CLUSTERR, a nonincremental methodology to generate concept descriptions for a given number of clusters selecting a better and better seed for each cluster. Their data sets consist of microcomputers and soybean diseases.</p><p>Cheng and Fu [ l l ] describe HUATUO, which is a conceptual clustering algorithm based on a distance measure for rules. They use a qualitative data set of disease manifestations and medical prescriptions.</p><p>Labowitz [ 121 presents UNIMEM, which creates nondisjoint concept hierarchies incrementally using several parameters and a matching process that recognizes similar instances. The data sets used in his experiments are drawn from the domains of universities, congressional voting records, and terrorist events.</p><p>The methodology of COBWEB developed by Fisher [13] performs incremental conceptual clustering in which concept hierarchies are incrementally formed top down using a category utility metric and probabilistic representation of concepts. The data sets are drawn from the domains of voting records, charcoal rot, and soybean diseases.</p><p>Kodratoff and Tecuci [ 141 present a hierarchical conceptual clustering algorithm that groups objects so as to maximize cohesiveness that is a function of conceptual distance based on generalizations. Ichino [ 151 defines general distance functions for mixed feature variables and presents dendrograms by the single linkage and complete linkage methods for data sets containing numeric and symbolic feature values. Hwang [ 161 uses symbolic clustering for grouping hypotheses with similar transform parameters so as to get a new transform hypothesis that is used in the hypothesis-and-test approach for recognizing and locating 2-D objects.</p><p>A hierarchical symbolic clustering algorithm is proposed in this paper. We were motivated by the general metrics for mixed features <ref type="bibr" target="#b28">[15]</ref> and the idea of conceptual distance [14] to define a new similarity measure with good discrimination properties. The proposed measure, defined on the basis of position, span, and content of symbolic objects, is applicable to symbolic data of mixed feature types consisting of quantitative (ratio, absolute, and interval) and qualitative <ref type="bibr">(nominal, ordinal, and combinational)</ref>  The methodology, in fact, makes use of two important principles of symbolic data analysis [6], namely, the coherence principle and the explicability principle. The coherence principle states that the input and output must be expressed by the same kind of objects. This is very much true in the proposed methodology. The explicability principle states that the results must be easily interpretable by the user even if they are less efficient. The results obtained by this method are easy to understand by the user and they can be used to build knowledge bases of expert systems.</p><p>The traditional principle of grouping objects into clusters utilizes some measure of object similarity, usually the reciprocal of a distance measure [SI. The objective of clustering is to group a set of objects into clusters such that the objects within a cluster have a high degree of similarity, while elements belonging to different clusters have a high degree of dissimilarity.</p><p>Kodratoff <ref type="bibr">[21]</ref> proposes that there should be distinct criteria of similarity and dissimilarity of symbolic objects and that one should not "average" over similarity and dissimilarity. In conventional clustering of numeric objects, dissimilarity is just another aspect of similarity that leads to the view that the more similar two objects are, the less dissimilar they remain. Such a hypothesis is not true in the case of symbolic similarity and dissimilarity. It is quite possible that two symbolic objects are very much similar in some aspects and quite dissimilar in some other aspects. It is suggested [21] that the dissimilarity criterion should serve to cluster the examples in clusters that are well-distinguished and that the similarity criterion should serve just to decide between the clusters displaying the same dissimilarity. Without contradicting this, we would like to suggest a new viewpoint. In real life, as the saying "birds of the same feather flock together" goes, people come closer together when there are lot of similarities between them; and they go apart when they have lot of differences. By analogy it can be said that the similarity criterion should be used for agglomerative clustering and the dissimilarity criterion for divisive clustering.</p><p>This paper deals with an agglomerative clustering algorithm for symbolic data using the newly defined similarity measure. A divisive clustering algorithm for symbolic data using a new dissimilarity measure will be given in a subsequent paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">DESCRIPTIONS OF SYMBOLIC OBJECTS</head><p>Various definitions and descriptions of symbolic objects are given by Diday <ref type="bibr" target="#b19">[6]</ref>. Symbolic objects are defined by a logical conjunction of events linking values and variables in which the variables can take one (including none) or more values and all the objects need not be defined on the same variables. We give below a nonformal description of symbolic objects of the type Assertion, Hoard, and Synthetic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event</head><p>feature values of objects. The following are two examples for events:</p><formula xml:id="formula_0">e l = [height = [1.5 -2.011 e2 = [color = {white, blue}].</formula><p>Here, e l is an event that indicates that the variable height takes a value between 1.5 and 2.0; and e2 is an event that indicates that the variable color takes a value either white or blue.</p><p>An event is a value-variable pair that links feature variables and   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assertion Objects</head><p>An assertion object is a conjunction of events pertaining to a particular object. Following is an example for an Assertion object:</p><formula xml:id="formula_1">a = [color={green, blue}]&amp;[size = 32]&amp;[price = [lo0 -15011.</formula><p>Here a is an Assertion object, having the following properties: 1) color is either green or blue 2) size equals 32</p><p>3) price ranges between 100 and 150.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hoard Objects</head><p>and events. Following is an example of an Hoard object:</p><p>A hoard object is a conjunction of two or more Assertion objects </p><formula xml:id="formula_2">h =[ VDU(computerl)=color] &amp; [RAM(computerl)=64K] &amp; [Keys(computerl) = [57-63]] &amp; [VDU(computer 2)</formula><formula xml:id="formula_3">=B&amp;W] &amp; [RAM(computer2)=48K] &amp; [Keys(computer2) = [ 64-73]].</formula><p>It means that the Hoard object h consists of two elementary objects: 1) "computerl" having a color VDU, 64K RAM, and Keys 2) "computer 2" having B&amp;W V D U , 48K RAM, and Keys between 57 and 63.</p><p>between 64 and73.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic Objects</head><p>and events. Following is an example for a Synthetic object:</p><p>A Synthetic object is a conjunction of two or more Hoard objects</p><formula xml:id="formula_4">s = h l &amp; h2 =[type(rl)=Expressway] &amp; [vehicles(r 1)=2] [type(v l)=car] [type(. 2)=truck] [type(v3)=bus] &amp; [type(r2)=Mainroad]&amp; [vehicles(r2)=1] &amp; &amp; [color(u l)=blue] &amp; [rnoving(vl)=rl] &amp; &amp; [color(v2)=red] &amp; [moving(v2)=rl] &amp; &amp; [color(v3)=green] &amp; [moving(v3)=r2].</formula><p>It means the synthetic object s consists of two Hoard objects h l and h2 where h l is a Hoard of roads and it consists of two elementary objects: r l : It is an Expressway with 2 vehicles. r2: It is a mainroad with 1 vehicle. u l : It is a car of blue color and it is on r l . v2: It is a truck of red color and it is on r l . u3: It is a bus of green color and it is on r2.</p><p>h2 is a Hoard of vehicles and it consists of three elementary objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">CONCEPTS AND DEFINITIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Types</head><p>of features Ak and Bk as:</p><p>Two Symbolic objects A and B are written as the Cartesian product x .</p><formula xml:id="formula_5">A = A l X A z X * . . X A d B = B i X B i</formula><formula xml:id="formula_6">X I I x x x I x x x I X x x x x X x x x . . . --.</formula><p>...   e.g., designation, military rank, etc. e.g., road-crossing (highway 1, highway 2), vehiclesin-same-direction (car, bus), etc.</p><p>3) Structured Variables (tree-ordered or graph-oriented sets):</p><p>Structured variables are tree-ordered sets where the parent nodes represent the generalizations of the children nodes. For example, a parent node called "vehicle" may be a generalization may be a generalization of cars of the type "Ford," "Fiat," "Renault," "Benz," and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarity</head><p>mapping from U ( d ) into R+ having the following properties:</p><p>The similarity measure S between two objects A and B is a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) S ( A , A ) = S ( B , B ) &gt; S ( A , B ) 2) S ( A , B ) = S ( B . A )</head><p>Similarity between A and B is written as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S ( A , B ) =S(Ai,B1)+S(Az,Bz)+...+S(Ak,Bk). (1)</head><p>For the kth feature, S(Ak, B k ) is defined using the following three     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S ( &amp; , B k ) = S,(Ak,Bk)+ S,(Ak.Bk). (9)</head><p>Net similarity between Ak and BI, is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iv. COMPOSITE SYMBOLIC OBJECTS</head><p>Successive merging operations lie at the heart of agglomerative clustering methods. Merging is the process of gathering together, on the basis of a similarity measure two samples and assigning them same cluster membership, or label for further clustering. Merging of two objects can also be viewed as the formation of a "link" between them. In a clustering procedure, if two objects belonging to two different clusters are linked, it is equivalent to merging the two clusters. If the two objects that are merged are to be represented by a single object, one of the frequently used methods in conventional clustering is the use of the mean of the two as a single representative.</p><p>The clustering methodology proposed in this paper forms a composite object when two selected objects are merged. This composite object, along with the rest of the objects of the set, is used in further similarity analysis.</p><p>A composite symbolic object is a new object resulting from merging two symbolic objects using a Cartesian join Operator <ref type="bibr" target="#b28">[15]</ref>,</p><p>Let A = AlXA2X...Ad and B = BlXBzX...Bd be two objects in U ( d ) . Then the composite object C resulting from merging of A and B is</p><formula xml:id="formula_8">c = A + +B = (A1 + + B I ) X ( A Z + +&amp;)X ... X(Ad + +Bd) [221. (<label>10</label></formula><formula xml:id="formula_9">)</formula><p>where ++ is a Cartesian join operator. When the bth feature is quantitative or ordinal qualitative, Ak + +Bk is defined as the minimum interval that includes both Ak and Bk. That is,</p><formula xml:id="formula_10">d k + +Bk = [min(Akl, B ~I ) , max(Ak,, &amp;,)I (11)</formula><p>where Akl and Aku stand for the lower and upper bounds respectively of Ak. When the bth feature is qualitative nominal, Ak + +Bk is the union of Ak and Bk.</p><p>v. MUTUAL PAIRS <ref type="bibr">Gowda and Krishna [17]</ref>-[ZO] have introduced the concept of "Mutual Nearest Neighborhood" and successfully used it for agglomerative and disaggregate clustering, learning, condensed nearest neighbor rule, editing, and error correction. In a data set, on the basis of a similarity measure, if an object X , is the first Nearest Neighbor <ref type="bibr">["]</ref> of an object X,, and X, is the first N N of X,,then X , and X , constitute a "mutual pair." It has been observed that about 62% of the total number of individuals in random artificial and natural populations are in mutual pairs <ref type="bibr">[23]</ref>. The mutual pair having the highest similarity value corresponds to the two objects of the data set having the highest similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. ALGORITHM</head><p>The proposed similarity based algorithm is nonparametric, hierarchical, and agglomerative in nature. The criterion is to merge the most similar mutual pair at each step. The criterion used to select the most similar mutual pair is analogous to that used in stepwise-optimal hierarchical clustering making smallest possible stepwise increase in the sum-of-squared-error <ref type="bibr">[24]</ref>. This criterion, which has the flavor of   minimum variance, takes into account the number of samples in each cluster as well as the similarity between the clusters. It tends to favor the merging of singleton clusters or the merging of small clusters with large ones over merging of medium sized clusters.</p><p>The symbolic clustering algorithm proceeds as follows.</p><p>1) Let { X I , X Z , . . , X N } be a set of N symbolic objects. Let the initial number of clusters be N, with each cluster having a cluster weight (number of objects) of 1.</p><p>2) Compute the weighted similarities between all pairs of symbolic objects in the data set as</p><p>where n;, n j are Cluster weights (number of objects) of X ; and X j respectively, and sqrt represents square root S ( X ; , X i ) , which is the Similarity value is given by (1). Determine the minimum and maximum similarity values. Also determine the mutual pair having the highest similarity and form a composite object by merging the individuals of this pair. Reduce the number of clusters by 1.</p><p>Repeat step 2 until the number of clusters is equal to 1.</p><p>Calculate the cluster indicator value CI using (13). The stage where C I is maximum, indicates the number of clusters in the data.</p><p>The composite objects of that stage describe the symbolic objects representing the clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DETERMINATION OF THE NUMBER OF CLUSTERS</head><p>At each stage, maximum similarity indicates the similarities between the individual objects of the mutual pair that are combined to form a composite object. The minimum similarity values at each stage indicates the similarity between the most distant clusters. Lower this value, better is the separation between the clusters.</p><p>Cluster indicator value at the pth stage is  where maxp+l, maxp =Maximum similarities in 0, + 1)th and pth stage respectively: min, = Minimum similarity at the pth stage.</p><formula xml:id="formula_11">(13)</formula><p>The stage at which C I is maximum gives the number of clusters.</p><p>In order to describe the philosophy behind the technique of determining the number of clusters, an example is chosen so that there are 100 samples drawn from a mixture of four bivariate normal distributions with mean m,, and covariance matrix ct having individual variances of 0.  <ref type="formula">b</ref>) is 0.4066, which is found to be the highest considering all the preceding and succeeding levels. This shows that the difference between maximum similarities of the previous level and the present level is a good indicator of the number of classes.</p><p>On the other hand, minimum similarity at each stage indicates the similarity between the most distant clusters. Lower this value, better is the separation between the clusters. The minimum similarities corresponding to situations of Figs. l(a)-(c) are 0.1112, 0.0512, and 0.0840 respectively. In fact, 0.0512,corresponding to <ref type="bibr">Fig. l(b)</ref>, is found to be the lowest similarity value considering all the preceding and succeeding stages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. RESULTS OF SIMULATION</head><p>In order to corroborate the efficacy of the algorithm, several simulation studies were made, the results of which are given in the following.</p><p>Example I: The first example chosen is such that the input data is of numeric type and the output is symbolic. The objects of numeric type were drawn from a mixture of normal distributions with known number of classes and classification so that the results show the efficacy of the algorithm for clustering the objects and finding the number of classes. The test set is drawn from a mixture of c normal distributions with mean m 2 , and Covariance matrix c, having individual variances of 0.25 and zero covariances.</p><p>The different values of the number of classes and the means chosen are shown in Table <ref type="table" target="#tab_1">I</ref> and the test samples were independently generated using a Gaussian Vector generator. The proposed algorithm was used on this test data. As is indicated in Table <ref type="table" target="#tab_1">I</ref>, there is perfect agreement between the number of classes used for generating Gaussian clusters and the number of clusters indicated by the algorithm based on the cluster indicator value C I . In all the seven cases, the classification results were in full agreement with the test samples generated and the classes used.</p><p>Example 2: The second example is chosen so as to graphically</p><p>show the transformation of numeric data into symbolic data and the maximum peaking of the cluster indicator value at the actual number of classes. In this example 100 samples are drawn from a mixture of five 2-D normal distributions with mean m , , and covariance matrix c,, having individual variances of 0.25 and zero covariances. The mean values are rri1 =(1.0, 1.0) 1112 ~( 3 . 0 , 3.0) n13 =(5.0, 5.0) m4 =(7.0, 7.0) 711 5 ~( 9 . 0 , 9.0). One hundred samples were independently generated using a Gaussian vector generator having the above parameters. The proposed algorithm was used on this data. Fig. <ref type="figure" target="#fig_3">2</ref> shows that the maximum value of C I corresponds to 5 clusters. Fig. <ref type="figure" target="#fig_4">3</ref> shows five symbolic objects having interval type of feature values representing the five clusters.</p><p>Exampfe3: This example is chosen so as to demonstrate the efficacy of the algorithm in clustering data belonging to five classes with lot of overlaps. The data set consists of five classes of data in three dimensions, with each class having overlaps in two of the three dimensions. Table <ref type="table" target="#tab_1">I1</ref> shows the given data on which the proposed algorithm is applied. Fig. <ref type="figure" target="#fig_6">4</ref> shows the maximum value of CI, which corresponds to five clusters. Table <ref type="table" target="#tab_3">111</ref> shows the five symbolic objects having interval type of feature values representing the five clusters. Fig. <ref type="figure" target="#fig_6">4</ref> shows the variation of C I and its maximum value that corresponds to five clusters.</p><p>Example 4: The data for the fourth example is taken from Botony <ref type="bibr">[25]</ref>. It consists of a data of 12 trees belonging to 4 classes as shown in Table <ref type="table" target="#tab_4">IV</ref>, which shows the symbolic objects representing the trees where the different alphabets represent different characteristics of the trees. Fig. <ref type="figure" target="#fig_7">5</ref> shows the C I value becoming maximum at number of classes equal to 4. Table <ref type="table" target="#tab_5">V</ref> shows the four symbolic objects representing the four classes of trees.</p><p>Example 5: The data set used for this example is shown in Table <ref type="table" target="#tab_7">VI</ref>. It consists of data of fats and oils <ref type="bibr" target="#b28">[15]</ref> having four quantitative features of interval type and one nominal qualitative feature. The initial weighted similarity matrix computed for this data is shown in Table <ref type="table" target="#tab_7">VII</ref>. For this data, as shown in Fig. <ref type="figure">6</ref>, C I has the maximum value corresponding to two clusters. Two symbolic objects representing the two classes are shown in Table <ref type="table" target="#tab_7">VIII</ref>, which also gives descriptive information about the classes.</p><p>The samples belonging to the two classes are {0,1,2,3,4,5} and {6,7}. Ichino <ref type="bibr" target="#b28">[15]</ref> presents a dendrogram when the single linkage method of clustering is applied on this data. The two classes obtained, when the dendrogram is cut at an appropriate level, is as follows: {0,1,2,3,4,5} and {6,7}. It can be observed that the two results are exactly the same.</p><p>Example 6: The data set of microcomputers <ref type="bibr">[lo]</ref>, <ref type="bibr" target="#b28">[15]</ref> shown in Table <ref type="table" target="#tab_11">IX</ref> is used in this experiment. Table <ref type="table" target="#tab_11">X</ref> shows the initial weighted similarity matrix for this data. As shown in Fig. <ref type="figure">7</ref>, the cluster indicator value has the maximum value at 4 indicating four clusters. Four symbolic objects representing the four clusters are shown in Table <ref type="table" target="#tab_11">XI</ref>, which also describes the four classes. In Table <ref type="table" target="#tab_11">XI</ref>, 8080X includes the 8080A and Z80 microprocessors, and 6502X includes 6502, 6502A, and 6502C microprocessors.</p><p>The elements belonging to the four classes are as follows: {0,1,9,10}, {6}, {2,8}, {3,4,5,7,11}. When the single linkage method is applied on this data and the dendrogram is cut at an appropriate level, we get four clusters with elements distributed as follows: {0,1,9,10,3,8},{6},{2},{4,5,7,11}. It can be observed that the difference between the two results is only marginal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ix. RELATIONS TO OTHER WORKS</head><p>In CLUSTER/2 <ref type="bibr">[lo]</ref> the authors use a single seed for each cluster and a conjunction statement (logical complex) to describe all objects in a cluster. The seeds are either the "central" events or the "border" events. The hierarchy is built by doing partitions at various levels using some parameters, thresholds, and a clustering quality criterion. Their algorithm requires the knowledge of the number of clusters. The methodology presented in this paper uses composite symbolic objects to represent each cluster. The composite symbolic object is a Cartesian join of all objects in a cluster. The proposed algorithm does not require the prior knowledge of the number of clusters as this is determined by the algorithm itself.</p><p>The general metrics for mixed features, described by Ichino <ref type="bibr" target="#b28">[15]</ref> using Cartesian join and meet operators, is a subtractive version of the "content" component of the similarity measure described here. <ref type="bibr">Ichino [22]</ref> uses the Cartesian join system for feature selection whereas the same is used in this paper for forming composite objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSION</head><p>A new similarity measure, which is not just another aspect of dissimilarity is defined considering "position," "span," and "content" of symbolic objects. The concept of a composite symbolic object is introduced that makes use of a Cartesian operator for combining two symbolic objects assigned to the same class. A nonparametric hierarchical, agglomerative clustering algorithm is developed for clustering symbolic data using the newly defined similarity measure. Several artificial and real-life data with known number of classes and classification assignments were used initially to corroborate the efficacy of the algorithm. Subsequently, the algorithm was applied on two typical Assertion type of symbolic data sets of fat-oil and microcomputers. The algorithm automatically determines the number of classes and the symbolic representation of the classes. The symbolic representation of the classes can be used for creating knowledge bases of expert systems.</p><p>In the present algorithm, two symbolic objects forming the most similar mutual pair are merged at each stage. Since about 62% of samples are in mutual pairs at each stage, it is possible to merge objects belonging to more than one mutual pair at each stage, and hence speed up the algorithm. But merging too many pairs at a stage may increase misclassification.</p><p>This paper presents the results of applying the proposed algorithm on mainly Assertion type of symbolic objects. With some modifications, it can also be applied on Hoard and Synthetic type of symbolic objects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>X * * * X B d . ... ...................................... ,-...... Y......-.--......., ............. x ........</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 1. A typical example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Variation of C I for five-class Gaussian data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Five composite symbolic objects (Clusters) in five-class Gaussian data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>, B k ) due to position p 2) S,(Ak,Bk) due to span s 3) S,(Ak,Bk) due to content c. The similarity components due to "position" arises only when the feature type is quantitative. It indicates the relative positions of two feature values on real line. The similarity component due to "span" indicates the relative sizes of the feature values without referring to common parts between them. The component due to "content" of cars, buses, trucks, and motorcycles. Further, the node "cars" is a measure of the common parts between two feature values. The I I -t .......................................................................... ...................</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Variation of C I for the overlapping data of 5-classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Variation of CI for the data of trees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>a1 7 ( 6 )Fig. 6 .Fig. 7 .</head><label>7667</label><figDesc>Fig. 6. Variation of C I for the fat-oil data. Fig. 7. Variation of C I for the microcomputer data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>5 and covariances of zero. The mean values are m i =(3.0, 3.0) m2 =(7.0, 3.0) m3 =(3.0, 7.0) m4 =(7.0, 7.0). One hundred samples were independently generated using a Gaussian V a o r generator having the above parameters. The proposed algori -was used on this data. Figs. l(a)-(c) show the situations when thereire five, four, and three clusters (symbolic objects) respectively. The cluster F in Fig. l(b) is the result of merging of the clusters D and E shown in Fig. l(a). Maximum similarity in Fig.l(a) is the similarity between the clusters D and E (0.8744), which is high compared to maximum similarity of 0.4678 in Fig.l(b), which is between B and C. The difference in maximum similarity values between levels of Fig. l(a) and (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 (d) shows the variation of C I with number of clusters. It is clear from this figure that the maximum value of C I occurs when the number of clusters equals 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I EXPERIMENTAL RESULTS OF RANDOMLY GENERATED CLASSES</head><label>I</label><figDesc></figDesc><table><row><cell>Number of Gaussian</cell><cell>Number of Samples</cell><cell>Mean Values Used for Generating</cell><cell>No. of Clusters Corresponding to</cell></row><row><cell>Clusters Generated</cell><cell>Generated</cell><cell>Samples</cell><cell>Maximum CI</cell></row><row><cell>2</cell><cell>60</cell><cell>1.0, 3.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 111 DESCRIPTION OF 5 CLASSES</head><label>111</label><figDesc></figDesc><table><row><cell cols="2">Cluster No. Samples in</cell><cell>Feature 1</cell><cell>Feature 2</cell><cell>Feature 3</cell></row><row><cell></cell><cell>the Cluster</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>0 to 6</cell><cell>24-26</cell><cell>24-26</cell><cell>100-102</cell></row><row><cell>2</cell><cell>7 to 13</cell><cell>10-12</cell><cell>24-26</cell><cell>99-101</cell></row><row><cell>3</cell><cell>14 to 20</cell><cell>10-12</cell><cell>10-12</cell><cell>100-102</cell></row><row><cell>4</cell><cell>21 to 27</cell><cell>24-26</cell><cell>10-12</cell><cell>100-102</cell></row><row><cell>5</cell><cell>28 to 34</cell><cell>24-26</cell><cell>24-26</cell><cell>89-91</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV DATA OF 12 TREES OF 4-cUSSES</head><label>IV</label><figDesc></figDesc><table><row><cell>Class 1 (Annonaceae)</cell><cell>Class 2 (Caesalpiniaceae)</cell><cell>Class3 (Clusiaceae)</cell><cell>Class4 (Mimosaceae)</cell></row><row><cell>0. degjknpCFR</cell><cell>3. bfgilmpBILPR</cell><cell>6. aehilmoswxzDFR</cell><cell>9. begikmpBJKPR</cell></row><row><cell>1. dfhjknpCFR</cell><cell>4. aehjlmpBIKPR</cell><cell>7. cfgilmoswxzDFR</cell><cell>10. begiknpBJKPR</cell></row><row><cell>2. dehjknpCFR</cell><cell>5. afhikmpDIKNR</cell><cell>8. cegjlmoswxzDFR</cell><cell>11. begjkmpBJKPR</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V DESCRIFTION OF FOUR CLUSTERS OF TREES</head><label>V</label><figDesc></figDesc><table><row><cell cols="2">Cluster Description</cell><cell>Samples in Clusters</cell></row><row><cell>1</cell><cell>degjknpCFRhf</cell><cell>0,1,2</cell></row><row><cell>2</cell><cell cols="2">bfgilmpBILPRaehjKkDN 3,4,5</cell></row><row><cell>3</cell><cell>cfgilmoswxzDFRejah</cell><cell>6,7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>,8 4 begjkmpBJKPRin 9,10,11 Quantitative RatiolAbsolute Type of Ak and Bk :</head><label></label><figDesc></figDesc><table /><note><p>Quantitative ratio and absolute type of features are special cases of interval type having the following properties:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI FAT-OIL DATA</head><label>VI</label><figDesc></figDesc><table><row><cell>Sample Name</cell><cell>sp.gravity (g/cm3)</cell><cell>fr.pt. ("C)</cell><cell>io.value</cell><cell>sa. value</cell><cell>m. f.acids</cell></row><row><cell>0) Linseed oil</cell><cell>0.9304935</cell><cell>-27 to -8</cell><cell>170-204</cell><cell>118-196</cell><cell>L,Ln,O,P,M</cell></row><row><cell>1) Perilla oil</cell><cell>0.9304937</cell><cell>-5 to -4</cell><cell>192-208</cell><cell>188-197</cell><cell>L,Ln,O,P,S</cell></row><row><cell cols="2">2) Cotton-seed 0.916-0.918</cell><cell>-6 to -1</cell><cell>99-113</cell><cell>189-198</cell><cell>L,O,P,M,S</cell></row><row><cell>3) Sesame-oil</cell><cell>0.920-0.926</cell><cell>-6 to -4</cell><cell>104-116</cell><cell>187-193</cell><cell>L,O,P,S,A</cell></row><row><cell>4) Camellia</cell><cell>0.916-0.917</cell><cell>-21 to -15</cell><cell>80-82</cell><cell>189-193</cell><cell>L,O</cell></row><row><cell>5) Olive oil</cell><cell>0.914-0.919</cell><cell>0 to 6</cell><cell>79-90</cell><cell>187-196</cell><cell>L,O,P,S</cell></row><row><cell>6) Beef-tallow</cell><cell>0.860-0.870</cell><cell>30 to 38</cell><cell>4048</cell><cell>190-199</cell><cell>O,P,M,S,C</cell></row><row><cell>7) Lard</cell><cell>0.858-0.864</cell><cell>22 to 32</cell><cell>53-77</cell><cell>19&amp;202</cell><cell>L,O,P,M,S,Lu</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Note-L Linoleic acid Ln: Linolenic acid 0: Oleic acid P Palmitic acid M: Myristic acid S: Searic acid A Arachic acid C Capric acid Lu: Lauric acid</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE X SIMILARITY</head><label>X</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="6">MATRIX FOR MICROCOMPUTER DATA</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>I</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell></row><row><cell>0) Apple I1 1) Atari 800 2) Corn. VIC 20 3) Ex. Sorcerer 4) Zenith H8</cell><cell cols="12">-5.27 4.40 4.32 3.29 3.42 1.15 3.68 4.31 5.02 4.56 4.09 5.27 -4.65 4.98 3.54 3.67 1.35 4.35 4.23 4.94 4.48 4.34 4.40 4.65 -3.64 3.55 3.71 2.36 3.03 4.75 4.04 3.64 4.47 4.32 4.98 3.64 -4.07 4.06 1.24 4.74 4.12 4.83 5.22 4.66 3.29 3.54 3.55 4.07 -5.81 1.18 4.71 2.65 3.35 3.74 5.00</cell></row><row><cell>5) Zenith H89 6) HP-85</cell><cell cols="12">1.30 4.83 2.77 3.48 3.87 5.13 1.14 1.35 2.36 1.24 1.18 1.30 -0.61 1.90 1.20 1.23 2.12 3.42 3.67 3.71 4.06 5.81 -</cell></row><row><cell>7) Horizon</cell><cell cols="12">3.68 4.35 3.03 4.74 4.71 4.83 0.61 -3.06 3.77 4.16 4.02</cell></row><row><cell>8) 0. .%Challenger 9) 0. S.11 Series</cell><cell cols="12">4.31 4.23 4.75 4.12 2.65 2.77 1.90 3.06 -5.23 4.77 3.44 5.02 4.94 4.04 4.83 3.35 3.48 1.20 3.77 5.23 -5.48 4.15</cell></row><row><cell>10) TRS-80 I</cell><cell cols="12">4.56 4.48 3.64 5.22 3.74 3.87 1.23 4.16 4.17 5.48 -4.61</cell></row><row><cell>11) TRS-80 111</cell><cell cols="12">4.09 4.34 4.47 4.66 5.00 5.13 2.12 4.02 3.44 4.15 4.61 -</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported by a High Level Research Fellowship from the Ministry of Foreign Affairs, Government of</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>An Approach to Robot Motion Analysis and</head><p>Planning for Conveyor 'Ikacking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T. H. Park and B. H. Lee</head><p>Abshcr-The robot motion is analyzed and planned for conveyor tracking considering the speed of the conveyor belt and the locations of the part and the robot. The joint toque limit, together with the joint velocity, acceleration, and jerk limits of the robot, is also taken into account in the motion analysis and planning. To include the robot arm dynamics, the problem is formulated as the second-order state equations using a parametric function. The conveyor tracking problem is then converted to an optimal tracking problem. The solution that minimizes the specified performance index is obtained using the dynamic programming approach.</p><p>Numerical examples are finally presented to demonstrate the significance of the proposed method for conveyor tracking of the robot in a workcell.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCnON</head><p>The robotic workcell with robot manipulators and conveyor belt systems is desirable in a broad class of industrial applications.</p><p>In most of the factory automation system, the part is transferred by the conveyor belt system. The primary advantage of conveyortracking applications is that continuous operations may maximize robot utilization and minimize production cycle time, contributing to economic performance and system productivity [ 11. Efficient control of a robot manipulator for conveyor tracking, however, has several problems as follows.</p><p>1) The steady-state tracking error should be eliminated since it is closely related to the task accuracy. Manipulation tasks are normally carried out in the steady state where the relative Manuscript received <ref type="bibr">October 6, 1990;</ref><ref type="bibr">revised August 13, 1991</ref> position vector from the robot hand to the part becomes the zero vector.</p><p>Since the position of the robot hand is different from that of the part in the initial state, there should be the transient state until the motion of the robot hand becomes equal to that of the part. The velocity of the conveyor belt system, together with the initial positions of the robot hand and the part, has important effects on the motion in the transient state.</p><p>The physical constraints of the robot manipulator must be taken into account in robot motion planning. The tracking trajectories should be generated subject to the torque constraints of the manipulator and the smoothness constraints of the trajectory</p><p>[ 111. In order to maximize the task productivity, the settling time of the tracking trajectory must be minimized subject to the constraints. The purpose of this paper is to analyze and plan the motion of the robot manipulator for tracking the conveyor belt system subject to the various requirements mentioned previously. We first consider the robot control structure. The control structure of the robot is generally divided into two hierarchical levels. The lower level includes path tracking control, and the upper level includes motion planning of the manipulator. Due to the division of the control structure, the highly coupled nonlinear dynamics can be easily included in the upper level.</p><p>[9] Since the nonlinearity of the manipulator dynamics is taken into account at this level, the tracking controller can generally keep the manipulator fairly close to the desired trajectory.</p><p>We next consider the conveyor belt system coupled with a robot manipulator. Several robot-conveyor belt systems have been announced so far. In the system developed by Holland et al. <ref type="bibr">[2]</ref> and MO et al. <ref type="bibr" target="#b16">[3]</ref>, the robot tracks the moving part on the conveyor belt system and the tracking motion is planned using the method of the straight line trajectory planning, presented by Paul <ref type="bibr" target="#b19">[6]</ref> and Taylor <ref type="bibr" target="#b20">[7]</ref>. However the robot motion was planned without considering the arm dynamics, while the conveyor belt speed and the initial position of the robot were considered in tracking motion. Also, there are other control methods taking the arm dynamics into account in the motion planning stage such as the minimum time control problem <ref type="bibr" target="#b21">[8]</ref>- <ref type="bibr">[ll]</ref>.</p><p>Here, we want to incorporate the robot arm dynamics together with the various requirements in the error-free conveyor tracking problem. We formulate the problem as an optimal tracking problem in the optimal control theory. The robot arm dynamics will be used in obtaining the second-order state equations. The limit of the joint torque will be considered as the bound on the control variables. Also the limit of the joint velocity, acceleration, and jerk will be accommodated as the constraints on the state variables. An optimal solution, which minimizes the performance index subject to the various constraints, is then obtained through dynamic programming.</p><p>This paper is organized as follows. In Section 11, the conveyor tracking problem is stated with some assumptions, and the problem formulation is presented in Section 111. In Section IV, a dynamic programming algorithm is presented to analyze and plan the robot arm motion. Finally, we discuss simple examples to demonstrate the utility of the proposed motion planning algorithm with some simulation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">A CONVEYOR TRACKING PROBLEM</head><p>We consider the system model consisting of a conveyor belt system and a nonredundant robot manipulator that has n degrees of freedom.</p><p>The system model is assumed to have the following characteristics: 0018-9472/92$03.00 0 1992 IEEE</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Astrom</surname></persName>
			<affiliation>
				<orgName type="collaboration">Adaptive Control</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wittenmark</surname></persName>
			<affiliation>
				<orgName type="collaboration">Adaptive Control</orgName>
			</affiliation>
		</author>
		<imprint>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive noise cancelling: Principles and applica-Addison Wesley, 1989. tions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1692" to="1716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stationary and nonstationary learning characteristics of the LMS adaptive filter</title>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1151" to="1162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Introduction to Robotics, Mechanics, and Control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Craig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance characteristics of an adaptive controller based on least square filters</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Merhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA Paper</title>
		<imprint>
			<biblScope unit="page" from="86" to="2160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Rudin</surname></persName>
		</author>
		<title level="m">Principles of Mathematical Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adaptive Control, the Model Reference Approach</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Landau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Marcel Dekker</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Practical adaptive control of actuated spatial mechanisms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conj Robotics Automat</title>
		<meeting>IEEE Int. Conj Robotics Automat<address><addrLine>Summer</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985">1987. 1985</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="650" to="655" />
		</imprint>
	</monogr>
	<note>Adaptive control of mechanical manipulators</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive control of robot manipulators-A review</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Hsia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conj Robotics Automat</title>
		<meeting>IEEE Int. Conj Robotics Automat</meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="183" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the adaptive control of robot manipulators</title>
		<author>
			<persName><forename type="first">J-J</forename><forename type="middle">E</forename><surname>Slotine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robotics Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="49" to="59" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An efficient algorithm for the adaptive control of a manipulator</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conj Robotics Automat</title>
		<meeting>IEEE Int. Conj Robotics Automat</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="682" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonlinear adaptive motion control for a manipulator with flexible joints</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conj Robotics Automat</title>
		<meeting>IEEE Int. Conj Robotics Automat</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="1201" to="1206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adaptive control of mechanical manipulators</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Craig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
	<note>UMI Dissertation Service</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The complete dynamic model and customized algorithms of the Puma robot</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Neuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="635" to="644" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Simon</surname></persName>
		</author>
		<title level="m">Clustering Analysis: Communication and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Recent Developments in Clustering and Data Analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jambu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ohsumi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>New York Academic</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Classification and Related Methods of Data Analysis Amsterdam</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Bock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>North Holland</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Algorithms for Clustering Data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Dubes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Data Analysis, Learning Symbolic and Numeric Knowledge</title>
		<author>
			<persName><forename type="first">Si</forename><forename type="middle">E</forename><surname>Diday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The symbolic approach in clustering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Classification and Related Methods of Data Analysis</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bock</surname></persName>
		</editor>
		<meeting><address><addrLine>Ed. Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science (North Holland</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Clustering in pattern recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Govaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lechevallier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Conj Pattern Recog</title>
		<meeting>5th Conj Pattern Recog<address><addrLine>Miami Beach</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Knowledge representation and symbolic data analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Workshop on Data, Expert Knowledge, and Decision</title>
		<meeting>2nd Int. Workshop on Data, Expert Knowledge, and Decision<address><addrLine>Hamburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-03-05">Sept. 3-5, 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A recent advance in data analysis: Clustering objects into classes characterized by conjunctive concepts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Stepp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Diday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Pattern Recognition</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Kana1</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North Holland</publisher>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automated construction of classifications: Conceptual clustering versus numerical taxonomy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Stepp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">396410</biblScope>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conceptual clustering in knowledge organization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="592" to="598" />
			<date type="published" when="1985-09">Sept. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Experiments with Incremental concept formation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Labovitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Machine Learning</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="103" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge acquisition via Incremental conceptual clustering</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="139" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning based on conceptual distance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kodrotoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tecuci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="897" to="909" />
			<date type="published" when="1988-11">Nov. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">General metrics for mixed features-The Cartesian space theory for pattern recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ichino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1988">1988. 1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recognizing and locating partially occluded 2-D objects: Symbolic clustering method</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S S</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1644" to="1655" />
			<date type="published" when="1989-12">Nov./Dec. 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighborhood</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="47" to="92" />
			<date type="published" when="1976">1977. 1976</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">France</forename><surname>Antibes</surname></persName>
			<affiliation>
				<orgName type="collaboration">Nova Science</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Disaggregate clustering using the concept of mutual nearest neighborhood</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="888" to="895" />
			<date type="published" when="1978-12">Dec. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The condensed nearest neighbour rule using the concept of mutual nearest neighborhood</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="488" to="490" />
			<date type="published" when="1979-07">July 1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning with a mutualistic teacher</title>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="383" to="390" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Kodratoff</surname></persName>
		</author>
		<title level="m">Introduction to Machine Learning</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Pitman</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pattern classification based on the Cartesian join system: A general tool for feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ichino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE In?. Con$ Syst</title>
		<meeting>IEEE In?. Con$ Syst<address><addrLine>Man, Cyben., Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">Oct. 14-17, 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Probability of Ocurrence of a constant number of isolated pairs in a random population</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hamming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. Wisconsin Computing News</title>
		<imprint>
			<biblScope unit="issue">32</biblScope>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">0</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<title level="m">Panern Classification and Scene Analysis</title>
		<imprint>
			<publisher>New York Wiley Interscience</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Microcomputer-aided identification: An application to trees from French Guiana</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Forget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lebb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vignes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hideux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Botanical J. Linnean Soc</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page">1418</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
