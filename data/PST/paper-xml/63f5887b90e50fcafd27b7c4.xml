<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zero-Shot Information Extraction via Chatting with ChatGPT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-02-20">20 Feb 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xingyu</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ning</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shen</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengjun</forename><surname>Xie</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinan</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yufeng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DAMO Academy</orgName>
								<address>
									<settlement>Alibaba Group</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenjuan</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Beijing Jiaotong University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Zero-Shot Information Extraction via Chatting with ChatGPT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-02-20">20 Feb 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.10205v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Zero-shot information extraction (IE) aims to build IE systems from the unannotated text. It is challenging due to involving little human intervention. Challenging but worthwhile, zero-shot IE reduces the time and effort that data labeling takes. Recent efforts on large language models (LLMs, e.g.,  ChatGPT)  show promising performance on zero-shot settings, thus inspiring us to explore prompt-based methods. In this work, we ask whether strong IE models can be constructed by directly prompting LLMs. Specifically, we transform the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework (ChatIE). With the power of ChatGPT, we extensively evaluate our framework on three IE tasks: entityrelation triple extract, named entity recognition, and event extraction. Empirical results on six datasets across two languages show that ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL). We believe that our work could shed light on building IE models with limited resources. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information extraction aims to extract structured information from unstructured text into structured data formats, including tasks such as entity-relation triple extract (RE), named entity recognition (NER), event extraction (EE) <ref type="bibr" target="#b24">(Tjong Kim Sang, 2002;</ref><ref type="bibr" target="#b16">Ratinov and Roth, 2009;</ref><ref type="bibr" target="#b27">Wei et al., 2020;</ref><ref type="bibr" target="#b29">Zheng et al., 2021;</ref><ref type="bibr">Li et al., 2020a)</ref>, etc. It is a fundamental and crucial task in natural language processing <ref type="bibr" target="#b21">(Sarawagi et al., 2008)</ref>. Working with an enormous amount of labeling data is always hectic, labor-intensive, and time-consuming. Hence, many organizations and companies rely on IE techniques to automate manual work with zero/few-shot methods, e.g., clinical IE <ref type="bibr" target="#b0">(Agrawal et al., 2022)</ref>.</p><p>1 https://github.com/cocacola-lab/ChatIE Recent works <ref type="bibr" target="#b0">(Agrawal et al., 2022;</ref><ref type="bibr" target="#b6">Jeblick et al., 2022;</ref><ref type="bibr" target="#b28">Zhang et al., 2022)</ref> on large-scale pre-trained language models (LLM), such as GPT-3 <ref type="bibr" target="#b1">(Brown et al., 2020)</ref>, InstructGPT <ref type="bibr" target="#b15">(Ouyang et al., 2022)</ref> and ChatGPT<ref type="foot" target="#foot_0">2</ref> , suggest that LLMs perform well in various downstream tasks even without tuning the parameters but only with a few examples as instructions. Hence, it is a timing question: Is it feasible to prompt LLMs to do zero-shot IE tasks under a unified framework? It is challenging because the structured data containing multiple dependent elements are difficult to extract through one-time prediction, especially for some complex tasks like RE. Previous works decompose these complex tasks into different parts and train several modules to solve each part. For example, in the RE task, the pipeline method PURE <ref type="bibr" target="#b30">(Zhong and Chen, 2021)</ref> first identifies two entities and then predicts the relations between them. However, supervision from labeled data is required in this model. Additionally, <ref type="bibr">Li et al. (2019b)</ref> regard RE as a question-answering process by first extracting subjects and then objects according to the relation templates.</p><p>Based on these clues, in this paper, we turn to ChatGPT and hypothesize that ChatGPT is born with the right abilities to deposit a unified zero-shot IE model in an interactive mode. More specifically, we propose ChatIE by transforming the zero-shot IE task into a multi-turn question-answering problem with a two-stage framework. In the first stage, we aim to find out the corresponding element types that may exist in a sentence. Then in the second stage, we perform a chained information extraction to each element type from Stage I. Each stage is implemented with a multi-turn QA process. In each turn, we construct prompts based on designed templates and previously extracted information as input to ask ChatGPT. Finally, we compose the results of each turn into structured data. We conduct extensive experiments on IE, NER, and EE tasks, including six datasets across two languages: English and Chinese. Empirical results show that while vanilla ChatGPT without using ChatIE fails in solving IE with original task instruction, our proposed two-stage framework instantiated on Chat-GPT succeeds when the IE task is decomposed into multiple simpler and easier sub-tasks. Surprisingly, ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets (e.g., NYT11-HRL <ref type="bibr" target="#b23">(Takanobu et al., 2019)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ChatIE</head><p>2.1 Multi-Turn QA framework for zero-shot IE</p><p>We decompose the IE task into two stages, each containing several turns of QA, which refer to the dialogue with ChatGPT. In the first stage, we aim to find out the existing types of entities, relations, or events in the sentence respectively in three tasks.</p><p>In this way, we filter out the element types that do not exist to reduce the search space and computational complexity, conducing to extracting information. Then in the second stage, we further extract relevant information based on the element types extracted in the first stage as well as the corresponding task-specific scheme. The overview of our framework is shown in Figure <ref type="figure" target="#fig_0">1</ref>, which we will describe in detail later.</p><p>Stage I: For one sample, this stage generally includes only one turn of QA. In order to find the element types presented in the sentence, we first utilize the task-specific TypeQuesTemplates and the list of element types to construct the question.</p><p>Then we combine the question and sentence as input to ChatGPT. To facilitate answer extraction, we ask the system to reply in the list form. If the sentence does not contain any element types, the system will generate a response with NONE Token.</p><p>Stage II: This stage generally includes multiple QA turns. In advance, we design a series of specific ChainExtractionTemplates for element types according to the scheme of the task. The ChainExtrac-tionTemplates define a chain of question templates and the length of the chain is usually one. But for complicated schemes such as complex-object value extraction in entity-relation triple extraction, the length of the chain is greater than one. At this point, the extraction of an element may depend on another previous element, so we call it chained templates. We perform multi turns QA in the order of previously extracted element types as well as the order of ChainExtractionTemplates. To generate a question, we need to retrieve the template with the element type and fill the corresponding slots if necessary. Then we access ChatGPT and get a response. Finally, we compose structured information based on the elements extracted in each turn. Similarly, for the convenience of answer extraction, we ask the system to reply in table form. If nothing is extracted, the system will generate a response with NONE token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Applying the Framework to IE tasks</head><p>After curating the unified framework, ChatIE, we'll then start applying the framework to information extraction tasks, to process and build models for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Entity-Relation Triple Extraction</head><p>Given a sentence x and question prompt q, the model is desired to predict triples T pxq " tps 1 , r 1 , o 1 q, ???, ps n , r n , o n qu, where typepps i , r i , o i qq P T T , a list of potential triple types. Formally for an output triple ps, r, oq, we can express the process as: Where q 1 is the question generated using relation types list R and the corresponding template in Stage I. And q r is the question generated using the template related to the previously extracted relation type in Stage II. It is worth noting that we omit x in Stage II, because ChatGPT can record the relevant information of each turn QA. In addition, we need further several turns QA for samples with complexobject values. The complex-object value refers to an object with multiple attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Named Entity Recognition</head><p>For the NER task, the first stage is to filter out the existing entity types in the sentence given the desired type list. Once we get the entity types, we can construct the input for the second stage accordingly. In the second stage, each turn aims to extract the entities of one type. So the number of turns in Stage II is up to the number of entities obtained in Stage I, and Stage II is omitted if the first stage gets no types at all. In the experiment, the BIO annotation is not considered since it's kind of hard for ChatGPT. Besides, because the type of entities is few (3 types in conllpp, 4 types in msra) in the datasets, the first stage is skipped in the actual experiment, asking for every type of entity in the second stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Event Extraction</head><p>ChatIE divides the zero-shot EE task into two subtasks: event classification and argument extrac-tion, solved with two stages in a pipelined fashion. The first stage is designed for event classification, formalized as a text classification problem getting event types from a given text. The second stage is then devoted to argument extraction, formalized as an extractive machine read comprehension (MRC) problem that identifies arguments of specific roles associated with predicted event types from the Stage I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>3.1 Setup Datasets RE. NYT11-HRL <ref type="bibr" target="#b23">(Takanobu et al., 2019)</ref> is a preprocessed version of NYT11 <ref type="bibr" target="#b17">(Riedel et al., 2010;</ref><ref type="bibr" target="#b5">Hoffmann et al., 2011)</ref> and contains 12 predefined relation types. DuIE2.0 <ref type="bibr">(Li et al., 2019a)</ref> is the industry's largest schema-based Chinese RE dataset and contains 48 predefined relation types. Some of the objects in the triples have multiple attributes, called complex-object values.</p><p>NER. The conllpp <ref type="bibr" target="#b26">(Wang et al., 2019)</ref> dataset is a modified version of the conll2003 <ref type="bibr" target="#b25">(Tjong Kim Sang and De Meulder, 2003)</ref> and contains 4 entity types. MSRA <ref type="bibr" target="#b9">(Levow, 2006</ref>) is a Chinese named entity recognition dataset for the news field and contains 3 entity types. EE. DuEE1.0 <ref type="bibr">(Li et al., 2020b</ref>) is a Chinese event extraction dataset released by Baidu, which contains 65 event types. The ACE05<ref type="foot" target="#foot_1">3</ref> corpus provides event annotations in document and sentence levels from a variety of domains such as newswires and online forums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>RE. We report the standard micro F1 measure and adopt two evaluate metrics: 1) border evaluation (BE): an extracted relation triple (subject, relation, object) is considered as correct if the whole entity span of both subject and object and relation are all correct. 2) strict evaluation (SE): in addition to what is required in the border evaluation, the type of both subject and object also must be correct. We use BE on NYT11-HRL because there is no annotation of entity types and use SE on DuIE2.0. NER. We only consider the complete matching and use the micro F1 to evaluate NER task. Only when both the border and the type of the predicted entity and the true entity are the same will we regard it as a correct prediction.</p><p>EE. We adopt the different evaluation metrics on the DuEE1.0 dataset and ACE05 dataset. For the DuEE1.0 dataset, F-measure (F1<ref type="foot" target="#foot_2">4</ref> ) is scored according to the word-level matching. For the ACE05 dataset, the predicted argument results are matched with the manually marked argument results at the entity level and evaluated by the micro F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Main Results</head><p>We summarize the main results in Table <ref type="table" target="#tab_0">1</ref>. We observe that while vanilla ChatGPT (Row single, ChatGPT using a single-turn QA instead of ChatIE) performs poorly in solving IE, our proposed twostage framework based on ChatGPT (Row ChatIE) succeeds. ChatIE generally improves performance over six widely used IE datasets by 18.98% points significantly on average.</p><p>Notably, the gains become more significant compared with few-shot approaches. For each few-shot experiment, we randomly select 3 sets of the training data, and train 3 times on each set to get an average result. The baselines are PaddleNLP LIC2021 IE<ref type="foot" target="#foot_3">5</ref> and CaseRel <ref type="bibr" target="#b27">(Wei et al., 2020)</ref> for RE, AdaSeq Bert-CRF<ref type="foot" target="#foot_4">6</ref> for NER, PaddleNLP LIC2021 EE<ref type="foot" target="#foot_5">7</ref> and Text2event <ref type="bibr" target="#b14">(Lu et al., 2021)</ref> for EE. ChatIE is comparable to fs-20 on MSRA, or outperforms fs-100 on NYT11-HRL, collnpp and ACE05, or even surpasses the full-shot on DuIE2.0 and DuEE1.0 in terms of performance.</p><p>More surprisingly, compared with two supervised models FCM <ref type="bibr" target="#b2">(Gormley et al., 2015)</ref> and MultiR <ref type="bibr" target="#b5">(Hoffmann et al., 2011)</ref> on NYT11-HRL, ChatIE surpassed them by 2.5% and 5.8% respectively. Supervised learning models are computationally-intensive and require high-quality labeled data. Additionally, for each task, an individual model is trained from scratch. In contrast, ChatIE works without any finetuning and training to update parameters. It vastly reduces the computation and time investment. With all these benefits, ChatIE still outperforms these supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Case Study</head><p>The first sentence "Just as the JAMA article was being published, three dozen children began dying of acute renal failure at two hospitals in Delhi, India." is an RE case where the same pair of entities belong to two different types of relations. The triples are (India, location-contains, Delhi) and (Delhi, administration_division-country, India). In the first stage, ChatIE detects the two relation types. Then in the second stage, ChatIE further extract the words Delhi and India and confirms which one is the source entity and which is the target. This shows ChatIE's ability to give different labels to the same entity in different relations. It is worth noting that we convert location-contains to location-located_in to predict in the actual experiment, which means we regard (Delhi, location-located_in, India) and (India, location-contains, Delhi) as equivalent.</p><p>The second sentence "Four other Google executives the chief financial officer, George Reyes; the senior vice president for business operations, Shona Brown; the chief legal officer, David Drummond; and the senior vice president for product management, Jonathan Rosenberg earned salaries of $ 250,000 each." is an RE example where one relation involves multiple triples. It's hard for many methods to extract but it is accomplished by ChatIE. The extracted triples are (George Reyes, person-company, Google), (Shona Brown, person-company, Google), (David Drummond, person-company, Google) and (Jonathan Rosenberg, person-company, Google). ChatIE first filters out the person-company and outputs the 4 triples related to the relation at the same time in the second stage.</p><p>The third sentence "Score on the first day of the four-day Sheffield Shield match between Tasmania and Victoria at Bellerive Oval on Friday." is a NER example with confusing entities. The word "Tasmania" and "Victoria" can be categorized as "LOCATION" types, but are actually team names in this sentence, which are "ORGANIZATION" types. ChatIE can recognize the confusing point, showing its advantage in understanding the sentence and choosing the right word meanings.</p><p>The last sentence "Clinton suffered greatly over the 19 Rangers that died, 18 on the 3rd of October and MattReersen (ph) three days later." is an EE example. In the first stage, ChatIE gets the event type when scanning the word "died". Then it goes from this word to catch the victim "19 rangers", further detects the agent "Clinton" before the predicate, and targets on "3rd of October" and "three days later".</p><p>5 Vanilla Prompt vs. Our Chat-based Prompt </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Working with an enormous amount of labeling data is always hectic, labor-intensive, and timeconsuming. Hence, researchers focus on zero/fewshot technologies even though IE is challenging in low-resource scenarios, such as few-shot relation classification or extraction <ref type="bibr" target="#b19">(Sainz et al., 2021;</ref><ref type="bibr" target="#b4">Han et al., 2018)</ref>, few-shot event argument extraction <ref type="bibr">(Sainz et al., 2022a</ref>) and few-shot information extraction <ref type="bibr">(Sainz et al., 2022b)</ref>.</p><p>ChatGPT has gained widespread attention recently. Many fields received its impacts and evolving fast, such as Medicine <ref type="bibr" target="#b6">(Jeblick et al., 2022;</ref><ref type="bibr" target="#b8">King, 2022)</ref> and Online Exam <ref type="bibr" target="#b22">(Susnjak, 2022)</ref>. In the NLP community, there are new investigations with ChatGPT in several tasks as well. For example, <ref type="bibr" target="#b28">(Zhang et al., 2022)</ref> use ChatGPT achieved state-of-the-art performance on Stance Detection, <ref type="bibr" target="#b3">(Guo et al., 2023)</ref> evaluated its helpfulness on question answering, <ref type="bibr" target="#b7">(Jiao et al., 2023)</ref> state that it is a good translator for spoken language. We try to dig into its information extraction ability, suggesting a simple zero-shot IE framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented ChatIE, a multi-turn QA framework for zero-shot information extraction based on Chat-GPT. Through this interactive mode, ChatIE can decompose complex IE tasks into several parts and compose the results of each turn into a final structured result. We apply this framework to RE, NER, and EE tasks and conduct extensive experiments on six datasets across two languages to validate its effectiveness. Surprisingly, ChatIE achieves impressive performance and even surpasses some full-shot models on several datasets. This work paves the way for a new paradigm for zero-shot IE, where the experts decompose IE task into multiple simpler and easier sub-tasks, define chat-like prompts, and directly runs those specifications without training and finetuning. The given sentence is "Bono said that President Jacques Chirac of France had spoken eloquently of the need to support Africa , though he added that France had not yet come through with the resources ."</p><p>relations:['location-located_in','administrative_division-country', 'person-place_lived', 'person-company', 'person-nationality', 'company-founders', 'country-administrative_divisions', 'personchildren <ref type="bibr">', 'country-capital','deceased_person-place_of_death','neighborhood-neighborhood_of', 'person-place_of_birth']</ref> subject_types: <ref type="bibr">['organization', 'person', 'location', 'country']</ref> object_types: <ref type="bibr">['person', 'location', 'country', 'organization', 'city']</ref> In the sentence, what triples might be contained? Please answer in the form (subject, relation, object):</p><p>Expected Output: [(Jacques Chirac, personnationality, France)] Output: []</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>The given sentence is " Bono said that President Jacques Chirac of France had spoken eloquently of the need to support Africa , though he added that France had not yet come through with the resources ."</p><p>List of given relations:</p><p>['location-located_in <ref type="bibr">','administrative_division-country', 'person-place_lived', 'person-company', 'person-nationality', 'company-founders', 'country-administrative_divisions', 'personchildren', 'country-capital','deceased_person-place_of_death','neighborhood-neighborhood_of', 'person-place_of_birth']</ref> What relations in the given list might be included in this given sentence? If not present, answer: none. According to the given sentence, the two entities are of type ('person', 'country') and the relation between them is 'person-nationality', find the two entities and list them all by group if there are multiple groups.</p><p>If not present, answer: none. Respond in the form of a table with two columns and a header of ('person', 'country'):</p><p>Expected Output: (Jacques Chirac, France) Output: (Jacques Chirac, France)  Expected Output: "event_type": "Life:Die", "arguments": [ "role": "Victim", "argument": "over a million of his own citizens" , { "role": "Agent", "argument": "Saddam Hussein" } Output: None The list of argument roles corresponding to the event type 'Life: Die' is <ref type="bibr">['Agent', 'Victim', 'Instrument', 'Time', 'Place']</ref>. please extract the event arguments in the given sentence according to the argument roles, and return them in the form of a table. The header of the table is 'event type', 'argument role', 'argument content'. If no argument role has a corresponding argument content, the argument content returns "None".</p><p>Expected Output: "arguments": [ "role": "Victim", "argument": "over a million of his own citizens" , { "role": "Agent", "argument": "Saddam Hussein" } Output: "arguments": [ "role": "Victim", "argument": "over a million of his own citizens" , { "role": "Agent", "argument": "Saddam Hussein" } Table 4: Illustration of vanilla prompts vs our Chat-based prompts in terms of EE. The text highlighted with red represents the prompt template. The text following Question: represents the prompt that is used in ChatIE.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration for the framework. For convenience, we use the samples of DuIE2.0 as examples of three tasks to show.</figDesc><graphic url="image-1.png" coords="2,70.87,70.86,453.52,255.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>ppps, r, oq|x, qq " ppr|x, q1q loooomoooon</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Suppose you are an entity-relationship triple extraction model. I'll give you list of head entity types: subject_types, list of tail entity types: ob-ject_types, list of relations: relations. Give you a sentence, please extract the subject and object in the sentence based on these three lists, and form a triplet in the form of (subject, relation, object).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Respond as a tuple, e.g. (relation 1, relation 2, ......): Expected Output: (person-nationality) Output:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>', 'Business:Declare-Bankruptcy', 'Justice:Sue'] Give a sentence: "What I do know is Saddam Hussein has butchered over a million of his own citizens." What types of events are included in this sentence? Please return the most likely answer according to the list of event types above. Require the answer in the form: Event type Expected Output: Life:Die Output:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>F1 score on six datasets over two languages.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>RE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">NER</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>EE</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>DuIE2.0</cell><cell></cell><cell cols="3">NYT11-HRL</cell><cell></cell><cell>MSRA</cell><cell></cell><cell></cell><cell>collnpp</cell><cell></cell><cell></cell><cell>DuEE1.0</cell><cell></cell><cell></cell><cell>ACE05</cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>fs-1</cell><cell cols="7">0.0 0.0 0.0 0.0 0.0 0.0 14.7</cell><cell>7.9</cell><cell>9.7</cell><cell cols="9">2.71 17.2 4.66 0.4 0.2 0.3 0.0 0.0 0.0</cell></row><row><cell>fs-5</cell><cell cols="18">0.0 0.0 0.0 0.0 0.0 0.0 34.5 10.3 15.5 2.53 16.65 4.38 0.2 0.6 0.3 0.0 0.0 0.0</cell></row><row><cell>fs-10</cell><cell cols="18">16.5 0.1 0.2 0.0 0.0 0.0 60.0 30.9 40.6 2.49 18.54 4.38 2.1 0.7 1.0 0.0 0.0 0.0</cell></row><row><cell>fs-20</cell><cell cols="18">41.4 0.4 0.8 3.4 2.7 0.5 63.4 44.8 52.5 2.48 19.36 4.41 1.7 0.8 1.1 4.6 0.1 0.2</cell></row><row><cell>fs-50</cell><cell cols="18">45.7 2.5 4.7 11.7 1.9 3.3 71.6 62.4 66.6 41.94 11.55 8.93 3.2 8.5 4.6 6.7 1.6 2.6</cell></row><row><cell>fs-100</cell><cell cols="18">50.8 7.2 12.0 34.8 6.2 10.6 81.3 76.1 78.6 50.26 24.97 32.89 8.7 12.0 10.1 8.0 4.9 6.0</cell></row><row><cell cols="19">full-shot 68.9 72.2 70.5 47.9 55.1 51.3 96.33 95.63 95.98 94.18 94.61 94.39 50.9 42.8 46.5 45.3 54.3 49.4</cell></row><row><cell>FCM</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">43.2 29.4 35.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MultiR</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">32.8 30.6 31.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>single</cell><cell cols="18">17.8 7.7 10.7 10.8 5.7 7.4 56.3 57.3 56.8 61.4 43.0 50.6 61.7 77.5 68.7 18.2 23.9 20.7</cell></row><row><cell cols="19">ChatIE 74.6 67.5 70.9 30.6 48.4 37.5 58.4 57.0 57.7 62.3 55.0 58.4 66.5 78.5 72.0 25.3 35.5 29.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, 3 and 4 demonstrate the comparison of</cell></row><row><cell>vanilla prompts and our Chat-based prompts in</cell></row><row><cell>terms of IE. 8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Illustration of vanilla prompts vs our Chat-based prompts in terms of RE. The text highlighted with red represents the prompt template. The text following Question: represents the prompt that is used in ChatIE.</figDesc><table><row><cell>1</cell><cell>Vanilla Prompt</cell><cell>Chat-based Prompt</cell></row><row><cell></cell><cell>Question:</cell><cell></cell></row><row><cell>STAGE I</cell><cell>I'm going to give you a sentence and ask you to identify the entities and label the entity category. There will only be 4 types of entities: ['LOC', 'MISC', 'ORG', 'PER']. Please present your re-sults in list form. "Japan then laid siege to the Syrian penalty area and had goal disallowed for offside in the 16th minute." Make the list like: ['entity name1', 'entity type1'],['entity name2',</cell><cell>Question: Given sentence: "Japan then laid siege to the Syrian penalty area and had a goal disallowed for offside in the 16th minute." The known en-tity types are: ['LOC', 'MISC', 'ORG', 'PER']. Please answer: What types of entities are in-cluded in this sentence?</cell></row><row><cell></cell><cell>'entity type2']......</cell><cell>Expected Output: LOC, MISC Output: LOC,</cell></row><row><cell></cell><cell>Expected Output: ["Japan", "LOC"], ["Syrian",</cell><cell>MISC</cell></row><row><cell></cell><cell>"MISC"] Output: []</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Question:</cell></row><row><cell></cell><cell></cell><cell>According to the sentence above, please output</cell></row><row><cell></cell><cell></cell><cell>the entities of 'LOC' in the form of list like:</cell></row><row><cell></cell><cell></cell><cell>['entity name1', 'entity type1'], ['entity name2',</cell></row><row><cell></cell><cell></cell><cell>'entity type2']......</cell></row><row><cell>STAGE II</cell><cell>None</cell><cell>According to the sentence above, please output the entities of 'MISC' in the form of list like: ['entity name1', 'entity type1'], ['entity name2', 'entity type2']......</cell></row><row><cell></cell><cell></cell><cell>Expected Output: ["Japan", "LOC"], ["Syrian",</cell></row><row><cell></cell><cell></cell><cell>"MISC"]Output: ["Japan", "LOC"], ["Syrian",</cell></row><row><cell></cell><cell></cell><cell>"LOC"]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Illustration of vanilla prompts vs our Chat-based prompts in terms of NER. The text highlighted with red represents the prompt template. The text following Question: represents the prompt that is used in ChatIE. What I do know is Saddam Hussein has butchered over a million of his own citizens.", please extract the event arguments according to the argument roles, and return them in the form of a table.The header of the table is 'event type', 'argument role', 'argument content'. If no argument role has a corresponding argument content, the argument content returns "None".</figDesc><table><row><cell>1</cell><cell>Vanilla Prompt</cell><cell>Chat-based Prompt</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://openai.com/blog/chatgpt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://catalog.ldc.upenn.edu/LDC2006T06</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/PaddlePaddle/PaddleNLP/ tree/develop/examples/information_extraction/ DuEE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>github.com/PaddlePaddle/PaddleNLP/tree/ develop/examples/information_extraction/DuIE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>github.com/modelscope/AdaSeq/tree/master/ examples/bert_crf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>github.com/PaddlePaddle/PaddleNLP/tree/ develop/examples/information_extraction/DuEE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>The experiments are conducted using the version of Chat-GPT prior to January 30, 2023.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot clinical information extractors</title>
		<author>
			<persName><forename type="first">Monica</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Hegselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hunter</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12689</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improved relation extraction with feature-rich compositional embedding models</title>
		<author>
			<persName><forename type="first">Mo</forename><surname>Matthew R Gormley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Language Processing</title>
		<meeting>the Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1774" to="1784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">How close is chatgpt to human experts? comparison corpus, evaluation, and detection</title>
		<author>
			<persName><forename type="first">Biyang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minqi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinran</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wu</surname></persName>
		</author>
		<idno>arxiv:2301.07597</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1514</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4803" to="4809" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies</title>
		<meeting>the 49th annual meeting of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Jeblick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balthasar</forename><surname>Schachtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Dexl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mittermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">Theresa</forename><surname>St?ber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johanna</forename><surname>Topalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Wesp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bastian</forename><surname>Sabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Ricke</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14882</idno>
		<title level="m">Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen-Tse</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08745</idno>
		<title level="m">Is chatgpt a good translator? a preliminary study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The future of ai in medicine: a perspective from a chatbot</title>
		<author>
			<persName><surname>Michael R King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Biomedical Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The third international Chinese language processing bakeoff: Word segmentation and named entity recognition</title>
		<author>
			<persName><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Event extraction as multi-turn question answering</title>
		<author>
			<persName><forename type="first">Fayuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="829" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Duie: A large-scale chinese dataset for information extraction</title>
		<author>
			<persName><forename type="first">Shuangjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yabing</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haijin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF International Conference on Natural Language Processing and Chinese Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="791" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Entity-relation extraction as multi-turn question answering</title>
		<author>
			<persName><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiayu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arianna</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duo</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingxin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1340" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Duee: a large-scale dataset for chinese event extraction in real-world scenarios</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fayuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF International Conference on Natural Language Processing and Chinese Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="534" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Text2event: Controllable sequence-tostructure generation for end-to-end event extraction</title>
		<author>
			<persName><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2795" to="2806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02155</idno>
		<title level="m">Training language models to follow instructions with human feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth conference on computational natural language learning</title>
		<meeting>the thirteenth conference on computational natural language learning</meeting>
		<imprint>
			<date type="published" when="2009">2009. CoNLL-2009</date>
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">2022a. Textual entailment for event argument extraction: Zero-and few-shot with multi-source learning</title>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itziar</forename><surname>Gonzalez-Dios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-naacl.187</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<meeting><address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2439" to="2455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Label verbalization and entailment for effective zero and few-shot relation extraction</title>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ander</forename><surname>Barrena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.92</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1199" to="1212" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">2022b. ZS4IE: A toolkit for zero-shot information extraction with simple verbalizations</title>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoling</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-demo.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations</meeting>
		<imprint>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
	<note>Hybrid: Seattle, Washington + Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Information extraction</title>
		<author>
			<persName><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends? in Databases</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="377" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Teo</forename><surname>Susnjak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09292</idno>
		<title level="m">Chatgpt: The end of online exam integrity? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A hierarchical framework for relation extraction with reinforcement learning</title>
		<author>
			<persName><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiexi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7072" to="7079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-02: The 6th Conference on Natural Language Learning</title>
		<imprint>
			<date type="published" when="2002">2002. 2002. CoNLL-2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meulder</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Crossweigh: Training named entity tagger from imperfect annotations</title>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5154" to="5163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A novel cascade binary tagging framework for relational triple extraction</title>
		<author>
			<persName><forename type="first">Zhepei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1476" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daijun</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwen</forename><surname>Jing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14548</idno>
		<title level="m">How would stance detection techniques evolve after the launch of chatgpt? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prgc: Potential relation and global correspondence based joint relational triple extraction</title>
		<author>
			<persName><forename type="first">Hengyi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yefeng</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6225" to="6235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A frustratingly easy approach for entity and relation extraction</title>
		<author>
			<persName><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="50" to="61" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
