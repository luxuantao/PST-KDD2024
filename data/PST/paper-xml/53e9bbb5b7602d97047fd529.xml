<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Reversible Watermarking via Clustering and Enhanced Pixel-Wise Masking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-07-18">July 18, 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lingling</forename><surname>An</surname></persName>
							<email>an.lingling@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Elec-tronic Engineering</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
							<email>xbgao@mail.xidian.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Elec-tronic Engineering</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE, Dacheng Tao, Senior Member, IEEE</roleName><forename type="first">Xuelong</forename><surname>Li</surname></persName>
							<email>xuelong_li@opt.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Elec-tronic Engineering</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Deng</surname></persName>
							<email>chdeng.xd@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Elec-tronic Engineering</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Li</surname></persName>
							<email>leejie@mail.xidian.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Elec-tronic Engineering</orgName>
								<orgName type="institution">Xidian University</orgName>
								<address>
									<postCode>710071</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jana</forename><forename type="middle">L</forename><surname>Dittmann</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep2">Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">X</forename><surname>An</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep2">Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">C</forename><surname>Gao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep2">Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep2">Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep2">Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an, Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Tao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Center for Quantum Computation and Intelligent Systems</orgName>
								<orgName type="department" key="dep2">Faculty of Engineering and Information Technology</orgName>
								<orgName type="institution">University of Technology</orgName>
								<address>
									<postCode>2007</postCode>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Reversible Watermarking via Clustering and Enhanced Pixel-Wise Masking</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-07-18">July 18, 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">9E43DF33F7AF4621FCACA6AB161B47A2</idno>
					<idno type="DOI">10.1109/TIP.2012.2191564</idno>
					<note type="submission">received January 20, 2011; revised January 11, 2012; accepted March 13, 2012. Date of publication March 21, 2012; date of current version</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Integer wavelet transform</term>
					<term>k-means clustering</term>
					<term>masking</term>
					<term>robust reversible watermarking (RRW)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Robust reversible watermarking (RRW) methods are popular in multimedia for protecting copyright, while preserving intactness of host images and providing robustness against unintentional attacks. However, conventional RRW methods are not readily applicable in practice. That is mainly because: 1) they fail to offer satisfactory reversibility on large-scale image datasets; 2) they have limited robustness in extracting watermarks from the watermarked images destroyed by different unintentional attacks; and 3) some of them suffer from extremely poor invisibility for watermarked images. Therefore, it is necessary to have a framework to address these three problems, and further improve its performance. This paper presents a novel pragmatic framework, wavelet-domain statistical quantity histogram shifting and clustering (WSQH-SC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compared with conventional methods, WSQH-SC ingeniously constructs new watermark embedding and extraction procedures</head><p>by histogram shifting and clustering, which are important for improving robustness and reducing run-time complexity. Additionally, WSQH-SC includes the property-inspired pixel adjustment to effectively handle overflow and underflow of pixels. This results in satisfactory reversibility and invisibility. Furthermore, to increase its practical applicability, WSQH-SC designs an enhanced pixel-wise masking to balance robustness and invisibility. We perform extensive experiments over natural, medical, and synthetic aperture radar images to show the effectiveness of WSQH-SC by comparing with the histogram rotation-based and histogram distribution constrained methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>R EVERSIBLE WATERMARKING (RW) methods [1] are used to embed watermarks <ref type="bibr" target="#b1">[2]</ref>, e.g., secret information <ref type="bibr" target="#b2">[3]</ref>, into digital media while preserving high intactness and good fidelity of host media. It plays an important role in protecting copyright and content of digital media for sensitive applications, e.g., medical and military images. Although researchers proposed some RW methods for various media, e.g., images <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, audios <ref type="bibr" target="#b5">[6]</ref>, videos <ref type="bibr" target="#b6">[7]</ref>, and 3-D meshes <ref type="bibr" target="#b7">[8]</ref>, they assume the transmission channel is lossless. The robust RW (RRW) is thus a challenging task. For RRW, the essential objective is to accomplish watermark embedding and extraction in both lossless and lossy environment. As a result, RRW is required to not only recover host images and watermarks without distortion for the lossless channel, but also resist unintentional attacks and extract as many watermarks as possible for the noised channel <ref type="bibr" target="#b8">[9]</ref>. Recently, a dozen of RRW methods for digital images have been proposed <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b12">[13]</ref>, which can be classified into two groups <ref type="bibr" target="#b8">[9]</ref>: histogram rotation (HR)-based methods and histogram distribution constrained (HDC) methods.</p><p>The HR-based methods <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> accomplish robust lossless embedding by slightly rotating the centroid vectors of two random zones in the nonoverlapping blocks. Due to the close correlation of neighboring pixels, these methods were reported to be robust against JPEG compression. However, they are sensitive to "salt-and-pepper" noise, which leads to poor visual quality of watermarked images, and impedes lossless recovery of host images and watermarks. To solve this problem, the HDC methods have been developed in spatialand wavelet-domains <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, which divide image blocks into different types and embed the modulated watermarks for each type based on histogram distribution. Unfortunately, these methods suffer from unstable reversibility and robustness according to <ref type="bibr" target="#b8">[9]</ref>. In summary, the above analysis shows that both kinds of RRW methods are not readily applicable in practice. Therefore, a novel pragmatic RRW framework with the following three objectives is of great demand: 1) reversibility, i.e., how to handle both overflow and underflow of pixels; 2) robustness, i.e., how to resist unintentional attacks; and 3) invisibility, i.e., how to make a trade-off between robustness and invisibility.</p><p>In this paper, motivated by the excellent spatio-frequency localization properties of wavelet transform, we develop a novel RRW framework in the wavelet domain. This framework uses the statistical quantity histogram (SQH) as the embedding carrier inspired by our previous work, the generalized SQH (GSQH) driven method <ref type="bibr" target="#b13">[14]</ref>, and constructs new watermark embedding and extraction processes by histogram shifting and clustering. In this framework, we carefully design the three key components, which are the property inspired pixel adjustment (PIPA), the SQH shifting and clustering, and the enhanced pixel-wise masking (EPWM), to effectively solve the aforementioned three problems. In particular:</p><p>1) PIPA: To successfully avoid both overflow and underflow of pixels, we develop PIPA to investigate the intrinsic relationship between wavelet coefficient and pixel changes in order to determine how to duly change wavelet coefficients during the embedding process. By taking the scale and region of wavelet coefficient changes into account, PIPA preprocesses the host images accordingly by adjusting the pixels possible to overflow and underflow into a reliable range before embedding. Finally, the preprocessed host images are used to embed watermarks. 2) SQH Shifting and Clustering: To better resist unintentional attacks, we build SQH with threshold constraint by deeply studying characteristics of the wavelet coefficients, design the watermark embedding process by bi-directionally shifting SQH, and adopt the k-means clustering algorithm to recover watermarks by creatively modeling the extraction process as a classification problem. Besides from superior robustness, this way simplifies watermark embedding and extraction, and reduces the run-time complexity of the proposed framework. 3) EPWM: To effectively balance robustness and invisibility, we consider the local sensitivity of human visual system (HVS) in wavelet domain, and design an EPWM to precisely evaluate the just noticeable distortion (JND) thresholds of wavelet coefficients, which thereafter are used to adaptively optimize watermark strength.</p><p>Because the SQH shifting and clustering are employed for watermark embedding and extraction, respectively, we term the proposed framework the wavelet-domain SQH shifting and clustering or WSQH-SC for short. WSQH-SC has the following advantages: 1) it not only offers the robust and lossless watermark embedding and extraction processes by integrating SQH shifting and clustering, but also duly introduces perceptual characteristics of HVS to the RRW field, forming a novel yet pragmatic RRW framework; 2) it outperforms the two representative kinds of RRW methods in terms of reversibility, robustness, invisibility, capacity, and run-time complexity; 3) it is widely applicable to different kinds of images; and 4) it is readily applicable in practice with the help of strong robustness and optimal performance trade-off.</p><p>The rest of this paper is organized as follows. Section II briefs the related works for readers to better understand the proposed framework. In Section III, we detail the proposed framework with four modules including PIPA, SQH construction, EPWM-based embedding, and extraction based on </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>In this section, we briefly introduce the GSQH driven method <ref type="bibr" target="#b13">[14]</ref> and discuss its useful inspirations to our novel framework. Thereafter, a popular pixel-wise masking (PWM) model is presented to lay the groundwork for the proposed EPWM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. GSQH Driven Method</head><p>The histogram plays an important role in many practical models and applications, e.g., histogram of oriented gradient features <ref type="bibr" target="#b14">[15]</ref>, bag-of-words <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, and digital watermarking <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. For RW methods, SQH has recently received considerable attention due to stability and simplicity, e.g., arithmetic average of difference (AAD) histogram <ref type="bibr" target="#b20">[21]</ref>, difference histogram <ref type="bibr" target="#b21">[22]</ref>, and prediction error histogram <ref type="bibr" target="#b22">[23]</ref>. In particular, we proposed a GSQH driven method <ref type="bibr" target="#b13">[14]</ref>, which embeds and extracts watermarks by SQH shifting. The following is a brief review of this method.</p><p>Given a t-bit host image I with n * nonoverlapping blocks, its SQH can be generated by calculating the AAD of each block. For convenience, we denote the SQH by a set of data pairs, i.e., X = {(x 1 , n 1 ) , . . . , (x i , n i ) , . . . , (x m * , n m * )}, where x i represents the different values of the AAD, and n i is the corresponding frequency of x i in SQH. Let x r and x l be the two peak points of SQH, wherein</p><formula xml:id="formula_0">r = arg max i n i , 1 ≤ i ≤ m *<label>(1)</label></formula><p>and</p><formula xml:id="formula_1">l = arg max n i i , 1 ≤ i ≤ m * , i = r. (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>Suppose x l ≤ x r , then the embedding is done according to</p><formula xml:id="formula_3">s w k = ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ s k -z -1, if s k &lt; x l -z s k -b k (z + 1) , if x l -z ≤ s k ≤ x l 0, if x l &lt; s k &lt; x r s k + b k (z + 1) , if x r ≤ s k ≤ x r + z s k + z + 1, if s k &gt; x r + z (3)</formula><p>in which s k and s w k are the AADs of the kth block in the host and watermarked images, respectively, b k ∈ {0, 1} is the kth watermark bit, and z ≥ 0 is a scale factor. Correspondingly, the watermarking extraction is defined as</p><formula xml:id="formula_4">b r k = ⎧ ⎨ ⎩ 0, if x l -z ≤ s w k ≤ x l or x r ≤ s w k ≤ x r + z 1, if x l -2z -1 ≤ s w k ≤ x l -z -1 or x r + z + 1 ≤ s w k ≤ x r + 2z + 1 (4)</formula><p>where b r k is the kth extracted watermark bit. Finally, the host image can be recovered without distortion using the inverse operation of (3) when the watermarked image is not degraded by unintentional attacks. Extensive experimental results suggest that the GSQH driven method has its pros and cons. On one hand, it combines GSQH and histogram shifting together to obtain good performance. On the other hand, however, it has three shortcomings: 1) it uses the AADs of all of the blocks, both reliable and unreliable, to generate the SQH of the host image, which increases complexity of watermark embedding; 2) it fails to consider the optimization of watermark strength; and 3) it suffers from unstable robustness against JPEG compression. By taking these pros and cons into account, we therefore integrate PIPA, SQH shifting, clustering, and EPWM into a novel RRW framework, which effectively overcomes the above shortcomings and makes our work intrinsically different from existing RRW methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PWM</head><p>The past years have witnessed the significance of HVS in various applications <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> and many visual masking algorithms revealing the perceptual characteristics of HVS have been applied to digital watermarking <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>. In particular, a PWM algorithm proposed by Barni et al. <ref type="bibr" target="#b28">[29]</ref> has received much publicity, which computes the JND threshold of each wavelet coefficient based on resolution sensitivity, brightness sensitivity, and texture sensitivity. Given the wavelet coefficient c ω ρ (i, j ) at (i, j) in the sub-band c ω ρ with resolution level ρ ∈ {0, 1, 2, 3} and orientation ω ∈ {L L, L H, H L, H H}, the JND threshold is denoted by</p><formula xml:id="formula_5">JND ω ρ (i, j) = (ρ, ω) (ρ, i, j ) (ρ, i, j ) 0.02 . (5)</formula><p>Here, (ρ, ω), (ρ, i, j ) and (ρ, i, j ) evaluate resolution, brightness, and texture sensitivities, respectively, defined by</p><formula xml:id="formula_6">(ρ, ω) = √ 2, if ω = H H 1, otherwise • ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ 1.00, if ρ = 0 0.32, if ρ = 1 0.16, if ρ = 2 0.10, if ρ = 3 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭<label>(6)</label></formula><p>and</p><formula xml:id="formula_7">(ρ, i, j ) = 1+ 1 -(ρ, i, j ) , if (ρ, i, j ) &lt; 0.5 (ρ, i, j ) , otherwise<label>(7)</label></formula><formula xml:id="formula_8">(ρ, i, j ) = 1 256 c L L 3 1 + i 2 3-ρ , 1 + j 2 3-ρ<label>(8)</label></formula><p>and</p><formula xml:id="formula_9">(ρ, i, j ) = 3-ρ k=0 1 16 k ω∈{L H,H L,H H} 1 x=0 1 y=0 c ω k+ρ x + i 2 k , y + j 2 k 2 ×Var c L L 3 1 + x + i 2 3-ρ , 1 + y + j 2 3-ρ x = 0, 1 y = 0, 1.<label>(9)</label></formula><p>In summary, PWM estimates how HVS perceives disturbances in images by considering the resolution, brightness, and texture sensitivities. However, it is not precise enough because the low-pass sub-band at the forth resolution level, i.e., c L L 3 , has less image content, which ends up with the approximate estimation of texture and brightness. To solve this problem, we design the EPWM to better depict local sensitivity of HVS, which not only improves texture and brightness sensitivities but also optimizes the sensitivity weight. In the next section, EPWM is used to adaptively adjust watermark strength, which is helpful for increasing practical applicability of the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED FRAMEWORK</head><p>In this section, we introduce a new RRW framework, i.e., WSQH-SC, which accomplishes the robust lossless embedding task by incorporating the merits of SQH shifting, k-means clustering and EPWM. WSQH-SC comprises two processes: watermark embedding and extraction. In view of their similarity, Fig. <ref type="figure" target="#fig_0">1</ref> only shows the diagram of the embedding process in which the three modules are termed: 1) PIPA; 2) SQH construction; and 3) EPWM-based embedding, and they are detailed in the following three subsections. To be specific, WSQH-SC first investigates the wavelet sub-band properties in depth and exploits PIPA to preprocess the host image, which is of great importance to avoid both overflow and underflow of pixels during the embedding process. Afterward, the host image is decomposed by the 5/3 integer wavelet transform (IWT) <ref type="bibr" target="#b29">[30]</ref> and the blocks of interest in the sub-band c H L 0 are selected to generate the SQH with the help of the threshold constraint. Finally, watermarks can be embedded into the selected blocks by histogram shifting, wherein EPWM is designed to adaptively control watermark strength. After the IWT reconstruction, the watermarked image is obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. PIPA</head><p>In RRW, how to handle both overflow and underflow of pixels is important for reversibility. Xuan et al. <ref type="bibr" target="#b30">[31]</ref> proposed a pixel adjustment strategy to tackle this problem. Unfortunately, it cannot be directly applied to wavelet domain because the adjustment scale related to wavelet transform is unknown. As a consequence, we develop PIPA to handle this problem. Firstly, PIPA deeply exploits the intrinsic relationship between wavelet coefficient and pixel changes. Secondly, by taking the scale and region of wavelet coefficient changes into consideration, PIPA determines the adjustment scale and employs the pixel adjustment strategy to preprocess the host images. To better present the technical details of PIPA, Table <ref type="table" target="#tab_2">III</ref> gives the 5/3 filter coefficients <ref type="bibr" target="#b31">[32]</ref>. Based on this, we investigate the effects of changing wavelet coefficients on pixels from two aspects.   </p><formula xml:id="formula_10">L L λ 4 • v T L v L (2i -1, 2 j -1) H L -λ 16 • v T L v H (2i -1, 2 j) L H -λ 16 • v T H v L (2i, 2 j -1) H H λ 64 • v T H v H (2i, 2 j)</formula><p>For convenience, we denote the wavelet coefficient <ref type="figure"></ref>and<ref type="figure">M</ref> × N is the size of c ω 0 . 1) Single Sub-Band and Single Wavelet Coefficient: Given the watermark strength λ, we consider the changes of pixels when an arbitrary wavelet coefficient in c ω 0 is changed. In particular, if c ω i, j ← c ω i, j + λ, the corresponding changes of pixels in terms of scale and region are shown in Table <ref type="table" target="#tab_2">III</ref>, wherein the affected region is represented by the location of the center,</p><formula xml:id="formula_11">c ω 0 (i, j) in the sub-band c ω 0 as c ω i, j , wherein 1 ≤ i ≤ M, 1 ≤ j ≤ N,</formula><formula xml:id="formula_12">v L = [1, 2, 1] and v H = [1, 2, -6, 2, 1].</formula><p>From Table <ref type="table" target="#tab_2">III</ref>, we can derive three properties: 1) intra-band correlation, i.e., the pixel regions affected by the neighboring wavelet coefficients in a sub-band are overlapped; 2) inter-band correlation, i.e., the regions affected by the wavelet coefficients in different sub-bands are also overlapped; and 3) bi-directional change, i.e., the grayscale values of pixels affected by the wavelet coefficients in the c H L 0 , c L H 0 , and c H H 0 sub-bands are both increased and decreased. Based on this, we conclude that it is impractical to use all of the wavelet coefficients in a sub-band for watermark embedding. That is because it is virtually impossible to determine the adjustment scale and use the pixel adjustment strategy to solve both overflow and underflow problems. Inspired by <ref type="bibr" target="#b12">[13]</ref>, we aim to search for a new solution by further investigating the effects of changing wavelet coefficients on pixels based on multiple sub-bands and multiple wavelet coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Multiple Sub-Bands and Multiple Wavelet Coefficients:</head><p>Considering an arbitrary block with the top left corner at ( p, q) in c ω 0 , 1 ≤ p &lt; M, 1 ≤ q &lt; N, we investigate the changes of wavelet coefficients and pixels in two special cases, as shown in Table <ref type="table" target="#tab_3">IV</ref>. Here, v F = [0, 0, 1, 0, 1, 0, . . . , 1, 0, 0] 2×h-1 , v G = [1, 2, . . . , 2, 1] 2×w-3 and the affected region of pixels is denoted by the location of its top left corner. To further illustrate such effects, Fig. <ref type="figure" target="#fig_1">2</ref> shows an example in which the block size is 3 × 3, and the wavelet coefficients of two neighboring blocks in c L L 0 and c L H 0 are changed simultaneously. With Table IV and Fig. <ref type="figure" target="#fig_1">2</ref>, we can deduce that: 1) the affected pixel regions are nonoverlapped when the wavelet coefficients of neighboring blocks are changed at the same time and 2) the pixel changes are monodirectional and the maximum change scale equals λ. In this case, we can easily </p><formula xml:id="formula_13">⎪ ⎪ ⎨ ⎪ ⎪ ⎩ c L H i, j ← c L H i, j + λ, c L L i, j ← c L L i, j + λ 4, c L L i+1, j ← c L L i+1, j + λ 4 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ p + 1 ≤ i ≤ p + h -2 q + 1 ≤ j ≤ q + w -2 λ 2 • v T F v G (2 p, 2q) ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ c H L i, j ← c H L i, j + λ, c L L i, j ← c L L i, j + λ 4, c L L i, j +1 ← c L L i, j +1 + λ 4 ⎫ ⎪ ⎪ ⎬ ⎪ ⎪ ⎭ p + 1 ≤ i ≤ p + h -2 q + 1 ≤ j ≤ q + w -2 λ 2 • v T G v F (2 p, 2q)</formula><p>determine the adjustment scale and use the pixel adjustment strategy to preprocess host images. In particular, given a t-bit host image I with the size of 2M × 2N, the pixel adjustment is performed by</p><formula xml:id="formula_14">I (i, j) = I (i, j) -η, if I (i, j) &gt; 2 t -1 -η I (i, j) + η, if I (i, j) &lt; η (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>where I (i, j) is the grayscale value of the pixel at (i, j) in the image I ,</p><formula xml:id="formula_16">I (i, j) is the adjusted one (1 ≤ i ≤ 2M, 1 ≤ j ≤ 2N</formula><p>), and η &gt; λ is the adjustment scale. Thereafter, the preprocessed host image can be reliably used for watermark embedding in the next subsections. Because the pixels are changed into a reliable range before embedding, i.e., η, 2 t -1 -η , PIPA can successfully avoid both overflow and underflow of pixels <ref type="bibr" target="#b32">[33]</ref>. It is also worth emphasizing that the proposed WSQH-SC is nonblind to some extent because the locations of the changed pixels need to be saved as a part of side information and transmitted to the receiver side in order to recover the original grayscale values of pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. SQH Construction</head><p>In this subsection, we consider the SQH construction task with a threshold constraint. Inspired by characteristics of the wavelet coefficients <ref type="bibr" target="#b12">[13]</ref>, we focus on the mean of wavelet coefficients (MWC) histogram by taking the following two properties into account: 1) it is designed in high-pass sub-bands of wavelet decomposition, to which HVS is less sensitive, leading to high invisibility of watermarked images and 2) it has almost a zero-mean and Laplacian-like distribution based on the experimental study of wavelet high-pass sub-bands from 300 test images illustrated in Section V, which is stable for different images. In particular, an MWC histogram is generated based on the following procedure.</p><p>Considering a given host image I , we first decompose I using 5/3 IWT to obtain the sub-band c H L 0 , and then divide c H L 0 into n nonoverlapping blocks. Let S = [S 1 , . . . , S k , . . . , S n ] be the MWCs in the sub-band, then the MWC of the kth block, S k , is defined as <ref type="bibr" target="#b10">(11)</ref> where</p><formula xml:id="formula_17">S k = 1 (h -2) × (w -2) h-1 i=2 w-1 j =2 P (i, j ) k</formula><formula xml:id="formula_18">P (i, j ) k</formula><p>represents the wavelet coefficient at (i, j) in the kth block.</p><p>To construct the MWC histogram, our concern is the possibility of utilizing the blocks of interest in a sub-band, which will be helpful for simplifying the embedding process. In view of the histogram distribution of MWC, only the peak and its neighbors in the histogram are mostly useful for the embedding task. Therefore, a threshold constraint is applied to the blocks to retain those of interest, each of which satisfies the following condition:</p><formula xml:id="formula_19">d (x, S k ) ≤ δ, 1 ≤ k ≤ n (<label>12</label></formula><formula xml:id="formula_20">)</formula><p>where d (•) computes the Euclidean distance of two elements, x ∈ {x l , x r } represents the aforementioned two peak points, and δ is a predefined constant for threshold control. When δ ≥ max {d (x l , min (S)) , d (x r , max (S))}, all of the blocks will be retained for embedding, which is a special case of this constraint. Moreover, with the help of the threshold constraint, the capacity can be controlled flexibly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. EPWM-Based Embedding</head><p>It has been well acknowledged that a balance between invisibility and robustness is important for robust watermarking methods. Although many efforts have been made to design lossless embedding models, little progress has been made in this trade-off. Therefore, we develop EPWM to tackle this problem by utilizing the JND thresholds of wavelet coefficients to optimize watermark strength. In view of the disadvantages of PWM discussed in Section II, EPWM focuses on improving the local sensitivity of images to noise by mainly estimating brightness and texture sensitivities in a more precise way.</p><p>Motivated by the benefits of luminance masking <ref type="bibr" target="#b33">[34]</ref>, we first redefine the brightness sensitivity in (5) by calculating the luminance masking of the low-pass sub-band at resolution level ρ, denoted as</p><formula xml:id="formula_21">(ρ, i, j ) = max f ρ v l ρ b (i, j) , f ρ s l ρ b (i, j) , l ρ m (i, j) . (<label>13</label></formula><formula xml:id="formula_22">)</formula><p>Here </p><formula xml:id="formula_23">f ρ v l ρ b (•) = (3/128) • l ρ b (•) -127 + 3, l ρ b (•) &gt; 127 17 • 1 -l ρ b (•)/127 + 3, l ρ b (•) ≤ 127 (14)</formula><formula xml:id="formula_24">S w k ∈ g j , if d S w k , f (ε) j ≤ d S w k , f (ε) l</formula><p>for all l = 1, 2, . . . μ; 5. End for 6. Update the cluster centers with f</p><formula xml:id="formula_25">(ε+1) j = 1 g (ε) j • S w k ∈g (ε) j S w k ; 7. While arg min g μ j =1 S w k ∈g j S w k -f (ε+1) j 2 .</formula><p>and</p><formula xml:id="formula_26">f ρ s l ρ b (•) , l ρ m (•) = l ρ m (•) d 1 l ρ b (•) + d 2 l ρ b (•)<label>(15)</label></formula><p>represent the visibility threshold and spatial masking functions, respectively, in which d 1 (•) and d 2 (•) are the background luminance dependent functions, and l ρ b (•) and l ρ m (•) mean the average background luminance and maximum weighted average of luminance differences. Then, the texture sensitivity is evaluated based on <ref type="bibr" target="#b34">[35]</ref> by</p><formula xml:id="formula_27">(ρ, i, j ) = 3-ρ k=0 1 16 k ω∈{L H,H L,H H} 1 x=0 1 y=0 c ω k+ρ y + i 2 k , x + j 2 k 2 × 1 Ῡ3 ρ ϒ 3 ρ (i, j) (16)</formula><p>where Ῡ3 ρ is the mean of the approximation sub-image ϒ 3 ρ . Because both ( <ref type="formula" target="#formula_21">13</ref>) and ( <ref type="formula">16</ref>) take the difference between resolution levels into account, we can replace <ref type="bibr" target="#b5">(6)</ref> with</p><formula xml:id="formula_28">(ω) = √ 2, if ω = H H 1, otherwise.<label>(17)</label></formula><p>Finally, the new JND threshold can be obtained by</p><formula xml:id="formula_29">JND ω ρ (i, j ) = (ω) (ρ, i, j ) ϑ (ρ, i, j ) 0.2<label>(18)</label></formula><p>in which 0 &lt; ϑ ≤ 1 is a tuning parameter corresponding to the weight of brightness sensitivity. In view of space limitation, refer to <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b34">[35]</ref> for the definitions of <ref type="figure"></ref>and<ref type="figure" target="#fig_2">ϒ 3</ref> ρ . With <ref type="bibr" target="#b17">(18)</ref>, we use the obtained JND thresholds to control watermark strength during the embedding process. To be specific, given the MWC of the kth block of interest, i.e., S k , 1 ≤ k ≤ m, the watermark embedding is given by</p><formula xml:id="formula_30">d 1 (•), d 2 (•), l ρ b (•), l ρ m (•),</formula><formula xml:id="formula_31">S w k = S k + βλb k . (<label>19</label></formula><formula xml:id="formula_32">)</formula><p>Here S w k is the obtained MWC after the kth watermark bit b k ∈ {0, 1} is embedded, β is a factor defined as</p><formula xml:id="formula_33">β = S k -S * /abs S k -S * (20) S * = arg min x∈{x l ,x r } d (S k , x)<label>(21)</label></formula><p>and</p><formula xml:id="formula_34">λ = α M × N M i=1 N j =1 JND ω ρ (i, j ) (<label>22</label></formula><formula xml:id="formula_35">)</formula><p>represents the watermark strength, where α is a global parameter and M × N is the sub-band size. Because the novel embedding model shown in <ref type="bibr" target="#b18">(19)</ref> expands the additive spread spectrum <ref type="bibr" target="#b35">[36]</ref> to a reversible embedding model, we term it a generalized additive spread spectrum. By applying <ref type="bibr" target="#b18">(19)</ref> to the blocks of interest in the sub-band, watermarks can be embedded into the wavelet coefficients. Thereafter, the IWT reconstruction is performed to obtain the watermarked image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Extraction Based on k-Means Clustering</head><p>If watermarked images are transmitted through an ideal channel, we can directly adopt the inverse operation of <ref type="bibr" target="#b18">(19)</ref> to recover host images and watermarks. However, in the real environment, degradation may be imposed on watermarked images due to unintentional attacks, e.g., lossy compression and random noise. Therefore, it is essential to find an effective watermark extraction algorithm so that it can resist unintentional attacks in the lossy environment.</p><p>Based on the aforementioned embedding model in <ref type="bibr" target="#b18">(19)</ref>, the MWC histogram of watermarked images are divided into three parts shown in Fig. <ref type="figure" target="#fig_2">3</ref>, in which the center part corresponds to watermark bit "0" and others to bit "1." To extract the embedded watermarks, the key issue is to partition these parts dynamically. In the lossy environment, this is very difficult because the histogram distribution of MWC is destroyed by unintentional attacks, as reported in <ref type="bibr" target="#b13">[14]</ref>. In this paper, by investigating the effects of unintentional attacks on histogram, we treat the partition as a clustering problem with a certain number of clusters and adopt the k-means clustering algorithm <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref> to tackle this problem for simplicity.</p><p>Similar to the embedding process, we first decompose the watermarked image with 5/3 IWT and construct the MWC histogram by calculating the MWCs of blocks of interest in the sub-band c H L 0 . Let S w = S w 1 , . . . , S w m be the obtained MWCs, F = f 1 , . . . , f μ be the cluster centers, and g = g 1 , . . . , g μ be the set of clusters, wherein μ is the number of clusters. The above classification process is summarized in Table V. Particularly, the initial cluster centers are given by considering the features of the embedding process, e.g., F = {τ min (S w ) , 0, τ max (S w )} for μ = 3, to improve the efficiency of classification. Based on the results of classification, the embedded watermarks can be extracted by  for μ = 3, in which S w k is the kth MWC, b r k is the extracted watermark bit, and Classes I-III denote the obtained set of clusters. Thereafter, we recover the MWCs with S r k = S w k -βλb r k , which are identical to the original ones in the lossless environment. After the IWT reconstruction, the inverse operation of ( <ref type="formula" target="#formula_14">10</ref>) is applied to the pixels changed by PIPA in the embedding process to recover host images. As mentioned earlier, the side information including the block size, watermark strength, and locations of the pixels changed by PIPA, should be transmitted to the receiver side, which is important for the recovery of watermarks and host images, and also leads to nonblindness of the proposed framework to some extent.</p><formula xml:id="formula_36">b r k = 0, if S w k ∈ Class II 1, if S w k ∈ Class I or Class III (<label>23</label></formula><formula xml:id="formula_37">)</formula><p>In summary, the embedding and extraction processes of the proposed framework are depicted in Tables VI and VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS FOR EPWM</head><p>To verify the effectiveness of the proposed EPWM, we compare it with the PWM <ref type="bibr" target="#b28">[29]</ref> and the improved PWM (IPWM) <ref type="bibr" target="#b34">[35]</ref> based on a synthetic dataset including ten standard images, e.g., Lena, Barbara, Boat, and 29 undistorted images from the laboratory for image and video engineering (LIVE) II database <ref type="bibr" target="#b38">[39]</ref>. In our experiments, the wavelet transform with the "Daubechies" filter with three taps is applied to decompose a given host image I into high-and low-pass sub-bands. Based on this, the JND thresholds of different sub-bands can be computed with <ref type="bibr" target="#b17">(18)</ref>. For the sake of simplicity, Fig. <ref type="figure" target="#fig_4">4</ref> shows the examples of different masking models in which ϑ is 0.5 in EPWM and the JND thresholds of wavelet coefficients in the sub-band c L L 0 are used for comparison. From Fig. <ref type="figure" target="#fig_4">4</ref>, we can see that the proposed EPWM estimates the brightness and texture sensitivities with greater precision than PWM and IPWM.</p><p>To further demonstrate the superiority of EPWM for different applications, we conducted two groups of experiments based on the suggestions in <ref type="bibr" target="#b39">[40]</ref>, in which the applications in noise shaping and image quality assessment were considered, respectively. To be specific, the noise shaping experiment compares the amount of noise hidden into an image to evaluate the accuracy of masking models, in which the noise is determined by the JND thresholds of different masking models. The experiment of image quality assessment performs the evaluation by applying the masking models under comparison to an objective image quality assessment method and comparing the consistency of the obtained objective scores with the given subjective viewing ones. In the following subsections, we will make an empirical study of the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Results of Noise Shaping</head><p>As discussed in <ref type="bibr" target="#b39">[40]</ref>, a better masking model should be able to hide more noise into an image at a certain level of perceptual quality. Therefore, we carried out this experiment by hiding the noise determined by JND thresholds of different masking models into a given host image I . In particular, we   </p><formula xml:id="formula_38">(i, j) = c H L 0 (i, j) + u • JND H L 0 (i, j)<label>(24)</label></formula><p>where JND H L 0 (i, j) was calculated by PWM, IPWM, and EPWM, respectively. Afterward, the wavelet reconstruction was used to obtain the noised image. Based on this, we compared the host image I and its noised variation Î from two aspects, human observers' observation and peak signal-to-noise ratio (PSNR). When a human observer cannot discern significant quality difference among the noised images obtained by the aforementioned three masking models, we consider these noised images to have the same level of perceptual quality. In this case, we compare the PSNRs of the noised image versus the host one to evaluate the amount of noise. The lower the PSNR is, the greater the amount of noise is, and thus the more precise the masking model is. Fig. <ref type="figure" target="#fig_5">5</ref> illustrates the examples of the images noised by three masking models, wherein the tuning parameter ϑ equals 0.8 in EPWM. As shown, these noised images have the same level of perceptual quality since no significant quality difference can be observed. The corresponding results of PSNR on the synthetic dataset are shown in Tables <ref type="table" target="#tab_4">VIII</ref> and<ref type="table" target="#tab_7">IX</ref>. On average, it can be  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>The JND thresholds of 12 high-pass sub-bands in a pair of reference and distorted images, i.e., JND</p><formula xml:id="formula_39">(i)</formula><p>R and JND</p><formula xml:id="formula_40">(i) D , 1 ≤ i ≤ 12. Output: Objective image quality Q. 1. For JND (i) ∈ JND (i) R , JND (i) D do 2.</formula><p>Compute the quality threshold using T * = γ 12 • 12 i=1 std JND (i) , std (•) being the standard deviation of JND (i) , and γ being a parameter of distortion type; 3. Generate the normalized histogram with each bin defined by seen that EPWM outperforms PWM by 0.46 dB and IPWM by 1.07 dB based on standard images, and it is superior to PWM by 0.85 dB and to IPWM by 1.1 dB based on LIVE II database, respectively. Therefore, we can conclude that EPWM is more precise than PWM and IPWM.</p><formula xml:id="formula_41">H (i) = C T (i) C N (i), C T (i)</formula><p>Another merit of EPWM is that it can regulate the noise energy with the help of the tuning parameter ϑ, as shown in Fig. <ref type="figure" target="#fig_6">6</ref>. With the increase of ϑ, the PSNR is decreased a little, so more noise can be hidden into the given image. Based on the empirical study, it is suggested that the tuning parameter be from 0.4 to 0.8 in view of the good trade-off between the noise energy and JND thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Application in Image Quality Assessment</head><p>In this subsection, we apply the masking models under comparison to an image quality assessment method based on the multiscale geometric analysis proposed in <ref type="bibr" target="#b40">[41]</ref> to further show the merits of EPWM. This evaluation is based on the fact that a better masking model with accurate estimation should lead to better objective quality assessment in comparison with subjective viewing scores <ref type="bibr" target="#b39">[40]</ref>. In this experiment, we adopted the LIVE II database and considered four kinds of attacks, including JPEG2000, white noisy (WN), Gaussian blurred (Gblur), and fast-fading (FF) Rayleigh channel noise. Here, the high-resolution color images and their degraded versions in LIVE II database are termed reference and distorted images, respectively. We decomposed these images by wavelet trans- form with the resolution level of four and then calculated the JND thresholds of the obtained 12 high-pass sub-bands. Let JND</p><formula xml:id="formula_42">(i)</formula><p>R , 1 ≤ i ≤ 12 be the JND threshold of the i th sub-band in a reference image and JND (i) D be that in the corresponding distorted image. Taking a pair of reference and distorted images as an example, Table <ref type="table" target="#tab_7">X</ref> illustrates the procedure of objective image quality computation.</p><p>By applying Table X to all of the pairs of reference and distorted images, we can obtain the objective image quality of each distorted image. Following this, the variance-weighted regression analysis is adopted to provide a nonlinear mapping between the objective quality and subjective mean opinion score. Based on this, the fitness with the subjective scores is evaluated using three metrics, i.e., Pearson linear correlation coefficient (CC) for prediction accuracy, Spearman rank-order CC (ROCC) for prediction monotonicity, and mean absolute error (MAE). Table XII reports the experimental comparisons from which we can observe that the quality metric based on EPWM is superior to the metrics using PWM and IPWM with higher CC and ROCC and lower MAE. Therefore, we can draw a conclusion that the proposed EPWM yields better overall performance than PWM and IPWM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS FOR WSQH-SC</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment Configuration</head><p>In this section, we utilize three kinds of images to illustrate the effectiveness of the proposed framework, i.e., WSQH-SC. The test images consist of 100 natural images from the CVG-UGR image database <ref type="bibr" target="#b41">[42]</ref>, 100 medical images based on DICOM sample image sets <ref type="bibr" target="#b42">[43]</ref> and OsiriX website [44], and 100 synthetic aperture radar (SAR) images picked up from some open image database websites. To facilitate comparison, all images are resized into a fixed size, i.e., 512 × 512 × 8 for natural and medical images and 256 × 256 × 8 for SAR images.</p><p>In our experiments, the robustness, reversibility, invisibility, capacity, and run-time complexity are used to evaluate the performance. In particular, the pure capacity is calculated in bits/pixel (b/ps) and the invisibility is measured by PSNR, defined as <ref type="bibr" target="#b25">(26)</ref> in which I (i, j) and I w (i, j) denote the grayscale values of the pixels at (i, j) in the host and watermarked images. To evaluate robustness, three kinds of unintentional attacks, including JPEG compression with the quality factor from 20 to 100 with a step of 10, JPEG2000 compression with the rate from 0.2 to 2.0 with a step of 0.2, and additive Gaussian noise (AGN) with zero mean and variance from 0.001 to 0.01 with a step of 0.001, are imposed on the watermarked images, respectively. It should be noted that the Kakadu command line tool is adopted to accomplish JPEG 2000 compression. Similar to other methods, e.g., <ref type="bibr" target="#b10">[11]</ref>, we repeatedly embedded the watermarks with a fixed length (e.g., 100 bits) into the host images and utilized the major voting to count the correctly extracted watermark bits at the receiver side. Moreover, we define a novel unified metric for robustness evaluation by</p><formula xml:id="formula_43">PSNR = 10 log 255 2 MSE (25) MSE = 1 4MN 2M i=1 2N j =1 I (i, j) -I w (i, j ) 2</formula><formula xml:id="formula_44">= ξ × abs (σ -κ) σ (<label>27</label></formula><formula xml:id="formula_45">)</formula><p>and 0 ≤ &lt; 1, in which ξ is a normalization factor and equals 1 for JPEG and JPEG2000, and 0.1 for AGN, σ represents the benchmark of the unintentional attack strength, i.e., 100 for JPEG, 2.0 for JPEG2000, and 0.001 for AGN, and κ is the tolerated unintentional attack strength, which is to say, when the unintentional attack strength is smaller than κ, the hidden watermarks can be recovered correctly. From ( <ref type="formula" target="#formula_44">27</ref>), it can be observed that the greater is, the better the robustness is, and vice versa. Besides, we employ the image error rate (IER), i.e., the ratio of the number of the images recovered with errors to the total number of each kind of the test images, to measure reversibility.</p><p>In the next subsections, we first analyze the parameter sensitivity based on the aforementioned environment configuration. Afterward, we evaluate the performance of the proposed WSQH-SC by comparing with that of the classical RRW methods to demonstrate its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameter Sensitivity Analysis</head><p>In this experiment, we study how free parameters affect the performance of WSQH-SC and how to set suitable parameters to achieve a reasonable result for different purposes. In the proposed framework, we have three free parameters, i.e., block size h × w, threshold δ and watermark strength λ. Because λ ≥ δ and reversibility is independent of the aforementioned three parameters, we take a simple case, i.e., λ = δ, into account, and thus pay more attention to the effects of threshold and block size on capacity, invisibility, and robustness.</p><p>1) Threshold: In this part, we first investigate the effects of threshold on capacity, invisibility and robustness, respectively. Then, the optimization of the threshold is discussed based on the proposed EPWM to make a trade-off between invisibility and robustness.</p><p>Given the host image I with the size of 2M × 2N, the pure capacity C can be computed by</p><formula xml:id="formula_46">C = S k d (x, S k ) ≤ δ, 1 ≤ k ≤ M h × N w (<label>28</label></formula><formula xml:id="formula_47">)</formula><p>in which x ∈ {x l , x r } represents the peak points, and | • | is the cardinality of a set, i.e., the number of elements of a   set. In view of the Laplacian-like distribution of MWC, we can see that the number of S k satisfying ( <ref type="formula" target="#formula_46">28</ref>) is increased with the increase of δ for a given block size h × w, which means the capacity is improved. Fig. <ref type="figure" target="#fig_8">7</ref> gives the average experimental results of three kinds of images for the block size of 8 × 8 and threshold δ from 1 to 8 with a step of 1. It can also be seen that medical images achieve the highest capacity because neighboring pixels in medical images are more closely correlated than those in other images and thus more S k s are included for the same threshold.</p><p>Given the block size h × w and wavelet sub-band c H L 0 , we study the influence of δ on invisibility. With Table <ref type="table" target="#tab_3">IV</ref>, we can equivalently rewrite MSE by</p><formula xml:id="formula_48">MSE = C • (h -2) × (2w -4.5) • δ 2 2M × 2N (<label>29</label></formula><formula xml:id="formula_49">)</formula><p>in which C is the capacity for a given δ. With ( <ref type="formula">25</ref>) and ( <ref type="formula" target="#formula_48">29</ref>), it can be seen that PSNR drops with Cδ 2 becoming ever larger. For empirical justification, the experiments are conducted in the same experimental environment and the results are shown in Fig. <ref type="figure" target="#fig_9">8</ref>. It should be noted that ( <ref type="formula" target="#formula_48">29</ref>) is derived on the assumption that no pixels are changed by PIPA in the first step. In practical scenarios, natural and SAR images satisfy this assumption averagely, however, for medical images, many pixels need to be changed. As a result, the PSNR of medical images is obviously lower than that of others.   To examine the effects of δ on robustness, Figs. 9-11 report the average robustness against the three kinds of unintentional attacks, respectively, where the block size is 8 × 8, and δ changes from 4 to 12 with a step of 1. It can be seen that the robustness is gradually increased with the increase of δ. In particular, the robustness against JPEG compression for SAR images is increased more greatly than that for other images, up to 0.5 when δ = 9. As for JPEG2000 compression, the robustness for medical images is the highest, up to 0.8 when δ = 5, while the robustness for natural and SAR images are 0.4 and 0.3 for the same δ, higher than that against JPEG compression. By contrast, a stronger robustness against AGN is obtained for natural, medical and SAR images. For example, it is as high as 0.9 for natural and SAR images when δ = 8.</p><p>According to the above results, we can see that the robustness increases with the threshold becoming ever larger while the invisibility drops at the same time. Therefore, it is of great importance to make a trade-off between them in practical applications. In this paper, we develop EPWM to serve this purpose by optimizing watermark strength. To demonstrate this point, we computed JND thresholds of host images with <ref type="bibr" target="#b17">(18)</ref> and adaptively adjusted watermark strength in the embedding process. The statistical average results for the block size of 8 × 8 are shown in Table XII, which show that EPWM applied to the proposed WSQH-SC can perform well for natural, medical, and SAR images with good robustness and acceptable invisibility.</p><p>2) Block Size: Besides the threshold, the block size is another important parameter affecting capacity, invisibility, and robustness. In our experiments, we will make an analysis of its effects, wherein the block size is specified from 4 × 4 to 16 × 16 with a step of 4, and the threshold is 8 for both capacity and invisibility tests and is 16 for the robustness test.</p><p>According to <ref type="bibr" target="#b27">(28)</ref>, the pure capacity C is decreased with the increase of block size for a fixed threshold. This is because the number of blocks satisfying the threshold constraint is reduced. Fig. <ref type="figure" target="#fig_1">12</ref> presents the experimental results for natural, medical, and SAR images, which demonstrates that the smaller the block is, the higher the capacity is, and vice versa.</p><p>Given a fixed threshold δ, suppose all blocks are used for watermark embedding, i.e., C = M/ h • N/w . We study the effect of block size h × w on invisibility. By substituting C = M/ h • N/w into (29), we can deduce</p><formula xml:id="formula_50">MSE = M/ h • N/w • (h -2) × (2w -4.5) 2M × 2N • δ 2 ≤ (h -2) × (2w -4.5) 2h × 2w • δ 2 = J • δ 2 . (<label>30</label></formula><formula xml:id="formula_51">)</formula><p>Furthermore, we derive the partial derivative of J with respect to h and w, respectively</p><formula xml:id="formula_52">∂ J ∂h = 1 - 9 4w • h -2 ∂ J ∂w = 9 1 8 - 1 4h • w -2 . (<label>31</label></formula><formula xml:id="formula_53">)</formula><p>Because h ≥ 3 and w ≥ 3 in the WSQH-SC, (∂ J/∂h) &gt; 0 and (∂ J / ∂w) &gt; 0. Based on this, we can conclude that PSNR becomes smaller with the increase of h and w. Fig. <ref type="figure" target="#fig_2">13</ref> provides the experimental justification, where medical images have the lowest PSNR due to the influence of PIPA.</p><p>Table <ref type="table" target="#tab_10">XIII</ref> illustrates the effect of the block size on robustness, from which we can see that the robustness is improved to some extent with the increase of the block size. For each kind of images, the robustness against JPEG2000 and AGN remains unchanged for block sizes of 8 × 8 to 16 × 16, while the robustness against JPEG compression is increased by up to 0.7 with the block size increasing from 4 × 4 to 12 × 12. Natural 0.3/0.6/0.6 0.6/0.7/0.9 0.7/0.7/0.9 0.7/0.7/0.9 Medical 0.3/0.8/0.4 0.6/0.9/0.9 0.7/0.9/0.9 0.7/0.9/0.9 SAR 0.4/0.5/0.9 0.6/0.6/0.9 0.7/0.6/0.9 0.7/0.6/0.9 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance Evaluation</head><p>In this section, we evaluate the proposed framework, i.e., WSQH-SC in comparison with the three classical RRW methods including HR <ref type="bibr" target="#b10">[11]</ref>, HDC (1) <ref type="bibr" target="#b11">[12]</ref>, and HDC (2) <ref type="bibr" target="#b12">[13]</ref> in terms of robustness, reversibility, invisibility, capacity, and run-time complexity. For the sake of fair comparison, we also apply these compared methods to the aforementioned 300 test images in the same experimental environment. In particular, BCH (15, 11, 1) is used in HDC (1) and HDC <ref type="bibr" target="#b1">(2)</ref>.</p><p>1) Robustness: We compare the robustness of the aforementioned methods when the block size is 8 × 8 and the watermark strength is 16: 1) the embedding level is 8 in HR; 2) K = 8 in HDC (1); and 3) λ = 16 in WSQH-SC. The strength in HDC (2) is T + 1. Refer to <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref> for the definitions of K and T . In addition, by taking the effect of major voting on robustness into account, we repeatedly embedded the watermarks with 100 bits into host images for spatial-domain methods, i.e., HR and HDC (1) and embedded the watermarks with 10 bits for wavelet-domain ones, i.e., HDC (2) and WSQH-SC.</p><p>Table XIV reports the experimental results, from which we conclude that the proposed WSQH-SC is superior to the other methods. In particular, we observe that: 1) WSQH-SC has higher robustness against JPEG2000 compression than HR by 0.5 for medical images; 2) WSQH-SC outperforms HDC (1) greatly with the robustness against AGN; and 3) the performance of HDC ( <ref type="formula" target="#formula_1">2</ref>) is poor and the robustness against JPEG compression is as low as 0 for medical images, much worse than that of WSQH-SC.</p><p>2) Reversibility: In this part, we use the aforementioned IER to evaluate reversibility, which shows whether host images and watermarks can be recovered without distortion in the Almost all of the host images cannot be recovered using HDC (1), as analyzed in <ref type="bibr" target="#b43">[45]</ref>. In this case, the extracted watermarks by HDC (1) may contain errors. HDC (2) also performs poorly, especially for medical images, which is related to insufficient consideration of the effects of changing wavelet coefficients on pixels. Therefore, a conclusion can be drawn that the proposed WSQH-SC achieves better reversibility in comparison with others. It should be noted that the results of HDC ( <ref type="formula" target="#formula_1">2</ref>) are the same because the watermark strength is determined by host images and irrelevant to the given thresholds.</p><p>3) Invisibility: Invisibility is used to evaluate the distortion of watermarked images versus host ones. Fig. <ref type="figure" target="#fig_14">14</ref> illustrates some examples of watermarked images obtained by the compared methods, where the regions of interest are zoomed to show the difference clearly. In this experiment, the block size is 4 ×4, and the watermark strength is 8 for HR, HDC (1) and WSQH-SC. It shows that "salt-and-pepper" noise greatly degrades the visual quality of the watermarked images in HR, and results in the worst PSNRs for the three test images. From the perspective of human observers, WSQH-SC achieves a similar visual quality to HDC (1) and a slightly better visual quality than HDC (2) due to the blocking effect in HDC <ref type="bibr" target="#b1">(2)</ref>. The objective comparison suggests that the PSNR of WSQH-SC for the SAR image is higher than that of the others, and that for the medical image is lower because of PIPA. In summary, the invisibility of WSQH-SC is superior to HR and comparable to HDC (1) and HDC (2) in most cases.</p><p>4) Capacity: To compare the capacity of WSQH-SC with the above three methods, we calculated their pure capacities based on the 300 test images. The average results are illustrated in Table XVI, wherein the block size is 8 × 8 and the threshold is 8 in WSQH-SC. For convenience, we classify the methods into two categories, i.e., those in spatialand wavelet-domains. It can be seen that the spatial-domain methods achieve higher capacity than those developed in the wavelet domain. This is because these methods employ the whole host image to embed watermarks while the latter uses only one sub-band. Based on the comparison between the wavelet-domain methods, the capacity of the WSQH-SC is higher than that of HDC (2) because of the usage of error correction coding in HDC (2).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Run-Time Complexity:</head><p>We study the run-time complexity of WSQH-SC and compare it with that of the aforementioned methods. To further verify the effects of the k-means clustering algorithm on the run-time, we construct a new method, termed WSQH-S, which has the same embedding process as WSQH-SC and employs the inverse operation of <ref type="bibr" target="#b18">(19)</ref> for watermark extraction. To fairly compare different methods, we carry out this experiment on the same computer with a 2.93-GHz Intel(R) Core(TM) i3 CPU and 2 GB memory. We  <ref type="table" target="#tab_14">XVII</ref> shows the average results of the 300 test images, wherein the parameters are the same as those for the robustness test. In addition, the JPEG compression with the quality factor of 100 is used here. From the results, we observe that the proposed WSQH-SC outperforms the classical RRW methods. And its run-time of watermark extraction is slightly longer than that of WSQH-S due to the usage of the k-means clustering algorithm. In particular, HDC (1) and HDC (2) are much slower than WSQH-SC due to the Arnold permutation. HR computes the centroids of two zones in a block, and results in a slightly longer run-time. In summary, the experimental results show that: 1) the WSQH-SC is superior to the classical RRW methods in terms of run-time complexity and 2) it is worthwhile to improve the robustness with a low run-time cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we have developed a novel yet pragmatic framework for RRW. It includes carefully designed PIPA, SQH shifting and clustering, and EPWM, each of which handles a specific problem in RRW. PIPA preprocesses host images by adjusting the pixels into a reliable range for satisfactory reversibility. SQH shifting and clustering constructs new watermark embedding and extraction processes for good robustness and low run-time complexity. EPWM precisely estimates the local sensitivity of HVS and adaptively optimizes the watermark strength for a trade-off between robustness and invisibility. In contrast to representative methods, thorough experimental results on natural, medical and SAR images demonstrate that the proposed framework: 1) obtains comprehensive performance in terms of reversibility, robustness, invisibility, capacity and run-time complexity; 2) is widely applicable to different kinds of images; and 3) is readily applicable in practice.</p><p>In future, we will combine the proposed framework with the local feature <ref type="bibr" target="#b44">[46]</ref>- <ref type="bibr" target="#b46">[48]</ref> to further improve robustness. In addition, it is valuable to integrate the merits of sparse representation <ref type="bibr" target="#b47">[49]</ref> and probabilistic graphical model <ref type="bibr" target="#b48">[50]</ref> into the designing of image watermarking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Embedding process of the proposed wavelet-domain SQH shifting and clustering framework. (a) PIPA. (b) SQH construction. (c) EPWM based embedding.</figDesc><graphic coords="4,93.47,54.29,424.46,210.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example of the effects of changing wavelet coefficients on pixels based on multiple sub-bands and multiple wavelet coefficients.</figDesc><graphic coords="4,344.99,302.57,184.34,124.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example of WMC histogram in a watermarked image. TABLE V PROPOSED CLASSIFICATION PROCESS Input: The MWCs S w = S w 1 , . . . , S w m , and the number of clusters μ. Output: The set of clusters g = g 1 , . . . , g μ . 1. Initialize the cluster centers f (1) 1 , . . . , f (1) μ , and iteration time ε; 2. Do 3. For k = 1 to m do 4. Assign the kth S w k to one of the clusters according to the distance between it and cluster centers:</figDesc><graphic coords="6,96.47,53.21,155.54,93.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 .= 3 6.</head><label>63</label><figDesc>Input: A t-bit host image I with the size of 2M × 2N , a watermark sequence b = [b 1 , . . . , b m ], and block size h × w. Output: The watermarked image I w . 1. Apply PIPA to host image I to obtain the adjusted image I , and record the locations of the pixels changed by PIPA; 2. Decompose I using 5/3 IWT and divide the sub-band c H L 0 into n nonoverlapping blocks with the size of h × w; 3. Compute the MWCs of all of the blocks with (11) and obtain S = S 1 , . . . , S k , . . . , S n ; 4. Retain blocks of interest with the threshold constraint in (12) and construct SQH; 5. Perform EPWM to compute the watermark strength For k = 1 to m do 7. Embed the kth watermark bit b k with S w k = S k + βλb k ; 8. End for 9. Reconstruct the watermarked image I w with inverse 5/3 IWT. TABLE VII EXTRACTION PROCEDURE OF THE PROPOSED FRAMEWORK Input: A watermarked image I w with the size of 2M × 2N , block size h × w, watermark strength λ and the locations of the pixels changed by PIPA. Output: The recovered watermark sequence b r and image I r . 1. Decompose I w using 5/3 IWT and divide the sub-band c H L 0 into n nonoverlapping blocks with the size of h × w; 2. Compute MWCs of blocks of interest with (11) and obtain S w = S w 1 , . . . , S w k , . . . , S w m ; 3. Classify S w with k-means clustering; 4. For k = 1 to m do 5. Extract the embedded watermarks S w k ∈ Class II 1, if S w k ∈ Class I or Class III for μ Recover the MWCs with S r k = S w k -βλb r k ; 7. End for 8. Perform inverse IWT followed by PIPA to obtain the recovered image I r ; 9. Return the recovered watermarks b r and image I r .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Examples of JND thresholds of different masking models: (a) original c L L 0 sub-band, (b) PWM, (c) IPWM, and (d) EPWM.</figDesc><graphic coords="7,323.27,53.81,228.50,195.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Examples of images noised by different masking models: (a) PWM, (b) IPWM, and (c) EPWM with ϑ = 0.8.</figDesc><graphic coords="8,57.71,53.09,232.58,125.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. PSNRs for different tuning parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>i=1</head><label></label><figDesc>being the number of wavelet coefficients greater than T * in the ith sub-band and C N (i) being the total number of wavelet coefficients in it, 1 ≤ i ≤ 12; 4. End for 5. Return the objective qualityQ |H R (i)-H D (i)| +1 , H R (•) and H D (•)being the normalized histograms of the reference and distorted images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Pure capacities for different thresholds.</figDesc><graphic coords="10,89.99,53.81,168.86,110.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. PSNRs for different thresholds.</figDesc><graphic coords="10,97.43,189.77,153.17,107.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Robustness against JPEG compression for different thresholds.</figDesc><graphic coords="10,339.95,53.33,194.62,84.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Robustness against JPEG2000 compression for different thresholds.</figDesc><graphic coords="10,348.47,167.21,177.91,84.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Robustness against AGN for different thresholds.</figDesc><graphic coords="10,346.55,280.49,181.86,84.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 12 .Fig. 13 .</head><label>1213</label><figDesc>Fig. 12. Pure capacities for different block sizes.</figDesc><graphic coords="11,57.95,53.57,232.58,79.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Examples of watermarked images of four methods. (a) Host images. (b) HR. (c) HDC (1). (d) HDC (2). (e) WSQH-SC. The PSNRs (dB) are given below the watermarked images.</figDesc><graphic coords="12,331.67,387.65,226.34,74.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III EFFECTS</head><label>III</label><figDesc></figDesc><table /><note><p>BASED ON SINGLE SUB-BAND AND SINGLE WAVELET COEFFICIENT Orientation ω Scale Center</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV EFFECTS</head><label>IV</label><figDesc>BASED ON MULTIPLE SUB-BANDS AND MULTIPLE WAVELET COEFFICIENTS</figDesc><table><row><cell></cell><cell cols="2">Changes of pixels</cell></row><row><cell>Changes of wavelet coefficients</cell><cell></cell><cell></cell></row><row><cell>⎧</cell><cell>Scale</cell><cell>Top left corner</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE VI EMBEDDING</head><label>VI</label><figDesc>PROCEDURE OF THE PROPOSED FRAMEWORK</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE X PROCEDURE</head><label>X</label><figDesc>OF OBJECTIVE IMAGE QUALITY COMPUTATION</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE XII ADAPTIVE</head><label>XII</label><figDesc>THRESHOLD FOR TRADE-OFF BETWEEN INVISIBILITY AND ROBUSTNESS</figDesc><table><row><cell>Image</cell><cell>δ</cell><cell>PSNR (dB)</cell><cell>JPEG</cell><cell cols="2">Robustness JPEG2000 AGN</cell></row><row><cell>Natural</cell><cell>13</cell><cell>33.60</cell><cell>0.5</cell><cell>0.7</cell><cell>0.9</cell></row><row><cell>Medical</cell><cell>12</cell><cell>26.94</cell><cell>0.5</cell><cell>0.9</cell><cell>0.9</cell></row><row><cell>SAR</cell><cell>20</cell><cell>29.30</cell><cell>0.7</cell><cell>0.6</cell><cell>0.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE XIII EFFECTS</head><label>XIII</label><figDesc>OF BLOCK SIZE ON ROBUSTNESS (JPEG/JPEG2000/AGN)</figDesc><table><row><cell>Image</cell><cell>4 × 4</cell><cell>Block size 8× 8 1 2× 12</cell><cell>16 × 16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE XV COMPARISON</head><label>XV</label><figDesc>OF REVERSIBILITY BASED ON IER lossless environment. The experimental results are presented in Table XV when the block size is fixed at 8×8 and the threshold δ equals 4 and 8. As shown, HR fails to recover a few of the host images due to both overflow and underflow of pixels.</figDesc><table><row><cell>Image</cell><cell>HR</cell><cell cols="2">δ = 4 HDC (1) HDC (2)</cell><cell>WSQH-SC</cell></row><row><cell>Natural</cell><cell>0.02</cell><cell>0.84</cell><cell>0.51</cell><cell>0</cell></row><row><cell>Medical</cell><cell>0.01</cell><cell>0.96</cell><cell>0.94</cell><cell>0</cell></row><row><cell>SAR</cell><cell>0.03</cell><cell>0.89</cell><cell>0.58</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>δ = 8</cell><cell></cell><cell></cell></row><row><cell>Natural</cell><cell>0.02</cell><cell>0.98</cell><cell>0.51</cell><cell>0</cell></row><row><cell>Medical</cell><cell>0.01</cell><cell>0.99</cell><cell>0.94</cell><cell>0</cell></row><row><cell>SAR</cell><cell>0.01</cell><cell>0.95</cell><cell>0.58</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE XVI COMPARISON</head><label>XVI</label><figDesc>OF CAPACITY (b/p)</figDesc><table><row><cell>Image</cell><cell cols="2">Spatial-domain HR HDC (1)</cell><cell cols="2">Wavelet-domain HDC (2) WSQH-SC</cell></row><row><cell>Natural</cell><cell>0.015</cell><cell>0.011</cell><cell>0.003</cell><cell>0.004</cell></row><row><cell>Medical</cell><cell>0.015</cell><cell>0.011</cell><cell>0.003</cell><cell>0.004</cell></row><row><cell>SAR</cell><cell>0.015</cell><cell>0.011</cell><cell>0.003</cell><cell>0.004</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE XVII COMPARISON</head><label>XVII</label><figDesc>OF RUN-TIME COMPLEXITY (EMBEDDING/EXTRACTION)</figDesc><table><row><cell>Method</cell><cell>Natural</cell><cell>Image Medical</cell><cell>SAR</cell></row><row><cell>HR</cell><cell>1.367/1.428</cell><cell>1.340/1.396</cell><cell>0.314/0.350</cell></row><row><cell>HDC (1)</cell><cell>3.370/10.875</cell><cell>3.373/10.871</cell><cell>0.810/0.981</cell></row><row><cell>HDC (2)</cell><cell>0.916/1.069</cell><cell>0.899/1.054</cell><cell>0.236/0.073</cell></row><row><cell>WSQH-S</cell><cell>0.096/0.079</cell><cell>0.104/0.086</cell><cell>0.026/0.017</cell></row><row><cell>WSQH-SC</cell><cell>0.098/0.086</cell><cell>0.104/0.091</cell><cell>0.027/0.019</cell></row><row><cell cols="4">use tic and toc commands in MATLAB to record the time</cell></row><row><cell cols="2">cost in seconds. Table</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. This work was supported in part by the National Basic Research Program of China 973 Program under Grant 2012CB316400, the National Natural Science Foundation of China under Grant 61125204, Grant 61172146, Grant 41031064, Grant 61125106, Grant 91120302, and Grant 61101250, the Natural Science Basic Research Plan in Shaanxi Province of China under Grant 2010JQ8026 and Grant 2011JM8008, and the Fundamental Research Funds for the Central Universities under Grant K50511030005. The associate editor coordinating the review of this manuscript and approving it for publication was Prof.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lossless data embedding-new paradigm in digital watermarking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goljan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Appl. Signal Process</title>
		<imprint>
			<biblScope unit="volume">2002</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="196" />
			<date type="published" when="2002-01">Jan. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A novel video watermarking scheme in compression domain based on fast motion estimation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf</title>
		<meeting>Int. Conf</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1878" to="1882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Watermarking in secure image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog. Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2431" to="2434" />
			<date type="published" when="2003-10">Oct. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Lossless generalized-LSB data embedding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tekalp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Saber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="253" to="266" />
			<date type="published" when="2005-02">Feb. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reversible watermarking using a difference expansion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="890" to="896" />
			<date type="published" when="2003-08">Aug. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High capacity reversible watermarking for audio</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Veen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bruekers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Leest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cavin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003-01">Jan. 2003</date>
			<biblScope unit="volume">5020</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lossless authentication of MPEG-2 video</title>
		<author>
			<persName><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fridrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Image Process</title>
		<meeting>IEEE Int. Conf. Image ess</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="893" to="896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Invertible authentication for 3-D-meshes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Benedens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003-01">Jan. 2003</date>
			<biblScope unit="volume">5020</biblScope>
			<biblScope unit="page" from="653" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust lossless data hiding: Analysis and evaluation</title>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. High Perform</title>
		<meeting>Int. Conf. High Perform</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="512" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Circular interpretation of histogram for reversible watermarking</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Vleeschouwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delaigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Multimedia Signal Process</title>
		<meeting>IEEE Workshop Multimedia Signal ess</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="345" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Circular interpretation of bijective transformations in lossless watermarking for media asset management</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">De</forename><surname>Vleeschouwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delaigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="105" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust lossless image data hiding designed for semi-fragile image authentication</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="497" to="509" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A semi-fragile lossless digital watermarking scheme based on integer wavelet transform</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1294" to="1300" />
			<date type="published" when="2006-10">Oct. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lossless data embedding using generalized statistical quantity histogram</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1061" to="1070" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vision Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vision Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Bayesian hierarchical model for learning natural scene categories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vision Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vision Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2005-06">Jun. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Descriptive visual words and visual phrases for image applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Multimedia</title>
		<meeting>ACM Int. Conf. Multimedia</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Local histogram based geometric invariant image watermarking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Process</title>
		<imprint>
			<date type="published" when="2010-12">Dec. 2010</date>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="3256" to="3264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Histogram modification based robust image watermarking approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Multimedia Intell. Secur</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="168" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reversible data hiding</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="354" to="362" />
			<date type="published" when="2006-03">Mar. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reversible watermarking based on statistical quantity histogram</title>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Multimedia Inf. Process</title>
		<meeting>Adv. Multimedia Inf. ess</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1300" to="1305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reversible data hiding based on histogram modification of pixel differences</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="906" to="910" />
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reversible image data hiding based on gradient adjusted prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fallahpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Electron. Exp</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="870" to="876" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhanced biologically inspired model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vision Pattern Recog</title>
		<meeting>IEEE Conf. Comput. Vision Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2008-06">Jun. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Biologically inspired feature manifold for scene classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="174" to="184" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust lossless data hiding using clustering and statistical quantity histogram</title>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Content-adaptive reliable robust lossless data embedding</title>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012-03">Mar. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Using perceptual models to improve fidelity and provide resistance to valumetric scaling for quantization index modulation watermarking</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Forens. Secur</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="139" />
			<date type="published" when="2007-06">Jun. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improved wavelet-based watermarking through pixel-wise masking</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bartolini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="783" to="791" />
			<date type="published" when="2001-05">May 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wavelet transforms that map integers to integers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sweldens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Comput. Harmon. Anal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="332" to="369" />
			<date type="published" when="1998-07">Jul. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimum histogram pair based image lossless data embedding</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Digit Watermark</title>
		<meeting>Digit Watermark</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="264" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The JPEG2000 still image coding system: An overview</title>
		<author>
			<persName><forename type="first">C</forename><surname>Christopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Skodras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Consumer Electron</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1103" to="1127" />
			<date type="published" when="2000-11">Nov. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reliable embedding for robust reversible watermarking</title>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Int. Conf. Internet Multimedia Comput. Service</title>
		<meeting>ACM Int. Conf. Internet Multimedia Comput. Service</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="467" to="476" />
			<date type="published" when="1995-12">Dec. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A new pixel-wise mask for watermarking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nafornita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Multimedia Secur. Workshop</title>
		<meeting>ACM Multimedia Secur. Workshop</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Secure spread spectrum watermarking for multimedia</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Leighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shamoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1673" to="1687" />
			<date type="published" when="1997-12">Dec. 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multiview spectral embedding</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B, Cybern</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1438" to="1446" />
			<date type="published" when="2010-12">Dec. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fast gradient clustering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS Workshop Discr</title>
		<meeting>NIPS Workshop Discr</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bovik</surname></persName>
		</author>
		<ptr target="http://live.ece.utexas.edu/research/quality/" />
		<title level="m">LIVE Image Quality Assessment Database</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Just noticeable difference for images with decomposition model for separating edge and textured regions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1648" to="1652" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image quality assessment based on multiscale geometric analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1409" to="1423" />
			<date type="published" when="2009-07">Jul. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Image Database</title>
		<author>
			<persName><surname>Cvg-Ugr</surname></persName>
		</author>
		<ptr target="http://decsai.ugr.es/cvg/dbimagenes/index.php" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<ptr target="http://pubimage.hcu-ge.ch:8080/" />
		<title level="m">DICOM Sample Image Sets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Reversibility improved lossless data hiding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Process</title>
		<imprint>
			<date type="published" when="2009-10">Oct. 2009</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="2053" to="2065" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A local Tchebichef moments-based robust image watermarking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Process</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1531" to="1539" />
			<date type="published" when="2009-08">Aug. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Geometric distortion insensitive image watermarking in affine covariant regions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. C, Appl. Rev</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="278" to="286" />
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Local feature based geometric-resistant image information hiding</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit. Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Joint learning for single-image super-resolution via a coupled constraint</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="469" to="480" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Her current research interests include lossless data hiding, machine learning, and visual cognition. Xinbo Gao (M&apos;02-SM&apos;07) was born in Shandong</title>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">He received the B.Sc., M.Sc., and Ph.D. degrees in signal and information processing from Xidian University</title>
		<meeting><address><addrLine>Xi&apos;an, China; China; Xi&apos;an, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1972">Sep. 2010. 2002 and 2005. 1972. 1994. 1997. 1999</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1537" to="1552" />
		</imprint>
	</monogr>
	<note>respectively, where she is currently pursuing the Ph.D. degree in intelligent information processing. respectively</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
