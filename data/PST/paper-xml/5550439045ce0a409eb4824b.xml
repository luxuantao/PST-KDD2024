<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-time detection of planar regions in unorganized point clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-01-09">January 9, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Frederico</forename><forename type="middle">A</forename><surname>Limberger</surname></persName>
							<email>falimberger@inf.ufrgs.br</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manuel</forename><forename type="middle">M</forename><surname>Oliveira</surname></persName>
							<email>oliveira@inf.ufrgs.br</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidade Federal do Rio Grande do Sul Instituto de Informática -PPGC</orgName>
								<orgName type="institution" key="instit2">-Porto Alegre -RS</orgName>
								<address>
									<postCode>15064, 91501-970</postCode>
									<region>CP</region>
									<country key="BR">BRAZIL</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-time detection of planar regions in unorganized point clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-01-09">January 9, 2015</date>
						</imprint>
					</monogr>
					<idno type="MD5">67303C6C707026510C38567EAF7F1A2C</idno>
					<idno type="DOI">10.1016/j.patcog.2014.12.020</idno>
					<note type="submission">Received date: 28 April 2014 Revised date: 15 November 2014 Accepted date: 23 December 2014 Preprint submitted to Pattern Recognition</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pattern Recognition Hough transform</term>
					<term>Real-time plane detection</term>
					<term>Unorganized point clouds</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic detection of planar regions in point clouds is an important step for many graphics, image processing, and computer vision applications. While laser scanners and digital photography have allowed us to capture increasingly larger datasets, previous techniques are computationally expensive, being unable to achieve real-time performance for datasets containing tens of thousands of points, even when detection is performed in a non-deterministic way. We present a deterministic technique for plane detection in unorganized point clouds whose cost is O(n log n) in the number of input samples. It is based on an efficient Hough-transform voting scheme and works by clustering approximately co-planar points and by casting votes for these clusters on a spherical accumulator using a trivariate Gaussian kernel. A comparison with competing techniques shows that our approach is considerably faster and scales significantly better than previous ones, being the first practical solution for deterministic plane detection in large unorganized point clouds.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automatic plane detection in point clouds is a key component in many graphics, image processing, and computer vision applications. These include, among others, model reconstruction for reverse engineering <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>, camera calibration <ref type="bibr" target="#b5">[6]</ref>, object recognition <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, augmented reality <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, and segmentation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. The recent popularization of laser scanners has led to an increasingly growth in the sizes of the available datasets, and point clouds containing tens of millions of samples are now commonplace. Software applications like SynthExport <ref type="bibr" target="#b12">[13]</ref> and Photosynth <ref type="bibr" target="#b13">[14]</ref> also allow us to extract point clouds from large collections of digital images. However, existing techniques for detecting planar regions in point clouds are computationally expensive and do not scale well with the size of the datasets. For performance improvement, they often exploit non-deterministic strategies, such as working on a randomly-selected sub-set of the original samples. While this can reduce execution time, these techniques are still unable to achieve real-time performance even on datasets containing just tens of thousands of points. More importantly, their results depend on the selected sample sub-sets and, therefore, there is no guarantee that all relevant planes will be detected, or that such results will be consistent across multiple executions.</p><p>We present an efficient technique to perform deterministic plane detection in unorganized point clouds whose cost is O(n log n) in the number of input samples. Our approach scales well with the size of the datasets, is robust to the presence of noise, and handles point clouds with different characteristics in terms of dimensions and sampling distributions. While the actual running times depend on specific features of the dataset (e.g., the number of planar regions), our technique is several orders of magnitude faster than previous ones. For instance, it processes an entire point cloud with 20-million samples (Bremen dataset) in just 2.1 seconds on a typical PC. In contrast, efficient versions of RANSAC can take from 12 minutes to more than 2 hours to process the same dataset, while the Randomized Hough transform takes 42.8 seconds to process only 10% of the samples.</p><p>Our technique is based on a robust and fast algorithm to segment point clouds into approximately planar patches, even in the presence of noise or irregularly distributed samples. For this, we use a subdivision procedure to refine an octree and cluster groups of approximately coplanar samples. We use the identified clusters to obtain an efficient Hough-transform voting scheme by casting votes for each of these clusters (instead of for individual samples) on a spherical accumulator. For voting, we use a Gaussian kernel centered at the cluster's best fitting plane, which takes into account the cluster's variances. In this sense, our approach extends the kernel-based voting scheme proposed by Fernandes and Oliveira <ref type="bibr" target="#b14">[15]</ref> using a trivariate Gaussian distribution defined over spherical coordinates (θ, φ, ρ). While, at first, plane detection in unorganized point clouds might seem as an immediate extension of line detection in images, the lack of explicit neighborhood information among samples imposes significant challenges, requiring new clustering and accumulation-management strategies. Fig. <ref type="figure" target="#fig_0">1</ref> shows an example of planar regions detected using our technique. The point cloud shown on the left consists of 179,744 samples obtained from a set of photographs taken inside a museum. The samples were extracted using SynthExport <ref type="bibr" target="#b12">[13]</ref> and Photosynth <ref type="bibr" target="#b13">[14]</ref>. The image on the right shows the planes detected by our technique in just 0.025 seconds on a 3.4 GHz PC, and illustrates the effectiveness of our approach.</p><p>The contributions of this paper include:</p><p>• An O(n log n) deterministic Hough-transform-based technique for detecting planar regions in unorganized point clouds (Section 3). Our solution is robust to noise, and to sampling distributions. It is a few orders of magnitude faster and scales significantly better than existing approaches. A software implementation of our technique handles datasets with up to 10 5 points in real time on a typical PC;</p><p>• A fast Hough-transform voting strategy for planar-region detection (Section 3.3). Our solution uses a robust segmentation strategy to identify clusters of approximately coplanar samples. Votes are cast for clusters as opposed to for individual samples, greatly accelerating the detection process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>The most popular techniques to detect planes in point clouds are the Hough transform, RANSAC, and region growing. This section discusses these algorithms and their various optimizations intended to accelerate plane detection in point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Hough Transform</head><p>The Hough transform (HT) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> is a feature-detection technique. For any given input sample, it casts a vote for each instance of the feature one wants to detect that could possibly contain that sample. The votes are accumulated over all samples, and the detected features correspond to the ones with most votes. The time and space complexity of the algorithm both depend on the discretization used for the accumulator, whose dimensionality varies with the number of parameters used to describe the features to be detected. For instance, plane detection requires a 3-D accumulator to represent the three parameters that characterize a plane.</p><p>The Hough transform was introduced by Paul Hough <ref type="bibr" target="#b15">[16]</ref> for the detection of lines in images. Today, the universally used version of the HT is the generalized Hough transform (GHT) proposed by Duda and Hart <ref type="bibr" target="#b16">[17]</ref>, which replaced the slope-intercept with an angle-radius parameterization based on the normal equation of the line (1):</p><formula xml:id="formula_0">ρ = x cos(θ) + y sin(θ).<label>(1)</label></formula><p>Here, x and y are the coordinates of a sample pixel, ρ is the distance from a line (passing through the pixel) to the origin of image's coordinate system, and θ is the angle between the normal of the line and the x-axis. This parameterization naturally extends to 3-D, supporting plane detection in the (θ, φ, ρ) Hough Space:</p><formula xml:id="formula_1">ρ = x cos(θ)sin(φ) + y sin(φ)sin(θ) + z cos(φ).<label>(2)</label></formula><p>In (2), x, y and z are the Cartesian coordinates of the samples, θ ∈ [0   ] are the polar coordinates of the plane's normal vector, and ρ ∈ R ≥0 is the distance from the plane to the origin of the coordinate system.</p><p>The Standard Hough transform (SHT) for plane detection uses (2) and iterates over each sample in the point cloud casting votes in the accumulator for all possible planes passing through that sample. More specifically, for given x, y and z coordinates, it iterates over all combinations of θ and φ, computing the value of the parameter ρ (2) and casting a vote at the corresponding accumulator cell (or bin). To make the computation feasible, one needs to discretize the θ and φ parameter values (defining angular steps). Thus, the computational cost of the SHT is O(|P |N θ N φ ), where |P | is the number of points in the point cloud P , and N θ and N φ are the number of bins in the discretization of the θ and φ angles, respectively.</p><p>Given the high computational cost of the SHT, many techniques have been proposed to accelerate its voting procedure. Common to most of these techniques is the focus on reducing the execution time by using a subset of the points in P , as opposed to designing new algorithms that effectively reduce the asymptotic cost of the voting process. Next, we briefly review these strategies.</p><p>The Probabilistic Hough transform (PHT) <ref type="bibr" target="#b17">[18]</ref> randomly selects m points (m &lt; |P |) and uses them, instead of the entire point cloud, for voting. Since m is a percentage of |P |, the asymptotic cost is still O(|P |N θ N φ ). The PHT needs to find an optimal value for m to achieve good results. Small values tend to cause some relevant planes not to be detected, while large values do not result in significant reduction in execution time. As opposed to the SHT, the PHT is not deterministic.</p><p>Finding the optimal value for m is not a simple task, as it depends on many characteristics of the point cloud. To overcome this difficulty, the Adaptive Probabilistic Hough transform (APHT) <ref type="bibr" target="#b18">[19]</ref> monitors the accumulator during the voting procedure. As stable structures emerge, they are stored in a list of potential maximum cells and only this list needs to be monitored. Since the process is adaptive, there is no need for an initial m value. The algorithm ends when the list of potential peaks becomes stable (i.e., when the list does not change for a few iterations). The APHT is sensitive to noise, as the choice of the points is probabilistic and may lead to the detection of planes not present in the dataset. Its asymptotic cost is the same as SHT's.</p><p>The Progressive Probabilistic Hough transform (PPHT) <ref type="bibr" target="#b19">[20]</ref> tries to avoid the influence of random noise by only detecting structures whose number of votes exceeds a threshold defined as a percentage of the total number of votes. Once a structure has been detected, the votes from all samples that support it are removed from the accumulator. Like the previous techniques, PPHT is non-deterministic and its asymptotic cost is the same as SHT's.</p><p>The Randomized Hough transform (RHT) <ref type="bibr" target="#b20">[21]</ref> reduces the SHT's votingprocessing time by exploiting the fact that a plane can be defined by three non-collinear points. The technique randomly selects groups of three noncollinear points and casts a single vote to the accumulator cell corresponding to the plane. This strategy significantly reduces the voting cost. However, the technique is non-deterministic and does not scale well with the size of the point cloud. Among all previous HT-based techniques for plane detection, the RHT is by far the fastest one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Other Hough Transform Variants</head><p>Vosselman et al. <ref type="bibr" target="#b21">[22]</ref> proposed a two-step procedure for the Hough transform, exploiting the connectivity of point clouds acquired with laser scanners to calculate the normal vectors of the points. This way, each sample casts a single vote. This approach is not as fast as the RHT, and its use with unorganized point clouds requires estimating surface normals. Bauer and Polthier <ref type="bibr" target="#b22">[23]</ref> use the Radon transform (continuous form of the HT) to detect planes on a structured or unstructured grid. They use a subdivided icosahedron, with a Hamiltonian path over the edge graph, to represent the parameter space in order to search for all connected components. This technique requires the use of a grid and its performance is similar to the SHT. More recently, Ogundana et al. <ref type="bibr" target="#b23">[24]</ref> used an optimized model for tridimensional sparse matrix to accumulate votes. They propose a robust peak detection algorithm using connected-component labeling and weighted average. Ogundana et al. also showed a Hough transform optimization specific to detect parallel planes, replacing the default accumulator by an unidimensional array, since the planes have the same orientation. Nguyen et al. <ref type="bibr" target="#b24">[25]</ref> estimate normals in range images and map such normals to a sphere (a Gauss map) to define plane orientations. Optimization is then used to segment patches of coplanar samples in the range image. The authors demonstrated their technique on simple box-like and polyhedral shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">RANSAC</head><p>Another important algorithm for performing shape detection is the Random Sample Consensus (RANSAC) <ref type="bibr" target="#b25">[26]</ref>. It performs plane detection iteratively by randomly choosing three points, calculating the plane defined by them, and counting how many points (in the dataset) lie on this plane within some tolerance threshold. The number of points found is called the score of the plane. The algorithm stops when it reaches stability, based on a low probability of finding a plane with higher score than the previous ones. RANSAC's computational cost for detecting a single plane is then given by (I (E + |P | F )) = O(I |P |), where I is the number of iterations required to detect a plane, E is the cost of estimating a plane from three points, and F is the cost of checking whether a point lies on a plane. While being robust to noise, RANSAC's random nature makes it non-deterministic. Depending on the choice of its parameter values, the algorithm may detect planes that are not representative of the original dataset. This is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref> for a point cloud corresponding to a cube. The dark gray plane was detected by RANSAC and is one of many planes that could be detected by the algorithm. Schnabel et al. <ref type="bibr" target="#b26">[27]</ref> introduced an optimization to RANSAC using an octree to establish spatial proximity among samples. In their approach, point selection is performed inside each node, and the score function only tests a local subset of the samples. Since spatial proximity does not guarantee coplanarity, the technique needs to estimate normals for the samples, and the shapes have to be properly sampled. While this approach can significantly accelerate RANSAC, it inherits RANSAC's limitations, and its performance is still far from real time for datasets with a few hundred thousand samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Surface Growing</head><p>The third class of techniques used to identify planes in point clouds is surface growing <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref> -the 3-D analogue of region growing in images. These techniques perform a local search to identify and expand regions with the same range of characteristics. Surface growing methods require information about the neighbors of each sample, not being directly applicable to unorganized point clouds, which lack explicit connectivity information.</p><p>Recently, Deschaud and Goulette <ref type="bibr" target="#b31">[32]</ref> proposed an algorithm to detect planes in unorganized point clouds using filtered normals and voxel growing. Their approach assigns a normal to each point through a normal-estimation procedure and uses a voxel-growing algorithm based on these normals. Like other surface-growing techniques, it is slow.</p><p>In contrast to the techniques described in this section, our approach is deterministic, does not require connectivity information nor information about sample normals, and its cost is O(n log n) in the number of samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Efficient Plane Detection in Point Clouds</head><p>This section presents the details of our technique. It has been inspired by the efficient Kernel-based Hough transform (KHT) for straight line detection introduced by Fernandes and Oliveira <ref type="bibr" target="#b14">[15]</ref>. However, when dealing with unorganized point clouds, the lack of explicit neighborhood information among samples (which is available for images) requires new and efficient clustering and accumulation-management strategies. In a nutshell, our technique performs a fast and robust octree-based segmentation of approximately coplanar clusters of samples. We then use the identified clusters to perform a Houghtransform voting procedure where votes are cast by clusters (as opposed to by individual samples) on a spherical accumulator. For voting, we use a trivariate Gaussian kernel defined over spherical coordinates (θ, φ, ρ) and centered at each cluster's best fitting plane. Peak detection is then performed on the resulting accumulator. Algorithm 1 summarizes the technique. q ← kernel(n) {kernel estimation (q stores the kernel parameters)}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>accumulator ← accumulator + voting(q) {voting} 5: end for 6: sort accumulator cells by voting importance in descending order 7: iterate over accumulator detecting cells not adjacent to already inspected ones {peak detection}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Clustering of Approximately Coplanar Samples</head><p>Clustering of approximately coplanar samples is key to our technique as it optimizes the voting procedure, which is the Hough transform's bottleneck. For unorganized point clouds, no neighborhood information among samples is available. For efficiency, we perform clustering by spatial subdivision. For this, we have compared the advantages of using kd-trees and octrees. Kdtrees provide little control over the dimensions of the nodes. According to our experience, subdividing the kd-tree cells using the centroid of the samples tends to lead to thin cells that do not capture the shapes of the planes in the dataset. In contrast, all nodes at a given level of an octree have 1/8 of the size of its parent node and better capture the structure of the planes. Moreover, the costs of creating and manipulating a kd-tree are higher than for an octree. For these reasons, we have chosen an octree as spatial-subdivision data structure. It has proven to be a good choice both in terms of efficiency and quality of the results.</p><p>The clustering procedure starts with a root node that includes the entire point cloud, which is then recursively subdivided to refine the octree. Except when the entire point cloud is just a plane, searching for planes in the initial level(s) of the octree often lends to less effective computations. Thus, the procedure only checks for approximate coplanarity among samples after a certain level of the octree has been reached, thus minimizing processing time. According to our experience, starting checking for approximately sample coplanarity at level 4 of the octree provides a good compromise between performance and robustness, and produces good segmentation in practice. The more detailed the point cloud, the more subdivisions are required, as nodes must be small enough to contain only approximately coplanar samples. If no further subdivision is required for an octree node, that branch stops and the node is stored as a cluster. If, on the other hand, the number of samples inside the octree node is smaller than a threshold, the node is marked as not containing a cluster (of approximately coplanar samples).</p><p>The procedure for clustering approximately coplanar samples is presented in Algorithm 2. It uses descriptive statistics to analyze the data and calculate the variances associated with the point-cloud distribution. For this, we use principal component analysis (PCA). call Clustering(c,s mp , s level , s α , s β ) {recursive call for node c} 19: end for Since the eigenvalues of the covariance matrix associated to the set of samples inside an octree node represent the proportions of the variances of the sample distribution inside that cell, they can be used to filter out clusters that could not represent planes. In order to check whether a set of Fig. <ref type="figure">3</ref>: Adaptive octree refinement and sample clustering for the Museum dataset using Algorithm 2. From left to right, top to bottom, the first five images show the 6th, 7th, 8th, 9th, and 10th levels of the octree. The image at the bottom right shows all nodes at different octree levels containing coplanar samples. Note that once a planar patch is found the subdivision stops for that branch. Each color represents one detected plane, whose reconstructions are shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>samples is approximately coplanar, two conditions are verified: the cluster thickness and its degree of isotropy (the technique should avoid detecting lines and thin elongated clusters as planes). Thus, let Λ and V represent, respectively, the eigenvalues and the eigenvectors of a cluster's covariance matrix Σ. These eigenvalues are non-negative and we sort them in ascending order so that λ i ≤ λ i+1 . A test for approximate sample coplanarity can be obtained by checking if (λ 2 &gt; s α λ 1 ) and (s β λ 2 &gt; λ 3 ), where s α and s β are scaling factors defining relative tolerances for the acceptable amount off-plane displacement (i.e., noise) and degree of sample anisotropy on the cluster. According to our experience, s α = 25 and s β = 6 produce good results and have been used for all examples shown in the paper. The recursive subdivision performed by Algorithm 2 stops when the current octree cell is considered to contain approximate coplanar samples (i.e., n coplanar = true, line 9) or the cell contains less than a minimum number of samples (s ms , in line 2). Small number of samples tend to provide less reliable estimates for the variances of the samples. In our experience, s ms = 30 provides a good threshold for large point clouds.</p><p>Once an octree cell is considered to contain an approximately coplanar sample cluster, least-squares is used for plane fitting <ref type="bibr" target="#b32">[33]</ref> after discarding samples at a distance bigger than τ /10 from the plane passing by the centroid of the cluster and whose normal is given by the eigenvector with smallest eigenvalue of Σ. τ is the current octree-node edge length.</p><p>Fig. <ref type="figure">3</ref> illustrates the adaptive octree refinement and sample clustering for the Museum dataset using Algorithm 2. From left to right, top to bottom, the first five images show the 6th, 7th, 8th, 9th, and 10th levels of the octree, respectively. The image at the bottom right shows the octree nodes containing approximately coplanar samples. Note that these nodes might be at different levels of the octree. A single color has been assigned to each plane, even when it spans different levels of the octree. This is possible by keeping track of the clusters who voted for the individual planes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Computing Gaussian Trivariate Kernels for Cluster Voting</head><p>Let K be a cluster of approximately coplanar samples stored in an octree node, with covariance matrix Σ, and centroid µ = (µ x , µ y , µ z ) T (Fig. <ref type="figure">4</ref>). Also let V = { v 1 , v 2 , v 3 } be the unit eigenvectors of Σ and let Λ = {λ 1 , λ 2 , λ 3 } be their respective eigenvalues, so that λ i ≤ λ i+1 . The equation of the plane π passing though µ and with normal n = v 1 = (n x , n y , n z ) T is given by:</p><formula xml:id="formula_2">Ax + By + Cz + D = n x x + n y y + n z z -(n x µ x + n y µ y + n z µ z ) = 0 (3)</formula><p>Using <ref type="bibr" target="#b1">(2)</ref>, one can rewrite (3) using spherical coordinates as:</p><formula xml:id="formula_3">ρ = -D = µ x n x + µ y n y + µ z n z = p 2 x + p 2 y + p 2 z , θ = arctan p y p x , φ = arccos p z ρ ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_4">ρ ∈ R ≥0 , θ ∈ [0 • , 360 • ), φ ∈ [0 • , 180 • ] and p = (p x , p y , p z ) T = ρ n.</formula><p>For θ calculation, When voting in an accumulator indexed by (θ, φ, ρ), the vote distribution is based on the uncertainties associated with each cluster's bestfitting plane π (i.e., the cluster's variances σ 2 φ , σ 2 θ , and σ 2 ρ ). A cluster with small variances concentrates its votes in a small region of the accumulator, while a cluster with large variances spreads its votes over a large region, like in the KHT <ref type="bibr" target="#b14">[15]</ref>.</p><formula xml:id="formula_5">λ 1 v 1 λ 2 v 2 λ 3 v 3 μ</formula><p>Fig. <ref type="figure">4</ref>: Samples approximating a planar region in a point cloud, shown with its best-fitting plane (left). Eigenvectors of the covariance matrix Σ associated to the sample distribution (center). Ellipsoid defined by the eigenvalues and eigenvectors of Σ (right).</p><p>Algorithm 3 Computing Σ (θ,φ,ρ) and the Gaussian kernel voting threshold Require: Σ (x,y,z) {covariance matrix with respect to x, y and z coordinates} The variances and covariances defined in the (θ, φ, ρ) space can be estimated from the covariance matrix Σ (x,y,z) defined in Euclidean space, using first-order uncertainty propagation analysis <ref type="bibr" target="#b33">[34]</ref> as:</p><formula xml:id="formula_6">1: J ← Jacobian() {defined in (6)} 2: Σ (θ,φ,ρ) ← J Σ (x,y,z) J T {cov. matrix in (θ, σ, ρ) space from Σ (x,y,z) } 3: σ 2 ρ ← σ 2 ρ + ε {add a small value to avoid zero variance} 4: (V θφρ , Λ θφρ ) ← eigen(Σ (θ,φ,ρ) ) {eigen-decomposition of Σ (θ,φ,ρ) } 5: λ θφρ min ← smallestEigenvalueIn(Λ θφρ ) {smallest</formula><formula xml:id="formula_7">Σ (θ,φ,ρ) =   σ 2 ρ σ ρφ σ ρθ σ ρφ σ 2 φ σ φθ σ ρθ σ φθ σ 2 θ   = JΣ (x,y,z) J T = J   σ 2 x σ xy σ xz σ xy σ 2 y σ yz σ xz σ yz σ 2 z   J T , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where J is the Jacobian matrix: </p><formula xml:id="formula_9">   =   n x n y n z pxpz √ wρ 2 pypz √ wρ 2 - √ w ρ 2 -py w px w 0   .<label>(6)</label></formula><p>(p x , p y , p z ) are defined in (4), n = (n x , n y , n z ) T , and w = p 2 x + p 2 y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Cluster Voting using 3-D Gaussian Distributions</head><p>Once we have computed the variances and covariances associated with θ, φ and ρ (Σ (θ,φ,ρ) ), the votes are cast in the spherical accumulator using a trivariate Gaussian distribution. For the multivariate non-degenerate case, i.e., when the covariance matrix Σ is symmetric and positive definite, its probability density function is given by <ref type="bibr" target="#b34">[35]</ref> </p><formula xml:id="formula_10">p(x|µ, Σ) = 1 (2π) k/2 |Σ| 1/2 exp - 1 2 (x -µ) t Σ -1 (x -µ) ,<label>(7)</label></formula><p>where |Σ| is the determinant of Σ. Considering the trivariate case (i.e., k = 3), letting δ = x -µ be the displacement with respect to the center, and since the votes are already centered at the best-fitting parameters (θ, φ, ρ), this equation can be rewritten as</p><formula xml:id="formula_11">p( δ, Σ) = 1 15.7496 |Σ| 1/2 exp - 1 2 δ t Σ -1 δ .<label>(8)</label></formula><p>Casting votes for a given accumulator cell requires two matrix-vector multiplications and one exponentiation, since the determinant of the covariance matrix and its inverse need to be calculated only once per cluster. While the values of σ 2 θ and σ 2 φ are never zero, the value of σ 2 ρ will be zero if all samples in the cluster are exactly coplanar. In such a case, Σ (θ,φ,ρ) becomes singular, and voting should be done using a bivariate Gaussian kernel defined over (θ, φ). We avoid the need to handle such a special case by adding a small value ε to σ 2 ρ (e.g., ε = 0.001, see line 3 in Algorithm 3). Thus, voting can always use a trivariate Gaussian kernel, without affecting the results.</p><p>As planes become more horizontal (i.e., when φ approaches 0 or 180 degrees) the variance relative to θ tend to become large, since at the poles the parameter θ does not affect the orientation of a plane. As a result, the amount of votes in individual accumulator cells near the poles tend to be smaller than in voted cells in other regions of the accumulator. Although this does not affect the correct detection of peaks around the poles, sorting the detected planes taking into account only the amount of votes would lead to always finding vertical planes before horizontal ones.</p><p>When estimating the importance of a cluster (and consequently the importance of its votes), one should consider other properties besides its number of samples. Aspects, such as area coverage should be given greater importance as sampling density varies with object distance to the scanner. Thus, we weight votes from a cluster by the relative size of its octree node with respect to the size of the octree root (in our system, all octree cells, including the root, are cubic cells). Votes are then weighted using</p><formula xml:id="formula_12">w cluster(i) = w a node size octree size + w d |C i | |P | ,<label>(9)</label></formula><p>where node size and octree size are, respectively, the edge length of the octree node containing the cluster and the edge length of the root node. |C i | is the number of samples in the cluster i and |P | is the total number of samples in the point cloud. w a and w d are the weights associated with relative area and relative number of samples, such that w a + w d = 1. According to our experience, spatial coverage should be favored over number of samples. While we have used w a = 0.75 and w d = 0.25 in all examples shown in the paper, even w a = 1 and w d = 0 produce good results in practice.</p><p>The voting procedure uses a spherical accumulator indexed by (θ, φ, ρ), which is described in Section 3.4. Starting at the center of the 3-D Gaussian kernel representing the position, orientation, and uncertainties of the bestfitting plane for a given cluster, the voting procedure iterates away from the kernel's center up to two standard deviations storing votes in the accumulator's cells. This provides a 95.4% assurance that the selected region of the parameter space receiving votes covers the true plane. Sampling is performed in the accumulator at steps of ∆θ, ∆φ and ∆ρ. The number of votes that a cluster casts in a given accumulator cell a is obtained by multiplying the weight of the cluster's vote (9) by the evaluation of (8) for the cell's (θ a , φ a , ρ a ) parameter values (i.e., for δ = (θ a , φ a , ρ a ) -(µ θ , µ φ , µ ρ )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">The Spherical Accumulator</head><p>While a 2-D array provides a good accumulator for the detection of lines in images, Borrmann et al. <ref type="bibr" target="#b35">[36]</ref> have demonstrated that the use of a 3-D accumulator array for plane detection may compromise the result of the HT. They have shown that since polar regions must have fewer cells than equatorial regions, the use of a full 3-D array may result in cells improperly receiving less votes than others. To overcome this problem, Borrmann et al. have proposed a spherical accumulator called the accumulator ball, whose illustration is provided in Fig. <ref type="figure" target="#fig_5">5</ref>.</p><p>While Borrmann et al. cast votes in a conventional way (i.e., they cast one vote for each possible plane passing through each sample in 3-D), we vote for each entire cluster at once. Thus, we also need to cast votes for cells adjacent to the one that represents the cluster's best-fitting plane. This is required to account for the uncertainty resulting from the variances in the cluster's sample positions. We use Borrmann et al.'s spherical accumulator, but normalize the azimuthal angle θ ∈ [0 • , 360 • ) to [0, 1), as its discretization varies with the elevation angle φ (see Fig. <ref type="figure" target="#fig_5">5</ref>). For any value of φ, the θ index for actually accessing the spherical accumulator is obtained as θ index = round(θ nc(φ)), where nc(φ) is the number of accumulator cells for the elevation angle φ: nc(φ) = 2 × length(φ vector ) × sin(φ). At the poles, we set nc(φ) = 1.</p><p>For identifying adjacent cells, θ index must be incremented/decremented using modular arithmetic. The φ index must be between 0 and the size of the array (φ max ), which varies with the accumulator discretization. If incrementing/decrementing φ index should exceed its lower or upper bounds, the sign of its increment is reversed to guarantee the wrapping around the sphere. Finally, ρ index must be between 0 and ρ max , which depends on the point cloud size. If ρ index exceeds the limit of ρ max , the voting process stops; if, however, it assumes a negative value, θ index and φ index are recalculated for angles θ and φ in the opposite sense along the same direction.</p><p>Votes in a HT 3-D accumulator tend to be sparsely distributed. Thus, during initialization, we only allocate space for the angular discretization of θ and φ. The third dimension (ρ) is allocated as needed during the voting procedure. Therefore, if a range of ρ values are only required around certain values of θ and φ, they will only be allocated there. This strategy lends to considerable memory savings, allowing such memory to be used towards better angular discretization, resulting in more accurate detections. Fig. <ref type="figure" target="#fig_3">6</ref> illustrates the data structures used for implementing the spherical accumulator: a 1-D array with size φ max represents the discretization of the elevation angle φ. Each element of this array contains a pointer to another 1-D array representing the discretization of the azimuthal angle (θ) at that specific el-evation. In turn, each element of a θ array stores a pointer to yet another 1-D ρ array that stores the number of votes cast to cells indexed by (θ, φ, ρ). Note that the arrays at this last level are only allocated if necessary. θ ρ Φ Fig. <ref type="figure" target="#fig_3">6</ref>: The spherical accumulator and its representation in memory (the bottom half is just indicated). The angular discretization (θ, φ) behaves like a sphere. The indexing of the azimuthal angle (θ) uses modular arithmetic (i.e., it wraps around). Each (θ, φ) cell has a points to a vector (allocated as needed during the voting process) storing the actual votes associated with the distances from the origin (ρ), thus covering all possible orientations and positions.</p><p>The accumulator discretization can be adjusted by choosing the number of φ cells, since the number of θ cells is automatically calculated to represent the same proportion of the arc length discretization. The number of cells used for radial discretization (ρ) is adjusted according to size of the point cloud to emphasize either performance or precision.</p><p>Accumulator structures used for HT store a discrete number of votes, which is true even for the KHT <ref type="bibr" target="#b14">[15]</ref>. In our solution, a vote represents a plane and the uncertainty associated to its exact location and orientation. Thus, our accumulator uses floats instead of integers to reduce the influence of rounding errors. This improves the accuracy of our solution allowing the accumulation of fractional votes, at the expense of a small increment (approximately 4%) in the execution time. Since our solution already achieves real-time performance for relatively large datasets, this additional cost is not perceived by the users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Peak Detection</head><p>The last stage of a Hough-transform consists of detecting peaks of votes in the accumulator. We optimize this process by using a 1-D auxiliary array (AA) to store the (θ,φ,ρ) coordinates of accumulator cells as they receive votes for the first time during the voting procedure. Only cells in this array need to be inspected for peak detection. As demonstrated in the KHT <ref type="bibr" target="#b14">[15]</ref>, low-pass filtering the accumulator smooths the voting map, consolidating adjacent peaks. Therefore, before peak detection is actually performed, we apply a low-pass filter to the accumulator cells whose indices have been stored in AA. For this, we use a 3-D isotropic kernel comprised of seven cells (the central one and its six-connected neighborhood in 3-D). This topology was used to handle the discretization of the accumulator, which has a singularity at the poles. The filtered results are stored in the corresponding cells of AA, thus avoiding the need for an extra copy of the accumulator. The kernel weights should satisfy w c , w n &gt; 0, w c + 6w n = 1, and w c ≥ w n , where w c and w n are the weights of the central and neighbor cells, respectively. Although various combinations of w c and w n values produce good results in practice, according to our experience the use of w c = 0.2 and w n = 0.133 seem to provide the best compromise between peak consolidation and smoothness.</p><p>For peak detection, the cells in AA are sorted in decreasing order with respect to the stored filtered values. Iterating over this sorted array, the algorithm inspects each peak candidate and checks if the corresponding accumulator cell has already been visited. If not, the cell is chosen as a peak and its (up to) 26 neighbors are tagged as visited. If the cell has already been visited, their neighbors are also tagged as visited. This procedure guarantees that only true peaks will be selected to represent the output planes.</p><p>The number of votes cast by a plane on the cells of a spherical accumulator decreases as one moves from the equator to the poles. This is illustrated in Fig. <ref type="figure" target="#fig_6">7(a)</ref>, which compares the distribution of votes cast by a cluster as it is rotated around the origin. The color scale indicates the number of cast votes, while the thumbnail image on its right shows the best fitting planes corresponding to the rotated cluster. Note that the number of votes cast on cells around the poles are significantly smaller than the ones near the equator. Figs. <ref type="figure" target="#fig_6">7(b</ref>) and 7(c) illustrate this behavior, for a fixed value of the parameter ρ. Fig. <ref type="figure" target="#fig_6">7(b)</ref> shows two versions of the rotated point cloud: one near the equator and the other near the north pole. The noise in the point cloud lends to some uncertainty on the plane's orientation, which is represented by a cone of normals around the normal of the best-fitting plane (shown in red). On the equator, such uncertainty causes some votes to be cast in a small θ and φ neighborhood around the (θ, φ, ρ) coordinates of the best fitting plane. There, equal angular steps in θ and in φ correspond to arc lengths of equal sizes, resulting in an isotropic Gaussian kernel in the (θ, φ) subspace. Such a Gaussian is illustrated on the top portion of Fig. <ref type="figure" target="#fig_6">7(c</ref>). Near a pole, on the other hand, the uncertainty on the plane's normal lends to a small uncertainty in the parameter φ, but to a huge uncertainty in the parameter θ, as at the pole the value of θ varies from 0 to 360 degrees. This results in a highly anisotropic Gaussian kernel in the (θ, φ) subspace, as shown by the truncated kernel at the bottom of Fig. <ref type="figure" target="#fig_6">7(c</ref>). This wider and lower Gaussian covers a large θ neighborhood, but the voting procedure constrains voting to values of at least g min . g min is obtained by evaluating Eq. 8 for δ = 2 × std dev × V θφρ min (see line 8 of Algorithm 3). This explains the smaller number of votes per cell as a cluster approaches a pole. Let C 1 and C 2 be two clusters with the same number of samples and same variances, C 1 located near the equator, and C 2 near a pole. Considering only the number of votes, C 1 would always be detected earlier, as its peak is higher than C 2 's. To retrieve the detected planes based on how representative they are for a scene, as opposed to just on the heights of their associated peaks, the list of detected planes is sorted based on the sum of the weights (9) of all clusters that voted for each plane π i :</p><formula xml:id="formula_13">w sum (π i ) = voted f or π i w cluster .<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Algorithm Complexity</head><p>The overall steps of our plane-detection technique can be summarized in Algorithm 4. The cost of constructing an octree for a set of |P | samples is O(|P | log 8 |P |). Checking whether a cluster C i with |C i | samples (inside an octree node) is approximately coplanar requires computing its covariance matrix Σ (x,y,z) and comparing its eigenvalues (lines 7 and 8 in Algorithm 2). These operations are performed in time O(|C i |). Since this operation is used to decide if a node needs to be subdivided, it has to be performed in all nodes of the octree, resulting in a total cost of O(|P | log 8 |P |). Transforming Σ (x,y,z) to the (θ, φ, ρ) space requires computing a Jacobian matrix and multiplying three 3×3 matrices (see 5 and 6), which has cost O(1). Computing the eigenvalues of Σ (θ,φ,ρ) costs O(1). These operations (lines 5 and 6 in Algorithm 4) are executed once per cluster, whose number is bounded by O(|P |). Each cluster C i casts votes over a total v C i cells. Note that since in a spherical accumulator each cell represents a (set of) plane orientation(s), each cluster only votes for a relatively small number of cells. Thus, typical numbers for v C i vary from 20 to 50, depending on the distribution of samples in the cluster, and on the resolution of the accumulator. Let B be the total number of accumulator bins that received some votes. . By restricting the maximum number of levels of the octree, one also restricts the number of clusters, making the time complexity linear in the number of samples: O(|P |). While this could accelerate the process, it may make it harder to detect small (approximately) planar patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Space Complexity</head><p>The amount of memory required by our 3-D Kernel-based Hough transform (3-D KHT) consists basically of the octree (used to store point-cloud samples and indexes), the voting map, the 1-D auxiliary array (AA), and the trivariate kernels. Except for the root, which stores the samples, each octree node only stores (integer) indexes for the sample array. Since each sample stores its (x, y, z) coordinates as doubles, the memory required for the octree is given by 3 × 8 × |P | bytes for the samples themselves, and 4 × |P | (log 8 |P | -1) bytes for the remainder of the octree. The voting map, in turn, depends on the discretization of the Hough space (θ, φ, ρ) and on how if cluster is approximately co-planar then 5:</p><p>Transform covariance matrix Σ (x,y,z) to (θ, φ, ρ) space; {O(1)}</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Compute eigenvalues of Σ (θ,φ,ρ) ; {O(1)} 7:</p><p>Cast cluster votes and update the auxiliary array (AA); {O(1)}  Each AA cell stores one double and two shorts for the indexes for θ, φ, and ρ, respectively, and one float for the filtered peak value. Finally, a trivariate kernel stores a 3 × 3 covariance matrix and the (θ, φ, ρ) Hough coordinates of the best fitting plane, resulting in 12 doubles per cluster. While voting could be performed in parallel on-the-fly as we reach the octree leaf nodes, we have not implemented concurrency control mechanisms for accessing the accumulator, and voting is performed in a serial fashion (see <ref type="bibr">Algorithm 4)</ref>. The space complexity of the algorithm is then O(|P | log 8 |P |). Similarly to time complexity, restricting the maximum level of the octree would make the space complexity linear in the number of samples: O(|P |).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>We have implemented our technique in C++, using OpenMP to parallelize the octree generation, and dlib <ref type="bibr" target="#b36">[37]</ref> to compute eigenvalue decompositions. We used OpenGL to render the detected planes. We have used this implementation to automatically detect planes in a large number of unorganized point clouds, and compared its performance against the state-of-the-art approaches: the Randomized Hough transform (RHT) and two efficient ver-sions of RANSAC. Since surface-growing techniques are not as fast as RHT and RANSAC, and require information about neighbor samples (see Section 2.3), they were not included in our performance comparisons.</p><p>To evaluate the accuracy of our approach, we created a point cloud (Box) by sampling the faces of a cube centered at the origin and with a side of 400 units. Each face of the cube contains 160,801 samples, to which we added 2.5% of uniformly-distributed noise (i.e., using a uniform distribution of noise values ranging from 0 to 2.5% of the side of octree root node). This point cloud is shown in Fig. <ref type="figure" target="#fig_10">8</ref>(a) and was also used for the RANSAC experiment shown in Fig. <ref type="figure" target="#fig_1">2</ref>. An unfolded slice of the spherical accumulator displaying the six peaks detected by our technique is shown in Fig. <ref type="figure" target="#fig_10">8(b</ref>). Four of these peaks are equally distributed on the central line (equator) of the accumulator, while gray indicates zero votes. Such peaks correspond to the lateral faces of the cube. The two additional peaks are at the poles (shown as the blue lines on top and at the bottom of the gray region), and correspond to the top and bottom faces of the cube. The detected planes are shown in Fig. <ref type="figure" target="#fig_10">8(c</ref>). Note that only six planes were found as our trivariate Gaussian kernel naturally handles the noise in the dataset. We have also rotated the point cloud by arbitrary amounts and around arbitrary axes and verified that our technique accurately detected the six planes in all cases (Fig. <ref type="figure" target="#fig_10">8(d)</ref>).</p><p>To evaluate the robustness of our technique to missing samples and noise, we downsampled a noiseless version of the Box dataset to 48,000 points and added 1% of Gaussian noise (i.e., using a normal distribution with σ = 1% of the side of octree root node). For this experiment, each face of the cube corresponds to three discontinuous stripes of samples covering approximately 60% of its original area. The resulting point cloud is illustrated in Fig. <ref type="figure" target="#fig_10">8(e)</ref> with six colored squares representing the most important detected planes. As in the previous experiment, the point cloud was rotated by arbitrary amounts around arbitrary axes, consistently producing the same results.</p><p>For performance comparisons, we used the optimized RANSAC technique (and code) of Schnabel et al. <ref type="bibr" target="#b26">[27]</ref>, and the RANSAC implementation for plane detection in point clouds available in the Point Cloud Library (PCL) v1.7 <ref type="bibr" target="#b37">[38]</ref>, a modern C++ library for 3-D point-cloud processing. For RHT, we used the implementation by Borrmann et al. <ref type="bibr" target="#b35">[36]</ref>. These implementations proved to be the most efficient ones for plane detection using RANSAC and RHT, respectively. All experiments were performed on an Intel i7-2600 3.4 GHz CPU with 16 GB of RAM. The codes for the four compared techniques were compiled for 64 bits to exploit the full potential of the hardware. Fig. 9 shows the datasets used for performance comparisons. On the right, it also shows the most representative planes detected by our approach (for the more complex examples, some planes are not shown to avoid cluttering the images). These datasets include a computer desk (Computer ), a room (Room), a set of façades from a city block (Utrecht), the interior of a museum (Museum), and façades of some buildings in the city of Bremen (Bremen). The Computer dataset is from <ref type="bibr" target="#b35">[36]</ref>. The other point clouds were extracted from sets of photographs using SynthExport <ref type="bibr" target="#b12">[13]</ref> and Photosynth <ref type="bibr" target="#b13">[14]</ref>. They were chosen because they span a large range of parameters, varying in number of points, sampling rate, occupied volume, and number of detectable planes. Table <ref type="table" target="#tab_5">1</ref> presents detailed information about the experiments performed with our technique on each dataset. These times were computed by averaging the results of 50 executions. It shows that our approach processes the Computer dataset with its 68K samples in approximately 22 milliseconds, and the Museum dataset, which contains 179K samples, in 25 milliseconds. For larger point clouds (e.g., Bremen, with 20 million samples) the octree creation (column 6) dominates the time of 3-D KHT. Still, our technique processes the Bremen dataset 353 faster than Schnabel et al.'s RANSAC technique <ref type="bibr" target="#b26">[27]</ref>, and 3,586 times faster than PCL's RANSAC <ref type="bibr" target="#b37">[38]</ref>. The available implementation of the RHT could not handle the entire dataset. Working on the full dataset, our technique is still 20 times faster than the RHT working on a subset containing only 10% of the original samples (Table <ref type="table" target="#tab_6">2</ref>). Table <ref type="table" target="#tab_5">1</ref> also shows that even though the octree might segment large coplanar structures into several clusters, such clusters vote for the same regions in the accumulator, resulting in the detection of the right planes. In our experiments, all datasets were processed in their original scales. Table <ref type="table" target="#tab_6">2</ref> compares the performance of our technique to RHT and RANSAC. These results show that our approach is one to four orders of magnitude faster than the competing ones. Although RHT and RANSAC are relatively fast on small datasets containing low noise and just a few planar structures (e.g., Computer ), they are not as efficient on bigger and noisier datasets (e.g., Bremen). Our approach can efficiently handle both large and noisy datasets.  <ref type="table" target="#tab_5">1</ref>. The detected planes were resized for better visualization. For all datasets, the accumulator discretization was obtained using φ max = 30 and ρ max = 300. The threshold s ms was set to 30. s level was chosen for each point cloud as 2, 4, 5, 6 and 7 (top to bottom), as at these levels the ratio between the sizes of the octree cells and the sizes of the planar patches inside them is approximately constant, which lends to good detection accuracy. These levels can be detected automatically by checking the sample variances of the detected planes.</p><p>While 3-D KHT and RANSAC use the same number of parameters (less than RHT), the 3-D KHT is less dependent on them. This is because our approach performs adaptive clustering based on relative measurements of the samples' variances, instead of using specific thresholds. Since the running times of the these algorithms are affected by the selected parameters, we chose values that optimize the execution times of each individual algorithm. Fig. <ref type="figure" target="#fig_12">10</ref> compares the planes detected by the three techniques on two datasets. The results are similar, but our technique is significantly faster (Table <ref type="table" target="#tab_6">2</ref>).</p><p>Rotating the input point cloud may result in a different sample distribution in the octree cells. This, however, should have no impact in the detection of large planes. The detection of small planar patches requires a minimum number of samples in a cell (i.e., s ms ), and might be affected positively or negatively by the rotation (similar to the original point cloud case). Limitations: Like in all other Hough-transform techniques for plane detection, the position and orientation of the detected planes is constrained by the accumulator discretization. This can be improved by refitting the detected planes using only the inlier samples. If the amount of noise inside the octree nodes is considerably high, our approach might not be able to detect a plane there. This would be a restriction for all techniques, Also, if the samples in an octree node are left-overs from its neighbors, our technique may fit a spurious plane through these samples. However, according to our experience, starting the approximate-coplanarity check after the third level of the octree subdivision tends to avoid this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>We have presented an O(n log n) Hough-transform technique to perform deterministic plane detection in unorganized point clouds. Our approach uses a fast and robust algorithm to segment clusters of approximately coplanar samples, and casts votes for individual clusters, instead of for individual samples, on a spherical accumulator. For this, we use a trivariate Gaussian kernel that models the uncertainty about the position and orientation of the plane represented by the cluster.</p><p>While previous approaches for plane detection have basically resorted to randomly selecting a subset of the samples as a way to reduce execution time, we have undertaken the more fundamental strategy of designing an efficient algorithm with lower asymptotic cost.</p><p>Probabilistic approaches are good at finding the first few best planes. However, as the points that lie on these planes are removed, the amount of noise relative to the number of left samples tend to increase. Thus, the odds of finding additional relevant planes in the resulting point cloud tend to decrease. In contrast, our approach scans the entire point cloud without removing partial information, thus keeping the inliners/outliers ratio constant.</p><p>Our experiments have shown that our approach is several orders of magnitude faster than existing (non-deterministic) techniques for plane detection in point clouds, such as RHT and RANSAC, and scales better with the size of the datasets. It is also robust to noise and to irregularly-distributed samples. As such, it has the potential to enable a new range of applications that require fast detection of planar features on large datasets.</p><p>Our approach can be further optimized using a more efficient subdivision procedure. The use of concurrency control mechanisms for accessing the accumulator would allow voting to be performed in parallel.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Example of plane detection using our technique. (left) Museum dataset: point cloud consisting of 179,744 samples obtained from a set of photographs using SynthExport and Photosynth. (right) Planes automatically detected by our technique in just 0.025 seconds on a 3.4 GHz PC. They were manually resized to better represent the original model.</figDesc><graphic coords="4,118.92,269.51,184.24,82.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: A point cloud representing the faces of a cube, shown in color. Depending on the used parameters, RANSAC may detected spurious planes, such as the one shown in dark gray, that do not represent the original dataset.</figDesc><graphic coords="8,248.43,298.49,113.37,76.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Plane Detection (3-D KHT) Algorithm Require: P {point cloud} 1: nodes ← Clustering(P ) {cluster approximately coplanar samples} 2: for each n in nodes do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>eigenvalue} 6 :</head><label>6</label><figDesc>V θφρ min ← Eigenvector(λ θφρ min ) {normalized eigenvector of λ θφρ min } 7: std dev ← sqrt(λ θφρ min ) {standard deviation} 8: g min = Gaussian(2 × std dev × V θφρ min ) {threshold value for voting}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: A discrete representation of the 3-D spherical accumulator, showing the individual cells for a given value of the parameter ρ. The colors represent normal directions. The coordinate axes on the right indicate directions of the normal vector components.</figDesc><graphic coords="17,253.66,127.24,59.77,59.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Fig.7: The number of votes cast by a cluster as it is rotated varies with the position on the spherical accumulator (a). The color scale indicates the number of votes, while the thumbnail image on its right shows the best-fitting planes corresponding to the rotated clusters. (b) On the equator, the uncertainty on the plane orientation lends to votes on a small isotropic neighborhood in the (θ, φ) subspace. At (next to) a pole, the same uncertainty on the plane orientation lends to a small uncertainty in the φ dimension, but to a big uncertainty in the θ dimension, as θ can range from 0 to 360 degrees. (c) isotropic (top) and truncated anisotropic (bottom) Gaussian kernels in the (θ, φ) subspace associated to the cluster near the equator and near the pole, respectively.</figDesc><graphic coords="20,110.85,125.80,96.16,91.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Since there are O(|P |) clusters and each cluster votes for a finite number of cells, B = O(|P |). Filtering any given accumulator cell is performed in O(1) time, for a total cost of O(|P |). Sorting the B voted cells is accomplished in O(|P | log |P |), and peak detection has cost O(|P |). Thus, the overall time complexity of the algorithm is O(|P | log |P |)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 4 1 : 3 :</head><label>413</label><figDesc>Algorithm Summary and Asymptotic Cost Require: P {point cloud} Octree generation; {O(|P | log 8 |P |)} 2: for each octree node do Compute cluster covariance matrix Σ (x,y,z) ; {O(|C i |)} 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Filter accumulator cells pointed by AA, storing result in AA; {O(|P |)} 11: Sort AA; {O(|P | log |P |)} 12: Iterate over sorted AA detecting peaks; {O(|P |)} many cells receive votes (only voted cells are allocated in memory). Each accumulator cell consists of one float for storing its votes, and one boolean to indicate if it has already been inspected by the peak-detection procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Box dataset. (a) A point cloud representing a cube centered at the origin. Each face consists of 160,801 points with 2.5% of uniformly-distributed noise. (b) A 3-D visualization of an unfolded slice of the accumulator representing all pairs (θ, φ) for one value of ρ after the voting procedure. There are six detected peaks: four equally distributed on the gray region represent the lateral faces of the cube, plus two at the poles (shown as the blue lines) corresponding to the top and bottom faces. (c) Reconstructed planes from the peaks detected by our approach. (d) Detected planes (with random colors) after rotating the point cloud by 20, 40, 60 and 80 degrees around the x-axis. (e) Downsampled version of the cube, where each face is covered by three stripes of samples covering approximately 60% of its original area. The squares indicate the detected planes.</figDesc><graphic coords="24,429.46,125.80,69.93,66.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Datasets used for performance comparison. Point clouds (left) and the most representative planes detected by our technique (right). From top to bottom, the datasets are: Computer (from<ref type="bibr" target="#b35">[36]</ref>), Room, Utrecht, Museum, and Bremen. Their numbers of samples are shown in Table1. The detected planes were resized for better visualization. For all datasets, the accumulator discretization was obtained using φ max = 30 and ρ max = 300. The threshold s ms was set to 30. s level was chosen for each point cloud as 2, 4, 5, 6 and 7 (top to bottom), as at these levels the ratio between the sizes of the octree cells and the sizes of the planar patches inside them is approximately constant, which lends to good detection accuracy. These levels can be detected automatically by checking the sample variances of the detected planes.</figDesc><graphic coords="26,178.84,352.55,124.34,64.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: Plane detection for two datasets using our technique (top), RHT (middle), and RANSAC (bottom). The results are similar, but our technique is significantly faster.</figDesc><graphic coords="27,184.67,333.60,174.83,56.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Algorithm 2 Clustering Require: n {current node of the octree } s {settings to cluster data: s mp , s level , s α , s β } Symbols n samples {samples in the current octree node } n level {level of the current octree node} n coplanar {are the samples in current node approximately coplanar?} n children {children of the current octree node} s ms {minimum number of samples required in a cluster} s level {first octree level for checking for approximate coplanarity} s α {relative tolerance associated with plane thickness } s β {relative tolerance associated with plane isotropy } 1: n coplanar ← f alse 2: if size(n samples ) &lt; s ms then if (λ 2 &gt; s α λ 1 ) and (s β λ 2 &gt; λ 3 ) then children ← children(n) {initialize the node's eight children} 14: for each p in n samples do</figDesc><table><row><cell>9:</cell><cell>n coplanar ← true</cell></row><row><cell>10:</cell><cell>return</cell></row><row><cell>11:</cell><cell>end if</cell></row><row><cell cols="2">12: end if</cell></row><row><cell>13: n 15:</cell><cell>put p in respective child node</cell></row><row><cell cols="2">16: end for</cell></row><row><cell cols="2">17: for each c in n children do</cell></row><row><cell>18:</cell><cell></cell></row></table><note><p>3: return 4: end if {octree subdivision step} 5: if n level &gt; s level then 6: Σ (x,y,z) ← cov(n samples ) {covariance matrix in (x, y, z) space} 7: (V xyz , Λ xyz ) ← eigen(Σ (x,y,z) ) {eigen-decomposition} {approximate coplanarity test } 8:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 :</head><label>1</label><figDesc>Data on the experiments performed with our technique. Number of samples in the point clouds, numbers of detected clusters, number of samples used in the voting procedure, octree-generation time, voting time, peak-detection time, and number of detected planes.</figDesc><table><row><cell>Point Cloud</cell><cell></cell><cell></cell><cell>Octree</cell><cell></cell><cell></cell><cell>Time (sec)</cell><cell></cell><cell></cell><cell>Result</cell></row><row><cell>Name</cell><cell>Size</cell><cell>Bounding Box</cell><cell cols="3">Clusters Used Points Rate(%)</cell><cell cols="3">Clustering Voting Peaks</cell><cell>Planes</cell></row><row><cell>Computer</cell><cell>68 852</cell><cell>1.3 × 3.0 × 0.9</cell><cell>119</cell><cell>30 630</cell><cell>44.48</cell><cell>0.005</cell><cell cols="2">0.009 0.008</cell><cell>8</cell></row><row><cell>Room</cell><cell>112 586</cell><cell>29.2 × 14.5 × 3.1</cell><cell>339</cell><cell>66 682</cell><cell>59.22</cell><cell>0.009</cell><cell>0.02</cell><cell>0.012</cell><cell>40</cell></row><row><cell>Utrecht</cell><cell>160 256</cell><cell>75.8 × 75.8 × 37.3</cell><cell>393</cell><cell>92 839</cell><cell>57.93</cell><cell>0.024</cell><cell cols="2">0.005 0.011</cell><cell>38</cell></row><row><cell>Museum</cell><cell cols="2">179 744 72.4 × 132.8 × 23.1</cell><cell>232</cell><cell>121 943</cell><cell>67.84</cell><cell>0.013</cell><cell cols="2">0.007 0.005</cell><cell>21</cell></row><row><cell>Box</cell><cell cols="2">964 806 409.9 × 409.9 × 409.9</cell><cell>144</cell><cell>584 028</cell><cell>60.53</cell><cell>0.054</cell><cell cols="2">0.008 0.015</cell><cell>6</cell></row><row><cell>Bremen</cell><cell cols="2">20 332 246 110.2 × 379.3 × 84.6</cell><cell>7 489</cell><cell>17 929 145</cell><cell>88.18</cell><cell>2.05</cell><cell cols="2">0.033 0.022</cell><cell>202</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of our approach (3-D KHT) against RHT, Schnabel et al.'s RANSAC<ref type="bibr" target="#b26">[27]</ref>, and PCL's RANSAC<ref type="bibr" target="#b37">[38]</ref> for various datasets. The entries of the table show the execution times (in seconds) of the four techniques for these datasets. (*) The RHT was computed with a simplified version of Bremen dataset containing only 2 million samples, because the available implementation did not support larger inputs.</figDesc><table><row><cell></cell><cell cols="3">Computer Room Utrecht Museum</cell><cell>Bremen</cell></row><row><cell>3-D KHT</cell><cell>0.022 0.041</cell><cell>0.040</cell><cell>0.025</cell><cell>2.105</cell></row><row><cell>RHT</cell><cell>0.121 6.313</cell><cell>2.814</cell><cell>11.960</cell><cell>42.824*</cell></row><row><cell>RANSAC [27]</cell><cell>0.340 0.774</cell><cell>0.919</cell><cell>1.200</cell><cell>745.055</cell></row><row><cell>RANSAC [38]</cell><cell>0.424 3.293</cell><cell cols="3">15.412 302.610 7,531.010</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was sponsored by CNPq-Brazil grants 131002/2012-0, 482271/2012-4, and 308936/2010-8, and FAPERGS PQG 10/1322-0.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">3d building model reconstruction from point clouds and ground plans</title>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dijkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Arch. of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="page" from="37" to="43" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Plane-based projective reconstruction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kaucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eighth IEEE International Conference on Computer Vision</title>
		<meeting>Eighth IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="420" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Hough-transform and extended ransac algorithms for automatic detection of 3d building roof planes from lidar data, International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tarsha-Kurdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Landes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grussenmeyer</surname></persName>
		</author>
		<idno>ISPRS 3</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="407" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">3d building roof reconstruction from point clouds via generative models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS &apos;11</title>
		<meeting>the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, GIS &apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="16" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal surface reconstruction from planar contours</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Uselton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="693" to="702" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Autocalibration from planar scenes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th European Conference on Computer Vision</title>
		<meeting>the 5th European Conference on Computer Vision</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="89" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Planar object recognition using projective shape representation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Rothwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mundy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="99" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Reconstruction of piecewise planar objects from point clouds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Peternell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Design</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="333" to="342" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Markerless tracking using planar structures in the scene</title>
		<author>
			<persName><forename type="first">G</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE and ACM International Symposium on Augmented Reality</title>
		<meeting>IEEE and ACM International Symposium on Augmented Reality</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ninja on a plane: Automatic discovery of physical planes for augmented reality using visual slam</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chekhlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Calway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mayol-Cuevas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE and ACM ISMAR</title>
		<meeting>of the IEEE and ACM ISMAR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised robust planar segmentation of terrestrial laser scanner point clouds based on fuzzy clustering methods</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Biosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Lerma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="98" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaeger</surname></persName>
		</author>
		<title level="m">Proc. 8th Int. Conf. Virtual Reality Continuum and Its Applications in Industry</title>
		<meeting>8th Int. Conf. Virtual Reality Continuum and Its Applications in Industry</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="127" to="132" />
		</imprint>
	</monogr>
	<note>Segmentation of architecture shape information from 3d point cloud</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Hausner</surname></persName>
		</author>
		<ptr target="http://synthexport.codeplex.com/" />
		<title level="m">Synthexport</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Microsoft</forename><surname>Photosynth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time line detection through an improved hough transform voting scheme</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A F</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Method and means for recognizing complex patterns</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hough</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Use of the hough transformation to detect lines and curves in pictures</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="15" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Eldar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<title level="m">A probabilistic hough transform, Pattern Recogn</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="303" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive termination of voting in the probabilistic circular hough transform</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ylä-Jääski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kiryati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="911" to="915" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Progressive probabilistic hough transform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Galambos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the British Machine Vision Conf</title>
		<meeting>of the British Machine Vision Conf</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="256" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kultanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A new curve detection method: randomized hough transform (rht)</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recognizing structure in laser scanner point clouds, Intern. Archives of Photogrammetry</title>
		<author>
			<persName><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G H</forename><surname>Gorte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sithole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rabbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing and Spatial Info. Sciences</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detection of planar regions in volume data for topology optimization</title>
		<author>
			<persName><forename type="first">U</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Polthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Int. Conference on Advances in Geometric Modeling and Processing</title>
		<meeting>the 5th Int. Conference on Advances in Geometric Modeling and Processing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automated detection of planes in 3-d point clouds using fast hough transforms</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">O</forename><surname>Ogundana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Coggrave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Burguete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Huntley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">53609</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Accurate and fast extraction of planar surface patches from 3d point cloud</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Ubiquitous Information Management and Communication</title>
		<meeting>the 7th International Conference on Ubiquitous Information Management and Communication</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient ransac for point-cloud shape detection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="214" to="226" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Perceptual organization and curve partitioning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="105" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Segmentation through variable-order surface fitting</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="192" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A data-driven intermediate level feature extraction algorithm</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="749" to="758" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast plane detection and polygonalization in noisy 3d range images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Poppinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vaskevicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Birk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pathak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conf. on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="3378" to="3383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A fast and accurate plane detection algorithm for large noisy point clouds using filtered normals and voxel growing</title>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Goulette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DPVT</title>
		<meeting>3DPVT</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Least-squares fitting algorithms of the nist algorithm testing system</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Shakarji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research of the National Institute of Standards and Technology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="633" to="641" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probability and experimental errors in science: an elementary survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Parratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Editions</title>
		<imprint>
			<date type="published" when="1961">1961</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The Multivariate Normal Distribution</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Tong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The 3d hough transform for plane detection in point clouds: A review and a new accumulator design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Borrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Elseberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lingemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nüchter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">3D Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<ptr target="http://dlib.net/(n.d" />
		<title level="m">dlib, dlib c++ library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">3d is here: Point cloud library (pcl)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cousins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
