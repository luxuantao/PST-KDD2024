<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">INFORMys: A Flexible Invoice-Like Form-Reader System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Francesca</forename><surname>Cesarini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">²²²²²²²²²²²²²²²² • F. Cesarini, S. Marinai, and G. Soda are with Dipartimento di Sistemi e Informatica</orgName>
								<orgName type="institution">Università di Firenze. Via S. Marta</orgName>
								<address>
									<postCode>3 -50138</postCode>
									<settlement>Firenze</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Marco</forename><surname>Gori</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">²²²²²²²²²²²²²²²² • F. Cesarini, S. Marinai, and G. Soda are with Dipartimento di Sistemi e Informatica</orgName>
								<orgName type="institution">Università di Firenze. Via S. Marta</orgName>
								<address>
									<postCode>3 -50138</postCode>
									<settlement>Firenze</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento di Ingegneria dell&apos;Informazione</orgName>
								<orgName type="institution">Università di Siena Via Roma</orgName>
								<address>
									<postCode>56 -53100</postCode>
									<settlement>Siena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Simone</forename><surname>Marinai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">²²²²²²²²²²²²²²²² • F. Cesarini, S. Marinai, and G. Soda are with Dipartimento di Sistemi e Informatica</orgName>
								<orgName type="institution">Università di Firenze. Via S. Marta</orgName>
								<address>
									<postCode>3 -50138</postCode>
									<settlement>Firenze</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Giovanni</forename><surname>Soda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">²²²²²²²²²²²²²²²² • F. Cesarini, S. Marinai, and G. Soda are with Dipartimento di Sistemi e Informatica</orgName>
								<orgName type="institution">Università di Firenze. Via S. Marta</orgName>
								<address>
									<postCode>3 -50138</postCode>
									<settlement>Firenze</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">INFORMys: A Flexible Invoice-Like Form-Reader System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">037C6D9D5984796A32BF3C30B2D91C6A</idno>
					<note type="submission">received 25 Sept. 1997; revised 4 May 1998. Recommended for acceptance by R. Kasturi.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T12:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Attributed relational graphs</term>
					<term>document analysis and recognition</term>
					<term>document registration</term>
					<term>invoice processing</term>
					<term>location of information fields</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe a flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies. In this kind of document, the extraction of some information fields cannot take place without having detected the corresponding instruction fields, which are only constrained to range in given domains. We propose modeling the document's layout by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focussed search for instruction fields. This search is carried out by means of a hybrid model, where proper algorithms, based on morphological operations and connected components, are integrated with connectionist models. Experimental results are given in order to assess the actual performance of the system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>OCUMENT image analysis and recognition have received much attention in the last years. Among different applications, financial document processing <ref type="bibr" target="#b0">[1]</ref> and forms processing <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> are becoming very important in practice, since those documents have typically a simple structure when compared with general documents, that like articles, include complex figures and mathematical symbols. Moreover, the automation of the form reading process is an objective of relevant interest, since forms processing is in fact an essential operation in many business organizations.</p><p>The overall objective of a form reading system is to obtain a symbolic representation of the data (either printed or handwritten) from a given form. The typical operations involved in these systems are document image acquisition and preprocessing, layout analysis, and data interpretation <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Most systems execute these steps sequentially by a bottom-up approach derived from classical image analysis approaches.</p><p>The preprocessing step usually involves binarization followed by form registration, which is often performed by bottom-up operations <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>. During the layout analysis, important regions which contain the information are located in the form. Throughout the paper, these regions are referred to as information fields. Finally the data interpretation step takes place on regions previously extracted and can involve either handwritten or printed character recognition.</p><p>In many practical cases, form recognition is simply based on the assumption that the information fields are in fixed positions. In other cases (see e.g., Tang et al. <ref type="bibr" target="#b0">[1]</ref>) the information fields are extracted thanks to the detection of lines. Each line is described by its orientation, thickness, and position in the form, and serves as a reference for detecting information fields. Most approaches that hardly rely simply on line detection, however, are quite limited in that they can only deal with table-like forms. Other approaches (see, e.g., <ref type="bibr" target="#b5">[6]</ref>) are based on the description of the form layout by means of rectangles instead of lines. This kind of description is obviously more compact but, on the other hand, it is not as much powerful as that based on line detection.</p><p>A more flexible way to characterize information fields is that of describing their position with respect to the corresponding instruction field, which describes the content of an information field. In the system proposed in <ref type="bibr" target="#b6">[7]</ref>, only fields that are inside rectangles (referred to as frames) are taken into account. Two classes of frames are considered: label frames, containing instruction fields, and data frames, containing information fields. The link between a label and the corresponding data frame is given by the spatial relationship between the two rectangles. The system described by Lam and Srihari <ref type="bibr" target="#b7">[8]</ref> locates related instruction and information fields by recognizing the text of the instruction field.</p><p>The sequence of operations needed to carry out form registration and layout analysis depends on whether or not the form is known in advance <ref type="bibr" target="#b8">[9]</ref>. Consequently, modeldriven and data-driven approaches can be adopted and, in some cases, these approaches can profitably be integrated <ref type="bibr" target="#b9">[10]</ref>. If the form is known in advance, that is, if its layout is exactly defined, then the data extraction can naturally be based on a top-down, model-driven process <ref type="bibr" target="#b10">[11]</ref>. In these systems, the form registration turns out to be the major problem, as data can directly be extracted once the registration has taken place. In the case of unknown forms, a possi-ble approach is that of classifying documents in a fixed number of classes, and then use the model corresponding to each document class to carry out the layout analysis <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref>. An intermediate case is that of forms of known class, where the layout has not a fixed geometrical structure, but can instead only be inferred on the basis of the instruction fields <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">An Overview of INFORMys</head><p>INFORMys, <ref type="foot" target="#foot_0">1</ref> the system described in this paper, is designed to deal with known-class forms and has been mainly conceived to deal with forms like those issued by service companies for accounting (see e.g., Fig. <ref type="figure" target="#fig_0">1</ref>). Like the models proposed in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b11">[12]</ref>, INFORMys is based on graphs for describing the form layout. However, instead of using hierarchical <ref type="bibr" target="#b3">[4]</ref> or nonhierarchical graph <ref type="bibr" target="#b11">[12]</ref> with symbolic spatial relationships (e.g., above, left), our model is based on nonhierarchical attributed relational graphs (ARG) <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. ARGs are typically used for image representation and analysis in computer vision. The nodes describe objects or parts of objects, while the arcs describe the mutual relationships between the nodes by means of numerical attributes.</p><p>In our model, the form layout is described by means of an attribute relational graph referred to as the form graph, where the nodes represent lines, instruction fields, information fields, and logos, while the arcs represent the mutual position of the items corresponding to the linked nodes. Concerning numerical arc attributes, instead of using only the distance between objects, as in <ref type="bibr" target="#b13">[14]</ref>, we consider a vector which connects the barycenters of the objects. By using ARGs, we have an accurate and flexible description of the form class. A bottom-up approach could be used in which one creates a graph describing the incoming unknown form, and subsequently matches the items of that graph with those of the form graph used as a reference to model the accounting forms <ref type="bibr" target="#b3">[4]</ref>. However, this would give rise to a very expensive algorithm, and it does not seem to be the best way to deal with documents in which the structure is known.</p><p>We suggest using a method in which a top-down processing is switched to a bottom-up processing on the basis of the information on the form graph. Form registration is performed by using an algorithm based on a hypothesize-andverify method <ref type="bibr" target="#b14">[15]</ref>. The alignment methods used in computer vision to register the position of rigid objects <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> are based on correspondences of data and model features of dimensionality sufficient to compute a complete transformation. Each transformation constitutes a hypothesis about the pose of the object which must be verified. By verification we mean that additional evidence, either supporting or refuting this hypothesis, must be accumulated in the image <ref type="bibr" target="#b14">[15]</ref>. In our approach to form registration, the features used to evaluate the form position are stored as nodes of a subgraph of the form graph, which is referred to as the registration graph. The hypothesized transformation is computed by aligning a model feature, e.g., a line node, with a corresponding feature in the incoming form. The verification is carried out by searching those form items that match all the nodes of the registration graph. If the verification fails then a new hypothesis is generated and subsequently verified until the verification succeeds or there are no more hypotheses to test.</p><p>Concerning the layout analysis, we propose an approach which is based on the location of both logos and instruction fields that, subsequently, make it possible the extraction of the information fields, thanks to our graph-based model. A related approach was proposed in <ref type="bibr" target="#b7">[8]</ref>, but the instruction fields were limited to keywords. Word recognition has been extensively studied in the literature with different approaches (e.g., see <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>). Methods for word recognition can be classified depending on whether or not the word being recognized is segmented into single characters. The segmentation into characters turns out to be the only pursuable way for recognizing words of a very large dictionary, whereas very effective algorithms can be conceived for the recognition of words of small dictionaries when using the whole word as input to the classifier. In order to deal with highly-noisy forms including also graphical items and to speed up the recognition, we use a connectionist-based model in which both keywords and logos are processed in the same way by simply regarding them as input patterns. The keyword recognition accuracy is improved by integrating the hypothesis obtained from the whole word, with an OCR module charged of recognizing the single characters which compose the word. This module is only fired once the connectionist-based model processing the whole keyword gives no enough recognition confidence.</p><p>Unlike instruction fields, which belong to a finite dictionary, the recognition of information fields must necessarily be based on the recognition of the single characters. We used a connectionist-based model for character recognition that is strongly inspired by the work described in <ref type="bibr" target="#b18">[19]</ref>. Like most form-reader systems, INFORMys offers a twofold user interface for assisting the user during both form modeling and reading. The Form Modeler (FM) assists the user building the form graph, while the Form Reader (FR) implements the recognition engine (see Fig. <ref type="figure" target="#fig_1">2</ref>).</p><p>INFORMys' user interface is based on X-window<ref type="foot" target="#foot_1">2</ref> and supports interactive functions for defining the form structure. During the construction of the form graph, the operator points to the objects (lines, instruction and information fields, logos) that are relevant for representing the structure of the forms. These objects correspond to the nodes of the form graph, while the arcs express the mutual relationships of different objects. The location of objects and of their mutual relationship is carried out by the user, and the corresponding information is subsequently exploited to create the form graph according to the specifications given in Section 2. The form-reader module is responsible for supporting the recognition phase. The form reading is a sequential process where the incoming form is first scanned and converted into an electronic image, then aligned by form registration, and, finally, the information fields are located and recognized.</p><p>INFORMys deals with documents which contain four different kinds of "objects," namely, lines, logos, instruction fields, and information fields. Lines, logos, and instruction fields are useful for locating the information field and, therefore, throughout this paper, are referred to as reference objects. A document class is identified by specifying the possible ways of relating the information to instruction fields and other objects. The class is defined when specifying exactly the objects and their relationships in the documents.</p><p>The paper is organized as follows. Section 2 describes in detail the form graph-based model, while the registration algorithm is given in Section 3. Section 4 describes the location of logos, instruction fields, and information fields. Experimental results are given in Section 5, and, finally, some conclusions are drawn in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MODELING FORMS</head><p>In this paper, Attributed Relational Graphs (ARG, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>) are adopted for representing forms. The nodes describe objects or parts of objects, like lines, logos, instruction fields, and information fields, whereas the arcs describe the mutual geometrical relationships between the objects represented by the nodes. Let us state these concepts more formally. DEFINITION 1. Form Graphs. </p><formula xml:id="formula_0">A form graph )* Џ {N, A, $ N , $ A , G N , G A }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Node attributes $ $</head><formula xml:id="formula_1">N N i i N N &amp; , = OE J L are four-tuples $ N i i i i i R T D S &amp; , , , = &lt; A (1)</formula><p>where R i is a registration flag, computed by G N R ◊ 05 that in- dicates whether node N i is used to register the form, T i is the type of the object associated with node N i , D i is the node description, and S i are the search attributes which are used for identifying the rectangular region Γ I where the search must operate, and for specifying how the search takes place. Given a node N i , function G N generates the corresponding node attributes $ N i , that is the four-tuple</p><formula xml:id="formula_2">{R i , T i , D i , S i }.</formula><p>DEFINITION 3. Node Type.</p><p>Given N i ∈ N, its type ranges in T i Џ {L, G, K, I}, that is, the type can be a line, a logo, an instruction field, and an information field, respectively, and the corresponding attribute is defined by the generating function G N T ◊</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>05.</head><p>Lines act as reference points only, whereas all other types support information. Depending on the type of node, different descriptions arise which result in different attributes. <ref type="bibr">DEFINITION</ref>  The searching area Γ i is given by means of P i Џ {E x , E y }, which are the sides of Γ i whose absolute position is given by one or two arcs. • L i : how the search takes place.</p><p>The L i ∈ {U, D, L, R, C} attribute describes how to search for the item into Γ i . The search can in fact begin from the rectangle sides (U (Up), D (Down), L (Left), R (Right)) or from the center (C).</p><p>Concerning the size of Γ i , one can effectively deal with either fixed position items (e.g., information field N 9 in Fig. <ref type="figure" target="#fig_4">4</ref>) or items that can be located in a variable position in a region of the form (e.g., instruction field N 7 in Fig. <ref type="figure" target="#fig_4">4</ref>). In the first case, the Γ i size needs to be only slightly greater than the corresponding item, whereas in the second case the search rectangle has to be large enough to cover the variable position of the item. DEFINITION 6. Arc Attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let A i,j be the arc connecting node N i to node N j . The arc attributes $ $</head><formula xml:id="formula_3">A A ij i j A A &amp; , , , = OE J L are defined as the triple $ A ij ij ij i j R V P , &amp;<label>, , , , , = r J L</label></formula><p>(2) r V i j , is a vector, P i,j is the point where the vector is applied, and R i,j is the registration flag.</p><p>If R i,j = false (the arc A i,j is not used for registration), then only r V i j , is generated which represents a vector giving the relative position of Γ j 's barycenter once given Γ i 's (Fig. <ref type="figure" target="#fig_2">3</ref>).</p><p>The magnitude and orientation of r V i j , are denoted by M i,j and α i,j , respectively. In order to identify the case in which the location of an instruction field is carried out by means of two arcs, the vector length M i,j is left undefined since, in that case, only the direction of r V i j , is needed. The arcs can describe the mutual position of two nodes used to register the form or can be used to locate information fields. In the first case, R i,j = true, while in the second case, R i,j = false. As will be described in Section 3, our approach to form registration allows the user to describe the invariant part of the form layout by defining some registration landmarks that can be both lines and instruction fields. In other cases, the registration is constrained by considering the mutual position between registration landmarks. Nodes and arcs used to describe the registration landmarks and mutual positions give rise to a subgraph of )*, that is referred to as the registration graph and is denoted by )* r . The registration graph plays a crucial role for the hypothesize and verification algorithm proposed in the following for registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DEFINITION 7. Registration Graph.</head><p>Given a form graph )*, its registration graph )* r only contains nodes and arcs used for the form registration, that is nodes and arcs for which the registration flag is true. )* r is partitioned into two subgraphs )* r h 1 5 , and )* r v 0 5 , that will be used in the registration for the hypothesize and verification steps, respectively.</p><p>Note that some nodes of )* r can be used for form registration and also to locate information fields, whereas the arcs in )* r are used only to register the form position. )* 1 5 &lt; A 4 9</p><p>= . P fm is the center of the line, a fm is aligned with the actual line, with direction corresponding to increasing coordinates, while M fm = 1. If Type fm = 2, then I fm corresponds to an arc, A 1,2 , and</p><formula xml:id="formula_4">)* r h N N A 1 5 = B = 1 2 1 ,2</formula><p>, , .</p><p>In the last case (Type fm = 3), the point P fm is obtained by considering the intersection of lines N 1 , and</p><formula xml:id="formula_5">N N N r h 2 1 2</formula><p>)* 1 5 &lt; A 4 9</p><p>= , , α fm is aligned with the actual line corresponding to N 1 , with direction corresponding to increasing coordinates, while M fm = 1.</p><p>The form graph is constructed by the user who interacts with the INFORMys graphical user interface. In a typical session of graph building the user first loads a prototype form. Afterwards he selects the objects corresponding to the nodes, enters some attributes of the nodes, and describes the mutual relationships between objects. Here is a brief description of the steps required in order to insert graph items.</p><p>• Line node. The searching area for the line (P i ) is defined by drawing an upright rectangle on the prototype form.</p><p>The user sets the registration flag and parameters Or i , St i , and L i . An appropriate procedure is executed in The values R i , P i , and L i are entered in the same way as line nodes. Afterwards, the user draws a rectangular region surrounding the object to be located. The system evaluates Sx i and Sy i so as to identify the object to be used subsequently for learning the parameters of Net i . • Information field node.</p><p>The values P i and L i are introduced as previously described. Attributes Type i , Min i , and Max i are directly typed by the user. • Arc.</p><p>The definition of an arc is very simple. INFORMys shows all the nodes of the graph and the user is asked to select the two nodes which identify the arc, and to set the registration flag. All the other attributes are computed by the system on the basis of the positions of the objects corresponding to the connected nodes.</p><p>Fig. <ref type="figure" target="#fig_6">5</ref> represents the )* for the document depicted in Fig. <ref type="figure" target="#fig_4">4</ref>, where the items corresponding to the nodes are indicated by arrows. Nodes N 1 , N 2 , N 3 , and N 4 are used for registration and</p><formula xml:id="formula_6">Type N N N N fm r h r v = 1 1 2 3 4 )* )* 1 5 0 5 &lt; A 4 &lt; A8 = = , , , .</formula><p>Examples of the meaning of some nodes and arcs are given in the following. N 1 describes a horizontal line with thickness one and length of 405 (pixels); the line must be found in region </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FORM REGISTRATION</head><p>A typical problem that arises when acquiring documents with scanners is that there is a mismatch between the reference model and the incoming form, which is due to the difficulty of predicting exactly the location of the form on the scan bed. In the literature <ref type="bibr" target="#b1">[2]</ref>, the solution of this problem is referred to as form registration (or alignment), while the term skew denotes the rotation to which the document is subjected. Basically, we need to evaluate the rototranslation map which makes the incoming form congruent with the INFORMys model. Many methods based on the location of single characters, have been proposed in order to detect the skew of unknown documents <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Unfortunately, these methods are very time consuming since they do not take the knowledge of the form layout into account, and are not very suitable for registration. In order to register forms, a pursuable approach is that of locating lines and then use a sort of bottom-up scheme that requires processing the entire document. The solution proposed in <ref type="bibr" target="#b4">[5]</ref> is limited to the estimation of the skew and is based on the detection of all the lines in the document, and then on a majority vote on line orientation. Although robust, that approach requires the analysis of the whole document and turns out to be useful when the form layout is not exactly defined, but we know that the form contains horizontal and/or vertical lines. In <ref type="bibr" target="#b2">[3]</ref>, the form registration is evaluated considering the relationships between the line corner junctions stored in the model and those found in the incoming form. This method is very accurate once working on tabular forms where there are many line crossings. When the form layout is exactly known, a bottom-up approach seems to be unnecessary. In some applications the form registration can be obtained simply by locating some specific items by hardcoding the form class knowledge <ref type="bibr" target="#b21">[22]</ref>. Although very effective for customized applications, these methods have a very low flexibility. On the contrary, the approach proposed in <ref type="bibr" target="#b22">[23]</ref>, which is based on the ex- traction of cross and end-point features, exhibits a higher flexibility. From the expected position of each feature in the document, the detector for that feature is applied to all pixels in an expanded region defined by the expected rotations and translations to which the form can be subjected. Geometrical constraints on the distance between features and the angles between pairs of features are used in order to make a registration hypothesis. Once a hypothesized transformation is found, it is verified considering a fixed number of additional landmarks. If verification is successful, then the document is rotated and translated accordingly. If the hypothesis fails, another one is generated and subsequently verified. This approach seems to be very effective since there is no need to extract all the features from the incoming document.</p><p>In INFORMys, we use a related approach in which lines, keywords, and logos are used to align forms. As shown in Section 2, the registration landmarks, which describe the invariant part of the layout, are stored as nodes of )* r . Moreover, instead of looking for any given item used for registration in the corresponding expanded region (as done in <ref type="bibr" target="#b22">[23]</ref>), we define the expanded region only for the nodes of )* r </p><formula xml:id="formula_7">G i E i r h N OE )* 1 5<label>4</label></formula><p>9 is specified by two error margins δ x and δ y , that give the maximum allowable displacement for the incoming form. G i E is chosen in such a way to take all the errors due to the positioning of the form into the scan bed into account.</p><p>The registration algorithm is based on the hypothesize and verify approach <ref type="bibr" target="#b14">[15]</ref>. Basically, the main procedure (see Algorithm 1) is composed of two steps: hypothesis generation and verification. In hypothesis generation, a list / of transformations is found by aligning the first-matching item with a related item extracted from the incoming form ). Each element of / is referred to as a hypothesis. When verifying a hypothesis Hyp j Џ (Θ j , ∆x j , ∆y j ), additional ob- </p><formula xml:id="formula_8">δ x ← δ x + δ xi ; δ y ← δ y + δ yi ; until d d x x</formula><p>&gt; or r &lt;&gt; nil end</p><p>In hypothesis generation and verification, when looking in ) for objects that can correspond to node N i some constraints must be satisfied. Two types of constraints can be defined: namely unary-constraints and binary-constraints <ref type="bibr" target="#b14">[15]</ref>. With unary-constraint(N i , 2) we denote the function used to evaluate the constraint defined on N i and 2. The constraint is true (and we say that object 2 can match node N i ) if 2 is an object of type T i and if the distances between numerical attributes of D i and corresponding features of 2 are below a threshold defined in advance. Binaryconstraints are applied to a pair of pairings of )* r nodes and ) objects. The nodes considered in the binary-constraint are connected by a )* r arc. Let 2 and 8 be two objects of ), binary-constraint(N i , N j , 2, 8) is true if 2 can match N i , 8 can match N j , and the mutual position between the barycenters of 2, and 8 (described by vector r V 28 ) is compatible with r V i j , . In hypothesis generation, r V 28 is compatible with r V i j , if the distance between M 28 and M i,j is below a threshold. The functions unary-constraint and binaryconstraint are used in the following, in order to test whether an object can match a graph node.</p><p>The  Hence two hypotheses (Hyp 1 , and Hyp 2 ) must be verified. The verification of Hyp 1 is described in (c) and (f). In (c) we report the regions ( G 2,1 , G 3,1 , that are superimposed) where to look for locating objects that can match )* r v 0 5 nodes. Since the line l 3 is assigned to both N 2 and N 3 , then the verification fails. In other words the verification tree, depicted in (f), does not contain a consistent path. The verification of Hyp 2 is shown in (d) and (g). In this case we can found two lines matching N 2 and N 3 , and this corresponds to the consistent path l 2 -l 4 -l 5 in (g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>begin case Type fm of 1: begin</head><formula xml:id="formula_9">G G 1 1 E x y ¨Expand , , d d 4 9 ; / ) ¨LineAlign G 1 1 1 E D S , , ,<label>4 9 end 2,3: begin G</label></formula><formula xml:id="formula_10">G 1 1 E x y ¨Expand , , d d 4 9 ; / ) 1 1 1 11 ¨FindObjs G E T D S , , , ,<label>4 9 ;</label></formula><p>G G</p><formula xml:id="formula_11">2 2 E x y ¨Expand , , d d 4 9 ; / ) 2 2 2 22 ¨FindObjs G E T D S , , , ,<label>4 9 ;</label></formula><p>if Type fm = 2</p><formula xml:id="formula_12">then / ← ArcAlign(/ 1 , / 2 , M 1,2 , α 1,2 ) else / ← CrossAlign (/ 1 , / 2 , D 1 , P 1 , D 2 , P 2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>end end end</head><p>The Verify function tests the correctness of the hypotheses in /, until a hypothesis is successfully verified or all the hypotheses are tested. A hypothesis Hyp j is successfully verified if we can assign a distinct object to each of the )* r v 0 5 nodes. We can assign an object 2 of ) to node N i , if</p><formula xml:id="formula_13">2 can match N i ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and for all arc A A h i h i h i r v , , OE &lt;</head><p>)* 0 5 4 9</p><p>binary-constraint(N h , N i , 8, 2) = true (where 8 is the object assigned to node N h ). The behavior of the verification algorithm can be described graphically by means of a tree representation of the search space (the verification tree: 97 ). The 97 nodes contain one or more objects of ). Each object is identified by the coordinates of its barycenter. For each hypothesis Hyp j , a tree 97 j can be created. The hypothesis is represented in the root of 97 j that contains an object for each of the )* r h 1 5 nodes. Each node at the ith level of 97 j contains an object of ) that can match the ith</p><formula xml:id="formula_14">node of )* r (v)</formula><p>. The children of the nodes of the ith level correspond to the objects found by the algorithm when matching N i+1 of )* r v 0 5 in region G i j E +1, . The 97 j leaves correspond to the last node of )* r v 0 5 . Given such a structure for 97 j , hypothesis verification is based on the search of a consistent path. A consistent path is a path from the root to a leaf of the tree that satisfies the following two conditions:</p><p>• All the objects in the nodes of the path are distinct;</p><p>• Let 2 i and 2 j be the objects in the nodes of the path at levels i and j. Given an arc A i,j such that N i and N j are in the path, binary-constraint(N i , N j , 2 i , 2 j ) = true.</p><p>The search of a consistent path is carried out by the depth-first traversal of 97. The hypothesis is verified when a consistent path is found, otherwise the hypothesis is rejected. The actual behavior of the registration algorithm can be understood by the following example (Fig. <ref type="figure" target="#fig_9">6</ref>). , .</p><p>• Hypothesis generation. The first step is the expansion of region Γ 1 to G 1 E , where we look for I fm (Fig. <ref type="figure" target="#fig_9">6b</ref>).</p><p>In order to evaluate the transformation required for form registration, a line that can match N 1 must be found in G 1 E . As we can see in Fig. <ref type="figure" target="#fig_9">6c</ref>, two lines (l 1 and l 2 ) can potentially match line node N 1 . The alignment of N 1 with l 1 and with l 2 yields two transformations denoted as Hyp 1 and Hyp 2 , respectively. • Hypothesis verification. The verification of hypothesis Hyp j (j = 1, 2) requires looking for a distinct line corresponding to N i (i = 2, 3) into the region Γ i,j (see Figs. <ref type="figure" target="#fig_9">6c</ref> and<ref type="figure" target="#fig_9">6d</ref>). This can be also interpreted as looking for a consistent path in the verification tree (see Figs. <ref type="figure" target="#fig_9">6f</ref> and<ref type="figure" target="#fig_9">6g</ref>). In the case of Hyp 1 the line l 3 (Fig. <ref type="figure" target="#fig_9">6c</ref>) can match N 2 , but no line corresponding to N 3 can be found in region Γ 3,1 . Hence the hypothesis verification fails, and we must verify the other hypothesis (Hyp 2 ).</p><p>The verification tree for Hyp 2 is shown in Fig. <ref type="figure" target="#fig_9">6g</ref>, where the consistent path (l 2 -l 4 -l 5 ) is reported. The path can be interpreted as the match of l 2 with N 1 , l 4 with N 2 , and l 5 with N 3 , as shown in Fig. <ref type="figure" target="#fig_9">6d</ref>. Note that the path (l 2 -l 5 -l 4 ) in Fig. <ref type="figure" target="#fig_9">6g</ref> is not consistent since binary-constraint(N 2 , N 3 , l 5 , l 4 ) is false. This example is based on line nodes only, but logos or instruction fields can also be used for verification, thus giving rise to a similar behavior.</p><p>As already pointed out, the registration can also be based on an arc A 1,2 as I fm , and the hypothesis is generated by using the function ArcAlign. In Fig. <ref type="figure">7</ref>, an example is shown with the two items (N 1 , N 2 ) used to determine arc A 1,2 . Node N 1 corresponds to a logo, while N 2 corresponds to an instruction field. The hypothesized transformation is calculated by aligning the vector described in r V 1,2 with the vector connecting the barycenters of two objects that can match N 1 and N 2 . As in the case of simple line nodes, regions Γ 1 and Γ 2 are expanded by the error margins (δ x , δ y ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LOCATION OF INFORMATION FIELDS</head><p>After form registration, the rototranslation transformation r can be used to locate the information fields in the incoming form ). In INFORMys, there are essentially three ways of locating an information field corresponding to node N k :</p><p>1) The information field is placed in a fixed position with respect to the layout.</p><p>2) The reference object and the corresponding information field are not in a fixed position in the form, but their mutual position is defined in advance.</p><p>3) The information field can be located by means of its relative position with respect to two reference objects, that are not in fixed positions in the form.</p><p>In the first case the location of the information field is obtained by applying the transformation r to points A (top left) and B (bottom right), described in search attributes of</p><formula xml:id="formula_15">N k (P k = {x A , y A , x B , y B }).</formula><p>In the second and third cases, the information field can be found only after having located the corresponding reference objects, while the size of the search region is described by P k = {E x , E y }. The number of reference objects depends on the number (na k ) of arcs having the "tip" in node N k (A i,j ∈ )*|j = k). If na k = 1, then the center of the rectangle containing N k is found applying the vector r V i j , to the barycenter of the object corresponding to node</p><formula xml:id="formula_16">N i . If na A A j k j k k i j i j = = = 2 1 1 2 2 1 2 , , , ,<label>4 9</label></formula><p>, then the center of the rectangle containing N k is defined by the intersection of the straight lines starting from objects matching N i 1 and N i 2 and with orientation a i j</p><formula xml:id="formula_17">1 1</formula><p>, and a i j</p><formula xml:id="formula_18">2 2</formula><p>, , respectively (Fig. <ref type="figure" target="#fig_3">8</ref>). In the second and third cases, the location of information fields requires, in general, to locate reference objects. Lines are located by an algorithm strictly related to the Run Length Smoothing Algorithm <ref type="bibr" target="#b23">[24]</ref>), while the localization of logos and instruction fields is based on the algorithm described in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Location of Logos and Instruction Fields</head><p>The location of logos and instruction fields is crucial for both form registration and location of information fields. In INFORMys, the recognition of the logos is based on a connectionist-based model, where a multilayer perceptron acting as an autoassociator is trained for each class. The neural networks are trained to reproduce the input layer to the the output layer. One hidden layer provides a compressed and nonlinear representation of the input information. It has been pointed out that reliable rejection criteria can be given for autoassociators that are based on the Euclidean distance between the inputs and the outputs <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><p>A massive experimentation of the multilayered autoassociators on the logo data base provided by the University of Maryland showed the effectiveness of the proposed approach also in presence of noise (see <ref type="bibr" target="#b26">[27]</ref> for noisy logos created by Baird's model <ref type="bibr" target="#b27">[28]</ref>, and <ref type="bibr" target="#b28">[29]</ref> for the case of spotnoise, in which documents contain blobs and strips that obstruct the logo partially).</p><p>Once properly segmented as a single pattern, each word corresponding to an instruction field (keyword) can be recognized by using the same connectionist architecture used for logos. In the first version of INFORMys, the keywords were in fact recognized using autoassociators only, but the subsequent massive experimentation on real-word data suggested us to exploit also the information that can be ex-Fig. <ref type="figure">7</ref>. A hypothesis generated by an arc connecting nodes N 1 and N 2 that are associated with a logo and an instruction field, respectively. In the hypothesis generation step, the expanded regions (G 1 E and G 2 E ) are calculated for both the items linked by the arc. tracted from the recognition of the characters composing the keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Function RecWord Input:</head><p>The node N i corresponding to a given instruction field The incoming form ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output:</head><p>the barycenter of the word corresponding to N i . A nil value if the word was not found. begin W ← Rlsa(), Γ i , Sx i , Sy i );</p><formula xml:id="formula_19">E ← AA(W, Net i ); J ← Order(E); if E J E J E J AA T 2 1 1 - &gt; then RecWord ← W[J[1]] else begin j ← 0; repeat j ← j + 1; d[j] ← Warp(Txt i , OCR(W[J[j]])); until j ≥ n or d[j] ≤ T 1 if j &lt; n then RecWord ← W[J[j]] else begin j m ← argmin {d[j], j = 1, …, n}; if d[j m ] ≤ T 2 then RecWord ← W[J[j m ]] else RecWord ← nil end end end</formula><p>The location of the words corresponding to node N i (N i ∈ )*|T i = K) is described by function RecWord (see Algorithm 3), and Fig. <ref type="figure">9</ref> gives an example of how the algorithm operates. RecWord begins with the Rlsa (Run Length Smoothing Algorithm) which performs the extraction of regions in the incoming form ) that are likely to contain a candidate word. For noisy forms and small character size, the gap between characters is sometimes filled by the noise and two consecutive characters are merged, while consecutive words are still separated. This means that it is very difficult to segment a word into characters, while it is relatively easy to segment a line into words by "smearing" the text. The classical run-length smoothing algorithm that we use looks for white spaces between black pixels on the same line and changes them to black if their length is less than a threshold (the threshold is chosen to be greater than the minimum intercharacter spacing). After merging characters, the positions of words are found by considering the sets of connected pixels with aspect-ratio nearly equal to Sx i /Sy i . The vector W contains up to n images extracted from the form by the run length smoothing algorithm.</p><p>These images are properly processed in order to feed the autoassociator Net i , whose computation is carried out by function AA in Algorithm 3. The similarity of the word W[j] according to N i is based on the Euclidean distance between the input and output layers of the neural network Net i . A vector E containing the Euclidean distance for each word represented in W is the output of function AA. The vector J, obtained by function Order, gives an ascending sorting of <ref type="bibr" target="#b0">[1]</ref>] is used to estimate the recognition confidence given by the autoassociator. If F ≤ T AA then the autoassociator does not offer enough confidence for the decision. However, the error values give a significant measure of the similarity of the word W[j] and the word modeled by N i . The function 2&amp;5(W[j]) performs the recognition of single characters on image W[j] giving, as output, the ASCII code of the characters. Warp (X, Y) is a function that calculates the string edit distance of string X from string Y. The Warp function is based on a straightforward adaptation of the dynamic time warping algorithm <ref type="bibr" target="#b29">[30]</ref> used for isolated word recognition, and takes into account insertions, deletions, and substitutions of characters. The distance d[j] is calculated for each word until d[j] ≤ T 1 or all Fig. <ref type="figure">9</ref>. Two examples of the location of the instruction fields Totale and imponibile. For each example, the figure contains the search region, the output of the run-length filter, the segmented words (with correct aspect-ratio), and the corresponding errors of the autoassociators. In the first example, F &gt; T AA . Hence, the prediction of the autoassociator is accepted. In the second example F ≤ T AA and, therefore, the subsequent OCRbased check is required.</p><formula xml:id="formula_20">E[j] (E[J[1]] ≤ E[J[2]] ≤ … ≤ E[J[n]]). In INFORMys the value F = (E[J[2]] -E[J[1]])/E[J</formula><p>the words are tested. The threshold T 1 is used to stop the OCR-based verification, whenever a word is close enough to Txt i , which is the code of the string corresponding to reference word i. W[J[j m ]] can be accepted as corresponding to the node N i provided that d[j m ] ≤ T 2 , being T 2 the rejection threshold. Thresholds T 1 and T 2 are fixed on the basis of statistical analysis on the dictionary of words of the documents being processed. When no such knowledge is available, we can choose a severe criterion like T 1 = 0 and T 2 = 0, thus accepting only "exactly" recognized words, and rejecting all the others. Algorithm 3 turns out to be a tradeoff between high accuracy and computational efficiency. A major assumption, that is confirmed by the experimental results in the next section, is that the algorithm is expected to rely mainly on the recognition of the autoassociator, that is in many cases there is no need to invoke the OCR module. It acts only in the case in which the prediction of the autoassociator is not reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>In order to evaluate the performance of INFORMys, we carried out a massive experimentation of the system on real-world data. In this paper, we report the results of two experiments in which INFORMys is used for the automatic recognition of forms issued by Italian TELECOM and Italian Electrical company ENEL. These forms were kindly made available by the University of Florence. 4 The database for testing the system was composed of 100 TELECOM invoices and 182 ENEL invoices. In both experiments INFORMys was used for form registration, location, and recognition of information fields. The difference between these two applications is that in the first one the most critical point is the form registration, while in the second one the most critical point is the location of instruction fields.</p><p>INFORMys was running on a Sun ultra1 equipped with one cpu UltraSparc (143 MHz) and 64 KBytes of RAM.</p><p>4. These data are public domain and can be retrieved from the research group home page http://mcculloch.ing.unifi.it/~docproc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">TELECOM Forms: Test of the Registration Algorithm</head><p>In this experiment, the form registration was the most critical step since the invoices were manually placed in the scanbed without paying attention to their position. 5 As shown in Fig. <ref type="figure" target="#fig_12">10</ref>, some forms were placed in the scanbed in such a way that the image is truncated. We tested the system using all the 100 black and white images acquired by a HP scanjet 4P scanner with a resolution of 300 × 300 dpi and size 1,201 × 601 pixels. The registration graph is composed of three horizontal lines N 1 , N 2 , and N 3 of the same length (see Fig. <ref type="figure" target="#fig_12">10</ref>). Search regions for N 2 and N 3 were "small" rectangles (the size is 550 × 20 pixels for the horizontal line of 530 pixels) in order to speed up the search of lines and avoid confusion with other lines of the form. In all the experiments we used four different registration graphs</p><formula xml:id="formula_21">)* )* r r 1 4</formula><p>, , K (see Table <ref type="table" target="#tab_3">1</ref>). These registration graphs differed only for the different searching areas G i E that were properly chosen in order to evaluate their effect on the system performance. The CPU time required by the registration algorithm depends in fact on G 1 E and on the number of increments of δ x and δ y that are required to locate N 1 (see Algorithm 1). It is worth mentioning that the CPU time should be mainly regarded as a way to show the different performance in the system when using various parameters. The best performances were found when adopting the form graph )* r 1 , where G 1 E covers most part of actual lines corresponding to N 1 . In this case G 1 E contains the line corresponding to N 1 for 88 of the 100 forms. Only for 10 forms δ x and δ y were increased once, while for the remaining two forms two region expansions were required. In )* r 2 , a larger G 1 E is always used. This allows the system to avoid restarting the search, but the form registration requires more time (0.21 vs 0.55 second). The experiments using 5. Horizontal and vertical displacements with respect to the reference model were in ranges <ref type="bibr">[-6, 6]</ref>, <ref type="bibr">[-17, 43</ref>] pixels, respectively. )* r 3 and )* r 4 showed that by choosing a completely wrong position and size for G 1 E , although more time consuming, the system can always register the form correctly. The location of the information fields, that are in fixed position, depends on the registration of the incoming form. Hence in all the tests the information fields where correctly found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ENEL Forms: Location of Instruction Fields</head><p>In these experiments the documents were carefully placed on the scanbed, and, therefore, unlike the case reported in the previous subsection, the registration was not the major problem. For the recognition of the ENEL forms (Fig. <ref type="figure" target="#fig_4">4</ref>) we used a form graph composed of eight nodes, which is a subgraph of that represented in Fig. <ref type="figure" target="#fig_6">5</ref>, and a very simple registration graph with two nodes only (N 3 , N 4 ). As described in Section 3, the intersection of the lines corresponding to these nodes and the line corresponding to N 3 are used for the registration (Type fm = 3). Three information fields were found by locating the three instruction fields described in nodes N 5 , N 7 , and N 10 , corresponding to words Periodo, imponibile, and Totale respectively. Search regions for N 5 and N 10 had a size of 120 × 170 pixels, while the search region for N 7 was 140 × 170 pixels.</p><p>The 182 images were acquired by using a scanner HP scanjet 4C with ADF (automatic document feeder). The resolution was 200 × 200 dpi with 256 gray levels, and the size of the images is 1,259 × 708 pixels. In these experiments, all the forms were correctly registered to the model and the first hypothesis generated by the registration algorithm was always the correct one and the major problem was that of locating the instruction fields.</p><p>In order to analyze the computational burden of the system for what concerns the location of instruction fields, it turns out to be useful to compare Algorithm 3 with the straightforward approach in which the words are simply recognized by OCR. Let N i be the node corresponding to a generic instruction field located by means of function Rec-Word. Let N i j w , be the number of words found by function Rlsa in region Γ i of form ) j ( j = 1, …, m), N i j o , be the number of calls to function OCR when locating word N i in form Hence, we can estimate the improvement obtained using our method by means of</p><formula xml:id="formula_22">R N N Lm N Lm i w i o i i w i 2 &amp; = + + ◊<label>(3)</label></formula><p>where Lm i is the average length of the words extracted by function Rlsa in region Γ i for all the m forms. The parameter R 2 is reported in Table <ref type="table" target="#tab_4">2</ref>, for the three words used in the experiments and for different values of  threshold T 1 . As we expected, the computational cost roughly approximated by R 2 decreases as T 1 increases.</p><p>When choosing large values for T 1 , Algorithm 3 often exits the check on the edit distance, whereas small values for the threshold represent a severe constraint which forces the algorithm to check all the candidate words. The best performance in terms of computational cost were achieved for word Totale, while the worst performance were found for the word imponibile.</p><p>Table <ref type="table" target="#tab_5">3</ref> shows the performance on ENEL forms when changing the threshold T AA which is used for deciding when the autoassociator-based criterion is itself sufficient to recognize the instruction fields. Table <ref type="table" target="#tab_5">3</ref> shows that when choosing values for T AA below 0.3 the accuracy is very poor.</p><p>In that case, the scores of the first and second candidates are too close and the autoassociator-based criterion does not provide a reliable behavior. However, as can be seen in Table 3, a small increase of this threshold makes it possible to recover the errors, without a significant increase of the computational burden (see the parameter R 2 ). This is due to the important role played by the autoassociator neural network, that for values of T AA Ӎ 0.3 still limits significantly the calls to the OCR module. Note that the autoassociator neural network provides a significant contribution to the recognition process especially in the case of short words (e.g., compare the performance for the words Totale and imponibile).</p><p>As can be seen in Fig. <ref type="figure" target="#fig_14">11</ref>, the recognition errors is strongly affected by the thresholds T 1 and T 2 , but the be- The number of errors is denoted by N E , N R is the number of rejected forms, and N AA is the number of words located by using only the autoassociator. The experimental results corresponds to the choice of T 1 = 1.0 and T 2 = 3.0. havior is quite regular and one can easily choose these parameters so as to have neither recognition errors nor rejection of forms (for instance, T 1 = 1 and T 2 = 3.0). The number of rejected forms decreases when increasing the values of T 2 (plot A). We found that for values higher than 3.0 no words were rejected. On the other hand, the threshold T 1 plays a major role on the recognition error (see plot B). According to the previous analysis on the behavior of the autoassociator, T AA = 0.3 was chosen for the experimental results reported in Fig. <ref type="figure" target="#fig_14">11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, we have described a flexible and efficient system for extracting information from images of financial documents like invoices and bills of service companies. The document layout is described by means of a model based on attributed relational graphs. This representation allows the user to specify the document structure by describing the features of the objects used for form registration and location of information fields.</p><p>We have proposed a form registration technique which is based on the hypothesize and verify paradigm. The proposed solution makes it possible to process a wide variety of layouts containing objects like lines, keywords, and logos. The location of keywords is based on a novel approach which integrates the recognition of whole words, based on autoassociator neural networks, with an OCR-based approach, where the words are recognized on the basis of the optimization of the string edit distance carried out by dynamic programming. The location of the information fields is based on the form model which makes it possible to determine these fields once the corresponding instruction fields are detected.</p><p>The overall performance of the system has been evaluated reporting two real-world applications for the recognition of invoices made available by the University of Florence. The experimental results reported in the paper support our claims concerning the flexibility (the two type of invoices are significantly different) and the efficiency of the overall system architecture (basically, the recognition process takes place in real-time on ordinary workstation).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A typical bill emitted by Italian Electrical Company ENEL. As can be seen on the right side (containing a portion of another bill), the largest box has no fixed structure.</figDesc><graphic coords="2,30.38,60.99,509.22,169.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The basic structure of INFORMys, a flexible form-reader system, where the user can define the layout of its own documents in the class of invoice-like documents.</figDesc><graphic coords="3,79.33,60.99,406.03,175.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Geometrical interpretation of an arc as a vector. (a) An instruction and a related information field. (b) The vector r V i, j connecting nodes N i and N j , corresponding to the two fields in (a).</figDesc><graphic coords="4,93.05,60.99,390.64,74.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>DEFINITION 8 .</head><label>8</label><figDesc>First Matching Item.The first matching item is the pair I document registration.M fm and a fm denote the magnitude and the orientation of r V fm , respectively. The registration transformation can be evaluated in three ways, as described by parameter Type fm OE 1 2 3 , , &lt; A . If Type fm = 1 , then I fm is defined by a line node,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. An example of the description of a document. The pointed items (instruction fields, information fields, and lines) are used for creating the form graph described in Fig. 5.</figDesc><graphic coords="5,78.99,60.99,406.71,247.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Γ 1 , defined by points A = (40, 100) and B =(458,  114). N 8 describes an information field containing up to 10 digits and located into a rectangular region Γ 8 with E x = 80 and E y = 15. The location of the field is obtained by giving its position with respect to node N 7 by means of arc A 7,8 . In order to take into account the variable position of the instruction field corresponding to node N 7 , region Γ 7 is quite large (A = (47, 110), B = (210, 350)). Nodes N 10 and N 11 are used to locate the information field corresponding to node N 12 . In the form of Fig.4, neither N 10 nor N 11 contain enough information to locate N 12 . Basically, N 10 and N 11 provide the horizontal and vertical position of the information field, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. A typical )* associated with the items selected by the user during the form modeling phase of form shown in Fig. 4. The registration graph )* r , is composed of nodes N 1 , N 2 , N 3 , N 4 . A detailed description of the meaning of some nodes and arcs is given in the text.</figDesc><graphic coords="6,56.46,60.99,463.83,151.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>h 1 5</head><label>5</label><figDesc>(see Definition 8), during the hy- pothesize phase. The other items are found by applying the hypothesized transformation to the location described in the attributes of )* r v 0 5 nodes. The expanded region</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>, 4 9</head><label>4</label><figDesc>jects corresponding to the nodes N i r v OE )* 0 5 are searched in regions Γ i,j calculated according to transformation Hyp j . in turn, tests each hypothesis of / until one of them is successfully verified. If no hypothesis is successfully verified then the error margins (δ x , δ y ) are increased by δ xi and δ yi so as to identify a larger region and hypothesis generation and verification is repeated until the maximum values d d x y are reached. Algorithm 1 5(*,675$7,21$/*25,7+0 Input: the registration graph )* )the roto-translation r which makes )* r congruent with ), r = nil denotes that no registration is possible. begin δ x ← δ xo ; δ y ← δ yo ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .,.</head><label>6</label><figDesc>Fig. 6. Example for the registration algorithm. The registration graph, reported in (e), contains the horizontal lines pointed out in (a). The hypotheses are generated by using N N r h 1 1)* 0 5 &lt; A 4 9=</figDesc><graphic coords="8,201.73,434.23,113.05,93.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>EXAMPLE.In this example, the form registration is based on a registration graph (Fig.6e) whose first matching item is a line node N 1 . The registration graph )* r is composed of line nodes N 1 , N 2 , and N 3 . Type fm = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Location of the information field N 12 by giving its position with respect to two reference objects (line node N 11 and instruction field node N 10 ). The nodes and arcs are part of )* depicted in Fig. 5. Note that the actual size of word Totale and horizontal distance from N 10 to N 12 change in the two forms.</figDesc><graphic coords="10,60.88,212.98,454.96,142.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Two examples of forms issued by Italian TELECOM. The registration graph )* r has three nodes corresponding to the lines pointed in the the first form. Note that, due to the document displacement, the form in the right side of the figure does not contain the upper horizontal line.</figDesc><graphic coords="12,84.52,60.99,407.68,169.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>) 1 .</head><label>1</label><figDesc>A rough estimation of the computational cost can be carried out by considering idea of the number of calls to the OCR module in Algorithm 3. The parameter R 1 , however, does not take into account the processing time of function AA. In our system, this function and the OCR recognition are carried out by artificial neural networks with multilayer architecture. Although the evaluation of function AA is based on autoassociators instead of the classical classifier-based mode used for OCR, in our experimental choices the computational complexity associated with the feedforward step of the two network is in fact roughly comparable. As a result the cost of the computation of the OCR module turns out to be T(OCR) Ӎ n ⋅ T(AA), where T(AA) is the computational cost for calculating E[j] given word image W[j].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Accuracy of the recognition of instruction fields in ENEL forms. The two plots report the number of rejected forms N R and the number of errors N E corresponding to different choices of T 2 and T 1 .</figDesc><graphic coords="14,103.15,376.09,370.43,155.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,31.32,60.99,502.07,204.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Sx i , Sy i ), Net i } (Sx i , Sy i ) are the dimensions (in pixels) of the rectangle surrounding the logo. Net i is</head><label></label><figDesc>4. Node Description. Sx i , Sy i ), Txt i , Net i }. (Sx i , Sy i ) are the dimensions (in pixels) of the upright rectangle surrounding the word.</figDesc><table><row><cell>05, which indi-</cell></row><row><cell>cate where the search takes place (P i ) and provide information</cell></row><row><cell>for its execution (L i ).</cell></row><row><cell>• P i : where the search takes place. The searching area is a rectangle Γ i , which can be identified</cell></row><row><cell>in two different ways; the number of parameters that specify Γ i indicates which description is used.</cell></row><row><cell>-absolute location of the searching area. The searching area Γ i is identified by P</cell></row><row><cell>Let N i ∈ N be a node. Depending on its type T i , the node description is provided by function G N D ◊ 05 which generates</cell></row><row><cell>the following attributes:</cell></row><row><cell>• Line nodes.</cell></row><row><cell>D i Џ {Or i , Th i , Ln i , St i }. Or i can only be H or V, which is</cell></row><row><cell>for horizontal or vertical line, respectively. Th i and Ln i are</cell></row><row><cell>the thickness and the length of the line (in pixels). Finally St i ∈ {C, D} is the line style, which indicates whether the</cell></row><row><cell>line is continuous or dashed.</cell></row><row><cell>• Logo nodes.</cell></row><row><cell>D i Џ {(a</cell></row><row><cell>pointer to a set of parameters required by the logo recogni-</cell></row><row><cell>tion algorithm.</cell></row><row><cell>• Instruction field nodes.</cell></row><row><cell>D i Џ {(3</cell></row><row><cell>Txt i is the word textual information, that is, a string</cell></row><row><cell>corresponding to the word ASCII coding. Net i is a</cell></row><row><cell>pointer to a set of parameters needed by the word recog-</cell></row><row><cell>nition algorithm.</cell></row><row><cell>• Information field nodes. D i Џ {Type i , Min i , Max i }. Type i ∈ {X, A, 9} indicates</cell></row><row><cell>whether the field is alphanumeric, alphabetic, or numeric.</cell></row><row><cell>Min i and Max i indicate the minimum and maximum</cell></row><row><cell>number of characters that can be found in the field.</cell></row></table><note><p><p>i Џ {x A , y A , x B , y B }, which represent the coordinates of its top-left (A) and bottom-right (B) corners.</p>-relative location of the searching area.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 1 EXPERIMENTAL</head><label>1</label><figDesc>RESULTS FOR THE REGISTRATION ALGORITHM WHEN USING TELECOM FORMSThe four registration graphs are all equal apart from G 1 E , whose variable parameters are reported in the second and the third columns. The fourth column reports the mean CPU time required to register the forms. The last four columns report the number of forms which required the specified number of increments (N inc ) for δ x and δ y , (δ xi = 15, δ yi= 15). The size and center of Γ i and the values of δ yo are reported in pixel.</figDesc><table><row><cell>Form Graph</cell><cell>size of G 1 E</cell><cell>center of Γ 1</cell><cell>Mean CPU time</cell><cell></cell><cell>N inc</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(value of δ yo )</cell><cell></cell><cell>(seconds)</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>)* r 1</cell><cell>597 x 30 (δ yo = 10)</cell><cell>280, 114</cell><cell>0.21</cell><cell>88</cell><cell>10</cell><cell>2</cell><cell>0</cell></row><row><cell>)* r 2</cell><cell>597 x 157 (δ yo = 75)</cell><cell>280, 114</cell><cell>0.55</cell><cell>100</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>)* r 3</cell><cell>597 x 157 (δ yo = 75)</cell><cell>280, 54</cell><cell>0.59</cell><cell>90</cell><cell>9</cell><cell>1</cell><cell>0</cell></row><row><cell>)* r 4</cell><cell>597 x 30 (δ yo = 10)</cell><cell>280, 54</cell><cell>1.02</cell><cell>0</cell><cell>2</cell><cell>90</cell><cell>8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="5">EXPERIMENTAL RESULTS ON THE ENEL FORMS CONCERNING</cell></row><row><cell></cell><cell cols="3">THE LOCATION OF INSTRUCTION FIELDS</cell><cell></cell></row><row><cell>T 1</cell><cell>Totale</cell><cell>Periodo</cell><cell>imponibile</cell><cell>WRWDO</cell></row><row><cell>0.0</cell><cell>0.18</cell><cell>0.37</cell><cell>0.80</cell><cell>0.52</cell></row><row><cell>1.0</cell><cell>0.16</cell><cell>0.32</cell><cell>0.49</cell><cell>0.36</cell></row><row><cell>2.0</cell><cell>0.16</cell><cell>0.32</cell><cell>0.46</cell><cell>0.34</cell></row><row><cell>3.0</cell><cell>0.16</cell><cell>0.32</cell><cell>0.43</cell><cell>0.33</cell></row></table><note><p><p>This table contains the values of R 2 corresponding to different values of T 1 .</p>The column WRWDO contains global values for R 2 corresponding to the location of the three words in all the 182 forms. For these experiments we choose T AA = 0.3, T 2 = 3.0.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 3 PERFORMANCE</head><label>3</label><figDesc>ON ENEL FORMS WHEN CHANGING THE THRESHOLD T AA</figDesc><table><row><cell></cell><cell></cell><cell>Totale</cell><cell>Periodo</cell><cell>imponibile</cell><cell>WRWDO</cell></row><row><cell></cell><cell>N E</cell><cell>0</cell><cell>2</cell><cell>42</cell><cell>44</cell></row><row><cell>T AA = 0.1</cell><cell>N R</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>N AA</cell><cell>182</cell><cell>139</cell><cell>23</cell><cell>344</cell></row><row><cell></cell><cell>R 2</cell><cell>0.15</cell><cell>0.21</cell><cell>0.34</cell><cell>0.25</cell></row><row><cell></cell><cell>N E</cell><cell>0</cell><cell>0</cell><cell>6</cell><cell>6</cell></row><row><cell>T AA = 0.2</cell><cell>N R</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell>N AA</cell><cell>180</cell><cell>112</cell><cell>3</cell><cell>295</cell></row><row><cell></cell><cell>R 2</cell><cell>0.16</cell><cell>0.26</cell><cell>0.47</cell><cell>0.33</cell></row><row><cell></cell><cell>N E</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>T AA = 0.3</cell><cell>N R</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell>N AA</cell><cell>177</cell><cell>61</cell><cell>0</cell><cell>238</cell></row><row><cell></cell><cell>R 2</cell><cell>0.16</cell><cell>0.32</cell><cell>0.49</cell><cell>0.36</cell></row><row><cell></cell><cell>N E</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>T AA = 0.4</cell><cell>N R</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell>N AA</cell><cell>171</cell><cell>41</cell><cell>0</cell><cell>212</cell></row><row><cell></cell><cell>R 2</cell><cell>0.18</cell><cell>0.35</cell><cell>0.49</cell><cell>0.37</cell></row><row><cell></cell><cell>N E</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>T AA = 0.5</cell><cell>N R</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell>N AA</cell><cell>156</cell><cell>16</cell><cell>0</cell><cell>172</cell></row><row><cell></cell><cell>R 2</cell><cell>0.22</cell><cell>0.38</cell><cell>0.49</cell><cell>0.39</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>INFORMys is an acronym for "flexible INvoice-like FORM-reader system."</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>In particular, INFORMys is an Open Look application developed on Sun Sparc machines.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that the word location algorithm recognizes also words of different size, but with the same aspect-ratio as that described in D i . DEFINITION 5. Search Attributes. S i Џ {P i , L i } are the attributes generated by G N S ◊</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank E. Francesconi, J. Sheng, M. Di Domenico, and F. Bocciarelli for the development of some important software modules of INFORMys. The recognition of instruction fields and logos was made possible by TRENNS Neural Network simulator. We are indebted to Marco Maggini (TRENNS designer) who offered his invaluable assistance for the usage of the simulator. This research was partially supported by MURST40%.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Financial Document Processing Based on Staff Line and Description Language</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="738" to="753" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intelligent Forms Processing System</title>
		<author>
			<persName><forename type="first">R</forename><surname>Casey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mohiuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Walach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="143" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Extraction of Data From Preprinted Forms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fritzson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Pastor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-Based Analysis and Understanding of Check Forms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l J. Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Anatomy of a Form Reader</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Javanbakht</surname></persName>
		</author>
		<author>
			<persName><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second Int&apos;l Conf. Document Anal</title>
		<meeting>Second Int&apos;l Conf. Document Anal<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="506" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Layout Recognition of Multikinds of Table-Form Documents</title>
		<author>
			<persName><forename type="first">T</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugie</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="432" to="445" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Segmentation Methods for Character Recognition: From Segmentation to Document Structure Analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fujisawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kurino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-Domain Document Layout Understanding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. First Int&apos;l Conf. Document Anal. Recog</title>
		<meeting>First Int&apos;l Conf. Document Anal. Recog</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="112" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Processing of Form Documents</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second Int&apos;l Conf. Document Anal. Recog</title>
		<meeting>Second Int&apos;l Conf. Document Anal. Recog<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="497" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structure Recognition Methods for Various Types of Documents</title>
		<author>
			<persName><forename type="first">T</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugie</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="163" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Form Items Extraction by Model Matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. First Int&apos;l Conf. Document Anal</title>
		<meeting>First Int&apos;l Conf. Document Anal<address><addrLine>St. Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Four Directional Adjacency Graphs (fdag) and Their Application in Locating Fields in Forms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Int&apos;l Conf. Document Anal</title>
		<meeting>Third Int&apos;l Conf. Document Anal<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="752" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Graph Distance Measure for Image Analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Eshera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="398" to="408" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Image Understanding System Using Attributed Symbolic Representation and Inexact Graph-Matching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Eshera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="617" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Object Recognition by Computer, the Role of Geometric Constraints</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Object Registration for Visual Inspection Operations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf</title>
		<meeting>Int&apos;l Conf</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="987" to="993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Computational Model for Recognition of Multifont Word Images</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Vision and Applications</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Word Recognition Algorithm for Machine-Printed Word Images of Multiple Fonts and Varying Qualities</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Int&apos;l Conf. Document Anal</title>
		<meeting>Third Int&apos;l Conf. Document Anal<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="351" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Backpropagation Applied to Handwritten Zip Code Recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Document Skew Detection Method Using Run-Length Encoding and the Hough Transform</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hinds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>D'amato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Int&apos;l Conf. Pattern Recognition</title>
		<meeting>10th Int&apos;l Conf. Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="464" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Document Spectrum for Page Layout Analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>O'gorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="162" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nist Form-Based Handprint Recognition System. Nistir 5469</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Garris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dimmick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Janet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technology Administration, Nat&apos;l Inst. Standards and Technology</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>U.S. Dept. of Commerce</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Document Image Understanding: Integrating Recovery and Interpretation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Maryland, College Park</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Document Processing for Automatic Knowledge Acquisition</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="20" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning in Multilayered Networks Used as Autoassociators</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bianchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="512" to="515" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Autoassociator-Based Models for Speech Verification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lastrucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="241" to="250" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Hybrid System for Locating and Recognizing Low Level Graphic Items</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Tombre</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="135" to="147" />
			<date type="published" when="1996-03">Mar. 1996</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
	<note>Graphics Recognition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Document Image Defect Models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Baird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structured Document Image Analysis</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="547" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Neural-Based Architecture for Spot-Noisy Logo Recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Francesconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Conf. Document Analysis and Recognition</title>
		<meeting>Int&apos;l Conf. Document Analysis and Recognition<address><addrLine>Ulm, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-08">Aug. 1997</date>
			<biblScope unit="page" from="175" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic Programming Algorithm Optimization for Spoken Word Recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Acoustic Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="1978-02">Feb. 1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
