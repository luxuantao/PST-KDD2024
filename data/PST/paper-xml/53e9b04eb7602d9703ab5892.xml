<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Profile-assisted Compiler Support for Dynamic Predication in Diverge-Merge Processors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hyesoon</forename><surname>Kim</surname></persName>
							<email>hyesoon@ece.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">José</forename><forename type="middle">A Joao</forename><surname>Onur Mutlu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yale</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
							<email>patt@ece.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Profile-assisted Compiler Support for Dynamic Predication in Diverge-Merge Processors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dynamic predication has been proposed to reduce the branch misprediction penalty due to hard-to-predict branch instructions. A recently proposed dynamic predication architecture, the diverge-merge processor (DMP), provides large performance improvements by dynamically predicating a large set of complex control-flow graphs that result in branch mispredictions. DMP requires significant support from a profiling compiler to determine which branch instructions and control-flow structures can be dynamically predicated. However, previous work on dynamic predication did not extensively examine the tradeoffs involved in profiling and code generation for dynamic predication architectures.</p><p>This paper describes compiler support for obtaining high performance in the diverge-merge processor. We describe new profile-driven algorithms and heuristics to select branch instructions that are suitable and profitable for dynamic predication. We also develop a new profile-based analytical cost-benefit model to estimate, at compiletime, the performance benefits of the dynamic predication of different types of control-flow structures including complex hammocks and loops. Our evaluations show that DMP can provide 20.4% average performance improvement over a conventional processor on SPEC integer benchmarks with our optimized compiler algorithms, whereas the average performance improvement of the best-performing alternative simple compiler algorithm is 4.5%. We also find that, with the proposed algorithms, DMP performance is not significantly affected by the differences in profile-and run-time input data sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Branch misprediction penalty is an important limitation for highperformance processors, even after significant research in branch predictors. Predication eliminates branches and therefore avoids the misprediction penalty, but it requires significant modifications to the ISA and it can degrade performance when a statically if-converted branch could have been correctly predicted. Instances of the same static branch could be easy or hard to predict during different phases of a program execution. Dynamic predication allows the processor to predicate instructions without requiring a predicated ISA and to choose when to predicate at run-time <ref type="bibr" target="#b14">[15]</ref>. A processor that supports dynamic predication executes both paths of a branch until it reaches the control-flow convergence point of the branch. Instructions on both paths are executed but only the correct-path instructions update the architectural state.</p><p>Dynamic hammock predication was proposed for dynamic predication of simple hammock structures (simple if and if-else structures with no intervening control flow instructions) <ref type="bibr" target="#b14">[15]</ref>. The Diverge-Merge Processor (DMP) architecture extends the dynamic predication concept to more complex code structures <ref type="bibr" target="#b11">[12]</ref>. The key improvement of DMP over previous work is its ability to predicate control-flow shapes that are not simple hammocks statically but that look like simple hammocks when only frequently-executed control flow paths at run-time are considered. These control-flow shapes are termed as frequently-hammocks.</p><p>In the DMP architecture, branches that can be dynamically predicated (i.e. diverge branches) and the corresponding control-flow convergence/merge points (CFM-points) are identified by the compiler and conveyed to the hardware through the ISA. Diverge branches can be parts of either simple hammocks or frequently-hammocks. How the compiler selects diverge branches and CFM points and how the processor chooses when to predicate them at run-time are critical factors that determine the performance of dynamic predication in a DMP processor. Previous work did not explore compiler algorithms/heuristics and profiling mechanisms used to select diverge branches and CFM points. In this paper, we describe the compiler and profiling algorithms for a DMP processor and explore the tradeoffs involved in the design of these algorithms. We evaluate the impact of these algorithms on the performance of a DMP processor and provide insights into what is important to consider in the design of such algorithms.</p><p>This paper makes the following contributions:</p><p>1. To our knowledge, this is the first paper that develops detailed code generation algorithms for dynamic predication architectures. We provide insights into the design of a profiler/compiler targeted for a DMP architecture. We explain and quantitatively analyze the tradeoffs involved in making the design choices for the profiler/compiler, a key component of the DMP architecture. 2. We propose an analytical, profile-driven cost-benefit model for dynamic predication used by the compiler to decide candidate branches for dynamic predication. The proposed model can also be used for understanding the behavior of DMP and improving its microarchitecture. <ref type="bibr" target="#b2">3</ref>. We analyze the sensitivity of a DMP architecture to differences in profile-time and run-time input sets. We explain and analyze the issues involved in profiling for the DMP architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Dynamic Predication: Simple Hammocks [15]</head><p>Figure <ref type="figure">1</ref> shows the control-flow graph (CFG) of a simple hammock branch and the dynamically predicated instructions. Hammock branches are identified at run-time or marked by the compiler. When the processor fetches a hammock branch, it estimates whether or not the branch is hard to predict using a branch confidence estimator <ref type="bibr" target="#b8">[9]</ref>. If the branch has low confidence, the processor dynamically predicates instructions on both paths of the branch (i.e. the processor enters dynamic predication mode (dpred-mode) in Kim et al.'s terminology <ref type="bibr" target="#b11">[12]</ref>). The processor generates a predicate id using the branch condition, and instructions inside the hammock are assigned the generated predicate id. When the hammock branch is resolved, the predicate id is also resolved. Instructions on the wrong path (i.e. predicated-FALSE instructions) become NOPs after the branch is resolved, and they do not update the architectural state. When the processor reaches a control reconvergence point after fetching both paths of the branch, the processor inserts c-moves <ref type="bibr" target="#b10">[11]</ref> or select-µops <ref type="bibr" target="#b23">[24]</ref> to reconcile the register data values produced on either side of the hammock. Select-µops are similar to the φ-functions in the static single-assignment (SSA) form <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dynamic Predication: DMP [12]</head><p>DMP extends dynamic predication to complex CFGs. Figure <ref type="figure">2</ref> shows a CFG example to illustrate the key mechanism of DMP. The processor considers frequently executed paths at run-time, so it can dynamically predicate blocks B, C, and E. To simplify the hardware, DMP uses some control-flow information provided by the compiler. The compiler identifies conditional branches with control flow suitable for dynamic predication as diverge branches. A diverge branch is a branch instruction after which the execution of the program usually reconverges at a control-independent point in the CFG, a point called the control-flow merge (CFM) point. In other words, diverge branches result in hammock-shaped control flow based on frequently executed paths in the CFG of the program but they are not necessarily simple hammock branches that require the CFG to be hammock-shaped. The compiler also identifies at least one CFM point associated with the diverge branch. In this example, the compiler marks the branch at block A as a diverge branch and the entry of block H as a CFM point.</p><p>The DMP microarchitecture fetches both paths after a lowconfidence diverge branch and dynamically predicates instructions between the diverge branch and one of its CFM points during dpredmode. On each path, the processor follows the branch predictor outcomes until it reaches a CFM point. After the processor reaches the same CFM point on both paths, it exits dpred-mode and starts to fetch from only one path. When DMP exits dpred-mode, select-µops are inserted to reconcile the register data values that are produced on either side of the "dynamic hammock." DMP can also dynamically predicate loop branches. The benefit of predicating loop branches is that the pipeline does not need to be flushed if a predicated loop is iterated more times than it should be because the predicated instructions in the extra loop iterations will become NOPs. Further explanations about the diverge loop behavior are provided in Section 5.1 when we discuss compiler heuristics for choosing diverge loops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Compiler Algorithms for DMP Architectures</head><p>The compiler marks the diverge branches and their respective CFM points in a DMP binary. At run-time, the processor decides whether or not to enter dpred-mode based on the confidence estimation for a diverge branch. The hardware has relatively more accurate dynamic information on whether or not a diverge branch is likely to be mispredicted. However, it is difficult for the hardware to determine (1) the CFM point of a branch, (2) whether or not dynamically predicating a diverge branch would provide performance benefit. <ref type="foot" target="#foot_0">1</ref> The performance benefit of dynamic predication is strongly dependent on the number of instructions between a diverge branch and its corresponding CFM points (similarly to static predication <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b17">18]</ref>). In frequently-hammocks, the probability that both paths after a diverge branch reach a CFM point could be another factor that determines whether or not dynamically predicating the diverge branch would be beneficial for performance. Since the compiler has easy access to both CFG information and profiling data to estimate frequently executed paths, it can estimate which branches and CFM points would be good candidates to be dynamically predicated. Thus, in this section, we develop profile-driven compiler algorithms to solve the following new problems introduced by DMP processors:</p><p>1. DMP introduces a new CFG concept: frequently-hammocks.</p><p>We develop a compiler algorithm to find frequently-hammocks and their corresponding CFM points. 2. DMP requires the selection of diverge branches and corresponding CFM points that would improve performance when dynamically predicated. We develop compiler algorithms to determine which branches should be selected as diverge branches and which CFM point(s) should be selected as corresponding CFM point(s). Simple algorithms and heuristics are developed in this section and a more detailed cost-benefit model is presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Diverge Branch Candidates</head><p>We consider four types of diverge branches based on the CFG types they belong to. Simple hammock (Figure <ref type="figure" target="#fig_1">3a</ref>) is an if or if-else structure that does not have any control-flow instructions inside the hammock. Nested hammock (Figure <ref type="figure" target="#fig_1">3b</ref>) is an if-else structure that has multiple levels of nested branches. Frequentlyhammock (Figure <ref type="figure" target="#fig_1">3c</ref>) is a complex CFG, which is not a simple/nested hammock, but becomes a simple hammock if we consider only frequently executed paths. Loop (Figure <ref type="figure" target="#fig_1">3d</ref>) is a cyclic CFG (for, do-while, or while structure) with the diverge branch as a loop exit branch. We also classify CFM points into two categories: exact and approximate. Exact CFM points are those that are always reached from the corresponding diverge branch, independently of the actually executed control-flow paths between the branch and the CFM point. In other words, an exact CFM point is the immediate post-dominator (IPOSDOM) of the diverge branch. Approximate CFM points are those that are reached from the corresponding diverge branch only on the frequently-executed paths. Simple and nested hammocks and single-exit loops have only exact CFM points. Frequently-hammocks have approximate CFM points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithm to Select Simple/Nested Hammock Diverge Branches and Exact CFM Points</head><p>Algorithm 1 (Alg-exact) describes how to find and select simple and nested hammock diverge branches that have exact CFM points. Simple and nested hammocks have strictly one exact CFM point, which is the IPOSDOM of the branch. We use Cooper et al.'s algorithm <ref type="bibr" target="#b3">[4]</ref> to find the IPOSDOM. Our algorithm uses the number of instructions and the number of conditional branches between the branch and the CFM point to select diverge branches among the possible candidates. This algorithm eliminates candidates that can reconverge only after a large number of instructions (M AX IN ST R) on any path. This is because the benefit of DMP processors comes from fetching and possibly executing instructions following the CFM point after dynamically predicating both paths of a diverge branch. Such controlindependent instructions do not have to be flushed when the diverge branch is resolved. If either the taken or the not-taken path of the diverge branch is too long, the processor's instruction window is likely to be filled before reaching the CFM point, thereby reducing the potential benefit of DMP. Additionally, instructions on the wrong path of the dynamically-predicated branch consume machine resources, increasing the overhead of predication. Therefore, a branch with a potentially long wrong path before the CFM point (i.e. a branch that has a large number of instructions between itself and its CFM point) is not a good candidate for dynamic predication and is not selected as a diverge branch by our algorithm.</p><p>Alg-exact also eliminates candidates with a large number of conditional branches (M AX CBR) on any path from the branch to the CFM point. DMP can enter dpred-mode for only one branch at a time. Limiting the number of conditional branches that are allowed between a diverge branch and its CFM point reduces the likelihood of another low-confidence branch occurring on a predicated path. Since the number of conditional branches is correlated with the number of instructions, we conservatively use M AX CBR = M AX IN ST R/10 in all experiments. We experiment with different values for M AX IN ST R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Algorithm to Select Frequently-hammock Diverge Branches and Approximate CFM Points</head><p>Algorithm 2 (Alg-freq) describes our algorithm for finding and selecting frequently-hammock diverge branches and their approximate CFM points. The algorithm uses edge profiling information to determine frequently executed paths.</p><p>While traversing the CFG to compute paths after a branch, only directions (taken/not-taken) that were executed with at least M IN EXEC P ROB during the profiling run are followed. This threshold (set to 0.001) eliminates the exploration of extremely infrequently executed paths during the search for paths that merge at CFMs, reducing the processing time of the algorithm.</p><p>In addition to M AX IN ST R and M AX CBR, the algorithm for selecting frequently-hammocks uses the probability of merging at each CFM point (M IN M ERGE P ROB) and the number of CFM points (M AX CF M ). The CFM point candidates with the highest probability of being reached on both paths during the profiling run are selected by our algorithm because dynamic predication provides more benefit if both paths of a diverge branch reach a corresponding CFM point. <ref type="foot" target="#foot_1">2</ref> If the profiled probability of reaching a CFM point candidate is lower than a threshold (M IN M ERGE P ROB), the CFM point candidate is not selected as a CFM point. Selecting multiple CFM points for a diverge branch increases the likelihood that the predicated paths after a diverge branch will actually reconverge and thus increases the likelihood that dynamic predication would provide performance benefits. Since we found that using three CFM Algorithm 2 Finding and selecting frequently-hammock diverge branches and approximate CFM points (Alg-freq)  for each basic block X reached on both the taken and the nottaken directions of B do 5:</p><p>pT (X) ← edge-profile-based probability of X being reached on the taken direction of B 6:</p><p>pNT (X) ← edge-profile-based probability of X being reached on the not-taken direction of B 7:</p><p>probability of merging at X ← p T (X) * p N T (X) select up to M AX CF M CFM point candidates for B, the ones with the highest probability of merging at X 13: end for points is enough to get the full benefit of our algorithms, we set M AX CF M = 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">A chain of CFM Points</head><p>Figure <ref type="figure" target="#fig_4">4</ref> shows a possible CFG with two CFM point candidates, C and D, for the branch at A. The DMP processor stops fetching from one path when it reaches the first CFM point in dpred-mode. Since the taken path of the diverge branch candidate at A always reaches C before it reaches D, even if both C and D are selected as CFM points, dynamic predication would always stop at C. D would never be reached by both dynamically-predicated paths of the branch at A in dpred-mode, and thus choosing D as a CFM point does not provide any benefit if C is chosen as a CFM point. Therefore, the compiler should choose either C or D as a CFM point, but not both. In general, if a CFM point candidate is on any path to another CFM point candidate, we call these candidates a chain of CFM points. The compiler identifies chains of CFM point candidates based on the list of paths from the diverge branch to each CFM point candidate, generated by Alg-freq. Then, the compiler conservatively chooses only one CFM point in the chain, the one with the highest probability of merging. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Short Hammocks</head><p>Frequently-mispredicted hammock branches with few instructions before the CFM point are good candidates to be always predicated, even if the confidence on the branch prediction is high. The reason for this heuristic is that while the cost of mispredicting a short-hammock 3 When there is a chain of CFM points, the probability of merging at X in Alg-freq has to be modified to compute the probability of both paths of the diverge branch actually merging at X for the first time, instead of just reaching X. For the diverge branch candidate A in Figure <ref type="figure" target="#fig_4">4</ref>  branch is high (flushing mostly control-independent instructions that were fetched after the CFM point), the cost of dynamic predication of a short-hammock branch is low (useless execution of just the few instructions on the wrong-path of the branch). Therefore, always predicating short-hammock diverge branch candidates with very low dynamic predication cost is a reasonable trade-off. Our experiments found that always predicating hammocks that execute fewer than 10 instructions on each path, that have a probability of merging of at least 95%, and that have a branch misprediction rate of at least 5% provides the best performance.</p><p>Note that, with this heuristic, diverge branch-CFM point pairs that are identified as short hammocks are always predicated, unlike regular hammocks. Therefore, any other CFM point candidates found for the same diverge branch that do not qualify as short hammocks are not selected as CFM points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Return CFM points</head><p>Some function calls are ended by different return instructions on the taken and not-taken paths of a diverge branch. In this case, the CFM point is the instruction executed after the return, whose address is not known at compile time because it depends on the caller position. We introduce a special type of CFM point called return CFM to handle this case. When a diverge branch includes a return CFM, the processor does not look for a particular CFM point address to end dpred-mode, but for the execution of a return instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Compile-Time Cost-Benefit Analysis of Dynamic Predication</head><p>In the basic algorithms presented in Section 3 (Alg-exact and Alg-freq), the compiler uses several simple heuristics to select diverge branches and CFM points that are likely to provide performance benefit during dynamic predication. These algorithms require the M AX IN ST R, M AX CBR, and M IN M ERGE P ROB thresholds to be optimized. Determining an effective combination of these parameters may require several iterations. In this section, we present an analytical cost-benefit model to select diverge branches and CFM points whose dynamic predication is likely to be beneficial for overall performance. The cost-benefit model still uses Algexact and Alg-freq to find diverge branch and CFM point candidates, but instead of filtering candidates with the compile-time fixed M IN M ERGE P ROB, M AX IN ST R, and M AX CBR parameters, it performs a profile-driven cost-benefit analysis. <ref type="foot" target="#foot_2">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Simple/Nested Hammocks</head><p>During dpred-mode, DMP always incurs some performance overhead in terms of execution cycles. The overhead of dynamic predication (dpred overhead) is due to the fetch and possible execution of useless (i.e. wrong-path) instructions. We describe how a profiling compiler can model the overhead of dynamic predication and make decisions as to whether or not dynamically predicating a branch instruction would be beneficial for performance.</p><p>There are two cases for which the cost of dynamic predication of a branch is different. First, if a diverge branch would actually have been correctly predicted, entering dpred-mode for that branch results only in overhead (dpred overhead) without providing any benefit. Second, if a diverge branch would actually have been mispredicted, entering dpred-mode for that branch results in both overhead (dpred overhead) and performance benefit that is equivalent to saving the branch misprediction penalty (misp penalty cycles). Hence, the overall cost of dynamic predication (dpred cost) in terms of cycles can be computed as: dpred cost = dpred overhead * P (enter dpred corr pred) +(dpred overhead − misp penalty) * P (enter dpred misp) (1)</p><formula xml:id="formula_0">P (enter dpred corr pred) = 1 − Acc Conf<label>(2)</label></formula><formula xml:id="formula_1">P (enter dpred misp) = Acc Conf (3)</formula><p>dpred overhead: Overhead of dynamic predication in cycles P (enter dpred corr pred): Probability of entering dpred-mode when a branch is correctly predicted P (enter dpred misp): Probability of entering dpred-mode when a branch is mispredicted misp penalty: Machine-specific branch misprediction penalty in cycles Acc Conf : The accuracy of the confidence estimator (i.e. the fraction of lowconfidence branches that are actually mispredicted)</p><p>The compiler decides to select a branch as a diverge branch if the cost of dynamic predication, as determined using Equation <ref type="bibr" target="#b0">(1)</ref>, is less than zero (i.e. if the benefit of dynamic predication is positive in terms of execution cycles):</p><p>Select a branch as a diverge branch if dpred cost &lt; 0 (4)</p><p>Note that the probability of entering dpred-mode when a branch is correctly predicted versus when it is mispredicted is a function of the accuracy of the hardware confidence estimator <ref type="bibr" target="#b8">[9]</ref>. Confidence estimator accuracy (defined as the percentage of low-confidence branches that are actually mispredicted, i.e. PVN <ref type="bibr" target="#b5">[6]</ref>) is usually between 15%-50% and is dependent on confidence estimator parameters such as the threshold values used in the design <ref type="bibr" target="#b5">[6]</ref>. In the calculation of the cost of dynamic predication, the compiler can use the average accuracy of the confidence estimator based on the set of profiled benchmarks or it can obtain the accuracy of the confidence estimator for each individual application and use that per-application accuracy. In our analysis the compiler uses one accuracy value (Acc Conf = 40%) for all applications.<ref type="foot" target="#foot_3">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Estimation of the overhead of dynamic predication</head><p>To calculate the overhead of dynamic predication (dpred overhead), the compiler first estimates the number of instructions fetched between a diverge branch candidate and the corresponding CFM point (N (dpred insts)). The compiler can estimate N (dpred insts) in three different ways: (1) based on the most frequently-executed two paths (using profile data), (2) based on the longest path between the diverge branch candidate and the CFM point, (3) based on the average number of instructions obtained using edge profile data. Equations 5-11 show how the compiler calculates N (dpred insts) with these three different methods using the example presented in Figure <ref type="figure">2</ref>. Note that the most frequently executed paths are shaded in Figure <ref type="figure">2</ref>. In the equations, N(X) is the number of instructions in block X, and P(XY) is the edge probability from basic block X to Y. <ref type="foot" target="#foot_4">6</ref> In our experiments, we evaluate methods 2 and 3.</p><formula xml:id="formula_2">N (dpred insts) = N (BH) + N (CH)<label>(5)</label></formula><p>N(BH): Estimated number of insts from block B to the beginning of block H N(CH): Estimated number of insts from block C to the beginning of block H</p><p>(Method 1) Based on the most frequently-executed two paths:</p><formula xml:id="formula_3">N(BH) = N (B) + N (E)<label>(6)</label></formula><formula xml:id="formula_4">N (CH) = N (C)<label>(7)</label></formula><p>(Method 2) Based on the longest possible path:</p><formula xml:id="formula_5">N(BH) = M AX{N(B) + N (D) + N (F ), N (B) + N (D) + N (E), N(B) + N(E)}<label>(8)</label></formula><formula xml:id="formula_6">N (CH) = N (C) + N(G)<label>(9)</label></formula><p>(Method 3) Based on the edge profile data (i.e. average number of </p><formula xml:id="formula_7">N (CH) = N (C) + P (CG) * N (G)<label>(10)</label></formula><p>Because not all of the instructions fetched in dpred-mode are useless, the compiler also estimates the number of instructions that are actually useful (i.e. those that are on the correct path). The number of instructions on the correct path in dpred-mode (N (usef ul dpred insts)) is calculated as follows. N (BH) and N (CH) can be calculated with any of above three methods.</p><p>N (usef ul dpred insts) = P (AB) * N (BH) + P (AC) * N (CH) <ref type="bibr" target="#b11">(12)</ref> Once the compiler has computed N (dpred insts) and N (usef ul dpred insts), it can calculate dpred overhead. We calculate dpred overhead in terms of fetch cycles. The actual cost of dynamic predication is the sum of its fetch overhead and execution overhead. Unfortunately, modeling the execution overhead is very complicated in an out-of-order processor due to the dataflowbased dynamic execution (which requires an analytical model of benchmark-dependent data dependence behavior as well as a model of dynamic events that affect execution). Furthermore, DMP does not execute predicated-FALSE instructions after the predicate value is known, so the execution overhead is likely not as high as the fetch overhead. Therefore, we model only the fetch overhead of dynamic predication in our cost-benefit analysis. The overhead of dynamically predicating a branch in terms of fetch cycles is thus calculated as: N (useless dpred insts) =N (dpred insts) − N (usef ul dpred insts) <ref type="bibr" target="#b12">(13)</ref> dpred overhead = N (useless dpred insts)/f w <ref type="bibr" target="#b13">(14)</ref> f w: Machine-specific instruction fetch width useless dpred insts: Useless instructions fetched during dpred-mode</p><p>Combining Equation <ref type="bibr" target="#b13">(14)</ref> with Equations ( <ref type="formula">1</ref>) and ( <ref type="formula">4</ref>) gives us the final equation used by the compiler to decide whether or not a branch should be selected as a diverge branch: Select a branch as a diverge branch if {N (useless dpred insts)/f w} * P (enter dpred corr pred) +{(N (useless dpred insts)/f w) − misp penalty} * P (enter dpred misp) &lt; 0 (15)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Frequently-hammocks</head><p>The overhead of predicating frequently-hammocks is usually higher than that of predicating simple or nested hammocks. With a frequently-hammock, the processor might not reach the corresponding CFM point during dpred-mode. In that case, the processor wastes half of the fetch bandwidth to fetch useless instructions until the diverge branch is resolved. On the other hand, if the processor reaches the CFM point in dpred-mode, the predication overhead of frequentlyhammocks is the same as that of simple/nested hammocks, as calculated in Equation <ref type="bibr" target="#b13">(14)</ref>. Therefore, we use the following equation to calculate the dynamic predication overhead of a frequently-hammock: The resulting dpred overhead is plugged into Equations ( <ref type="formula">1</ref>) and (4) to determine whether or not selecting a frequently-hammock branch as a diverge branch would be beneficial for performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Diverge Branches with Multiple CFM Points</head><p>So far, we have discussed how the compiler selects diverge branches assuming that there is only one CFM point for each diverge branch. However, in frequently-hammocks, there are usually multiple CFM point candidates for a branch. After reducing the list of CFM point candidates according to Section 3.3.1, the overhead of dynamically predicating a diverge branch with multiple CFM points is computed assuming all CFM points (Xi) are independent: If the diverge branch candidate satisfies Equations ( <ref type="formula">1</ref>) and (4) after using the dpred overhead developed in Equation ( <ref type="formula">17</ref>), the branch is selected as a diverge branch with its reduced list of CFM points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Limitations of the Model</head><p>Note that we make the following assumptions to simplify the construction of the cost-benefit analysis model:</p><p>1. The processor can fetch f w (f etchwidth) number of instructions all the time. There are no I-cache misses or fetch breaks. 2. During dpred-mode, the processor does not encounter another diverge branch or a branch misprediction. 3. When the two predicated paths of a diverge branch do not merge, half of the fetched instructions are useful. This is not always true because the processor may reach the CFM point on one path. In that case, the processor would fetch instructions only from the path that did not reach the CFM point, which may or may not be the useful path. 4. The overhead of the select-µops is not included in the model.</p><p>We found that this overhead is negligible; on average less than 0.5 fetch cycles per entry into dpred-mode.</p><p>Especially the first three assumptions do not always hold and therefore limit the accuracy of the model. However, accurate modeling of these limitations requires fine-grain microarchitecturedependent, application-dependent, and dynamic-event-dependent information to be incorporated into the model, which would significantly complicate the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Diverge Loop Branches</head><p>DMP dynamically predicates low-confidence loop-type diverge branches to reduce the branch misprediction penalty in loops. If a mispredicted forward (i.e. non-loop) branch is successfully dynamically predicated, performance will likely improve. However, this is not necessarily true for loop branches. With dynamically-predicated loop branches, there are three misprediction cases (early-exit, late-exit and no-exit; similarly to wish loops <ref type="bibr" target="#b12">[13]</ref>). Only the late-exit case provides performance benefit (see below). Hence, the cost-benefit analysis of loops needs to consider these different misprediction cases. In this section, we provide a cost-benefit model for the dynamic predication of diverge loop branches and describe simple heuristics to select diverge loop branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Cost-Benefit Analysis of Loops</head><p>The overhead of correctly-predicted case: Entering dpred-mode when a diverge loop branch is correctly predicted has performance overhead due to the select-µops inserted after each dynamicallypredicated iteration. We model the cost of select-µops based on the number of fetch cycles they consume as shown below:</p><formula xml:id="formula_9">dpred overhead = N (select uops) * dpred iter/f w<label>(18)</label></formula><p>N(select uops): The number of select-µops inserted after each iteration dpred iter: The number of loop iterations during dpred-mode</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misprediction case 1 (Early-exit):</head><p>During dpred-mode, if the loop is iterated fewer times than it should be, the processor needs to execute the loop at least one more time, so it flushes its pipeline. Hence, the early-exit case has only the overhead of select-µops and no performance benefit. The overhead is calculated the same way as in the correctly predicted case (Equation ( <ref type="formula" target="#formula_9">18</ref>)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misprediction case 2 (Late-exit):</head><p>During dpred-mode, if the loop is iterated a few times more than it should be, the misprediction case is called late-exit. Late exit is the only case for which the dynamic predication of a loop branch provides performance benefit because the processor is able to fetch useful control-independent instructions after the loop exit. In this case, the overhead is due to the cost of selectµops and extra loop iterations (that will become NOPs). However, instructions fetched after the processor exits the loop are useful and therefore not included in the overhead. The overhead of the late-exit case is thus calculated as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misprediction case 3 (No-exit):</head><p>If the processor has not exited a dynamically-predicated loop until the loop branch is resolved, the processor flushes the pipeline just like in the case of a normal loop branch misprediction. Hence, the no-exit case has only overhead, which is the cost of select-µops as calculated in Equation <ref type="bibr" target="#b17">(18)</ref>.</p><p>Thus, the total cost of dynamically predicating a loop is: </p><formula xml:id="formula_10">dpred cost =</formula><p>dpred overhead(X): dpred overhead of case X</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Heuristics to Select Diverge Loop Branches</head><p>According to the cost-benefit model presented in Section 5.1, the cost of a diverge loop branch increases with (1) the number of instructions in the loop body, (2) the number of select-µops (We found this is strongly correlated with the loop body size), (3) the average number of dynamically-predicated loop iterations (dpred iter), (4) the average number of extra loop iterations (dpred extra iter) in the late-exit case, and (5) the probability of a dynamic predication case other than late-exit. Unfortunately, a detailed cost-benefit analysis of each dynamic predication case requires the collection of per-branch profiling data obtained by emulating the behavior of a DMP processor. In particular, determining the probability of each misprediction case, the number of dynamically predicated iterations, and the number of extra iterations in the late-exit case requires either profiling on a DMP processor (with specialized hardware support for profiling) or emulating a DMP processor's behavior in the profiler. Since such a profiling scheme is impractical due to its cost, we use simple heuristics that take into account the insights developed in the cost-benefit model to select diverge loop branches. These heuristics do not select a loop branch as a diverge branch if any of the following is true:</p><p>1. If the number of instructions in the loop body is greater than ST AT IC LOOP SIZE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">If the average number of executed instructions from the loop</head><p>entrance to the loop exit (i.e. the average number of instructions in the loop body times the average loop iteration count) based on profile data is greater than DY N AM IC LOOP SIZE. We found that there is a strong correlation between the average number of loop iterations and dpred extra iter. Hence, this heuristic filters branches with relatively high dpred overhead for the late-exit case based on Equation <ref type="bibr" target="#b18">(19)</ref>.</p><p>3. If the average number of loop iterations (obtained through profiling) is greater than LOOP IT ER. We found that when a branch has high average number of loop iterations, it has high P (no exit).</p><p>In our experiments, we use ST AT IC LOOP SIZE = 30, DY N AM IC LOOP SIZE = 80, and LOOP IT ER = 15, which we empirically determined to provide the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Control-flow Analysis and Selection of Diverge Branch Candidates</head><p>We developed a binary analysis toolset to analyze the controlflow graphs, implement the selection algorithms presented in Section 3, and evaluate the diverge branch candidates using the costbenefit model developed in Sections 4 and 5. The result of our analysis is a list of diverge branches and CFM points that is attached to the binary and passed to a cycle-accurate execution-driven performance simulator that implements a diverge-merge processor.</p><p>A limitation of our toolset is that the possible targets of indirect branches/calls are not available because our tool does not perform data flow analysis. Therefore, we cannot exploit possible diverge branches whose taken/not-taken paths encounter indirect branches/calls before reaching a CFM point. Implementing our techniques in an actual compiler can overcome this limitation because a compiler has source-level information about the targets of indirect branches/calls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Simulation Methodology</head><p>We use an execution-driven simulator of a processor that implements the Alpha ISA. The parameters of the baseline processor and the additional support needed for DMP are shown in Table <ref type="table" target="#tab_4">1</ref>. The experiments are run using the 12 SPEC CPU2000 integer benchmarks and 5 SPEC 95 integer benchmarks. <ref type="foot" target="#foot_5">7</ref> Table <ref type="table" target="#tab_5">2</ref> shows the relevant characteristics of the benchmarks. All binaries are compiled for the Alpha ISA with the -fast optimizations. The benchmarks are run to completion with a reduced input set <ref type="bibr" target="#b15">[16]</ref> to reduce simulation time. Section 7.3 presents results obtained when the train input sets are used for profiling. All other sections present results with the reduced input set used for profiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Diverge Branch Selection Algorithms</head><p>Figure <ref type="figure" target="#fig_9">5</ref> shows the performance improvement of DMP with different diverge branch selection algorithms. The left graph in Figure <ref type="figure" target="#fig_9">5</ref> shows the performance impact of adding the results of each selection algorithm one by one cumulatively: Alg-exact (exact), Alg-freq (exact+freq), short hammocks (exact+freq+short), return CFM points (exact+freq+short+ret), and loops (exact+freq+short+ret+loop). <ref type="foot" target="#foot_6">8</ref> All algorithms use thresholds that are empirically determined to provide the best performance.</p><p>According to Figure <ref type="figure" target="#fig_9">5</ref> (left) the performance benefit of DMP increases as we cumulatively employ our diverge branch selection tech-  niques. Using just Alg-exact, DMP provides a performance improvement of 4.5%. However, when all our techniques are used, the performance improvement of DMP increases to 20.4%. Figure <ref type="figure" target="#fig_11">6</ref> provides insight into the performance increases by showing the number of pipeline flushes in the baseline processor and in DMP. As we employ more and more of the proposed branch selection algorithms, the number of pipeline flushes due to branch mispredictions decreases. These results demonstrate that the proposed mechanisms are effective at selecting diverge branches that provide performance benefits when dynamically predicated.</p><p>As shown in Figure <ref type="figure" target="#fig_9">5</ref> (left), selecting frequently-hammocks (Algfreq) improves average performance by 10% on top of Alg-exact. Hence, the selection of frequently-hammocks is the largest contributor to the performance of dynamic predication. Always predicating short hammocks improves performance by 2.2% on average and by more than 4% in vpr (12%), mcf (14%) and twolf (4%). Vpr and twolf have many short hammocks that are highly mispredicted and, thus, always predicating them provides significant improvements. In mcf, the most highly mispredicted branch is a short hammock branch whose predication provides a 14% performance benefit. Including return CFM points improves performance by 0.8% on average and by  more than 3% in twolf (8%) and go (3.5%). Twolf and go have many hammocks inside function calls that merge at different return instructions. Those hammocks cannot be diverge branches without the return CFM point mechanism. Finally, selecting diverge loop branches using the heuristics described in Section 5 provides an additional 1.7% av-erage performance improvement, especially in gzip (6%) and parser (14%). Parser has a frequently-executed small loop in which an input word is compared to a word in the dictionary. The exit branch of this loop is frequently mispredicted (because the lengths of the input words are not predictable), and therefore its dynamic predication results in a large performance benefit.</p><p>The right graph in Figure <ref type="figure" target="#fig_9">5</ref> shows the performance improvement of DMP if we use the cost-benefit analysis developed in Section 4 to select diverge branches. The compiler uses two different methods to calculate the overhead of dynamic predication: longest path (costlong), method 2 in Section 4.1.1, and edge-profile-based average path (cost-edge), method 3 in Section 4.1.1. The cost-edge method provides slightly higher performance than the cost-long method because cost-edge calculates the overhead of dynamic predication more precisely. Figure <ref type="figure" target="#fig_9">5</ref> (right) also shows the performance impact of adding each algorithm in sequence with the edge-profiling based cost-benefit analysis: always predicating short hammocks (cost-edge+short), return CFM points (cost-edge+short+ret), and diverge loops (cost-edge+short+ret+loop). 9 Using all these optimizations in conjunction with cost-edge results in 20.2% performance improvement over the baseline processor. Therefore, we conclude that using cost-benefit analysis (which does not require the optimization of any thresholds) to determine diverge branches can provide the same performance provided by using optimized threshold-based heuristics in conjunction with Alg-exact and Alg-freq. Note that not selecting the best thresholds results in an average performance loss of as much as 3%. Therefore, optimizing the thresholds used in our heuristic-based selection algorithms is important to obtain the best performance. This observation also argues for the use of the analytical cost-benefit model that does not require the optimization of any thresholds to provide equivalent performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1.">Effect of Optimizing Branch Selection Thresholds</head><p>Another conclusion from Figure <ref type="figure" target="#fig_12">7</ref> is that selecting only those CFM points with a large merging probability (M IN M ERGE P ROB = 90%) provides most of the per-9 cost-edge+short+ret+loop is called All-best-cost in the rest of the paper. formance benefit in DMP. Adding CFM point candidates with smaller merge probabilities incrementally improves average performance by at most 3%, but selecting candidates with a merge probability lower than 30% provides only negligible (less than 0.1%) benefit. Thus, DMP gains most of its performance from the frequently executed paths in which control-flow is very likely to merge at a control-independent point. This result can be used to optimize (i.e. reduce) the number of CFM points supported by the DMP ISA, but a thorough discussion of the tradeoffs in the DMP ISA is out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Comparisons with Other Diverge Branch Selection Algorithms</head><p>Since there is no previous work on compilation for DMP processors, we compare our algorithms with several simple algorithms to select diverge branches. Figure <ref type="figure" target="#fig_14">8</ref> compares the performance of six different algorithms: (1) Every-br: This is the extreme case where all branches in the program are selected as diverge branches, (2) Random-50: 50% of all branches are randomly selected, (3) High-BP-5: All branches that have higher than 5% misprediction rate during the profiling run are selected, (4) Immediate: All branches that have an IPOSDOM are selected. <ref type="bibr" target="#b4">(5)</ref> If-else: Only if and if-else branches with no intervening control-flow are selected, (6) All-best-heur: Our best-performing algorithm. Note that for the simple algorithms (1), ( <ref type="formula" target="#formula_0">2</ref>) and <ref type="bibr" target="#b2">(3)</ref>, not all branches have corresponding CFM points. <ref type="foot" target="#foot_7">10</ref> If there is no CFM point for a low-confidence diverge branch, then the processor stays in dpred-mode until the branch is resolved, and any performance benefit would come from dual-path execution.</p><p>Figure <ref type="figure" target="#fig_14">8</ref> shows that Every-br, High-BP-5, and Immediate are the best-performing simple algorithms for selecting diverge branches with average performance improvements of 4.4%, 4.3% 4.5% respectively. However, none of these other algorithms provide as large performance improvements as our technique, which improves average performance by 20.4%. We conclude that our algorithms are very effective at identifying good diverge branch candidates.</p><p>Note that Every-br, High-BP-5, and Immediate show relatively large performance improvements in benchmarks where a large percentage of the mispredicted branches are simple hammock branches (e.g. eon, perlbmk, and li). Only in gcc does one simple algorithm (Every-br) perform almost as well as our scheme. Gcc has very complex CFGs (that usually do not result in frequently-hammocks), so there are few diverge branch candidates. Gcc also has a very high branch misprediction rate (7%). Every-br allows the processor to enter dpred-mode for all low-confidence branches, which covers 62% of all mispredicted branches. Therefore, Every-br provides a similar performance improvement as that of entering dpred-mode for only carefully selected branches, which covers only 30% of all mispredicted branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Input Set Effects</head><p>We developed the algorithms and heuristics in previous sections by profiling and evaluating with the same input set to exclude the effects of input-set variations on the evaluation. In this experiment, we use the same algorithms and the same heuristic values developed in the previous sections, but we profile with the train input set to select diverge branches and CFM points. Figure <ref type="figure">9</ref> shows the DMP performance when the profiling input set is the same as the run-time input set (same) versus when the profiling input set is different from the run-time input set (diff). The compiler uses the best performing heuristic-based optimizations (All-best-heur-same, All-best-heur-diff) and the cost-benefit model with all optimizations (All-best-cost-same, All-best-cost-diff).</p><p>Figure <ref type="figure">9</ref> shows that the performance improvement provided by DMP is 19.8% (both All-best-heur-diff and All-best-cost-diff) when different input sets are used for profiling and actual runs. These improvements are only very slightly (0.5%) lower than when the same input set is used for profiling and actual runs. Only in gzip does profiling with the same input set significantly outperform profiling with a different input set (by 6%) when the compiler uses All-best-heur to select diverge branches. Hence, we find that DMP performance is not significantly sensitive to differences in the profile-time and run-time input sets.</p><p>Figure <ref type="figure">10</ref> shows whether or not the compiler finds the same set of diverge branches across input sets. We classify diverge branches into three groups: (1) Only-run: branches that are selected only when the compiler uses the run-time input set (MinneSPEC's reduced input set <ref type="bibr" target="#b15">[16]</ref>) for profiling, (2) Only-train: branches that are selected only when the compiler uses a different input set (SPEC's train input set) for profiling, (3) Either-run-train: branches that are selected when the compiler uses either input set for profiling. The bars in Figure <ref type="figure">10</ref> show More than 74% of all dynamic diverge branches in all benchmarks are selected when either input set is used for profiling. Thus, most of the diverge branches identified by profiling with different input sets are the same. Only gap (26%) has more than 20% and mcf (14%), crafty (13%), vortex (13%), bzip2 (16%) and ijpeg (18%) have more than 10% of all dynamic diverge branches that are classifed as either only-run or only-train. However, even with differences of 10-20% in the dynamic diverge branches selected by profiling with different input sets, only mcf (1%) and crafty (1.6%) show more than 1% IPC degradation when a different input set is used for profiling. This is due to two major reasons: (1) programs have similar sets of highly mispredicted static branches across different input sets <ref type="bibr" target="#b2">[3]</ref>, (2) even though a branch may be marked as a diverge branch by the compiler, only low-confidence diverge branches are actually predicated at runtime; therefore the selection of a slightly different set of branches with different profiling input sets does not necessarily mean that the set of dynamically predicated branches will be significantly different.</p><p>We can make the following conclusions based on our results:</p><p>1. Our diverge branch selection algorithms are not significantly sensitive to differences in the profiling input set. 2. The dynamic nature of predication in the DMP architecture mitigates the effects of changing the profiling input set by selectively entering dpred-mode and dynamically choosing which CFM points to use at run-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Branch Selection for Dynamic Predication</head><p>The most relevant work to ours is Klauser et al. <ref type="bibr" target="#b14">[15]</ref>, which briefly describes how they select branches for a processor that can dynamically predicate very simple control flow hammocks (i.e. hammocks with no intervening control-flow inside). They used two compile-time methods, size-based selection and profile-based selection, to select branch candidates for dynamic predication. The size-based method uses the number of instructions between a branch and the join point (i.e. CFM-point in DMP) of the branch to select suitable simple hammocks. The profile-based method uses a cost-benefit model, similar to our cost-benefit model but applicable to only simple hammocks. Their cost-benefit model took into account the branch misprediction rates, but they did not consider the accuracy of the confidence estimator. Our work includes both size-based heuristics and cost-benefit analysis using profile data. Our compiler algorithms provide more generalized selection mechanisms and cost-benefit analysis for not only simple hammocks, but also more complex control-flow structures (nested hammocks, frequently-hammocks, and loops) to support DMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Branch Selection for Static Predication</head><p>Less relevant to our work is the body of literature on branch selection algorithms for static if-conversion <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref> for predicated instruction set architectures. Static predicated code generation algorithms use edge profiling and/or the number of instructions in a region that is considered for static predication to decide whether or not to ifconvert a branch instruction. Both Pnevmatikatos and Sohi <ref type="bibr" target="#b19">[20]</ref> and Tyson <ref type="bibr" target="#b22">[23]</ref> used the number of instructions in a region to determine whether a short forward branch should be if-converted. Chang et al. converted highly mispredicted branches to predicated code <ref type="bibr" target="#b2">[3]</ref>.</p><p>Mantripragada and Nicolau <ref type="bibr" target="#b17">[18]</ref> developed compiler algorithms to select static if-conversion candidates based on basic block sizes (in terms of the number of instructions) and branch misprediction profile data. Our cost-benefit model presented in Section 4 is conceptually similar to Mantripragada and Nicolau's cost-benefit model for static predication in that both models try to select branches for which predication would provide performance benefits. However, as dynamic predication is different from static predication, we consider dynamic effects such as the accuracy of the confidence estimator and merge probability. Furthermore, we provide a new analytical model to select candidates for frequently-hammocks and loops, which cannot be predicated by conventional if-conversion.</p><p>Hyperblock formation <ref type="bibr" target="#b16">[17]</ref> uses path execution frequencies, basic block sizes, and basic block characteristics to decide which blocks should be included in a hyperblock. Hyperblocks enhance the compiler's scope for code optimization by increasing basic block sizes. Hence, identifying hot-paths is more important than identifying highly mispredicted branches. August et al. <ref type="bibr" target="#b1">[2]</ref> proposed a framework that considers branch misprediction rate and instruction scheduling effects due to predication in an EPIC processor to decide which branches would not benefit from if-conversion and should be reverse if-converted <ref type="bibr" target="#b24">[25]</ref>. They also proposed a cost-benefit model for statically predicated code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.">Input Set Differences in Profiling for Predication</head><p>Chang et al. <ref type="bibr" target="#b2">[3]</ref> compared the set of frequently mispredicted branches between different input sets of SPEC 95 applications. They found that if an input set resulted in the execution of most of the static branches in an application, then the set of frequently mispredicted branches (i.e. branches that are if-conversion candidates in their ifconversion algorithms) would be similar across different input sets.</p><p>Sias et al. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b20">21]</ref> evaluated the performance variation in hyperblock-based code optimizations due to variations in the input set used for profiling. They found that among SPEC CPU2000 benchmarks, crafty, perlbmk and gap showed more than 3% performance difference when profiled with the train input set versus the reference input set. In hyperblocks, the processor does not have the ability to change the statically optimized code. Thus, if the profiling input set is not similar to the run-time input set, there can be significant performance variations as the hardware cannot override a possibly wrong decision made by the compiler based on the profiling input set. In contrast to hyperblocks (and static predication), DMP has the ability to dynamically choose which dynamic instances of each branch to predicate. Hence, DMP is less sensitive to differences between input sets used for profiling and actual execution.</p><p>Hazelwood and Conte <ref type="bibr" target="#b6">[7]</ref> discussed the performance problems associated with statically predicated code when the input set of the program changes. They used dynamic profiling to identify hard-topredict branches and dynamically re-optimized the code based on the run-time behavior of branches. Both software-based dynamic optimization and hardware-based dynamic predication reduce the dependence of predication performance on the profile-time input set.</p><p>Kim et al. <ref type="bibr" target="#b13">[14]</ref> evaluated the extent of variations in branch misprediction rate across input sets. They proposed a profiling algorithm (2D-profiling) that can detect input-dependent branches (i.e. branches whose misprediction rates change significantly across input sets) using a single profiling run. Our work can be further improved by incorporating the 2D-profiling scheme to our algorithms to select only possibly mispredicted branches as diverge branches. Excluding always easy-to-predict branches from selection as diverge branches would reduce the static code size and also reduce the potential for aliasing in the confidence estimator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion and Future Work</head><p>This paper presented and evaluated new code generation algorithms for dynamic predication in the diverge-merge processor (DMP) architecture. The proposed algorithms select branches that are suitable and profitable for dynamic predication based on profiling information. We explored diverse heuristics to select hammock and loop diverge branches and corresponding control-flow merge (CFM) points, and some optimizations based on program characteristics: always-predicating short hammocks and return CFM points. We also proposed a new profile-driven analytical cost-benefit model to select branches that are profitable for dynamic predication.</p><p>Our results show that, with the proposed branch selection algorithms, a DMP processor outperforms an aggressive baseline processor by 20.4%. In contrast, the best-performing alternative branch selection algorithm results in a performance increase of only 4.5% over the baseline.</p><p>Our future work includes the exploration of more accurate costbenefit models. In particular, the proposed cost model for loop diverge branches requires the profiler to collect DMP-specific information. We intend to examine techniques that can make the cost model for selecting loop branches implementable. Exploration of dynamic profiling mechanisms that collect feedback on the usefulness of dynamic predication at run-time and accordingly enable/disable dynamic predication is another promising avenue for future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. Simple hammock example: (a) source code (b) CFG (c) assembly code (d) predicated instructions after register renaming</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Types of CFGs: (a) simple hammock (b) nested hammock (c) frequently-hammock (d) loop. The branch at the end of block A is a possible diverge branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>, probability of merging at C = p T (C) * p N T (C) = 1 * P (BC) = P (BC), where P(BC) is the edge probability from B to C. In contrast, probability of merging at D = p T (D) * p N T (D) = P (CD) * P (BE) because if the not-taken path of the branch at A takes BC, the actual merging point would be C instead of D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Example of a chain of CFM points</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>) = N (B) + P (BE) * N (E) + P (BD) * P (DE) * N (E) +P (BD) * N (D) + P (BD) * P (DF ) * N (F )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>dpred overhead = {1 − P (merge)} * {branch resol cycles/2} + P (merge) * {N (useless dpred insts)/f w} (16) P (merge): The probability of both paths after the candidate branch merging at the CFM point (based on edge profile data) branch resol cycles: The time (in cycles) between when a branch is fetched and when it is resolved (i.e. misp penalty)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>N</head><label></label><figDesc>(useless dpred insts(Xi)) * P (merge at Xi)}/f w + {1 − X i P (merge at Xi)} * {branch resolution cycles/2} (17) N(useless dpred insts(x)): useless dpred insts assuming x is the only CFM point of the diverge branch candidate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>dpred overhead = N (loop body) * dpred extra iter/f w + N (select uops) * dpred iter/f w (19) N(loop body): The number of instructions in the loop body dpred extra iter: The number of extra loop iterations in dpred-mode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Performance improvement of DMP with different selection algorithms: (left) Alg-exact and Alg-freq (right) cost-benefit analysis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Pipeline flushes due to branch mispredictions in the baseline and DMP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7</head><label>7</label><figDesc>shows the performance improvement for different M IN M ERGE P ROB and M AX IN ST R thresholds when the compiler uses only Alg-exact and Alg-freq. The results show that it is better to choose lower M IN M ERGE P ROB when the number of instructions between a diverge branch and the CFM is less than 50, since the overhead of entering dpred-mode for these small hammocks is relatively low. When M AX IN ST R is 100 or 200, M IN M ERGE P ROB=5% results in the best average performance. On average, M AX IN ST R=50, M AX CBR=5, and M IN M ERGE P ROB=1% provides the best performance, so we used these thresholds for all other experiments that do not use the cost-benefit model to select diverge branches. Using a too small (e.g. 10) or too large (e.g. 200) threshold value for M AX IN ST R hurts performance. A too small M AX IN ST R value prevents many mispredicted relatively large hammocks from being dynamically predicated, thereby reducing the performance potential. A too large M AX IN ST R value causes the selection of very large hammocks that fill the instruction window in dpred-mode, which significantly reduces the benefit of dynamic predication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Performance improvement of DMP with different MAX INSTR and MIN MERGE PROB heuristics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Performance improvement of DMP with alternative simple algorithms for selecting diverge branches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Figure 9. Performance improvement of DMP when a different input set is used for profiling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>1: for each conditional branch B executed during profiling do</head><label></label><figDesc>With a working list algorithm, compute all paths starting from B, up to reaching IP OSDOM (B) or M AX IN ST R instructions or M AX CBR conditional branches, following only branch directions with profiled frequency ≥ M IN EXEC P ROB.</figDesc><table><row><cell>2:</cell><cell>Compute IP OSDOM (B) of B</cell></row><row><cell>3:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 . Baseline processor configuration and additional support needed for DMP</head><label>1</label><figDesc></figDesc><table><row><cell>Front End</cell><cell>64KB, 2-way, 2-cycle I-cache; fetches up to 3 conditional not-taken branches</cell></row><row><cell>Branch Predictors</cell><cell>16KB (64-bit history, 256-entry) perceptron branch predictor [10]; 4K-entry BTB 64-entry return address stack; minimum branch misprediction penalty is 25 cycles</cell></row><row><cell>Execution Core</cell><cell>8-wide fetch/issue/execute/retire; 512-entry reorder buffer; 128-entry load-store queue; 512 physical registers scheduling window is partitioned into 8 sub-windows of 64 entries each; 4-cycle pipelined wake-up and selection logic</cell></row><row><cell>Memory System</cell><cell>L1 D-cache: 64KB, 4-way, 2-cycle, 2 ld/st ports L2 unified cache: 1MB, 8-way, 8 banks, 10-cycle, 1 port; All caches: LRU replacement and 64B line size 300-cycle minimum memory latency; 32 memory banks; bus latency: 40-cycle round-trip</cell></row><row><cell>DMP Support [12]</cell><cell>2KB (12-bit history, threshold 14) enhanced JRS confidence estimator [9, 6]; 32 predicate registers; 3 CFM registers</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Characteristics of the benchmarks: baseline IPC, mispredictions per kilo-instructions (MPKI), number of retired instructions (Insts), number of all static branches (All br.), number of static diverge branches (Diverge br.), and average of number of CFM points per diverge branch (Avg. # CFM). Diverge branches and CFM points are selected based on All-best-heur evaluated in Section 7.</figDesc><table><row><cell></cell><cell cols="15">gzip vpr gcc mcf crafty parser eon perlbmk gap vortex bzip2 twolf compress go ijpeg li m88ksim</cell></row><row><cell>Base IPC</cell><cell cols="4">2.10 1.58 1.09 0.45 2.24</cell><cell cols="2">1.30 3.17</cell><cell>1.91</cell><cell cols="2">1.94 3.26</cell><cell cols="2">1.42 2.17</cell><cell>2.29</cell><cell cols="3">0.86 2.88 2.07</cell><cell>2.27</cell></row><row><cell>MPKI</cell><cell cols="3">5.1 9.4 12.6 5.4</cell><cell>5.5</cell><cell>8.3</cell><cell>1.7</cell><cell>3.6</cell><cell>1.0</cell><cell>1.0</cell><cell>7.7</cell><cell>6.0</cell><cell>5.2</cell><cell cols="2">23.0 4.5</cell><cell>5.9</cell><cell>1.3</cell></row><row><cell>Insts (M)</cell><cell>249 76</cell><cell>83</cell><cell cols="2">111 190</cell><cell cols="2">255 129</cell><cell>99</cell><cell>404</cell><cell>284</cell><cell>316</cell><cell>101</cell><cell>150</cell><cell cols="3">137 346 248</cell><cell>145</cell></row><row><cell>All br. (K)</cell><cell cols="3">1.6 4.2 29.5 1.4</cell><cell>5.1</cell><cell>3.7</cell><cell>4.9</cell><cell>9.4</cell><cell>4.6</cell><cell>13</cell><cell>1.4</cell><cell>4.7</cell><cell>0.6</cell><cell>7.7</cell><cell>2</cell><cell>1.2</cell><cell>1.7</cell></row><row><cell>Diverge br.</cell><cell cols="3">175 272 2364 86</cell><cell>643</cell><cell cols="2">167 205</cell><cell>513</cell><cell>286</cell><cell>319</cell><cell>97</cell><cell>358</cell><cell>24</cell><cell cols="2">1286 117</cell><cell>21</cell><cell>136</cell></row><row><cell cols="3">Avg. # CFM 1.02 1.02 1.03</cell><cell>1</cell><cell>1.07</cell><cell cols="2">1.02 1.05</cell><cell>1.03</cell><cell cols="2">1.03 1.03</cell><cell cols="2">1.01 1.02</cell><cell>1.04</cell><cell cols="2">1.04 1.02</cell><cell>1</cell><cell>1.04</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The hardware could measure the usefulness of dynamic predication for each branch at run-time, but the previously proposed DMP implementation<ref type="bibr" target="#b11">[12]</ref> does not support such a feedback scheme due to the hardware cost associated with such a scheme.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">If both paths after the dynamically-predicated diverge branch do not merge at a CFM point, DMP could still provide performance benefit. In that case, the benefit would be similar to that of dual-path execution<ref type="bibr" target="#b7">[8]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2">In order to use Alg-exact and Alg-freq, the compiler still needs values for M AX IN ST R and M AX CBR because these parameters also decide the compiler scope for the CFG analysis. In our cost-benefit model, we use M AX IN ST R = 200 and M AX CBR = 20, which we found to be large enough to enable the analysis of all CFGs that can profit from dynamic predication.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3">Note that there is a trade-off between coverage (of mispredicted branches) and accuracy in confidence estimators. We found that the cost-benefit model is not sensitive to reasonable variations in Acc Conf values (20%-50%). We do not present the results of varying Acc Conf due to space limitations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4">Edge profiling assumes that the direction taken by a branch is independent of the direction taken by a previous branch, which is not always accurate. However, we use edge profiling due to its simplicity and short run-time.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5">Gcc, vortex, and perl in SPEC 95 are not included because later versions of these benchmarks are included in SPEC CPU2000.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6">exact+freq+short+ret+loop is called All-best-heur in the rest of the paper, standing for "all techniques, with the best empirically-determined thresholds, and using heuristics to select diverge branches."</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7">If a branch has an IPOSDOM, the IPOSDOM is selected as the CFM point in the explored simple algorithms.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Robert Cohn, Moinuddin Qureshi, Aater Suleman, Mark Oskin, members of the HPS research group, and the anonymous reviewers for their comments and suggestions. We gratefully acknowledge the support of the Cockrell Foundation, Intel Corporation and the Advanced Technology Program of the Texas Higher Education Coordinating Board.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Conversion of control dependence to data dependence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Porterfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">POPL-10</title>
				<imprint>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A framework for balancing control flow and predication</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>August</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<idno>MICRO-30</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using predicated execution to improve the performance of a dynamically scheduled machine with speculative execution</title>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
				<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A simple, fast dominance algorithm. Software Practice and Experience</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficiently computing static single assignment form and the control dependence graph</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cytron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Wegman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Zadeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Programming Languages and Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="490" />
			<date type="published" when="1991-10">Oct. 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Confidence estimation for speculation control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pleszkun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA-25</title>
				<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A lightweight algorithm for dynamic if-conversion during dynamic optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Conte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
				<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Selective dual path execution</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-11">Nov. 1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Assigning confidence to conditional branch predictions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-29</title>
				<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic branch prediction with perceptrons</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA-7</title>
				<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Alpha 21264 microprocessor</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Diverge-merge processor (DMP): Dynamic predicated execution of complex control-flow graphs based on frequently executed paths</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno>MICRO-39</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Wish branches: Combining conditional branching and predication for adaptive predicated execution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<idno>MICRO-38</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">2D-profiling: Detecting input-dependent branches with a single input data set</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic hammock predication for non-predicated instruction set architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACT</title>
				<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MinneSPEC: A new SPEC benchmark workload for simulation-based computer architecture research</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kleinosowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lilja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2002-06">June 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective compiler support for predicated execution using the hyperblock</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Hank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bringmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-25</title>
				<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using profiling to reduce branch misprediction costs on a dynamically scheduled processor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mantripragada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nicolau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICS</title>
				<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On predicated execution</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlansker</surname></persName>
		</author>
		<idno>HPL-91-58</idno>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
			<pubPlace>Hewlett-Packard Laboratories, Palo Alto CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Guarded execution and dynamic branch prediction in dynamic ILP processors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Pnevmatikatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA-21</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A Systematic Approach to Delivering Instruction-Level Parallelism in EPIC Systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Sias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
		<respStmt>
			<orgName>University of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Sias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<idno>ISCA-31</idno>
		<title level="m">Field-testing IMPACT EPIC research results in Itanium 2</title>
				<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The effects of predication on branch prediction</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Tyson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO-27</title>
				<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Register renaming and scheduling for dynamic execution of predicated code</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA-7</title>
				<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reverse if-conversion</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Warter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Rau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
				<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
