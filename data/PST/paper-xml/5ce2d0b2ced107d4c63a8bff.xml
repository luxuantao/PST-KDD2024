<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>zhang-jing@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bowen</forename><surname>Hao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
							<email>bochen@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cuiping</forename><surname>Li</surname></persName>
							<email>licuiping@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
							<email>jsun@cc.gatech.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information School</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computational Science and Engineering at College of Computing</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Reinforcement Learning for Course Recommendation in MOOCs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The proliferation of massive open online courses (MOOCs) demands an effective way of personalized course recommendation. The recent attention-based recommendation models can distinguish the effects of different historical courses when recommending different target courses. However, when a user has interests in many different courses, the attention mechanism will perform poorly as the effects of the contributing courses are diluted by diverse historical courses. To address such a challenge, we propose a hierarchical reinforcement learning algorithm to revise the user profiles and tune the course recommendation model on the revised profiles. Systematically, we evaluate the proposed model on a real dataset consisting of 1,302 courses, 82,535 users and 458,454 user enrolled behaviors, which were collected from XuetangX-one of the largest MOOCs in China. Experimental results show that the proposed model significantly outperforms the state-of-the-art recommendation models (improving 5.02% to 18.95% in terms of HR@10).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Nowadays, massive open online courses, or MOOCs, are attracting widespread interest as an alternative education model. Lots of MOOCs platforms such as Coursera, edX and Udacity have been built and provide low cost opportunities for anyone to access a massive number of courses from the worldwide top universities. The proliferation of heterogeneous courses in MOOCs platforms demands an effective way of personalized course recommendation for their users.</p><p>The problem can be simply formalized as given a set of historical courses that were enrolled by a user before time t, we aim at recommending the most relevant courses that will be enrolled by the user at time t + 1. We can view the historical enrolled courses as a user's profile, and the key factor of recommendation is to accurately characterize and model the user's preference from her profile. Many state-of-the-art algorithms have been proposed to model users' preferences in different ways. For example, when ignoring the order of the historical courses, we can adopt the factored item similarity model (FISM) <ref type="bibr" target="#b11">(Kabbur, Ning, and Karypis 2013)</ref> to represent each course as an embedding vector and average Figure <ref type="figure">1:</ref> A motivating example of course recommendation. The scores on top of the historical courses are the attention coefficients calculated by NAIS and the scores on top of the target courses are the recommendation probabilities predicted by NAIS <ref type="bibr" target="#b8">(He et al. 2018)</ref>. The goal of this paper is to remove the courses with few contributions in a prediction as much as possible. user's preference. To capture the order of the courses, we can input a temporal sequence of the historical courses into the gated recurrent unit (GRU) model <ref type="bibr" target="#b9">(Hidasi et al. 2016)</ref> and output the last embedding vector as the user preference. However, the model fidelity is limited by the assumption that all the historical courses play the same role at estimating the similarity between the user profile and the target course. To distinguish the effects of different courses, attention-based models such as neural attentive item similarity (NAIS) <ref type="bibr" target="#b8">(He et al. 2018</ref>) and neural attentive session-based recommendation (NASR) <ref type="bibr" target="#b13">(Li et al. 2017</ref>) can be used to estimate an attention coefficient for each historical course as its importance in recommending the target course.</p><p>Although existing attention-based models improve the recommendation performance, it still poses unsolved challenges. Firstly, when a user enrolled diverse courses, the effects of the courses that indeed reflect the user's interest in the target course will be diluted by many irrelevant courses. For example, Figure <ref type="figure">1</ref> illustrates a recommendation result calculated by NAIS <ref type="bibr" target="#b8">(He et al. 2018)</ref>. The score on top of each historical course represents the calculated attention coefficient 1 . The real target course "Big Data Systems" is not successfully recommended in the top 10 ranked courses. Although the major contributing historical courses like "Data Structure", "Operation System" and "Programming Foundation" are assigned relatively high attention coefficients, their effects are discounted by many other categories of courses such as psychology, physics and mathematics after aggregating all the historical courses by their attentions. Secondly, even if no historical courses can contribute in predicting a random target course, each historical course will still be rigidly assigned an attention coefficient, which may cause the random target course ranked before the real target one, as demonstrated by the random course "Financial Management" in Figure <ref type="figure">1</ref>. In summary, the historical noisy courses that make small or even no contributions may disturb the prediction results significantly, even if they are assigned small attention coefficients.</p><p>To deal with the above issues, we propose to revise user profiles by removing the noisy courses instead of assigning an attention coefficient to each of them. The key challenge is that we do not have explicit/supervised information about which courses from the history are noises and should be removed. We propose a hierarchal reinforcement learning algorithm to solve it. Specifically, we formalize the revising of a user profile to be a hierarchical sequential decision process. A high-level task and a low-level task are performed to remove the noisy courses, under the supervision of the feedback from the environment that consists of the dataset and a pre-trained basic recommendation model. Essentially, the profile reviser and the basic recommendation model are jointly trained together. Our contributions include:</p><p>• We propose a novel model for course recommendation in MOOCs, which consists of a profile reviser and a basic recommendation model. With joint training of the two models, we can effectively remove the noisy courses in user profiles. • We propose a hierarchical reinforcement learning algorithm to revise the user profiles, which enables the model to remove the noise courses without explicit annotations. • We collect a dataset, consisting of 1,302 courses, 82,535 users and 458,454 user enrolled behaviors, from Xue-tangX, one of the largest MOOCs in China, to evaluate the proposed model. Experimental results show that the proposed model significantly outperforms the stateof-the-art baselines (improving 5.02% to 18.95% in terms of HR@10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOOC Data</head><p>We collect the dataset from XuetangX<ref type="foot" target="#foot_2">2</ref> , one of the largest MOOCs platforms in China. We unify the same courses offered in different years such as "Data Structure <ref type="bibr" target="#b7">(2017)</ref>" and "Data Structure(2018)" into one course and only select the users who enrolled at least three courses from October 1st, 2016 to March 31st, 2018. The resulting dataset consists of 1,302 courses which belonging to 23 categories, 82,535 users and 458,454 user-course pairs. We also collect the duration of each video in a course watched by a user. Before training the model, we conduct a series of analyses to investigate why we need to revise the user profiles.</p><p>Figure <ref type="figure">2a</ref> presents the distribution of the enrolled course number of a user in the top and the distribution of the category number of the enrolled courses in the bottom. Then we calculate the ratio between the category number and the course number as the category ratio of a profile to represent the attentiveness of a user. A bigger category ratio indicates the user is more distractive, while a smaller category ratio indicates the user is more attentive. Figure <ref type="figure">2b</ref> shows the distribution of the category ratio. From the three figures, we can see that although a large number of users enrolled a small number of courses and categories, the ratio between them is relatively evenly distributed. We further average the probabilities of recommending a real target course calculated by NAIS <ref type="bibr" target="#b8">(He et al. 2018)</ref> for the user profiles of the same category ratio and present the probability distribution over category ratio in Figure <ref type="figure">2c</ref>. We can see that the probability decreases with the increase of the category ratio. In summary, all these analyses indicate that a large number of users enrolled diverse courses, and the recommendation performance based on these diverse profiles is impacted. Thus, we have to study how to revise the user profiles. In addition, we calculate the ratio between the watch duration and the total duration of a video as the watch ratio, and use the maximal watch ratio of all the videos in a course to represent the effort taken by the user in the course. We present the effort distribution of user enrolled courses in Figure <ref type="figure">2d</ref> and the filtered effort distribution (i.e., effort larger than 0.01) in the embeded subfigure, which indicate that users take distinguished effort in different courses. The phenomenon can guide the design of the agent policy later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background: Recommendation Models Problem Formulation</head><formula xml:id="formula_0">Let U = {u 1 , • • • , u |U | } be a set of users and C = {c 1 , • • • , c |C| }</formula><p>be a set of courses in the MOOCs platform. For each user u, given her profile, i.e., the historical enrolled courses E u := (e u 1 , • • • , e u tu ) with e u t ∈ C, we are aiming at recommending the courses u would enroll at next time t u + 1. We deal with the relative time instead of the absolute time the same as <ref type="bibr" target="#b18">(Rendle, Freudenthaler, and Schmidt-Thieme 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Basic Recommendation Model</head><p>The key factor of recommendation is to accurately characterize a user's preference according to her profile E u . The general idea is, we represent each historical course e u t as a realvalued low dimensional embedding vector p u t , and aggregate the embeddings of all the historical courses p u 1 , . . . , p u t to represent user u's preference q u . If we also represent a target course c i as an embedding vector p i , the probability of recommending course c i to user u, i.e.,P (y = 1|E u , c i ), can be calculated as:</p><formula xml:id="formula_1">P (y = 1|E u , c i ) = σ(q T u p i ),<label>(1)</label></formula><p>where y = 1 indicates that c i is recommended to user u and σ is the sigmoid function to transform the input into a probability. Then the key issue is how to obtain the aggregated embedding q u . One straightforward way is to average the embeddings of all the historical courses, i.e. q u = 1 tu ∑ tu t=1 p u t . However, equally treating all the courses' contributions may impact the representation of a user's real interest in a target course. Thus, as NAIS <ref type="bibr" target="#b8">(He et al. 2018</ref>) does, we can adopt the attention mechanism to estimate an attention coefficient a u it for each historical course e u t when recommending c i . Specifically, we parameterize the attention coefficient a u it as a function with p u t and p i as inputs and then aggregate the embeddings according to their attentions:</p><formula xml:id="formula_2">q u = tu ∑ t=1 a u it p u t , a u it = f (p u t , p i ),<label>(2)</label></formula><p>where f can be instantiated by a multi-layer perception on the concatenation or the element-wise product of the two embeddings p u t and p i . We can also adopt NASR <ref type="bibr" target="#b13">(Li et al. 2017</ref>)-an attentive recurrent neural networks to capture the order of the historical courses. Specifically, at each time t, NASR outputs a hidden vector h u t to represent a user's preference until time t based on both the course enrolled at time t and all the previous courses before t. Then the same attention mechanism is applied on the hidden vectors of all the timestamps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Proposed Model</head><p>In this section, we firstly give an overview of the proposed model, then we introduce a hierarchal reinforcement learning algorithm to revise user profiles, and finally explain the training process of the entire model.</p><formula xml:id="formula_3">Internal reward G Original profile a l 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k I H V c n Y 7 j 1 V V H b I J i e Y q n / z S p v U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 8 B 5 l d V C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 3 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z H 8 n Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 1 C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A g h Y 7 D &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k I H V c n Y 7 j 1 V V H b I J i e Y q n / z S p v U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 8 B 5 l d V C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 3 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z H 8 n Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 1 C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A g h Y 7 D &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k I H V c n Y 7 j 1 V V H b I J i e Y q n / z S p v U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 8 B 5 l d V C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 3 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z H 8 n Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 1 C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A g h Y 7 D &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k I H V c n Y 7 j 1 V V H b I J i e Y q n / z S p v U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 8 B 5 l d V C u u D V 3 A b J O v J x U I E d z U P 7 q D 2 O W R l w h k 9 S Y n u c m 6 G d U o 2 C S z 0 r 9 1 P C E s g k d 8 Z 6 l i k b c + N n i 3 B m 5 s M q Q h L G 2 p Z A s 1 N 8 T G Y 2 M m U a B 7 Y w o j s 2 q N x f / 8 3 o p h t d + J l S S I l d s u S h M J c G Y z H 8 n Q 6 E 5 Q z m 1 h D I t 7 K 2 E j a m m D G 1 C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A g h Y 7 D &lt; / l a t e x i t &gt; a l 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x l D x k s M n z d R u 9 c l n l 6 F + Y C J K / O U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 q D / K 6 q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j 1 L F Y 2 4 8 b P F u T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 O h k J z h n J q C W V a 2 F s J G 1 N N G d q E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E i D I 7 E &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x l D x k s M n z d R u 9 c l n l 6 F + Y C J K / O U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 q D / K 6 q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j 1 L F Y 2 4 8 b P F u T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 O h k J z h n J q C W V a 2 F s J G 1 N N G d q E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E i D I 7 E &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x l D x k s M n z d R u 9 c l n l 6 F + Y C J K / O U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 q D / K 6 q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j 1 L F Y 2 4 8 b P F u T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 O h k J z h n J q C W V a 2 F s J G 1 N N G d q E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E i D I 7 E &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x l D x k s M n z d R u 9 c l n l 6 F + Y C J K / O U = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V O l U 6 q D / K 6 q B c c W v u A m S d e D m p Q I 7 m o P z V H 8 Y s j b h C J q k x P c 9 N 0 M + o R s E k n 5 X 6 q e E J Z R M 6 4 j 1 L F Y 2 4 8 b P F u T N y Y Z U h C W N t S y F Z q L 8 n M h o Z M 4 0 C 2 x l R H J t V b y 7 + 5 / V S D K / 9 T K g k R a 7 Y c l G Y S o I x m f 9 O h k J z h n J q C W V a 2 F s J G 1 N N G d q E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E i D I 7 E &lt; / l a t e x i t &gt; P (y = 1| Êu , ci) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 + P d y c n k B f W N d T G Y + 8 x Y / d y 6 J O c = " &gt; A A A C B 3 i c b V D L S s N A F J 3 U V 6 2 v q E t B B o t Q Q U o i g m 6 E i g g u K 9 g H N D F M p t N 2 6 G Q S Z i Z C i N m 5 8 V f c u F D E r b / g z r 9 x 0 m a h 1 Q M X D u f c y 7 3 3 + B G j U l n W l 1 G a m 1 9 Y X C o v V 1 Z W 1 9 Y 3 z M 2 t t g x j g U k L h y w U X R 9 J w i g n L U U V I 9 1 I E B T 4 j H T 8 8 U X u d + 6 I k D T k N y q J i B u g I a c D i p H S k m f u N m v J m X 3 v j J B K n Q C p E U Y s v c y y 2 / g Q e / T A M 6 t W 3 Z o A / i V 2 Q a q g Q N M z P 5 1 + i O O A c I U Z k r J n W 5 F y U y Q U x Y x k F S e W J E J 4 j I a k p y l H A Z F u O v k j g / t a 6 c N B K H R x B S f q z 4 k U B V I m g a 8 7 8 1 P l r J e L / 3 m 9 W A 1 O 3 Z T y K F a E 4 + m i Q c y g C m E e C u x T Q b B i i S Y I C 6 p v h X i E B M J K R 1 f R I d i z L /</formula><p>8 l 7 a O 6 b d X t 6 + N q 4 7 y I o w x 2 w B 6 o A R u c g A a 4 A k 3 Q A h g 8 g C f w A l 6 N R + P Z e D P e p 6 0 l o 5 j Z B r 9 g f H w D d E + Z C A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 +</p><formula xml:id="formula_4">P d y c n k B f W N d T G Y + 8 x Y / d y 6 J O c = " &gt; A A A C B 3 i c b V D L S s N A F J 3 U V 6 2 v q E t B B o t Q Q U o i g m 6 E i g g u K 9 g H N D F M p t N 2 6 G Q S Z i Z C i N m 5 8 V f c u F D E r b / g z r 9 x 0 m a h 1 Q M X D u f c y 7 3 3 + B G j U l n W l 1 G a m 1 9 Y X C o v V 1 Z W 1 9 Y 3 z M 2 t t g x j g U k L h y w U X R 9 J w i g n L U U V I 9 1 I E B T 4 j H T 8 8 U X u d + 6 I k D T k N y q J i B u g I a c D i p H S k m f u N m v J m X 3 v j J B K n Q C p E U Y s v c y y 2 / g Q e / T A M 6 t W 3 Z o A / i V 2 Q a q g Q N M z P 5 1 + i O O A c I U Z k r J n W 5 F y U y Q U x Y x k F S e W J E J 4 j I a k p y l H A Z F u O v k j g / t a 6 c N B K H R x B S f q z 4 k U B V I m g a 8 7 8 1 P l r J e L / 3 m 9 W A 1 O 3 Z T y K F a E 4 + m i Q c y g C m E e C u x T Q b B i i S Y I C 6 p v h X i E B M J K R 1 f R I d i z L /</formula><p>8 l 7 a O 6 b d X t 6 + N q 4 7 y I o w x 2 w B 6 o A R u c g A a 4 A k 3 Q A h g 8 g C f w A l 6 N R + P Z e D P e p 6 0 l o 5 j Z B r 9 g f H w D d E + Z C A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 +</p><formula xml:id="formula_5">P d y c n k B f W N d T G Y + 8 x Y / d y 6 J O c = " &gt; A A A C B 3 i c b V D L S s N A F J 3 U V 6 2 v q E t B B o t Q Q U o i g m 6 E i g g u K 9 g H N D F M p t N 2 6 G Q S Z i Z C i N m 5 8 V f c u F D E r b / g z r 9 x 0 m a h 1 Q M X D u f c y 7 3 3 + B G j U l n W l 1 G a m 1 9 Y X C o v V 1 Z W 1 9 Y 3 z M 2 t t g x j g U k L h y w U X R 9 J w i g n L U U V I 9 1 I E B T 4 j H T 8 8 U X u d + 6 I k D T k N y q J i B u g I a c D i p H S k m f u N m v J m X 3 v j J B K n Q C p E U Y s v c y y 2 / g Q e / T A M 6 t W 3 Z o A / i V 2 Q a q g Q N M z P 5 1 + i O O A c I U Z k r J n W 5 F y U y Q U x Y x k F S e W J E J 4 j I a k p y l H A Z F u O v k j g / t a 6 c N B K H R x B S f q z 4 k U B V I m g a 8 7 8 1 P l r J e L / 3 m 9 W A 1 O 3 Z T y K F a E 4 + m i Q c y g C m E e C u x T Q b B i i S Y I C 6 p v h X i E B M J K R 1 f R I d i z L /</formula><p>8 l 7 a O 6 b d X t 6 + N q 4 7 y I o w x 2 w B 6 o A R u c g A a 4 A k 3 Q A h g 8 g C f w A l 6 N R + P Z e D P e p 6 0 l o 5 j Z B r 9 g f H w D d E + Z C A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 7 +</p><formula xml:id="formula_6">P d y c n k B f W N d T G Y + 8 x Y / d y 6 J O c = " &gt; A A A C B 3 i c b V D L S s N A F J 3 U V 6 2 v q E t B B o t Q Q U o i g m 6 E i g g u K 9 g H N D F M p t N 2 6 G Q S Z i Z C i N m 5 8 V f c u F D E r b / g z r 9 x 0 m a h 1 Q M X D u f c y 7 3 3 + B G j U l n W l 1 G a m 1 9 Y X C o v V 1 Z W 1 9 Y 3 z M 2 t t g x j g U k L h y w U X R 9 J w i g n L U U V I 9 1 I E B T 4 j H T 8 8 U X u d + 6 I k D T k N y q J i B u g I a c D i p H S k m f u N m v J m X 3 v j J B K n Q C p E U Y s v c y y 2 / g Q e / T A M 6 t W 3 Z o A / i V 2 Q a q g Q N M z P 5 1 + i O O A c I U Z k r J n W 5 F y U y Q U x Y x k F S e W J E J 4 j I a k p y l H A Z F u O v k j g / t a 6 c N B K H R x B S f q z 4 k U B V I m g a 8 7 8 1 P l r J e L / 3 m 9 W A 1 O 3 Z T y K F a E 4 + m i Q c y g C m E e C u x T Q b B i i S Y I C 6 p v h X i E B M J K R 1 f R I d i z L / 8 l 7 a O 6 b d X t 6 + N q 4 7 y I o w x 2 w B 6 o A R u c g A a 4 A k 3 Q A h g 8 g C f w A l 6 N R + P Z e D P e p 6 0 l o 5 j Z B r 9 g f H w D d E + Z C A = = &lt; / l a t e x i t &gt; Reward R e u 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W p / R m X H S j Z h 6 h G l j 4 s / E u A E L A n g = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 o D 7 z G t D s o V t + Y u Q N a J l 5 M K 5 G g O y l / 9 Y c z S C K V h g m r d 8 9 z E + B l V h j O B s 1 I / 1 Z h Q N q E j 7 F k q a Y T a z x b n z s i F V Y Y k j J U t a c h C / T 2 R 0 U j r a R T Y z o i a s V 7 1 5 u J / X i 8 1 4 b W f c Z m k B i V b L g p T Q U x M 5 r + T I V f I j J h a Q p n i 9 l b C x l R R Z m x C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A 0 V o 7 Q &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W p / R m X H S j Z h 6 h G l j 4 s / E u A E L A n g = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 o D 7 z G t D s o V t + Y u Q N a J l 5 M K 5 G g O y l / 9 Y c z S C K V h g m r d 8 9 z E + B l V h j O B s 1 I / 1 Z h Q N q E j 7 F k q a Y T a z x b n z s i F V Y Y k j J U t a c h C / T 2 R 0 U j r a R T Y z o i a s V 7 1 5 u J / X i 8 1 4 b W f c Z m k B i V b L g p T Q U x M 5 r + T I V f I j J h a Q p n i 9 l b C x l R R Z m x C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A 0 V o 7 Q &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W p / R m X H S j Z h 6 h G l j 4 s / E u A E L A n g = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 o D 7 z G t D s o V t + Y u Q N a J l 5 M K 5 G g O y l / 9 Y c z S C K V h g m r d 8 9 z E + B l V h j O B s 1 I / 1 Z h Q N q E j 7 F k q a Y T a z x b n z s i F V Y Y k j J U t a c h C / T 2 R 0 U j r a R T Y z o i a s V 7 1 5 u J / X i 8 1 4 b W f c Z m k B i V b L g p T Q U x M 5 r + T I V f I j J h a Q p n i 9 l b C x l R R Z m x C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A 0 V o 7 Q &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W p / R m X H S j Z h 6 h G l j 4 s / E u A E L A n g = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 o D 7 z G t D s o V t + Y u Q N a J l 5 M K 5 G g O y l / 9 Y c z S C K V h g m r d 8 9 z E + B l V h j O B s 1 I / 1 Z h Q N q E j 7 F k q a Y T a z x b n z s i F V Y Y k j J U t a c h C / T 2 R 0 U j r a R T Y z o i a s V 7 1 5 u J / X i 8 1 4 b W f c Z m k B i V b L g p T Q U x M 5 r + T I V f I j J h a Q p n i 9 l b C x l R R Z m x C J R u C t / r y O m n X a 5 5 b 8 + 7 r l c Z t H k c R z u A c L s G D K 2 j A H T S h B Q w m 8 A y v 8 O Y k z o v z 7 n w s W w t O P n M K f + B 8 / g A 0 V o 7 Q &lt; / l a t e x i t &gt; e u 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z r C f o I H 1 J I N m L T W b D v y F f x c Y i N E = " &gt; A A A B 8 H i c b V D L S g N B E O y N r x h f U Y 9 e B h P B U 9 g N g h 4 D e v A Y w T w k W c P s p J M M m d l d Z m a F s O Q r v H h Q x K u f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l h w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 4 S x b D B I h G p d k A 1 C h 5 i w 3 A j s B 0 r p D I Q 2 A r G 1 z O / 9 Y R K 8 y i 8 N 5 M Y f U m H I R 9 w R o 2 V H s r Y S y + m j 0 m 5 V y y 5 F X c O s k q 8 j J Q g Q 7 1 X / O r 2 I 5 Z I D A 0 T V O u O 5 8 b G T 6 k y n A m c F r q J x p i y M R 1 i x 9 K Q S t R + O j 9 4 S s 6 s 0 i e D S N k K D Z m r v y d S K r W e y M B 2 S m p G e t m b i f 9 5 n c Q M r v y U h 3 F i M G S L R Y N E E B O R 2 f e k z x U y I y a W U K a 4 v Z W w E V W U G Z t R w Y b g L b + 8 S p r V i u d W v L t q q X a T x Z G H E z i F c / D g E m p w C 3 V o A A M J z / A K b 4 5 y X p x 3 5 2 P R m n O y m W P 4 A + f z B w C t j 9 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z r C f o I H 1 J I N m L T W b D v y F f x c Y i N E = " &gt; A A A B 8 H i c b V D L S g N B E O y N r x h f U Y 9 e B h P B U 9 g N g h 4 D e v A Y w T w k W c P s p J M M m d l d Z m a F s O Q r v H h Q x K u f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l h w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 4 S x b D B I h G p d k A 1 C h 5 i w 3 A j s B 0 r p D I Q 2 A r G 1 z O / 9 Y R K 8 y i 8 N 5 M Y f U m H I R 9 w R o 2 V H s r Y S y + m j 0 m 5 V y y 5 F X c O s k q 8 j J Q g Q 7 1 X / O r 2 I 5 Z I D A 0 T V O u O 5 8 b G T 6 k y n A m c F r q J x p i y M R 1 i x 9 K Q S t R + O j 9 4 S s 6 s 0 i e D S N k K D Z m r v y d S K r W e y M B 2 S m p G e t m b i f 9 5 n c Q M r v y U h 3 F i M G S L R Y N E E B O R 2 f e k z x U y I y a W U K a 4 v Z W w E V W U G Z t R w Y b g L b + 8 S p r V i u d W v L t q q X a T x Z G H E z i F c / D g E m p w C 3 V o A A M J z / A K b 4 5 y X p x 3 5 2 P R m n O y m W P 4 A + f z B w C t j 9 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z r C f o I H 1 J I N m L T W b D v y F f x c Y i N E = " &gt; A A A B 8 H i c b V D L S g N B E O y N r x h f U Y 9 e B h P B U 9 g N g h 4 D e v A Y w T w k W c P s p J M M m d l d Z m a F s O Q r v H h Q x K u f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l h w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 4 S x b D B I h G p d k A 1 C h 5 i w 3 A j s B 0 r p D I Q 2 A r G 1 z O / 9 Y R K 8 y i 8 N 5 M Y f U m H I R 9 w R o 2 V H s r Y S y + m j 0 m 5 V y y 5 F X c O s k q 8 j J Q g Q 7 1 X / O r 2 I 5 Z I D A 0 T V O u O 5 8 b G T 6 k y n A m c F r q J x p i y M R 1 i x 9 K Q S t R + O j 9 4 S s 6 s 0 i e D S N k K D Z m r v y d S K r W e y M B 2 S m p G e t m b i f 9 5 n c Q M r v y U h 3 F i M G S L R Y N E E B O R 2 f e k z x U y I y a W U K a 4 v Z W w E V W U G Z t R w Y b g L b + 8 S p r V i u d W v L t q q X a T x Z G H E z i F c / D g E m p w C 3 V o A A M J z / A K b 4 5 y X p x 3 5 2 P R m n O y m W P 4 A + f z B w C t j 9 8 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z r C f o I H 1 J I N m L T W b D v y F f x c Y i N E = " &gt; A A A B 8 H i c b V D L S g N B E O y N r x h f U Y 9 e B h P B U 9 g N g h 4 D e v A Y w T w k W c P s p J M M m d l d Z m a F s O Q r v H h Q x K u f 4 8 2 / c Z L s Q R M L G o q q b r q 7 g l h w b V z 3 2 8 m t r W 9 s b u W 3 C z u 7 e / s H x c O j p o 4 S x b D B I h G p d k A 1 C h 5 i w 3 A j s B 0 r p D I Q 2 A r G 1 z O / 9 Y R K 8 y i 8 N 5 M Y f U m H I R 9 w R o 2 V H s r Y S y + m j 0 m 5 V y y 5 F X c O s k q 8 j J Q g Q 7 1 X / O r 2 I 5 Z I D A 0 T V O u O 5 8 b G T 6 k y n A m c F r q J x p i y M R 1 i x 9 K Q S t R + O j 9 4 S s 6 s 0 i e D S N k K D Z m r v y d S K r W e y M B 2 S m p G e t m b i f 9 5 n c Q M r v y U h 3 F i M G S L R Y N E E B O R 2 f e k z x U y I y a W U K a 4 v Z W w E V W U G Z t R w Y b g L b + 8 S p r V i u d W v L t q q X a T x Z G H E z i F c / D g E m p w C 3 V o A A M J z / A K b 4 5 y X p x 3 5 2 P R m n O y m W P 4 A + f z B w C t j 9 8 = &lt; / l a t e x i t &gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Revised profile</head><p>Recommendation probability Basic Recommendation Model Profile Reviser p i &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z p 9 d 2 X q n s n k e N a s 4 O w p T + 4 / e K O c = " &gt; A</p><formula xml:id="formula_7">A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 B F v B U 0 l 6 0 W N B D x 4 r 2 F Z o Q 9 h s J + 3 S z S b s T o o l 5 J 9 4 8 a C I V / + J N / + N 2 4 + D t j 4 Y e L w 3 w 8 y 8 M B V c o + t + W 6 W N z a 3 t n f J u Z W / / 4 P D I P j 7 p 6 C R T D N o s E Y l 6 D K k G w S W 0 k a O A x 1 Q B j U M B 3 X B 8 M / O 7 E 1 C a J / I B p y n 4 M R 1 K H n F G 0 U i B b d f 6 C E 8 Y R n l a B D k v a o F d d e v u H M 4 6 8 Z a k S p Z o B f Z X f 5 C w L A a J T F C t e 5 6 b o p 9 T h Z w J K C r 9 T E N K 2 Z g O o W e o p D F o P 5 9 f X j g X R h k 4 U a J M S X T m 6 u + J n M Z a T + P Q d M Y U R 3 r V m 4 n / e b 0 M o 2 s / 5 z L N E C R b L I o y 4 W D i z G J w B l w B Q z E 1 h D L F z a 0 O G 1 F F G Z q w K i Y E b / X l d d J p 1 D 2 3 7 t 0 3 q s 3 b Z R x l c k b O y S X x y B V p k j v S I m 3 C y I Q 8 k 1 f y Z u X W i / V u f S x a S 9 Z y 5 p T 8 g f X 5 A 6 C t k 6 Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z p 9 d 2 X q n s n k e N a s 4 O w p T + 4 / e K O c = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 B F v B U 0 l 6 0 W N B D x 4 r 2 F Z o Q 9 h s J + 3 S z S b s T o o l 5 J 9 4 8 a C I V / + J N / + N 2 4 + D t j 4 Y e L w 3 w 8 y 8 M B V c o + t + W 6 W N z a 3 t n f J u Z W / / 4 P D I P j 7 p 6 C R T D N o s E Y l 6 D K k G w S W 0 k a O A x 1 Q B j U M B 3 X B 8 M / O 7 E 1 C a J / I B p y n 4 M R 1 K H n F G 0 U i B b d f 6 C E 8 Y R n l a B D k v a o F d d e v u H M 4 6 8 Z a k S p Z o B f Z X f 5 C w L A a J T F C t e 5 6 b o p 9 T h Z w J K C r 9 T E N K 2 Z g O o W e o p D F o P 5 9 f X j g X R h k 4 U a J M S X T m 6 u + J n M Z a T + P Q d M Y U R 3 r V m 4 n / e b 0 M o 2 s / 5 z L N E C R b L I o y 4 W D i z G J w B l w B Q z E 1 h D L F z a 0 O G 1 F F G Z q w K i Y E b / X l d d J p 1 D 2 3 7 t 0 3 q s 3 b Z R x l c k b O y S X x y B V p k j v S I m 3 C y I Q 8 k 1 f y Z u X W i / V u f S x a S 9 Z y 5 p T 8 g f X 5 A 6 C t k 6 Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z p 9 d 2 X q n s n k e N a s 4 O w p T + 4 / e K O c = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 B F v B U 0 l 6 0 W N B D x 4 r 2 F Z o Q 9 h s J + 3 S z S b s T o o l 5 J 9 4 8 a C I V / + J N / + N 2 4 + D t j 4 Y e L w 3 w 8 y 8 M B V c o + t + W 6 W N z a 3 t n f J u Z W / / 4 P D I P j 7 p 6 C R T D N o s E Y l 6 D K k G w S W 0 k a O A x 1 Q B j U M B 3 X B 8 M / O 7 E 1 C a J / I B p y n 4 M R 1 K H n F G 0 U i B b d f 6 C E 8 Y R n l a B D k v a o F d d e v u H M 4 6 8 Z a k S p Z o B f Z X f 5 C w L A a J T F C t e 5 6 b o p 9 T h Z w J K C r 9 T E N K 2 Z g O o W e o p D F o P 5 9 f X j g X R h k 4 U a J M S X T m 6 u + J n M Z a T + P Q d M Y U R 3 r V m 4 n / e b 0 M o 2 s / 5 z L N E C R b L I o y 4 W D i z G J w B l w B Q z E 1 h D L F z a 0 O G 1 F F G Z q w K i Y E b / X l d d J p 1 D 2 3 7 t 0 3 q s 3 b Z R x l c k b O y S X x y B V p k j v S I m 3 C y I Q 8 k 1 f y Z u X W i / V u f S x a S 9 Z y 5 p T 8 g f X 5 A 6 C t k 6 Q = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z p 9 d 2 X q n s n k e N a s 4 O w p T + 4 / e K O c = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 B F v B U 0 l 6 0 W N B D x 4 r 2 F Z o Q 9 h s J + 3 S z S b s T o o l 5 J 9 4 8 a C I V / + J N / + N 2 4 + D t j 4 Y e L w 3 w 8 y 8 M B V c o + t + W 6 W N z a 3 t n f J u Z W / / 4 P D I P j 7 p 6 C R T D N o s E Y l 6 D K k G w S W 0 k a O A x 1 Q B j U M B 3 X B 8 M / O 7 E 1 C a J / I B p y n 4 M R 1 K H n F G 0 U i B b d f 6 C E 8 Y R n l a B D k v a o F d d e v u H M 4 6 8 Z a k S p Z o B f Z X f 5 C w L A a J T F C t e 5 6 b o p 9 T h Z w J K C r 9 T E N K 2 Z g O o W e o p D F o P 5 9 f X j g X R h k 4 U a J M S X T m 6 u + J n M Z a T + P Q d M Y U R 3 r V m 4 n / e b 0 M o 2 s / 5 z L N E C R b L I o y 4 W D i z G J w B l w B Q z E 1 h D L F z a 0 O G 1 F F G Z q w K i Y E b / X l d d J p 1 D 2 3 7 t 0 3 q s 3 b Z R x l c k b O y S X x y B V p k j v S I m 3 C y I Q 8 k 1 f y Z u X W i / V u f S x a S 9 Z y 5 p T 8 g f X 5 A 6 C t k 6 Q = &lt; / l a t e x i t &gt; q u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q w h D P G 3 m 9 R s y A v z l / 9 r C i 7 f s F i I = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L L a C p 5 L 0 o s e C H j x W s B / Q h r D Z b t q l m 0 3 c n R R L y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w D Y 7 z b Z U 2 N r e 2 d 8 q 7 l b 3 9 g 8 M j + / i k o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 M z 9 7 p Q p z W P 5 A L O E e R E Z S R 5 y S s B I v m 3 X B s C e I A i z x 9 z P 0 r z m 2 1 W n 7 i y A 1 4 l b k C o q 0 P L t r 8 E w p m n E J F B B t O 6 7 T g J e R h R w K l h e G a S a J Y R O y I j 1 D Z U k Y t r L F p f n + M I o Q x z G y p Q E v F B / T 2 Q k 0 n o W B a Y z I j D W q 9 5 c / M / r p x B e e x m X S Q p M 0 u W i M B U Y Y j y P A Q + 5 Y h T E z B B C F T e 3 Y j o m i l A w Y V V M C O 7 q y + u k 0 6 i 7 T t 2 9 b 1 S b t 0 U c Z X S G z t E l c t E V a q I 7 1 E J t R N E U P a N X 9 G Z l 1 o v 1 b n 0 s W 0 t W M X O K / s D 6 / A G 0 f 5 O x &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q w h D P G 3 m 9 R s y A v z l / 9 r C i 7 f s F i I = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L L a C p 5 L 0 o s e C H j x W s B / Q h r D Z b t q l m 0 3 c n R R L y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w D Y 7 z b Z U 2 N r e 2 d 8 q 7 l b 3 9 g 8 M j + / i k o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 M z 9 7 p Q p z W P 5 A L O E e R E Z S R 5 y S s B I v m 3 X B s C e I A i z x 9 z P 0 r z m 2 1 W n 7 i y A 1 4 l b k C o q 0 P L t r 8 E w p m n E J F B B t O 6 7 T g J e R h R w K l h e G a S a J Y R O y I j 1 D Z U k Y t r L F p f n + M I o Q x z G y p Q E v F B / T 2 Q k 0 n o W B a Y z I j D W q 9 5 c / M / r p x B e e x m X S Q p M 0 u W i M B U Y Y j y P A Q + 5 Y h T E z B B C F T e 3 Y j o m i l A w Y V V M C O 7 q y + u k 0 6 i 7 T t 2 9 b 1 S b t 0 U c Z X S G z t E l c t E V a q I 7 1 E J t R N E U P a N X 9 G Z l 1 o v 1 b n 0 s W 0 t W M X O K / s D 6 / A G 0 f 5 O x &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q w h D P G 3 m 9 R s y A v z l / 9 r C i 7 f s F i I = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L L a C p 5 L 0 o s e C H j x W s B / Q h r D Z b t q l m 0 3 c n R R L y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w D Y 7 z b Z U 2 N r e 2 d 8 q 7 l b 3 9 g 8 M j + / i k o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 M z 9 7 p Q p z W P 5 A L O E e R E Z S R 5 y S s B I v m 3 X B s C e I A i z x 9 z P 0 r z m 2 1 W n 7 i y A 1 4 l b k C o q 0 P L t r 8 E w p m n E J F B B t O 6 7 T g J e R h R w K l h e G a S a J Y R O y I j 1 D Z U k Y t r L F p f n + M I o Q x z G y p Q E v F B / T 2 Q k 0 n o W B a Y z I j D W q 9 5 c / M / r p x B e e x m X S Q p M 0 u W i M B U Y Y j y P A Q + 5 Y h T E z B B C F T e 3 Y j o m i l A w Y V V M C O 7 q y + u k 0 6 i 7 T t 2 9 b 1 S b t 0 U c Z X S G z t E l c t E V a q I 7 1 E J t R N E U P a N X 9 G Z l 1 o v 1 b n 0 s W 0 t W M X O K / s D 6 / A G 0 f 5 O x &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q w h D P G 3 m 9 R s y A v z l / 9 r C i 7 f s F i I = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L L a C p 5 L 0 o s e C H j x W s B / Q h r D Z b t q l m 0 3 c n R R L y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k R w D Y 7 z b Z U 2 N r e 2 d 8 q 7 l b 3 9 g 8 M j + / i k o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 M z 9 7 p Q p z W P 5 A L O E e R E Z S R 5 y S s B I v m 3 X B s C e I A i z x 9 z P 0 r z m 2 1 W n 7 i y A 1 4 l b k C o q 0 P L t r 8 E w p m n E J F B B t O 6 7 T g J e R h R w K l h e G a S a J Y R O y I j 1 D Z U k Y t r L F p f n + M I o Q x z G y p Q E v F B / T 2 Q k 0 n o W B a Y z I j D W q 9 5 c / M / r p x B e e x m X S Q p M 0 u W i M B U Y Y j y P A Q + 5 Y h T E z B B C F T e 3 Y j o m i l A w Y V V M C O 7 q y + u k 0 6 i 7 T t 2 9 b 1 S b t 0 U c Z X S G z t E l c t E V a q I 7 1 E J t R N E U P a N X 9 G Z l 1 o v 1 b n 0 s W 0 t W M X O K / s D 6 / A G 0 f 5 O x &lt; / l a t e x i t &gt; Embeddings p u 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m w i D X 8 M t 4 U V t O y s T D p l 9 L I P G L f w = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u t 7 j 2 m l b 5 f d q r u A s 0 6 8 n J Q h R 6 N v f / U G M U 0 j J p E K o n X X c x P 0 M 6 K Q U 8 F m p V 6 q W U L o m A x Z 1 1 B J I q b 9 b H H 5 z L k w y s A J Y 2 V K o r N Q f 0 9 k J N J 6 G g W m M y I 4 0 q v e X P z P 6 6 Y Y X v s Z l 0 m K T N L l o j A V D s b O P A Z n w B W j K K a G E K q 4 u d W h I 6 I I R R N W y Y T g r b 6 8 T l q 1 q u d W v f t a u X 6 b x 1 G E M z i H S / D g C u p w B w 1 o A o U J P M M r v F m Z 9 W K 9 W x / L 1 o K V z 5 z C H 1 i f P x K 9 k 0 c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m w i D X 8 M t 4 U V t O y s T D p l 9 L I P G L f w = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u t 7 j 2 m l b 5 f d q r u A s 0 6 8 n J Q h R 6 N v f / U G M U 0 j J p E K o n X X c x P 0 M 6 K Q U 8 F m p V 6 q W U L o m A x Z 1 1 B J I q b 9 b H H 5 z L k w y s A J Y 2 V K o r N Q f 0 9 k J N J 6 G g W m M y I 4 0 q v e X P z P 6 6 Y Y X v s Z l 0 m K T N L l o j A V D s b O P A Z n w B W j K K a G E K q 4 u d W h I 6 I I R R N W y Y T g r b 6 8 T l q 1 q u d W v f t a u X 6 b x 1 G E M z i H S / D g C u p w B w 1 o A o U J P M M r v F m Z 9 W K 9 W x / L 1 o K V z 5 z C H 1 i f P x K 9 k 0 c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m w i D X 8 M t 4 U V t O y s T D p l 9 L I P G L f w = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u t 7 j 2 m l b 5 f d q r u A s 0 6 8 n J Q h R 6 N v f / U G M U 0 j J p E K o n X X c x P 0 M 6 K Q U 8 F m p V 6 q W U L o m A x Z 1 1 B J I q b 9 b H H 5 z L k w y s A J Y 2 V K o r N Q f 0 9 k J N J 6 G g W m M y I 4 0 q v e X P z P 6 6 Y Y X v s Z l 0 m K T N L l o j A V D s b O P A Z n w B W j K K a G E K q 4 u d W h I 6 I I R R N W y Y T g r b 6 8 T l q 1 q u d W v f t a u X 6 b x 1 G E M z i H S / D g C u p w B w 1 o A o U J P M M r v F m Z 9 W K 9 W x / L 1 o K V z 5 z C H 1 i f P x K 9 k 0 c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m w i D X 8 M t 4 U V t O y s T D p l 9 L I P G L f w = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u t 7 j 2 m l b 5 f d q r u A s 0 6 8 n J Q h R 6 N v f / U G M U 0 j J p E K o n X X c x P 0 M 6 K Q U 8 F m p V 6 q W U L o m A x Z 1 1 B J I q b 9 b H H 5 z L k w y s A J Y 2 V K o r N Q f 0 9 k J N J 6 G g W m M y I 4 0 q v e X P z P 6 6 Y Y X v s Z l 0 m K T N L l o j A V D s b O P A Z n w B W j K K a G E K q 4 u d W h I 6 I I R R N W y Y T g r b 6 8 T l q 1 q u d W v f t a u X 6 b x 1 G E M z i H S / D g C u p w B w 1 o A o U J P M M r v F m Z 9 W K 9 W x / L 1 o K V z 5 z C H 1 i f P x K 9 k 0 c = &lt; / l a t e x i t &gt; p u 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e m o b w 2 s X g M Y 5 6 G N k K q K E R q R 0 K k 0 = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u v X H t N K 3 y 6 7 V X c B Z 5 1 4 O S l D j k b f / u o N Y p p G T C I V R O u u 5 y b o Z 0 Q h p 4 L N S r 1 U s 4 T Q M R m y r q G S R E z 7 2 e L y m X N h l I E T x s q U R G e h / p 7 I S K T 1 N A p M Z 0 R w p F e 9 u f i f 1 0 0 x v P Y z L p M U m a T L R W E q H I y d e Q z O g C t G U U w N I V R x c 6 t D R 0 Q R i i a s k g n B W 3 1 5 n b R q V c + t e v e 1 c v 0 2 j 6 M I Z 3 A O l + D B F d T h D h r Q B A o T e I Z X e L M y 6 8 V 6 t z 6 W r Q U r n z m F P 7 A + f w A U R J N I &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e m o b w 2 s X g M Y 5 6 G N k K q K E R q R 0 K k 0 = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u v X H t N K 3 y 6 7 V X c B Z 5 1 4 O S l D j k b f / u o N Y p p G T C I V R O u u 5 y b o Z 0 Q h p 4 L N S r 1 U s 4 T Q M R m y r q G S R E z 7 2 e L y m X N h l I E T x s q U R G e h / p 7 I S K T 1 N A p M Z 0 R w p F e 9 u f i f 1 0 0 x v P Y z L p M U m a T L R W E q H I y d e Q z O g C t G U U w N I V R x c 6 t D R 0 Q R i i a s k g n B W 3 1 5 n b R q V c + t e v e 1 c v 0 2 j 6 M I Z 3 A O l + D B F d T h D h r Q B A o T e I Z X e L M y 6 8 V 6 t z 6 W r Q U r n z m F P 7 A + f w A U R J N I &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e m o b w 2 s X g M Y 5 6 G N k K q K E R q R 0 K k 0 = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u v X H t N K 3 y 6 7 V X c B Z 5 1 4 O S l D j k b f / u o N Y p p G T C I V R O u u 5 y b o Z 0 Q h p 4 L N S r 1 U s 4 T Q M R m y r q G S R E z 7 2 e L y m X N h l I E T x s q U R G e h / p 7 I S K T 1 N A p M Z 0 R w p F e 9 u f i f 1 0 0 x v P Y z L p M U m a T L R W E q H I y d e Q z O g C t G U U w N I V R x c 6 t D R 0 Q R i i a s k g n B W 3 1 5 n b R q V c + t e v e 1 c v 0 2 j 6 M I Z 3 A O l + D B F d T h D h r Q B A o T e I Z X e L M y 6 8 V 6 t z 6 W r Q U r n z m F P 7 A + f w A U R J N I &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e m o b w 2 s X g M Y 5 6 G N k K q K E R q R 0 K k 0 = " &gt; A A A B + X i c b V B N T 8 J A E J 3 i F + J X 1 a O X R j D x R F o u e i T R g 0 d M 5 C O B S r b L F j Z s t 8 3 u l E g a / o k X D x r j 1 X / i z X / j A j 0 o + J J J X t 6 b y c y 8 I B F c o + t + W 4 W N z a 3 t n e J u a W / / 4 P D I P j 5 p 6 T h V l D V p L G L V C Y h m g k v W R I 6 C d R L F S B Q I 1 g 7 G N 3 O / P W F K 8 1 g + 4 D R h f k S G k o e c E j R S 3 7 Y r P W R P G I R Z M u v X H t N K 3 y 6 7 V X c B Z 5 1 4 O S l D j k b f / u o N Y p p G T C I V R O u u 5 y b o Z 0 Q h p 4 L N S r 1 U s 4 T Q M R m y r q G S R E z 7 2 e L y m X N h l I E T x s q U R G e h / p 7 I S K T 1 N A p M Z 0 R w p F e 9 u f i f 1 0 0 x v P Y z L p M U m a T L R W E q H I y d e Q z O g C t G U U w N I V R x c 6 t D R 0 Q R i i a s k g n B W 3 1 5 n b R q V c + t e v e 1 c v 0 2 j 6 M I Z 3 A O l + D B F d T h D h r Q B A o T e I Z X</formula><p>e L M y 6 8 V 6 t z 6 W r Q U r n z m F P 7 A + f w A U R J N I &lt; / l a t e x i t &gt; p u 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 s c 5 n g 7 F a I i w C q x 8 S a s X T W 9 4 W P 8 = " &gt; A</p><formula xml:id="formula_8">A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W W w F T y U p g h 4 L e v B Y w X 5 A G 8 t m u 2 m X b j Z h d y I t I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P B N T j O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O N y W 0 e J o q x F I x G p r k 8 0 E 1 y y F n A Q r B s r R k J f s I 4 / u Z n 7 n S e m N I / k A 8 x i 5 o V k J H n A K Q E j D e x y t Q 9 s C n 6 Q x t k g v c w e k + r A r j g 1 Z w G 8 T t y c V F C O 5 s D + 6 g 8 j m o R M A h V E 6 5 7 r x O C l R A G n g m W l f q J Z T O i E j F j P U E l C p r 1 0 c X u G z 4 0 y x E G k T E n A C / X 3 R E p C r W e h b z p D A m O 9 6 s 3 F / 7 x e A s G 1 l 3 I Z J 8 A k X S 4 K E o E h w v M g 8 J A r R k H M D C F U c X M r p m O i C A U T V 8 m E 4 K 6 + v E 7 a 9 Z r r 1 N z 7 e q V x m 8 d R R K f o D F 0 g F 1 2 h B r p D T d R C F E 3 R M 3 p F b 1 Z m v V j v</formula><p>1 s e y t W D l M y f o D 6 z P H + c / l F Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 s c 5 n g 7 F a I i w C q x 8 S a s X T W 9 4 W P 8 = " &gt; A</p><formula xml:id="formula_9">A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W W w F T y U p g h 4 L e v B Y w X 5 A G 8 t m u 2 m X b j Z h d y I t I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P B N T j O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O N y W 0 e J o q x F I x G p r k 8 0 E 1 y y F n A Q r B s r R k J f s I 4 / u Z n 7 n S e m N I / k A 8 x i 5 o V k J H n A K Q E j D e x y t Q 9 s C n 6 Q x t k g v c w e k + r A r j g 1 Z w G 8 T t y c V F C O 5 s D + 6 g 8 j m o R M A h V E 6 5 7 r x O C l R A G n g m W l f q J Z T O i E j F j P U E l C p r 1 0 c X u G z 4 0 y x E G k T E n A C / X 3 R E p C r W e h b z p D A m O 9 6 s 3 F / 7 x e A s G 1 l 3 I Z J 8 A k X S 4 K E o E h w v M g 8 J A r R k H M D C F U c X M r p m O i C A U T V 8 m E 4 K 6 + v E 7 a 9 Z r r 1 N z 7 e q V x m 8 d R R K f o D F 0 g F 1 2 h B r p D T d R C F E 3 R M 3 p F b 1 Z m v V j v</formula><p>1 s e y t W D l M y f o D 6 z P H + c / l F Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 s c 5 n g 7 F a I i w C q x 8 S a s X T W 9 4 W P 8 = " &gt; A</p><formula xml:id="formula_10">A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W W w F T y U p g h 4 L e v B Y w X 5 A G 8 t m u 2 m X b j Z h d y I t I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P B N T j O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O N y W 0 e J o q x F I x G p r k 8 0 E 1 y y F n A Q r B s r R k J f s I 4 / u Z n 7 n S e m N I / k A 8 x i 5 o V k J H n A K Q E j D e x y t Q 9 s C n 6 Q x t k g v c w e k + r A r j g 1 Z w G 8 T t y c V F C O 5 s D + 6 g 8 j m o R M A h V E 6 5 7 r x O C l R A G n g m W l f q J Z T O i E j F j P U E l C p r 1 0 c X u G z 4 0 y x E G k T E n A C / X 3 R E p C r W e h b z p D A m O 9 6 s 3 F / 7 x e A s G 1 l 3 I Z J 8 A k X S 4 K E o E h w v M g 8 J A r R k H M D C F U c X M r p m O i C A U T V 8 m E 4 K 6 + v E 7 a 9 Z r r 1 N z 7 e q V x m 8 d R R K f o D F 0 g F 1 2 h B r p D T d R C F E 3 R M 3 p F b 1 Z m v V j v</formula><p>1 s e y t W D l M y f o D 6 z P H + c / l F Y = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 s c 5 n g 7 F a I i w C q x 8 S a s X T W 9 4 W P 8 = " &gt; A</p><formula xml:id="formula_11">A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W W w F T y U p g h 4 L e v B Y w X 5 A G 8 t m u 2 m X b j Z h d y I t I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P B N T j O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O N y W 0 e J o q x F I x G p r k 8 0 E 1 y y F n A Q r B s r R k J f s I 4 / u Z n 7 n S e m N I / k A 8 x i 5 o V k J H n A K Q E j D e x y t Q 9 s C n 6 Q x t k g v c w e k + r A r j g 1 Z w G 8 T t y c V F C O 5 s D + 6 g 8 j m o R M A h V E 6 5 7 r x O C l R A G n g m W l f q J Z T O i E j F j P U E l C p r 1 0 c X u G z 4 0 y x E G k T E n A C / X 3 R E p C r W e h b z p D A m O 9 6 s 3 F / 7 x e A s G 1 l 3 I Z J 8 A k X S 4 K E o E h w v M g 8 J A r R k H M D C F U c X M r p m O i C A U T V 8 m E 4 K 6 + v E 7 a 9 Z r r 1 N z 7 e q V x m 8 d R R K f o D F 0 g F 1 2 h B r p D T d R C F E 3 R M 3 p F b 1 Z m v V j v 1 s e y t W D l M y f o D 6 z P H + c / l F Y = &lt; / l a t e x i t &gt; a h &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B o / 4 1 Q e s r k V x 8 p v / 7 a h e E c x F Q = " &gt; A A A B 7 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 D j Y U i t v 4 g O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V W l X 6 O K 4 O y h W 3 5 i 5 A 1 o m X k w r k a A 7 K X / 1 h z N K I K 2 S S G t P z 3 A T 9 j G o U T P J Z q Z 8 a n l A 2 o S P e s 1 T R i B s / W x w 7 I x d W G Z I w 1 r Y U k o X 6 e y K j k T H T K L C d E c W x W f X m 4 n 9 e L 8 X w 2 s + E S l L k i i 0 X h a k k G J P 5 5 2 Q o N G c o p 5 Z Q p o W 9 l b A x 1 Z S h z a d k Q / B W X 1 4 n 7 X r N c 2 v e f b 3 S u M 3 j K M I Z n M M l e H A F D b i D J r S A g Y B n e I U 3 R z k v z r v z s W w t O P n M K f y B 8 / k D 8 y C O G w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B o / 4 1 Q e s r k V x 8 p v / 7 a h e E c x F Q = " &gt; A A A B 7 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 D j Y U i t v 4 g O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V W l X 6 O K 4 O y h W 3 5 i 5 A 1 o m X k w r k a A 7 K X / 1 h z N K I K 2 S S G t P z 3 A T 9 j G o U T P J Z q Z 8 a n l A 2 o S P e s 1 T R i B s / W x w 7 I x d W G Z I w 1 r Y U k o X 6 e y K j k T H T K L C d E c W x W f X m 4 n 9 e L 8 X w 2 s + E S l L k i i 0 X h a k k G J P 5 5 2 Q o N G c o p 5 Z Q p o W 9 l b A x 1 Z S h z a d k Q / B W X 1 4 n 7 X r N c 2 v e f b 3 S u M 3 j K M I Z n M M l e H A F D b i D J r S A g Y B n e I U 3 R z k v z r v z s W w t O P n M K f y B 8 / k D 8 y C O G w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B o / 4 1 Q e s r k V x 8 p v / 7 a h e E c x F Q = " &gt; A A A B 7 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 D j Y U i t v 4 g O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V W l X 6 O K 4 O y h W 3 5 i 5 A 1 o m X k w r k a A 7 K X / 1 h z N K I K 2 S S G t P z 3 A T 9 j G o U T P J Z q Z 8 a n l A 2 o S P e s 1 T R i B s / W x w 7 I x d W G Z I w 1 r Y U k o X 6 e y K j k T H T K L C d E c W x W f X m 4 n 9 e L 8 X w 2 s + E S l L k i i 0 X h a k k G J P 5 5 2 Q o N G c o p 5 Z Q p o W 9 l b A x 1 Z S h z a d k Q / B W X 1 4 n 7 X r N c 2 v e f b 3 S u M 3 j K M I Z n M M l e H A F D b i D J r S A g Y B n e I U 3 R z k v z r v z s W w t O P n M K f y B 8 / k D 8 y C O G w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K i B o / 4 1 Q e s r k V x 8 p v / 7 a h e E c x F Q = " &gt; A A A B 7 H i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 e 8 m S v b 1 j d 0 4 I R 3 6 D j Y U i t v 4 g O / + N m + Q K T X w w 8 H h v h p l 5 Q S K F Q d f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k b e J U M 9 5 i s Y x 1 N 6 C G S 6 F 4 C w V K 3 k 0 0 p 1 E g e S e Y 3 M z 9 z h P X R s T q A a c J 9 y M 6 U i I U j K K V W l X 6 O K 4 O y h W 3 5 i 5 A 1 o m X k w r k a A 7 K X / 1 h z N K I K 2 S S G t P z 3 A T 9 j G o U T P J Z q Z 8 a n l A 2 o S P e s 1 T R i B s / W x w 7 I x d W G Z I w 1 r Y U k o X 6 e y K j k T H T K L C d E c W x W f X m 4 n 9 e L 8 X w 2 s + E S l L k i i 0 X h a k k G J P 5 5 2 Q o N G c o p 5 Z Q p o W 9 l b A x 1 Z S h z a d k Q / B W X 1 4 n 7 X r N c 2 v e f b 3 S u M 3 j K M I Z n M M l e H A F D b i D J r S A g Y B n e I U 3 R z k v z r v z s W w t O P n M K f y B 8 / k D 8 y C O G w = = &lt; / l a t e x i t &gt; E u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_12">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_13">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_14">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; 1 0 Êu &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q g x R u i M H a 4 t g B r 8</p><formula xml:id="formula_15">I G b A w 5 n f A 5 D o = " &gt; A A A B / n i c b V B N S 8 N A F N z U r 1 q / o u L J y 2 I r e C p J L 3 o s q O C x g q 2 F J p a X 7 a Z d u t m E 3 Y 1 Q Q s G / 4 s W D I l 7 9 H d 7 8 N 2 7 a H L R 1 Y G G Y e Y 8 3 O 0 H C m d K O 8 2 2 V V l b X 1 j f K m 5 W t 7 Z 3 d P X v / o K P i V B L a J j G P Z T c A R T k T t K 2 Z 5 r S b S A p R w O l 9 M L 7 M / f t H K h W L x Z 2 e J N S P Y C h Y y A h o I / X t o 5 o 3 A p 1 5 E e g R A Z 5 d T 6 c P a a 1 v V 5 2 6 M w N e J m 5 B q q h A q 2 9 / e Y O Y p B E V m n B Q q u c 6 i f Y z k J o R T q c V L 1 U 0 A T K G I e 0 Z K i C i y s 9 m 8 a f 4 1 C g D H M b S P K H x T P 2 9 k U G k 1 C Q K z G Q e U y 1 6 u f i f 1 0 t 1 e O F n T C S p p o L M D 4 U p x z r G e R d 4 w C Q l m k 8 M A S K Z y Y r J C C Q Q b R q r m B L c x S 8 v k 0 6 j 7 j p 1 9 7 Z R b V 4 V d Z T R M T p B Z 8 h F 5 6 i J b l A L t R F B G X p G r + j N e r J e r H f r Y z 5 a s o q d Q / Q H 1 u c P L E u V n A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q g x R u i M H a 4 t g B r 8 I G b A w 5 n f A 5 D o = " &gt; A A A B / n i c b V B N S 8 N A F N z U r 1 q / o u L J y 2 I r e C p J L 3 o s q O C x g q 2 F J p a X 7 a Z d u t m E 3 Y 1 Q Q s G / 4 s W D I l 7 9 H d 7 8 N 2 7 a H L R 1 Y G G Y e Y 8 3 O 0 H C m d K O 8 2 2 V V l b X 1 j f K m 5 W t 7 Z 3 d P X v / o K P i V B L a J j G P Z T c A R T k T t K 2 Z 5 r S b S A p R w O l 9 M L 7 M / f t H K h W L x Z 2 e J N S P Y C h Y y A h o I / X t o 5 o 3 A p 1 5 E e g R A Z 5 d T 6 c P a a 1 v V 5 2 6 M w N e J m 5 B q q h A q 2 9 / e Y O Y p B E V m n B Q q u c 6 i f Y z k J o R T q c V L 1 U 0 A T K G I e 0 Z K i C i y s 9 m 8 a f 4 1 C g D H M b S P K H x T P 2 9 k U G k 1 C Q K z G Q e U y 1 6 u f i f 1 0 t 1 e O F n T C S p p o L M D 4 U p x z r G e R d 4 w C Q l m k 8 M A S K Z y Y r J C C Q Q b R q r m B L c x S 8 v k 0 6 j 7 j p 1 9 7 Z R b V 4 V d Z T R M T p B Z 8 h F 5 6 i J b l A L t R F B G X p G r + j N e r J e r H f r Y z 5 a s o q d Q / Q H 1 u c P L E u V n A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q g x R u i M H a 4 t g B r 8 I G b A w 5 n f A 5 D o = " &gt; A A A B / n i c b V B N S 8 N A F N z U r 1 q / o u L J y 2 I r e C p J L 3 o s q O C x g q 2 F J p a X 7 a Z d u t m E 3 Y 1 Q Q s G / 4 s W D I l 7 9 H d 7 8 N 2 7 a H L R 1 Y G G Y e Y 8 3 O 0 H C m d K O 8 2 2 V V l b X 1 j f K m 5 W t 7 Z 3 d P X v / o K P i V B L a J j G P Z T c A R T k T t K 2 Z 5 r S b S A p R w O l 9 M L 7 M / f t H K h W L x Z 2 e J N S P Y C h Y y A h o I / X t o 5 o 3 A p 1 5 E e g R A Z 5 d T 6 c P a a 1 v V 5 2 6 M w N e J m 5 B q q h A q 2 9 / e Y O Y p B E V m n B Q q u c 6 i f Y z k J o R T q c V L 1 U 0 A T K G I e 0 Z K i C i y s 9 m 8 a f 4 1 C g D H M b S P K H x T P 2 9 k U G k 1 C Q K z G Q e U y 1 6 u f i f 1 0 t 1 e O F n T C S p p o L M D 4 U p x z r G e R d 4 w C Q l m k 8 M A S K Z y Y r J C C Q Q b R q r m B L c x S 8 v k 0 6 j 7 j p 1 9 7 Z R b V 4 V d Z T R M T p B Z 8 h F 5 6 i J b l A L t R F B G X p G r + j N e r J e r H f r Y z 5 a s o q d Q / Q H 1 u c P L E u V n A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q g x R u i M H a 4 t g B r 8 I G b A w 5 n f A 5 D o = " &gt; A A A B / n i c b V B N S 8 N A F N z U r 1 q / o u L J y 2 I r e C p J L 3 o s q O C x g q 2 F J p a X 7 a Z d u t m E 3 Y 1 Q Q s G / 4 s W D I l 7 9 H d 7 8 N 2 7 a H L R 1 Y G G Y e Y 8 3 O 0 H C m d K O 8 2 2 V V l b X 1 j f K m 5 W t 7 Z 3 d P X v / o K P i V B L a J j G P Z T c A R T k T t K 2 Z 5 r S b S A p R w O l 9 M L 7 M / f t H K h W L x Z 2 e J N S P Y C h Y y A h o I / X t o 5 o 3 A p 1 5 E e g R A Z 5 d T 6 c P a a 1 v V 5 2 6 M w N e J m 5 B q q h A q 2 9 / e Y O Y p B E V m n B Q q u c 6 i f Y z k J o R T q c V L 1 U 0 A T K G I e 0 Z K i C i y s 9 m 8 a f 4 1 C g D H M b S P K H x T P 2 9 k U G k 1 C Q K z G Q e U y 1 6 u f i f 1 0 t 1 e O F n T C S p p o L M D 4 U p x z r G e R d 4 w C Q l m k 8 M A S K Z y Y r J C C Q Q b R q r m B L c x S 8 v k 0 6 j 7 j p 1 9 7 Z R b V 4 V d Z T R M T p B Z 8 h F 5 6 i J b l A L t R F B G X p G r + j N e r J e r H f r Y z 5 a s o q d Q / Q H 1 u c P L E u V n A = = &lt; / l a t e x i t &gt; : e u 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r f 0 R Y K u H V 5 w R / X j t 1 i y K H I U 4 i s o = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 q D + m N a H Z Q r b s 1 d g K w T L y c V y N E c l L / 6 w 5 i l E U r D B N W 6 5 7 m J 8 T O q D G c C Z 6 V + q j G h b E J H 2 L N U 0 g i 1 n y 3 O n Z E L q w x J G C t b 0 p C F + n s i o 5 H W 0 y i w n R E 1 Y 7 3 q z c X / v F 5 q w m s / 4 z J J D U q 2 X B S m g p i Y z H 8 n Q 6 6 Q G T G 1 h D L F 7 a 2 E j a m i z N i E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E 1 3 Y 7 R &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r f 0 R Y K u H V 5 w R / X j t 1 i y K H I U 4 i s o = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 q D + m N a H Z Q r b s 1 d g K w T L y c V y N E c l L / 6 w 5 i l E U r D B N W 6 5 7 m J 8 T O q D G c C Z 6 V + q j G h b E J H 2 L N U 0 g i 1 n y 3 O n Z E L q w x J G C t b 0 p C F + n s i o 5 H W 0 y i w n R E 1 Y 7 3 q z c X / v F 5 q w m s / 4 z J J D U q 2 X B S m g p i Y z H 8 n Q 6 6 Q G T G 1 h D L F 7 a 2 E j a m i z N i E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E 1 3 Y 7 R &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r f 0 R Y K u H V 5 w R / X j t 1 i y K H I U 4 i s o = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 q D + m N a H Z Q r b s 1 d g K w T L y c V y N E c l L / 6 w 5 i l E U r D B N W 6 5 7 m J 8 T O q D G c C Z 6 V + q j G h b E J H 2 L N U 0 g i 1 n y 3 O n Z E L q w x J G C t b 0 p C F + n s i o 5 H W 0 y i w n R E 1 Y 7 3 q z c X / v F 5 q w m s / 4 z J J D U q 2 X B S m g p i Y z H 8 n Q 6 6 Q G T G 1 h D L F 7 a 2 E j a m i z N i E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E 1 3 Y 7 R &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r f 0 R Y K u H V 5 w R / X j t 1 i y K H I U 4 i s o = " &gt; A A A B 7 n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F h P B K t y l 0 T K g h W U E 8 w H J G f Y 2 c 8 m S v b 1 j d 0 8 I R 3 6 E j Y U i t v 4 e O / + N m + Q K T X w w 8 H h v h p l 5 Q S K 4 N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 8 e p Y t h i s Y h V N 6 A a B Z f Y M t w I 7 C Y K a R Q I 7 A S T m 7 n f e U K l e S w f z D R B P 6 I j y U P O q L F S p 4 q D + m N a H Z Q r b s 1 d g K w T L y c V y N E c l L / 6 w 5 i l E U r D B N W 6 5 7 m J 8 T O q D G c C Z 6 V + q j G h b E J H 2 L N U 0 g i 1 n y 3 O n Z E L q w x J G C t b 0 p C F + n s i o 5 H W 0 y i w n R E 1 Y 7 3 q z c X / v F 5 q w m s / 4 z J J D U q 2 X B S m g p i Y z H 8 n Q 6 6 Q G T G 1 h D L F 7 a 2 E j a m i z N i E S j Y E b / X l d d K u 1 z y 3 5 t 3 X K 4 3 b P I 4 i n M E 5 X I I H V 9 C A O 2 h C C x h M 4 B l e 4 c 1 J n B f n 3 f l Y t h a c f O Y U / s D 5 / A E 1 3 Y 7 R &lt; / l a t e x i t &gt; 0 1 1 a l 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y p Z 5 s H / N + t S w Z r o m / 0 / 6 k 9 8 g n F w = " &gt; A A A B 8 H i c b V A 9 T 8 M w E L 2 U r 1 K + C o w s F i 0 S U 5 W U A c Z K M D A W i X 6 g N l S O 6 7 R W b S e y H a Q q 6 q 9 g Y Q A h V n 4 O G / 8 G p 8 0 A L U 8 6 6 e m 9 O 9 3 d C 2 L O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p K F K E t E v F I d Q O s K W e S t g w z n H Z j R b E I O O 0 E k + v M 7 z x R p V k k 7 8 0 0 p r 7 A I 8 l C R r C x 0 k M V D 9 K L 2 S O v D s o V t + b O g V a J l 5 M K 5 G g O y l / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O Z 6 V + o m m M y Q S P a M 9 S i Q X V f j o / e I b O r D J E Y a R s S Y P m 6 u + J F A u t p y K w n Q K b s V 7 2 M v E / r 5 e Y 8 M p P m Y w T Q y V Z L A o T j k y E s u / R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x G J R u C t / z y K m n X a 5 5 b 8 + 7 q l c Z N H k c R T u A U z s G D S 2 j A L T S h B Q Q E P M M r v D n K e</formula><p>X H e n Y 9 F a 8 H J Z 4 7 h D 5 z P H + s 9 j 9 E = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y p Z 5 s H / N + t S w Z r o m / 0 / 6 k 9 8 g n F w</p><formula xml:id="formula_16">= " &gt; A A A B 8 H i c b V A 9 T 8 M w E L 2 U r 1 K + C o w s F i 0 S U 5 W U A c Z K M D A W i X 6 g N l S O 6 7 R W b S e y H a Q q 6 q 9 g Y Q A h V n 4 O G / 8 G p 8 0 A L U 8 6 6 e m 9 O 9 3 d C 2 L O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p K F K E t E v F I d Q O s K W e S t g w z n H Z j R b E I O O 0 E k + v M 7 z x R p V k k 7 8 0 0 p r 7 A I 8 l C R r C x 0 k M V D 9 K L 2 S O v D s o V t + b O g V a J l 5 M K 5 G g O y l / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O Z 6 V + o m m M y Q S P a M 9 S i Q X V f j o / e I b O r D J E Y a R s S Y P m 6 u + J F A u t p y K w n Q K b s V 7 2 M v E / r 5 e Y 8 M p P m Y w T Q y V Z L A o T j k y E s u / R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x G J R u C t / z y K m n X a 5 5 b 8 + 7 q l c Z N H k c R T u A U z s G D S 2 j A L T S h B Q Q E P M M r v D n K e</formula><p>X H e n Y 9 F a 8 H J Z 4 7 h D 5 z P H + s 9 j 9 E = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y p Z 5 s H / N + t S w Z r o m / 0 / 6 k 9 8 g n F w</p><formula xml:id="formula_17">= " &gt; A A A B 8 H i c b V A 9 T 8 M w E L 2 U r 1 K + C o w s F i 0 S U 5 W U A c Z K M D A W i X 6 g N l S O 6 7 R W b S e y H a Q q 6 q 9 g Y Q A h V n 4 O G / 8 G p 8 0 A L U 8 6 6 e m 9 O 9 3 d C 2 L O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p K F K E t E v F I d Q O s K W e S t g w z n H Z j R b E I O O 0 E k + v M 7 z x R p V k k 7 8 0 0 p r 7 A I 8 l C R r C x 0 k M V D 9 K L 2 S O v D s o V t + b O g V a J l 5 M K 5 G g O y l / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O Z 6 V + o m m M y Q S P a M 9 S i Q X V f j o / e I b O r D J E Y a R s S Y P m 6 u + J F A u t p y K w n Q K b s V 7 2 M v E / r 5 e Y 8 M p P m Y w T Q y V Z L A o T j k y E s u / R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x G J R u C t / z y K m n X a 5 5 b 8 + 7 q l c Z N H k c R T u A U z s G D S 2 j A L T S h B Q Q E P M M r v D n K e</formula><p>X H e n Y 9 F a 8 H J Z 4 7 h D 5 z P H + s 9 j 9 E = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y p Z 5 s H / N + t S w Z r o m / 0 / 6 k 9 8 g n F w</p><formula xml:id="formula_18">= " &gt; A A A B 8 H i c b V A 9 T 8 M w E L 2 U r 1 K + C o w s F i 0 S U 5 W U A c Z K M D A W i X 6 g N l S O 6 7 R W b S e y H a Q q 6 q 9 g Y Q A h V n 4 O G / 8 G p 8 0 A L U 8 6 6 e m 9 O 9 3 d C 2 L O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p K F K E t E v F I d Q O s K W e S t g w z n H Z j R b E I O O 0 E k + v M 7 z x R p V k k 7 8 0 0 p r 7 A I 8 l C R r C x 0 k M V D 9 K L 2 S O v D s o V t + b O g V a J l 5 M K 5 G g O y l / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O Z 6 V + o m m M y Q S P a M 9 S i Q X V f j o / e I b O r D J E Y a R s S Y P m 6 u + J F A u t p y K w n Q K b s V 7 2 M v E / r 5 e Y 8 M p P m Y w T Q y V Z L A o T j k y E s u / R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x G J R u C t / z y K m n X a 5 5 b 8 + 7 q l c Z N H k c R T u A U z s G D S 2 j A L T S h B Q Q E P M M r v D n K e</formula><p>X H e n Y 9 F a 8 H J Z 4 7 h D 5 z P H + s 9 j 9 E = &lt; / l a t e x i t &gt; a l 4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + T 5 s y 6 y</p><formula xml:id="formula_19">X B D O 7 h J i L a z Y d R g o v N S 0 = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C b a C p 7 J b B D 0 W 9 O C x g v 2 Q d i 3 Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b s + 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d 5 6 o 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a G K B + n F 7 J F X B + W K W 3 P n Q K v E y 0 k F c j Q H 5 a / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n s 1 I / 0 T T G Z I J H t G e p x I J q P 5 0 f P E N n V h m i M F K 2 p E F z 9 f d E i o X W U x H Y T o H N W C 9 7 m f i f 1 0 t M e O W n T M a J o Z I s F o U J R y Z C 2 f d o y B Q l h k 8 t w U Q x e</formula><p>y s i Y 6 w w M T a j k g 3 B W 3 5 5 l b T r N c + t e X f 1 S u M m j 6 M I J 3 A K 5 + D B J T T g F p r Q A g I C n u E V 3 h z l v D j v z s e i t e D k M 8 f w B 8 7 n D + z F j 9 I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + T 5 s y 6 y</p><formula xml:id="formula_20">X B D O 7 h J i L a z Y d R g o v N S 0 = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C b a C p 7 J b B D 0 W 9 O C x g v 2 Q d i 3 Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b s + 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d 5 6 o 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a G K B + n F 7 J F X B + W K W 3 P n Q K v E y 0 k F c j Q H 5 a / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n s 1 I / 0 T T G Z I J H t G e p x I J q P 5 0 f P E N n V h m i M F K 2 p E F z 9 f d E i o X W U x H Y T o H N W C 9 7 m f i f 1 0 t M e O W n T M a J o Z I s F o U J R y Z C 2 f d o y B Q l h k 8 t w U Q x e</formula><p>y s i Y 6 w w M T a j k g 3 B W 3 5 5 l b T r N c + t e X f 1 S u M m j 6 M I J 3 A K 5 + D B J T T g F p r Q A g I C n u E V 3 h z l v D j v z s e i t e D k M 8 f w B 8 7 n D + z F j 9 I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + T 5 s y 6 y</p><formula xml:id="formula_21">X B D O 7 h J i L a z Y d R g o v N S 0 = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C b a C p 7 J b B D 0 W 9 O C x g v 2 Q d i 3 Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b s + 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d 5 6 o 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a G K B + n F 7 J F X B + W K W 3 P n Q K v E y 0 k F c j Q H 5 a / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n s 1 I / 0 T T G Z I J H t G e p x I J q P 5 0 f P E N n V h m i M F K 2 p E F z 9 f d E i o X W U x H Y T o H N W C 9 7 m f i f 1 0 t M e O W n T M a J o Z I s F o U J R y Z C 2 f d o y B Q l h k 8 t w U Q x e</formula><p>y s i Y 6 w w M T a j k g 3 B W 3 5 5 l b T r N c + t e X f 1 S u M m j 6 M I J 3 A K 5 + D B J T T g F p r Q A g I C n u E V 3 h z l v D j v z s e i t e D k M 8 f w B 8 7 n D + z F j 9 I = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " + T 5 s y 6 y </p><formula xml:id="formula_22">X B D O 7 h J i L a z Y d R g o v N S 0 = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C b a C p 7 J b B D 0 W 9 O C x g v 2 Q d i 3 Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b s + 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H b R 0 l i t A W i X i k u g H W l D N J W 4 Y Z T r u x o l g E n H a C y X X m d 5 6 o 0 i y S 9 2 Y a U 1 / g k W Q h I 9 h Y 6 a G K B + n F 7 J F X B + W K W 3 P n Q K v E y 0 k F c j Q H 5 a / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n s 1 I / 0 T T G Z I J H t G e p x I J q P 5 0 f P E N n V h m i M F K 2 p E F z 9 f d E i o X W U x H Y T o H N W C 9 7 m f i f 1 0 t M e O W n T M a J o Z I s F o U J R y Z C 2 f d o y B Q l h k 8 t w U Q x e</formula><formula xml:id="formula_23">v 5 B 8 f C o q a N E M W y w S E S q H V C N g o f Y M N w I b M c K q Q w E t o L x 9 c x v P a H S P A r v z S R G X 9 J h y A e c U W O l h z L 2 0 o v p Y 1 L u F U t u x Z 2 D r B I v I y X I U O 8 V v 7 r 9 i C U S Q 8 M E 1 b r j u b H x U 6 o M Z w K n h W 6 i M a Z s T I f Y s T S k E r W f z g + e k j O r 9 M k g U r Z C Q + b q 7 4 m U S q 0 n M r C d k p q R X v Z m 4 n 9 e J z G D K z / l Y Z w Y D N l i 0 S A R x E R k 9 j 3 p c 4 X M i I k l l C l u b y V s R B V l</formula><p>x m Z U s C F 4 y y + v k m a 1 4 r k V 7 6 5 a q t 1 k c e T h B E 7 h H D y 4 h B r c Q h 0 a w E D C M 7 z C m 6 O c F + f d + V i 0 5 p x s 5 h j + w P n 8 A f 8 W j 9 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n V 5</p><formula xml:id="formula_24">I G V y T g p c v f s F w c m M Z f 4 v 9 j t k = " &gt; A A A B 8 H i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s s t C T R w h I T + T B w k r 1 l g A 2 7 d 5 f d P R N y 4 V f Y W G i M r T / H z n / j A l c o + J J J X t 6 b y c y 8 I B Z c G 9 f 9 d n J r 6 x u b W / n t w s 7 u 3 v 5 B 8 f C o q a N E M W y w S E S q H V C N g o f Y M N w I b M c K q Q w E t o L x 9 c x v P a H S P A r v z S R G X 9 J h y A e c U W O l h z L 2 0 o v p Y 1 L u F U t u x Z 2 D r B I v I y X I U O 8 V v 7 r 9 i C U S Q 8 M E 1 b r j u b H x U 6 o M Z w K n h W 6 i M a Z s T I f Y s T S k E r W f z g + e k j O r 9 M k g U r Z C Q + b q 7 4 m U S q 0 n M r C d k p q R X v Z m 4 n 9 e J z G D K z / l Y Z w Y D N l i 0 S A R x E R k 9 j 3 p c 4 X M i I k l l C l u b y V s R B V l</formula><p>x m Z U s C F 4 y y + v k m a 1 4 r k V 7 6 5 a q t 1 k c e T h B E 7 h H D y 4 h B r c Q h 0 a w E D C M 7 z C m 6 O c F + f d + V i 0 5 p x s 5 h j + w P n 8 A f 8 W j 9 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n V 5</p><formula xml:id="formula_25">I G V y T g p c v f s F w c m M Z f 4 v 9 j t k = " &gt; A A A B 8 H i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s s t C T R w h I T + T B w k r 1 l g A 2 7 d 5 f d P R N y 4 V f Y W G i M r T / H z n / j A l c o + J J J X t 6 b y c y 8 I B Z c G 9 f 9 d n J r 6 x u b W / n t w s 7 u 3 v 5 B 8 f C o q a N E M W y w S E S q H V C N g o f Y M N w I b M c K q Q w E t o L x 9 c x v P a H S P A r v z S R G X 9 J h y A e c U W O l h z L 2 0 o v p Y 1 L u F U t u x Z 2 D r B I v I y X I U O 8 V v 7 r 9 i C U S Q 8 M E 1 b r j u b H x U 6 o M Z w K n h W 6 i M a Z s T I f Y s T S k E r W f z g + e k j O r 9 M k g U r Z C Q + b q 7 4 m U S q 0 n M r C d k p q R X v Z m 4 n 9 e J z G D K z / l Y Z w Y D N l i 0 S A R x E R k 9 j 3 p c 4 X M i I k l l C l u b y V s R B V l x m Z U s C F 4 y y + v k m a 1 4 r k V 7 6 5 a q t 1 k c e T h B E 7 h H D y 4 h B r c Q h 0 a w E D C M 7 z C m 6 O c F + f d + V i</formula><p>0 5 p x s 5 h j + w P n 8 A f 8 W j 9 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n </p><formula xml:id="formula_26">V 5 I G V y T g p c v f s F w c m M Z f 4 v 9 j t k = " &gt; A A A B 8 H i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s s t C T R w h I T + T B w k r 1 l g A 2 7 d 5 f d P R N y 4 V f Y W G i M r T / H z n / j A l c o + J J J X t 6 b y c y 8 I B Z c G 9 f 9 d n J r 6 x u b W / n t w s 7 u 3 v 5 B 8 f C o q a N E M W y w S E S q H V C N g o f Y M N w I b M c K q Q w E t o L x 9 c x v P a H S P A r v z S R G X 9 J h y A e c U W O l h z L 2 0 o v p Y 1 L u F U t u x Z 2 D r B I v I y X I U O 8 V v 7 r 9 i C U S Q 8 M E 1 b r j u b H x U 6 o M Z w K n h W 6 i M a Z s T I f Y s T S k E r W f z g + e k j O r 9 M k g U r Z C Q + b q 7 4 m U S q 0 n M r C d k p q R X v Z m 4 n 9 e J z G D K z / l Y Z w Y D N l i 0 S A R x E R k 9 j 3 p c 4 X M i I k l l C l u b y V s R B V l x m Z U s C F 4 y y + v k m a 1 4 r k V 7 6 5 a q t 1 k c e T h B E 7 h H D y 4 h B r c Q h 0 a w E D C M 7 z C m 6 O c F + f d + V i</formula><formula xml:id="formula_27">= " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_28">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_29">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k L 1 N 2 e i X + F V + y k i T L U i e a r J 0 X 8 4 = " &gt; A</p><formula xml:id="formula_30">A A B + H i c b V D L S s N A F L 3 x W e u j U Z d u B l v B V U m 6 0 W V B B Z c V 7 A P a W C b T a T t 0 M g n z E G r o l 7 h x o Y h b P 8 W d f + O k z U J b D w w c z r m X e + a E C W d K e 9 6 3 s 7 a + s b m 1 X d g p 7 u 7 t H 5 T c w 6 O W i o 0 k t E l i H s t O i B X l T N C m Z p r T T i I p j k J O 2 + H k K v P b j 1 Q q F o t 7 P U 1 o E O G R Y E N G s L Z S 3 y 1 V e h H W Y 4 J 5 e j N 7 M J W + W / a q 3 h x o l f g 5 K U O O R t / 9 6 g 1 i Y i I q N O F Y q a 7 v J T p I s d S M c D o r 9 o y i C S Y T P K J d S w W O q A r S e f A Z O r P K A A 1 j a Z / Q a K 7 + 3 k h x p N Q 0 C u 1 k l l I t e 5 n 4 n 9 c 1 e n g Z p E w k R l N B F o e G h i M d o 6 w F N G C S E s 2 n l m A i m c 2 K y B h L T L T t q m h L 8 J e / v E p a t a r v V f 2 7 W r l + n d d R g B M 4 h X P w 4 Q L q c A s N a A I B A 8 / w C m / O k / P i v D</formula><p>s f i 9 E 1 J 9 8 5 h j 9 w P n 8 A P 5 i S z w = = &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original profile</head><p>Figure <ref type="figure">3</ref>: The overall framework of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>Although the basic recommendation models can estimate an attention coefficient for each historical course, the effects of the contributing courses to the target one may be diluted by the irrelevant ones when users enrolled many diverse courses. To deal with this issue, we propose a model to revise the user profiles by removing the noisy courses from the history, and recommend courses based on the revised profiles. The key challenge is how to determine which historical courses are the noises without direct supervision, i.e., identify the courses that disturb the recommendation performance. Thus, we propose a hierarchical reinforcement learning algorithm to solve it. Specifically, we formalize the revising process of a user profile to be a hierarchical sequential decision process by an agent. Following a revising policy, a high-level and a low-level task are performed to revise the profile. After the whole profile of a user is revised, the agent gets a delayed reward from the environment, based on which it updates its policy. The environment can be viewed as the dataset and a pre-trained basic recommendation model as introduced in the previous section. After the policy is updated, the basic recommendation model is re-trained based on the profiles revised by the agent. Essentially, the profile reviser and the recommendation model are jointly trained. Figure <ref type="figure">3</ref> illustrates the framework of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Profile Reviser</head><p>As mentioned before, the profile reviser aims to remove the noisy courses with few contributions in a prediction. Inspired by the theory of hierarchical abstract machines <ref type="bibr" target="#b15">(Parr and Russell 1998)</ref>, we cast the task of profile reviser as a hierarchical Markov Decision Process (MDP). Generally speaking, we decompose the overall task MDP M into two kinds of subtasks M h and M l , where M h is the high-level abstract task in the hierarchy and solving it solves the entire MDP M , and M l is the low-level primitive task in the hierarchy. Each kind of task is defined as a 4-tuple MDP (S, A, T , R), where S is a set of states, A is a set of actions, T is a transition model mapping S × A × S into probabilities in [0,1], and R is a reward function mapping S × A × S into real-valued rewards. We formulate our task by a high-level task and a low-level task. Specifically, given a sequence of historical courses E u := (e u 1 , • • • , e u tu ) of user u and the target course c i , the agent performs a high-level task of one binary action to determine whether to revise the whole profile E u or not. If it decides to revise E u , the agent performs HRL+NAIS: is the proposed model that adopts NAIS as the basic recommendation model and we jointly train it with the hierarchical reinforcement learning (HRL) based profile reviser.</p><p>HRL+NASR: is also the proposed model but adopts NASR as the basic recommendation model. Evaluation Metrics. We evaluate all the methods in terms of the widely used metrics Hit Ratio of top K items (HR@K) and Normalized Discounted Cumulative Gain of top K items (NDCG@K), where HR@K is a recall-based metric that measures the percentage of the ground truth instances that are successfully recommended in top-K, and NDCG@K is a precision-based metrics that accounts for the predicted position of the ground truth instance <ref type="bibr" target="#b10">(Huang et al. 2018;</ref><ref type="bibr" target="#b8">He et al. 2018;</ref><ref type="bibr" target="#b18">Rendle, Freudenthaler, and Schmidt-Thieme 2010)</ref>. We set K as 5 and 10 and calculate all the metrics for every 100 instances (1 positive plus 99 negatives) and report the average score of all the users. Implementaion Details. We implement the model by Tensorflow and run the code on an Enterprise Linux Server with 40 Intel(R) Xeon(R) CPU cores (E5-2630 and 512G memory) and 1 NVIDIA TITAN V GPU core (12G memory). For the profile reviser, sampling time M is set as 3, the learning rate is set as 0.001/0.0005 at the pre-training and joint-training stage respectively. In the policy function, the dimensions of the hidden layer d l 2 and d h 2 are both set as 8. For the basic recommender, the dimension of the course embeddings is set to 16, the learning rate is 0.01 at both the pre-training and joint-training stage, and the size of the minibatch is 256. The delayed coefficient λ for the joint-training is 0.0005. The code is online now 3 . the number of the remaining courses is almost the same as those by HRL+NAIS.</p><p>Compared with Attentions Coefficients. We present several cases of the revised profiles by the proposed HRL+NAIS and show three cases and the corresponding learned attention coefficients by NAIS in Table <ref type="table" target="#tab_2">2</ref>. The cases present that HRL+NAIS can definitely remove the noisy courses in the profile that are totally irrelevant to the target course. In contrary, although NAIS assigns high attentions to the contributing historical courses, the attentions of some other irrelevant courses are not significantly different, or even higher than the relevant ones, thus the effects of the real contributing courses are discounted after aggregating all the historical courses by their attentions. As a result, the performance of the recommendation model based on the discriminative revised profiles is improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Collaborative filtering (CF) is widely used to do recommendation. User-to-item based CF, such as matrix factorization <ref type="bibr" target="#b12">(Koren, Bell, and Volinsky 2009)</ref>, bayesian personalized ranking (BPR) <ref type="bibr" target="#b17">(Rendle et al. 2009</ref>) and factorization machine (FM) <ref type="bibr" target="#b19">(Rendle 2012</ref>) performs recommendation based on both the user and item embeddings. These shallow models are further extended to deep neural network models <ref type="bibr" target="#b5">(He et al. 2017;</ref><ref type="bibr" target="#b5">Guo et al. 2017;</ref><ref type="bibr" target="#b28">Zhang, Du, and Wang 2016)</ref>. The user-to-item CF suffers from the sparsity of users' profiles. On the contrary, the item-to-item CF does not need to estimate user embeddings, and is heavily adopted in industrial applications <ref type="bibr" target="#b2">(Davidson et al. 2010;</ref><ref type="bibr" target="#b21">Smith and Linden 2017)</ref>. Early item-to-item based CF uses heuristic metrics such as Pearson coefficient or cosine similarity to estimate item similarities <ref type="bibr" target="#b20">(Sarwar et al. 2001)</ref>, followed by a machine learning method which calculates the item similarity as the dot product of item embeddings (Kabbur, Ning, and Karypis 2013). Sequential based models such as RNN (Tan, Xu, and Liu 2016) and GRU <ref type="bibr" target="#b9">(Hidasi et al. 2016</ref>) are proposed to capture the temporal factor. Then the attention-based models such as NAIS <ref type="bibr" target="#b8">(He et al. 2018)</ref> and NASR <ref type="bibr" target="#b13">(Li et al. 2017)</ref> are further proposed to distinguish the effects of different items. Several researches are conducted on MOOCs platforms, such as learning behavior analysis <ref type="bibr" target="#b0">(Anderson et al. 2014;</ref><ref type="bibr" target="#b17">Qiu et al. 2016;</ref><ref type="bibr" target="#b16">Qi et al. 2018</ref>) and course recommendation (Jing and <ref type="bibr">Tang 2017)</ref>. They focus on extracting features from multi-mode data sources besides the enrolled behaviors of users, thus it is unfair to compare with their methods.</p><p>Recently, some researchers attempt to adopt the reinforce-ment learning algorithm to solve many kinds of problems, such as relation classification <ref type="bibr" target="#b3">(Feng et al. 2018</ref>), text classification <ref type="bibr" target="#b29">(Zhang, Huang, and Zhao 2018)</ref>, information extraction <ref type="bibr" target="#b14">(Narasimhan, Yala, and Barzilay 2016)</ref>, question answering <ref type="bibr" target="#b26">(Wang et al. 2018b</ref>) and treatment recommendation <ref type="bibr" target="#b25">(Wang et al. 2018a</ref>). Inspired by these successful attempts, we propose a hierarchal reinforcement learning algorithm to conduct course recommendation. Hierarchical reinforcement learning aims at decomposing complex tasks into multiple small tasks to reduce the complexity of decision making <ref type="bibr" target="#b1">(Barto and Mahadevan 2003)</ref>, where different HRLs such as option-based HRL that formulates the abstract knowledge and action as options <ref type="bibr" target="#b23">(Sutton, Precup, and Singh 1999)</ref> and the hierarchical abstract machines (HAMs) that decomposes high-level activities into low-level activities <ref type="bibr" target="#b23">(Sutton, Precup, and Singh 1999)</ref> are proposed. We formalize our problem by the theory of HAMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We present the first attempt to solve the problem of course recommendation in MOOCs platform by a hierarchical reinforcement learning model. The model jointly trains a profile reviser and a basic recommendation model, which enables the recommendation model being trained on user profiles revised by the profile reviser. With the designed two-level tasks, the agent in the hierarchical reinforcement learning model can effectively remove the noisy courses and reserve the real contributing courses to the target course.</p><p>We will try the proposed model in other domains. For example, people usually watch diverse movies, read diverse books and purchase diverse products. In those scenarios, we can imagine the need for selecting the most contributing historical items from users' diverse profiles, which poses the same challenges with the recommendations in MOOCs. In the future, we will also explore how to connect the courses in MOOCs to the external entities or knowledge such as the academic papers and researchers <ref type="bibr" target="#b24">(Tang et al. 2008)</ref> to enable more accurate course recommendation in MOOCs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 2: Data distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>y s i Y 6 w w M T a j k g 3 B W 3 5 5 l b T r N c + t e X f 1 S u M m j 6 M I J 3 A K 5 + D B J T T g F p r Q A g I C n u E V 3 h z l v D j v z s e i t e D k M 8 f w B 8 7 n D + z F j 9 I = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " n V 5I G V y T g p c v f s F w c m M Z f 4 v 9 j t k = " &gt; A A A B 8 H i c b V A 9 T w J B E J 3 D L 8 Q v 1 N J m I 5 h Y k T s s t C T R w h I T + T B w k r 1 l g A 2 7 d 5 f d P R N y 4 V f Y W G i Mr T / H z n / j A l c o + J J J X t 6 b y c y 8 I B Z c G 9 f 9 d n J r 6 x u b W / n t w s 7 u 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Recommendation performance (%).</figDesc><table><row><cell>Methods</cell><cell cols="4">HR@5 HR@10 NDCG@5 NDCG@10</cell></row><row><cell>BPR</cell><cell>46.82</cell><cell>60.73</cell><cell>34.16</cell><cell>38.65</cell></row><row><cell>MLP</cell><cell>52.16</cell><cell>66.29</cell><cell>40.39</cell><cell>44.41</cell></row><row><cell>FM</cell><cell>46.01</cell><cell>61.07</cell><cell>35.28</cell><cell>40.15</cell></row><row><cell>FISM</cell><cell>52.73</cell><cell>65.64</cell><cell>40.00</cell><cell>44.98</cell></row><row><cell>GRU</cell><cell>52.07</cell><cell>68.63</cell><cell>38.92</cell><cell>46.30</cell></row><row><cell>NAIS</cell><cell>56.42</cell><cell>69.05</cell><cell>43.73</cell><cell>47.82</cell></row><row><cell>NASR</cell><cell>54.64</cell><cell>69.48</cell><cell>42.39</cell><cell>47.33</cell></row><row><cell cols="2">HRL+NAIS 64.59</cell><cell>79.68</cell><cell>45.74</cell><cell>50.69</cell></row><row><cell cols="2">HRL+NASR 59.05</cell><cell>74.50</cell><cell>47.51</cell><cell>52.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Case studies of the profiles revised by HRL+NAIS and the attention coefficients learned by NAIS. Revised profile or the learned attentions The target course HRL+NAIS Crisis Negotiation, Social Civilization, Web Technology, C++ Program Web Development NAIS Crisis Negotiation(29.61), Social Civilization(29.09), Web Technology(28.32), C++ Program(28.12) Web Development HRL+NAIS Modern Biology, Medical Mystery, Biomedical Imaging, R Program Biology NAIS Modern Biology(37.79), Medical Mystery(37.96), Biomedical Imaging(37.62), R Program(37.84) Biology HRL+NAIS Web Technology, Art Classics, National Unity Theory, Philosophy Life Aesthetics NAIS Web Technology(38.32), Art Classics(35.87), National Unity Theory(40.63), Philosophy(43.69) Life Aesthetics</figDesc><table><row><cell>Methods</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The sum of the attentions is normalized larger than 1 to lessen the punishment of active users (Cf.(He et al.  </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2018" xml:id="foot_1">) for details).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2">http://www.xuetangx.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported by National Key R&amp;D Program of China (No.2018YFB1004401) and NSFC under the grant No. 61532021, 61772537, 61772536, 61702522, the Research Funds of Renmin University of China (15XNLQ06) and the Research Funds of Online Education (2017ZD205). *Cuiping Li is the corresponding author.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>a low-level task of multiple actions to determine whether to remove each historical course e u t ∈ E u or not. After the low-level task is finished, the overall task is finished. If the high-level task decides to make no revision, low-level task will not be executed and the overall task is directly finished.</p><p>We formulate the profile reviser as two-level MDPs, because a part of the user profiles are discriminative and can be already correctly predicted by the basic recommendation model. As presented in Figure <ref type="figure">2b</ref>, about 30% users are relatively attentive (i.e., #Categories/#Courses&lt;0.4) and the corresponding average probabilities of recommending the real target courses are high (i.e., larger than 0.6). We can simply keep those profiles as the original ones and only revise the indiscriminative ones. Out of this consideration, we design a high-level task to decide whether to revise the whole profile of a user or not, and a low-level task to decide which course in the profile should be removed.</p><p>Note that for both the high-level and low-level task, given a state and an action, it will transit to a determined state with probability 1. We will introduce the details of how to design the state, action and reward for the two-level tasks. State. The high-level task takes an action according to the state of the whole profile E u and the low-level task takes a sequence of actions according to the state of each course e u t ∈ E u . We define different state features for the two tasks.</p><p>• Low-level task: When determining to remove a historical course e u t ∈ E u , we define the state features s l t as the cosine similarity between the embedding vectors of the current historical course e u t and the target course c i , the element-wise product between them, and also the average of the two previous features over all the reserved historical courses, where the embedding vector of a course p i can be provided by a pre-trained basic recommendation model. We also define the effort taken in a course as an additional state feature, as the effort taken in a course is significantly different (Cf. Figure <ref type="figure">2d</ref>) and it may also indicate the contribution of e u t to c i besides the similaritybased features. For simplicity and clarity, we ignore the superscript u in all the notations about the state features.</p><p>• High-level task: When determining to revise a whole profile E u , we define the state features s h as the average cosine similarity between the embedding vectors of each historical course in E u and the target course and the average element-wise product between them. We also define an additional state feature as the probability P (y = 1|E u , c i ) of recommending c i to user u by a basic recommendation model. The probability reflects how credible the course c i will be recommended based on the profile E u . The lower recommendation probability is, more effort should be taken to revise E u . Note we train the profile reviser only based on the positive instances, i.e., a user profile paired with a real target course, as negative instances with random target courses can hardly guide the agent to select the contributing courses to the target course. Thus P (y = 0|E u , c i ) for a negative instance is not calculated.</p><p>Action and Policy. We define the high-level action a h ∈ {0, 1} as a binary value to represent whether to revise the whole profile of a user or not, and define a low-level action a l t ∈ {0, 1} as a binary value to represent whether to remove the historical course e u t or not. We perform a low-level action a l t according to the policy function as follows:</p><p>where</p><p>are the parameters to be learned with d l 1 as the number of the state features and d l 2 as the dimension of the hidden layer. Notation H l t represents the embedding of the input state. We denote</p><p>Sigmoid function σ is used to transform the input into a probability. The high-level action is performed according to the similar policy function with different parameters</p><p>The reward is a signal to indicate whether the performed actions are reasonable or not. We assume that every low-level action in the low-level task has a delayed reward after the last action a l tu is performed for the last course e u tu ∈ E u . In another word, the immediate reward for a lowlevel action is zero except the last low-level action. Thus, we define the reward for each low-level action as:</p><p>and Êu is the revised profile, which is a subset of E u . For the special case Êu = ∅, i.e., all the historical courses are removed, we randomly select a course from the original set E u . The reward is defined as the difference between the log-likelihood after and before the profile is revised. A positive difference indicates a positive utility gained by the revised profile.</p><p>If the high-level task chooses the revising action, it calls the low-level task and receives the same delayed reward R(a l t , s l t ) after the last low-level action is performed. Otherwise, it keeps the original profile and obtain a zero reward as log p(E u , c i ) is not changed.</p><p>In addition, we define an internal reward G(a l t , s l t ) which is used only inside the low-level task to speed up its local learning and does not propagate to the high-level task <ref type="bibr" target="#b4">(Ghavamzadeh and Mahadevan 2003)</ref>. Specifically, we first calculate the average cosine similarity between each historical course and the target course after and before the profile is revised, and then use the difference between them as the internal reward G(a l t , s l t ). The internal reward encourages the agent to select the most relevant courses to the target course. Finally, we sum G(a l t , s l t ) and R(a l t , s l t ) as the reward for the low-level task. Objective Function. We aim at finding the optimal parameters of the policy function defined in Eq. (3) to maximize the expected reward, i.e.,</p><p>Pre-train the basic recommendation model; Pre-train the profiler reviser by running Algorithm 2 with the basic recommendation model fixed; Jointly train the two models together by running Algorithm 2;</p><p>Algorithm 1: The Overall Training Process where Θ represents either Θ h or Θ l , τ is a sequence of the sampled actions and the transited states, P Θ (τ ; Θ) denotes the corresponding sampling probability and R(τ ) is the reward for the sampled sequence τ . The sampled sequence τ can be {s l 1 , a l 1 , s l 2 , • • • , s l t , a l t , s l t+1 , • • • } for the low-level task and {s h , a h } for the high-level task. Since there are too many possible action-state trajectories for the entire sequences of the two tasks, we adopt the policy gradient theorem <ref type="bibr" target="#b22">(Sutton et al. 2000)</ref> and the monto-carlo based policy gradient method <ref type="bibr" target="#b27">(Williams 1992</ref>) to sample M action-state trajectories, based on which we calculate the gradient of the parameters for the low-level policy function:</p><p>where the reward R(a m t , s m t ) + G(a m t , s m t ) for each actionstate pair in sequence τ (m) is assigned the same value and equals to the terminal reward R(a m tu , s m tu ) + G(a m tu , s m tu ). The gradient for the high-level policy function:</p><p>where the reward R(a m , s m ) is assigned as R(a m tu , s m tu ) when a m = 1, and 0 otherwise. We omit the superscript l and h in Eq. (??) and (??) for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Training</head><p>The two models of the profile reviser and the basic recommendation model are interleaved together, and we need to train them jointly. The training process is shown in Algorithm 1, where we firstly pre-train the basic recommendation model based on the original dataset, then we fix the parameters of the basic recommendation model and pre-train the profile reviser to automatically revise the user profiles; finally, we jointly train the models together. Same as the settings of <ref type="bibr" target="#b3">(Feng et al. 2018)</ref>, to have a stable update, each parameter is updated by a linear combination of its old version and the new old version, i.e.,</p><p>where L is the number of epochs, N is the number of instances, tu is the the average number of historical courses and M is the Monto Carlo sampling time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Experimental Settings</head><p>Settings. The dataset is introduced in the section of MOOC data. We select the enrolled behaviors from October 1st, 2016 to December 30th, 2017 as the training set, and those Each instance in the training or the test set is a sequence of historical enrolled courses paired with a target course. During the training process, for each sequence in the training data, we hold out the last course as the target course, and the rest are treated as the historical courses. For each positive instance, we construct 4 negative instances by replacing the target course with each of 4 randomly sampled courses. During the test process, we treat each enrolled course in the test set as the target course, and the corresponding courses of the same user in the training set as the historical courses. Each positive instance in the test set is paired with 99 randomly sampled negative instances <ref type="bibr" target="#b8">(He et al. 2018</ref>). Baseline Methods. The comparison methods include:</p><p>BPR <ref type="bibr" target="#b17">(Rendle et al. 2009</ref>): optimizes a pairwise ranking loss for the recommendation task in a Bayesian way.</p><p>MLP <ref type="bibr" target="#b5">(He et al. 2017)</ref>: applies a multi-layer perceptron (MLP) on a pair of user and course embeddings to learn the probability of recommending the course to the user.</p><p>FM <ref type="bibr" target="#b19">(Rendle 2012)</ref>: is a principled approach that can easily incorporate any heuristic features. But for fair comparison, we only use the embeddings of users and courses.</p><p>FISM <ref type="bibr" target="#b11">(Kabbur, Ning, and Karypis 2013)</ref>: is an itemto-item collaborative filtering algorithm which conducts recommendation based on the average embedding of all the historical courses and the embedding of the target course.</p><p>NAIS <ref type="bibr" target="#b8">(He et al. 2018)</ref>: is also an item-to-item collaborative filtering algorithm but distinguishes the weights of different historical courses by an attention mechanism.</p><p>GRU <ref type="bibr" target="#b9">(Hidasi et al. 2016)</ref>: is a gated recurrent unit model that receives a sequence of historical courses as input and output the last hidden vector as the representation of a user's preference.</p><p>NASR <ref type="bibr" target="#b13">(Li et al. 2017)</ref>: is an improved GRU model that estimates an attention coefficient for each historical course based on the corresponding hidden vector output by GRU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Analysis</head><p>Overall Prediction Performance. Table <ref type="table">1</ref> shows the overall performance of all the comparison methods. The proposed model performs clearly better than the comparison baselines (improving 5.02% to 18.95% in HR@10). The user-to-item based collaborative filtering methods such as BPR, MLP and FM perform the worst among all the methods, because in our dataset, most of the users only enrolled a few courses (i.e., less than 10 courses as shown in Figure <ref type="figure">2a</ref>). Thus the embeddings for many users can not be sufficiently inferred from the sparse data. Among all the item-to-item 3 https://github.com/jerryhao66/HRL HR@5 HR@10 NDCG@5 NDCG@10 40 based collaborative filtering methods, FISM and GRU perform worse than the others, as they make equal treatments on all the historical enrolled courses and thus the preference representation ability is limited. NAIS and NASR distinguish the effects of different historical courses by assigning them different attention coefficients. However, the useless courses will dilute the effects of the useful courses in the history when users enrolled many diverse courses. The proposed methods, HRL+NAIS and HRL+NASR perform the best, as they forcely remove the noisy courses instead of assigning soft attention coefficients, which distinguish the useful and useless courses significantly.</p><p>For the proposed methods, processing 1 episode of profile update requires 50-80 seconds and the recommender update requires 20-30 seconds. The best recommendation performance on test set is reached after about 20 episodes of recommender pre-training, 20 episodes of profile reviser pretraining and 5 episodes of joint training through the data, which totally requires 30-45 minutes of joint training.</p><p>Compared with One-level RL. We compare the proposed HRL with an one-level RL algorithm, which only uses the low-level task to directly decide to remove each course or not. The comparison results in Figure <ref type="figure">4a</ref> show that HRL outperforms the one-level RL. We find that for HRL, the average #Categories/#Courses of the revised profiles is 0.73 and that for the one-level RL is 0.75, which indicates that the revised profiles by the proposed HRL are more consistent (The larger the value is, the more diverse a profile is). This is because HRL uses an additional high-level task to decide to keep the consistent profiles and revise the diverse profiles. To verify whether the high-level task takes effect or not, we further check the difference between the kept profiles and the revised profiles decided by the high-level task. The average #Categories/#Courses of the kept profiles is 0.57, and that of the revised profiles is 0.69, which indicates that the high-level task tends to keep more consistent profiles while revise more diverse profiles. Compared with Greedy Revision. We compare the proposed HRL with a greedy revision algorithm, which firstly decides to revise the whole profile E u if log P (y = 1|E u , c i ) &lt; µ 1 , and further removes a e u t ∈ E u if its cosine similarity with c i is less than µ 2 . In Figure <ref type="figure">4b</ref>, we tune µ 1 from -2.5 to 0 with interval 0.5, and tune µ 2 from -0.1 to 0.1 with interval 0.04, and obtain the best HR@10 as 77.44% when µ 1 =-1 and µ 2 =0.1, which is 2.27% less than HRL+NAIS. Note the best performance is obtained when</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Engaging with massive online courses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;14</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="687" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recent advances in hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete event dynamic systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="41" to="77" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The youtube video recommendation system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liebald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Vleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Gargi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Livingston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems&apos;10</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reinforcement learning for relation classification from noisy data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="5779" to="6786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical policy gradient algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Department Faculty Publication Series</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deepfm: a factorization-machine based neural network for ctr prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1725" to="1731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;17</title>
				<imprint>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nais: Neural attentive item similarity model for recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Session-based recommendations with recurrent neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;16</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving sequential recommendation with knowledge-enhanced memory networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;18</title>
				<imprint>
			<date type="published" when="2017">2018. 2017</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="783" to="789" />
		</imprint>
	</monogr>
	<note>Guess you like: course recommendation in moocs</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fism: factored item similarity models for top-n recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kabbur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD&apos;13</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="659" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural attentive session-based recommendation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;17</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving information extraction by acquiring external evidence with reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reinforcement learning with hierarchies of machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;98</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1043" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bandit learning with implicit feedback</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;18</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bpr: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;16</title>
				<imprint>
			<date type="published" when="2009">2016. 2009</date>
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
	<note>UAI&apos;09</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for nextbasket recommendation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;10</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Factorization machines with libfm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;01</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Two decades of recommender systems at amazon. com</title>
		<author>
			<persName><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="18" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;00</title>
				<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
				<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<date type="published" when="1999">1999. 2016</date>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
	<note>Improved recurrent neural networks for session-based recommendations</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Arnetminer: extraction and mining of academic social networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD&apos;08</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2018">2018a</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2447" to="2456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Joint training of candidate extraction and answer selection for reading comprehension</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2018">2018b</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1715" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning over multi-field categorical data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECIR&apos;16</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning structured representation for text classification via reinforcement learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="6053" to="6060" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
