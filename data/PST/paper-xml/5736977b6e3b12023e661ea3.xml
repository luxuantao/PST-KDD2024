<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Moat: Verifying Confidentiality of Enclave Programs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rohit</forename><surname>Sinha</surname></persName>
							<email>rsinha@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sriram</forename><surname>Rajamani</surname></persName>
							<email>sriram@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kapil</forename><surname>Vaswani</surname></persName>
							<email>kapilv@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Moat: Verifying Confidentiality of Enclave Programs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F1542A3D00B78C2990E71A11098DE455</idno>
					<idno type="DOI">10.1145/2810103.2813608</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>D.4.6 [Operating Systems]: Security and Protection -Information flow controls, Verification</term>
					<term>D.2.4 [Software Engineering]: Software/Program Verification -Formal methods, Model checking Enclave Programs</term>
					<term>Secure Computation</term>
					<term>Confidentiality</term>
					<term>Formal Verification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Security-critical applications constantly face threats from exploits in lower computing layers such as the operating system, virtual machine monitors, or even attacks from malicious administrators. To help protect application secrets from such attacks, there is increasing interest in hardware implementations of primitives for trusted computing, such as Intel's Software Guard Extensions (SGX) instructions. These primitives enable hardware protection of memory regions containing code and data, and provide a root of trust for measurement, remote attestation, and cryptographic sealing. However, vulnerabilities in the application itself, such as the incorrect use of SGX instructions or memory safety errors, can be exploited to divulge secrets. In this paper, we introduce a new approach to formally model these primitives and formally verify properties of so-called enclave programs that use them. More specifically, we create formal models of relevant aspects of SGX, develop several adversary models, and present a sound verification methodology (based on automated theorem proving and information flow analysis) for proving that an enclave program running on SGX does not contain a vulnerability that causes it to reveal secrets to the adversary. We introduce Moat, a tool which formally verifies confidentiality properties of applications running on SGX. We evaluate Moat on several applications, including a one time password scheme, off-the-record messaging, notary service, and secure query processing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Building applications that do not leak secrets, i.e., provide confidentiality guarantees, is a non-trivial task. There are at least three kinds of attacks a developer must guard against. The first kind of attack, which we call protocol attack, is relevant for distributed applications involving client nodes and cloud-based services, and can arise from vulnerabilities in the cryptographic protocol used to establish trust between various distributed components. Examples of protocol attacks include man-in-the-middle or replay attacks. The second kind of attack, which we call application attack, is due to errors or vulnerabilities in the application code itself which can be exploited to leak confidential information from the application (e.g., the Heartbleed bug <ref type="bibr" target="#b43">[18]</ref>). The third kind of attack, which we call infrastructure attack, is due to exploits in the software stack (e.g. operating system (OS), hypervisor) that the application relies upon, where the privileged malware has full control of the CPU, memory, I/O devices, etc. Infrastructure attacks can result in an attacker gaining control of any application's memory and reading secrets at will.</p><p>Several mitigation strategies have been proposed for each of these kinds of attacks. In order to guard against protocol attacks, we can use protocol verifiers (e.g., ProVerif <ref type="bibr" target="#b36">[11]</ref>, CryptoVerif <ref type="bibr" target="#b37">[12]</ref>) to check for protocol errors. In order to guard against application attacks, the application can be developed in a memory-safe language with information flow control, such as Jif <ref type="bibr" target="#b53">[28]</ref>. Infrastructure attacks are the hardest to protect against, since the attack can happen even if the application is error free (i.e., without application vulnerabilities or protocol vulnerabilities). While some efforts are under way to build a fully verified software stack ground-up (e.g. <ref type="bibr" target="#b46">[21,</ref><ref type="bibr" target="#b50">25]</ref>), this approach is unlikely to scale to real-world OS and system software.</p><p>An alternative approach to guarding against infrastructure attack is by hardware features that enable a user-level application to be protected from privileged malware. For instance, Intel SGX <ref type="bibr" target="#b48">[23,</ref><ref type="bibr" target="#b49">24]</ref> is an extension to the x86 instruction set architecture, which provides any application the ability to create protected execution contexts called enclaves containing code and data. SGX features include 1) hardware-assisted isolation from privileged malware for enclave code and data, 2) measurement and attestation primitives for detecting attacks on the enclave during creation, and 3) sealing primitives for storing secrets onto untrusted persistent storage. Using these extensions it is possible to write applications with a small trusted computing base, which includes only the enclave code and the SGX processor. All other layers in the software stack including the operating system and the hypervisor can be excluded from the trusted computing base. However, establishing such a guarantee requires precise understanding of the contract between the hardware and software. In particular, it requires specifying a formal API-level semantics of SGX instructions, an adversary model, and a verification methodology (with tool support) to detect insecure use of SGX instructions. Our work addresses each of these aspects, as we describe below.</p><p>Semantics of SGX instructions. SGX provides instructions which enable applications to create enclaves, transfer control to and from enclaves, perform remote attestation, and seal and unseal secrets so that they can persist on the platform. We give a formal semantic model of the interface between the programmer and the implementation of SGX, with an eye towards automatic formal verification of the enclave code's security. Our approach is similar in spirit to previous work on finding API-level exploits <ref type="bibr" target="#b45">[20]</ref> using the UCLID modeling and verification system <ref type="bibr" target="#b40">[15]</ref>.</p><p>Adversary model. We consider a powerful adversary who can compromise the infrastructure code (OS, hypervisor, etc.) and perform both passive and active attacks by accessing any non-enclave memory (i.e. memory not protected by SGX), modifying page tables, generating interrupts, controlling I/O interaction, etc. It is non-trivial to reason about enclave behaviors (and potential vulnerabilities) in the presence of such an adversary. As a first step, using our formal ISA-level semantics of the SGX instructions, we prove that (if the application follows certain guidelines during enclave creation) any combination of the above adversarial actions can be simply modeled as an arbitrary update of non-enclave memory. This simplifies our reasoning of enclave execution in the presence of privileged adversaries. In particular, we show that a so-called havocing adversary who symbolically modifies all of the non-enclave memory after every instruction of the enclave code, and is able to observe all nonenclave memory, is powerful enough to model all passive and active adversaries. We consider this to be one of the key contributions of this paper. It greatly simplifies the construction of automated verifiers for checking security properties of enclave code, and potentially even programming and reasoning about enclaves.</p><p>Verification methodology and tool support. Even though SGX offers protection from infrastructure attacks, the developer must take necessary steps to defend against protocol and application attacks by using SGX instructions correctly, using safe cryptographic protocols, avoiding traditional bugs due to memory safety violations, etc. For instance, the enclave may suffer from exploits like Heartbleed <ref type="bibr" target="#b43">[18]</ref> by using vulnerable SSL implementations, and these exploits have been shown to leak secret cryptographic keys from memory. To that end, our next step is to prove that enclaves satisfy confidentiality i.e. there is no execution that leaks a secret to the adversary-visible, non-enclave memory. Proving confidentiality involves tracking the flow of secrets within the application's memory, and proving that the adversary does not observe values that depend on secrets. While past research has produced several type systems that verify information flows (e.g. Jif <ref type="bibr" target="#b53">[28]</ref>, Volpano et al. <ref type="bibr" target="#b59">[34]</ref>, Balliu et al. <ref type="bibr" target="#b30">[5]</ref>), they make a fundamental assumption that the infrastructure (OS/VMM, etc.) on which the code runs is safe, which is unrealistic due to privileged malware attacks. Furthermore, extending traditional type systems to enclave programs is non-trivial because the analysis must faithfully model the semantics of SGX instructions and infer information flows to individual addresses within enclave memory. Therefore, we develop a static verifier called Moat that analyzes the instruction-level behavior of the enclave binary program. Moat employs a flowand path-sensitive type checking algorithm (based on automated theorem proving using satisfiability modulo theories solving <ref type="bibr">[8]</ref>) for automatically verifying whether an enclave program (in the presence of an active adversary) provides confidentiality guarantees. For ill-typed programs, Moat returns an exploit demonstrating a potential leak of secret to non-enclave memory. By analyzing the binary, we remove the compiler from our trusted computing base, and relax several memory safety assumptions that are common in traditional information flow type systems.</p><p>Although we do not focus on protocol attacks in this paper, we briefly describe how one can compose protocollevel analysis (performed by a verifier such as ProVerif <ref type="bibr" target="#b36">[11]</ref>) with Moat to achieve end-to-end confidentiality guarantees against infrastructure, application, and protocol attacks.</p><p>In summary, the goal of this paper is to explore the contract between the SGX hardware and the enclave developer and provide a methodology and tool support for the programmer to write secure enclaves. We make the following specific contributions:</p><p>• We develop the first semantic API model of the SGX platform and its new instruction set, working from publiclyavailable documentation <ref type="bibr" target="#b49">[24]</ref>.</p><p>• We formally study active and passive adversaries for SGX enclaves, and show that a havocing adversary who observes and havocs non-enclave memory after every instruction in the enclave is both powerful enough to model all such adversaries, and amenable to be used in automated symbolic verification tools.</p><p>• We develop Moat, a system for statically verifying confidentiality properties of an enclave program in the face of application and infrastructure attacks.</p><p>Though we study these issues in the context of Intel SGX, similar issues arise in other architectures based on trusted hardware such as ARM TrustZone <ref type="bibr" target="#b29">[4]</ref> and Sancus <ref type="bibr" target="#b54">[29]</ref>, and our approach is potentially applicable to them as well. The theory we develop with regard to attacker models and our verifier is mostly independent of the specifics of SGX, and our use of the term "enclave" is also intended in the more general sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SGX</head><p>The SGX instructions allow a user-level host application to instantiate a protected execution context, called an enclave, containing code and data. An enclave's memory resides within the untrusted host application's virtual address space, but is protected from accesses by that host application or any privileged software -only the enclave code is allowed to access enclave memory. Furthermore, to protect against certain hardware attacks, the cache lines belonging to enclave memory are encrypted and integrity protected by the CPU prior to being written to off-chip memory.</p><p>The host application creates an enclave using a combination of instructions: ecreate, eadd, eextend, and einit. The application invokes ecreate to reserve protected memory for enclave use. To populate the enclave with code and data, the host application uses a sequence of eadd and eextend instructions. eadd loads code and data pages from non-enclave memory to enclave's reserved memory. eextend extends the current enclave measurement with the measurement of the newly added page. Finally, einit terminates the initialization phase, which prevents any further modification to the enclave state (and measurement) from non-enclave code. The host application transfers control to the enclave by invoking eenter, which targets a programmer defined entry point inside the enclave (via a callgate-like mechanism). The enclave executes until one of the following events occur:</p><p>(1) enclave code invokes eexit to transfer control to the host application, (2) enclave code incurs a fault or exception (e.g. page fault, divide by 0 exception, etc.), and (3) the CPU receives a hardware interrupt and transfers control to a privileged interrupt handler. In the case of faults, exceptions, and interrupts, the CPU saves state (registers, etc.) in State Save Area (SSA) pages in enclave memory, and can resume the enclave in the same state once the OS / VMM handles the event. Although a compromised OS may launch denial of service attacks, we show that an enclave can still guarantee properties such as data confidentiality.</p><p>The reader may have observed that before enclave initialization, code and data is open to eavesdropping and tampering by adversaries. For instance, an adversary may modify a OTP enclave's binary (on user's machine) so that it leaks a user's login credentials. SGX provides an attestation primitive called ereport to defend against this class of attacks. The enclave participates in attestation by invoking ereport, which generates a hardware-signed report of the enclave's measurement, and then sending the report to the verifying party. The enclave can also use ereport to bind data to its measurement, thereby adding authenticity to that data. The enclave can use egetkey to attain a hardware-generated sealing key, and store sealed secrets to untrusted storage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Example</head><p>We demonstrate the use of SGX by an example of a onetime password (OTP) service, although the exposition extends naturally to any secret provisioning protocol. OTP is typically used in two factor authentication as an additional step to traditional knowledge based authentication via username and passphrase. A user demonstrates ownership of a pre-shared secret by providing a fresh, one-time password that is derived deterministically from that secret. For instance, RSA SecurID R is a hardware-based OTP solution, where possession of a tamper-resistant hardware token is required during login. In this scheme, a pre-shared secret is established between the OTP service and the hardware token. From then on, they compute a fresh one-time password as a function of the pre-shared secret and time duration since the secret was provisioned to the token. The user must provide the one-time password displayed on the token during authentication, in addition to her username and passphrase. This OTP scheme is both expensive and inconvenient because it requires distributing tamper-resistant hardware tokens physically to the users. Although pure soft-ware implementations have been attempted, they are often prone to infrastructure attacks from malware, making them untrustworthy.</p><p>The necessary primitives for implementing this protocol securely are (1) ability to perform the cryptographic operations (or any trusted computation) without interference from the adversary, (2) protected memory for computing and storing secrets, and (3) root of trust for measurement and attestation. Intel SGX processors provide these primitives. Hoekstra et al. <ref type="bibr" target="#b48">[23]</ref> propose the following OTP scheme based on SGX, which we implement (Figure <ref type="figure" target="#fig_0">1</ref>) and verify using Moat. In this protocol, a bank OTP server provisions the pre-shared secret to a client, which is running on a potentially infected machine with SGX hardware. 0. The host application on the client sets up an enclave that contains trusted code for the client side of the protocol.</p><p>1. The server sends the client an attestation challenge nonce.</p><p>Consequent messages in the protocol use the nonce to guarantee freshness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The client and OTP server engage in an authenticated</head><p>Diffie-Hellman key exchange in order to establish a symmetric session_key. The client uses ereport instruction to send a report containing a signature over the Diffie-Hellman public key dh_pubkey and the enclave's measurement. The signature guarantees that the report was generated by an enclave on an Intel SGX CPU, while the measurement guarantees that the reporting enclave was not tampered during initialization. After verifying the signatures, both the client and OTP server compute the symmetric session_key.</p><p>3. The OTP server sends the pre-shared OTP secret to the client by first encrypting it with the session_key, and then signing the encrypted content with the bank's private TLS key. The client verifies the signature and decrypts the message to retrieve the pre-shared otp_secret.</p><p>4. For future use, the client requests for sealing_key (using egetkey instruction), encrypts otp_secret using seal-ing_key, and writes the sealed_secret to disk.</p><p>A typical application (such as our OTP client) uses enclave code to implement trusted computation such as the cryptographic operations, stores secrets in the enclave heap, and uses non-enclave code (host application, OS, VMM, etc.) for untrusted computation. In fact, SGX prevents the enclave code from invoking any privileged instructions such as system calls, thus forcing the enclave to rely on nonenclave code to issue system calls, perform I/O, etc. For instance, to send the Diffie-Hellman public key to the server, the enclave (1) invokes ereport with enclave_state.dh_pubkey, (2) copies the report to non-enclave memory app_heap, (3) invokes eexit to transfer control to the untrusted app, and (4) waits for app to invoke the socket system calls to send the report to the bank server. Over their lifetimes, app and enclave perform several eenter and eexit while alternating between trusted and untrusted computation. To facilitate the interaction between an enclave and non-enclave code, SGX allows the enclave to access the entire address space of the host application.</p><p>While SGX implements the necessary primitives for doing trusted computation, we need a methodology for writing secure enclave programs. Confidentiality requires protecting secrets, which requires understanding of the contract between the enclave developer and the SGX hardware. First, the enclave developer must follow the enclave creation guidelines (see § 3.1) so that the hardware protects the enclave from an attacker that has gained privileged access to the system. Even then, the enclave developers needs to ensure that their code does not leak secrets via application attacks and protocol attacks. For instance, they should encrypt secrets before writing them to non-enclave memory. They should account for adversary modifying non-enclave memory at any time, which could result in time-of-check-to-time-of-use attacks. For example, the enclave code in Figure <ref type="figure" target="#fig_0">1</ref> has such a vulnerability. The enclave code here copies encrypted data from enclave memory to non-enclave memory, but the size of the data copied is determined by a variable size_field, which resides in non-enclave memory. Thus, by manipulating the value of this variable the adversary can trick the enclave code into leaking secrets to non-enclave memory. Avoiding such attacks is non-trivial. In this paper, we present a methodology and tool support for detecting such errors, and proving that enclaves are secure.</p><p>The rest of this paper is structured as follows. We provide an overview of our approach in § 3. § 4 describes how Moat constructs a formal model of the enclave program (including its use of x86 and SGX instructions), and also formalizes an active and a passive adversary. § 5 introduces the havocing adversary, and shows how it can be used to model the enclave's execution in the presence of an active adversary. The results presented in § 5 allow us soundly verify any safety property of enclave programs. Next, we focus our attention on proving confidentiality by first formalizing it in § 6, and then developing a verification algorithm in § 7. § 8 describes several case studies where we apply Moat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">OVERVIEW OF MOAT</head><p>We are interested in building secure distributed applications, which have components running in trusted and untrusted environments, where all communication channels are untrusted. For the application to be secure, we need (1) secure cryptographic protocols between the components (to protect from protocol attack), and (2) secure implementation in each component to protect from application attack and infrastructure attack. Our goal is to prove that, even in the presence of such attacks, the enclave does not leak its secrets to the adversary. Moat defends against application and infrastructure attacks. Furthermore, we combine Moat with off-the-shelf protocol verifiers to defend against protocol attacks as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Protecting from Infrastructure Attacks</head><p>An infrastructure attack can generate interrupts, modify page tables, modify any non-enclave memory, invoke any x86 and SGX instruction - § 4.3 formalizes the threat model. We mandate that the enclave be created with the following sequence that measures all pages in memenc, which denotes memory reserved for the enclave. We do not find this to be a restriction in practice. ecreate(size(memenc)); foreach page ∈ memenc : {eadd(page); eextend(page)}; einit</p><p>If some component of enclave state is not measured, then the adversary may havoc that component of state during initialization without being detected. This precondition on the initialization sequence lets us prove that the SGX hardware provides some very useful guarantees. For instance, we prove Theorem 1 in § 5 which guarantees that an enclave initialized using this sequence is protected from each adversarial operation in our threat model -we formally model each SGX instruction (see § 4.2) to perform this proof. Specifically, we prove a non-interference property <ref type="bibr" target="#b41">[16]</ref> that the enclave's execution (i.e. its set of reachable states) is independent of the adversarial operations, with the caveat that the enclave may read non-enclave memory for inputs. However, we do not consider this to be an attack because the enclave must read non-enclave memory for inputs, which are untrusted by design. The utility of this proof is that all infrastructure attacks can now be modeled by a so-called havocing adversary that is only allowed to update non-enclave memory, and this simplifies our reasoning of enclave execution in the presence of privileged adversaries. We call this havocing adversary H (defined in § 5), and we allow H to update all addresses in non-enclave memory between any consecutive instructions executed by the enclave. Going forward, we focus primarily on application attacks, and model H's operations only for the purpose of reads from non-enclave memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Protecting from Application Attacks</head><p>In this section, we give an overview of Moat's approach for proving confidentiality properties of enclave code (detailed exposition in § 4 through § 7). Moat accepts an enclave program in x86 Assembly, containing SGX instructions ereport, egetkey, and eexit. Moat is also given a set of annotations, called Secrets, indicating 1) program points where secrets values are generated (e.g. after decryption), and 2) memory locations where those secret values are stored. In the OTP example, the Secrets include otp_secret, session_key, and sealing_key. Moat proves that a privileged software adversary running on the same machine does not observe a value that depends on Secrets, regardless of any operations performed by that adversary. We demonstrate Moat's proof methodology on a snippet of OTP enclave code containing lines 22-26 from Figure <ref type="figure" target="#fig_0">1</ref>, which is first compiled to x86+SGX Assembly in Figure <ref type="figure" target="#fig_1">2</ref>. Here, the enclave invokes egetkey to retrieve a 128-bit sealing key, which is stored in the byte array sealing_key. Next, the enclave encrypts otp_secret (using AES-GCM-128 encryption library function called encrypt) to compute the sealed_secret. Finally, the enclave copies sealed_secret to untrusted memory app_heap (to be written to disk). Observe that the size argument to memcpy (line 26 in Figure <ref type="figure" target="#fig_0">1</ref>) is a variable size_field which resides in non-enclave memory. This buffer overrun vulnerability can be exploited by the adversary, causing the enclave to leak secrets from its stack. egetkey movl $0x8080AC,0x8(%esp) lea -0x6e0(%ebp),%eax mov %eax,0x4(%esp) lea -0x720(%ebp),%eax mov %eax,(%esp) call &lt;AES_GCM_encrypt&gt; mov 0x700048,%eax movl %eax,0x8(%esp) lea -0x720(%ebp),%eax mov %eax,0x4(%esp) movl $0x701000,(%esp) call &lt;memcpy&gt; mem := egetkey(mem, ebx, ecx); mem := store(mem,add(esp,8),8080AC); eax := sub(ebp, 6e0); mem := store(mem,add(esp,4),eax); eax := sub(ebp, 720); mem := store(mem, esp, eax); mem := AES_GCM_encrypt(mem, esp); eax := load(mem, 700048); mem := store(mem, add(esp,8), eax); eax := sub(ebp, 720); mem := store(mem, add(esp,4), eax); mem := store(mem, esp, 701000); mem := memcpy(mem, esp); To reason about enclave code and find such vulnerabilities, Moat first extracts a model in an imperative verification language, as shown in Figure <ref type="figure" target="#fig_1">2</ref>. We refer to the model as penc. penc models x86 (e.g. load, store) and SGX (e.g. egetkey) instructions as uninterpreted functions constrained with axioms. The axioms (presented in § 4.2) are part of our machine model, and they encode the ISA-level semantics of each instruction. penc uses BAP to model x86 <ref type="bibr" target="#b39">[14]</ref> precisely, including updates to CPU flags. For brevity, Fig-ure 2 omits all updates to flags as they are irrelevant to this code snippet. For reasons explained later, Moat does not model the implementation of cryptographic routines (such as AES_GCM_encrypt in Figure <ref type="figure" target="#fig_1">2</ref>). It replaces all calls to the cryptographic library with their specifications. In the case of AES_GCM_encrypt, the specification ensures memory safety: only the output ciphertext buffer and memory allocated to the library can be modified by this call.</p><p>Since penc executes in the presence of an active adversary, we must model the effects of adversarial operations on penc's execution. Section 3.1 introduces an active adversary H (formalized in 5), which can perform the operation "havoc mem¬epc" once between consecutive instructions along any execution of penc. Here, memepc denotes memory reserved by the SGX processor for enclave use, and mem¬epc is all of untrusted, non-enclave memory; havoc mem¬epc updates each address in mem¬epc with a non-deterministically chosen value. We define H this way because a privileged software adversary can interrupt penc at any point, perform havoc mem¬epc, and then resume penc. We model the effect of H on penc's behavior by instrumenting havoc mem¬epc in penc (see Figure <ref type="figure" target="#fig_3">3</ref>). The instrumented program is called penc-H.   <ref type="figure" target="#fig_3">3</ref>), which reads a value from non-enclave memory and passes that value as the size argument to memcpy. To perform the exploit, H uses havoc mem¬epc (in line 8) to choose the number of bytes that penc-H writes to non-enclave memory, starting at the base address of sealed_secret. By setting this value to be greater than the size of sealed_secret, H causes penc-H to leak the stack contents, which includes the sealing_key. We can assume for now that writing sealed_secret to the unprotected app_heap is safe because it is encrypted. We formalize a confidentiality property in § 6 that prevents such vulnerabilities, and build a static type system in § 7 which only admits programs that satisfy confidentiality. Confidentiality enforces that for any pair of traces of penc-H that differ in the values of Secrets, if H's operations along the two traces are equivalent, then H's observations along the two traces must also be equivalent. In other words, H's observation of penc's execution is independent of Secrets. Note that we omit side channels from H's observation in this work.</p><p>Our type system checks confidentiality by instrumenting penc-H with ghost variables that track the flow of Secrets within registers and memory, akin to taint tracking but performed using static analysis. Moat tracks both implicit and explicit information flows <ref type="bibr" target="#b55">[30]</ref>. Figure <ref type="figure" target="#fig_4">4</ref> demonstrates how Moat type-checks penc-H. For each state variable x, the type system instruments a ghost variable Cx. Cx is updated on each assignment that updates x, and is assigned to f alse only if x's value is independent of Secrets (details in § 7). For instance, Cmem[esp] in line 13 is assigned to Ceax because a secret in the eax register makes the written memory location also secret. Furthermore, for each secret in Secrets, we set the corresponding locations in Cmem to true. For instance, lines 1-3 assign true to those 16 bytes in Cmem where egetkey places the secret sealing_key. Information leaks can only happen via store to mem¬enc, where memenc is a subset of memepc that is reserved for use by penc, and mem¬enc is either non-enclave memory or memory used by other enclaves. enc(i) is true if i is an address in memenc. For each store instruction, the type system instruments an assert checking that a secret value is not written to mem¬enc (with special treatment of memcpy for efficiency). For a program to be well-typed, all assertions in the instrumented penc-H must be valid along any feasible execution. Moat feeds the instrumented program (Figure <ref type="figure" target="#fig_4">4</ref>) to a static program verifier <ref type="bibr" target="#b31">[6]</ref>, which uses SMT solving to explore all executions (i.e. all reachable states) and verify that the assertions are valid along all executions. The assertion in line 30 is invalid because Cmem is true for memory locations that hold the sealing_key. Our type system rejects this enclave program. A fix to the OTP implementation is to replace size_field with the correct size, which is 64 bytes. Although memory safety vulnerabilities can be found using simpler static analysis, Moat can identify several classes of vulnerabilities using these typing assertions. The analysis in Moat is sound (if penc terminates) i.e. Moat finds any vulnerable execution of penc that leaks a secret to mem¬enc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declassification.</head><p>In the previous section, we claim that writing sealed_secret to app_heap is safe because it is encrypted using a secret key. We now explain how Moat evaluates whether a particular enclave output is safe. As a pragmatic choice, Moat does not reason about cryptographic operations for there is significant body of research on cryptographic protocol verification. For instance, if encryption uses a key established by Diffie-Hellman, the verification would need to reason about the authentication and attestation scheme used in that Diffie-Hellman exchange in order to derive that the key can be safely used for encryption. Protocol verifiers (e.g. ProVerif <ref type="bibr" target="#b36">[11]</ref>, CryptoVerif <ref type="bibr" target="#b37">[12]</ref>) excel at this form of reasoning. Therefore, when Moat encounters a cryptographic library call, it abstracts it as an uninterpreted function with the conservative axiom that secret inputs produce secret output. For instance in Figure <ref type="figure" target="#fig_4">4</ref>, AES_GCM_encrypt on line 16 is an uninterpreted function, and C_AES_GCM_encrypt on line 15 marks the ciphertext as secret if any byte of the plain-text or encryption key is secret. This conservative axiomatization is very unnecessary because a secret encrypted with a key (that is unknown to the adversary) can be safely output. To reduce this imprecision in Moat, we introduce declassification to our type system. A declassified output is a intentional information leak of the program, which may be proven to be a safe information leak using other proof techniques. In our experiments, we safely eliminate declassified outputs from information leakage checking if the protocol verifier has already proven them to be safe outputs.</p><p>To collect the Declassif ed annotations, we manually model the cryptographic protocol to verify using an off-the-shelf protocol verifier. The choice of protocol verifier is orthogonal to our work. A protocol verifier accepts as input an abstract model of the protocol (in a formalism such as pi calculus), and proves properties such as confidentiality of protocol-level secrets. We briefly describe how we use Moat in tandem with a protocol verifier. If Moat establishes that a particular value generated by penc is secret, this can be added to the set of secrecy assumptions made in the protocol verifier. Similarly, if the protocol verifier establishes confidentiality even while assuming that a penc's output is observable by the adversary, then we can declassify that output while verifying penc with Moat. This assume-guarantee reasoning is sound because the adversary model used by Moat can simulate a network adversary -a network adversary reorders, inserts, and deletes messages, and the observable effect of these operations can be simulated by a havoc mem¬epc.</p><p>We demonstrate this assume-guarantee reasoning on lines 22-26 of the OTP enclave in Figure <ref type="figure" target="#fig_0">1</ref>, where line 26 no longer has the memory safety vulnerability i.e. it uses the constant 64 instead of size_field. Despite the fix, Moat is unable to prove that memcpy in line 26 of Figure <ref type="figure" target="#fig_0">1</ref> is safe because its axiomatization of aes_gcm_encrypt is imprecise. We proceed by first proving in Moat that the sealing_key (obtained using egetkey) is not leaked to the adversary. Next, we annotate the ProVerif model with the assumption that sealing_key is secret, which allows ProVerif to prove that the outbound message (via memcpy) is safe. Based on this ProVerif proof, we annotate the sealed_secret as Declassif ied, hence telling Moat that the assert on line 30 of Figure <ref type="figure" target="#fig_4">4</ref> is valid.</p><p>This illustrates that protocol verification not only provides Declassif ied annotations, but also specifies which values must be kept secret by the enclave to ensure that the protocol is safe. The combination of Secrets and Declassif ied annotations is called a policy, and this policy forms an input to Moat in addition to the enclave program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Assumptions and Limitations</head><p>Our work has the following fundamental limitations:</p><p>• The Intel SGX hardware is in our trusted computing base. Specifically, we assume that all x86 + SGX instructions fulfill the ISA-defined semantics. This eliminates a class of attacks such as physical tampering of the CPU and supply chain attacks.</p><p>• To make static analysis feasible, Moat assumes that the enclave code cannot be modified at runtime (enforced using page permissions), and is statically linked.</p><p>• We do not consider attacks from observing side channels such as memory access patterns, timing, etc.</p><p>• Although SGX allows an enclave to have multiple CPU threads, we only consider single-threaded enclaves for simplicity.</p><p>The current implementation of Moat makes the following additional assumptions:</p><p>• Moat's implementation uses the Boogie <ref type="bibr" target="#b31">[6]</ref> program verifier, Z3 <ref type="bibr" target="#b42">[17]</ref> SMT solver, and BAP <ref type="bibr" target="#b39">[14]</ref> for modeling x86 instructions. All these dependencies are in our trusted computing base.</p><p>• We use trusted implementation of cryptographic routines (cryptopp library [1]) to develop our benchmarks. Since Moat does not model their implementation, they are in our trusted computing base.</p><p>• Moat assumes that the enclave program has control flow integrity. Moat does not find vulnerabilities that exploit the control flow behavior (such as ROP attacks). This assumption is not fundamental, and can be removed using modern runtime defenses (e.g. <ref type="bibr">[3]</ref>).</p><p>• We assume that the enclave code cannot cause exceptions, apart from page fault exceptions which are handled seamlessly by the OS/VMM. In other words, we terminate the enclave in the event of all other exceptions (such as divide by 0).</p><p>• Moat assumes that the enclave code does not read (via load instruction) from static save area (SSA). Note that this assumption does not prevent the untrusted code from invoking eresume (which is necessary for resuming from asynchronous exits). We have not yet found this to be a limiting assumption in our benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">FORMAL MODEL OF THE ENCLAVE PROGRAM AND THE ADVERSARY</head><p>The remainder of this paper describes our verification approach for defending against application attacks, which is the focus of this paper. Moat takes a binary enclave program and proves confidentiality i.e. it does not leak secrets to a privileged adversary. In order to construct proofs about enclave behavior, we first model the enclave's semantics in a formal language that is amenable to verification, and also model the effect of adversarial operations on enclave behavior. This section describes (1) formal modeling of enclave programs, (2) formal model of the x86+SGX instruction set, and (3) formal modeling of active and passive adversaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Syntax and Semantics of Enclave Programs</head><p>Our model of a x86+SGX machine consists of an unbounded number of Intel SGX CPUs operating with shared memory. Although SGX allows an enclave to have multiple CPU threads, we restrict our focus to single-threaded enclaves for simplicity, and model all other CPU threads as running privileged adversarial code. A CPU thread is a sequence of x86+SGX instructions. In order to reason about enclave execution, Moat models the semantics of all x86+SGX instructions executed by that enclave. This section describes Moat's translation of x86+SGX Assembly program to a formal model, called penc, as seen in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Moat first uses BAP <ref type="bibr" target="#b39">[14]</ref> to lift x86 instructions into a simple microarchitectural instruction set: load from mem, store to mem, bitwise (e.g. xor) and arithmetic (e.g. add) operations on regs, conditional jumps cjmp, unconditional jumps jmp, and user-mode SGX instructions (ereport, egetkey, and eexit). We choose BAP for its precise modeling of x86 instructions, which includes updating of CPU flags. We have added a minimal extension to BAP in order to decode SGX instructions. Each microarchitectural instruction from above is modeled in penc as a sequential composition of Boo-giePL <ref type="bibr" target="#b31">[6]</ref> statements (syntax described in Figure <ref type="figure" target="#fig_5">5</ref>). Boo-giePL is an intermediate verification language supporting assertions that can be statically checked for validity using automated theorem provers. Within penc, Moat uses uninterpreted Functions constrained with axioms (described in § 4.2) to model the semantics of each microarchitectural instruction. These axioms describe the effect of microarchitectural instructions on machine state variables Vars, which include main memory mem, ISA-visible CPU registers regs, etc. We define the state σ ∈ Σ of penc at a given program location to be a valuation of all variables in Vars. The semantics of a BoogiePL statement s ∈ Stmt is given by a relation R(s) ⊆ 2 Σ×Σ over pairs of pre and post states, where (σ, σ ) ∈ R(s) if and only if there is an execution of s starting at σ and ending in σ . We use standard axiomatic semantics for each Stmt in Figure 5 <ref type="bibr" target="#b32">[7]</ref>.</p><p>Enclaves have an entrypoint which is configured at compile time and enforced at runtime by a callgate-like mechanism. Therefore, Moat makes BAP disassemble instructions in the code region starting from the enclave entrypoint. Procedure calls are either inlined or abstracted away as uninterpreted functions. Specifically, trusted library calls (e.g. AES-GCM authenticated encryption) are abstracted as uninterpreted functions with standard axioms -the cryptographic library is in our trusted computing base. Furthermore, Moat soundly unrolls loops to a bounded depth by adding an assertion that any iteration beyond the unrolling depth is unreachable. We omit further details on the translation from the microarchitectural instructions to penc (in the language presented in Figure <ref type="figure" target="#fig_5">5</ref>) because it is mostly syntactic and standard -lack of indirect control flow transfers (due to inlining) makes control flow reconstruction simpler. Our penc model is sound under the following assumptions: (1) control flow integrity, (2) code pages are not modified (which is enforced using page permissions), and (3) the trusted cryptographic library implementation is memory safe (i.e. it does not modify any memory outside of the allocated result buffer or memory allocated to the library).</p><p>By bounding the number of loop iterations and recursion depth, the resulting verification problem becomes decidable, and one that can be checked using a theorem prover. Several efficient techniques <ref type="bibr" target="#b32">[7]</ref> transform this loop-free and call-free procedure containing assertions into a compact logical formula in the Satisfiability Modulo Theories (SMT) format by a process called verification-condition generation. This formula is valid if and only if penc does not fail any assertion in any execution -validity checking is done by an automated theorem prover based on SMT solving <ref type="bibr" target="#b42">[17]</ref>. In the case of assertion failures, the SMT solver also constructs a counter-example execution of penc demonstrating the assertion failure. In § 7, we show how Moat uses assertions and verification-condition generation to prove confidentiality properties of penc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Formal Model of x86 and SGX instructions</head><p>While formal models of x86 instructions using BoogiePL has been done before (see for instance <ref type="bibr" target="#b60">[35]</ref>), we are the first to model SGX instructions. In section 4.1, we lifted x86 to a microarchitectural instruction sequence, and modeled each microarchitectural instruction as an uninterpreted function (e.g. xor, load, ereport). In this section, we add axioms to these uninterpreted functions in order to model the effect of instructions on machine state.</p><p>A state σ is a valuation of all Vars, which consists of mem, regs, and epcm. As their names suggest, physical memory σ.mem is modeled as an unbounded array, with index type of 32 bits and element type of 8 bits. mem is partitioned by the platform into two disjoint regions: protected memory for enclave use (memepc), and unprotected memory (mem¬epc). For any physical address a, epc(a) is true iff a is an address in memepc. Furthermore, memenc is a subset of memepc that is reserved for use by pencmemenc is virtually addressed and it belongs to the host application's virtual address space. For any virtual address a, enc(a) is true iff a is within memenc. The epcm is a finite sized array of hardware-managed structures, where each structure stores security critical metadata about a page in memepc. epcm enc is a subset of epcm that stores metadata about each page in memenc -other epcm structures are either free or in use by other enclaves. regs is the set of ISA-visible CPU registers such as eax, esp, etc.</p><p>Each microarchitectural instruction in penc has side-effects on σ, which we model using axioms on the corresponding uninterpreted functions. In Figure <ref type="figure" target="#fig_6">6</ref>, we present our model of a sample bitvector operation xor, sample memory instruction load, and sample SGX instruction eexit. We use the theorem prover's built-in bitvector theories (⊕ operator in line 1) for modeling microarchitectural instructions that perform bitvector operations. For load, we model both traditional checks (e.g. permission bits, valid page table mapping, etc.) and SGX-specific security checks. First, load reads the page table to translate the virtual address va to physical address pa (line 7) using a traditional page walk, which we model as an array lookup. Operations on arrays consist of reads x := X[y] and writes X[y] := x, which are interpreted by the Theory of Arrays <ref type="bibr">[8]</ref>. The boolean variable ea denotes whether this access is made by enclave code to memenc. If ea is true, then load asserts (line 14) that the following security checks succeed:</p><p>• the translated physical address pa resides in memepc (line 9)</p><p>• epcm contains a valid entry for address pa (lines 10 and 11)</p><p>• enclave's epcm entry and the CPU's control register both agree that the enclave owns the page (line 12)</p><p>• the page's mapping in pagetable is same as when enclave was initialized (line 13)</p><p>If non-enclave code is accessing memepc, or if penc is accessing some other enclave's memory (i.e. within memepc but outside memenc), then load returns a dummy value 0xff (line 16). We refer the reader to <ref type="bibr" target="#b51">[26]</ref> for details on SGX memory access semantics. Figure <ref type="figure" target="#fig_6">6</ref> also contains a model of eexit, which causes the control flow to transfer to the host application. Models of other SGX instructions are available at <ref type="bibr" target="#b1">[2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Adversary Model</head><p>In this section, we formalize a passive and active adversary, which is general enough to model an adversarial host application and also privileged malware running in the OS-/VMM layer. penc's execution is interleaved with the host application -host application transfers control to penc via eenter or eresume, and penc returns control back to the host application via eexit. Control may also transfer from penc to the OS (i.e. privileged malware) in the event of an interrupt, exception, or fault. For example, the adversary may generate interrupts or control the page tables so that any enclave memory access results in a page fault, which is handled by the OS/VMM. The adversary may also force a hardware interrupt at any time. Once control transfers to adversary, it may execute any number of arbitrary x86+SGX instructions before transferring control back to the enclave. Therefore, our model of an active adversary performs an unbounded number of following adversarial transitions between any consecutive microarchitectural instructions executed by penc:</p><p>1. Havoc all non-enclave memory (denoted by havoc mem¬epc):</p><p>While the CPU protects the epc region, a privileged software adversary can write to any memory location in mem¬epc region. havoc mem¬epc is encoded in BoogiePL as:</p><formula xml:id="formula_1">assume ∀a. epc(a) → memnew[a] == mem[a]; mem := memnew;</formula><p>where memnew is an unconstrained symbolic value that is type-equivalent to mem. Observe that the adversary modifies an unbounded number of memory locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Havoc page tables: A privileged adversary can modify</head><p>the page tables to any value. Since page tables reside in mem¬epc, mem¬epc models havoc on page tables. where each register (e.g. eax ∈ regs) is set to an unconstrained symbolic value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Generate interrupt (denoted by interrupt):</head><p>The adversary can generate interrupts at any point, causing the CPU jump to the adversarial interrupt handler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Invoke any SGX instruction with any operands (denoted by call sgx):</head><p>The attacker may invoke ecreate, eadd, eextend, einit, eenter, and eresume to launch any number of new enclaves with code and data of attacker's choosing.</p><p>Any x86+SGX instruction that an active adversary invokes can be approximated by some finite-length combination of the above 5 transitions. Our adversary model is sound because it allows the active adversary to invoke an unbounded number of these transitions. Furthermore, the active adversary is quite powerful in this model. It may control the entire software stack, from the host application upto the OS/VMM layers, thereby modeling attacks from malicious administrators and privileged malware. The adversary controls all hardware peripherals, and may insert, delete, modify and replay all communication with the external world -these attacks can be modeled using the above 5 transitions. Side-channels are out of scope, where typical side channels may include memory access patterns, timing leaks, and I/O traffic patterns.</p><p>We define an active and passive adversary:</p><p>Definition 1. General Active Adversary G. Between any consecutive statements along an execution of penc, G may execute an unbounded number of transitions of type havoc mem¬epc, havoc regs, interrupt, or call sgx, thereby modifying a component σ|G of machine state σ. Following each microarchitectural instruction in penc, G observes a projection σ| obs of machine state σ. Here, σ| obs . = (σ.mem¬epc), and σ|G . = (σ.mem¬enc, σ.regs, σ.epcm ¬enc ).</p><p>Definition 2. Passive Adversary P. The passive adversary P observes a projection σ| obs of machine state σ after each microarchitectural instruction in penc. Here, σ| obs . = (σ.mem¬epc) includes the non-enclave memory. P does not modify any state.</p><p>Note that we omit σ.regs from σ| obs because they cannot be accessed by the adversary while the CPU operates in enclave mode -asynchronous exits clear their values, while eexit removes the CPU from enclave mode. Enclave execution may result in exceptions (such as divide by 0 and page fault exception) or faults (such as general protection fault), in which case the exception codes are conveyed to the adversarial OS. We omit exception codes from σ| obs for verification ease, and terminate the enclave (at runtime) on an exception, with the caveat of page fault exceptions which are allowed. Since G can havoc page tables, it can cause page fault exceptions at runtime. However, a page fault only reveals memory access patterns (at the page granularity), which we consider to be a side-channel observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">COMPOSING ENCLAVE WITH THE AD-VERSARY</head><p>Moat reasons about penc's execution in the presence of an adversary (P or G) by composing their state transition systems. An execution of penc is a sequence of statements [l1 : s1, l2 : s2, . . . , ln : sn], where each si is a load, store, register assignment x := e, user-mode SGX instruction (ereport, egetkey, or eexit), or a conditional statement. Since penc is made to be loop-free (by sound loop unrolling), each statement si has a distinct label li that relates to the program counter. We assume that each microarchitectural instruction (not the x86 instruction) executes atomically, although the atomicity assumption is architecture dependent.</p><p>Composing enclave penc with passive adversary P.</p><p>In the presence of P, penc undergoes a deterministic sequence of state transitions starting from initial state σ0. P cannot update V ars, therefore P affects penc's execution only via the initial state σ0. We denote this sequence of states as trace t = [σ0, σ1, . . . , σn], where (σi, σi+1) ∈ R(si) for each i ∈ 0, . . . , n -1. We also write this as penc, σ0 ⇓ t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Composing enclave penc with active adversary G.</head><p>G can affect penc at any step of execution by executing an unbounded number of adversarial transitions. Therefore, to model penc's behaviour in the presence of G, we consider the following composition of penc and G. For each penc statement l : s, we transform it to: adv1; . . . ; adv k ; l : s</p><p>This instrumentation (where k is unbounded) guarantees that between any consecutive statements along an execution of penc, G can execute an unbounded sequence of adversarial transitions adv1; . . . ; adv k , where each statement advi is an adversarial transition of type havoc mem¬epc, havoc regs, interrupt, or call sgx. This composed model, hereby called penc-G, encodes all possible behaviours of penc in the presence of G. An execution of penc-G is described by a sequence of states i.e. trace t = [α0, σ0, α1, σ1, . . . , αn, σn], where each αi ∈ t denotes the state after the last adversary transition adv k (right before execution resumes in the enclave). We coalesce the effect of all adversary transitions into a single state αi for cleaner notation. Following adv k , the composed model penc-G executes an enclave statement l : s, taking the system from a state αi to state σi.</p><p>Given a trace t = [α0, σ0, α1, σ1, . . . , αn, σn], we define</p><formula xml:id="formula_3">t| obs . = [σ 0 | obs , σ 1 | obs , . . . , σn| obs ]</formula><p>denoting the adversary-observable projection of trace t, ignoring the adversary controlled α states. Correspondingly, we define</p><formula xml:id="formula_4">t| G . = [α 0 | G , α 1 | G , . . . , αn| G ]</formula><p>capturing the adversary's effects within a trace t. We define the enclave projection of σ to be</p><formula xml:id="formula_5">σ|enc . = (σ.memenc, σ.regs, σ.epcm enc )</formula><p>This is the component of machine state σ that is accessible only by penc. Correspondingly, we define</p><formula xml:id="formula_6">t|enc . = [σ 0 |enc, σ 1 |enc, . . . , σn|enc]</formula><p>The transformation in (2) allows the adversary to perform an unbounded number of operations adv1, . . . , adv k , where k is any natural number. Since we cannot verify unbounded length programs using verification-condition generation, we consider the following alternatives:</p><p>• Bound the number of operations (k) that the adversary is allowed to perform. Although this approach bounds the length of penc-G, it unsoundly limits the G's capabilities.</p><p>• Use alternative adversary models in lieu of G with the hope of making the composed model both bounded and sound.</p><p>We explore the latter option in Moat. Our initial idea was to try substituting P for G. This would be the equivalent of making k equal 0, and thus penc-G bounded in length. However, for this to be sound, we must prove that G's operations can be removed without affecting penc's execution, as required by the following property.</p><formula xml:id="formula_7">∀σ ∈ Σ. ∀t i , t j ∈ Σ * . p enc-G , σ ⇓ t i ∧ penc, σ ⇓ t j ⇒ ∀i. t i |enc[i] = t j |enc[i]<label>(3)</label></formula><p>If property (3) holds, then we can substitute P for G while proving any safety (or k-safety <ref type="bibr" target="#b41">[16]</ref>) property of penc. While attempting to prove this property in the Boogie verifier <ref type="bibr" target="#b31">[6]</ref>, we quite expectedly discovered counter-examples that illustrate the different ways in which G affects penc's execution:</p><p>1. penc invokes load(mem, a), where a is an address in mem¬epc.</p><p>G havocs mem¬epc and penc reads mem¬epc for inputs, so this counter-example is not surprising.</p><p>2. penc invokes load(mem, a), where a is an address within SSA pages. G can force an interrupt, causing the CPU to save enclave state in SSA pages. If the enclave resumes and reads from SSA pages, then the value read depends on the enclave state at the time of last interrupt.</p><p>If we prevent penc from reading mem¬epc or the SSA pages, we successfully prove property <ref type="bibr">(3)</ref>. From hereon, we constrain penc to not read from SSA pages; we do not find this to be limiting in our case studies. Note that this restriction does not prevent the use of eresume instruction, which causes the CPU to access the SSA pages directly. However, the former constraint (not reading mem¬epc) is too restrictive in practice because penc must read mem¬epc to receive inputs. Therefore, we must explore alternative adversary models. Instead of replacing G with P, we attempt replacing G with H defined below. Definition 3. Havocing Active Adversary H. Between any consecutive statements along an execution of penc, H may execute a single havoc mem¬epc operation, thereby modifying a component σ|H of machine state σ. Following each microarchitectural instruction in penc, H observes a projection σ| obs of machine state σ. Here, σ| obs . = (σ.mem¬epc), and σ|H . = (σ.mem¬epc).</p><p>Composing enclave penc with active adversary H.</p><p>To construct penc-H, we transform each penc statement l : s to:</p><formula xml:id="formula_8">havoc mem¬epc; l : s<label>(4)</label></formula><p>Figure <ref type="figure" target="#fig_3">3</ref> shows a sample transformation from penc to penc-H. Similar to our previous exercise with P, we prove that it is sound to replace G with H while reasoning about enclave execution.</p><p>Theorem 1. Given an enclave program penc, let penc-G be the composition of penc and G via the transformation in (2) and penc-H be the composition of penc and H via the transformation in (4). Then,</p><formula xml:id="formula_9">∀σ ∈ Σ. ∀t 1 ∈ Σ * . p enc-G , σ ⇓ t 1 ⇒ ∃t 2 ∈ Σ * . p enc-H , σ ⇓ t 2 ∧ ∀i. t 1 |enc[i] = t 2 |enc[i]</formula><p>Validity of this theorem implies that we can replace G with H while proving any safety property or k-safety hyperproperty of enclave behaviour <ref type="bibr" target="#b41">[16]</ref>. We prove theorem 1 with the use of lemma 1 and lemma 2, described next.</p><p>The transformation in (2) composed penc with G by instrumenting an unbounded number of adversary operations adv1; . . . ; adv k before each statement in penc. Let us further instrument havoc mem¬epc after each advi ∈ {adv1; . . . ; adv k } -this is sound because a havoc on mem¬epc does not restrict the allowed values of mem¬epc. The resulting instrumentation for each statement l : s is: adv1; havoc mem¬epc; . . . ; adv k ; havoc mem¬epc; l : s</p><p>Lemma 1 proves that the effect of advi ∈ {adv1; . . . ; adv k } on penc can be simulated by a sequence of havocs to mem¬epc.</p><p>In order to define lemma 1, we introduce the following transformation on each statement l : s of penc: havoc mem¬epc; . . . ; havoc mem¬epc; l : s</p><p>Lemma 1. Given an enclave program penc, let penc-G * be the composition of penc and adversary via the transformation in <ref type="bibr" target="#b30">(5)</ref> and penc-H * be the composition of penc and adversary via the transformation in <ref type="bibr" target="#b31">(6)</ref>. Then,</p><formula xml:id="formula_12">∀σ ∈ Σ. ∀t 1 ∈ Σ * . p enc-G * , σ ⇓ t 1 ⇒ ∃t 2 ∈ Σ * . p enc-H * , σ ⇓ t 2 ∧ ∀i. t 1 |enc[i] = t 2 |enc[i]</formula><p>Proof : The intuition is that (if the enclave makes progress) the other adversarial transitions do not affect penc in any way that is not already simulated by havoc mem¬epc. For example, an interrupt causes the enclave to resume in the state prior to the interrupt. In addition, the CPU detects modifications to the page tables that affect the enclave pages, and prevents the enclave from progressing. Other enclaves on the machine may affect execution, but only by sending messages via non-enclave memory, which is simulated by havoc mem¬epc. We prove lemma 1 by induction as follows, and also machine-check the proof in Boogie <ref type="bibr" target="#b31">[6]</ref> (proof available at <ref type="bibr" target="#b1">[2]</ref>). The inductive proof makes use of our modeling of SGX instructions, and is setup as follows. This property in Lemma 1 is a predicate over a pair of traces, making it a 2-safety hyperproperty <ref type="bibr" target="#b41">[16]</ref>. A counter-example to this property is a pair of traces ti, tj where G has caused ti to diverge from tj. We rewrite the property as a 2-safety property and prove it via 1-step induction over the length of the trace, as follows. For any pair of states (σi,σj) that is indistinguishable to the enclave, we prove that after one transition, the new pair of states (σ i ,σ j ) is also indistinguishable. Here, (σi, σ i ) ∈ R(si) and (σj, σ j ) ∈ R(sj), where si is executed by penc-G * and sj is executed by penc-H * . The state predicate Init represents an enclave state after invoking einit in the prescribed initialization sequence in (1). Property 7 is the base case and property 8 is the inductive step in the proof by induction of lemma 1.</p><formula xml:id="formula_13">∀σ i , σ j .Init(σ i ) ∧ Init(σ j ) ⇒ σ i |enc = σ j |enc<label>(7)</label></formula><p>∀σ i , σ j , σ i , σ j , s i , s j .</p><formula xml:id="formula_14">σ i |enc = σ j |enc ∧ (σ i , σ i ) ∈ R(s i ) ∧ (σ j , σ j ) ∈ R(s j ) ∧ p(s i , s j ) ⇒ σ i |enc = σ j |enc<label>(8)</label></formula><p>where</p><formula xml:id="formula_15">p(s i , s j ) . =      s i ∈ {egetkey, ereport, eexit, load, store} ∧ s j = s i s i = s; havoc mem¬epc ∧ s j = havoc mem¬epc</formula><p>where s ∈ {havoc mem¬epc, . . . , interrupt, call sgx} Lemma 2. A sequential composition of unbounded number of havoc mem¬epc statements can be simulated by a single havoc mem¬epc statement.</p><p>Proof : Lemma 2 requires a straightforward proof as it follows naturally from the semantics of havoc.</p><p>Combining lemma 1 and lemma 2, we prove that the effect of adv1; havoc mem¬epc; . . . ; adv k ; havoc mem¬epc (or adv1; adv2;. . . ; advn) on enclave's execution can be simulated by havoc mem¬epc. By theorem 1, it is sound to prove any safety (or k-safety) property on penc-H because penc-H allows all traces allowed by penc-G. The benefits of composing with H are (1) penc-H is bounded in size, which allows using standard verification techniques to prove safety (or k-safety) properties of enclave programs, and (2) H gives a convenient mental model of an active adversary's effects on enclave execution. While we focus on proving confidentiality from hereon, we note that theorem 1 is valuable for soundly proving any safety property of enclave programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">FORMALIZING CONFIDENTIALITY</head><p>Moat's definition of confidentiality is inspired by standard non-interference definition <ref type="bibr">[27]</ref>, but adapted to the instructionlevel modeling of the enclave programs. Confidentiality can be trivially achieved with the definition that H cannot distinguish between penc and an enclave that executes skip in each step. However, such definition prevents penc from writing to mem¬epc, which it must write in order to return outputs or send messages to remote parties. To that end, we weaken this definition to allow for writes to mem¬epc, but constraining the values to be independent of the secrets. An input to Moat is a policy that defines Secrets = {(l, v) | l ∈ L, v ∈ Vars}, where a tuple (l, v) denotes that variable v holds a secret value at program location l. In practice, since secrets typically occupy several bytes in memory, v is a range of symbolic addresses in the enclave heap. We define the following transformation from penc-H to penc-H-sec for formalizing confidentiality. For each (l, v) ∈ Secrets, we transform the statement l : s to:</p><formula xml:id="formula_16">l : s; havoc v;<label>(9)</label></formula><p>havoc v assigns an unconstrained symbolic value to variable v. With this transformation, we define confidentiality as follows:</p><p>Definition 4. Confidentiality For any pair of traces of penc-H-sec that potentially differ in the values of the Secret variables, if H's operations along the two traces are equivalent, then H's observations along the two traces must also be equivalent.</p><formula xml:id="formula_17">∀σ ∈ Σ, t 1 , t 2 ∈ Σ * .( p enc-H-sec , σ ⇓ t 1 ∧ p enc-H-sec , σ ⇓ t 2 ∧ ∀i.t 1 | H [i] = t 2 | H [i]) ⇒ (∀i.t 1 | obs [i] = t 2 | obs [i])<label>(10)</label></formula><p>The havoc on Secrets cause the secret variables to take potentially differing symbolic values in t1 and t2. Property <ref type="bibr" target="#b35">(10)</ref> requires t1| obs and t2| obs to be equivalent, which is achieved only if the enclave does not leak secrets to Hobservable state.</p><p>While closer to the desired definition, it still prevents penc from communicating declassified outputs that depend on secrets. For instance, recall that the OTP enclave outputs the encrypted secret to be stored to disk. In this case, since different values of secret produce different values of ciphertext, penc violates property <ref type="bibr" target="#b35">(10)</ref>. This is a false alarm if the encryption uses a secret key to produce the ciphertext. To remove such false alarms, we take the standard approach of extending the policy with Declassif ied = {(l, v) | l ∈ L, v ∈ Vars}, where a tuple (l, v) denotes that variable v at location l contains a declassified value. In practice, since outputs typically occupy several bytes in memory, v is a range of symbolic addresses in the enclave heap. We can safely eliminate declassified outputs from information leaks as the protocol verifier has already proven them to be safe outputs (see Section 3.2). When declassification is necessary, we use the following property for checking confidentiality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 5. Confidentiality with Declassification</head><p>For any pair of traces of penc-H-sec that potentially differ in the values of the Secret variables, if H's operations along the two traces are equivalent, then H's observations (ignoring Declassified outputs) along the two traces must also be equivalent.</p><formula xml:id="formula_18">∀σ ∈ Σ, t 1 , t 2 ∈ Σ * .( p enc-H-sec , σ ⇓ t 1 ∧ p enc-H-sec , σ ⇓ t 2 ∧ ∀i.t 1 | H [i] = t 2 | H [i]) ⇒ (∀i, j. ¬epc(j) ⇒ ((i, mem[j]) ∈ Declassif ied ∨ t 1 | obs [i].mem[j] = t 2 | obs [i].mem[j]))<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">PROVING CONFIDENTIALITY</head><p>Moat automatically checks if penc-H satisfies confidentiality (property 11). Since confidentiality is a 2-safety hyperproperty (property over pairs of traces), we cannot use black box program verification techniques, which are tailored towards safety properties. Hence, we create a security type system in which type safety implies that penc-H satisfies confidentiality. We avoid a self-composition approach because of complications in encoding equivalence assumptions over adversary operations in the two traces of penc-H-sec (property 11). As in many type-based systems <ref type="bibr" target="#b59">[34,</ref><ref type="bibr" target="#b53">28]</ref>, the typing rules prevent programs that have explicit and implicit information leaks. Explicit leaks occur via assignments of secret values to H-observable state i.e. σ| obs . For instance, mem := store(mem,a,d) is ill-typed if d's value depends on a secret and enc(a) is false i.e. it writes a secret to non-enclave memory. An implicit leak occurs when a conditional statement has a secret-dependent guard, but updates H-visible state in either branch. For instance, if (d == 42) {mem := store(mem, a, 1)} else {skip} is ill-typed if d's value depends on a secret and enc(a) is false. In both examples above, H learns the secret value d by reading mem at address a. In addition to the store instruction, explicit and implicit leaks may also be caused by unsafe use of SGX instructions. For instance, egetkey returns a secret sealing key, which must not be leaked from the enclave. Similarly, ereport generates a signed report containing public values (e.g. measurement) and potentially secret values (enclave code may bind upto 64 bytes of data, which may be secret). Our type system models these details of SGX accurately, and accepts penc-H only if it has no implicit or explicit leaks.</p><p>A security type is either (secret) or ⊥ (public). At each program location, each memory location and CPU register has a security type based on the x86+SGX instructions executed until that label. The security types are needed at each program location because variables (especially regs) may alternate between holding secret and public values. As explained later in this section, Moat uses the security types in order to decide whether instructions in penc-H have implicit or explicit leaks. penc-H has Secrets = {(l, v)} and Declassif ied = {(l, v)} annotations. However, there are no other type declarations; therefore, Moat implements a type inference algorithm based on computing refinement type constraints and checking their validity using a theorem prover. In contrast, type checking without inference would require the programmer to painstakingly provide security types for each memory location and CPU register, at each program location -flow sensitivity and type inference are key requirements of type checking machine code.</p><p>Moat's type inference algorithm computes first-order logical constraints under which an expression or statement takes a security type. A typing judgment e : τ ⇒ ψ means that the expression e has security type τ whenever the constraint ψ is satisfied. An expression of the form op(v1, . . . , vn) (where op is a relation or function) has type τ if all variables {v1, . . . , vn} have type τ or lower. That is, an expression may have type ⊥ iff its value is independent of Secrets.</p><p>For a statement s to have type τ , every assignment in s must update a state variable whose security class is τ or higher. We write this typing judgment as [τ ] s ⇒ ψ, F , where ψ is a first-order (SMT) formula and F is a set of first-order (SMT) formulae. Each satisfiable interpretation of ψ corresponds to a feasible execution of s. F contains a SMT formula for each instruction in s, such that the formula is valid iff that instruction does not leak secrets. We present our typing rules in Figure <ref type="figure">7</ref>, which assume that penc-H is first converted to single static assignment form. s has type τ if we derive [τ ] s ⇒ ψ, F using the typing rules, and prove that all formulae in F are valid. If s has type , then s does not update H-visible state, and thus cannot contain information leaks. Having type also allows s to execute in a context where a secret value is implicitly known through the guard of a conditional statement. On the other hand, type ⊥ implies that s either does not update H-observable state or the update is independent of Secrets.</p><p>By Theorem 1, penc-H models all potential runtime behaviours of penc in the presence of an active adversary, and hence Moat feeds penc-H to the type checking algorithm. We now explain some of our typing rules from Figure <ref type="figure">7</ref>. For each variable v ∈ Vars within penc-H, our typing rules introduce a ghost variable Cv that is true iff v has security type . For a scalar register v, Cv is a boolean; for an array variable v, Cv (e.g. Cmem) is an array and Cv[i] denotes the security type for each location i. exp1 rule allows inferring the type of any expression e as . exp2 rule allows inferring an expression type e as ⊥ if we derive Cv to be false for all variables v in the expression e. storeL rule marks the memory location as secret if the stored data is secret. In case of secret data, we assert that the updated location is within mem¬enc; we also assert that the address is public to prevent implicit leaks. Since storeH rule types store instructions as , it unconditionally marks the memory location as secret. This is necessary because the store may execute in a context where a secret is implicitly known through the guard of a conditional statement. load marks the updated register as secret if the memory location contains a secret value. ereportL rule types the updated memory locations as per SGX semantics. ereport takes 64 bytes of data (that the programmer intends to bind to the measurement) at address in ecx, and copies them to memory starting at address edx + 320; the rest of the report has public data such as the MAC, measurement, etc. Hence, Cmem retains the secrecy level for the 64 bytes of data, and assumes f alse for the public data. Similar to storeH, ereportH unconditionally marks all 432 bytes of the report as secret. egetkey stores 16 bytes of the sealing key at address ecx, hence the egetkey rule marks those 16 bytes in Cmem as secret. Notice that we do not assert that ereport and egetkey writes to enclave memory since this is enforced by SGX. eexit jumps to the host application without clearing regs. Hence, the eexit rule asserts that those regs hold public values. We prove the following type soundness theorem (machine-checked proof available at <ref type="bibr" target="#b1">[2]</ref>).</p><p>Theorem 2. For any penc-H such that [τ ] penc-H ⇒ (ψ, F) is derivable (where τ is either or ⊥) and all formulae in F are valid, penc-H satisfies property 11.</p><p>• Our type system includes rules for updating unbounded array variables (e.g. mem), without requiring that all indices in the array take the same security type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">EVALUATION AND EXPERIENCE</head><p>Moat's implementation comprises (1) translation from x86 + SGX program to penc using BAP, (2) transformation to penc-H using instrumentation in 4, (3) transformation to I(penc-H) using Figure <ref type="figure">8</ref>, and (4) invoking the Boogie verifier to prove validity of all assertions in I(penc-H) (modulo declassifications from the protocol verification step). Optimizations: Our primary objective was to build a sound verifier for proving confidentiality in the presence of an active adversary. However, due to certain scalability challenges, we implement the following optimizations. First, we only introduce havoc mem¬epc prior to load instructions because only a load can be used to read mem¬epc. Furthermore, we axiomatize specific library calls such as memcpy and memset, because their loopy implementations incur significant verification overhead.</p><p>We now describe some case studies which we verified using Moat and ProVerif in tandem, and summarize the results in Figure <ref type="figure" target="#fig_10">9</ref>. We use the following standard crytpographic notation and assumptions. m1| . . . |mn denotes tagged concatenation of n messages. We use a keyed-hash message authentication function MAC k (text) and hash function H(text), both of which are assumed to be collision-resistant. For asymmetric cryptography, K -1 e and Ke are principal e's private and public signature keys, where we assume that Ke is long-lived and distributed within certificates signed by a root of trust authority. Digital signature using a key k is written as Sig k (text); we assume unforgeability under chosen message attacks. Intel provisions each SGX processor with a unique private key K -1 SGX that is available to a special quoting enclave. In combination with this quoting enclave, an enclave can invoke ereport to produce quotes, which is essentially a signature (using the private key K -1 SGX ) of the data produced by the enclave and its measurement. We write a quote produced on behalf of enclave e as Quote e (text), which is equivalent to Sig K -1 SGX (H(text) | Me) -measurement of enclave e is written as Me. N is used to denote nonce. Finally, we write Enc k (text) for the encryption of text, for which we assume indistinguishability under chosen plaintext attack. We also use AEnc k (text) for authenticated encryption, for which we assume indistinguishability under chosen plaintext attack and integrity of ciphertext. Recall that although the enclave code contains calls to these cryptographic primitives, Moat abstracts them as uninterpreted functions with basic memory safety axioms. We use cryptopp [1] in our case studies, and we do not verify its implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-time Password Generator.</head><p>The abstract model of the OTP secret provisiong protocol (from § 2), where client runs in a SGX enclave, bank is an uncompromised service, and disk is under adversary control:</p><formula xml:id="formula_19">bank → client : N client → bank : N | g c | Quote client (N | g c ) bank → client : N | g b | Sig K -1 bank (N | g b ) | AEnc H(g bc ) (secret) client → disk : AEncK seal (secret)</formula><p>First, we use Moat to prove that g bc and K seal are not leaked to H. Next, ProVerif uses secrecy assumption on g bc and K seal to prove that secret is not leaked to a network adversary. This proof allows Moat to declassify client's output to disk while proving property 11. Moat successfully proves that the client enclave satisfies confidentiality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notary Service.</head><p>We implement a notary service introduced by <ref type="bibr" target="#b46">[21]</ref> but adapted to run on SGX. The notary enclave assigns logical timestamps to documents, giving them a total ordering. The notary enclave responds to (1) a connect message for obtaining the attestation report, and (2) a notarize message for obtaining a signature over the document hash and the current counter. The only secret here is the private signature key K -1 notary . First, we use Moat to prove that K -1 notary is not leaked to H. This proof fails because the output of Sig (in the response to notarize message) depends on the secret signature key -Moat is unaware of cryptographic properties of Sig. ProVerif proves that this message does not leak K -1 notary to a network adversary, which allows Moat to declassify this message and prove that the notary enclave satisfies confidentiality.</p><p>End-to-End Encrypted Instant Messaging.</p><p>We implement the off-the-record messaging protocol <ref type="bibr" target="#b38">[13]</ref>, which provides perfect forward secrecy and repudiability for messages exchanged between principals A and B. We adapt this protocol to run on SGX, thus providing an additional guarantee that an infrastructure attack cannot compromise the ephemeral Diffie-Hellman keys, which encrypt and integrity-protect the messages between A and B. We only present a synchronous form of communication here for simplicity. The OTR protocol only needs a digital signature on the initial Diffie-Hellman exchange -future exchanges use MACs to authenticate a new key using an older, known-authentic key. For the same reason, we only append a SGX quote to the initial key exchange. First, we use Moat to prove that the Diffie-Hellman secrets computed by penc (i.e. g a 1 b 1 , g a 2 b 1 , g a 2 b 2 ) are not leaked to H. Next, ProVerif uses this secrey assumption to prove that messages m1, m2, and m3 are not leaked to the network adversary. The ProVerif proofs allows Moat to declassify all messages following the initial key exchange, and successfully prove confidentiality.</p><formula xml:id="formula_20">A → B : g a 1 | Sig K -1 A (g a 1 ) | Quote A (Sig K -1 A (g a 1 )) B → A : g b 1 | Sig K -1 B (g b 1 ) | Quote B (Sig K -1 B (g b 1 )) A → B : g a 2 | Enc</formula><p>Query Processing over Encrypted Database.</p><p>In this case study, we evaluate Moat on a stand-alone application, removing the possibility of protocol attacks and therefore the need for any protocol verification. We build a database table containing two columns: name which is deterministically encrypted, and amount which is nondeterministically encrypted. Alice wishes to select all rows with name "Alice" and sum all the amounts. We partition this computation into two parts: unprivileged computation (which selects the rows) and enclave computation (which computes the sum).  Secure Systems on Trusted Hardware. In recent years, there has been growing interest in building secure systems on top of trusted hardware. Sancus <ref type="bibr" target="#b54">[29]</ref> is a security architecture for networked embedded devices that seeks to provide security guarantees without trusting any infrastructural software, only relying on trusted hardware. Intel SGX <ref type="bibr" target="#b48">[23]</ref> seeks to provide similar guarantees via extension to the x86 instruction set. There are some recent efforts on using SGX for trusted computation. Haven <ref type="bibr" target="#b35">[10]</ref> is a system that exploits Intel SGX for shielded execution of unmodified Windows applications. It links the application together with a runtime library OS that implements the Windows 8 API. However, it does not provide any confidentiality or integrity guarantees, and includes a significant TCB. VC3 <ref type="bibr" target="#b58">[33]</ref> uses SGX to run map-reduce computations while protecting data and code from an active adversary. However, VC3's confidentiality guarantee is based on the assumption that enclave code does not leak secrets, and we can use Moat to verify this assumption. Santos et al. <ref type="bibr" target="#b57">[32]</ref> seek to build a trusted language runtime for mobile applications based on ARM TrustZone <ref type="bibr" target="#b29">[4]</ref>. These design efforts have thrown up very interesting associated verification questions, and our paper seeks to address these with a special focus on Intel SGX. Verifying Information Flow on Programs. Checking implementation code for safety is also a well studied problem. Type systems proposed by Sabelfeld et al. <ref type="bibr" target="#b56">[31]</ref>, Barthe et al. <ref type="bibr" target="#b34">[9]</ref>, and Volpano et al. <ref type="bibr" target="#b59">[34]</ref> enable the programmer to annotate variables that hold secret values, and ensure that these values do not leak. Balliu et al. <ref type="bibr" target="#b30">[5]</ref> automate information flow analysis of ARMv7 machine code. Languages and verification techniques also exist for quantitative information flow (e.g., <ref type="bibr" target="#b47">[22]</ref>). However, these works assume that the infrastructure (OS/VMM, etc.) on which the code runs is safe, which is unrealistic due to malware and other attacks. Our approach builds upon this body of work, showing how it can be adapted to the setting where programs run on an adversarial OS/VMM, and instead rely on trusted SGX hardware for information-flow security. Cryptographic Protocol Verification. There is a vast literature on cryptographic protocol verification (e.g. <ref type="bibr" target="#b36">[11,</ref><ref type="bibr" target="#b37">12]</ref>). Our work builds on top of cryptographic protocol verifiers showing how to use them to reason about protocol attacks and to generate annotations for more precise verification of enclave programs. In the future, it may also be possible to connect our work to the work on correctby-construction generation of cryptographic protocol implementation <ref type="bibr">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">CONCLUSION</head><p>This paper introduces a technique for verifying information flow properties of enclave programs. Moat is a first step towards building an end-to-end verifier. Our current evaluation uses separate models for Moat and ProVerif. In future, we plan to design a high-level language from which we generate machine code, enclave model, and a protocol model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Running OTP Example. The enclave performs trusted cryptographic operations, and the host application performs untrusted tasks such as UI handling and network communications with the OTP server.</figDesc><graphic coords="4,38.74,53.80,532.22,208.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: OTP enclave snippet (left) and penc (right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1</head><label></label><figDesc>havoc mem¬epc; mem := egetkey(mem, ebx, ecx); 2 havoc mem¬epc; mem := store(mem, add(esp,8), 8080AC); 3 havoc mem¬epc; eax := sub(ebp, 6e0); 4 havoc mem¬epc; mem := store(mem, add(esp,4), eax); 5 havoc mem¬epc; eax := sub(ebp, 720); 6 havoc mem¬epc; mem := store(mem, esp, eax); 7 havoc mem¬epc; mem := AES_GCM_encrypt(mem, esp); 8 havoc mem¬epc; eax := load(mem, 700048); 9 havoc mem¬epc; mem := store(mem, add(esp,8), eax); 10 havoc mem¬epc; eax := sub(ebp, 720); 11 havoc mem¬epc; mem := store(mem, add(esp,4), eax); 12 havoc mem¬epc; mem := store(mem, esp, 701000); 13 havoc mem¬epc; mem := memcpy(mem, esp);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: penc-H constructed from OTP pencAs mentioned before, the OTP enclave implementation is vulnerable. The size argument to memcpy (line 26 in Figure1) is a field within a data structure in non-enclave memory. This vulnerability manifests as a load (line 8 of Figure3), which reads a value from non-enclave memory and passes that value as the size argument to memcpy. To perform the exploit, H uses havoc mem¬epc (in line 8) to choose the number of bytes that penc-H writes to non-enclave memory, starting at the base address of sealed_secret. By setting this value to be greater than the size of sealed_secret, H causes penc-H to leak the stack contents, which includes the sealing_key. We can assume for now that writing sealed_secret to the unprotected app_heap is safe because it is encrypted. We formalize a confidentiality property in § 6 that prevents such vulnerabilities, and build a static type system in § 7 which only admits programs that satisfy confidentiality. Confidentiality enforces that for any pair of traces of penc-H that differ in the values of Secrets, if H's operations along the two traces are equivalent, then H's observations along the two traces must also be equivalent. In other words, H's observation of penc's execution is independent of Secrets. Note that we omit side channels from H's observation in this work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: penc-H instrumented with typing assertions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Syntax of programs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Axioms for xor, load, and eexit instructions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3 .</head><label>3</label><figDesc>Havoc CPU registers (denoted by havoc regs). regs are modified only during adversary execution, and retrieve their original values once the enclave resumes. havoc regs is encoded in BoogiePL as: regs := regs new ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>user → notary : connect | N notary → user : Quote notary (N ) user → notary : notarize | H(text) notary → user : counter | H(text) | Sig K -1 notary (counter | H(text))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>H(g a 1 b 1 ) (m1) | MAC H(H(g a 1 b 1 )) (g a 2 | Enc H(g a 1 b 1 ) (m1)) B → A : g b 2 | Enc H(g a 2 b 1 ) (m2) | MAC H(H(g a 2 b 1 )) (g b 2 | Enc H(g a 2 b 1 ) (m2)) A → B : g a 3 | Enc H(g a 2 b 2 ) (m3) | MAC H(H(g a 2 b 2 )) (g a 3 | Enc H(g a 2 b 2 ) (m3))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Summary of experimental results. Columns are (1) instructions analyzed by Moat not including crypto library, (2) size of I(penc-H), (3) proof time, (4) number of secret and declassifed annotations</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">ACKNOWLEDGMENTS</head><p>This research is supported in part by SRC contract 2460.001 and NSF STARSS grant 1528108. We gratefully acknowledge Brent ByungHoon Kang and the anonymous reviewers for their insightful feedback.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>[⊥] mem := store(mem, ea, e Moat implements this type system by replacing each statement s in penc-H by I(s) using the instrumentation rules in Figure <ref type="figure">8</ref>. Observe that we introduce Cpc to track whether confidential information is implicitly known through the program counter. If a conditional statement's guard depends on a secret value, then we set Cpc to true within the then and else branches. Moat invokes I(penc-H) and applies the instrumentation rules in Figure <ref type="figure">8</ref> recursively. Figure <ref type="figure">4</ref> demonstrates an example of instrumenting penc-H. Moat then feeds the instrumented program I(penc-H) to an off-the-shelf program verifier, which proves validity all assertions or finds a counter-example. Our implementation uses the Boogie <ref type="bibr" target="#b31">[6]</ref> program verifier, which receives I(penc-H) and generates verification conditions in the SMT format. Boogie uses the Z3 <ref type="bibr" target="#b42">[17]</ref> theorem prover (SMT solver) to prove the verification conditions. An advantage of using SMT solving is that a typing error is explained using counter-example execution, demonstrating the information leak and exploit.   In summary, Moat's type system is inspired by the typebased approach for information flow checking by Volpano et al. <ref type="bibr" target="#b59">[34]</ref>. The core modifications are as follows:</p><p>• Our type system includes rules for SGX instructions ereport, egetkey, and eexit. The rules precisely model the memory locations written by these these instructions, and whether the produced data is public or confidential.</p><p>• Our type system is flow-sensitive and path-sensitive, and performs type inference. A program is well-typed if the typing assertions are valid in all feasible executions. We ensure soundness by using a sound program verifier to explore all feasible executions of the instrumented penc-H.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">assert ¬Cecx; C old mem := Cmem</title>
		<imprint/>
	</monogr>
	<note>havoc Cmem</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">ecx ≤ i &lt; ecx + 16) → Cmem</title>
		<imprint/>
	</monogr>
	<note>i] ↔ true</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">¬(ecx ≤ i &lt; ecx + 16) → Cmem[i] ↔ C old mem</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">havoc mem¬epc; mem := egetkey(mem, ebx</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m">= false; 6 havoc mem¬epc; mem := store</title>
		<imprint/>
	</monogr>
	<note>assert ¬Cesp; Cmem[add(esp, 8). mem, add(esp,8), 8080AC</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">havoc mem¬epc; eax := sub</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><surname>Cmem</surname></persName>
		</author>
		<title level="m">Ceax; 10 havoc mem¬epc; mem := store(mem, add</title>
		<imprint/>
	</monogr>
	<note>add(esp, 4)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">11 Ceax := C ebp</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
	<note>eax := sub(ebp, 720</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">13 assert ¬Cesp ∧ (¬enc(esp) → ¬Ceax)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><surname>Cmem</surname></persName>
		</author>
		<title level="m">Ceax; 14 havoc mem¬epc; mem := store</title>
		<imprint/>
	</monogr>
	<note>mem, esp, eax</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m">15 Cmem := C_AES_GCM_encrypt</title>
		<meeting><address><addrLine>Cmem, esp</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">16 havoc mem¬epc; mem := AES_GCM_encrypt(mem</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">17 Ceax := Cmem</title>
		<imprint>
			<biblScope unit="volume">700048</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">18 havoc mem¬epc; eax := load(mem</title>
		<imprint>
			<biblScope unit="volume">700048</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><surname>Cmem</surname></persName>
		</author>
		<title level="m">Ceax; 20 havoc mem¬epc; mem := store</title>
		<imprint/>
	</monogr>
	<note>add(esp, 8). mem, add(esp,8), eax</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m">21 Ceax := C ebp ; 22 havoc mem¬epc; eax := sub</title>
		<imprint>
			<biblScope unit="volume">720</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><surname>Cmem</surname></persName>
		</author>
		<title level="m">Ceax; 24 havoc mem¬epc; mem := store(mem, add</title>
		<imprint/>
	</monogr>
	<note>add(esp, 4)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">25 assert ¬Cesp; Cmem[esp] := false</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
	<note>mem := store(mem, esp, 7001000</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Cmem := C_memcpy</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">28 arg1 := load(mem, esp)</title>
		<imprint/>
	</monogr>
	<note>arg3 := load(mem, add(esp, 8)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">29 havoc mem¬epc; mem := memcpy(mem</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">30 assert ∀i. ((arg1 ≤ i &lt; add(arg1, arg3)) ∧ ¬enc(i)) → ¬Cmem</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m">{ return x ⊕ y; } 2 function load</title>
		<imprint/>
	</monogr>
	<note>function xor(x: bv32, y: bv32. mem:[bv32]bv8, va:bv32</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m">EPCM security checks succeed? 5 var pa : bv32</title>
		<imprint/>
	</monogr>
	<note>translated physical address 6 var ea : bool; //enclave access to enclave memory? 7 pa := pagetable[va</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">= epc(pa) &amp;&amp; 10 EPCM_VALID(epcm[pa]) &amp;&amp; 11 EPCM_PT(epcm</title>
		<idno>== PT_REG &amp;&amp; 12 EPCM_ENCLAVESECS(epcm[pa]) == CR_ACTIVE_SECS &amp;&amp; 13 EPCM_ENCLAVEADDRESS</idno>
		<imprint/>
	</monogr>
	<note>== va</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">//read bit set and pagetable has valid mapping 16 if (!ea &amp;&amp; epc(pa)) {return 0xff;} else {return mem</title>
	</analytic>
	<monogr>
		<title level="s">EPCM security checks 15 assert .</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m">17 } 18 function eexit</title>
		<imprint/>
	</monogr>
	<note>mem:[bv32]bv8, ebx:bv32</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">20 var mem&apos; := mem; var regs</title>
	</analytic>
	<monogr>
		<title level="j">= regs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Preventing memory error exploits with wit</title>
		<author>
			<persName><forename type="first">P</forename><surname>Akritidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raiciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Castro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 IEEE Symposium on Security and Privacy, SP &apos;08</title>
		<meeting>the 2008 IEEE Symposium on Security and Privacy, SP &apos;08<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m">ARM Security Technology -Building a Secure System using TrustZone Technology. ARM Technical White Paper</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automating information flow analysis of low level code</title>
		<author>
			<persName><forename type="first">M</forename><surname>Balliu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guanciale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;14</title>
		<meeting>the 2014 ACM SIGSAC Conference on Computer and Communications Security, CCS &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1080" to="1091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Boogie: A modular reusable verifier for object-oriented programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R M</forename><surname>Leino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FMCO &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">4111</biblScope>
			<biblScope unit="page" from="364" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakest-precondition of unstructured programs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R M</forename><surname>Leino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PASTE &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="82" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Satisfiability modulo theories</title>
		<author>
			<persName><forename type="first">C</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Satisfiability</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Biere</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Van Maaren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Walsh</surname></persName>
		</editor>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Secure information flow for a concurrent language with scheduling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Nieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Security</title>
		<imprint>
			<biblScope unit="page" from="647" to="689" />
			<date type="published" when="2007">2007</date>
			<publisher>IOS Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Shielding applications from an untrusted cloud with Haven</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An Efficient Cryptographic Protocol Verifier Based on Prolog Rules</title>
		<author>
			<persName><forename type="first">B</forename><surname>Blanchet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IEEE Computer Security Foundations Workshop</title>
		<meeting><address><addrLine>Cape Breton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-06">June 2001</date>
			<biblScope unit="page" from="82" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A computationally sound automatic prover for cryptographic protocols</title>
		<author>
			<persName><forename type="first">B</forename><surname>Blanchet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on the link between formal and computational models</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">June 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Off-the-record communication, or, why not to use pgp</title>
		<author>
			<persName><forename type="first">N</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACM Workshop on Privacy in the Electronic Society, WPES &apos;04</title>
		<meeting>the 2004 ACM Workshop on Privacy in the Electronic Society, WPES &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">BAP: A binary analysis platform</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brumley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Avgerinos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computer Aided Verification, CAV&apos;11</title>
		<meeting>the 23rd International Conference on Computer Aided Verification, CAV&apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="463" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modeling and Verifying Systems using a Logic of Counter Arithmetic with Lambda Expressions and Uninterpreted Functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer-Aided Verification (CAV&apos;02)</title>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
			<biblScope unit="volume">2404</biblScope>
			<biblScope unit="page" from="78" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><surname>Hyperproperties</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Security</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1157" to="1210" />
			<date type="published" when="2010-09">Sept. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An efficient SMT solver</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bjørner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TACAS &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="337" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The matter of heartbleed</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Durumeric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kasten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Adrian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Halderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Amann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Payer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Internet Measurement Conference</title>
		<meeting>the 2014 Conference on Internet Measurement Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="475" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cryptographically sound implementations for typed information-flow security</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fournet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rezk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 35th Symposium on Principles of Programming Languages</title>
		<meeting>35th Symposium on Principles of Programming Languages</meeting>
		<imprint>
			<publisher>G. Smith</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic discovery of API-level exploits</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ganapathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Reps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 27th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<date type="published" when="2005-05">May 2005</date>
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Ironclad apps: end-to-end security via automated full-system verification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hawblitzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th USENIX conference on Operating Systems Design and Implementation</title>
		<meeting>the 11th USENIX conference on Operating Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="165" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Quantifying information leaks in software</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heusser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malacaria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Computer Security Applications Conference</title>
		<meeting>the 26th Annual Computer Security Applications Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="261" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Using innovative instructions to create trustworthy software solutions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hoekstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pappachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Phegade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cuvillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Hardware and Architectural Support for Security and Privacy</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Intel Software Guard Extensions Programming Reference</title>
		<ptr target="https://software.intel.com/sites/default/files/329298-001.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">sel4: Formal verification of an os kernel</title>
		<author>
			<persName><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Elphinstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andronick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Derrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Elkaduwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kolanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP &apos;09</title>
		<meeting>the ACM SIGOPS 22nd Symposium on Operating Systems Principles, SOSP &apos;09<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="207" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Innovative instructions and software model for isolated execution</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mckeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Alexandrovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berenzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Rozas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shanbhogue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">R</forename><surname>Savagaonkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, HASP &apos;13</title>
		<meeting>the 2nd International Workshop on Hardware and Architectural Support for Security and Privacy, HASP &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Proving noninterference and functional correctness using traces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mclean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="37" to="58" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A decentralized model for information flow control</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Symposium on Operating Systems Principles, SOSP &apos;97</title>
		<meeting>the 16th ACM Symposium on Operating Systems Principles, SOSP &apos;97<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="129" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sancus: Low-cost trustworthy extensible networked devices with a zero-software trusted computing base</title>
		<author>
			<persName><forename type="first">J</forename><surname>Noorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Strackx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Herrewege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huygens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preneel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Verbauwhede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Piessens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd USENIX Conference on Security</title>
		<meeting>the 22nd USENIX Conference on Security</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="479" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Language-based information-flow security. Selected Areas in Communications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sabelfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="19" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A model for delimited information release</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sabelfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Symp. on Software Security</title>
		<meeting>International Symp. on Software Security</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="174" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Using ARM TrustZone to build a trusted language runtime for mobile applications</title>
		<author>
			<persName><forename type="first">N</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saroiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wolman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on Architectural support for programming languages and operating systems (ASPLOS)</title>
		<meeting>the 19th international conference on Architectural support for programming languages and operating systems (ASPLOS)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="67" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">VC3: trustworthy data analytics in the cloud using SGX</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fournet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gkantsidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mainar-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Russinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Symposium on Security and Privacy</title>
		<meeting><address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-17">2015. May 17-21, 2015. 2015</date>
			<biblScope unit="page" from="38" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A sound type system for secure flow analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Volpano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Security</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="167" to="187" />
			<date type="published" when="1996-01">Jan. 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Safe to the last instruction: Automated verification of a type-safe operating system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hawblitzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Conference on Programming Language Design and Implementation</title>
		<meeting>the 31st Conference on Programming Language Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="99" to="110" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
