<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework</title>
				<funder>
					<orgName type="full">HiSilicon</orgName>
				</funder>
				<funder ref="#_UUFvdsc #_tR6Xx7M">
					<orgName type="full">The Research Grants Council of Hong Kong SAR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chen</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianwang</forename><surname>Zhai</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuzhe</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bei</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">D F</forename><surname>Wong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The microarchitecture design of a processor has been increasingly difficult due to the large design space and timeconsuming verification flow. Previously, researchers rely on prior knowledge and cycle-accurate simulators to analyze the performance of different microarchitecture designs but lack sufficient discussions on methodologies to strike a good balance between power and performance. This work proposes an automatic framework to explore microarchitecture designs of the RISC-V Berkeley Out-of-Order Machine (BOOM), termed as BOOM-Explorer, achieving a good trade-off on power and performance. Firstly, the framework utilizes an advanced microarchitectureaware active learning (MicroAL) algorithm to generate a diverse and representative initial design set. Secondly, a Gaussian process model with deep kernel learning functions (DKL-GP) is built to characterize the design space. Thirdly, correlated multi-objective Bayesian optimization is leveraged to explore Pareto-optimal designs. Experimental results show that BOOM-Explorer can search for designs that dominate previous arts and designs developed by senior engineers in terms of power and performance within a much shorter time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Recently, RISC-V, an open-source instruction set architecture (ISA) gains much attention and also receives strong support from academia and industry. Berkeley Out-of-Order Machine (BOOM) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, a RISC-V design fully in compliance with RV64GC instructions, is competitive in power and performance against low-power, embedded out-of-order cores in academia. By adopting Chisel hardware construction language <ref type="bibr" target="#b2">[3]</ref>, BOOM can be parametric, providing great opportunities to explore a series of microarchitecture designs that have a better balance on power and performance for different purposes of use.</p><p>Microarchitecture defines the implementation of an ISA in a processor. Due to different organizations and combinations of components inside a processor, microarchitecture designs under a specific technology process can affect power dissipation, performance, die area, etc. of a core <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. Finding a good microarchitecture that can accommodate a good balance between power and performance is a notorious problem because of two restrictions. On the one hand, the design space is extremely large and the size of it can be exponential with more components to be considered, e.g., special queues, buffers, branch predictors, vector execution unit, external co-processors, etc. Thus, we cannot traverse and evaluate each microarchitecture to retrieve the best one. On the other hand, it costs a lot of time to acquire metrics, e.g., power, performance, etc. when we verify one microarchitecture with diverse benchmarks.</p><p>In industry, the traditional solution is based on prior engineering experience from computer architects. However, it lacks scalability for newly emerged processors. In academia, to overcome these two obstacles, researchers proposed various arts, which can be categorized as two kinds of methodologies. First, in view of the difficulty in constructing an analytical model, researchers can otherwise characterize a microarchitecture design space with fewer samples as much as possible by leveraging statistical sampling and predictive black-box models. Li et al. <ref type="bibr" target="#b5">[6]</ref> proposed AdaBoost Learning with novel sampling algorithms to explore the design space. Second, to search for more designs within a limited time budget, researchers often rely on coarse-grained simulation infrastructure rather than a register-transfer level (RTL) verification flow to accelerate the process <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Moreover, by decreasing redundant overhead, the simulation can be further speed up <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>.</p><p>Unfortunately, both of these academic solutions contain several limitations. In the first place, despite the fact that statistical analysis performs well when highly reliable models can be constructed, it fails to embed prior knowledge on microarchitectures to further improve design space exploration. For another, to accelerate the simulation, coarsegrained simulation infrastructure is used widely. Nevertheless, most of them lose sufficient accuracy, especially for distinct processors. The low quality of results is generated often due to the misalignment between simulation and real running behaviors of processors. More importantly, because it is difficult to model the power dissipation of modern processors at the architecture level <ref type="bibr" target="#b14">[15]</ref>, some infrastructure cannot provide power value, e.g., <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>. In general, because of the aforementioned limitations, academia lacks sufficient discussions on methodologies that can explore microarchitecture designs achieving a good trade-off between power and performance.</p><p>In this paper, following the first strategy, we propose BOOM-Explorer address these issues. In BOOM-Explorer, without sacrificing the accuracy of a predictive model, we embed prior knowledge of BOOM to form a microarchitectureaware active learning (MicroAL) algorithm based on transductive experimental design <ref type="bibr" target="#b15">[16]</ref> by utilizing BOOM RTL samples among the entire design space as few as possible. Secondly, a novel Gaussian process model with deep kernel learning functions (DKL-GP) initialized through MicroAL, is proposed to characterize the features of different microarchitectures. The design space is then explored via correlated multi-objective Bayesian optimization flow <ref type="bibr" target="#b16">[17]</ref> based on DKL-GP. Our framework can not only take advantage of fewer microarchitecture designs as much as possible but also helps us to find superior designs that have a better balance between power and performance.</p><p>Our contributions are summarized as follows:</p><p>? A microarchitecture-aware active learning methodology based on transductive experimental design is introduced for the first time to attain the most representative designs from an enormous RISC-V BOOM design space.</p><p>? A novel Gaussian process model with deep kernel learning and correlated multi-objective Bayesian optimization are leveraged to characterize the microarchitecture design space. With the help of DKL-GP, Pareto optimality is explored between power and performance.</p><p>? We verify our framework with BOOM under advanced 7nm technology. The experimental results demonstrate the outstanding performance of BOOM-Explorer on various BOOM microarchitectures. The remainder of this paper is organized as follows. Section II introduces the RISC-V BOOM core and the problem formulation. Section III provides detailed explanations on the framework. Section IV conducts several experiments on BOOM core to confirm the outstanding performance of the proposed framework. Finally, Section V concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. RISC-V BOOM Core</head><p>BOOM is an open-source superscalar out-of-order RISC-V processor in academia and it is proved to be industrycompetitive in low-power, embedded application scenarios <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> demonstrates the organization of BOOM. Consist of four main parametric modules, i.e., FrontEnd, IDU, EU, and LSU, BOOM can execute benchmarks in distinct behaviors via choosing different candidate values for each component inside these modules. FrontEnd fetches instructions from L2 Cache, packs these instructions as a sequence of fetch packages, and sends them to IDU. IDU decodes instructions as micro-ops and dispatches these micro-ops w.r.t. their categories to issue queues in EU, the latter of which, triggered by corresponding micro-ops and related logics, is responsible for manipulating operands in an out-of-order manner. Finally, some memory-related operations, i.e., loading data and storing data, interact with LSU after EU calculates the results. In addition, BOOM also integrates branch predictors, floatingpoint execution units, vector execution units, etc.</p><p>Thanks to the parameterized modules provided by BOOM, various BOOM microarchitectures can be acquired by configuring the core with different parameters. Thus, divergent trade-offs between power dissipation and performance to meet various design requirements can be achieved, e.g., lowpower, and embedded applications. However, a satisfying microarchitecture design is non-trivial to be found. Across all parametric modules, a microarchitecture design space of BOOM is constructed and shown in the module. RasEntry and BranchCount in FrontEnd are considered since they have great impacts on the behaviors of branch predictions, and thus incur different power and performance. Because caches, e.g., D-Cache in LSU, often runs at a lower frequency compared to other modules, the component might be hotspots when many memory-related requests occur in the instructions pipeline. A suitable structure of D-Cache can alleviate the burden, therefore different organizations of D-Cache (i.e., associativity, block width, TLB size, etc.) are also included for exploration. Besides, I-Cache is also considered in the design space. Different BOOM microarchitecture designs can be constructed with various combinations of candidate values. However, some combinations do not observe constraints of BOOM design specifications as shown in TABLE II. Thus they are illegal and cannot be compiled to Verilog. For example, each entry of the reorder buffer traces status of every in-flight but decoded instruction in the pipeline. If a microarchitecture does not obey rule 2, reorder buffer may not reserve enough entries for each decoded instruction or may contain redundant entries that cannot be fully used at all. The last three rules in TABLE II are added to simplify the design space. They require the same number of entries or registers in respective components and their additions will not affect the performance of BOOM-Explorer. After we prune the design space w.r.t. rules in   Definition 2 (Power). The power is to be defined as the summation of dynamic power dissipation, short-circuit power dissipation, and leakage power dissipation.</p><p>Definition 3 (Clock Cycle). The clock cycle is to be defined as the clock cycles consumed when a BOOM microarchitecture design runs a specific benchmark.</p><p>Provided with the same benchmark, power and clock cycle are a pair of trade-off metrics since the lower cycles are, the more power will be dissipated when a design integrates more hardware resources to accelerate instructions execution. Together, They reflect whether a microarchitecture design is good or not. Power and clock cycle are denoted as y.</p><p>Definition 4 (Pareto Optimality). For a n-dimensional minimization problem, an objective vector f (x) is said to be dominated by</p><formula xml:id="formula_0">f (x ) if ?i ? [1, n], f i (x) ? f i (x ); ?j ? [1, n], f j (x) &lt; f j (x ).<label>(1)</label></formula><p>In this way, we denote x x. In the entire design space, a set of designs that are not dominated by any other is called the Pareto-optimal set and they form the Pareto optimality in this space.</p><p>In this paper, our objective is to explore Pareto optimality defined in Definition 4 w.r.t. power and clock cycle for various BOOM microarchitectures. Due to the power and clock cycle are a pair of negatively correlated metrics, a microarchitecture belonged to the Pareto-optimal set cannot improve one metric without sacrificing another metric. To guarantee high quality of results, rather than use coarse-grained simulation infrastructure introduced in Section I, we evaluate power and performance using commercial electronic automation (EDA) tools and they are referred to as the VLSI flow. Based on the above definitions, our problem can be formulated.</p><p>Problem 1 (BOOM Microarchitecture Design Space Exploration). Given a search space D, each microarchitecture design inside D is regarded as a feature vector x. Power and clock cycle form the power-performance space Y. Through VLSI flow, the power and cycles y ? Y can be obtained according to x. BOOM microarchitecture design space exploration is to be defined as to find a series of features X that form the Pareto optimality among the corresponding Y ? Y. Hence, Y = {y|y y, ?y ? Y}, X = {x|f (x) ? Y , ?x ? D}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview of BOOM-Explorer</head><p>Fig. <ref type="figure" target="#fig_5">2</ref> shows an overview of BOOM-Explorer. Firstly, the active learning algorithm MicroAL is adopted to sample a set of initial microarchitectures from the large design space. In this step, domain-specific knowledge is used as the prior information to guide the sampling of the initial designs. Then, a Gaussian process model with deep kernel learning functions (DKL-GP) is built on the initial set. To explore the optimal microarchitecture, the multi-objective Bayesian optimization algorithm is used, with the Expected Improvement of Pareto Hypervolume as the acquisition function, and the DKL-GP model as the surrogate model. During this process, BOOM-Explorer interacts with the VLSI flow to get the accurate performance and power values of designs according to different benchmarks. Finally, The outputs of BOOM-Explorer are the set of explored microarchitectures in the iterative optimization process, and the Pareto optimality is gained from the set. The deep hierarchical generalization of GPs is done in a fully connected, feed-forward manner. The outputs of the previous layer serve as an input to the next. However, a significant difference from neural networks is that the layer outputs are probabilistic rather than exact values so the uncertainty is propagated through the network. The left part of Figure <ref type="figure" target="#fig_0">1</ref> illustrates the concept with a single hidden layer. The input to the hidden layer is the input data x and the output of the hidden layer f1 serves as the input data to the output layer, which itself is formed by GPs.</p><p>Exact inference is infeasible in GPs for large datasets due to the high computational cost of working with the inverse covariance matrix. Instead, the posterior is approximated using a small set of pseudo datapoints (?100) also referred to as inducing points <ref type="bibr">[Snelson and Ghahramani, 2006</ref><ref type="bibr">, Titsias, 2009</ref><ref type="bibr">, Qui?onero-Candela and Rasmussen, 2005]</ref>. We assume this inducing point framework throughout the paper. Predictions are made using the inducing points to avoid computing the covariance matrix of the whole dataset. Both in GPs and DGPs, the inducing outputs are treated as latent variables that need to be marginalized. However, a drawback of DSVI is that it approximates the posterior distribution with a Gaussian. We show, with high confidence, that the posterior distribution is non-Gaussian for every dataset that we examine in this work. This finding motivates the use of inference methods with a more flexible posterior approximations.</p><p>In this work, we apply an inference method new to DGPs, Stochastic Gradient Hamiltonian Monte Carlo (SGHMC), a sampling method that accurately and efficiently captures the posterior distribution. In order to apply a sampling-based inference method to DGPs, we have to tackle the problem of optimizing the large number of hyperparameters. To address this problem, we propose Moving Window Monte Carlo Expectation Maximization, a novel method for obtaining the Maximum Likelihood (ML) estimate of the hyperparameters. This method is fast, efficient and generally applicable to any probabilistic model and MCMC sampler.</p><p>One might expect a sampling method such as SGHMC to be more computationally intensive than a variational method such as DSVI. However, in DGPs, sampling from the posterior is inexpensive, since it does not require the recomputation of the inverse covariance matrix, which only depends on The deep hierarchical generalization of GPs is done in a fully connected, feed-forward manner. The outputs of the previous layer serve as an input to the next. However, a significant difference from neural networks is that the layer outputs are probabilistic rather than exact values so the uncertainty is propagated through the network. The left part of Figure <ref type="figure" target="#fig_0">1</ref> illustrates the concept with a single hidden layer. The input to the hidden layer is the input data x and the output of the hidden layer f1 serves as the input data to the output layer, which itself is formed by GPs.</p><p>Exact inference is infeasible in GPs for large datasets due to the high computational cost of working with the inverse covariance matrix. Instead, the posterior is approximated using a small set of pseudo datapoints (?100) also referred to as inducing points <ref type="bibr">[Snelson and Ghahramani, 2006</ref><ref type="bibr">, Titsias, 2009</ref><ref type="bibr">, Qui?onero-Candela and Rasmussen, 2005]</ref>. We assume this inducing point framework throughout the paper. Predictions are made using the inducing points to avoid computing the covariance matrix of the whole dataset. Both in GPs and DGPs, the inducing outputs are treated as latent variables that need to be marginalized. However, a drawback of DSVI is that it approximates the posterior distribution with a Gaussian. We show, with high confidence, that the posterior distribution is non-Gaussian for every dataset that we examine in this work. This finding motivates the use of inference methods with a more flexible posterior approximations.</p><p>In this work, we apply an inference method new to DGPs, Stochastic Gradient Hamiltonian Monte Carlo (SGHMC), a sampling method that accurately and efficiently captures the posterior distribution. In order to apply a sampling-based inference method to DGPs, we have to tackle the problem of optimizing the large number of hyperparameters. To address this problem, we propose Moving Window Monte Carlo Expectation Maximization, a novel method for obtaining the Maximum Likelihood (ML) estimate of the hyperparameters. This method is fast, efficient and generally applicable to any probabilistic model and MCMC sampler.</p><p>One might expect a sampling method such as SGHMC to be more computationally intensive than a variational method such as DSVI. However, in DGPs, sampling from the posterior is inexpensive, since it does not require the recomputation of the inverse covariance matrix, which only depends on  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Microarchitecture-aware Active Learning Algorithm</head><p>Due to the time-consuming VLSI flow, to save time, only a limited number of designs will be synthesized practically to obtain power and performance. To guarantee that adequate information is covered in the data set, two principles are considered during the initialization. First, feature vectors should cover the entire design space uniformly. Second, their diversity should fully represent the characteristics of the design space. Within a limited time budget, only push the most representative microarchitecture to VLSI flow can we alleviate the burden to get power and performance.</p><p>A naive solution is to sample microarchitectures randomly. In literature, most previous works <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> choose this simple method directly for convenience. In addition, by appraising the importance of each feature vector with suitable distance measurement, greedy sampling <ref type="bibr" target="#b19">[20]</ref> can be facilitated to select representative microarchitecture designs.</p><p>To further improve the sampling, orthogonal design <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b20">[21]</ref> is also utilized to pick up dissimilar microarchitectures that are distributed orthogonally across the design space.</p><p>Algorithm 1 TED(U, ?, b) Require: U is the unsampled microarchitecture design space, ? is a normalization coefficient, and b is the number of samples to draw. Ensure: X: the sampled set with |X| = b.</p><p>1:</p><formula xml:id="formula_1">X ? ?, K uu ? f (u, u ), ?u, u ? U; 2: for i = 1 ? b do 3: x * ? arg max x?U Tr[K Ux (K xx + ?I) -1 K xU ]; K Ux , K xx and K xU are calculated via f w.r.t. corresponding columns in K 4: X ? X ? x * , U ? U \ x * ; 5: K ? K -K Ux * (K x * x * + ?I) -1 K x * U ; 6: end for 7: return The sampled set X;</formula><p>Nevertheless, the aforementioned methodologies are failed to capture the key components of different microarchitectures that bring great impacts to the trade-off in the powerperformance space.</p><p>Recently, witnessing the great performance improvement attained by transductive experimental design (TED) in the design space exploration of high-level synthesis <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, compilation and deployment of deep neural networks <ref type="bibr" target="#b23">[24]</ref>, and etc., we introduce this method into the exploration of microarchitectures for the first time.</p><p>TED tends to choose microarchitecture that can spread across the feature space to retain most of the information among the whole design space <ref type="bibr" target="#b15">[16]</ref>. A pool of representative feature vectors can be acquired with high mutual divergences, by iteratively maximizing the trace of the distance matrix constructed on a newly sampled design and unsampled ones. Algorithm 1 shows the backbone of TED, where f represents the distance function used in computing the distance matrix K. Note that any suitable distance functions can be applied without restrictions.</p><p>Unfortunately, TED cannot fully guarantee to generate a good initial data set owing to a lack of prior knowledge of microarchitecture designs. We are motivated to embed the domain knowledge to improve its performance.</p><p>DecodeWidth as referred to in TABLE I decides the maximal number of instructions to be decoded as corresponding micro-ops simultaneously. In consequence, it can affect the execution bandwidth of EU and LSU (i.e., instructions executed per clock cycle). Assigning a larger candidate value to DecodeWidth and allocating a balanced amount of hardware resources, on the one hand, can lead to greater performance improvement. On the other hand, power dissipation will also increase significantly. By clustering w.r.t. DecodeWidth, the power-performance space can be separated along the potential Pareto optimality, as shown in Fig. <ref type="figure">3</ref>. Each cluster in Fig. <ref type="figure">3</ref> represents a group of microarchitectures with different candidate values for DecodeWidth in the power-performance space. The entire design space is discrete and non-smooth but nonetheless a large number of microarchitectures with the same DecodeWidth achieve similar power-performance Fig. <ref type="figure">3</ref> Clustering w.r.t. DecodeWidth characteristics within their sub-regions respectively. It inspires us that we can select microarchitectures on the possible sub-area from the initial design space, to better cover the entire design space at the same time improve the diversity of samples.</p><p>Inside each cluster, Algorithm 1 can be applied instead of choosing the centroid to enlarge the initial data set. The clustering w.r.t. DecodeWidth, together with TED, forms MicroAL and the pseudo code is detailed in Algorithm 2.</p><p>First, we cluster the entire design space according to ?, which is the distance function with a higher penalty along the dimension of DecodeWidth. One possible alternative can be ?</p><formula xml:id="formula_2">= (x i -c j ) T ?(x i -c j ), with i ? {1, ? ? ? , |U|} and j ? {1, ? ? ? , k},</formula><p>where ? is a pre-defined diagonal weight matrix. Next, we apply TED for each cluster to sample the most representative feature vectors, i.e., line 9 in Algorithm 2. Finally, containing all of the sampled microarchitectures, the initial data set is formed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Gaussian Process with Deep Kernel Learning</head><p>Given the initial data set, it is hard to build a reliable model to fully capture the characteristics of the design space yet.</p><p>However, thanks to robustness and non-parametric approximation features reside in Gaussian process (GP) models, they have been applied in various domains <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>. In view of the success, BOOM-Explorer adopts GP as well.</p><p>Assume that we have feature vectors X = {x 1 , x 2 , ...x n } and they index a set of corresponding power or clock cycles y = {y 1 , y 2 , ..., y n }. GP provides a prior over the value function f as f (x) ? GP(?, k ? ), where ? is the mean value and the kernel function k is parameterized by ?. Then, Gaussian distributions can be constructed with any collection of value functions f according to Equation (2)</p><formula xml:id="formula_3">f = [f (x 1 ), f (x 2 ), ...f (x n )] T ? N(?, K XX|? ), (2)</formula><p>where K XX|? is the intra-covariance matrix among all feature vectors and calculated via</p><formula xml:id="formula_4">K XX|? ij = k ? (x i , x j ). A Gaus- sian noise N(f (x), ? 2 e</formula><p>) is necessary to model uncertainties of power or clock cycles generated by different microarchitecture designs. Thus, given a newly sampled feature vector x * , the predictive joint distribution f * that depends on y can be </p><formula xml:id="formula_5">f * |y ? N( ? ? * , K XX|? + ? 2 e I K Xx * |? K x * X|? k x * x * |? ).<label>(3)</label></formula><p>By maximizing the marginal likelihood of GP, ? is optimized to sense the entire design space. Nevertheless, the performance of GP normally depends on the expressiveness and hyper-parameters of kernel functions k ? , e.g., radial bias functions, and etc. Therefore, a suitable kernel function is necessary to the performance of GP.</p><p>In the recent years, deep neural networks (DNN) have shown great potential in various applications and tasks as the black-box model to extract useful features <ref type="bibr" target="#b26">[27]</ref>- <ref type="bibr" target="#b28">[29]</ref>. Thus, with the help of DNN as a meta-learner for kernel functions, we can relieve workloads in tuning hyper-parameters of kernel functions. By leveraging multi-layer non-linear transformations and weights to calibrate kernel functions with Equation (4) <ref type="bibr" target="#b29">[30]</ref>, deep kernel functions can provide better performance.</p><formula xml:id="formula_6">k ? (x i , x j ) ? k w,? (?(x i , w), ?(x j , w))<label>(4)</label></formula><p>? in Equation ( <ref type="formula" target="#formula_6">4</ref>) denotes non-linear transformation layers stacked by DNN and w denotes weights in DNN. Enhanced with the expressive power of DNN, DKL-GP is constructed and then plugged into Bayesian optimization as the surrogate model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Correlated Multi-Objective Design Exploration</head><p>Notwithstanding DKL-GP can be used to evaluate a single object (i.e., power or clock cycles) well, to find the Paretooptimal set still remains an issue, especially for such negatively correlated objectives.       A traditional methodology usually integrates different acquisition functions to solve it. Lyu et al. <ref type="bibr" target="#b30">[31]</ref> combines Expectation Improvement (EI), Probability Improvement (PI) and Confidence Bound (i.e., UCB and LCB) to form a multiobjective optimization framework in analog circuit design. It still leads to sub-optimal results except that we can select a good composite of acquisition functions for specific problems. To solve the problem more efficiently, we introduce Expected Improvement of Pareto Hypervolume (EIPV) <ref type="bibr" target="#b31">[32]</ref> and demonstrate its usability to characterize the trade-off in the power-performance space of different microarchitecture designs.</p><formula xml:id="formula_7">v 5 B + f C o q Z N M U e b T R C S q H a J m g k v m G 2 4 E a 6 e K Y R w K 1 g p H t z O / 9 c S U 5 o l 8 M O O U B T E O J I 8 4 R W M l H 3 v e o 9 c r V 9 y q O w d Z J V 5 O K p C j 0 S t / d f s J z W I m D R W o d c d z U x N M U B l O B Z u W u p l m K d I R D l j H U o k x 0 8 F k f u y U n F m l T 6 J E 2 Z K G z N X f E x O M t R 7 H o e 2 M 0 Q z 1 s j c T / / M 6 m Y m u g w m X a W a Y p I t F U S a I S c j s c 9 L n i l E j x p Y g V d z e S u g Q F V J j 8 y n Z E L z l l 1 d J s 1 b 1 L q q 1 + 8 t K / S a P o w g n c A r n 4 M E V 1 O E O G u A D B Q 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H D t G O M A = = &lt; / l a t e x i t &gt; a 2 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E C C R / F L F i z o 1 A + M o a s V J 4 4 9 z 0 D E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q 1 e P C j i 1 R / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U p H 3 v s d Y v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z s l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T g Z c I T N i Y g l l i t t b C R t R R Z m x + Z R s C N 7 y y 6 u k V a t 6 F 9 X a / W W l f p P H U Y Q T O I V z 8 O A K 6 n A H D W g C A w 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H E F W O M Q = = &lt; / l a t e x i t &gt; a 3 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P 2 t A l p U K O a d O q D R E w k 8 T f 5 6 n U Z k = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k r 6 L H o x W M F 0 x b a W C b b T b t 0 s w m 7 G 6 G U / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n b X 1 j c 2 t 7 c J O c X d v / + C w d H T c 1 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j 2 5 n f e m J K 8 0 Q + m H H K g h g H k k e c o r G S j z 3 v s d Y r l d 2 K O w d Z J V 5 O y p C j 0 S t 9 d f s J z W I m D R W o d c d z U x N M U B l O B Z s W u 5 l m K d I R D l j H U o k x 0 8 F k f u y U n F u l T 6 J E 2 Z K G z N X f E x O M t R 7 H o e 2 M 0 Q z 1 s j c T / / M 6 m Y m u g w m X a W a Y p I t F U S a I S c j s c 9 L n i l E j x p Y g V d z e S u g Q F V J j 8 y n a E L z l l 1 d J s 1 r x a p X q / W W 5 f p P H U Y B T O I M L 8 O A K 6 n A H D f C B A o d n e I U 3 R z o v z r v z s W h d c / K Z E / g D 5 / M H E d m O M g = = &lt; / l a t e x i t &gt; a 4 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l w O A / y o k R 7 b s q i h Z A J l b 1 N y F 6 d A = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 9 F L x 4</formula><formula xml:id="formula_8">x W M S q E 1 C N g k t s G W 4 E d h K F N A o E P g T j 2 5 n / 8 I R K 8 1 j e m 0 m C f k S H k o e c U W O l p t s v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z o l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T Q Z c I T N i Y g l l i t t b C R t R R Z m x 2 Z R</formula><formula xml:id="formula_9">+ g f H j U M k m m G f d Z I h P d D q n h U i j u o 0 D J 2 6 n m N A 4 l f w h H N z P / 4 Y l r I x J 1 j + O U B z E d K B E J R t F K P u 3 V H u u 9 c s W t u n O Q V e L l p A I 5 m r 3 y V 7 e f s C z m C p m k x n Q 8 N 8 V g Q j U K J v m 0 1 M 0 M T y k b 0 Q H v W K p o z E 0 w m R 8 7 J W d W 6 Z M o 0 b Y U k r n 6 e 2 J C Y 2 P G c W g 7 Y 4 p D s + z N x P + 8 T o b R V T A R K s 2 Q K 7 Z Y F G W S Y E J m n 5 O + 0 J y h H F t C m R b 2 V s K G V F O G N p + S D c F b f n m V t G p V 7 6 J a u 6 t X G t d 5 H E U 4 g V M 4 B w 8 u o Q G 3 0 A Q f G A h 4 h l d 4 c 5 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / F O O O N A = = &lt; / l a t e x i t &gt; a 3 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q x + r J c m O O n t w u U E o w f O G m e F 4 u Q 0 = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k r 6 L H o x W M F 0 x b a W C b b T b t 0 s w m 7 G 6 G U / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n b X 1 j c 2 t 7 c J O c X d v / + C w d H T c 1 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j 2 5 n f e m J K 8 0 Q + m H H K g h g H k k e c o r G S j 7 3 q Y 6 1 X K r s V d w 6 y S r y c l C F H o 1 f 6 6 v Y T m s V M G i p Q 6 4 7 n p i a Y o D K c C j Y t d j P N U q Q j H L C O p R J j p o P J / N g p O b d K n 0 S J s i U N m a u / J y Y Y a z 2 O Q 9 s Z o x n q Z W 8 m / u d 1 M h N d B x M u 0 8 w w S R e L o k w Q k 5 D Z 5 6 T P F a N G j C 1 B q r i 9 l d A h K q T G 5 l O 0 I X j L L 6 + S Z r X i 1 S r V + 8 t y / S a P o w C n c A Y X 4 M E V 1 O E O G u A D B Q 7 P 8 A p v j n R e n H f n Y 9 G 6 5 u Q z J / A H z u c P E 1 + O M w = = &lt; / l a t e x i t &gt; a 2 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q U M z 1 a 4 N 8 2 w E x P m e V m G o f A m 2 j v I = " &gt; A A A B 7 H i c b V B N S 8 N A E J 2 t X 7 V + V T 1 6 W S y C p 5 J E Q Y 9 F L x 4 r m L b Q x r L Z b t q l m 0 3 Y 3 Q g l 9 D d 4 8 a C I V 3 + Q N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Y S q 4 N o 7 z j U p r 6 x u b W + X t y s 7 u 3 v 5 B 9 f C o p Z N M U e b T R C S q E x L N B J f M N 9 w I 1 k k V I 3 E o W D s c 3 8 7 8 9 h N T m i f y w U x S F s R k K H n E K T F W 8 k n f e / T 6 1 Z p T d + b A q 8 Q t S A 0 K N P v V r 9 4 g o V n M p K G C a N 1 1 n d Q E O V G G U 8 G m l V 6 m W U r o m A x Z 1 1 J J Y q a D f H 7 s F J 9 Z Z Y C j R N m S B s / V 3 x M 5 i b W e x K H t j I k Z 6 W V v J v 7 n d T M T X Q c 5 l 2 l m m K S L R V E m s E n w 7 H M 8 4 I p R I y a W E K q 4 v R X T E V G E G p t P x Y b g L r + 8 S l p e 3 b 2 o e / e X t c Z N E U c Z T u A U z s G F K 2 j A H T T B B w o c n u E V 3 p B E L + g d f S x a S 6 i Y O Y Y / Q J 8 / E d u O M g = = &lt; / l a t e x i t &gt; a 1 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a y 7 4 p w O e 3 G 9 u T h D G H q K 9 c 8 W d X Z k = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q 1 e P C j i 1 R / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U p P 3 a o 9 c v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z s l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T g Z c I T N i Y g l l i t t b C R t R R Z m x + Z R s C N 7 y y 6 u k V a t 6 F 9 X a / W W l f p P H U Y Q T O I V z 8 O A K 6 n A H D W g C A w 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H E F e O M Q = = &lt; / l a t e x i t &gt; v ref &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W M 4 j X J 0 N F d n U r N h 3 6 q p d 6 P o v E W 8 = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 o W y 2 k 3 b p Z h N 2 N 4 U S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s s n M 0 3 Q j + h Q 8 p A z a q z U n v Q z h e G s X 6 6 4 V X c B s k 6 8 n F Q g R 6 N f / u o N Y p Z G K A 0 T V O u u 5 y b G z 6 g y n A m c l X q p x o S y M R 1 i 1 1 J J I 9 R + t j h 3 R i 6 s M i B h r G x J Q x b q 7 4 m M R l p P o 8 B 2 R t S M 9 K o 3 F / / z u q k J b / 2 M y y Q 1 K N l y U Z g K Y m I y / 5 0 M u E J m x N Q S y h S 3 t x I 2 o o o y Y x M q 2 R C 8 1 Z f X S a t W 9 a 6 q t c f r S v 0 u j 6 M I Z 3 A O l + D B D d T h A R r Q B A Z j e I Z X</formula><formula xml:id="formula_10">v 5 B + f C o q Z N M U e b T R C S q H a J m g k v m G 2 4 E a 6 e K Y R w K 1 g p H t z O / 9 c S U 5 o l 8 M O O U B T E O J I 8 4 R W M l H 3 v e o 9 c r V 9 y q O w d Z J V 5 O K p C j 0 S t / d f s J z W I m D R W o d c d z U x N M U B l O B Z u W u p l m K d I R D l j H U o k x 0 8 F k f u y U n F m l T 6 J E 2 Z K G z N X f E x O M t R 7 H o e 2 M 0 Q z 1 s j c T / / M 6 m Y m u g w m X a W a Y p I t F U S a I S c j s c 9 L n i l E j x p Y g V d z e S u g Q F V J j 8 y n Z E L z l l 1 d J s 1 b 1 L q q 1 + 8 t K / S a P o w g n c A r n 4 M E V 1 O E O G u A D B Q 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H D t G O M A = = &lt; / l a t e x i t &gt; a 2 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E C C R / F L F i z o 1 A + M o a s V J 4 4 9 z 0 D E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q 1 e P C j i 1 R / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U p H 3 v s d Y v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z s l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T g Z c I T N i Y g l l i t t b C R t R R Z m x + Z R s C N 7 y y 6 u k V a t 6 F 9 X a / W W l f p P H U Y Q T O I V z 8 O A K 6 n A H D W g C A w 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H E F W O M Q = = &lt; / l a t e x i t &gt; a 3 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P 2 t A l p U K O a d O q D R E w k 8 T f 5 6 n U Z k = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k r 6 L H o x W M F 0 x b a W C b b T b t 0 s w m 7 G 6 G U / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n b X 1 j c 2 t 7 c J O c X d v / + C w d H T c 1 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j 2 5 n f e m J K 8 0 Q + m H H K g h g H k k e c o r G S j z 3 v s d Y r l d 2 K O w d Z J V 5 O y p C j 0 S t 9 d f s J z W I m D R W o d c d z U x N M U B l O B Z s W u 5 l m K d I R D l j H U o k x 0 8 F k f u y U n F u l T 6 J E 2 Z K G z N X f E x O M t R 7 H o e 2 M 0 Q z 1 s j c T / / M 6 m Y m u g w m X a W a Y p I t F U S a I S c j s c 9 L n i l E j x p Y g V d z e S u g Q F V J j 8 y n a E L z l l 1 d J s 1 r x a p X q / W W 5 f p P H U Y B T O I M L 8 O A K 6 n A H D f C B A o d n e I U 3 R z o v z r v z s W h d c / K Z E / g D 5 / M H E d m O M g = = &lt; / l a t e x i t &gt; a 4 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l w O A / y o k R 7 b s q i h Z A J l b 1 N y F 6 d A = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 9 F L x 4 r 2 F p o Y 9 l s J + 3 S z S b s b o Q S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y x W M S q E 1 C N g k t s G W 4 E d h K F N A o E P g T j m 5 n / 8 I R K 8 1 j e m 0 m C f k S H k o e c U W O l F u 1 7 j / V + u e J W 3 T n I K v F y U o E c z X 7 5 q z e I W R q h N E x Q r b u e m x g / o 8 p w J n B a 6 q U a E 8 r G d I h d S y W N U P v Z / N g p O b P K g I S x s i U N m a u / J z I a a T 2 J A t s Z U T P S y 9 5 M / M / r p i a 8 8 j M u k 9 S g Z I t F Y S q I i c n s c z L g C p k R E 0 s o U 9 z e S t i I K s q M z a d k Q / C W X 1 4 l 7 V r V u 6 j W 7 u q V x n U e R x F O 4 B T O w Y N L a M A t N K E F D D g 8 w y u 8 O d J 5 c d 6 d j 0 V r w c l n j u E P n M 8 f E 1 2 O M w = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r s P G D o 3 8 d C U r L s A t / f t n o s r C h U A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 t 2 F p o Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y x W M S q E 1 C N g k t s G W 4 E d h K F N A o E P g T j 2 5 n / 8 I R K 8 1 j e m 0 m C f k S H k o e c U W O l p t s v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z o l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T Q Z c I T N i Y g l l i t t b C R t R R Z m x 2 Z R s C N 7 y y 6 u k X a t 6 F 9 V a 8 7 J S v 8 n j K M I J n M I 5 e H A F d b i D B r S A A c I z v M K b 8 + i 8 O O / O x 6 K 1 4 O Q z x / A H z u c P e m e M u A = = &lt; / l a t e x i t &gt; a 4 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S o F 1 t j k F V h M h 4 E n p k g / 4 T e M B r o c = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 9 F L x 4 r m F p o Y 9 l s N + 3 S z S b s T o R S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M J X C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U M k m m G f d Z I h P d D q n h U i j u o 0 D J 2 6 n m N A 4 l f w h H N z P / 4 Y l r I x J 1 j + O U B z E d K B E J R t F K P u 3 V H u u 9 c s W t u n O Q V e L l p A I 5 m r 3 y V 7 e f s C z m C p m k x n Q 8 N 8 V g Q j U K J v m 0 1 M 0 M T y k b 0 Q H v W K p o z E 0 w m R 8 7 J W d W 6 Z M o 0 b Y U k r n 6 e 2 J C Y 2 P G c W g 7 Y 4 p D s + z N x P + 8 T o b R V T A R K s 2 Q K 7 Z Y F G W S Y E J m n 5 O + 0 J y h H F t C m R b 2 V s K G V F O G N p + S D c F b f n m V t G p V 7 6 J a u 6 t X G t d 5 H E U 4 g V M 4 B w 8 u o Q G 3 0 A Q f G A h 4 h l d 4 c 5 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / F O O O N A = = &lt; / l a t e x i t &gt; a 3 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q x + r J c m O O n t w u U E o w f O G m e F 4 u Q 0 = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k r 6 L H o x W M F 0 x b a W C b b T b t 0 s w m 7 G 6 G U / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n b X 1 j c 2 t 7 c J O c X d v / + C w d H T c 1 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j 2 5 n f e m J K 8 0 Q + m H H K g h g H k k e c o r G S j 7 3 q Y 6 1 X K r s V d w 6 y S r y c l C F H o 1 f 6 6 v Y T m s V M G i p Q 6 4 7 n p i a Y o D K c C j Y t d j P N U q Q j H L C O p R J j p o P J / N g p O b d K n 0 S J s i U N m a u / J y Y Y a z 2 O Q 9 s Z o x n q Z W 8 m / u d 1 M h N d B x M u 0 8 w w S R e L o k w Q k 5 D Z 5 6 T P F a N G j C 1 B q r i 9 l d A h K q T G 5 l O 0 I X j L L 6 + S Z r X i 1 S r V + 8 t y / S a P o w C n c A Y X 4 M E V 1 O E O G u A D B Q 7 P 8 A p v j n R e n H f n Y 9 G 6 5 u Q z J / A H z u c P E 1 + O M w = = &lt; / l a t e x i t &gt; a 2 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q U M z 1 a 4 N 8 2 w E x P m e V m G o f A m 2 j v I = " &gt; A A A B 7 H i c b V B N S 8 N A E J 2 t X 7 V + V T 1 6 W S y C p 5 J E Q Y 9 F L x 4 r m L b Q x r L Z b t q l m 0 3 Y 3 Q g l 9 D d 4 8 a C I V 3 + Q N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Y S q 4 N o 7 z j U p r 6 x u b W + X t y s 7 u 3 v 5 B 9 f C o p Z N M U e b T R C S q E x L N B J f M N 9 w I 1 k k V I 3 E o W D s c 3 8 7 8 9 h N T m i f y w U x S F s R k K H n E K T F W 8 k n f e / T 6 1 Z p T d + b A q 8 Q t S A 0 K N P v V r 9 4 g o V n M p K G C a N 1 1 n d Q E O V G G U 8 G m l V 6 m W U r o m A x Z 1 1 J J Y q a D f H 7 s F J 9 Z Z Y C j R N m S B s / V 3 x M 5 i b W e x K H t j I k Z 6 W V v J v 7 n d T M T X Q c 5 l 2 l m m K S L R V E m s E n w 7 H M 8 4 I p R I y a W E K q 4 v R X T E V G E G p t P x</formula><formula xml:id="formula_11">+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U p P 3 a o 9 c v V 9 y q O w d Z J V 5 O K p C j 0 S 9 / 9 Q Y x S y O U h g m q d d d z E + N n V B n O B E 5 L v V R j Q t m Y D r F r q a Q R a j + b H z s l Z 1 Y Z k D B W t q Q h c / X 3 R E Y j r S d R Y D s j a k Z 6 2 Z u J / 3 n d 1 I T X f s Z l k h q U b L E o T A U x M Z l 9 T g Z c I T N i Y g l l i t t b C R t R R Z m x + Z R s C N 7 y y 6 u k V a t 6 F 9 X a / W W l f p P H U Y Q T O I V z 8 O A K 6 n A H D W g C A</formula><formula xml:id="formula_12">M S q E 1 C N g k t s G m 4 E d h K F N A o E t o P x / d x v T 1 B p H s s n M 0 3 Q j + h Q 8 p A z a q z U n v Q z h e G s X 6 6 4 V X c B s k 6 8 n F Q g R 6 N f / u o N Y p Z G K A 0 T V O u u 5 y b G z 6 g y n A m c l X q p x o S y M R 1 i 1 1 J J I 9 R + t j h 3 R i 6 s M i B h r G x J Q x b q 7 4 m M R l p P o 8 B 2 R t S M 9 K o 3 F / / z u q k J b / 2 M y y Q 1 K N l y U Z g K Y m I y / 5 0 M u E J m x N Q S y h S 3 t x I 2 o o o y Y x M q 2 R C 8 1 Z f X S a t W 9 a 6 q t c f r S v 0 u j 6 M I Z 3 A O l + D B D d T h A R r Q B A Z j e I Z X</formula><p>In our problem, a better microarchitecture can not only run faster (i.e., it gets fewer average clock cycles among all benchmarks) but also dissipate less power. Given a reference point v ref ? Y, Pareto hypervolume bounded above from v ref is the Lebesgue measure of the space dominated by the Pareto optimality as shown in Fig. <ref type="figure" target="#fig_10">4</ref>(a) <ref type="bibr" target="#b32">[33]</ref>. The shaded area in orange, indicating Pareto hypervolume w.r.t. the current Pareto-optimal set P(Y) is calculated by Equation ( <ref type="formula" target="#formula_13">5</ref>)</p><formula xml:id="formula_13">PVol vref (P(Y)) = Y 1[y v ref ][1 - y * ?P(Y) 1[y * y]]dy,<label>(5)</label></formula><p>where 1(?) is the indicator function, which outputs 1 if its argument is true and 0 otherwise. v ref is carefully chosen for convenience of calculation. Ideally, a feature vector x that can increase the likelihood of DKL-GP maximally should be picked up from the design space D in every iteration. Thus, a better predictive Pareto-optimal set, enveloping the previous one by improving PVol vref (P(Y)) is the direct solution according to Equation <ref type="bibr" target="#b5">(6)</ref> where f : x ? y ? Y is denoted as DKL-GP. Then the feature vector x * = arg max  L ? L ? x * , U ? U \ x * ; 10: end for 11: Construct Pareto-optimal set X from L; 12: return Pareto-optimal set X;</p><formula xml:id="formula_14">EIPV(x |D) = E p(f (x )|D) [PVol vref (P(Y) ? f (x )) -PVol vref (P(Y))].<label>(6)</label></formula><p>By decomposing the power-performance space as grid cells shown in Fig. <ref type="figure" target="#fig_10">4</ref>, Equation ( <ref type="formula" target="#formula_14">6</ref>) can be further simplified as Equation ( <ref type="formula" target="#formula_15">7</ref>)</p><formula xml:id="formula_15">EIPV(x |D) = C?Cnd C PVol v C (y)p(y, |D)dy,<label>(7)</label></formula><p>where C nd denotes non-dominated cells. Region colored in green as referred to Fig. <ref type="figure" target="#fig_10">4</ref>(b) shows the improvement of Pareto hypervolume. In Equation <ref type="bibr" target="#b6">(7)</ref>, p(y|D) is modeled as a multi-objective GP for power and clock cycles where the kernel function in Equation (4) parameterized by DNN can be Mat?rn 5/2 kernel. Equipped with all aforementioned methodologies, Algorithm 3 provides the end-to-end flow of BOOM-Explorer. We first leverage Algorithm 2 to sample representative microarchitectures (e.g., different branch prediction capability, cache organization, various structures of issue unit, etc.). DKL-GP is then built to characterize the design space. Finally, with Bayesian optimization, the Pareto-optimal set is explored via the maximization of EIPV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>We conduct comprehensive experiments to evaluate the proposed BOOM-Explorer. Chipyard framework <ref type="bibr" target="#b33">[34]</ref> is leveraged to compile various BOOM RTL designs. We utilize 7-nm ASAP7 PDK <ref type="bibr" target="#b34">[35]</ref> for the VLSI flow. Cadence Genus 18.12-e012 1 is used to synthesize every sampled RTL design, and Synopsys VCS M-2017.03 is used to simulate the design running at 2GHz with different benchmarks. PrimeTime PX R-2020.09-SP1 is finally used to get power value for all benchmarks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmarks and Baselines</head><p>Since it is time-consuming to verify every sampled microarchitecture design online, we construct an offline data set. Consisting of 994 legal microarchitectures, the offline data set is sampled randomly and uniformly from the BOOM design space as referred to in TABLE I. Each design is fed to the VLSI flow to get power and clock cycles with high fidelity for all benchmarks and the corresponding time to conduct the flow is also recorded. The VLSI flow for each design takes approximately from 6 hours to more than 14 hours to finish. All of experiments are conducted on this data set. Several benchmarks are selected to test the performance of microarchitectures, i.e., median, mt-vvadd, whetstone, and mm from commonly used CPU benchmark suites. These four benchmarks are complete to all RISC-V instructions, e.g., instructions that transfer data between registers and memory, floating-point manipulations, multi-threading executions, vector instructions, etc. The average clock cycles and power on the four benchmarks are denoted as the performance and power value for each design respectively.</p><p>Several representative baselines are compared with BOOM-Explorer. The ANN-based method <ref type="bibr" target="#b17">[18]</ref> (shorted as ASP-LOS'06), stacks ANN to predict the performance of designs, including a complicated chip multiprocessor. The regressionbased method <ref type="bibr" target="#b18">[19]</ref> (termed HPCA'07), leverages regression models with non-linear transformations to explore the powerperformance Pareto curve on POWER4/POWER5 designs. The AdaBoost-RT-based method <ref type="bibr" target="#b5">[6]</ref> (abbreviated as DAC'16), utilizes OA sampling and active learning-based AdaBoost regression tree models to explore microarchitectures w.r.t. their performance. The aforementioned arts are proved effective in their works of the exploration of microarchitectures respectively. Therefore, it is requisite to compare these methodologies with BOOM-Explorer. The HLS predictive modelbased method <ref type="bibr" target="#b35">[36]</ref> (named DAC <ref type="bibr">'19)</ref>, exploring the high-level synthesis design is also chosen as our baseline. Although the starting point is different, their method is proved to be robust and transferable. Moreover, we also compare BOOM-Explorer with traditional machine learning models, i.e., support vector regression (SVR), random forest, and XGBoost <ref type="bibr" target="#b36">[37]</ref>. For fair comparisons, experimental settings of the baselines are the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments Settings</head><p>In the settings of BOOM-Explorer, DKL-GP is stacked with three hidden layers, each of which has 1000, 500, and 50 hidden neurons respectively, and it adopts ReLU as the non-linear transformation for deep kernel learning. The Adam optimizer <ref type="bibr" target="#b37">[38]</ref> is used, with an initial learning rate equals to 0.001. DKL-GP is initialized with 5 microarchitectures sampled according to MicroAL and then BOOM-Explorer performs Bayesian exploration with 9 rounds sequentially. All experiments together with baselines are repeated 10 times and we report corresponding average results.</p><p>Average distance to reference set (ADRS) and overall running time (ORT) are two metrics for performance comparisons. ADRS, as shown in Equation ( <ref type="formula" target="#formula_16">8</ref>), is widely used in design space exploration problems to measure how close a learned Pareto-optimal set to the real Pareto-optimal set of the design space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ADRS(?,</head><formula xml:id="formula_16">?) = 1 |?| ??? min ??? f (?, ?), (<label>8</label></formula><formula xml:id="formula_17">)</formula><p>where f is the Euclidean distance function. ? is the real Pareto-optimal set and ? is the learned Pareto-optimal set. ORT measures the total time of algorithms including initialization and exploring.</p><p>C. Results Analysis Fig. <ref type="figure" target="#fig_17">5</ref> shows the learned Pareto-optimal sets obtained by the baselines and BOOM-Explorer. The results show that the Pareto-optimal set learned by BOOM-Explorer is much closer to the real Pareto-optimal set and thus outperforming baselines remarkably.</p><p>The normalized results of ADRS and ORT are listed in TABLE III. BOOM-Explorer outperforms ASPLOS'06, HPCA'07, DAC'16, and DAC'19 by 70%, 66%, 29%, and 64% in ADRS, respectively. Meanwhile, it accelerates the exploring by more than 88% compared with DAC'16. Since the prior knowledge of BOOM microarchitecture designs is embedded in our method, DKL-GP can outperform baselines by a large margin in ADRS and ORT. The effectiveness of the proposed MicroAL is demonstrated by conducting comparative experiments of BOOM-Explorer with random sampling instead of MicroAL. The corresponding results are  If a larger initialization set is sampled via MicroAL, BOOM-Explorer will be able to gain a better predictive Pareto-optimal set. Finally, we can achieve different designs to strike good balances between power and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. The Optimal BOOM Microarchitecture Design</head><p>Our Pareto design is chosen from the Pareto-optimal set found by BOOM-Explorer and it is compared with a twowide BOOM developed by senior engineers <ref type="bibr" target="#b0">[1]</ref>.</p><p>The aforementioned two microarchitectures of BOOM are listed in TABLE IV. Indicated by "Design Parameters" in TABLE IV, our Pareto design has the same DecodeWidth compared with the two-wide BOOM. However, the Pareto design reduces hardware components on the branch predictor (i.e., RasEntry, BranchCount, etc.), entries of the reorder buffer, etc., but enlarges instructions issue width, LDQ, STQ, etc. Moreover, it has different cache organizations, e.g., different associate sets. Because LSU introduced in Section II-A tends to become a bottleneck, the Pareto design increases hardware resources for LDQ, STQ, and meanwhile increases associate sets and MSHR entries for D-Cache to overcome more data conflicts. Furthermore, the Pareto design reduces resources of RAS and BTB since there are not many branches or jump instructions in these benchmarks. Via reducing redundant hardware resources while increasing necessary compo-nents, our Pareto design achieves a better trade-off on power and performance.</p><p>To demonstrate the superiority of the Pareto design compared with the two-wide BOOM, both of them are evaluated on more benchmarks, and TABLE IV shows the average power and clock cycles of all these benchmarks. These benchmarks are chosen from different application scenarios, e.g., add-int, add-fp, etc. are from ISA basic instructions, iir, firdim, etc. are from DSP-oriented algorithms <ref type="bibr" target="#b38">[39]</ref>, compress, duff, etc. are from real-time computing applications <ref type="bibr" target="#b39">[40]</ref>, etc. Fig. <ref type="figure" target="#fig_18">6</ref> shows the comparison of power and performance between them. For all of these benchmarks, our Pareto design runs approximately 2.11% faster and at the same time dissipates 3.45% less power than the two-wide BOOM.</p><p>V. CONCLUSIONS In this paper, BOOM-Explorer is proposed to search for Pareto optimality among the microarchitecture design space within a short time. To the best of our knowledge, this is the first work introducing automatic design space exploration solution to the RISC-V community. We expect to see a lot of researches in our community to further improve microarchitecture design space explorations of processors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (Left): Deep Gaussian Process illustration 1 . (Middle): Histograms of a random selection of inducing outputs. The best-fit Gaussian distribution is denoted with a dashed line. Some of them exhibit a clear multimodal behaviour. (Right): P-values for 100 randomly selected inducing outputs per dataset. The null hypotheses are that their distributions are Gaussian. resulting in a Bayesian 'self-tuning' covariance function that fits the data without any human input [Damianou, 2015].</figDesc><graphic url="image-4.png" coords="4,120.13,328.21,54.06,70.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The current state-of-the-art inference method in DGPs is Doubly Stochastic Variation Inference (DSVI)[Salimbeni and Deisenroth, 2017]  which has been shown to outperform Expectation Propagation [Minka, 2001, Bui et al., 2016] and it also has better performance than Bayesian Neural Networks with Probabilistic Backpropagation [Hern?ndez-Lobato and Adams, 2015] and Bayesian Neural Networks with earlier inference methods such as Variation Inference [Graves, 2011], Stochastic Gradient Langevin Dynamics [Welling and Teh, 2011] and Hybrid Monte Carlo [Neal, 1993].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 2 Figure 1 :</head><label>21</label><figDesc>Figure 1: (Left): Deep Gaussian Process illustration 1 . (Middle): Histograms of a random selection of inducing outputs. The best-fit Gaussian distribution is denoted with a dashed line. Some of them exhibit a clear multimodal behaviour. (Right): P-values for 100 randomly selected inducing outputs per dataset. The null hypotheses are that their distributions are Gaussian. resulting in a Bayesian 'self-tuning' covariance function that fits the data without any human input [Damianou, 2015].</figDesc><graphic url="image-6.png" coords="4,134.82,354.23,52.42,66.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>The current state-of-the-art inference method in DGPs is Doubly Stochastic Variation Inference (DSVI)[Salimbeni and Deisenroth, 2017]  which has been shown to outperform Expectation Propagation [Minka, 2001, Bui et al., 2016] and it also has better performance than Bayesian Neural Networks with Probabilistic Backpropagation [Hern?ndez-Lobato and Adams, 2015] and Bayesian Neural Networks with earlier inference methods such as Variation Inference [Graves, 2011], Stochastic Gradient Langevin Dynamics [Welling and Teh, 2011] and Hybrid Monte Carlo [Neal, 1993].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Overview of the proposed BOOM-Explorer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm 2 ,</head><label>2</label><figDesc>MicroAL(U, ?, b) Require: U is the unsampled microarchitecture design space, ? is a normalization coefficient, b is the number of samples that to draw. Ensure: X: the sampled set with |X| = b. 1: X ? ?; 2: initialize k clusters randomly with the centroids set C = {c 1 , c 2 , ..., c k } from U; 3: while not converged do 4: c i = arg min j?{1,2,...,k} ? (x ic j ), ?x i ? U; ?j ? {1, 2, ..., k}; 6: end while 7: C ? neighborhood of c i ? C, ?i ? {1, 2, ..., k}; 8: for K in C do 9: X = TED(K, ?, b k ); Algorithm 1 10:X = X ? X; 11: end for 12: return The sampled set X; calculated according to Equation<ref type="bibr" target="#b2">(3)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " j 3 B K J 8 8 o 8 A c A k 5 r m S J / y P n 5 e x x E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V T F t o Y 5 l s N + 3 S z S b s b o R S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M B V c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>r 2 F</head><label>2</label><figDesc>p o Y 9 l s J + 3 S z S b s b o Q S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y x W M S q E 1 C N g k t s G W 4 E d h K F N A o E P g T j m 5 n / 8 I R K 8 1 j e m 0 m C f k S H k o e c U W O l F u 1 7 j / V + u e J W 3 T n I K v F y U o E c z X 7 5 q z e I W R q h N E x Q r b u e m x g / o 8 p w J n B a 6 q U a E 8 r G d I h d S y W N U P v Z / N g p O b P K g I S x s i U N m a u / J z I a a T 2 J A t s Z U T P S y 9 5 M / M / r p i a 8 8 j M u k 9 S g Z I t F Y S q I i c n s c z L g C p k R E 0 s o U 9 z e S t i I K s q M z a d k Q / C W X 1 4 l 7 V r V u 6 j W 7 u q V x n U e R x F O 4 B T O w Y N L a M A t N K E F D D g 8 w y u 8 O d J 5 c d 6 d j 0 V r w c l n j u E P n M 8 f E 1 2 O M w = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r s P G D o 3 8 d C U r L s A t / f t n o s r C h U A = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 t 2 F p o Q 9 l s J + 3 a z S b s b o Q S + g u 8 e F D E q z / J m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o r e N U M W y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>4 2&lt;</head><label>4</label><figDesc>s C N 7 y y 6 u k X a t 6 F 9 V a 8 7 J S v 8 n j K M I J n M I 5 e H A F d b i D B r S A A c I z v M K b 8 + i 8 O O / O x 6 K 1 4 O Q z x / A H z u c P e m e M u A = = &lt; / l a t e x i t &gt; a l a t e x i t s h a 1 _ b a s e 6 4 = " S o F 1 t j k F V h M h 4 E n p k g / 4 T e M B r o c = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l q Q Y 9 F L x 4 r m F p o Y 9 l s N + 3 S z S b s T o R S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M J X C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>e H M S 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w C z o Y / O &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " j 3 B K J 8 8 o 8 A c A k 5 r m S J / y P n 5 e x x E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V T F t o Y 5 l s N + 3 S z S b s b o R S + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M B V c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>1 2&lt;</head><label>1</label><figDesc>Y b g L r + 8 S l p e 3 b 2 o e / e X t c Z NE U c Z T u A U z s G F K 2 j A H T T B B w o c n u E V 3 p B E L + g d f S x a S 6 i Y O Y Y / Q J 8 / E d u O M g = = &lt; / l a t e x i t &gt;a l a t e x i t s h a 1 _ b a s e 6 4 = " a y 7 4 p w O e 3 G 9 u T h D G H q K 9 c 8 W d X Z k = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q 1 e P C j i 1 R / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>w 7 P 8 A p v j n R e n H f n Y 9 F a c P K Z Y / g D 5 / M H E F e O M Q = = &lt; / l a t e x i t &gt; v ref &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W M 4 j X J 0 N F d n U r N h 3 6 q p d 6 P o v E W 8 = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 A e 0 o W y 2 k 3 b p Z h N 2 N 4 U S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p e N U M W y y W</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 An example of Pareto hypervolume is shown in the power-performance space. (a) The region covered in orange is dominated by the currently explored Pareto-optimal set denoted as circles in blue. Circles in red denote dominated microarchitecture designs. (b) The circle in green denotes an explored potential candidates of the Pareto-optimal set among the entire design space. EIPV is represented as the area of sub-region colored in light green.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>x ?D EIPV(x |D) can be sampled as a new candidate for the predictive Pareto optimality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Algorithm 3 BOOM 6 :</head><label>36</label><figDesc>Explorer(D, T, ?, b) Require: D is the microarchitecture design space, T is the maximal iteration number, ? is a normalization coefficient and b is the number of samples to draw. Ensure: Pareto-optimal set X that forms Pareto optimality among D. 1: X 0 ? MicroAL(D, ?, b); Algorithm 2 2: Push X 0 to VLSI flow to obtan corresonding power and clock cycles Y ; 3: L ? X 0 ; 4: U ? D \ L; 5: for i = 1 ? T do Establish and train DKL-GP on L with Y ; Push x * to VLSI flow to obtain corresponding power and clock cycles and add to Y ; 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Learned Pareto optimal set of BOOM microarchitectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 6</head><label>6</label><figDesc>Fig.6Comparisons of power and performance between the Pareto design found by BOOM-Explorer and the two-wide BOOM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>Each row of TABLE I defines structures of a component inside</figDesc><table><row><cell></cell><cell cols="2">I-Cache</cell><cell></cell><cell>I-TLB BP</cell><cell>BTB RAS</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Fetch Buffer</cell></row><row><cell></cell><cell>Decoder</cell><cell cols="2">Decoder</cell><cell>??</cell><cell>Decoder</cell></row><row><cell></cell><cell>Rename Logic</cell><cell></cell><cell cols="2">Allocate Logic</cell><cell>Retire Logic</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Re-Order Buffer</cell></row><row><cell></cell><cell>FP</cell><cell cols="2">INT</cell><cell>MEM</cell><cell>INT RF</cell></row><row><cell>L2</cell><cell>Issue Queue</cell><cell cols="2">Issue Queue</cell><cell>Issue Queue</cell><cell>FP RF</cell></row><row><cell>Cache</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">FPDiv</cell><cell></cell><cell>iMul</cell><cell>ALU</cell></row><row><cell></cell><cell>MemCalc</cell><cell>FPInt</cell><cell></cell><cell>iDiv</cell><cell>CSRs</cell><cell>ALU</cell></row><row><cell></cell><cell></cell><cell>FMA</cell><cell></cell><cell>ALU</cell><cell>RoCC</cell></row><row><cell></cell><cell>STQ</cell><cell></cell><cell></cell><cell></cell><cell>LDQ</cell></row><row><cell></cell><cell>MSHR</cell><cell></cell><cell></cell><cell>D-Cache</cell><cell>D-TLB</cell></row><row><cell></cell><cell cols="2">FrontEnd</cell><cell>IDU</cell><cell>EU</cell><cell>LSU</cell></row></table><note><p>Fig. 1 BOOM implements a ten-stage pipeline, i.e., Fetch, Decode, Register Rename, Dispatch, Issue, Register Read, Execute, Memory, Writeback and Commit.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>TABLE II, the size of the legal microarchitecture design space is approximately 1.6 ? 10 8 .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I Microarchitecture</head><label>I</label><figDesc>Design Space of BOOM</figDesc><table><row><cell>Module</cell><cell>Component</cell><cell>Descriptions</cell><cell>Candidate values</cell></row><row><cell>FrontEnd</cell><cell>FetchWidth FetchBufferEntry RasEntry BranchCount ICacheWay ICacheTLB ICacheFetchBytes</cell><cell>Number of instructions the fetch unit can retrieve once Entries of the fetch buffer register Entries of the Return Address Stack (RAS) Entries of the Branch Target Buffer (BTB) Associate sets of L1 I-Cache Entries of Table Look-aside Buffer (TLB) in L1 I-Cache Unit of line capacity that L1 I-Cache supports</cell><cell>4, 8 8, 16, 24, 32, 35, 40 16, 24, 32 8, 12, 16, 20 2, 4, 8 8, 16, 32 2, 4</cell></row><row><cell>IDU</cell><cell>DecodeWidth RobEntry IntPhyRegister FpPhyRegister</cell><cell>Number of instructions the decoding unit can decode once Entries of the reorder buffer Number of physical integer registers Number of physical floating-point registers</cell><cell>1, 2, 3, 4, 5 32, 64, 96, 128, 130 48, 64, 80, 96, 112 48, 64, 80, 96, 112</cell></row><row><cell>EU</cell><cell>MemIssueWidth IntIssueWidth FpIssueWidth</cell><cell>Number of memory-related instructions that can issue once Number of integer-related instructions that can issue once Number of floating-point-related instructions that can issue once</cell><cell>1, 2 1, 2, 3, 4, 5 1, 2</cell></row><row><cell>LSU</cell><cell>LDQEntry STQEntry DCacheWay DCacheMSHR DCacheTLB</cell><cell>Entries of the Loading Queue (LDQ) Entries of the Store Queue (STQ) Associate sets of L1 D-Cache Entries of Miss Status Handling Register (MSHR) Entries of Table Look-aside Buffer (TLB) in L1 D-Cache</cell><cell>8, 16, 24, 32 8, 16, 24, 32 2, 4, 8 2, 4, 8 8, 16, 32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell cols="2">Constraints of BOOM design specifications</cell></row><row><cell>Rule</cell><cell>Descriptions</cell></row><row><cell>1 2 3 4 5 6 7 8</cell><cell>FetchWdith ? DecodeWidth RobEntry | DecodeWidth + FetchBufferEntry &gt; FetchWidth FetchBufferEntry | DecodeWidth fetchWidth = 2? ICacheFetchBytes IntPhyRegister = FpPhyRegister LDQEntry = STQEntry MemIssueWidth = FpIssueWidth</cell></row><row><cell cols="2">+ "|" means RobEntry should be divisible by DecodeWidth.</cell></row><row><cell cols="2">B. Problem Formulation</cell></row><row><cell cols="2">Definition 1 (Microarchitecture Design). Microarchitecture</cell></row><row><cell cols="2">design is to define a combination of candidate values given</cell></row><row><cell cols="2">in TABLE I. A microarchitecture design is legal if it satisfies</cell></row><row><cell cols="2">all constraints as referred to in TABLE II. Every legal</cell></row><row><cell cols="2">microarchitecture design to be determined is encoded as a</cell></row><row><cell cols="2">feature vector among the entire design space D. The feature</cell></row><row><cell cols="2">vector is denoted as x. For convenience, microarchitecture</cell></row><row><cell cols="2">and microarchitecture design in the following sections are the</cell></row><row><cell>same.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III</head><label>III</label><figDesc></figDesc><table><row><cell cols="3">Normalized Experimental Results</cell></row><row><cell>Methodologies</cell><cell>Normalized ADRS</cell><cell>Normalized ORT +</cell></row><row><cell>SVR Random Forest XGBoost ASPLOS'06 [18] HPCA'07 [19] DAC'16 [6] DAC'19 [36]</cell><cell>0.2399 0.2263 0.2171 0.1948 0.1907 0.1473 0.1884</cell><cell>1.0000 0.9763 1.010 0.9437 0.8544 3.0102 0.8973</cell></row><row><cell>BOOM-Explorer w/o MicroAL BOOM-Explorer</cell><cell>0.1441 0.1145</cell><cell>0.3307 0.3556</cell></row><row><cell>+ ORT: Overall Running Time</cell><cell></cell><cell></cell></row><row><cell cols="3">same as those mentioned in their papers. Simulated anneal-ing is leveraged for traditional machine learning algorithms, e.g., SVR, Random Forest, and XGBoost.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV</head><label>IV</label><figDesc>, 16, 32, 12, 4, 8, 2, 2, 64, 80, 64, 1, 2, 1, 16, 16, 4, 2, 8] 6.0700 ? 10 -2 74915.2963 Pareto Design * [4, 16, 16, 8, 2, 8, 2, 2, 32, 64, 64, 1, 3, 1, 24, 24, 8, 4, 8] 5.8600 ? 10 -2 73333.7407 + The parameters are in the same order as TABLE I * Pareto Design is found by BOOM-Explorer</figDesc><table><row><cell></cell><cell cols="2">Comparison with two-wide BOOM</cell><cell></cell></row><row><cell>Micro-architecture Design</cell><cell>Design Parameters +</cell><cell>Average Power (unit: watts)</cell><cell>Average Clock Cycles</cell></row><row><cell cols="4">Two-wide BOOM 0.0 0.05 0.10 Ave. Power [4m m m e d i a n m t -v v a d d w h e t s t o n e a d d -i n t a d d -i n t + a d d -f p a d d -f p + b r a n c h Two-wide BOOM b r a n c h + s t d i o s t d i o + c o m p l e x fi r 2 d i m i i r t a r a i Pareto Design c n t c o m p r e s s c o v e r d u f f f a c i n s e r t s o r t m a t m u l t m i n v e r n s s t r e c u r s i o n m m m e d i a n m t -v v a d d w h e t s t o n e a d d -i n t a d d -i n t + a d d -f p a d d -f p + b r a n c h b r a n c h + s t d i o s t d i o + c o m p l e x fi r 2 d i m i i r t a r a i c n t c o m p r e s s c o v e r d u f f f a c i n s e r t s o r t m a t m u l t m i n v e r n s s t r e c u r s i o n log 0.0 2.00 4.00 6.00 2 Ave. Clock Cycles</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work is partially supported by <rs type="funder">HiSilicon</rs> and <rs type="funder">The Research Grants Council of Hong Kong SAR</rs> <rs type="grantNumber">CUHK14209420</rs>, <rs type="grantNumber">CUHK14208021</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UUFvdsc">
					<idno type="grant-number">CUHK14209420</idno>
				</org>
				<org type="funding" xml:id="_tR6Xx7M">
					<idno type="grant-number">CUHK14208021</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The berkeley out-of-order machine (BOOM): An industry-competitive, synthesizable, parameterized RISC-V processor</title>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Celio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>University of California at Berkeley, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A Highly Productive Implementation of an Out-of-Order Processor Generator</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Celio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Chisel: constructing hardware in a scala embedded language</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Avi?ienis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wawrzynek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1212" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Power-efficient heterogeneous many-core design with ncfet technology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pathania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Amrouch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1484" to="1497" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evolution of the samsung exynos CPU microarchitecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Grayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rupley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Zuraski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Quinnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Jim?nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nakra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kitchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hensley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brekelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Symposium on Computer Architecture (ISCA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient design space exploration via statistical sampling and adaboost learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Validation of turandot, a fast processor model for microarchitecture exploration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moudgill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Performance Computing and Communications Conference (IPCCC)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="451" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SimpleScalar: An infrastructure for computer system modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">New methodology for early-stage, microarchitecture-level power-performance analysis of microprocessors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gschwind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Emma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rosenfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="653" to="670" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The gem5 simulator</title>
		<author>
			<persName><forename type="first">N</forename><surname>Binkert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Hower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sardashti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vaish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1145/2024716.2024718</idno>
		<ptr target="https://doi.org/10.1145/2024716.2024718" />
	</analytic>
	<monogr>
		<title level="s">SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using simpoint for accurate and efficient simulation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Biesbrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="318" to="319" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic translation of behavioral testbench for fully accelerated simulation</title>
		<author>
			<persName><forename type="first">Y.-I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Kyung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer-Aided Design</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="218" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficiently exploiting low activity factors to accelerate RTL simulation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Beamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donofrio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and accurate DRAM simulation: Can we further accelerate it?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="364" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Symposium on Microarchitecture</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Active Learning via Transductive Experimental Design</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Correlated multi-objective multi-fidelity optimization for hls directives design</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficiently exploring architectural design spaces via predictive modeling</title>
		<author>
			<persName><forename type="first">E</forename><surname>?pek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>De Supinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="195" to="206" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Illustrative design space studies with microarchitectural regression models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Sympo-sium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="340" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Active learning for regression using greedy sampling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">474</biblScope>
			<biblScope unit="page" from="90" to="105" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross-program design space exploration by ensemble transfer learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer-Aided Design</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="201" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On learning-based methods for designspace exploration with high-level synthesis</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Carloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accelerating FPGA prototyping through predictive model-based HLS design space exploration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Schafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Neural Network Hardware Deployment Optimization via Advanced Active Learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cross-layer optimization for high speed adders: A pareto driven machine learning approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2298" to="2311" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CAD Tool Design Space Exploration via Bayesian Optimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Workshop on Machine Learning CAD (MLCAD)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Counteracting adversarial attacks in autonomous driving</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer-Aided Design</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14030</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep kernel learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Batch bayesian optimization via multi-objective acquisition ensemble for automated analog circuit design</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3306" to="3314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Pareto frontier learning with expensive correlated objectives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1919" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Differentiable expected hypervolume improvement for parallel multi-objective bayesian optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Daulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Balandat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Chipyard: Integrated design, simulation, and implementation framework for custom socs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biancolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Magyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pemberton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rigge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nikoli?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="10" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Asap7 predictive design kit development and cell design technology co-optimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vashishtha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vangala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Conference on Computer-Aided Design</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="992" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Accelerating FPGA Prototyping through Predictive Model-Based HLS Design Space Exploration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Schafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">XGBoost: A scalable tree boosting system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DSPstone: A DSP-Oriented Benchmarking Methodology</title>
		<author>
			<persName><forename type="first">V</forename><surname>Zivojnovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schl?ger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meyr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSPAT</title>
		<meeting>ICSPAT</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">MBBench: A WCET benchmark suite</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuzhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>?n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sakarya University Journal of Computer and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="50" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
