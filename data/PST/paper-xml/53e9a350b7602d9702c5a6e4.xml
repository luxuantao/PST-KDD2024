<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
							<email>zhu@arcadia.havvard.edu</email>
						</author>
						<author>
							<persName><forename type="first">Webster</forename><surname>St</surname></persName>
						</author>
						<author>
							<persName><forename type="first">San</forename><surname>Francisco</surname></persName>
						</author>
						<author>
							<persName><forename type="middle">A</forename><surname>Yuille</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Division of Applied Sciences</orgName>
								<orgName type="laboratory">Havvard Robotics Laboratory</orgName>
								<orgName type="institution">Havvard Univevsity</orgName>
								<address>
									<postCode>M A 02138</postCode>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Smith-Kettlewell Eye Research Institute</orgName>
								<address>
									<postCode>2232</postCode>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C794A358385E238B24DDCAFB4389B5B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>compefifion. This algorithm is derived by minimizing a generalized BayesiMDL criterion using the variational principle. The algorithm is guaranteed to converge to a local minimum and combines aspects of snakesiballoons and region growing. Indeed the classic snakesiballoons and region growing algorithms can be directly derived from our approach. We provide theoretical analysis of region competition including accuracy of boundary location, criteria for initial conditions, and the relationship to edge detection using filters.</p><p>It is straightforward to generalize the algorithm to multiband segmentation and we demonstrate it on gray level images, color images and texture images. The novel color model allows us to eliminate intensity gradients and shadows, thereby obtaining segmentation based on the albedos of objects. It also helps detect highlight regions.</p><p>Index Terms-Image segmentation, region growing, snakes, minimum description length, Bayes statistics, uncertainty principle, color model. A common property of these approaches is that they all make hypotheses about the image, test features, and make decisions by applying thresholds explicitly or implicitly. As</p><p>shown by the shadowed areas in Fig. <ref type="figure" target="#fig_0">1</ref>, a major difference between the four approaches lies in the domains on which the hypotheses, tests, and decisions are based. These approaches all have certain drawbacks. The filtering approach only makes use of local information and cannot guarantee continuous closed edge contours. Snake/balloon models make use only of information along the boundary and require good initial estimates to yield correct convergence.</p><p>An advantage of region growing is that it tests the statistics inside the region, however it often generates irregular detector 141, boundaries and small holes. In addition, all these three methods lack a global criterion for segmenting the entire image. By contrast, energy/ ria but it is often very difficu iv. BayedMDL ns based on which the hypotheses, tests, and decisions are made by (i) filtering, (ii) snakes/balloons, (iii) region growing, and (iv) the energy/Bayes/MDL approach.</p><p>In this paper we present a statistical framework for image segmentation using a novel algorithm which we call region competition. It is derived by minimizing a generalized Bayes/MDL criterion which involves a sampling window (whose size depends on the signal to noise ratio). The algorithm combines the attractive geometrical features of snake/balloon models and the statistical techniques of regon growing. Indeed we can derive the classic snake/balloon and region growing algorithms directly from our framework. Our approach can therefore be applied for finding individual image regions, though we only show simulations for the harder task of global segmentation.</p><p>The precision of the boundary location depends on the size of the sampling windows. As for the Canny edge detector 141, the desirable size of these windows depends on a trade-off between the conflicting goals of maximizing the signal to noise ratio and locating the boundaries accurately. This gives rise to an uncertaincy principle <ref type="bibr">[36]</ref>. We describe how optimally sized windows can be chosen to minimize this uncertainty.</p><p>Like many algorithms, the performance of region competition will depends on the initial conditions-more precisely on the choice of initial "seeds." We discuss criteria for choosing such seeds. We also describe an important domino effect whereby bad seeds are transformed into good seeds.</p><p>Our approach is directly generalized to multiband segmentation. First we extend it to color using a novel model which, for certain types of materials, allows us to segment the image based on the albedo of the material. This avoids the key drawback of many approaches to image segmentation which only look for discontinuities in intensities, and which can give misleading results. For example, clothes typically have regions of homogeneous albedo or texture, but will often have sharp shadows due to creases. Finally we run our algorithm on texture images using filters to provide multiband input.</p><p>This paper has some similarities to work described by <ref type="bibr">[291 and [26]</ref>. Both approaches use statistical tests to grow multiple seed regions independently, and then use the MDL criterion to compress the overlapping between regions. By contrast, our method minimizes the MDL criterion for the entire image directly. Our work also has some similarities to ideas discussed in <ref type="bibr">[281 and [221, [271.</ref> These works differ from ours by not using a statistical criterion.</p><p>This paper is organized as follows. Section 2 sets the scene by briefly describing snakes and balloons, region growing, and energy/Bayes/MDL. In Section 3, we introduce our approach for gray level images and describe implementation results. Section 4 discusses how the window size affects the precision of boundary location and the influence of initial conditions. Section 5 describes the color model and discusses how it can remove intensity gradients and detect highlights. In Section 6, we apply our method to texture images. Finally, Section 7 discusses several possible extensions of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SNAKES, REGION GROWING, AND</head><p>This section briefly reviews the properties of snakes/balloons, region growing, and Energy/Bayes/MDL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ENERGY/BAYES/MDL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Snakes and Balloons</head><p>A snake <ref type="bibr" target="#b19">[19]</ref> is an active contour defined by where s can be the arc length of the contour.' Here we assume that T(s) is the closed boundary of a region R (i.e., Us)</p><formula xml:id="formula_0">= ax). r(s) = MS), Y(s)),</formula><p>A typical energy for a snake is: which is minimized by steepest descent:</p><p>1. The contour can also be represented parametrically, for example by Bsplines or Fourier coefficients, but we will not consider such variants in this paper.</p><p>where rss = (i!(s), y(s)), etc. This derivation requires taking functional derivatives of the energy, see the Appendix.</p><p>The balloon models [6], 171, [37] are motivated by the desire to drive the snake automatically to a good position (thereby decreasing the dependence on the initial conditions). They introduce an additional force term vli(s) to (2), which pushes the contour out (or in) along its normal fi(s).</p><p>This additional force term can be derived from an energy function. It corresponds, see the Appendix, to an additional energy term Eudd[r(s)] = -V IR dxdy. The complete energy for the balloon is:</p><p>Thus the balloon tries to maximize its area while smoothing its bounding contour and maximizing the intensity gradient along the contour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Region Growing and Merging</head><p>The goal of region merging and region growing 1161, [26] is to divide the domain R of the image I into regions {R, : i = 1, ..., M} so that R = uEIR,, R, n R, = q3 if i # j , and I satisfies a homogeneity criterion on each R,.</p><p>Region merging builds up complicated regions by combining smaller regions using a statistical similarity test. A popular choice is Fisher's test 1331. For example, suppose there are two adjacent regions XI and R2, where nl, n2, ,ill, ,i12, S:, 6; are the sizes, sample means, and sample variances of RI, R2, respectively. Then in order to decide whether or not to merge them, we can look at the squared</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fishev distance:</head><p>where n = nl + n2 and 6' is the sample variance of the mixture region (a generalization to the multidimensional case is called Hotelling's test 1171). If this statistic is below a certain threshold then the regions are merged.</p><p>Region growing can be considered as a special case of region merging, where R, is the growing region and R2 is a single pixel at the boundary of RI, i.e., n2 = 1 and nl is very large (say nl &gt; 100). In this case we can treat p = &amp;, o2 = a:, and = I( x,y) (the intensity at point (x, y)), and approximate the squared Fisher distance [81 by: 7.</p><p>A variant of region growing <ref type="bibr">[26]</ref> is to fit the intensity within each region to a parameterized model, such as a plane or a quadratic form. Then tests like (4) can be applied to the residuals of the boundary pixels after fitting.</p><p>Although region growing algorithms are very intuitive they can rarely be proven to converge to the minimum of a global cost function, and the resulting regions may have noisy boundaries. Another drawback results from the use of Fisher's test, see (4), which cannot distinguish between two distributions with the same means but different variances. This problem will be discussed in a later section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Energy, Bayes, and MDL</head><p>Both Bayes and MDL specify ways for segmenting images using global energy function criteria. These two approaches are motivated by different considerations but it is straightforward to transfer an MDL criterion into a Bayesian one and vice versa.</p><p>The use of global energy criteria, derived from Bayesian principles, is a common approach to image segmentation <ref type="bibr">[lo]</ref>. The observed image is modeled as being a degraded version of an ideal image which is assumed to be piecewise smooth. For example, the energy function used in Mumford and Shah [28], and in Blake and Zisserman [3] (i.e., the weak membrane model) is:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R (5)</head><p>where I is the input image, f is the output image, and r labels the discontinuities. It is easy to see that when A ++ 00 this reduces to a cartoon model: where f, is constant within each region R, and 0' = is constant over the entire image.</p><p>On the other hand, <ref type="bibr">Leclerc [23]</ref> suggests that segmenting images according to the above Bayesian model should be equivalent to obtaining the minimum description length (MDL) of it in terms of a previously specified description language. Equation ( <ref type="formula">6</ref>) is a special case where the image description is in terms of piecewise constant values, the standard deviation is assumed to be globally constant, and a penalty is paid for encoding the boundary proportional to its length I rl . A more typical MDL criterion occurs in (7) (see next section). It differs from (6) by letting the OS be unknown variables which are assumed to be constant within each region.</p><p>It is usually very difficult to minimize the energy functions resulting from Bayes or MDL. Algorithms such as simulated annealing [ 101, graduated nonconvexity [3], and deterministic annealing [9] are perhaps the most successful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>In this section, we first derive our region competition algorithm from a global optimization criterion. Then we show how the classic snake/balloon and region growing algo-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REGIQN CQMPETlTlON FOR GRAY LEVEL IMAGES</head><p>rithms can be derived as special cases. Next we do a generalization to standard MDL which is more robust. Finally we illustrate the region competition algorithm by simulations on gray level images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">From MDL to a Unified Framework</head><p>The goal of image segmentation is to partition the image into subregions with homogeneous intensity (color or texture) properties which will hopefully correspond to objects or object parts. Before describing the algorithm we first need a definition of homogeneity.</p><p>In this section a region R.is considered to be homogeneous if its intensity values are consistent with having been generated by one of a family of prespecified probability distributions P(I I a), where a are the parameters of the distribution. We assume that the probability models may differ in different regions. Such an assumption will be necessary if the application domain is human skin and clothes, where different patches will typically have different properties and hence will need to be described by different distributions. In later sections we will describe how the probability distributions P(I I a) can be generalized to residuals of fitting certain physical models or multiband features extracted from the images, in which cases a may includes the parameters specifying those physical models. Now suppose that the entire image domain R has been initially segmented into M piecewise "homogeneous" underlying regions { RJ, i = 1, 2, ..., M, i.e., R = uEIR1, RI n R, = 8 , if i # j . Let aR, be the boundary of region R, where we define the direction of 3 R, to be counter-clockwise, i.e., when we travel along the boundary, R, is on the left-hand side.2 Let r = uzll,T, be the edges or segmentation boundaries of the entire image with I-= ax,.</p><p>Now consider an MDL criterion-a global energy functional-which is the continuum limit of <ref type="bibr">Leclerc's [23]</ref> for an appropriate choice of the family of probability distributions. This gives:</p><p>where the first term within the braces is the length of the boundary curve dR, for region R,. We simply assume that the code length is proportional to the curve length where p is the code length for unit arc length. Since all edge segments are shared by two adjacent regions, we divide the first term by a factor of 2. The second term is the sum of the cost for coding the intensity of every pixel (x, y) inside region R, according to a distribution P({I(x,yl : (x, y) E x,) I q). A is the code length needed to describe the distribution and code system for region R, and we simply assume A is com-2. In case of holes, it will be clockwise. mon to all region^.^ will assume independent probability models so that For the rest of this paper, for purpose of illustration, we Because the energy E in (7) depends on two groups of variables-the segmentation l7 and the parameters aLs-we propose a greedy algorithm which consists of two alternating stages. The first stage locally minimizes the energy with the number of regions fixed. It proceeds by iterating two steps both of which cause the energy to decrease. The second stage merges regions provided this decreases the energy.</p><p>We now describe the first stage.</p><p>In the first step, we fix r. In other words, we fix R, and {I,,,, "(x, y) E RI}, and we solve for the a,, i = 1, 2, ..., M to minimize the description cost for each region. By Bayes rule this corresponds to setting4</p><p>In the discrete case:</p><p>In other words, the a,s are estimated by maximizing the conditional probabilities. For many distributions this can be done analytically. For example, if P(I I q) is the Gaussian distribution then the a i s are simply the sample mean and variance of the pixels inside R,.</p><p>In the second step, we fix the {q} and do steepest descent with respect to r. For any point . 7? = (x,y). On the boundary r we obtain:</p><p>(10)</p><p>where the right-hand side is (minus) the functional derivative of the energy E.</p><p>Taking the functional derivative, see the Appendix, yields the motion equation for point v' :</p><p>where Q(?;, = {kl.z?liesonT,}, i.e., the summation is done</p><formula xml:id="formula_2">over those regions Rk for which E is on I -, . K ~( ~)</formula><p>is the curvature of rk at point 3 and iik(G) is the unit normal to l-, at point 3 . We use the counter-clockwise convention that ii, points outward from Rk.</p><p>Equation (1 1) has a simple intuitive interpretation. There are two kinds of "forces" acting on the contour, both pointing along the normal. The first term, the smoothing force, is strongest at points of high curvature. Fig. <ref type="figure" target="#fig_2">2a</ref> shows the smoothing force at points along the region boundary. This force is independent of the direction of the curve and it tries to make the curve as straight as possible. The second term is the statistics force, f = logP(1Ia)ii. Since log P I 0, the statistics force always compresses the region. The better the point v' satisfies the homogeneity requirement the larger P(I 1 a), and the weaker the statistics force. The motion equation for E is:</p><p>It is easy to see that the smoothing term by itself is the Euclidean geometric heat flow equation used for curve smoothing and evolution, and it is equal to the following heat diffusion equation.</p><p>(</p><formula xml:id="formula_3">)<label>14</label></formula><p>where s is the arc length of the curve r. Detailed discussions of properties of this equation are given in <ref type="bibr">[12]</ref>.</p><p>Besides the smoothing term, the motion of 5 is determined by the likelihood ratio test. If P(I(Z)la,) &gt; P(I(G)laJ) -i.e., if the intensity at v' fits better to the distribution of region RI than to that of region Rc7--then the boundary will move along iil . This is the same for points which are shared by several region boundaries, Fig. <ref type="figure" target="#fig_2">2c</ref> shows the statistics forces at a junction point. Intuitively, adjacent regions compete for ownership of pixels along their boundaries, subject to the smoothness constraint. This is why we call our algo-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Recently we noticed that a similar equation (11) was reported in [35].</head><p>But it was not derived from MDL and the statistical meaning was not analyzed there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>rithm vegion competition.</head><p>Both steps in the algorithm cause the energy function to decrease.6 In addition the function is bounded below and so the algorithm is guaranteed to converge to a local minimum. This two step process, however, does not allow us to alter the number of regions. Thus we add a second stage where adjacent regions are merged if this causes the energy to decrease. This is followed by the two step iteration stage again, and so on. Overall each operation reduces the energy and so a local minimum is reached.</p><p>We argue that region competition contains many of the desirable properties of region growing, snakes and balloons. Indeed we can derive many aspects of these models as special cases of region competition.</p><p>Firstly, region growing with constant threshold can be considered to be a degenerate case of region competition where we treat the growing region as RI, with P(I I a,) chosen according to our desired homogeneity criterion, and the background region as Ro (so that R, U Ro = R ) with uniform probability distribution Po. Then the motion equation for each point 5 along the boundary is:</p><formula xml:id="formula_4">(15)</formula><p>where ii is the normal of the region contour. Discretizing this equation corresponds to region growing where the probability P(I(511 all is calculated and compared with the absolute threshold Po. Fisher's test 1331 and the x2 test 1261 correspond to particular choices of P(I(o)l all.</p><p>Secondly, the underlying statistical assumption for the balloon/snake model is even simpler; it treats both the current region RI and the background Ro as uniform distributions PI, Po with v = log PIlog Po. We obtain the snake model as the special case where v = 0. According to the balloon model, taking the derivatives of (3), the motion equation for the boundary 5 is:</p><formula xml:id="formula_5">-- &amp; ( S I --ar, + pr,,,, + dt (16)</formula><p>This equation differs from region competition (13) in two respects. The smoothing force for balloons-the first two terms on the right-hand side of (16)-differs slightly from the smoothing term for region competition. This is only a minor modification and could easily be removed by an alternative smoothness term in the energy function. The final term in ( <ref type="formula">16</ref>) is a threshold for deciding when to stop moving the contour and is provided by local edge measurements. Such a term does not appear directly in region competition, but a similar term can be obtained by including a cost for encoding edges such as where P(I, I e) is the probability of an edge measurement I,, conditional on an edge e being present. However, because the balloon model relies only on edge information and does not do statistics inside the regions it often fails to segment images into homogeneous regions.</p><p>In summary, the region competition algorithm combines the most attractive aspects of snakes/balloons and region growing to minimize a global cost function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Generalizing the MDL Criterion for</head><p>To proceed further we need to specify a family of probability distributions P(I I a). In this paper, for purposes of illustration, we will consider Gaussian distributions. This means we set a = (, U, 01, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Region Competition</head><p>\ 2 1</p><p>This simplifies the equations though we stress that more sophisticated models will usually be needed to deal with real images.</p><p>However, an analysis of the motion (13) reveals some underlyin disadvantages for the greedy algorithm that we proposed. This force seems plausible but, since only a single sample is taken from this distribution, there is a reasonable chance that I(x,y) will lie on one of the tails of the distribution. This can lead to the pixel being misclassified and the statistics force therefore may be overly sensitive to fluctuations in the intensity. This can be seen intuitively in Fig. <ref type="figure" target="#fig_4">3a</ref>, where the solid curves show two overlapping Gaussian distributions and the region of misclassification is indicated by the shadowed area. In Section 4, we describe quantitative results showing the amount of fluctuation of the statistics force. Second, in an extreme case where two distributions have the same mean but different variances, the classification error will be intolerable, see Fig. <ref type="figure" target="#fig_4">3b</ref>. One such image is studied in Fig. <ref type="figure" target="#fig_9">6</ref>. In such cases, we need to measure the second order moments (the variances) near each boundary point (x, y) in order to tell whether the point (x, y) should be classified as belonging to one distribution or to the other. As we mentioned earlier, this cannot be done by Fisher's test used in the region growing algorithm. Furthermore, if the distribution P(I I a) is more sophisticated than the Gaussian distribution then more complex statistics must be computed in the neighborhood of (x, y).</p><p>We argue that these problems are due not only to our greedy algorithm but also to the nature of the MDL criterion. For example, if the data is generated by Gaussians and 7. Similar problems will arise for snakes and region growing. the variance is large, then any algorithm will have difficulty in classifying pixels, because of sample fluctuations, and so faulty segmentations may occur even if the global minimum of the MDL has been reached. It can be shown, see <ref type="bibr">[41]</ref>, that if the data in a region is generated by a Gaussian with variance o2 then the variance of the sample variance in the region is of order o4 / N . For small regions, with N &lt;&lt; 04, it will often be energetically favourable, independent of the minimization algorithm, to encode the region as two, or more, sets. Thus standard MDL cannot be expected to give the correct solution for regions of this size and will have a tendency to oversegment the image. We propose dealing with these problems by using circular windows of m pixels around each point. We call these pixels the neighbor set of (x, y) denoted by ?/v(X,y). The effect of this is to replace P(I(X,y) I a) by the joint probability: n EMx,y)P(I(u,u) I a). Correspondingly, we obtain a generalized energy function:</p><p>The window ?/v solves our problems. Firstly, we observe that the larger m is then the bigger the chance that the window is representative of the distribution and the smaller the risk of misclassification. Secondly, the window enables us to do higher order statistics over : ( U , v) E %' (x, y)l to answer the second problem raised earlier. But the window cannot be too large or we will not be able to locate boundaries accurately. Thus there is a trade off and later in Section 4 we see that the optimal choice of m depends on the signal to noise ratio. Observe that the original MDL (7) will be obtained as a special case of the generalized energy when m = 1. Our analysis will show this is the correct choice for high signal to noise ratios. Moreover, the use of windows will help reduce the oversegmentation problems due to fluctuations by effectively smoothing the sample means and variances, see <ref type="bibr">[41]</ref>.</p><p>How does our generalized energy relate to standard MDL? First observe that we can rewrite ( <ref type="formula">17</ref> for all (x, y). In other words, we assume that each pixel (x, y) has a multiplicative mixture distribution, As seen in Fig. <ref type="figure" target="#fig_6">4</ref>, point A is totally inside region R,, so Z, = 1, n; = 0, Vj # i. Point B is near the boundary, so the corresponding q, n; are shown by the shadow areas (similarly for the point at the junction). If we assume Gaussian distributions for P(I(x,y) I 0;) then the multiplicative mixture P(I(x,y) I (0;)) is still a Gaussian with means and variances depending on the position (x, y).</p><p>For points in the interior of a region R, the means and variances will be those of the region. However, for points near the boundary of regions R, and RI the means and variances will be weighted averages of the means and variances of the two regions. This softens the changes in the means and the variances as we move from region to region, see Fig. <ref type="figure" target="#fig_7">5</ref>, and is a better model for realistic edge profiles, hence improving performance. Moreover, we can obtain the generalized energy (17) from a maximum entropy argument using Bayes theorem, see <ref type="bibr">[41]</ref>, though with addition of an extra term. We can show, however, that this extra term is small and can be neglected. Hence, (17) can also be considered an MDL criterion.' We can rewrite the statistics force generated by a single region R, at (x, y) in the direction of I i , as the following:</p><p>and 5' 10 8. The maximuin entropy derivation, see also [391 and 1401, uses constraints about the expected number of regions, the expected lengths of the regions, and the expected distributions of the region parameters. 9. Similar results would hold for many exponential distributions [391,</p><p>1401.</p><p>-j-</p><formula xml:id="formula_6">1 j-logP(z(u,v)la,)dudv = m Y X ) )<label>(19)</label></formula><p>In <ref type="bibr" target="#b19">(19)</ref>, the second term tests the mean, and the last term tests the variance (i.e., the F-test). With the addition of this "variance" force, we can detect two regions with the same means but different variances, see Fig. <ref type="figure" target="#fig_4">3b</ref>. Equation ( <ref type="formula" target="#formula_6">19</ref>) will be generalized to higher dimension in a later section (see (35)).</p><p>Thus from (17), we can derive the motion equation for point 5 at the boundary I ? , fl ri by plugging <ref type="bibr" target="#b19">(19)</ref> into the motion equation (13).</p><p>Before describing the complete region competition algorithm at the end of this section, we first explain how to decrease the energy by merging two adjacent regions. Suppose that n,, ni, , U, , /+, q, q are the pixel number, intensity mean, and intensity variance of two adjacent regions R,, RI, respectively. Let R, = R, U RI be the region after merging, let ell = ax, fl dR, be the common boundary between R, and RI, and let qI = (,U,], 4) be the mean and variance of R,. It is easy to see that:</p><p>1 Then the change of energy for merging R,, RI is: f flogP(zlnj)dxdy -I flogP(ZIa,)dxdy <ref type="bibr" target="#b21">(21)</ref> Equation ( <ref type="formula">21</ref>) is a generalization of (4). If AE 5 0, then merging R, and RI will decrease the energy. A brief description of the algorithm is given in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 1 THE REGION COMPETITION ALGORITHM</head><p>1. Initialize the segmentation, we can put N seeds randomly across the image, and all background (area not occupied by any seed regions) is treated as a single region with uniform probability distribution.</p><p>2. Fix the boundary r, compute the parameters {a1) by maximizing P(1: orl).</p><p>3. Fix {or1}, move the boundary r by minimizing the energy function. When two seed regions meet, edge is formed at their common boundary, then these two regions compete along this boundary. 4. execute step 2,3 iteratively until the motion of boundary I' converges. Then goto step 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">If there is background region not occupied by any seed</head><p>regions, then put a new seed in the background, and goto step 2; else goto step 6.</p><p>6. Merge two adjacent regions so that the merging causes the largest energy decrease, goto step 2. If no merge can decrease the energy, then goto step 7.</p><p>7. stov.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Simulations on Gray Level Images</head><p>In this subsection, we illustrate the region competition algorithm on two typical gray level images.  <ref type="figure" target="#fig_9">6f</ref> shows how the boundary moves if we drop the last term in <ref type="bibr" target="#b20">(20)</ref>. Thus if we do not test the variance then the edge just moves to the low-right corner and disappears. This results in an incorrect segmentation with the image being perceived as a single region. For this image, we use a circular window Wwhich contains 32 pixels. Fig. <ref type="figure" target="#fig_10">7a</ref> is a 150 x 150 image consists of four regions whose intensities are generated randomly from four Gaussian distributions: N(50, lo2), N(80, lo'), N(110, ll'), and N(150, 15'). The segmentation is started by putting nine seed regions (each has 80 pixels) on a grid, with four seeds inside the four regions, four seeds straddling the boundaries, and one seed lying on the intersection point of the four regions. As we will define in the next section, the first four regions are called the good seeds, while the later five ones the bad seeds. The background (shown by the shadow) is treated as a single region which has uniform probability distribution Po. As discussed earlier for balloons, Po provides the forces causing the seed regions to grow. The motion of regions at iteration steps t = 0, 10, 30, 42, 65,120,150 are shown in Figs. 7b, 7c, 7d, 7e, 7f, 7g, and 7h, respectively. At t = 10 we observe that the good seeds grow faster than the bad seeds. Where these regions meet edges are formed, see Fig. <ref type="figure" target="#fig_10">7d</ref>. The four good seeds keep compressing the bad regions and taking over the background, see Figs. <ref type="figure" target="#fig_10">7e</ref> and<ref type="figure" target="#fig_10">7f</ref>. During competition process some regions may be squeezed out or split by their neighbors (see step t = 42). Finally the competition converges at t = 120 in Fig. <ref type="figure" target="#fig_10">7g</ref> with all the bad seed regions being driven into one of the four real regions. Then, in the second stage of the algorithm, we merge the pairs of adjacent regions which cause the energy function to decrease the most, and restart the first stage of region competition. After 30 more iteratives, the algorithm converges at t = 150, see Fig. <ref type="figure" target="#fig_10">7h</ref>.</p><formula xml:id="formula_7">c (t=20) tl (t=30) f' (without F-test)</formula><p>The current implementation has two drawbacks. First, observe that the bounding contours are sometimes jagged and it appears that the smoothness term is not always doing its job. Second, the good seeds in the four squares of Fig. <ref type="figure" target="#fig_10">7</ref> all appear to grow at similar speeds even though the variances in these regions differ. Both these effects can be traced to the simple discretization used in our current implementation of the algorithm. More sophisticated discretization, currently being investigated, would eliminate these problems. ) with small blobs of 3 x 3 pixels and lines (gray value 200) of one pixel width superimposed on it. (b) the final segmentation after merging Note the failure to detect the small blobs and many of the edges Finally we show an image for which the algorithm gets a wrong answer, see Fig. <ref type="figure">8</ref>. The lines and spots are degenerate regions-i.e., they have one and zero dimensionswhich do not fit our assumptions about the image and hence cause the algorithm to give the incorrect segmentation. It converges to a state where the left side of the image, which has a high density of lines, is considered a separate region from the right side of the image (where the lines are sparse). It completely fails to locate the four blobs in the right of the image because they are too small. To succeed our algorithm would need to be modified to contain an edge term, as discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANALYSIS OF THE BOUNDARIES, WINDOWS, AND SEEDS</head><p>To further understand the performance of the region competition algorithm, it is crucial to analyze the precision of the boundary and the effects of the initial seed configurations. For reasons of space we summarize the results here and refer interested readers to 1411 for more details. Firstly we show that there exists an uncertainty interval U for the boundary, and show how to choose the size and shape of the window ?/v to minimize U. In the following, we use square windows and assume Gaussian distributions for mathematical convenience. Observe that, since the variance of the force, D[f(,)], will be a monotonic decreasing function of the window size m, thus the larger the window the less the force fluctuates and the closer the dashed lines are to the solid line. From Fig. <ref type="figure" target="#fig_11">9c</ref> we see that window size m has to satisfy the following constraints: <ref type="bibr" target="#b24">(24)</ref> Otherwise, the uncertainty interval of the edge (i.e. the thick line segment) will be infinitely long, in other words, the boundary may be located at any point with a certain probability. For instance, in the case of Fig. <ref type="figure" target="#fig_11">9c</ref>, solving the above inequalities gives m 2 -.</p><p>Notice that $ is the signal-to-noise ratio (SNR); clearly in an image with high contrast regions (i.e., high SNR) where Ap &gt;&gt; 0, we can simply choose m = 1. This explains why region growing algorithms work for certain images. But once the window is big enough, U becomes a constant (see ( <ref type="formula">23</ref>)) This corresponds to the general uncertainty principle in image processing <ref type="bibr">[36]</ref>. We choose the window size to be the smallest m which satisfies the inequalities ( <ref type="formula">24</ref>), <ref type="bibr" target="#b25">(25)</ref>. Fig. <ref type="figure" target="#fig_11">9d</ref> shows another special cases where pl = M 01 7L 0 2 . Since E[f(,,] # 0, the resulting boundary will be a biased estimate of the true boundary. Thus the boundary will be moved to the region which has less variance. This effect 4a2a2 Afi will be noticable in the texture segmentation of late section.</p><p>Further analysis suggests that the precision of the boundary would be increased by using elliptical windows with their major axes parallel to the boundary, see Fig. <ref type="figure" target="#fig_13">10</ref>. This would relate our approach more closely to standard edge detectors. By using various surface models in the two adjacent regions, our approach could detect step edges, crease edges, or even C edges. This is a subject of current research. Secondly, the performance of region competition will highly depend on the initial seeds configurations. In fact, each initial seed is a hypothesis about the location of a certain probability distribution family (OY a model). Therefore, we define a seed to be "good if 1) it is completely inside a "true" region and 2) it picks the correct probability family (or model).</p><p>A seed is bad if it fails to satisfy either of these conditions, typically because it straddles the boundary between two regions.</p><p>Thus to decide whether a seed is good or not we must test the sample characteristics. In <ref type="bibr">[41]</ref>, several tests are proposed for the special case of Gaussian models, such as skewness and kurtosis. It is illustrated that these tests automatically select "good seeds completely inside regions and avoid selecting " b a d seeds which straddle boundaries.</p><p>Empirically we observe that a sufficient condition for an optimal segmentation is that at the beginning each 'true' region includes at least one good seed. But this is not a necessary condition. It can be shown by simulations that "good seeds can convert "bad" seeds by a type of domino effect. In Fig. <ref type="figure" target="#fig_14">11</ref> we show several stages of region competition running on the image shown in Fig. <ref type="figure" target="#fig_10">7</ref>. where seeds 1,2, 3, and 4 are bad and seed 5 is good. At the first stage, all bad seeds grow across the boundaries (see t = 20). After they contact each other, seed 5 drives seeds 1 and 2 out of the upper-left region (see t = 50). By time step t = 84, we observe that seeds 1 and 2 have been completely expelled from the upper-left region, and both become good seeds, while seeds 3 and 4 remain bad seeds. Once seed 1 and 2 become good, they kick seeds 3 and 4 out from their territories until, at time step t = 126, both seeds 3 and 4 are driven into the lower-right region and become good seeds. Finally they are merged into a single region at t = 150. Such domino effects will continue when more regions are involved and we think this is a key difference between the region competition algorithm and conventional region growing If we assume red, green, and blue color bands, then we can simplify (26) at each point (x, y) to:</p><formula xml:id="formula_8">2 [ ! I , -[i)(x,y) (29) x,y)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MULTIVARIATE MODELS: COLOR</head><p>The previous sections have described segmentation tech-(</p><p>niques where regions are considered to have homogeneous intensity properties, But the image intensity is a function both of the material properties of the object, its albedo, and the surface orientation and lighting.</p><p>where (Y, 8, b) is the (assu-") spatially constant body color within each region, (Y~, gs, b,) is the (assumed) spatially constant color of the light source, I(x,y) is the illumination, Is,(x,y) For many applications image segmentation should be based on the albedo and independent of the lighting conditions or the geometric configuration of the material. For example, if we are looking at a person then the skin or each patch of the clothes will have constant albedo properties but the intensity of the skin or clothes may change dramatically due to the changes of the geometric configuration.</p><formula xml:id="formula_10">(a) t = 0 (b) t = 20 (c) t = 50 (d) t = 84 (e) t = 126 (f) t = 150</formula><p>is the specular component, and the (eT, eg, are the residuals (or noise).</p><p>Although there have been many attempts to separate the body color (Y, g, b) from the specular color (Y~, g,, b,) <ref type="bibr" target="#b21">[21]</ref>,</p><p>[15], [34], these approaches have been demonstrated on plastic and metal objects with nice illumination. If the noise level is quite high and the intensity around the specular regions are approximately saturated-conditions commonly observed for skin and clothes-it will be very difficult to separate out the specularity using these approaches.</p><p>For now we simply combine the highlights into the body reflectance and the residuals (highlights can be detected, see Fig. <ref type="figure" target="#fig_16">12c</ref>, from the form of the residuals) giving:</p><p>We use no prior knowledge about the illumination I(x,y) or the colors (Y, g, b). This is equivalent to assuming that they are coded by uniform probability distributions, rather than the Gaussian models used in Section 3.</p><p>We now determine the residuals by assuming that they are as small as possible, in the least squares sense, while requiring that (28) is satisfied. The residuals, the albedo ( Y , g, b) and the intensity I(x, y) can be found by minimizing the sum of the squared error over all point (x, y) within region R,:</p><formula xml:id="formula_11">I(a, t ) = p(a, Y , ) F ~( E , ti, s)E(a, ti, s) + F,(E, ti, ?)E(A, ti, 2 ) + noise( q ) (<label>26</label></formula><formula xml:id="formula_12">)</formula><p>where I is the image as function of the image position &lt; and wavelength A, p is the surface albedo as a function of i l and surface location Ts, F is the geometric viewing term as a function of A, the surface normal ?i, and the light source direction S , and E is the surface irradiance as a function of A, ii , and S . In general, the first term corresponds to the body reflectance and the second term corresponds to specularities (typically highlights). This model has been tested over a range of materials <ref type="bibr" target="#b25">[25]</ref> and is shown to be a good approximation in many cases, though it fails for some dielectrics.</p><p>We minimize this energy by steepest descent (though SVD could also be used). The solutions, (Y*, g', be, Iix,y,), at In other words, as seen in Fig. <ref type="figure" target="#fig_16">12a</ref>, we find a unit vector (Y*, g*, b*) in the RGB space and project each pixel color vector (R, G, B),,,, onto this vector. The projected length (i.e., their inner product) is the intensity &amp;). Then the residual vector (ey, eg, eb)(x,y) is perpendicular to the color vector shown in Fig. <ref type="figure" target="#fig_16">12a</ref>. Therefore all the residuals 2 lie on a 2D plane pwhose normal is (Y*, $, b*).</p><p>By  such points have little weight, see Fig. <ref type="figure" target="#fig_16">12a</ref> where pixels 1 and 2 have the same color but different intensity I-the residual error is smaller for 1 and therefore 1 has less weight in determining the region color (Y, g, b). Both approaches, however, share the disadvantage that they cannot detect intensity boundaries, because they have factored out the intensity.</p><p>Our work also differs from the approach in <ref type="bibr" target="#b18">[18]</ref> who encode structured models for the red, green, and blue components, which is similar to applying our gray-level model directly to three color dimensions. For certain types of illumination profiles this will be essentially the same as our model. We argue, however, that it is important to factor out the illuminant so as to get segmenation based on albedo rather than color. Similarly our method for detecting specularities is different from the one developed in [211 which calculates the 3 x 3 covariance matrix on each patch independently and classifies the color patches into 2 = 8 classes based on the size of the three eigenvalues. We argue that this approach is not applicable to our application and the physical meaning of the eigenvectors is not always clear. For example, in a region with constant color but heavy gradient shading the biggest eigenvalue will correspond to illumidation changes while in a region with less shading but big noise fluctuations the largest eigenvalue will instead correspond to noise fluctuations. For these reasons we argue that the eigenvalue analysis should be done in 2D instead of 3D.</p><p>By contrast, an alternative approach [151 works on normalized color images but involves a separate edge detection mechanism to help group the image into regions with constant material properties. The test for specularity is different from ours and we are unable to compare it directly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Color Segmentation</head><p>As before, the region competition algorithm iterates two steps. In the first step! we fix the boundary r/ and compute the best fit color ((, g:, b:) for each region R,. Then we calculate the fitting residuals X on the 0, plane, whose normal is ((,g:,b:), for each (x, y) E RI. We define the Fig. <ref type="figure" target="#fig_16">12b</ref> shows a typical residual distribution for a homogeneous color region. B~ contrast Q, . 1zC is a typical residual distribution for a highlight region. The difference can be seen in the aspect ratio a = , / =.</p><p>For a region without a highlight we typically find 1 5 a 5 2, but in a highlight residuals tend to have a larger component intro-highlight region we usually find a 2 4. In other words, ( X f Y ) duced by the specularity vector, i.e., the second term in (27). We therefore use this property to detect highlights. Here mean and covariance of region R, (with I R, I = N&gt; to be: again we see that the window at the boundary and the second order moments are crucial for highlight detection.</p><p>1</p><formula xml:id="formula_13">N (X,Y) 1 p,=-c x</formula><p>This color model has allowed us to decompose the input</p><formula xml:id="formula_14">(X!Y).R,</formula><p>color image into a constant color term, a varying intensity term, and the residuals on a 2D plane. Our method can be contrasted to the currently existing approaches, for example 1341, which tries to eliminate the intensity term by normalizing the input color images, i.e., sending '(w)</p><p>-Pl)(rl.c.,y) -i q</p><formula xml:id="formula_15">x l = N c (1( .,Y)<label>(31)</label></formula><p>The second step involves moving the boundary r by (R + G + B)lx</p><formula xml:id="formula_16">\ " I</formula><p>calculate: We claim that our method has advantages because the standard normalization becomes very noise sensitive at 1) the projection of (R, G, B)(u,v) onto the (y,*, g:, b:) vecplaces where ( R + G + B)(x,y) is small, but in our method 11. This dataset consisted of cloth and skin patches chosen from real images. tor and 2) the fitting residual in the 0, plane.</p><p>Similarly to the gray level case, we sample a window containing m pixels and obtain a set of measurements (Yl, ..., qm). We define the probability for these pixels to belong to region X, to be:</p><p>We modify (17) to include these distributions. Then the update equations for the boundary are obtained by doing steepest descent, as before.</p><p>Once again we can relate this approach to conventional region growing using statistical tests. We define the window mean and co-variance by: These are sufficient statistics for the Gaussian distribution, thus: Observe that (35) generalizes ( <ref type="formula" target="#formula_6">19</ref>) to higher dimensions.</p><p>As for the gray level case we can identify the terms on the right-hand side of (35) as the standard generalizations of the T and F tests to higher dimensions.</p><p>Observe that we only introduce probabilities after fitting  From top to bottom, we show the cross-sections on the face, torso, and arms, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Color Images Experiments</head><p>Fig. <ref type="figure" target="#fig_21">14a</ref> shows the red band of a color image of 261 x 116 pixels. Observe the noise, shading in the cloth and the highlights on several parts of the skin. Fig. <ref type="figure" target="#fig_20">13</ref> illustrates the shading by plotting cross-sections in the gray level image, Fig. <ref type="figure" target="#fig_21">14b</ref> (obtained as a linear combination of the red, green, and blue bands). The algorithm was implemented as for the gray level case. Fig. <ref type="figure" target="#fig_21">14c</ref> shows the initial seeds at iteration step t = 0.</p><p>Figs. 14d, 14e, 14f, 14g, and 14h show the sequence at steps t = 10, 20, 60, 100, 135, respectively. The competition between the seed regions converged at t = 100 as shown in Fig. <ref type="figure" target="#fig_21">14g</ref>. The small shadow regions are the image spaces which are not occupied by the 20 initial seeds. In such regions we need to introduce additional seeds which can compete with the initial ones. We observe that the eyes and mouth are included in the face region because they are too small (about 10 to 25 pixels) and thus are treated as noise.</p><p>Observe in Fig. <ref type="figure" target="#fig_21">14g</ref> that the algorithm detects the highlights and labels them correctly. These highlight regions are:</p><p>1) on the neck and shoulder, 2) on the left arm, 3) on the left leg, and 4) on the breast. Fig. <ref type="figure" target="#fig_21">14h</ref> shows the final segmentation after spreading additional seeds and merging. In most case, it is desirable for the color model to eliminate shading effects, but in some cases, it become disadvantageous. For example, a black region like the hair will fit well to any color regions. In addition small regions like the eyes and teeth are incorrectly merged.</p><p>In our implementation, we put a constraint in the merging step so that two regions with enormous intensity difference should not be merged. This prevents the hair from being merged with other regions. We consider this to be a naive way for integrating the color and intensity clues. A more sophisticated data fusion algorithm is under implementation.</p><p>We give two other examples of our algorithm. Fig. <ref type="figure" target="#fig_13">15</ref> shows a hand correctly segmented from a background of red and white fabric with the donut correctly located. This image shows that the algorithm works even if the background region is not Gaussian. The highlights on the nails, and ring, are correctly detected (except for the second finger) when the A parameter is low but are merged with the fingers when A is increased. Fig. <ref type="figure" target="#fig_13">16</ref> shows a squirrel being successfully segmented from a grassy background. The color of the squirrel, however, is not constant and the aIgorithm segments it into the correct color parts. The color varies a lot on the tail and so several regions are found. Right: The grass has very variable intensity but the final segmentation is good.</p><p>Note that the images in this section can be viewed in http: / /hrl.harvard.edu/people/students/zhu/zhu.html.</p><p>color on the first author's www home page:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">TEXTURE SEGMENTATION</head><p>We can directly adapt our algorithm to perform texture segmentation. First we apply a set of p texture filters to the input image to obtain a set of p texture images. This gives us a multi-band input (sl, ..., sp)(x,y) at each pixel (x, y). Then = (sI, . . . , sp) is considered to be a p-dimensional random variable at each pixel. We then apply our multi-band model, assuming multivariate Gaussian distributions, using the 2 as input.</p><p>In this paper, for purposes of illustration, we set p = 2 and set = G, * I,, G,*Iy where G, is a zero mean Gaus- Fig. <ref type="figure" target="#fig_27">18a</ref> shows a texture image of 172 x 247 pixels. For each region-such as the cheetah body, the grass and the buffalo-we study the second order texture statistics:</p><p>The lower half of Fig. <ref type="figure" target="#fig_26">17</ref> shows the histograms of Go * I,, G, * Iy on the three regions. Such Gaussian-like histograms indicate that the second order statistics are good discriminators. We found that the j2s are very close to zero for all regions. The sample covariance X can be simply characterized by its eigenvalues &amp;, &amp;, and the direction 8 between the largest eigenvector and the x axis. The upper half of Fig.   Our algorithm proceeds as in the color case using (34) but with r*, g*, b'; being set to zero First we compute the statistics (,G1,X1) for each region RI. The means for all the regions are close to zero, see Fig. <ref type="figure" target="#fig_26">17</ref>, so the covariance is the major discriminator. Then we sample in a window surrounding a boundary pixel (x, y) and compute the sample mean and the sample covariance. In order to obtain enough data to calculate these sample covariances reliably we choose the window size m to be large. We set m = 68 for our experiments.</p><p>These sample means and covariances can be used to compute the statistical forces exactly as in (35). As before these forces, in conjunction with the smooth forces, will update the positions of the contour boundaries. Fig. <ref type="figure" target="#fig_27">18b</ref> is the final result after merging, where we observe that the belly of the cheetah, which is highly shadowed, is merged with the grass under the body. This is due to the similarity of their covariance matrices, see the corresponding ellipses shown in Fig. <ref type="figure" target="#fig_26">17</ref>, Since the variances change dramatically between regions, for example, the variance in the cheetah region is about 6 times larger than that in the buffalo region, it can be shown [411 that the bias of the boundary location will be noticeable. This example has only used two texture filters. Recently one of us 1391 developed a novel texture model which incorporates Gabor features into a probability model and is able to synthesize a large number of real textures. Hopefully, with this model it will be possible to perform a normalization between texture bands, as we did for the color bands, and reduce the effect of gradients caused by shadows and geometric effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CQNCLUSIQN</head><p>We have designed a novel algorithm, region competition, for image segmentation by minimizing a generalized MDL criterion. This algorithm combines some of the most attractive features of snakes/balloons and region growing. We have successfully demonstrated our approach on gray level images, color images, and texture images. For color images we have developed new ways to: 1) eliminate intensity gradients due to shadows and geometric factors and 2) to detect specularities.</p><p>It is possible to extend this work by 1) integrating gray level, color, and texture cues, 2) integrating the filtering approaches to locate the edge 3) using this algorithm as a front end for our object rec-more precisely.</p><p>ognition systems <ref type="bibr">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>In the preceding sections, we took functional derivatives of integrals along contours and integrals over regions. This Appendix shows how to perform these derivatives.</p><p>Consider:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>+ 1 INTRODUCTION</head><label>1</label><figDesc>MAGE segmentation is a critical problem of early vision I and it has been intensively studied. Approaches to image segmentation can be roughly classified into four groups: 1) Local filtering approaches such as the Canny edge 2) Snake [191 and Balloon methods [61, [71, [371,[321, 3) Region growing and merging techniques 121, [l], [26], and 4) Global optimization approaches based on energy functions [281 or Bayesian 1101, [31, [lll and MDL (Minimum Description Length) criteria 1231, [20], 1181.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fia. 1 .</head><label>1</label><figDesc>The shadowed areas show the imaae domi ninima.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The forces acting on the contour: (a) the smoothing force, (b the statistics force at a boundary point, (c) the statistics force at a junc tion point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>First</head><label></label><figDesc>, the statistics force at each boundary point (x, y) will depend on P(&amp;) I p, d, in other words on the probability that I(x,y) on the boundary can be generated by a Gaussian F distribution N ( p , 0 2 ] .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Two possible distributions for adjacent regions: (a) Solid lines show two Gaussian distributions with large overlap due to noise fluctuation, the shadowed area displays the classification errors. Dash lines show the distribution after using window sampling. (b) Two Gaussian distributions with same mean but different variances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Each pixel is coded by a multiplicative mixture distribution with zi being the shaded proportions inside the window.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 5</head><label>5</label><figDesc>Fig 5 We plot the means, E[l(x)], of the distributions of the pixels near the boundary r between R, and R, If we use standard MDL with Gaussian distributions then there IS a step edge in ,U at r, see dashed line By constrast, our generalized energy softens the edge by allowing the mean to change smoothly from , U, to ,U within the window from l--0/2 to r + wi2, see continuous curve The variances will behave similarly</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6a is</head><label></label><figDesc>Fig. 6a is a 100 x 100 image partitioned into two regions by a S-shaped curve. The intensities in these two regions are generated randomly from two Gaussian distributions with identical means: N(128, 10') and N(128, 35'). Suppose the image is initially segmented by a slanted straight line, see Fig. 6b. Then the motion of the regions at iteration steps t = 0,20,30,50 are shown in Figs. 6b, 6c, 6d, and 6e, respectively. Finally, Fig.6fshows how the boundary moves if we drop the last term in<ref type="bibr" target="#b20">(20)</ref>. Thus if we do not test the variance then the edge just moves to the low-right corner and disappears. This results in an incorrect segmentation with the image being perceived as a single region. For this image, we use a circular window Wwhich contains 32 pixels. Fig.7ais a 150 x 150 image consists of four regions whose intensities are generated randomly from four Gaus-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Two regions with identical means but different variances. See text for interpretation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The competition of good and bad seed regions. See text for interpretation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9a showsFig. 9 .</head><label>9</label><figDesc>Fig. 9. The expectations and variances of the statistics force 4, ) . See text for interpretation of (a), (b). In (c) and (d), the solid lines show E[?,)], and the dashed lines show the confidence intervals, in other words, upper and lower bounds for the force fluctuations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>I ( 0 ,</head><label>0</label><figDesc>Fig. 10. When an ellipse window is used with the same size (area) m, the uncertainty interval shown by the thick line segment becomes smaller.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>5. 1</head><label>1</label><figDesc>The Color Model If we include specularity in the image formation process then the standard color dichromatic reflection model is 1211: (y , g', b*, I;x,y,) = arg min r,g,b,I (X,Y)ER, approaches. If seed 5 was not present the segmentation would be incorrect, see 1411.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. The domino effect converting bad seeds into good ones. The image is in Fig. 7a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>the minimum must satisfy (minimizing (29)) with respect to J and I(?)): (30) where we have imposed the normalization constraint Y*' + *2 *2 b +g = l .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The Color models: (a) fitting the irradiance equation, (b) residuals distribution for homogeneous color regions, (c) residual distribution for a highlight region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>For a pixel</head><label></label><figDesc>p = (U, v) on the boundary of region R, we (X,Y)ER, R(xrY) minimizing the MDL criterion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>mP(</head><label></label><figDesc>Yjl pi, ci, (U;, g;, b:)) = j=1 1 where C, = , and "tu(.)" denotes matrix trace. ( ~) " l l ~, l l mi 2 Thus the statistics force generated by single X, at (x, y) is f , . iil, with: 1 J = -,(log(Zs) + logllC,I/ + (7 -p,)z;l(Yp,) + iU(Z,'S)) (35)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 13 .</head><label>13</label><figDesc>Fig.13. Cross-sections for the woman image, see Fig.14b. From top to bottom, we show the cross-sections on the face, torso, and arms, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Segmentation of a color image of a woman. See text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Fig. 16. Left: A squirrel sitting on the grass displayed as gray image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>deviation o and * denotes convolution, (I,, Iy) = VI is the gradient of image I. This statistic captures the local orientation of the texture elements (or textons).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>17  </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>shows the ellipse corresponding to various texture regions with &amp;, &amp;, 8 listed on the right-hand side.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. The statistics and histograms of G, * /x, Gz * /y on several regions of the texture image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Segmentation of a texture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Chun Zhu a n d Alan Yuille Abstract-We present a novel statistical and variational approach to image segmentation based on a new algorithm named region</figDesc><table><row><cell>mpetition: Unifying Snakes,</cell></row><row><cell>egion Growin and Bayes/MDL for</cell></row><row><cell>Image Segmentation</cell></row><row><cell>S o n g</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>analyzing the distribution (histogram) of residuals {X} in plane p over our dataset of regions with constant albedo, we found that if the region size is large enough, say larger than 100 pixels, then these residuals can typically be modeled by a 2D normal distribution N(p, C) with p very close to zero. In our experiments, we calculate the 2 x 2 covariance matrix C. C can be intuitively represented by an ellipse in plane p with its eigenvalues 4, &amp; (4 2 &amp;) as the squared long and short axes of the ellipse, and the rotational angle 8 as the orientation of the ellipse.</figDesc><table><row><cell>11</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>~G</cell><cell>,</cell><cell>b</cell><cell>~. ~~</cell><cell>= ~~.</cell></row><row><cell>... ..i. ..i, .... . . . . . ; . . 'i.;..: _., . , i ;;:&gt;, :...:.,:., . ... .. . . . : . . .. ..</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>8 . . . . ... . ..; i . ....i.. .... .. .</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>([-PI2</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>It is possible to use coding theory to derive alternative costs [311, [201. However, we argue that these costs should be determined by the properties of real images, rather than from coding theory, and should be found empirically[391, [401.  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>4. We assume q has uniform a priori distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>This two step iteration process is similar to the well-known EM algorithm which can be re-expressed as two steepest descent stages[14]   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>It is a pleasure to acknowledge many highly stimulating discussions with David Mumford and Tai Sing Lee. Tai Sing Lee worked with us on the texture section and is a coauthor for the version of this work which appeared in ICCV. The authors also thank Yingnian Wu for his consulting role in statistics. We would also like to thank some anonymous referees and an editor, Byron Dom, for some extremely detailed and helpful reviewing which greatly improved the paper. The first author was supported by National Science Foundation grant DMS-91-21266 to David Mumford, and this work was also supported in part by the Brown/Harvard/MIT Center for Intelligent Control Systems with U.S. Army Research Office grant number DAAL03-86-K-0171, and ARPA for an Air Force contract F49620-92-J-0466 to Alan Yuille.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>m-,,i = i ix f(x, Y) dxdy, <ref type="bibr">(37)</ref> where &amp;) = aR = (qS), y(s)) is the boundary contour of the region R, with 0 5 s 5 4 is the arc-length.</p><p>states that: for a planar region R, (P(x,y), Q(x,y)) is any vector field with continuous first order derivatives, then 12 Green's theorem where ',.'' denotes differentiation with respect to s, and For example, and 0 will satisfy the above requirement.</p><p>we can write (37) as Thus, using (381, and let L(x, 35, y, y) = Q(x, y)i + P(x, y)y (39) by choosing L = $W. It is straightforward, for example, to check that the functional derivative of the line integral J2 is -xii.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Seeded Region Growing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattevn Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1994-06">June 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Segmenting Images Using Localizing Histograms and Region Merging</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Beveridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l 1. Compt. Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Visual Reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Computational Approach to Edge Detection</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deformable Boundary Finding Influenced by Region Homogeneity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Straib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pvoc. CVPR</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Seattle</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m">A Finite Element Method Applied to New Active Contour Models and 3D Reconstruction From Cross Sections</title>
		<meeting><address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note>Proc. Third Int&apos;l Conf. Computer Vision ICCVSO</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Active Contour Models and Balloons</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991-03">Mar. 1991</date>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
	<note>CVGIP: I m g e Understanding</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<title level="m">Statistical Pattevn Recognition</title>
		<meeting><address><addrLine>San Diego, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Common Framework for Image Segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l 1. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tvansactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Boundary Detection by Constrained Optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattevn Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="609" to="628" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Heat Equation Shrinking Convex Plane Curves</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">1. Differential Geometry</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="285" to="314" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Foundations of Applied Mathematics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Greenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, N.J.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Another Interpretation for the EM Algorithm for Mixture Distributions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hathaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Pvob. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="53" to="56" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Segmenting Images Using Normalized Color</title>
		<author>
			<persName><forename type="first">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Systems, Man, nnd Cybernetics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Compact Region Extraction Using Weighted Pixel Linking in a Pyramid</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="222" to="229" />
			<date type="published" when="1984-03">Mar. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wichem</surname></persName>
		</author>
		<title level="m">Applied Multivariate Statistical Analysis</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Englewood Cliffs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Fast Algorithm for MDL-Based Multi-Band Image Segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kanungo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Comp. Vision and Putt. Recognition, CVPR</title>
		<meeting>Comp. Vision and Putt. Recognition, CVPR</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Snakes: Active Contour Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. lnt&apos;l Conf. Computer Vision, ICCV87</title>
		<meeting>lnt&apos;l Conf. Computer Vision, ICCV87<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Map Representations and Coding-B&apos;ased Priors for Segmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keeler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR<address><addrLine>Maui, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Physical Approach to Color Image Understanding</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Klinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">lnt&apos;l J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="7" to="38" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Multiscale Algorithm for lmage Segmentation by Variational Approach</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koepfler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">S l A M J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="282" to="299" />
			<date type="published" when="1994-02">Feb. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Constructing Simple Stable Descriptions for Image Partitioning</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Leclerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int&apos;l]. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="73" to="102" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Region Growing Using the MDL Principle</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Leclerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DARPA lnzage Understanding Workshop</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling Light Reflection for Color Computer Vision</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Breneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Schulte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">I E E E Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="402" to="409" />
			<date type="published" when="1990-04">Apr. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Segmentation of Range lmages as the Search for Geometric Parametric Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Int&apos;l</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Variational Methods in Image Segnzentation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Morel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Solimini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Birkhauser Publishing Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimal Approximations by Piecewise Smooth Functions and Associated Variational Problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="577" to="684" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">From 1991 to 1992 he worked as a research assistant at USTC. He received his MS and PhD degrees in computer science from Haward University in 1994 and 1996, respectively. Since February 1996 he has been a postdoctoral fellow at the Harvard Robotics Laboratory. His research is concentrated in the areas of computational and human vision. statistical modelina. and theoretical neuroscience. Currently he is working with David Mimford, investigating a general unified theory for computational vision</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Extraction of Deformable Part Mod</title>
		<imprint>
			<date type="published" when="1986">1991. 1986</date>
		</imprint>
		<respStmt>
			<orgName>University of Science and Technology of China</orgName>
		</respStmt>
	</monogr>
	<note>Alan Yuille received his BA in mathematics at the University of Cambridge in 1976 He completed his PhD in theoretical physics at the University of Cambridge in 1980 and was on the physics faculty at the University of Texas at Austin and the Institute for Theoretical Physics at the University of California at Santa Barbara From 1982 to 1986 he worked at the Artificial Intelligence Laboratory at MIT From. to 1995 he worked at the Division of Applied Sciences at Harvard University In 1995 he joined the Smith-Kettlewell Eye Research Institute in San Francisco He has published more than 50 papers and two books on topics in vision, physics, and neural networks. els,&quot; lnt&apos;l</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modelling by Shortest Data Description</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="465" to="471" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
		<title level="m">Stochastic Complexity in Statistical Inquiry</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Region-Based Strategies for Active Contour Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ronfard</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Int&apos;l</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><surname>Comp</surname></persName>
		</author>
		<author>
			<persName><surname>Vision</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">O(1og n) Bimodality Analysis</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Philips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Sher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="741" to="746" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Vector Signal Processing Approach to Color</title>
		<author>
			<persName><forename type="first">K.-K</forename><surname>Sung</surname></persName>
		</author>
		<idno>1349</idno>
	</analytic>
	<monogr>
		<title level="j">MIT Artificial Intelligence Laboratory</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Existence and Regularity of Solutions to a Variational Problem of Mumford and Shah</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAMJ</title>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note>Optimization</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Granlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Uncertainty Principle in Image Processing</title>
		<imprint>
			<date type="published" when="1984-11">Nov. 1984</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Robust Active Contours With Insensitive Parameters</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Segawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tsuji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="879" to="884" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">FORMS: A Flexible Object Recognition and Modelling System,&quot; Int&apos;l ]. Computer Vision</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">FRAME (Filters, Random Fields, and Maximum Entropy): Towards a Unified Theory for Texture Modelling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. lnt&apos;l Conf Computer Vision and Pattern Recognition</title>
		<meeting>lnt&apos;l Conf Computer Vision and Pattern Recognition<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-06">June 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning and Sampling the Prior Distribution for Visual Computation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mumford</surname></persName>
		</author>
		<idno>95-3</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="report_type">Harvard Robotics Laboratory Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A Unified Theory for Image Segmentation: Region Competition and Its Analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno>95-7</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Harvard Robotics Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
