<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ahmed</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
							<email>ahmedmalaa@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical Engineering Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
							<email>mihaela.vanderschaar@eng.ox.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">802628445A5DFD66EDFC85B5FA817B5A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Predicated on the increasing abundance of electronic health records, we investigate the problem of inferring individualized treatment effects using observational data. Stemming from the potential outcomes model, we propose a novel multi-task learning framework in which factual and counterfactual outcomes are modeled as the outputs of a function in a vector-valued reproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian method for learning the treatment effects using a multi-task Gaussian process (GP) with a linear coregionalization kernel as a prior over the vvRKHS. The Bayesian approach allows us to compute individualized measures of confidence in our estimates via pointwise credible intervals, which are crucial for realizing the full potential of precision medicine. The impact of selection bias is alleviated via a risk-based empirical Bayes method for adapting the multi-task GP prior, which jointly minimizes the empirical error in factual outcomes and the uncertainty in (unobserved) counterfactual outcomes. We conduct experiments on observational datasets for an interventional social program applied to premature infants, and a left ventricular assist device applied to cardiac patients wait-listed for a heart transplant. In both experiments, we show that our method significantly outperforms the state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Clinical trials entail enormous costs: the average costs of multi-phase trials in vital therapeutic areas such as the respiratory system, anesthesia and oncology are $115.3 million, $105.4 million, and $78.6 million, respectively <ref type="bibr" target="#b0">[1]</ref>. Moreover, due to the difficulty of patient recruitment, randomized controlled trials often exhibit small sample sizes, which hinders the discovery of heterogeneous therapeutic effects across different patient subgroups <ref type="bibr" target="#b1">[2]</ref>. Observational studies are cheaper and quicker alternatives to clinical trials <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. With the advent of electronic health records (EHRs), currently deployed in more than 75% of hospitals in the U.S. according to the latest ONC data brief <ref type="foot" target="#foot_0">1</ref> , there is a growing interest in using machine learning to infer heterogeneous treatment effects from readily available observational data in EHRs. This interest glints in recent initiatives such as STRATOS <ref type="bibr" target="#b2">[3]</ref>, which focuses on guiding observational medical research, in addition to various recent works on causal inference from observational data developed by the machine learning community <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>.</p><p>Motivated by the plethora of EHR data and the potentiality of precision medicine, we address the problem of estimating individualized treatment effects (i.e. causal inference) using observational data. The problem differs from standard supervised learning in that for every subject in an observational cohort, we only observe the "factual" outcome for a specific treatment assignment, but never observe the corresponding "counterfactual" outcome <ref type="foot" target="#foot_2">2</ref> , without which we can never know the true treatment effect <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Selection bias creates a discrepancy in the feature distributions for the treated and control patient groups, which makes the problem even harder. Much of the classical works have focused on the simpler problem of estimating average treatment effects via unbiased estimators based on propensity score weighting (see <ref type="bibr" target="#b13">[14]</ref> and the references therein). More recent works learn individualized treatment effects via regression models that view the subjects' treatment assignments as input features <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. We provide a thorough review on these works in Section 3.</p><p>Contribution At the heart of this paper lies a novel conception of causal inference as a multi-task learning problem. That is, we view a subject's potential outcomes as the outputs of a vectorvalued function in a reproducing kernel Hilbert space (vvRKHS) <ref type="bibr" target="#b14">[15]</ref>. We propose a Bayesian approach for learning the treatment effects through a multi-task Gaussian process (GP) prior over the populations' potential outcomes. The Bayesian perspective on the multi-task learning problem allows reasoning about the unobserved counterfactual outcomes, giving rise to a loss function that quantifies the Bayesian risk of the estimated treatment effects while taking into account the uncertainty in counterfactual outcomes without explicit propensity modeling. Furthermore, we show that optimizing the multi-task GP hyper-parameters via risk-based empirical Bayes <ref type="bibr" target="#b15">[16]</ref> is equivalent to minimizing the empirical error in the factual outcomes, with a regularizer that is proportional to the posterior uncertainty (variance) in counterfactual outcomes. We provide a feature space interpretation of our method showing its relation to previous works on domain adaptation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>, empirical risk minimization <ref type="bibr" target="#b12">[13]</ref>, and tree-based learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>The Bayesian approach allows us to compute individualized measures of confidence in our estimates via pointwise credible intervals. With the exception of <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b8">[9]</ref>, all previous works do not associate their estimates with confidence measures, which hinders their applicability in formal medical research. While Bayesian credible sets do not guarantee frequentist coverage, recent results on the "honesty" (i.e. frequentist coverage) of adaptive credible sets in nonparametric regression may extend to our setting <ref type="bibr" target="#b15">[16]</ref>. In particular, [ <ref type="bibr">Theorem 1,</ref><ref type="bibr" target="#b15">16]</ref> shows that -under some extrapolation conditions-adapting a GP prior via risk-based empirical Bayes guarantees honest credible sets: investigating the validity of these results in our setting is an interesting topic for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Setup</head><p>We consider the setting in which a specific treatment is applied to a population of subjects, where each subject i possesses a d-dimensional feature X i ∈ X , and two (random) potential outcomes</p><formula xml:id="formula_0">Y (1) i , Y (0) i ∈ R that are drawn from a distribution (Y (1) i , Y (0) i )|X i = x ∼ P(.|X i = x)</formula><p>, and correspond to the subject's response with and without the treatment, respectively. The realized causal effect of the treatment on subject i manifests through the random variable (Y</p><formula xml:id="formula_1">(1) i -Y (0) i ) | X i = x.</formula><p>Hence, we define the individualized treatment effect (ITE) for subjects with a feature X i = x as</p><formula xml:id="formula_2">T (x) = E Y (1) i -Y (0) i X i = x . (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>Our goal is to conduct the causal inference task of estimating the function T (x) from an observational dataset D, which typically comprises n independent samples of the random tuple</p><formula xml:id="formula_4">{X i , W i , Y<label>(Wi) i</label></formula><p>}, where W i ∈ {0, 1} is a treatment assignment indicator that indicates whether or not subject i has received the treatment under consideration. The outcomes Y (Wi) i and Y</p><p>(1-Wi) i are known as the factual and the counterfactual outcomes, respectively <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref>. Treatment assignments are generally dependent on features, i.e. W i ⊥ ⊥ X i . The conditional distribution P(W i = 1|X i = x), also known as the propensity score of subject i <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, reflects the underlying policy for assigning the treatment to subjects. Throughout this paper, we respect the standard assumptions of unconfoundedness (or ignorability) and overlap: this setting is known in the literature as the "potential outcomes model with unconfoundedness" <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>.</p><p>Individual-based causal inference using observational data is challenging. Since we only observe one of the potential outcomes for every subject i, we never observe the treatment effect</p><formula xml:id="formula_5">Y (1) i -Y (0) i</formula><p>for any of the subjects, and hence we cannot resort to standard supervised learning to estimate T (x). Moreover, the dataset D exhibits selection bias, which may render the estimates of T (x) inaccurate if the treatment assignment for individuals with X i = x is strongly biased (i.e. P(W i = 1|X i = x) is close to 0 or 1). Since our primary motivation for addressing this problem comes from its application potential in precision medicine, it is important to associate our estimate of T (.) with a pointwise measure of confidence in order to properly guide therapeutic decisions for individual patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-task Learning for Causal Inference</head><p>Vector-valued Potential Outcomes Function We adopt the following signal-in-white-noise model for the potential outcomes:</p><formula xml:id="formula_6">Y (w) i = f w (X i ) + i,w , w ∈ {0, 1},<label>(2)</label></formula><p>where i,w ∼ N (0,</p><formula xml:id="formula_7">σ 2 w ) is a Gaussian noise variable. It follows from (2) that E[Y (w) i | X i = x] = f w (x)</formula><p>, and hence the ITE can be estimated as T (x) = f1 (x) -f0 (x). Most previous works that estimate T (x) via direct modeling learn a single-output regression model that treats the treatment assignment as an input feature, i.e. f w (x) = f (x, w), f (., .) : X × {0, 1} → R, and estimate the ITE as T (x) = f (x, 1) -f (x, 0) <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. We take a different perspective by introducing a new multi-output regression model comprising a potential outcomes (PO) function f (.) : X → R 2 , with d inputs (features) and 2 outputs (potential outcomes); the ITE estimate is the projection of the estimated PO function on the vector e = [-1 1] T , i.e. T (x) = f T (x) e.</p><p>Consistent pointwise estimation of the ITE function T (x) requires restricting the PO function f (x) to a smooth function class <ref type="bibr" target="#b8">[9]</ref>. To this end, we model the PO function f (x) as belonging to a vector-valued Reproducing Kernel Hilbert Space (vvRKHS) H K equipped with an inner product ., . H K , and with a reproducing kernel K : X × X → R 2×2 , where K is a (symmetric) positive semi-definite matrix-valued function <ref type="bibr" target="#b14">[15]</ref>. Our choice for the vvRKHS is motivated by its algorithmic advantages; by virtue of the representer theorem, we know that learning the PO function entails estimating a finite number of coefficients evaluated at the input points {X i } n i=1 <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-task Learning</head><p>The vector-valued model for the PO function conceptualizes causal inference as a multi-task learning problem. That is,</p><formula xml:id="formula_8">D = {X i , W i , Y<label>(Wi) i</label></formula><p>} n i=1 can be thought of as comprising training data for two learning tasks with target functions f 0 (.) and f 1 (.), with W i acting as the "task index" for the i th training point <ref type="bibr" target="#b14">[15]</ref>. For an estimated PO function f (x), the true loss functional is</p><formula xml:id="formula_9">L( f ) = x∈X f T (x) e -T (x) 2 • P(X = x) dx.<label>(3)</label></formula><p>The loss functional in (3) is known as the precision in estimating heterogeneous effects (PEHE), and is commonly used to quantify the "goodness" of T (x) as an estimate of T (x) <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b7">8]</ref>. A conspicuous challenge that arises when learning the "PEHE-optimal" PO function f is that we cannot compute the empirical PEHE for a particular f ∈ H K since the treatment effect samples {Y</p><formula xml:id="formula_10">(1) i -Y<label>(0)</label></formula><p>i } n i=1 are not available in D. On the other hand, using a loss function that evaluates the losses of f 0 (x) and f 1 (x) separately (as in conventional multi-task learning [Sec. <ref type="bibr">3.2, 15]</ref>) can be highly problematic: in the presence of a strong selection bias, the empirical loss for f (.) with respect to factual outcomes may not generalize to counterfactual outcomes, leading to a large PEHE loss. In order to gain insight into the structure of the optimal PO function, we consider an "oracle" that has access to counterfactual outcomes. For such an oracle, the finite-sample empirical PEHE is</p><formula xml:id="formula_11">L( f ; K, Y (W) , Y (1-W) ) = 1 n n i=1 f T (X i ) e -(1 -2W i ) Y (1-Wi) i -Y (Wi) i 2 ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_12">Y (W) = [Y (Wi) i ] i and Y (1-W) = [Y (1-Wi) i ] i . When Y (1-W)</formula><p>is accessible, the PEHEoptimal PO function f (.) is given by the following representer Theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1 (Representer Theorem for Oracle Causal Inference). For any f</head><formula xml:id="formula_13">* ∈ H K satisfying f * = arg min f ∈H K L( f ; K, Y (W) , Y (1-W) ) + λ || f || 2 H K , λ ∈ R + ,<label>(5)</label></formula><p>we have that T * (.) = e T f * (.) ∈ span{ K(., X 1 ), . . . , K(., X n )}, where K(., .) = e T K(., .) e. That is, T * (.) admits a representation T * (.) =</p><formula xml:id="formula_14">n i=1 α i K(., X i ), α = [α 1 , . . . , α n ] T , where α = ( K(X, X) + n λ I) -1 ((1 -2W) (Y (1-W) -Y (W) )),<label>(6)</label></formula><p>where denotes component-wise product, K(X, X)</p><formula xml:id="formula_15">= ( K(X i , X j )) i,j , W = [W 1 , . . . , W n ] T .</formula><p>A Bayesian Perspective Theorem 1 follows directly from the generalized representer Theorem <ref type="bibr" target="#b16">[17]</ref> (A proof is provided in <ref type="bibr" target="#b16">[17]</ref>), and it implies that regularized empirical PEHE minimization in vvRKHS is equivalent to Bayesian inference with a Gaussian process (GP) prior [Sec. <ref type="bibr">2.2, 15]</ref>. Therefore, we can interpret T * (.) as the posterior mean of T (.) given a GP prior with a covariance kernel K, i.e. T ∼ GP(0, K). We know from Theorem 1 that K = e T Ke, hence the prior on T (.) is equivalent to a multi-task GP prior on the PO function f (.) with a kernel K, i.e. f ∼ GP(0, K).</p><p>The Bayesian view of the problem is advantageous for two reasons. First, as discussed earlier, it allows computing individualized (pointwise) measures of uncertainty in T (.) via posterior credible intervals. Second, it allows reasoning about the unobserved counterfactual outcomes in a Bayesian fashion, and hence provides a natural proxy for the oracle learner's empirical PEHE in <ref type="bibr" target="#b3">(4)</ref>. Let θ ∈ Θ be a kernel hyper-parameter that parametrizes the multi-task GP kernel K θ . We define the Bayesian PEHE risk R(θ, f ; D) for a point estimate f as follows</p><formula xml:id="formula_16">R(θ, f ; D) = E θ L( f ; K θ , Y (W) , Y (1-W) ) D .<label>(7)</label></formula><p>The expectation in ( <ref type="formula" target="#formula_16">7</ref>) is taken with respect to Y (1-W) |D. The Bayesian PEHE risk R(θ, f ; D) is simply the oracle learner's empirical loss in (4) marginalized over the posterior distribution of the unobserved counterfactuals Y (1-W) , and hence it incorporates the posterior uncertainty in counterfactual outcomes without explicit propensity modeling. The optimal hyper-parameter θ * and interpolant f * (.) that minimize the Bayesian PEHE risk are given in the following Theorem.</p><p>Theorem 2 (Risk-based Empirical Bayes). The minimizer</p><formula xml:id="formula_17">( f * , θ * ) of R(θ, f ; D) is given by f * = E θ * [ f | D ], θ * = arg min θ∈Θ      Y (W) -E θ [ f | D ] 2 2</formula><p>Empirical factual error</p><formula xml:id="formula_18">+ Var θ [ Y (1-W) | D ] 1 Posterior counterfactual variance     </formula><p>, where Var θ [.|.] is the posterior variance and . p is the p-norm.</p><p>The proof is provided in Appendix A. Theorem 2 shows that hyper-parameter selection via risk-based empirical Bayes is instrumental in alleviating the impact of selection bias. This is because, as the Theorem states, θ * minimizes the empirical loss of f * with respect to factual outcomes, and uses the posterior variance of the counterfactual outcomes as a regularizer. Hence, θ * carves a kernel that not only fits factual outcomes, but also generalizes well to counterfactuals. It comes as no surprise that</p><formula xml:id="formula_19">f * = E θ * [ f | D ]; E θ * [ f | D, Y (1-W)</formula><p>] is equivalent to the oracle's solution in Theorem 1, hence by the law of iterated expectations,</p><formula xml:id="formula_20">E θ * [ f | D ] = E θ * [ E θ * [ f | D, Y (1-W) ] | D ]</formula><p>is the oracle's solution marginalized over the posterior distribution of counterfactuals.</p><p>Related Works A feature space interpretation of Theorem 2 helps creating a conceptual equivalence between our method and previous works. For simplicity of exposition, consider a finite-dimensional vvRKHS in which the PO function resides: we can describe such a space in terms of a feature map Φ : X → R p , where K(x, x ) = Φ(x), Φ(x ) [Sec. <ref type="bibr">2.3, 15]</ref>. Every PO function f ∈ H K can be represented as f = α, Φ(x) , and hence the two response surfaces f o (.) and f 1 (.) are represented as hyperplanes in the transformed feature space as depicted in Fig. <ref type="figure" target="#fig_0">1</ref> (right). The risk-based empirical Bayes method attempts to find a feature map Φ and two hyperplanes that best fit the factual outcomes (right panel in Fig. <ref type="figure" target="#fig_0">1</ref>) while minimizing the posterior variance in counterfactual outcomes (middle panel in Fig. <ref type="figure" target="#fig_0">1</ref>). This conception is related to that of counterfactual regression <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>, which builds on ideas from co-variate shift and domain adaptation <ref type="bibr" target="#b18">[19]</ref> in order to jointly learn a response function f and a "balanced" representation Φ that makes the distributions P(Φ(X i = x)|W i = 1) and P(Φ(X i = x)|W i = 0) similar. Our work differs from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref> in the following aspects. First, our Bayesian multi-task formulation provides a direct estimate of the PEHE: ( <ref type="formula" target="#formula_16">7</ref>) is an unbiased estimator of the finite-sample version of (3). Contrarily, [Eq. 2, 6] creates a coarse proxy for the PEHE by using the nearest-neighbor factual outcomes in replacement of counterfactuals, whereas [Eq. <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b7">8]</ref> optimizes a generalization bound which may largely overestimate the true PEHE for particular hypothesis classes. <ref type="bibr" target="#b5">[6]</ref> optimizes the algorithm's hyper-parameters by assuming (unrealistically) that counterfactuals are available in a held-out sample, whereas <ref type="bibr" target="#b7">[8]</ref> uses an ad hoc nearest-neighbor approximation. Moreover, unlike the case in <ref type="bibr" target="#b5">[6]</ref>, our multi-task formulation protects the interactions between W i and X i from being lost in high-dimensional feature spaces.</p><p>Most of the previous works estimate the ITE via co-variate adjustment (G-computation formula) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b19">20]</ref>; the most remarkable of these methods are the nonparametric Bayesian additive regression trees <ref type="bibr" target="#b4">[5]</ref> and causal forests <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>. We provide numerical comparisons with both methods in Section 5. <ref type="bibr" target="#b10">[11]</ref> also uses Gaussian processes, but with the focus of modeling treatment response curves over time. Counterfactual risk minimization is another framework that is applicable only when the propensity score P(W i = 1|X i = x) is known <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. <ref type="bibr" target="#b24">[25]</ref> uses deep networks to infer counterfactuals, but requires some of the data to be drawn from a randomized trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Causal Multi-task Gaussian Processes (CMGPs)</head><p>In this Section, we provide a recipe for Bayesian causal inference with the prior f ∼ GP(0, K θ ). We call this model a Causal Multi-task Gaussian Process (CMGP).</p><p>Constructing the CMGP Kernel As it is often the case in medical settings, the two response surfaces f 0 (.) and f 1 (.) may display different levels of heterogeneity (smoothness), and may have different relevant features. Standard intrinsic coregionalization models for constructing vector-valued kernels impose the same covariance parameters for all outputs <ref type="bibr" target="#b17">[18]</ref>, which limits the interaction between the treatment assignments and the patients' features. To that end, we construct a linear model of coregionalization (LMC) <ref type="bibr" target="#b14">[15]</ref>, which mixes two intrinsic coregionalization models as follows</p><formula xml:id="formula_21">K θ (x, x ) = A 0 k 0 (x, x ) + A 1 k 1 (x, x ),<label>(8)</label></formula><p>where k w (x, x ), w ∈ {0, 1}, is the radial basis function (RBF) with automatic relevance determination, i.e.</p><formula xml:id="formula_22">k w (x, x ) = exp -1 2 (x -x ) T R -1 w (x -x ) , R w = diag( 2 1,w ,<label>2 2</label></formula><p>,w , . . . , 2 d,w ), with d,w being the length scale parameter of the d th feature in k w (., .), whereas A 0 and A 1 are given by</p><formula xml:id="formula_23">A 0 = β 2 00 ρ 0 ρ 0 β 2 01 , A 1 = β 2 10 ρ 1 ρ 1 β 2 11 .<label>(9)</label></formula><p>The parameters (β 2 ij ) ij and (ρ i ) i determine the variances and correlations of the two response surfaces f 0 (x) and f 1 (x). The LMC kernel introduces degrees of freedom that allow the two response surfaces to have different covariance functions and relevant features. When β 00 &gt;&gt; β 01 and β 11 &gt;&gt; β 10 , the length scale parameter d,w can be interpreted as the relevance of the d th feature to the response surface f w (.). The set of all hyper-parameters is θ = (σ 0 , σ 1 , R 0 , R 1 , A 0 , A 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adapting the Prior via Risk-based Empirical Bayes</head><p>In order to avoid overfitting to the factual outcomes Y (W) , we evaluate the empirical error in factual outcomes via leave-one-out cross-validation (LOO-CV) with Bayesian regularization <ref type="bibr" target="#b23">[24]</ref>; the regularized objective function is thus given by R(θ;</p><formula xml:id="formula_24">D) = η 0 Q(θ) + η 1 θ 2 2 ,</formula><p>where</p><formula xml:id="formula_25">Q(θ) = Var θ [ Y (1-W) | D ] 1 + n i=1 Y (Wi) i -E θ [f (X i ) | D -i ] 2 ,<label>(10)</label></formula><p>and D -i is the dataset D with subject i removed, whereas η 0 and η 1 are the Bayesian regularization parameters. For the second level of inference, we use the improper Jeffrey's prior as an ignorance prior for the regularization parameters, i.e. P(η 0 ) ∝ 1 η0 and P(η 1 ) ∝ 1 η1 . This allows us to integrate out the regularization parameters [Sec. <ref type="bibr">2.1, 24]</ref>, leading to a revised objective function</p><formula xml:id="formula_26">R(θ; D) = n log(Q(θ)) + (10 + 2 d) log( θ<label>2</label></formula><p>2 ) [Eq. ( <ref type="formula">15</ref>), 24]. It is important to note that LOO-CV with squared loss has often been considered to be unfavorable in ordinary GP regression as it leaves one degree of freedom undetermined [Sec. <ref type="bibr">5.4.2, 5]</ref>; this problem does not arise in our setting since the term Var θ [ Y (1-W) | D ] 1 involves all the variance parameters, and hence the objective function R(θ; D) does not depend solely on the posterior mean.</p><p>Causal Inference via CMGPs Algorithm 1 sums up the entire causal inference procedure. It first invokes the routine Initialize-hyperparameters, which uses the sample variance and upcrossing rate of Y (W) to initialize θ (see Appendix B). Such an automated initialization procedure allows running our method without any user-defined inputs, which facilitates its usage by researchers conducting observational studies. Having initialized θ (line 3), the algorithm finds a locally optimal θ * using gradient descent (lines 5-12), and then estimates the ITE function and the associated credible intervals (lines <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>.</p><formula xml:id="formula_27">(X = [{X i } Wi=0 , {X i } Wi=1 ] T , Y = [{Y (Wi) i } Wi=0 , {Y (Wi) i } Wi=1 ] T , Σ = diag(σ 2 0 I n-n1 , σ 2 1 I n1 ), n 1 = i W i , erf(x) = 1 √ π x</formula><p>-x e -y 2 dy, and</p><formula xml:id="formula_28">K θ (x) = (K θ (x, X i )) i .)</formula><p>We use a re-parametrized version of the Adaptive Moment Estimation (ADAM) gradient descent algorithm for optimizing θ <ref type="bibr" target="#b20">[21]</ref>; we first apply a transformation φ = exp(θ) to ensure that all covariance parameters remain positive, and then run ADAM to minimize R(log(φ t ); D). The ITE function is estimated as the posterior mean of the CMGP (line 14). The credible interval C γ (x) with a Bayesian coverage of γ for a subject with feature x is defined as P θ (T (x) ∈ C γ (x)) = γ, and is computed straightforwardly using the error function of the normal distribution (lines <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. The computational burden of Algorithm 1 is dominated by the O(n 3 ) matrix inversion in line 13; for large observational studies, this can be ameliorated using conventional sparse approximations [Sec. <ref type="bibr">8.4, 23]</ref>. </p><formula xml:id="formula_29">φ 0 ← exp(θ), t ← 0, mt ← 0, vt ← 0, 5: repeat 6: mt+1 ← β1 mt + (1 -β1) • φt ∇ φ R(log(φt); D) 7: vt+1 ← β2 vt +(1-β2) • (φt ∇ φ R(log(φt); D)) 2 8: mt+1 ← mt/(1 -β t 1 ), vt+1 ← vt/(1 -β t 2 ) 9: φt+1 ← φt exp -η • mt+1/( √ vt+1 + ) 10: t ← t + 1 11: until convergence 12: θ * ← log(φt-1) 13: Λ θ * ← (K θ * (X, X) + Σ) -1 14: T (x) ← (K T θ * (x) Λ θ * Y) T e 15: V(x) ← K θ * (x, x) -K θ * (x) Λ θ * K T θ * (x) 16: Î(x) ← erf -1 (γ) (2e T V(x)e) 1 2 17: Cγ(x) ← [ T (x) -Î(x), T (x) + Î(x)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Since the ground truth counterfactual outcomes are never available in real-world observational datasets, evaluating causal inference algorithms is not straightforward. We follow the semi-synthetic experimental setup in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref>, where covariates and treatment assignments are real but outcomes are simulated. Experiments are conducted using the IHDP dataset introduced in <ref type="bibr" target="#b4">[5]</ref>. We also introduce a new experimental setup using the UNOS dataset: an observational dataset involving end-stage cardiovascular patients wait-listed for heart transplantation. Finally, we illustrate the clinical utility and significance of our algorithm by applying it to the real outcomes in the UNOS dataset.</p><p>The IHDP dataset The Infant Health and Development Program (IHDP) is intended to enhance the cognitive and health status of low birth weight, premature infants through pediatric follow-ups and parent support groups <ref type="bibr" target="#b4">[5]</ref>. The semi-simulated dataset in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref> is based on covariates from a real randomized experiment that evaluated the impact of the IHDP on the subjects' IQ scores at the age of three: selection bias is introduced by removing a subset of the treated population. All outcomes (response surfaces) are simulated. The response surface data generation process was not designed to favor our method: we used the standard non-linear "Response Surface B" setting in <ref type="bibr" target="#b4">[5]</ref> (also used in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b7">[8]</ref>). The dataset comprises 747 subjects (608 control and 139 treated), and there are 25 covariates associated with each subject.</p><p>The UNOS dataset <ref type="foot" target="#foot_3">3</ref> The United Network for Organ Sharing (UNOS) dataset contains information on every heart transplantation event in the U.S. since 1987. The dataset also contains information on patients registered in the heart transplantation wait-list over the years, including those who died before undergoing a transplant. Left Ventricular Assistance Devices (LVADs) were introduced in 2001 as a life-saving therapy for patients awaiting a heart donor <ref type="bibr" target="#b25">[26]</ref>; the survival benefits of LVADs are very heterogeneous across the patients' population, and it is unclear to practitioners how outcomes vary across patient subgroups. It is important to learn the heterogeneous survival benefits of LVADs in order to appropriately re-design the current transplant priority allocation scheme <ref type="bibr" target="#b25">[26]</ref>.</p><p>We extracted a cohort of patients enrolled in the wait-list in 2010; we chose this year since by that time the current continuous-flow LVAD technology became dominant in practice, and patients have been followed up sufficiently long to assess their survival. (Details of data processing is provided in Appendix C.) After excluding pediatric patients, the cohort comprised 1,006 patients (774 control and 232 treated), and there were 14 covariates associated with each patient. The outcomes (survival times) generation model is described as follows:</p><formula xml:id="formula_30">σ 0 = σ 1 = 1, f 0 (x) = exp((x +<label>1</label></formula><p>2 ) Ω), and f 1 (x) = Ω x -ω, where Ω is a random vector of regression coefficients sampled uniformly from [0, 0.1, 0.2, 0.3, 0.4], and ω is selected for a given Ω so as to adjust the average survival benefit to 5 years. In order to increase the selection bias, we estimate the propensity score P(W i = 1|X i = x) using logistic-regression, and then, sequentially, with probability 0.5 we remove the control patient whose propensity score is closest to 1, and with probability 0.5 we remove a random control patient. A total of 200 patients are removed, leading to a cohort with 806 patients. The resulting dataset is more biased than IHDP, and hence poses a greater inferential challenge. Benchmarks We compare our algorithm with: ♣ Tree-based methods (BART <ref type="bibr" target="#b4">[5]</ref>, causal forests (CF) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>, virtual-twin random forests (VTRF) <ref type="bibr" target="#b6">[7]</ref>, and counterfactual random forests (CFRF) <ref type="bibr" target="#b6">[7]</ref>), ♠ Balancing counterfactual regression (Balancing linear regression (BLR) <ref type="bibr" target="#b5">[6]</ref>, balancing neural networks (BNN) <ref type="bibr" target="#b5">[6]</ref>, and counterfactual regression with Wasserstein distance metric (CFRW) <ref type="bibr" target="#b7">[8]</ref>), Propensity-based and matching methods (k nearest-neighbor (kNN), matching-smoothing (MS) <ref type="bibr" target="#b9">[10]</ref>), ♦ Doubly-robust methods (Targeted maximum likelihood (TML) <ref type="bibr" target="#b21">[22]</ref>), and ♥ Gaussian processbased methods (separate GP regression for treated and control with marginal likelihood maximization (GP)). Details of all these benchmarks are provided in Appendix D.</p><p>Following <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>, we evaluate the performance of all algorithms by reporting the square-root of PEHE</p><formula xml:id="formula_31">= 1 n n i=1 ((f 1 (X i ) -f 0 (X i )) -E[Y (1) i -Y (0) i |X i = x]) 2</formula><p>, where f 1 (X i ) -f 0 (X i ) is the estimated treatment effect. We evaluate the PEHE via a Monte Carlo simulation with 1000 realizations of both the IHDP and UNOS datasets, where in each experiment we run all the benchmarks with 60/20/20 train-validation-test splits. Counterfactuals are never made available to any of the benchmarks. We run Algorithm 1 with the a learning rate of 0.01 and with the standard setting prescribed in <ref type="bibr" target="#b20">[21]</ref> (i.e. β 1 = 0.9, β 2 = 0.999, = 10 -8 ). We report both the in-sample and out-of-sample PEHE estimates: the former corresponds to the accuracy of the estimated ITE in a retrospective cohort study, whereas the latter corresponds to the performance of a clinical decision support system that provides out-of-sample patients with ITE estimates <ref type="bibr" target="#b7">[8]</ref>. The in-sample PEHE metrics is non-trivial since we never observe counterfactuals even in the training phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As can be seen in Table <ref type="table" target="#tab_0">1</ref>, CMGPs outperform all other benchmarks in terms of the PEHE in both the IHDP and UNOS datasets. The benefit of the risk-based empirical Bayes method manifest in the comparison with ordinary GP regression that fits the treated and control populations by evidence maximization. The performance gain of CMGPs with respect to GPs increase in the UNOS dataset as it exhibits a larger selection bias, hence naïve GP regression tends to fit a function to the factual outcomes that does not generalize well to counterfactuals. Our algorithm is also performing better than all other nonparametric tree-based algorithms. In comparison to BART, our algorithm places an adaptive prior on a smooth function space, and hence it is capable of achieving faster posterior contraction rates than BART, which places a prior on a space of discontinuous functions <ref type="bibr" target="#b15">[16]</ref>. Similar insights apply to the frequentist random forest algorithms. CMGPs also outperform the different variants of counterfactual regression in both datasets, though CFRW is competitive in the IHDP experiment. BLR performs badly in both datasets as it balances the distributions of the treated and control populations by variable selection, and hence it throws away informative features for the sake of balancing the selection bias. The performance gain of CMGPs with respect to BNN and CFRW shows that the multi-task learning framework is advantageous: through the linear coregionalization kernel, CMGPs preserves the interactions between W i and X i , and hence is capable of capturing highly non-linear (heterogeneous) response surfaces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion: Towards Precision Medicine</head><p>To provide insights into the clinical utility of CMGPs, we ran our algorithm on all patients in the UNOS dataset who were wait-listed in the period 2005-2010, and used the real patient survival times as outcomes. The current transplant priority allocation scheme relies on a coarse categorization of patients that does not take into account their individual risks; for instance, all patients who have an LVAD are thought of as benefiting from it equally. We found a substantial evidence in the data that this leads to wrong clinical decision. In particular, we found that 10.3% of wait-list patients for whom an LVAD was implanted exhibit a delayed assignment to a high priority allocation in the wait-list. One of such patients has her pathway depicted in Fig. <ref type="figure" target="#fig_2">2</ref>: she was assigned a high priority (status 1A) in June 2013, but died shortly after, before her turn to get a heart transplant. Her late assignment to the high priority status was caused by an overestimated benefit of the LVAD she got implanted in 2010; that is, the wait-list allocation scheme assumed she will attain the "populational average" survival benefit from the LVAD. Our algorithm had a much more conservative estimate of her survival; since she was diabetic, her individual benefit from the LVAD was less than the populational average. We envision a new priority allocation scheme in which our algorithm is used to allocate priorities based on the individual risks in a personalized manner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pictorial depiction for model selection via risk-based empirical Bayes.</figDesc><graphic coords="5,108.00,72.00,396.00,106.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 Causal Inference via CMGPs 1 : 2 :</head><label>112</label><figDesc>Input: Observational dataset D, Bayesian coverage γ Output: ITE function T (x), credible intervals Cγ(x) 3: θ ← Initialize-hyperparameters(D) 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Pathway for a representative patient in the UNOS dataset.</figDesc><graphic coords="8,124.76,469.70,360.01,87.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results on the IHDP and UNOS datasets (lower</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">√ PEHE is better).</cell></row><row><cell></cell><cell></cell><cell cols="2">IHDP</cell><cell cols="2">UNOS</cell></row><row><cell></cell><cell></cell><cell>In-sample √ PEHE</cell><cell>Out-of-sample √ PEHE</cell><cell>In-sample √ PEHE</cell><cell>Out-of-sample √ PEHE</cell></row><row><cell cols="2">♥ CMGP</cell><cell>0.9 ± 0.07</cell><cell>1.0 ± 0.08</cell><cell>1.7 ± 0.10</cell><cell>1.8 ± 0.13</cell></row><row><cell></cell><cell>GP</cell><cell>2.1 ± 0.11</cell><cell>2.3 ± 0.14</cell><cell>4.1 ± 0.15</cell><cell>4.5 ± 0.20</cell></row><row><cell>♣</cell><cell>BART</cell><cell>2.0 ± 0.13</cell><cell>2.2 ± 0.17</cell><cell>3.5 ± 0.17</cell><cell>3.9 ± 0.23</cell></row><row><cell></cell><cell>CF</cell><cell>2.3 ± 0.21</cell><cell>2.4 ± 0.23</cell><cell>3.8 ± 0.25</cell><cell>4.3 ± 0.31</cell></row><row><cell></cell><cell>VTRF</cell><cell>2.5 ± 0.26</cell><cell>2.9 ± 0.51</cell><cell>4.5 ± 0.35</cell><cell>4.9 ± 0.41</cell></row><row><cell></cell><cell>CFRF</cell><cell>2.7 ± 0.31</cell><cell>3.3 ± 0.72</cell><cell>4.7 ± 0.21</cell><cell>5.2 ± 0.32</cell></row><row><cell>♠</cell><cell>BLR</cell><cell>5.9 ± 0.31</cell><cell>6.1 ± 0.41</cell><cell>5.7 ± 0.21</cell><cell>6.2 ± 0.30</cell></row><row><cell></cell><cell>BNN</cell><cell>2.1 ± 0.11</cell><cell>2.2 ± 0.13</cell><cell>3.2 ± 0.10</cell><cell>3.3 ± 0.12</cell></row><row><cell></cell><cell>CFRW</cell><cell>1.0 ± 0.07</cell><cell>1.2 ± 0.08</cell><cell>2.7 ± 0.07</cell><cell>2.9 ± 0.11</cell></row><row><cell></cell><cell>kNN</cell><cell>3.2 ± 0.12</cell><cell>4.2 ± 0.22</cell><cell>5.2 ± 0.11</cell><cell>5.4 ± 0.12</cell></row><row><cell></cell><cell>MS</cell><cell>2.8 ± 0.18</cell><cell>2.9 ± 0.20</cell><cell>4.6 ± 0.12</cell><cell>4.8 ± 0.16</cell></row><row><cell>♦</cell><cell>TML</cell><cell>4.9 ± 0.23</cell><cell>4.9 ± 0.23</cell><cell>6.2 ± 0.31</cell><cell>6.2 ± 0.31</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.healthit.gov/sites/default/files/briefs/ 31st Conference on Neural Information Processing Systems (NIPS</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2017), Long Beach, CA, USA.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>Some works refer to this setting as the "logged bandits with feedback"<ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>https://www.unos.org/data/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spending on New Drug Development</title>
		<author>
			<persName><forename type="first">C</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Brantner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Economics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="141" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subgroup Identification from Randomized Clinical Trial Data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G T</forename><surname>Jeremy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Ruberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in medicine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="2867" to="2880" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Strengthening Analytical Thinking for Observational Studies: the STRATOS Initiative</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sauerbrei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abrahamowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cessie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in medicine</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="5413" to="5432" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recursive Partitioning for Heterogeneous Causal Effects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Imbens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="7353" to="7360" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian Nonparametric Modeling for Causal Inference</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning Representations for Counter-factual Inference</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Feaster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishwaran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05306</idno>
		<title level="m">Estimating Individual Treatment Effect in Observational Data using Random Forest Methods</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03976</idno>
		<title level="m">Estimating Individual Treatment Effect: Generalization Bounds and Algorithms</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.04342</idno>
		<title level="m">Estimation and Inference of Heterogeneous Treatment Effects using Random Forests</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating Heterogeneous Treatment Effects with Observational Data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methodology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="314" to="347" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A Bayesian Nonparametic Approach for Estimating Individualized Treatment-Response Curves</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.05182</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Doubly robust policy evaluation and learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dudík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Batch Learning from Logged Bandit Feedback Through Counter-factual Risk Minimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1731" to="1755" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Matching on the Estimated Propensity Score</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Imbens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="781" to="807" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernels for Vector-valued Functions: A Review</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="266" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive Bayesian Credible Sets in Regression with a Gaussian Process Prior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sniekers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Vaart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2475" to="2527" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Generalized Representer Theorem</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Learning Theory</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-task Gaussian Process Prediction</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Bonilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative Learning under Covariate Shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brückner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scheffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2137" to="2155" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Chernozhukov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chetverikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duflo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.00060</idno>
		<title level="m">Double Machine Learning for Treatment and Causal Parameters</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">ADAM: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Relative Performance of Targeted Maximum Likelihood Estimators</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Sekhon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Carl</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rasmussen</forename></persName>
		</author>
		<title level="m">Gaussian Processes for Machine Learning</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Preventing Over-fitting During Model Selection via Bayesian Regularisation of the Hyper-parameters</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L C</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="841" to="861" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taddy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.09596</idno>
		<title level="m">Counterfactual Prediction with Deep Instrumental Variables Networks</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Advanced Heart Failure Treated with Continuous-flow Left Ventricular Assist Device</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Slaughter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2241" to="2251" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
