<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering</orgName>
								<orgName type="laboratory">Australian Research Council (ARC) Centre of Ex-cellence for Autonomous Systems (CAS)</orgName>
								<orgName type="institution">University of Technology</orgName>
								<address>
									<postCode>2007</postCode>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">294F5E2B36BECE5728636032EDD28221</idno>
					<idno type="DOI">10.1109/TRO.2008.2003259</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I N THE RECENT years, it has become evident that the simul- taneous localization and mapping (SLAM) problem can be efficiently solved by exploiting the sparseness of the information matrix or techniques from sparse graph and sparse linear algebra (see, e.g., <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b4">[5]</ref>). However, most of the methods based on sparse representations have focused on building a single largescale map, resulting in the need to update a large map whenever a new observation is made.</p><p>Alternatively, local submap joining <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> provides an efficient way to build large-scale maps. In local submap joining, a sequence of small-sized local submaps are built (e.g., using conventional extended Kalman filter (EKF) SLAM <ref type="bibr" target="#b7">[8]</ref>), and then combined into a large-scale global map. During map joining <ref type="bibr" target="#b5">[6]</ref>, the state vector of the local submap is first transferred into the global coordinate frame. Common features present in both the local and global maps are identified, and an EKF is used to enforce identity constraints to obtain the global map. The resulting map covariance matrix is fully correlated, and thus, the map fusion process is computationally demanding. Overall computational savings are achieved due to the fact that the frequency of global map updates is reduced.</p><p>This paper demonstrates that local submap joining can be achieved through the use of a sparse information filter. The proposed map joining filter, sparse local submap joining filter (SLSJF), combines the advantages of the local submap joining algorithms and the sparse representation of SLAM to substantially reduce the computational cost of the global map construction.</p><p>The paper is organized as follows. Section II presents the overall structure of the SLSJF and demonstrates that the associated information matrix is exactly sparse. The SLSJF algorithm is described in detail in Section III. Section IV provides simulation and experiment results. Section V discusses some properties of the SLSJF and some related work. Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. OVERALL STRUCTURE OF SLSJF</head><p>This section presents the overall structure of the SLSJF and explains why it results in a sparse representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Input and Output of SLSJF</head><p>The input to the SLSJF is a sequence of local submaps constructed by some SLAM algorithm. Local maps 1 are denoted by</p><formula xml:id="formula_0">( XL , P L )<label>(1)</label></formula><p>where XL (the superscript "L" stands for the local map) is an estimate of the state vector</p><formula xml:id="formula_1">X L = (X L r , X L 1 , . . . , X L n ) = (x L r , y L r , φ L r , x L 1 , y L 1 , . . . , x L n , y L n )<label>(2)</label></formula><p>and P L is the associated covariance matrix. The state vector X L contains the robot final pose X L r (the subscript "r" stands for the robot) and all the local feature positions X L 1 , . . . , X L n , as typically generated by conventional EKF SLAM. The coordinate system of a local map is defined by the robot pose when the building of the local map is started, i.e., the robot starts at the coordinate origin of the local map. It is assumed that the robot starts to build local map k + 1 as soon as it finishes local map k. Therefore, the robot end pose of local map k (defined as the global position of the last robot pose when building local map k) is the same as the robot start pose of local map k + 1 (see Fig. <ref type="figure" target="#fig_1">1</ref>).</p><p>The output of SLSJF is a global map. The global map state vector contains all the feature positions and all the robot end poses of the local maps (see Fig. <ref type="figure" target="#fig_1">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Why can Local Map Joining Have Sparse Representation?</head><p>The reason why SLSJF can be developed is that the information contained in each local map is the relative position information about some "nearby objects"-the features and the robot start/end poses involved in the local map.</p><p>By including all the objects (all the features and all the robot start/end poses) in the global map state vector, the local map joining problem becomes a large-scale estimation problem with only "local" information (similar to smooth and mapping (SAM) <ref type="bibr" target="#b1">[2]</ref> and full SLAM <ref type="bibr" target="#b4">[5]</ref>). When extended information filter (EIF) is used to solve the estimation problem, a nonzero off-diagonal element of the information matrix (a "link" between the two related objects) occurs only when the two objects are within the same local map. 2 Since the size of each local map is limited, any object will only have links with its "nearby objects," no matter how many (overlapping) local maps are fused (see Fig. <ref type="figure" target="#fig_1">1</ref>). This results in an exactly sparse information matrix.</p><p>Since all the objects involved in the local maps are included in the global state vector, no marginalization is required in the map joining process, and thus, the information matrix will stay exactly sparse all the time. Because most of the robot poses 2 An off-diagonal element of the information matrix is exactly zero if the two related variables are conditionally independent given all the other variables (see, e.g., <ref type="bibr" target="#b8">[9]</ref> for a proof). In local map joining, two objects are conditionally independent unless they are involved in the same local map. are marginalized out during the local map building process, the dimension of the global state vector is much less than that of SAM <ref type="bibr" target="#b1">[2]</ref> and full SLAM <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Overall Structure of SLSJF</head><p>SLSJF fuses the local maps sequentially to build a global map, in a manner similar to <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>, using the structure presented in Algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. State Vector of the Global Map</head><p>The state vector of the global map contains the global positions of all features and all the robot end poses of local maps. For convenience, the origin of the global map is chosen to be the same as the origin of local map 1 (see Fig. <ref type="figure" target="#fig_1">1</ref>).</p><p>After local maps 1 to k are fused into the global map, the global state vector is denoted as X G (k) (the superscript "G" stands for the global map) and is given by</p><formula xml:id="formula_2">X G (k) = (X G 1 , . . . , X G n 1 , X G 1e , X G n 1 +1 , . . . , X G n 1 +n 2 , X G 2e , . . . X G n 1 +•••+n k -1 +1 , . . . , X G n 1 +•••+n k -1 +n k , X G ke )<label>(3)</label></formula><p>where X G 1 , . . . , X G n 1 are the global positions of the features in local map 1; X G n 1 +1 , . . . , X G n 1 +n 2 are the global positions of these features in local map 2 but not in local map 1;</p><formula xml:id="formula_3">X G n 1 +•••+n k -1 +1 , . . . , X G n 1 +•••+n k -1 +n k are the global positions of the features in local map k but not in local maps 1 to k -1. X G ie = (x G ie , y G ie , φ G ie ) (1 ≤ i ≤ k)</formula><p>is the global position of the robot end pose of local map i, which is also the robot start pose of local map i + 1 . Here, the subscript "e" stands for robot "end pose."</p><p>In the information filter framework, an information vector i(k) and an information matrix I(k) are used for map fusion. The relationship between the state vector estimate XG (k), the corresponding covariance matrix P (k) and i(k), I(k) is ( <ref type="bibr" target="#b4">[5]</ref>)</p><formula xml:id="formula_4">I(k) XG (k) = i(k), P (k) = I(k) -1 . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>As I(k) is an exactly sparse matrix, it can be stored and computed efficiently. The state vector estimate XG (k) is recovered after fusing each local map by solving the sparse linear equation [the first equation in <ref type="bibr" target="#b3">(4)</ref>]. The whole dense matrix P (k) is neither computed nor stored in SLSJF. Small parts of P (k) required for data association are computed by solving a set of sparse linear equations, as outlined in Section III-C3.</p><p>When fusing local map k + 1 into the global map, the features that are present in local map k + 1 but have not yet been included in the global map,</p><formula xml:id="formula_6">X G n 1 +•••+n k +1 , . . . , X G n 1 +•••+n k +n k + 1</formula><p>, together with the robot end pose of local map k + 1, X G (k +1)e , are added into the global state vector X G (k) in (3) to form the new state vector X G (k + 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Steps of Local Map Fusion</head><p>The steps used in fusing local map k + 1 into the global map are listed in Algorithm 2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Data Association</head><p>Data association in SLSJF refers to finding the features in local map k + 1 that are already included in the global map and their corresponding indexes in the global state vector. This is an essential step in any practically deployable SLAM algorithm, yet is often neglected in many of the sparse information filterbased SLAM algorithms published in the literature.</p><p>Data association is a challenge problem in EIF SLAM if only the geometric relationships among features present in the global and local maps are available. How this can be efficiently achieved in SLSJF is described in the following.  maximal distance from the local map features to its origin. Fig. <ref type="figure" target="#fig_3">2</ref> illustrates the idea. Note that the location estimate of the origin of local map i is XG (i-1)e (for 2 ≤ i ≤ k), while that of local map 1 is (0 0 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Set of Potentially Matched Features:</head><p>A feature from potentially overlapping local maps is added to a potentially matched feature list, if the distance from it to XG ke is smaller than the radius of local map k + 1 plus the maximal possible estimation error. This list is further simplified by removing any member that is located further than a predetermined threshold distance from all features in local map k + 1.</p><p>3) Covariance Submatrix Associated With X G ke and all Potentially Matched Features: The covariance submatrix can be obtained by first computing the corresponding columns of the covariance matrix P (k), and then extracting the desired rows.</p><p>Using (4), the lth column of the covariance matrix P (k), P l can be obtained by solving the sparse linear equation <ref type="bibr" target="#b4">[5]</ref> </p><formula xml:id="formula_7">I(k)P l = e l (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where</p><formula xml:id="formula_9">e l = [ l-1 0, . . . , 0, 1,,0 . . . , 0] T . (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>Since the Cholesky factorization of I(k), L k is a triangular matrix satisfying L k L T k = I(k), the sparse linear equation ( <ref type="formula" target="#formula_7">5</ref>) can be solved efficiently by first solving L k q = e l , and then solving L T k P l = q <ref type="bibr" target="#b1">[2]</ref>. Note that the Cholesky factorization L k is already available from step 5 of Algorithm 2 when fusing local map k into the global map, as described in Section III-G.</p><p>4) Feature Matching: Since both the state estimates and the covariance matrices of the potentially matched features are available, any statistical data association algorithm (such as the simple nearest neighbor method <ref type="bibr" target="#b7">[8]</ref> or the more robust joint compatibility test with branch and bound technique <ref type="bibr" target="#b11">[12]</ref>) can be used to find the matching features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Initialize the New Features and X G</head><p>(k +1)e in the Global Map The initial values of the global positions of all unmatched features and the robot end pose of local map k + 1 are computed (using XG ke and the local map state estimate) and inserted into XG (k) to form a new state vector estimate XG (k). The dimensions of i(k), I(k), and L k are increased by adding zeros to form a new information vector i(k), a new information matrix I(k), and the corresponding Cholesky factorization L k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Update the Global Map</head><p>Suppose that local map k + 1 is given by <ref type="bibr" target="#b0">(1)</ref>. Since the local map provides a consistent estimate of the relative positions from the robot start pose to the local features and the robot end pose, this map can be treated as an observation of the true relative positions with a zero-mean Gaussian observation noise whose covariance matrix is P L .</p><p>To state it clearly, suppose that the data association result is</p><formula xml:id="formula_11">X L 1 ↔ X G i1 , . . . , X L n ↔ X G</formula><p>in (including both old and new features). Then, the local map state estimate XL can be regarded as an observation of the true relative positions from</p><formula xml:id="formula_12">X G ke to X G i1 , . . . , X G in , X G (k +1)e , i.e. z map = XL = H map (X G ) + w map<label>(7)</label></formula><p>where H map (X G ) is the vector of relative positions given by</p><formula xml:id="formula_13">                  (x G (k +1)e -x G ke ) cos φ G ke + (y G (k +1)e -y G ke ) sin φ G ke (y G (k +1)e -y G ke ) cos φ G ke -(x G (k +1)e -x G ke ) sin φ G ke φ G (k +1)e -φ G ke (x G i1 -x G ke ) cos φ G ke + (y G i1 -y G ke ) sin φ G ke (y G i1 -y G ke ) cos φ G ke -(x G i1 -x G ke ) sin φ G ke . . . (x G in -x G ke ) cos φ G ke + (y G in -y G ke ) sin φ G ke (y G in -y G ke ) cos φ G ke -(x G in -x G ke ) sin φ G ke                  </formula><p>and w map is the zero-mean Gaussian "observation noise" whose covariance matrix is P L . The "observation" z map can now be used to update the information vector and the information matrix as follows:</p><formula xml:id="formula_14">I(k + 1) = I(k) + ∇H T map (P L ) -1 ∇H map i(k + 1) = i(k) + ∇H T map (P L ) -1 × [z map -H map ( XG (k))+∇H map XG (k)] (8)</formula><p>where ∇H map is the Jacobian of the function H map with respect to X G (k) evaluated at XG (k).</p><p>Since z map = XL only involves two robot poses X G ke , X G (k +1)e and some local features (a small fraction of the total features in the global map), the matrix ∇H T map (P L ) -1 ∇H map in ( <ref type="formula">8</ref>) and the information matrix I(k + 1) are both exactly sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Reorder the Global Map State Vector When Necessary</head><p>The purpose of reordering the global state vector is to make the computation of Cholesky factorization (Section III-G), the state vector recovery (Section III-H), and the covariance submatrix recovery (Section III-C.3) more efficient. Many different strategies for reordering are available. The strategy proposed here is a combination of the approximately minimal degree (AMD) reordering <ref type="bibr" target="#b1">[2]</ref> and the reordering based on distances <ref type="bibr" target="#b3">[4]</ref>.</p><p>Whether to reorder the global map state vector or not depends on where the features in local map k + 1 are located within the global state vector. If all of the features in local map k + 1 are present within the n 0 elements from the bottom of the global state vector, <ref type="foot" target="#foot_0">3</ref> then the state vector is left unchanged. If this condition is violated, which happens only when closing a large loop, then the state vector is reordered.</p><p>The state vector is reordered using the following process. The robot pose X G (k +1)e and the features that are within distance d 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>to XG (k +1)e are placed at the bottom part of the state vector. Their order is determined based on the distances from them to XG (k +1)e . The smaller the distance, the closer the position to the bottom. All the other robot poses and features are placed in the upper part of the state vector, and they are reordered based on AMD.</p><p>The major advantage of reordering by AMD is that the number of fill-ins in Cholesky factorization will be reduced. The major advantage of reordering the nearby features based on distances is that once the reordering is performed, another reordering will not be required for the fusion of next few local maps. This is because the robot cannot observe features that are not located in the bottom part of the state vector until it travels a certain distance.</p><p>Once the state vector is reordered, the corresponding information matrix I(k + 1) and information vector i(k + 1) are reordered accordingly. For notational simplicity, they are still denoted as I(k + 1) and i(k + 1). Note that the Cholesky factorization of the reordered I(k + 1) cannot be easily obtained from L k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Compute the Cholesky Factorization of I(k + 1)</head><p>The method used to compute the Cholesky factorization of I(k + 1) depends on whether the global state vector was reordered in Section III-F or not.</p><p>Case (i). If the global state vector was not reordered in Section III-F, then the Cholesky factorization of I(k) (available from step 5 of Algorithm 2 when fusing local map k) is used to construct the Cholesky factorization of I(k + 1) as follows.</p><p>By <ref type="bibr" target="#b7">(8)</ref>, the relation between I(k + 1) and I(k) is</p><formula xml:id="formula_15">I(k + 1) = I(k) + 0 0 0 Ω<label>(9)</label></formula><p>where the upper left element in Ω is nonzero. Here, Ω is a symmetric matrix determined by the term ∇H T map (P L ) -1 ∇H map in <ref type="bibr" target="#b7">(8)</ref>. Its dimension is less than n 0 since otherwise the state vector would have been reordered.</p><p>Let I(k) and its Cholesky factorization L k (a lower triangular matrix) be partitioned according to <ref type="bibr" target="#b8">(9)</ref> as</p><formula xml:id="formula_16">I(k) = I 11 I T 21 I 21 I 22 L k = L 11 0 L 21 L 22 . (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>According to ( <ref type="formula" target="#formula_15">9</ref>) and ( <ref type="formula" target="#formula_16">10</ref>), I(k + 1) can be expressed by</p><formula xml:id="formula_18">I(k + 1) = I 11 I T 21 I 21 I k +1 22 = I 11 I T 21 I 21 I 22 + Ω . (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>By Lemma 1 in the Appendix of <ref type="bibr" target="#b3">[4]</ref>, the Cholesky factorization of I(k + 1) can be obtained by</p><formula xml:id="formula_20">L k +1 = L 11 0 L 21 L k +1 22 (<label>12</label></formula><formula xml:id="formula_21">)</formula><p>where L k +1 22 is the Cholesky factorization of the low- <ref type="formula" target="#formula_20">12</ref>) is much more efficient than directly computing the Cholesky factorization of the high-dimensional matrix I(k + 1).</p><formula xml:id="formula_22">dimensional matrix Ω + L 22 L T 22 = I k +1 22 -L 21 L T 21 . Computing L k +1 by (</formula><p>Case (ii). If the global state vector has been reordered in Section III-F, then the Cholesky factorization of I(k) cannot be used to construct the Cholesky factorization of I(k + 1). In this case, a direct Cholesky factorization of I(k + 1) is performed to obtain L k +1 .</p><p>Since the reordering only happens occasionally, case (i) occurs most of the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. State Vector Recovery</head><p>Because the global map is maintained as an information vector and an information matrix, the global state estimate XG (k + 1) is not directly available. Using (4), the state vector estimate XG (k + 1) can be recovered by solving the sparse linear equation</p><formula xml:id="formula_23">I(k + 1) XG (k + 1) = i(k + 1). (<label>13</label></formula><formula xml:id="formula_24">)</formula><p>The Cholesky factorization L k +1 computed in Section III-G is used to solve the sparse linear equation. Since L k +1 L T k +1 = I(k + 1), the sparse linear equation ( <ref type="formula" target="#formula_23">13</ref>) can be solved efficiently by first solving L k +1 Y = i(k + 1) and then solving</p><formula xml:id="formula_25">L T k +1 XG (k + 1) = Y .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SIMULATION AND EXPERIMENT RESULTS</head><p>In this section, simulation and experiment results are given to illustrate the accuracy and efficiency of SLSJF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Results</head><p>The 150 × 150 m 2 simulation environment used contains 2500 features arranged in uniformly spaced rows and columns.</p><p>The robot started from the left bottom corner of the square and followed a random trajectory, as shown in Fig. <ref type="figure" target="#fig_6">3(a)</ref>. A sensor with a field of view of 180 • and a range of 6 m [the small semicircle seen near the bottom in Fig. <ref type="figure" target="#fig_6">3(a)</ref>] was simulated to generate relative range and bearing measurements between the robot and the features. There were 27 924 robot poses in total and 170 846 measurements were made from the robot poses. The robot observed 2270 features in total and most of them were observed a number of times.</p><p>Six hundred small-sized local maps were built by conventional EKF SLAM using the odometry and measurement information. Each local map contains around ten features. Fig. <ref type="figure" target="#fig_6">3(a)</ref> shows the global map generated by fusing all the 600 local maps using SLSJF. The data association in the SLSJF was performed using the nearest neighbor method <ref type="bibr" target="#b7">[8]</ref>. The global map was superimposed with the global map generated by fusing the 600 local maps using EKF sequential map joining <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> and the map generated by a single EKF SLAM. Close examination [e.g., Fig. <ref type="figure" target="#fig_6">3(b)</ref>] shows that the feature position estimates computed by the three methods are all consistent. The feature position estimates of SLSJF and EKF sequential map joining are almost identical.</p><p>Fig. <ref type="figure" target="#fig_6">3</ref>(c) shows the errors and 2σ bounds of the estimates of the 600 robot end poses obtained using the three methods. It is clear that the estimates are all consistent. It should be noted that in SLSJF, the robot end poses are included in the global state vector and are continuously updated. Therefore, the error and 2σ bounds of SLSJF are smaller than that of EKF sequential map joining and EKF SLAM, where the robot poses, except the most recent one, are not included in the state vector (hence are not updated).</p><p>Fig. <ref type="figure" target="#fig_6">3(d</ref>) shows all the nonzero elements of the sparse information matrix obtained by SLSJF in black. Fig. <ref type="figure" target="#fig_6">3(e)</ref> shows the CPU time <ref type="foot" target="#foot_2">5</ref> required for the local map fusion using SLSJF and EKF sequential map joining. The total time for fusing all the 600 local maps is 145 s for SLSJF and 7306 s for EKF sequential map joining (building the 600 local maps takes 95 s, it takes conventional EKF SLAM more than 15 h to finish the map). Table <ref type="table">I</ref> presents the detailed processing time for the two map joining algorithms. In SLSJF, the major computational cost is due to "data association" which includes the time for covariance submatrix recovery. The "others" including reordering of the state vector, Cholesky factorization, and state vector recovery also take significant time. On the other hand, "global map update" uses most of the computation time in EKF sequential map joining.</p><p>Fig. <ref type="figure" target="#fig_6">3</ref>(f) compares the CPU time of SLSJF with the proposed reordering strategy and that of SLSJF with the AMDonly reordering <ref type="bibr" target="#b1">[2]</ref> (for the proposed reordering, the parameters n 0 = 400 and d 0 = 15; for the AMD-only reordering, the reordering is performed after fusing every five local maps, the parameters are chosen such that both algorithms have their </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I PROCESSING TIME OF EKF SEQUENTIAL MAP JOINING AND SLSJF</head><p>best performance). The performance of the two reordering algorithms are very similar, presumably due to the fact that the MATLAB implementation of AMD algorithm is very efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Results</head><p>SLSJF was also applied to the Victoria Park dataset that was first used in <ref type="bibr" target="#b13">[14]</ref>. Neither ground truth nor noise parameters are available for this dataset. Published results for the vehicle trajectory and uncertainty estimates vary <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, presumably due to different parameters used by various researchers. The results in this section, therefore, only demonstrate that SLSJF can be applied to this popular dataset.  used to build 200 local maps by EKF SLAM. Fig. <ref type="figure" target="#fig_8">4(b)</ref> shows the global map obtained by joining the 200 local maps using SLSJF. Data association in SLSJF was performed using the nearest neighbor method <ref type="bibr" target="#b7">[8]</ref>. Fig. <ref type="figure" target="#fig_8">4(c</ref>) shows all the nonzero elements of the information matrix in black. The information matrix is not very sparse because the sensor range is relatively large (around 80 m) as compared with the size of the environment (300 m × 300 m). Fig. <ref type="figure" target="#fig_8">4(d)</ref> shows the CPU time required to fuse each of the 200 local maps. The total processing time for joining all the 200 maps by SLSJF is 22 s (the time required for building the 200 local maps is 63 s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK AND DISCUSSION</head><p>In this section, some of the properties of SLSJF and some related work are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Different Ways to Achieve Sparse Representation</head><p>The sparse representations of SLAM recently proposed in the literature (e.g., <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b14">[15]</ref>) make use of different state vectors and/or have different strategies for marginalizing out robot poses. In SAM <ref type="bibr" target="#b1">[2]</ref>, incremental SAM (iSAM) <ref type="bibr" target="#b12">[13]</ref>, tectonic SAM <ref type="bibr" target="#b10">[11]</ref>, and full SLAM <ref type="bibr" target="#b4">[5]</ref>, all the robot poses are included in the state vector and no marginalization is needed. However, the dimension of the state vector is very high, especially when the robot trajectory is long.</p><p>When all the previous robot poses are marginalized out as in conventional EIF SLAM, the information matrix becomes dense although it is approximately sparse <ref type="bibr" target="#b15">[16]</ref>. The sparse extended information filter (SEIF) presented in <ref type="bibr" target="#b0">[1]</ref> approximates the information matrix by a sparse one using sparsification, and this leads to inconsistent estimates <ref type="bibr" target="#b2">[3]</ref>.</p><p>The exactly sparse extended information filter (ESEIF) developed by <ref type="bibr" target="#b2">[3]</ref> follows the conventional EIF SLAM algorithm, but marginalizes out the robot pose and relocates the robot from time to time. In this way, the information matrix is kept exactly sparse by sacrificing the robot location information once in a while.</p><p>In decoupled SLAM (D-SLAM) algorithm <ref type="bibr" target="#b3">[4]</ref>, the robot pose is not incorporated in the state vector for mapping. The observations made from one robot pose are first transferred into the relative position information among the observed features (the robot pose is marginalized out from the observations), and then the relative position information is used to update the map. This process also results in some information loss.</p><p>The D-SLAM map joining algorithm <ref type="bibr" target="#b14">[15]</ref> first builds local maps and then marginalizes out the robot start and end poses from the local map, the obtained relative position information among features are fused into the global map in a way similar to the D-SLAM algorithm. The odometry information is maintained in the local maps, but there is still some information loss due to the marginalization of robot start/end poses.</p><p>In SLSJF, the robot start and end poses of the local maps are never marginalized but kept in the global state vector. Thus, all the information from local maps is preserved.</p><p>If each local map is treated as one integrated observation, then SLSJF has some similarity to iSAM <ref type="bibr" target="#b12">[13]</ref>. The role of local maps in SLSJF is also similar to the "star nodes" in the graphical SLAM <ref type="bibr" target="#b16">[17]</ref>. However, in the graphical SLAM, the poses are first added in the graph, and then, "star nodes" are made. While in SLSJF, most of the robot poses are marginalized out during the local map building steps. These robot poses are never present in the global state vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Computational Complexity</head><p>The map joining problem considered in this paper is similar to that studied in <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>. The computational complexity of the local map building is O(1) since the size of a local map is small. The computational complexity of the global map update is O(n 2 ) for the sequential map joining approach in <ref type="bibr" target="#b5">[6]</ref> and the constrained local submap filter in <ref type="bibr" target="#b6">[7]</ref>.</p><p>In SLSJF, the robot start/end poses of the local maps are included in the global state vector, and the EIF implementation results in an exactly sparse information matrix. This makes SLSJF much more efficient than the EKF sequential map joining <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>.</p><p>Although simulation results show that SLSJF is computationally very efficient for large-scale SLAM, the computational complexity of several steps in SLSJF may not be O(n) for worst case scenarios. For example, the number of fill-ins introduced in the Cholesky factorization depends on the environment and the robot trajectory. This influences the computational cost of the full Cholesky factorization step and the step of solving the sparse linear equations. Also, the computational cost of the proposed reordering is not well understood yet. In theory, SLSJF suffers the general O(n 1.5 ) cost for worst case scenario of planar grids, as all sparse-factorization-based methods do <ref type="bibr" target="#b17">[18]</ref>. This is similar to the treemap algorithm <ref type="bibr" target="#b18">[19]</ref> and the SAM using nested dissection algorithm <ref type="bibr" target="#b19">[20]</ref>.</p><p>Very recently, it was shown in <ref type="bibr" target="#b20">[21]</ref> that the total computational cost of local map building and map joining can be reduced to O(n 2 ) by an EKF-based "divide and conquer SLAM" (D&amp;C SLAM). Although D&amp;C SLAM was shown to be much more efficient than the conventional EKF SLAM, it was not compared with the more efficient EKF sequential map joining <ref type="bibr" target="#b20">[21]</ref>.</p><p>The SLSJF has some similarity to the tectonic SAM algorithm <ref type="bibr" target="#b10">[11]</ref>. Tectonic SAM is also an efficient submap-based approach, and the state vector reordering and Cholesky factorization are used in solving the least-square problem. The submap fusion in tectonic SAM uses a D&amp;C approach, which is more efficient than the sequential map joining in SLSJF when data association is assumed. The major difference between the tectonic SAM and SLSJF is that in tectonic SAM, all the robot poses involved in building the local maps are kept, and the dimension of the global state vector is much higher than that of SLSJF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Requirements on SLSJF</head><p>In SLSJF, it is assumed that the local maps are consistent and accurate enough. If the local maps are inconsistent, SLSJF may produce wrong results due to the wrong information provided by the local maps. When the local maps are inaccurate, SLSJF may become inconsistent due to linearization errors.</p><p>Another assumption made in SLSJF is that the local map only involves "nearby objects." This guarantees that the information matrix is exactly sparse, no matter how many local maps are fused. When this assumption does not hold such as the case with vision sensors, SLSJF can still be applied since a significant number of feature pairs will not be present concurrently in the same local map. However, the processes of selecting potentially matched features and reordering the state vector may need modifications to make the algorithm more efficient.</p><p>Similar to <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>, there is no requirement on the structure of the environment for SLSJF to be applicable. This is different from the efficient treemap SLAM algorithm <ref type="bibr" target="#b18">[19]</ref>, where the environment has to be "topological suitable." Another difference between the SLSJF and the treemap SLAM algorithm is that the covariance submatrix recovery and data association have been ignored in the treemap SLAM implementations available to date <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Exact Covariance Submatrix Recovery</head><p>The covariance submatrix recovery in SLSJF is exact. This is different from the approximate covariance submatrix recovery methods (e.g., <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>), where only an approximate or upper bound of covariance submatrix is computed. As pointed out in <ref type="bibr" target="#b9">[10]</ref>, the upper bound can only be used in nearest neighbor data association <ref type="bibr" target="#b7">[8]</ref> but cannot be used in the more robust joint compatibility test <ref type="bibr" target="#b11">[12]</ref>.</p><p>An algorithm for exact recovery of covariance submatrix was proposed in iSAM <ref type="bibr" target="#b12">[13]</ref>. It has "O(n) time complexity for banddiagonal matrices and matrices with only a constant number of entries far from the diagonal, but can be more expensive for general sparse matrices" <ref type="bibr" target="#b12">[13]</ref>. The covariance submatrix recovery in SLSJF is similar. The major advantages of SLSJF over iSAM is that the dimension of the state vector in SLSJF is much lower than that of iSAM. Thus, SLSJF may be more suitable for the situations where the robot trajectory is very long and/or the observation frequency is high, which is true for many common sensors such as laser range finders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Incremental Cholesky Factorization for Recovery</head><p>The idea of incrementally computing the Cholesky factorization is motivated by <ref type="bibr" target="#b3">[4]</ref>. The main difference between the recovery method in SLSJF and that in <ref type="bibr" target="#b3">[4]</ref> is that complete Cholesky factorization and direct method for linear equation solving are used in SLSJF, while approximate Cholesky factorization and preconditioned conjugate gradient method were used in <ref type="bibr" target="#b3">[4]</ref>.</p><p>The incremental Cholesky factorization also has some similarity with the QR factorization update in <ref type="bibr" target="#b12">[13]</ref>. The QR factorization update in <ref type="bibr" target="#b12">[13]</ref> is based on "Givens rotations," while the incremental Cholesky factorization process in SLSJF is based on the "block-partitioned form of Cholesky factorization." The performance of these two approaches is expected to be similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Reordering of the Global State Vector</head><p>In SLSJF, the reordering of state vector aims to combine the advantages of AMD reordering (where the number of fill-ins is reduced <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b12">[13]</ref>), and the reordering by distance (where the efficient incremental Cholesky factorization procedure can be applied in most cases <ref type="bibr" target="#b3">[4]</ref>).</p><p>The idea behind the "reordering by distance" is to make sure that the robot observes only the features that are in the bottom part of the state vector for as long as possible, no matter in which direction the robot is moving. However, this is not the best way of reordering for indoor environments where features in different rooms might actually be very close but cannot be seen simultaneously. For indoor environments, the knowledge on the structure of the environment (and the knowledge on the possible robot trajectory) can be exploited to place "the features that are likely to be re-observed" near the bottom of the state vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Consistency</head><p>The SLSJF algorithm does not contain any approximations (such as sparsification <ref type="bibr" target="#b0">[1]</ref>) that can lead to estimator inconsistency. However, as the case with all EKF/EIF-based estimation algorithms, it is possible that inconsistencies occur in SLSJF due to the errors introduced by the linearization process.</p><p>It has been suggested that local map-based strategies can improve the consistency of SLAM by keeping the robot orientation error small <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. We had conducted many simulations and found that this is true for some scenarios especially when the process noise, the feature density, and the sensor range are all small, or sequential update is used in EKF when multiple features can be observed from one robot pose. In many practical scenarios, for example, in the simulation results presented in Section IV-A, we found that both EKF SLAM (with batch update) and map joining results are consistent, mainly due to the small observation and odometry noises and the high feature density. When noise values were gradually increased, both strategies became inconsistent, almost always at the same level of noise. This is likely due to the fact that in any submap joining algorithm, inconsistency in even one of the submaps, leads to an inconsistent global map.</p><p>In SLSJF, all the robot start/end poses are in the global state vector, and there is no prediction step within the EIF. Thus, the SLSJF can be treated as a linearized least square solution with only one iteration in each map fusion step. In fact, at any map fusion step, the linearization error can be reduced further by recomputing the information matrix I and the information vector i as a sum of all the contributions in (8), using the new estimate as a linearization point for the Jacobians. This process is able to improve the consistency significantly, but with more computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Treating the Local Map as a Virtual Observation</head><p>Many submap-based SLAM algorithms (either explicitly or implicitly) treat the local map as a virtual observation, but most of them treat a local map as "an observation made from the robot start pose to all the features in the local map." In SLSJF, the local map is treated as "an observation made from the robot start pose to all the features in the local map and a virtual robot located at the robot end pose." This motivates the inclusion of all the robot start/end poses in the global state vector to achieve an exactly sparse information matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Comparison With Two-Level Mapping Algorithms</head><p>The output of SLSJF is one single global stochastic map. This approach is different from the two-level mapping algorithms (e.g., hierarchical SLAM <ref type="bibr" target="#b25">[26]</ref>, Atlas <ref type="bibr" target="#b26">[27]</ref>, network-coupled feature maps <ref type="bibr" target="#b27">[28]</ref>), where a set of local maps are maintained and the relationship among these maps is described at a higher level. Though promising due to their reduced computational cost, the two-level mapping approaches require more work to completely resolve the question of how to treat the overlapping regions among local maps. As pointed out in <ref type="bibr" target="#b25">[26]</ref>, all the two-level mapping systems result in suboptimal solutions because the effect of the upper level update cannot be propagated back to the local level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>By adding robot start/end poses of the local maps into the global state vector, an exactly sparse extended information filter for local submap joining, SLSJF, is developed. There is no approximation involved in SLSJF apart from linearization processes. SLSJF contains not only the filter steps but also two important steps that are essential for real-world application of the EIF-based algorithms-a covariance submatrix recovery step and a data association step. The sparse information matrix together with the novel state vector and the covariance submatrix recovery procedure make the SLSJF algorithm computationally very efficient.</p><p>SLSJF achieves an exactly sparse information matrix with no information loss. The dimension of its state vector is significantly less than that of the full SLAM algorithm <ref type="bibr" target="#b4">[5]</ref>, where all the robot poses are included in the state vector. As it does not matter how the local maps are built, SLSJF can also be applied to large-scale range-only or bearing-only SLAM problem-first use range-only or bearing-only SLAM algorithms to build local maps, and then, fuse the local maps together using SLSJF.</p><p>For the successful application of SLSJF for local map joining, it is important that all the local maps are consistent. Thus, it is essential to use reliable SLAM algorithms to build the local maps.</p><p>More work is required to determine the best reordering strategy for SLSJF, improve the robustness of SLSJF to linearization errors, and extend SLSJF to 3-D local map joining. Research along these directions is underway.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Sparse</head><label></label><figDesc>Local Submap Joining Filter for Building Large-Scale Maps Shoudong Huang, Member, IEEE, Zhan Wang, and Gamini Dissanayake, Member, IEEE Abstract-This paper presents a novel local submap joining algorithm for building large-scale feature-based maps: sparse local submap joining filter (SLSJF). The input to the filter is a sequence of local submaps. Each local submap is represented in a coordinate frame defined by the robot pose at which the map is initiated. The local submap state vector consists of the positions of all the local features and the final robot pose within the submap. The output of the filter is a global map containing the global positions of all the features as well as all the robot start/end poses of the local submaps. Use of an extended information filter (EIF) for fusing submaps makes the information matrix associated with SLSJF exactly sparse. The sparse structure together with a novel state vector and covariance submatrix recovery technique makes the SLSJF computationally very efficient. The SLSJF is a canonical and efficient submap joining solution for large-scale simultaneous localization and mapping (SLAM) problems that makes use of consistent local submaps generated by any reliable SLAM algorithm. The effectiveness and efficiency of the new algorithm is verified through computer simulations and experiments. Index Terms-Extended information filter (EIF), extended Kalman filter, map joining, simultaneous localization and mapping (SLAM), sparse matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Structure of SLSJF: small ellipses indicate the objects involved in the local maps. Each object (e.g., the feature ) is only linked to its "nearby objects" (features and robot poses that share the same local map with it). The final global map state vector contains the locations of all the shaded objects.</figDesc><graphic coords="2,61.81,68.33,211.60,197.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Overall structure of SLSJF REQUIRE: A sequence of local maps: each local map contains a state vector estimate and a covariance matrix 1: Set local map 1 as the global map 2: For k = 2 : p (p is the total number of local maps), fuse local map k into the global map 3: End III. SLSJF ALGORITHM This section describes the various steps of SLSJF algorithm, including global map initialization and update, reordering of the global state vector, state vector and covariance submatrix recovery, and data association.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 2 :</head><label>2</label><figDesc>Fuse local map k + 1 into global map REQUIRE: global map and local map k + 1 1: Data association 2: Initialize the new features and X G (k +1)e in the global map 3: Update the global map 4: Reorder the global map state vector when necessary 5: Compute the Cholesky Factorization of I(k + 1) 6: Recover the global map state estimate XG (k + 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 3 : 1 :</head><label>31</label><figDesc>Data association between local map k + 1 and the global map REQUIRE: global map and local map k + 1 Determine the set of potentially overlapping local maps 2: Find the set of potentially matched features 3: Recover the covariance submatrix associated with X G ke and the potentially matched features 4: Use a statistical data association method to find the match 1) Set of Potentially Overlapping Local Maps: Local map i cannot overlap with local map k + 1 if the distance between the origins of the two maps in the global coordinate frame is larger than the sum of the two local map radii plus the possible estimation error. The radius of a local map is defined as the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Finding the potentially overlapping local maps: if the distance between the global position of the robot start pose in local map i and the global position of the robot start pose in local map k + 1 is larger than the sum of the two local map radii, then the two local maps cannot overlap.</figDesc><graphic coords="3,318.69,68.27,215.50,197.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Simulation results. (a) Robot trajectory and the global map obtained by SLSJF (red: feature, green: robot poses) superimposed with the EKF SLAM map (black) and the global map by EKF map joining (blue). (b) Close look at the estimate of the five features at the upper left corner of the map (a): dots (black) are true positions, solid ellipses (red) are from SLSJF, dotted ellipses (blue, coincide with red ones) are from EKF map joining, dashed ellipses (black) are from EKF SLAM. (c) Estimation errors of the 600 robot end poses by SLSJF, EKF map joining, and conventional EKF SLAM. (d) Sparse information matrix obtained by SLSJF (441 286 nonzero elements in a 6340 × 6340 matrix). (e) Time required for fusing each local map in SLSJF and EKF sequential map joining. (f) Comparison between the processing time using the proposed reordering and that using AMD reordering.</figDesc><graphic coords="6,122.04,68.31,354.20,474.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 (</head><label>4</label><figDesc>a) shows the map obtained by conventional EKF SLAM. The odometry and range-bearing observation data were</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Map joining results using Victoria Park dataset. (a) EKF SLAM result. (b) Map obtained by joining 200 local maps using SLSJF. (c) Sparse information matrix obtained by SLSJF. (d) Processing time for fusing each of the 200 local maps.</figDesc><graphic coords="7,105.95,68.26,378.00,336.48" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>The threshold n 0 needs to be properly chosen in order to make the SLSJF algorithm efficient. A smaller n 0 will make the incremental Cholesky factorization step (case (i) in Section III-G) more efficient but will also increase the total number of reordering and the direct Cholesky factorization operations (case (ii) in Section III-G). As a rule of thumb, n 0 can be chosen to be around one tenth of the dimension of the global state vector.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p><ref type="bibr" target="#b3">4</ref> The threshold d 0 is related to the parameter n 0 ; it also depends on the feature density of the environment. The guideline is that the number of features that are within distance d 0 to X G (k + 1)e is around half of n 0 .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>All time measurements in this paper are performed on a laptop computer with Intel Core 2 Duo T7500 at 2.2GHz, 3GB of RAM and running Windows, with all programs written in MATLAB. More simulation results are available at the Web site: http://services.eng.uts.edu.au/ ∼ sdhuang.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank Dr. U. Frese for very helpful suggestions and the anonymous reviewers for the valuable comments.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper was recommended for publication by Associate Editor J. Tardos and Editor L. Parker upon evaluation of the reviewers' comments. This work was supported in part by the Australian Research Council (ARC) Centre of Excellence programme funded by the ARC and in part by the New South Wales State Government. This paper was presented in part at the 2008 IEEE International Conference on Robotics and Automation, Pasadena, CA, May 19-23, 2008.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simultaneous localization and mapping with sparse extended information filters</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Durrant-Whyte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="693" to="716" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Square root SAM: Simultaneous localization and mapping via square root information smoothing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dellaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1181" to="1203" />
			<date type="published" when="2006-12">Dec. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exactly sparse extended information filters for feature-based SLAM</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Eustice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="359" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">D-SLAM: A decoupled solution to simultaneous localization and mapping</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dissanayake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="204" />
			<date type="published" when="2007-02">Feb. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Probabilistic Robotics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust mapping and localization in indoor environments using sonar data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="311" to="330" />
			<date type="published" when="2002-04">Apr. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Efficient solutions to autonomous mapping and navigation problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="http://www.acfr.usyd.edu.au" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Australian Centre Field Robot., Univ. Sydney</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A solution to the simultaneous localization and map building (SLAM) problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dissanayake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Durrant-Whyte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Csorba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Autom</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="241" />
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gaussian Markov distributions over finite graphs</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Speed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Kiiveri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="138" to="150" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visually mapping the RMS Titanic: Conservative covariance estimates for SLAM information filters</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Eustice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1223" to="1242" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tectonic SAM: Exact, out-of-core, submap-based SLAM</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steedly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dellaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2007 IEEE Int. Conf. Robot. Autom. (ICRA)</title>
		<meeting>2007 IEEE Int. Conf. Robot. Autom. (ICRA)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1678" to="1685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Data association in stochastic mapping using the joint compatibility test</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Autom</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="890" to="897" />
			<date type="published" when="2001-12">Dec. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">iSAM: Fast incremental smoothing and mapping with efficient data association</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kaess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dellaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2007 IEEE Int. Conf. Robot. Autom. (ICRA)</title>
		<meeting>2007 IEEE Int. Conf. Robot. Autom. (ICRA)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1670" to="1677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimization of the simultaneous localization and map building (SLAM) algorithm for real time implementation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Guivant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Nebot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Autom</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="242" to="257" />
			<date type="published" when="2001-06">Jun. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mapping large-scale environments using relative position information among landmarks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dissanayake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2006 Int. Conf. Robot. Autom</title>
		<meeting>2006 Int. Conf. Robot. Autom</meeting>
		<imprint>
			<biblScope unit="page" from="2297" to="2302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A proof for the approximate sparsity of SLAM information matrices</title>
		<author>
			<persName><forename type="first">U</forename><surname>Frese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2005 IEEE Int. Conf. Robot. Autom</title>
		<meeting>2005 IEEE Int. Conf. Robot. Autom<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="331" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Closing the loop with Graphical SLAM</title>
		<author>
			<persName><forename type="first">J</forename><surname>Folkesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="731" to="741" />
			<date type="published" when="2007-08">Aug. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generalized nested dissection</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numerical Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="346" to="358" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Treemap: An O(log n) algorithm for indoor simultaneous localization and mapping</title>
		<author>
			<persName><forename type="first">U</forename><surname>Frese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auton. Robots</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="122" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting locality by nested dissection for square root smoothing and mapping</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krauthausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dellaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Robot.: Sci. Syst</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data association in O(n) for divide and conquer SLAM</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guivant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf</title>
		<meeting>IEEE Int. Conf<address><addrLine>Atlanta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06">2007. Jun</date>
			<biblScope unit="page" from="27" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Closing a million-landmarks loop</title>
		<author>
			<persName><forename type="first">U</forename><surname>Frese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schroder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots Syst<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09-15">Oct. 9-15, 2006</date>
			<biblScope unit="page" from="5032" to="5039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient 6-DOF SLAM with treemap as a generic backend</title>
		<author>
			<persName><forename type="first">U</forename><surname>Frese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2007 IEEE Int. Conf. Robot. Autom. (ICRA)</title>
		<meeting>2007 IEEE Int. Conf. Robot. Autom. (ICRA)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="4814" to="4819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robocentric map joining: Improving the consistency of EKF-SLAM</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez-Cantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot. Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convergence and consistency analysis for extended Kalman filter based SLAM</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dissanayake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1036" to="1049" />
			<date type="published" when="2007-10">Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hierarchical SLAM: Real-time accurate mapping of large environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="588" to="596" />
			<date type="published" when="2005-08">Aug. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SLAM in largescale cyclic environments using the atlas framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1113" to="1139" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mobile robot localization and mapping in extensive outdoor environment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bailey</surname></persName>
		</author>
		<ptr target="http://www.acfr.usyd.edu.au/" />
	</analytic>
	<monogr>
		<title level="m">Shoudong Huang (M&apos;04) was born on December 8, 1969. He received the Bachelors&apos; and Masters&apos; degrees in mathematics and the Ph.D. degree in automatic control from Northeastern University</title>
		<meeting><address><addrLine>Shenyang, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">2002. 1987. 1990. 1998</date>
		</imprint>
		<respStmt>
			<orgName>Australian Centre Field Robot., Univ., Sydney</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
	<note>respectively</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
