<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Qi</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Center for OPTi-cal IMagery Analysis and Learning</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Center for OPTical Imagery Analysis and Learning</orgName>
								<orgName type="department" key="dep2">State Key Laboratory of Transient Optics and Photonics</orgName>
								<orgName type="department" key="dep3">Xi&apos;an Institute of Optics and Precision Mechanics</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>710119</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Jianzhe</forename><surname>Lin</surname></persName>
							<email>linjianzhe@opt.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Center for OPTi-cal IMagery Analysis and Learning</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Yuan</forename><surname>Yuan</surname></persName>
							<email>yuany@opt.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Center for OPTi-cal IMagery Analysis and Learning</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1737F28CF094640298AFA38222A9A543</idno>
					<idno type="DOI">10.1109/TNNLS.2015.2477537</idno>
					<note type="submission">received October 6, 2014; revised July 28, 2015 and September 1, 2015; accepted September 5, 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Band selection</term>
					<term>deep learning</term>
					<term>hyperspectral image (HSI) classification</term>
					<term>manifold ranking (MR)</term>
					<term>saliency</term>
					<term>stacked autoencoders (SAEs)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Saliency detection has been a hot topic in recent years, and many efforts have been devoted in this area. Unfortunately, the results of saliency detection can hardly be utilized in general applications. The primary reason, we think, is unspecific definition of salient objects, which makes that the previously published methods cannot extend to practical applications. To solve this problem, we claim that saliency should be defined in a context and the salient band selection in hyperspectral image (HSI) is introduced as an example. Unfortunately, the traditional salient band selection methods suffer from the problem of inappropriate measurement of band difference. To tackle this problem, we propose to eliminate the drawbacks of traditional salient band selection methods by manifold ranking. It puts the band vectors in the more accurate manifold space and treats the saliency problem from a novel ranking perspective, which is considered to be the main contributions of this paper. To justify the effectiveness of the proposed method, experiments are conducted on three HSIs, and our method is compared with the six existing competitors. Results show that the proposed method is very effective and can achieve the best performance among the competitors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>targets and ignore the unnecessary backgrounds. Therefore, saliency detection is generally considered as an efficient preprocessing step or high-level feature extraction procedure in many applications <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, such as multimedia retrieval, object detection, video compression, and image resizing.</p><p>Though tremendous effort toward saliency detection has been made, and many works achieve manifest performance on public data sets, the general-purpose saliency detection is still far from satisfying. One primary reason, we think, is the unclear definition of saliency, which makes the task-specific application less compatible. Considering this deficiency, we restrict the scope of saliency interpretation to a specific area, hyperspectral image (HSI) classification <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. In this case, the examined HSI consists of hundreds of spectral bands for the same scene, enabling accurate discrimination of different land cover materials. Generally speaking, the finer spectral resolution will lead to better discriminative ability. But that does not mean more data are always needed. For one thing, the huge volume of data implies large computational complexity. For another, the low number of labeled data in HSI is prone to result in the Hughes phenomenon <ref type="bibr" target="#b8">[9]</ref>. Therefore, a balance between the spectral number and the classification performance is highly desired. In order to make a good compromise, the salient bands from the entire hyperspectral volume should be selected, extracting the most informative clues and abandoning the less important ones <ref type="bibr" target="#b9">[10]</ref>. Clearly, the saliency formulation in this context has a meaningful explanation and the salient band definition is the key to success.</p><p>Actually, the salient band selection is not the only means for reducing the hyperspectral data redundancy. Feature extraction is also an alternative. But differently, feature extraction techniques transform the original high-dimensional data to low-dimensional data through certain kinds of projections, such as principle component analysis <ref type="bibr" target="#b10">[11]</ref>, independent component analysis <ref type="bibr" target="#b11">[12]</ref>, and discrete wavelet transform <ref type="bibr" target="#b12">[13]</ref>. This treatment cannot preserve the physical meaning of the original bands, which might be very crucial for some geology analysis. Considering this fact, the salient band selection is usually preferred for the HSI processing.</p><p>Although many efforts toward the salient band selection have been made during the past decades, the selection criterions are mainly based on the similarity metrics. One disadvantage of this strategy is that most of these criterions are computed under the assumption that the original data lie on the Euclidean space. But this is not the case from time-to-time because the data may lie along a low-dimensional manifold embedded in a high-dimensional space, where the low-dimensional space reflects the underlying parameters and a high-dimensional space is the feature space <ref type="bibr" target="#b13">[14]</ref>. Therefore, the traditional treatment is inappropriate. In order to make a more fair measurement, we tackle this problem in the intrinsic manifold structure collectively revealed by a great amount of data. The proposed method is named as salient band selection via manifold ranking (MR). Three contributions are claimed in this paper.</p><p>1) Propose a novel method of MR-based band selection. Instead of rating the similarities in the Euclidean space, the manifold structure is taken into consideration to properly assess the hyperspectral data structure. The associated measurement is input to a ranking operation and a subsequent band selection is based on the obtained ranking score. This is a novel alternative that reformulates the hyperspectral band selection as a ranking problem. 2) Estimate the interband distance in a batch manner. Most existing techniques for band selection always compute the distance between two individual bands. The calculated results then serve as guidance for band selection. However, this strategy is not suitable for the sequential selection because the selected band at this time might resemble the one selected at previous time. In our implementation, we treat the already selected batch of bands as the query, and the examined band is compared with the whole batch. This can ensure the further selected band is distinct with the previously selected ones. 3) Provide a thorough comparison using different band selection methods and classifiers. In order to validate the effectiveness of the proposed method, we compare it with several recently presented methods. Besides, we also test these methods on typical classifiers that are frequently used for HSI classification. These experimental comparisons are meaningful references for other researchers. Furthermore, the possibility of popular deep learning technique as a classifier is also discussed in this paper. The rest of this paper is organized as follows. Section II briefly reviews the existing works on the topic of salient band selection. Section III gives a detailed description of the proposed method, which is salient band selection via MR. Section IV presents the experimental results to justify the effectiveness of this paper. Section V extends the work to the deep learning framework and discusses the associated problems. Finally, the conclusion is drawn in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we will review three topics that are closely related to this paper. First, salient band selection is primarily investigated, which is directly the related work of the proposed method. Then, saliency detection in computer vision and HSI classification are briefly introduced. These two points are not the main focus of this paper but have certain relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Salient Band Selection</head><p>The salient band selection is enabled by two key elements. The first one is an appropriate criterion, which measures the difference between bands. For this purpose, the existing methods investigate various indices <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>, such as mutual information (MI), spectral angle mapper distance, information divergence, correlation coefficient, and volume-based distance. Apart from these traditional measures, other new criteria are also presented recently, including sparse reconstruction error and approximate MI.</p><p>The second one is the selection strategy. According to the band selection procedure, existing works can be divided into two categories: 1) sequential selection and 2) batch selection. For the sequential selection, the desired bands are chosen one by one, instead of all at a time. For example, Chang et al. <ref type="bibr" target="#b17">[18]</ref> construct a loading factor by eigenvalue and eigenvector analysis to rank bands according to the effectiveness of their classification abilities. After this band prioritization step, the spectral association is then decorrelated to eliminate the similar bands among the selected bands. Ball and Bruce <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> first use a forward selection to choose the band set enabling maximum Receiver Operating Characteristic curve (ROC) curve area A z . Then, a backward rejection is enforced to remove the bands that cannot help the A z criterion. In the end, the selected bands are input to the level-set segmentation process. Du and Yang <ref type="bibr" target="#b20">[21]</ref> employ a strategy similar to that in <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. But the criterion for selecting band is different, in which the potential band is determined as the one with the largest linear reconstruction error from existing bands. Yang et al. <ref type="bibr" target="#b21">[22]</ref> select the bands with an incremental manner. They initially choose one band and project others to its orthogonal subspace. Then, the band with maximum projection, represented by a stochastic feature, is selected. This procedure is repeated until the desired number of bands is obtained.</p><p>As for the batch selection, more distinctive techniques are designed. Sun et al. <ref type="bibr" target="#b22">[23]</ref> pay more attention to the band quality instead of band information. They introduce a new index to measure the quality of a data cube by combining the noise adjusted principle components with maximum determinant of covariance matrix. Based on this, the minimum noise band selection method is proposed, aiming at selecting bands with high quality. The selection process begins with full bands set, followed by removing bands successively. Venkataraman et al. <ref type="bibr" target="#b23">[24]</ref> use the manual grouping and the automated grouping to divide the original bands into subsets. Subsequently, features are extracted by the supervised and unsupervised methods. Martínez-Usó et al. <ref type="bibr" target="#b15">[16]</ref> utilize a similar strategy. But the clustering method is hierarchical, which can ensure producing the minimum variance partition. Then, the representative band for each group is selected as the one that is least correlated with the others. Xia et al. <ref type="bibr" target="#b24">[25]</ref> divert from the general idea of selecting the bands that are distinctive from others. Instead, they construct a graph network using the image pixels and choose bands that can form the most approximate network construction compared with the original data. Chang and Wang <ref type="bibr" target="#b25">[26]</ref> propose a constrained energy minimization (CEM) for band selection. It linearly constrains the examined band image while minimizing the interfering effects caused by the remaining bands. Yuan et al. <ref type="bibr" target="#b26">[27]</ref> present an evolutionary immune clone strategy to handle the computational burden of possible band combinations. Besides, a novel multitask sparsity pursuit-based criterion is adopted to evaluate the performance of each candidate band set. Similar work can be found in <ref type="bibr" target="#b16">[17]</ref>, who use the trivariate MI to approximate the MI measure. In addition, a clone search strategy is taken to find a good solution with low time and space cost. The work of Chang et al. <ref type="bibr" target="#b27">[28]</ref> is also of this type, while parallel simulated annealing is adopted.</p><p>Besides the two aspects, other researchers dig alternatively from the related topics of a salient band selection. Demir and Erturk <ref type="bibr" target="#b28">[29]</ref> concentrate on reducing the computational complexity before formal band selection. They use one-bit transform of each band to remove the noisy and less discriminative bands, which is decided via the number of transitions in the one-bit map. Yang et al. <ref type="bibr" target="#b29">[30]</ref> focus on the parallel implementations via emerging general-purpose graphics processing units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Saliency Detection in Computer Vision</head><p>Saliency detection is a hot topic in recent years in the computer vision community. Since the pioneer work of Koch and Ullman <ref type="bibr" target="#b52">[53]</ref>, numerous methods have been presented. In general, these methods can be categorized into two classes <ref type="bibr" target="#b30">[31]</ref>: 1) contrast-based computational model and 2) learning-based adaptive model. For the first type, the saliency model is defined beforehand in terms of the color/ texture contrast. No matter what the input image is, the saliency value is calculated with the same predefined formula. For the second type, the machine learning techniques are usually employed to adaptively train a saliency model in a particular data set. With respect to different training set, the learned model parameters might differ with each other. However, despite the extensive research in these two paradigms, few works have concentrated on the specific definition of saliency detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Hyperspectral Image Classification</head><p>HSI classification has been researched a lot in remote sensing field. Traditional methods primarily focus on the spectral feature with adjusted classifier, such as support vector machines (SVMs) <ref type="bibr" target="#b31">[32]</ref> and k-nearest neighborhood (kNN) <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. However, only utilizing the spectral clue achieves a limited performance. The joint spectral and spatial classification techniques <ref type="bibr" target="#b34">[35]</ref> have recently attracted much more attention because they can considerably overcome the salt and pepper noise that often exists in HSI. For example, morphological filters <ref type="bibr" target="#b35">[36]</ref>, segmentation <ref type="bibr" target="#b36">[37]</ref>, Markov random fields <ref type="bibr" target="#b37">[38]</ref>, and empirical mode decomposition with spectral gradient enhancement <ref type="bibr" target="#b38">[39]</ref> are recently presented and they demonstrate a superior performance. Though these methods differ in their ways of utilizing the HSI data, they all try to explore the abundant clues from the original HSI volume. Unfortunately, they neglect a fact that the large number of bands might be redundant from time-to-time. Trying to select the most critical bands may still get a good result, at the same time reducing the storage burden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>In this paper, we present a salient band selection method based on MR for HSI classification. The flowchart of the method is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. First, the original band set is grouped into subsets, within which each band image has similar characteristics to the others. Then, the representative of each group is chosen by clone selection algorithm, with the principle that the representatives should be far to each other. After that, the representative bands are treated as queries and the other bands will be ranked according to the queries. Finally, the most dissimilar band will be added to the query set and the whole procedure repeats again until the desired number is achieved. In the following, we will focus on the queries generation and the MR steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Query Generation</head><p>Our aim is to select the most distinctive bands to support classification. For this purpose, the interband similarity metrics are not suitable because they only reflect a local perspective. For instance, the examined two bands may have large distance, and selecting them seems to be a good choice. But putting them in the whole band set, they might highly resemble the other selected ones, which is undesirable. The main reason inducing this fact is that we improperly check the relationship of band pairs and lack the global view to systematically balance all the selected bands. To overcome this limitation, an MR technique is adopted <ref type="bibr" target="#b39">[40]</ref>. Instead of treating the bands individually, we adopt a batch manner. We first get several query band representatives, and then the remaining bands are ranked according to their similarities to all the queries. Every time the ranking is conducted globally, considering the full data relationships.</p><p>The general idea of MR is to list the data in order with respect to the similarities to the predefined queries. In this paper, the queries are initially specified as the original band set representatives. This can be achieved by a simple clustering method, such as k-means, and then choosing the representatives in each cluster. However, we think the selected representatives should not only have maximum interdistances (distinctiveness among clusters) but also minimum intradistances (representativeness with a cluster). The formal formulation is as follows.</p><p>In this paper, each band is denoted as a point in the high-dimensional space. Suppose there are k mean centers {μ 1 , μ 2 , . . . , μ k } after the clustering of the original bands and the desired representatives are {r 1 , r 2 , . . . , r k }. The sum of interdistances are then defined as D inter = (1/2) i, j =1:k d(r i , r j ), where d(,) measures the Euclidean distance between two points, and sum of intradistances are similarly calculated as</p><formula xml:id="formula_0">D intra = i=1:k j =1:n i d(μ i , e i, j</formula><p>), where e i, j is the j th element in cluster i and n i is the number of elements within it. The final criterion is the combination of the two terms arg max</p><formula xml:id="formula_1">{r 1 ,r 2 ,...,r k } D inter D intra . (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>By searching for the solution of the objective function, we can get the desired representatives. However, maximizing this criterion is not an easy task because there are numerous candidate combinations. A traversal search is impossible and impractical. Fortunately, inspired by the success of natural computation <ref type="bibr" target="#b40">[41]</ref>, the clone selection algorithm <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> is utilized to solve this problem. This algorithm is motivated by the immunology and is a typical paradigm of artificial immune systems. It uses the basic immune principles to help solve complex engineering tasks. To be specific, when an animal is exposed to an antigen, it will produce particular antibodies with different affinities. Those antibodies with high affinity values will respond more adequately to the antigen. After the interaction, the antibodies will be cloned with a number proportional to its affinity values and at the same time, the obtained clones are also accelerated by mutation, the probability of which is inversely proportional to its affinity. With this strategy, the animal body can effectively eliminate the antigen infection.</p><p>Motivated by the efficiency of the clone selection principle, this work employs it to get the solution of (1). Similarly, the original problem of establishing the band representatives is treated as the antigen, and the chosen set of bands is taken as the antibody. By maximizing the affinity function defined in (1), the best antibody can be selected. Initially, we randomly select l sets of representatives, with each set containing one band from each cluster. This means there are l antibodies in the beginning. Then, these antibodies will subject to three steps of processing, clone, mutation, and selection.</p><p>1) Clone: The antibodies will be cloned according to their affinities to the antigen. Higher affinity indicates more copies will be obtained. 2) Mutation: The antibodies after the above step will mutate to generate new antibodies, which means any band contained in an antibody may change to the other band in the same cluster. The probability of mutation is inversely proportional to the affinity of the antibody. 3) Selection: After the clone and mutation procedure, there will be a larger number of antibodies compared with the initial set, which demonstrates a more various diversity and possibility. We then select the l most promising ones to start the next round of processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Manifold Ranking</head><p>With the obtained k queries, the other bands are ranked according to them. Suppose the band with the lowest ranking score is found, which means it is the most dissimilar one to the queries. Then, it will be added to the original query set, the number of which now becomes k + 1. With the updated query set, the remaining bands are further ranked with respect to it. This operation repeats until the desired K bands are identified (in general, K is predefined by the user). This strategy can ensure the newly selected band is much different from what have been selected. Clearly, this strategy is fundamentally different from traditional calculation of pairs of bands.</p><p>As for the ranking procedure, the manifold structure of data is considered because it can explore the intrinsic data nature <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b43">[44]</ref>. In this step, the goal is to learn a ranking function, which defines the relevance between the queries (representative bands) and the unlabeled data (remaining bands). In the following, a detailed introduction is followed.</p><p>Suppose a set of given points (hyperspectral bands) X = {x 1 , x 2 , . . . , x n } ∈ R m , where m is the dimensionality of the data (the number of pixels for a single band image) and n is the number of the data (the band number). Some of these points are labeled beforehand as queries and the others are unlabeled. The aim is to rank the unlabeled ones according to their relevance to the queries. Before detailed explanation of the method, notations are first introduced <ref type="bibr" target="#b44">[45]</ref>. Let f : X → R denote a ranking function that assigns every point x i a ranking score f i , leading to a vector of f</p><formula xml:id="formula_3">= [ f 1 , f 2 , . . . , f n ].</formula><p>We also define an indicator vector y = [y 1 , y 2 , . . . , y n ] with y i = 1 means x i is a query and y i = 0 otherwise. For an appropriate measurement of the ranking function, we define a graph network G = (V, E) on the data points X , where V is the vertex set, and E is the edge set. We also define an affinity matrix W = [w i j ] n×n with</p><formula xml:id="formula_4">w i j = e -d 2 (x i ,x j )/2σ 2 (2)</formula><p>if x i and x j are connected; otherwise w i j = 0. For the HSI context, if two points (bands) are neighboring relationship, they are assumed to be connected. The distance between two connected points d(x i , x j ) is computed as the Euclidean distance between them. Consequently, the degree matrix is denoted as D = diag{d 11 , . . . , d nn }, where d ii = j w i j . With these definitions, the optimal ranking is derived by solving the following optimization problem <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>: where the first term is the smoothness constraint indicating the neighboring points should not differ greatly, and the second term the fitting constraint implying the ranking score should not divert too much from the initial query assignment. μ balances the contributions of the two terms. To solve the above problem, we set the derivative of (3) to be zero. Let S = D -1/2 WD -1/2 be the normalized Laplacian matrix. The desired ranking function can be obtained as</p><formula xml:id="formula_5">f * = argmin f 1 2 ⎛ ⎝ n i, j =1 w i j f i d ii - f j d j j + μ n i=1 f i -y i 2 ⎞ ⎠<label>(3</label></formula><formula xml:id="formula_6">f * = (I -αS) -1 y (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>where I is the identity matrix and α = 1/(1 + μ). With this solution, the ranking for each point is finally acquired, which indicates all the other hyperspectral bands are ranked with reference to the query bands. Therefore, the one with the lowest score is set as the most dissimilar one compared with the queries and it is added into the query set to start another round of ranking. The whole procedure is outlined in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, intensive experiments are conducted to prove the effectiveness of the proposed method. First, the data set used in the experiments is introduced. Then, the comparative methods are selected, with a brief analysis. After that, the experimental setup is detailed and the results are shown and analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Data Sets</head><p>To verify the effectiveness of the proposed framework, we complete our experiments on three traditional data sets, Indian Pines, Salinas Scene, and The Pavia University. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparative Methods</head><p>In order to justify the effectiveness of the proposed MR method, several competitors are employed to conduct comparison. They are of two prototypes: 1) CEM selection <ref type="bibr" target="#b25">[26]</ref> and 2) clustering-based band selection (CBBS) <ref type="bibr" target="#b15">[16]</ref>.</p><p>1) For the CEM selection, each band image is represented as a column vector. Then, an energy function reflecting the band image correlation is defined. For solving this function, a linear constraint is enforced on one band and all the bands are used to calculate the correlation matrix. With the obtained solution, two criteria for band selection are defined: 1) band correlation minimization and 2) band correlation constraint. The induced algorithms are denoted by CEM-Band Correlation Minimization (BCM) and CEM-Band Correlation Constraint (BCC). However, the enormous size of band vectors can cause tremendous computing time. In order to mitigate this problem, the band image is treated as matrix instead of vector conversion. This idea can be traced back to the linearly constrained minimum variance (LCMV) <ref type="bibr" target="#b46">[47]</ref> and the induced algorithms are similarly denoted as LCMV-BCM and LCMV-BCC. 2) For the CBBS, a hierarchical clustering structure, Ward's linkage method <ref type="bibr" target="#b47">[48]</ref> to be specific, is used to group bands. Then, the representative for each group is chosen as the one having the highest correlation with the other bands in the group. It can minimize the intracluster variance and maximize the intercluster variance.</p><p>The criterion for measuring the band similarity is MI and Kullback-Leibler (KL) divergence. Therefore, the resulted comparative methods are denoted as CBBS-MI and CBBS-KL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Setup</head><p>To evaluate the effectiveness of the proposed method, comparisons should be conducted. Two factors need to be considered here, the influence of selected band number and the effect of different classifiers. For one specific classifier, we set the selected band number every five intervals from small to large. This can test the ability of different band selection methods under fixed band numbers. In order to see the robustness of band selection methods, we also vary the classifiers to repeat the above processing. Four widely used classifiers are adopted in our experiments, Naive Bayes, kNN,  classification and regression trees (CARTs), and SVMs, which are the benchmark classifiers <ref type="bibr" target="#b48">[49]</ref> used in HSI classification.</p><p>There are four parameters in the experiments to be determined. They are the edge weight related σ , the balance between the smoothness term and the fitting term α, the initial clustering number k, and the number of antibodies l. The first two are empirically set as σ 2 = 0.1, α = 0.99 according to <ref type="bibr" target="#b44">[45]</ref>. As for k and l, a lot of experiments have been done to choose the best parameters. We set the two variables as different values and then check their performance under various classifiers and images. From Figs. <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>, we can see that k = 10 and l = 4 is the best choice. With these two values, the averaged performance on the three images is satisfying for each classifier.</p><p>Note the initial query number k is generally smaller than the desired band number. For one reason, this means fewer initial clusters and more representative and discriminative queries. For another, if we have enough query bands, there is no need to conduct the MR procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Results</head><p>In this section, we will discuss the band selection results on different HSIs, with respect to the different classifiers. Two kinds of results are shown in the experiments. The first kind is the band number-accuracy curves and the second kind is the averaged accuracy bars. Please note the accuracy is defined as the proportion of correctly classified pixels to all the corresponding class pixels in the image.</p><p>For the Indian Pines image, the performance of our MR method differs from classifier to classifier. This is shown in Figs. <ref type="figure" target="#fig_3">4</ref> and<ref type="figure" target="#fig_4">5</ref>. With the SVM and kNN classifiers, MR generally achieves the best classification accuracy. This superiority is more manifest when the selected band number is small, which is also the case for the CART and Naive Bayes classifiers. But when the selected bands increase, the CART and Naive Bayes are no better than the other competitors, especially when the band number surpasses 50.</p><p>For the Salinas Scene, the superiority of our MR method is more obvious as shown in Figs. <ref type="figure" target="#fig_5">6</ref> and<ref type="figure" target="#fig_6">7</ref>, particularly for the SVM, kNN, and CART. At every selected band, MR acquires much higher accuracy than all the other competitors. When it comes to the Naive Bayes classifier, the result is similar to that of the Indian Pines image. If the selected band number is small, MR method works very well. But when the band number goes beyond 50, LCMV-BCM ranks first. However, the difference between MR and LCMV-BCM is only 3% and MR still outperforms all the other ones.</p><p>For the Pavia University, the results are more different, as shown in Figs. <ref type="figure" target="#fig_7">8</ref> and<ref type="figure" target="#fig_8">9</ref>. The proposed MR method can classify the pixels more precisely on the kNN and CART classifiers. But for the SVM classifier, the difference from the other competitors except CEM-BCM and CEM-BCC is not so apparent. Unfortunately, the results of the Naive Bayes classifier fluctuate heavily and cannot see an absolute superiority.</p><p>After introducing the experimental results, we will give some in-depth analysis. The first question is about the performance on different images. In general, the proposed MR method is more effective than the other competitors. This is mainly due to the MR method and batch comparison strategy. But this superiority is not equally demonstrated on the three images. The Salinas Scene is a typical example, while the Pavia University and the Indian Pines image are less obvious. This can be understandable because the performance of one specific method is actually related to the training and testing data. Since the experimental subject varies with each other, the performances have more or less disparities.</p><p>The second question is about the performance on different classifiers. The proposed MR method is more stable and robust on the SVM, kNN, and CART. For the Naive Bayes classifier, MR has a vibrate result, especially on the Pavia University. We also find with the increase of band number, the MR method with Naive Bayes will have a decreasing performance. This is because the Naive Bayes models each feature dimension as an independent and normal distribution. If we sample the feature space randomly, the obtained samples can reflect the statistics rightly. But our operation is to select the samples that are dissimilar with each other, using the MR technique. Therefore, the more the selected bands, the more the true distribution will be distorted.</p><p>The third question is about the band number. There is a phenomenon that the performance is better when the band number is larger. But the superiority of the proposed MR method is more evident when the band number is small. This is because for the purpose of hyperspectral band selection,  we aim to choose the most representative and the distinctive bands from the original large volume of bands. This operation can enhance the computational efficiency and relieve the storage burden at the same time. From this point of view, if the selected band number is not large but the performance of classification is satisfying, we can say the band selection method is effective and of great value. Fewer bands while good classification performance is encouraged for a band selection method. Therefore, we think the performance with a smaller band number can reflect the real ability and meaning of the band selection method. The fact that our MR method is more effective when the selected number is small just proves the success of MR compared with the other competitors. In fact, the small number of bands is of great use in practice. With the increase of data volume, the requirement for storage and processing ability is demanding. If we can reduce the original data volume while retaining its acceptable performance, the designed method might be helpful.</p><p>The fourth question is about the comparison with the full band classification. We conduct experiments using the whole image cube and the results are as follows: Salinas Scene [SVM(0.9078) kNN(0.8594) CART(0.8248) NaiveBayes(0.7741)],</p><p>Indian Pines [SVM(0.7736) kNN(0.6543) CART(0.5400) NaiveBayes(0.5509)], and Pavia University [SVM(0.8717) kNN(0.7379) CART(0.7012) NaiveBayes(0.6622)]. Comparing the band selection method (Figs. <ref type="figure" target="#fig_6">5, 7,</ref> and<ref type="figure" target="#fig_8">9</ref>) with the full band method, we can find that the proposed band selection method does not decrease the performance very much. For each image and classifier, abandoning most redundant bands only leads to a small amount of accuracy drop (&lt;5%) for the classification task. This means our band selection method is very effective and useful. Though we only select a limited number of bands, we can achieve an acceptable performance.</p><p>To sum up, the proposed method has distinct performance on the three images and with the various classifiers. However, we can say our method is more superior than the other competitors of the salient band selection methods. This superiority is more obvious when the selected band number is small.  classification process. In this section, we will talk about the state of the art classifier-deep neural networks <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref> for HSI classification combined with our band selection process. For this purpose, there are several types of deep architectures, such as deep belief networks, deep Boltzmann machines, convolutional neural networks, and stacked autoencoders (SAEs). In this paper, we mainly focus on the SAEs <ref type="bibr" target="#b51">[52]</ref>.</p><p>An AE has the ability to self-express the original input. It includes two parts: 1) encoder and 2) decoder. The first part reexpresses the input vector in a higher level through the hidden layers and the second part uses the same parameter to reconstruct the original input. After the training procedure, the reconstruction layers are removed and the learned high-level features lie in the hidden layers. This can be utilized for direct classification or as the input of a higher layer to produce a deeper architecture. The SAEs are actually a concatenation of single AE, with the output of each AE as the input of another one. Each layer is a higher level expression of the previous layer, and the finally learned features have certain kinds of semantic meanings and are more appropriate for the future classification.</p><p>Unfortunately, deep networks including SAE have a disadvantage of the overfitting problem, due to the small number of training samples and the large number of model parameters. Deeper networks generally have more powerful ability, but are harder to train. Another serious problem is that the architecture of deep networks is not easy to determine. Most of the success heavily relies on the designer's experience. All these factors make the deep learning related tasks formidable.</p><p>In this paper, the flowchart of the processing steps are shown in Fig. <ref type="figure" target="#fig_9">10</ref>. The input HSI first goes through the band selection operation. Then, the resulted data vectors are input to the SAEs. After that, the logistic regression that is learned together with the deep parameters, is used to classify the data. The SAEs have a structure of K -50-50-20 nodes, where K is the number of selected bands. The experimental results are shown in Fig. <ref type="figure" target="#fig_10">11</ref>.</p><p>From Fig. <ref type="figure" target="#fig_10">11</ref>, we can see clearly that the proposed deep networks perform stably for each HSI. But the performance is not the best compared with the results shown in Figs. <ref type="figure" target="#fig_3">4,</ref><ref type="figure" target="#fig_5">6</ref>, and 8. The reasons are analyzed as follows. First, the performance does not improve with the increase of the band number. Generally speaking, more selected bands   will lead to better classification accuracy. This is true for the traditional classifiers, but is not fully right for the deep networks. The reason is that the dimensionality of the visible layer in SAE equals to the dimensionality of the input vector. The increased band number will lead to higher input dimensionality, implying more parameters and connections in the networks. The effect of increased bands compromises with that of the added parameters. Therefore, the performance does not improve much, as shown in Fig. <ref type="figure" target="#fig_10">11</ref>. Second, the model structure is not necessarily the best. In our experiments, we find different layers and nodes can affect the final results greatly. There is no recognized principle to determine these factors. Therefore, it is actually very hard to get a properly configured deep networks. Sometimes, we have to try many times to establish an acceptable structure. Third, we think the SAEs have certain kind of overfitting. There are all together 50 × 50 × 20 × K parameters in the model. Unfortunately, only 10% pixels of the input HSI are used for training. At the same time, it is difficult to do data augmentation for HSI. All these factors make the performance not very satisfying.</p><p>To summarize, the deep networks are extraordinarily popular in the vision community. But there are several unresolved problems associated with them. To make the deep structure more rationale, more deep research is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>Saliency definition is a critical factor that influences the saliency detection performance. In this paper, we formulate saliency in the context of band selection in the HSI classification and propose an MR-based selection method. In order to prove its rightness, intensive experiments and comparisons are conducted. Results show that the proposed method is effective and outperforms the competitors.</p><p>The contributions are threefolds. First, the band selection is alternatively treated as a novel MR problem. Second, the interband distance is measured in a batch manner. Third, we have provided a meaningful reference for other researchers with the abundant experimental results and comparisons, together with the discussion on the popular deep learning extension. In the future, how to effectively and systematically design a deep learning model for HSI classification is the next step.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Flowchart of the proposed salient band selection method via MR.</figDesc><graphic coords="3,104.75,79.97,71.54,79.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Classification performance under different choices of k for SVM, kNN, CART, and Naive Bayes classifiers. Each curve is averaged on the three HSIs (Indian Pines, Salinas Scene, and Pavia University).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. performance under different choices of l for SVM, kNN, CART, and Naive Bayes classifiers. Each curve is averaged on the three HSIs (Indian Pines, Salinas Scene, and Pavia University).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. selection results on the Indian Pines image. (a)-(d) Results by SVM, kNN, CART, and Naive Bayes classifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Average band selection results on the Indian Pines image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Band selection results on the Salinas Scene image. (a)-(d) Results by SVM, kNN, CART, and Naive Bayes classifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Average band selection results on the Salinas Scene image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Band selection results on the Pavia University image. (a)-(d) Results by SVM, kNN, CART, and Naive Bayes classifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Average band selection results on the Pavia University image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Flowchart using SAE for HSI classification.</figDesc><graphic coords="9,164.27,593.09,71.06,77.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. selection results by the SAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>)</head><label></label><figDesc>Algorithm 1 Salient Band Selection via Manifold Ranking Input: X = {x 1 , x 2 , . . . , x n }, K .</figDesc><table><row><cell>Initialize: k, σ , μ, l.</cell></row><row><cell>Step1: Get the k clustering groups.</cell></row><row><cell>Step2: Use clone selection strategy to establish the group</cell></row><row><cell>representatives as the initial queries.</cell></row><row><cell>Step3:</cell></row><row><cell>while not enough bands are selected do</cell></row><row><cell>1: Rank the other bands according to the queries.</cell></row><row><cell>2: Select the most dissimilar one as the new band.</cell></row><row><cell>3: Update the query set with the newly established band.</cell></row><row><cell>end while</cell></row><row><cell>Output: K bands.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The image size is 512 × 217, with a spatial resolution of 3.7 m/pixel and spectral coverage within 0.4-2.5 μm. There are also224  spectral bands and 16 classes of interest, including vegetables, bare soils, and vineyard fields. 3) The Pavia University was acquired by the ROSIS sensor during a flight campaign over Pavia, Northern Italy in 2002. The sensor generates 115 spectral bands ranging from 0.43 to 0.86 μm. Removing the 12 noisiest bands, the 103 bands are retained, and the image size is 610 × 340. The geometric resolution is 1.3 m/pixel and nine classes of land cover objects are included.</figDesc><table><row><cell>1) Indian Pines image was gathered by AVIRIS sensor</cell></row><row><cell>over the Indian Pines test site in North-Western</cell></row><row><cell>Indiana in 1992. It consists of 145 × 145 pixels and</cell></row><row><cell>224 spectral reflectance bands in the wavelength range</cell></row><row><cell>of 0.</cell></row></table><note><p><p>4-2.5 μm. The spatial resolution is 20 m/pixel. The 16 classes of vegetation and forests are included in the image and the ground truth labels are publicly available. In general, the water absorbtion bands are removed, leading to a total of 200 bands.</p>2) The Salinas Scene was also captured by AVIRIS sensor in 1998, but at a different location in Salinas Valley, California.</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Basic Research Program of China (Youth 973 Program) under Grant 2013CB336500, in part by the State Key Program of National Natural Science of China under Grant 61232010, in part by the National Natural Science Foundation of China under Grant 61172143, Grant 61105012, and Grant 61379094, in part by the Natural Science Foundation Research Project of Shaanxi Province under Grant 2015JM6264, in part by the Fundamental Research Funds for Central Universities under Grant 3102014JC02020G07 and 3102015BJ(II)JJZ01, and in part by the Open Research Fund through the Key Laboratory of Spectral Imaging Technology, Chinese Academy of Sciences.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast-learning adaptive-subspace self-organizing map: An application to saliency-based invariant image feature construction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laurent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="746" to="757" />
			<date type="published" when="2008-05">May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scale-invariant amplitude spectrum modulation for visual saliency detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1206" to="1214" />
			<date type="published" when="2012-08">Aug. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An objectoriented visual saliency detection framework based on sparse coding representations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2009" to="2021" />
			<date type="published" when="2013-12">Dec. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Background prior-based salient object detection via deep reconstruction residual</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1309" to="1321" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">High quality image resizing</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="348" to="356" />
			<date type="published" when="2014-01">Jan. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Targeting accurate object extraction from an image: A comprehensive study of natural image matting</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="207" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral imagery with neural networks: Comparison to conventional tools</title>
		<author>
			<persName><forename type="first">E</forename><surname>Merényi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Farrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Taranik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Minor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Appl. Signal Process</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2014-12">Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Jointly learning the hybrid CRF and MLR model for simultaneous denoising and classification of hyperspectral imagery</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1319" to="1334" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the mean accuracy of statistical pattern recognizers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="63" />
			<date type="published" when="1968-01">Jan. 1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distance metrics and band selection in hyperspectral processing with applications to material identification and spectral libraries</title>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1552" to="1565" />
			<date type="published" when="2004-07">Jul. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient hierarchical-PCA dimension reduction for hyperspectral imagery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>El-Ghazawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>El-Askary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Le-Moigne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th IEEE Int. Symp. Signal Process</title>
		<meeting>7th IEEE Int. Symp. Signal ess<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-12">Dec. 2007</date>
			<biblScope unit="page" from="353" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Independent component analysis-based dimensionality reduction with applications in hyperspectral image analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-I</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1586" to="1600" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Feature extraction and selection hybrid algorithm for hyperspectral imagery classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th IEEE Int. Geosci. Remote Sens. Symp</title>
		<meeting>29th IEEE Int. Geosci. Remote Sens. Symp<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07">Jul. 2010</date>
			<biblScope unit="page" from="72" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithms for manifold learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">School Comput. Sci., Univ. California</title>
		<imprint>
			<date type="published" when="2005">2008-0923, Jun. 2005</date>
			<pubPlace>San Diego, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep. CS</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Relevance-based feature extraction for hyperspectral images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mendenhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Merenyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="658" to="672" />
			<date type="published" when="2008-04">Apr. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Clusteringbased hyperspectral band selection using information measures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Martínez-Usó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Sotoca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>García-Sevilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4158" to="4171" />
			<date type="published" when="2007-12">Dec. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hyperspectral band selection based on trivariate mutual information and clonal selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="4092" to="4105" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A joint band prioritization and band-decorrelation approach to band selection for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">C.-I</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L G</forename><surname>Althouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2631" to="2641" />
			<date type="published" when="1999-11">Nov. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Accuracy analysis of hyperspectral imagery classification using level sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASPRS Annu. Conf</title>
		<meeting>ASPRS Annu. Conf<address><addrLine>Reno, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Level set hyperspectral image classification using best band analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3022" to="3027" />
			<date type="published" when="2007-10">Oct. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Similarity-based unsupervised band selection for hyperspectral image analysis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="564" to="568" />
			<date type="published" when="2008-10">Oct. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An efficient method for supervised hyperspectral band selection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="138" to="142" />
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A new band selection method for hyperspectral image based on data quality</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2697" to="2703" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hyperspectral dimensionality reduction via localized discriminant bases</title>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cheriyadat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th IEEE Int. Geosci. Remote Sens. Symp</title>
		<meeting>24th IEEE Int. Geosci. Remote Sens. Symp<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-07">Jul. 2005</date>
			<biblScope unit="page" from="1245" to="1248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Network topology analysis: A new method for band selection</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st IEEE Int. Geosci. Remote Sens. Symp</title>
		<meeting>31st IEEE Int. Geosci. Remote Sens. Symp<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07">Jul. 2012</date>
			<biblScope unit="page" from="3062" to="3065" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Constrained band selection for hyperspectral imagery</title>
		<author>
			<persName><forename type="first">C.-I</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1575" to="1585" />
			<date type="published" when="2006-06">Jun. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hyperspectral band selection by multitask sparsity pursuit</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="631" to="644" />
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A parallel simulated annealing approach to band selection for hyperspectral imagery</title>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Geosci. Remote Sens. Symp</title>
		<meeting>IEEE Int. Geosci. Remote Sens. Symp<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="994" to="997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reducing the computational load of hyperspectral band selection using the one-bit transform of hyperspectral bands</title>
		<author>
			<persName><forename type="first">B</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th IEEE Int. Geosci. Remote Sens. Symp</title>
		<meeting>27th IEEE Int. Geosci. Remote Sens. Symp<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-07">Jul. 2008</date>
			<biblScope unit="page" from="919" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised hyperspectral band selection using graphics processing units</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="660" to="668" />
			<date type="published" when="2011-09">Sep. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Salient object detection: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.5878" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004-08">Aug. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Comparative study of intrinsic dimensionality estimation and dimension reduction techniques on hyperspectral images using K-NN classifier</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hasanlou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Samadzadegan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1046" to="1050" />
			<date type="published" when="2012-11">Nov. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transfer learning for visual categorization: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1019" to="1034" />
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SVMand MRF-based method for accurate classification of hyperspectral images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="736" to="740" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Advances in spectral-spatial classification of hyperspectral images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fauvel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chanussot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Tilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="652" to="675" />
			<date type="published" when="2013-03">Mar. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semisupervised hyperspectral image segmentation using multinomial logistic regression with active learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4085" to="4098" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Empirical mode decomposition of hyperspectral images for support vector machine classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4071" to="4084" />
			<date type="published" when="2010-11">Nov. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using empirical mode decomposition with spectral gradient enhancement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Erturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gullu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2787" to="2798" />
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ranking on data manifolds</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Adv</title>
		<meeting>16th Adv<address><addrLine>Whistler, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Feature learning for image classification via multiobjective genetic programming</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1359" to="1371" />
			<date type="published" when="2014-07">Jul. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evolutionary Optimization Algorithms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Wiley</publisher>
			<pubPlace>NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning and optimization using the clonal selection principle</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>De Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Von Zuben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="2002-06">Jun. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimizing multi-graph learning: Towards a unified video annotation scheme</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-R</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Int. Conf. Multimedia</title>
		<meeting>15th Int. Conf. Multimedia<address><addrLine>Augsburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">Sep. 2007</date>
			<biblScope unit="page" from="862" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Saliency detection via graph-based manifold ranking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>26th IEEE Conf. Comput. Vis. Pattern Recognit<address><addrLine>Portland, OR, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06">Jun. 2013</date>
			<biblScope unit="page" from="3166" to="3173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Adv</title>
		<meeting>16th Adv<address><addrLine>Whistler, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-12">Dec. 2003</date>
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An algorithm for linearly constrained adaptive array processing</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1972-08">Aug. 1972</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="926" to="935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hierarchical grouping to optimize an objective function</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ward</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">301</biblScope>
			<biblScope unit="page" from="236" to="244" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<title level="m">Pattern Classification</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Feature extraction with deep neural networks by a generalized discriminant analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stuhlsatz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lippel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zielke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="596" to="608" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning deep and wide: A spectral method for learning deep networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2303" to="2308" />
			<date type="published" when="2014-12">Dec. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-01">Jan. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Shifts in selective visual attention towards the underlying neural circuitry</title>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Neurobiol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="219" to="227" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
