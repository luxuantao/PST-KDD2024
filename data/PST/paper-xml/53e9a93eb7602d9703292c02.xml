<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpreting Pictures of Polyhedral Scenes*</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mackworth</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory of Experimental Psychology</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Falmer, Sussex</settlement>
									<country key="GB">England</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interpreting Pictures of Polyhedral Scenes*</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">44219B0BFB74DB17BDCC7CAAB5C24166</idno>
					<note type="submission">* Accepted for presentation at the Third international Joint Conferen~ on Artificial Intelligence, 1973. Artificial Intelligence 4 (1973), 121-137 Received 14 June 1973 Artificial Intelligence 4 (1973), !21-137</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A program that achieves the interpretation of line drawings as polyhedral scenes is described. The method is based on general coherence rules that the surfaces and edges must satisfy, thereby avoiding the use of predetermined interpretations of particular categories of picture junctions and corners.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>One way to capture the meaning of pictures is to investigate the relationship between two domains: the picture and whatever it is that is depicted--the scene <ref type="bibr" target="#b0">(1)</ref>. This paper closely examines that relationship for pictures consisting of straight line segments and scenes made up of opaque polyhedra~ A program, POLY, in the same tradition as Guzman's SEE <ref type="bibr" target="#b2">[3]</ref> and Clowes' OBSCENE <ref type="bibr" target="#b0">[1]</ref> is presented. POLY exploits the relationship between the domains and also coherence rules that entities in the scene domain must satisfy. Following a description of POLY, some feasible extensions to this scheme are described. Finally, the relevance of this program to other scene analysis programs is discussed.</p><p>The work reported here stemmed from consideration of several unsatisfactory aspects of OBSCENE. The "predicate table" embodied in that program appears to be a rigid and opaque theory of three-surface corners and the picture-taking process. Secondly, OBSCENE has a very weak grip on the consistency of the viewing direction. Finally, it interprets many pictures as polyhedra which cannot, in fact, exist. The conceptual framework for POLY was inspired by Huffman's "'dual-graph" <ref type="bibr" target="#b5">[6]</ref>, which was presemed as a device for checking an interpretation provided by the Huffman-Clowes labelling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Scene Coherence</head><p>Let us first establish a ~epresentation for the geometry of polyhedra and the picture taking process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Dua! Space</head><p>In conventional Cartesian space we describe a point by giving its coordinates (x, y, z) and a plane by a constraint upon the coordinates of a point: a,,x + ayy + a..z + 1 = 0. The representation is as it were point. oriented. Since planes are of more interest to us than points in the context of planar.faced polyhedra, it is desirable to use a representatien that is plane-oriented. Such a repre~ntation is the dual space <ref type="bibr" target="#b4">[5]</ref> in which a plane is represented as a point--specifically by the coefficients ax, ay, a: of the variables in the equation of the "real" plane. It follows that the dual of a point (x, y, z) is a plane such that (ax, a,, a,) is on the plane if xax + yay + za. + 1-0.</p><p>If a line in real space is construed as the intersection of two real planes then its dual i~ the line passing through the points in dual space which represent those real planes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Viewpoint</head><p>A two-dimensional image of a three-dimensional body is a projection whose form can be specified in terms of a viewing position and a picture plane. FIo. i. The picture-taking process.</p><p>Artificial Intelligence <ref type="bibr">4 (1973)</ref>, 121-137</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Picture Plone</head><p>Figure I illustrates such a situation where the picture plane is the x-y plane and the viewpoint V is on the z-axis. If we consider a particular line such as PxP2, then P~P2, BIB2 (the corresponding edge) and V all lie in a plane. This plane we call the plane of interpretation (I) of PiP2 since given PIP2 in a picture we have only to hypothesize the position of V relative to that picture to achieve a powerful constraint upon the possible interpretations of P~P2 as an edge, namely that the edge lies in the plane I beyond PIP2. Such a hypothesis about V has global implications for it determines the planes of interpretation for all other picture ~ines simultaneously because ali planes of interpretation must pass through V. "/'his fact is expressed elegantly in the dual space as the assertion that the duals of all the interpretation planes must lie on the dual of V namely a plane in the dual space D.</p><p>If V is at infinity relative to the picture (an ideal point) the projection is orthographic, otherwise it is perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Bodies</head><p>The interpretation of some of picture lines as edges bounding a plane surface of a body is expressed in dual space as the requirement that the duals of these edges all pass through the dual point representing that surface. Hidden edges of a partially visible surface would of course also be subjected to this requirement as would the dual of any life presumed to be upon the surface.</p><p>The interpretation of a picture junction as the corner of a polyhedron can also be usefully characterised in dual space, A point in real space can be construed as the intersection of a set of planes so that we can ideutify the planes with the surfaces of the corner and the point with the corner itself. Ea,:h edge of the corJ~er is the1! the lin,~ of intersection of a pair of planes, and has as its dual a line which passes through the dual (point) of each of the pair of planes. This set of dual lines forms a polygon lying in a plane in D, that plane which is the dual of the point in real space that we identified with the corner. Thus the dual of an n-surface corner of a polyhedron is a plane n-gon.</p><p>Assumptions that the objects in the portrayed three-dimensional situation are polyhedra interface with a model of viewpoint in a particularly simple way. Both the picture line and the edge it depicts lie in the plane of interpretation, I, for that line. Thus the dual of the edge (a line in D) must pass through the dual of I. This can be combined with the requirement that the dual of" an edge pass through the duals of the surfaces it belongs to, to obtain the requirement that the duals of I and the two surfaces intersecting in I lie on the dual of the edge which is that intersection. Thus in Fig. <ref type="figure">I</ref> the duals of the surfaces B~BzB3B4, BIB2BsB6 and the plane of interpretation of P~Pz all lie on the dual line of BIB2.</p><p>Artificial Intelligence <ref type="bibr">4 (1973)</ref>, 121-137</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">The Gradient Space</head><p>A particularly interesting 2-D subspace of the dual space D is the gradient space G. A point (ax, ay, a:) in D ccxresponds to the point (a~, a~) in G. Geometrically, this corresponds to projecting (a~, a, a:) into the az = 1 plane with centre of projection at O and using (0, 0, 1) as the origin OG of G. In Fig. <ref type="figure" target="#fig_1">2</ref>, I in D is projected into Ic in G. then we can see why (G,~, xy) = (ax/az, a,/a=) is called the gradient of the plane. In Fig. <ref type="figure">1</ref>, -z is the distance from the point (x, y, z) on a surface of .the object as BtB2B3B4 to the picture plane, z = 0. The gradient represents the vector rate of change of this distance with respect to movement in the picture plane, that is, The length of the vector from OG to a point W in G is the tangent of the angle between the picture p!ane and the plane corresponding to W; the direction of that vector is the direction of the dip of the plane corresponding to W relative to the picture plane, Since the dual of the picture plane is the ideal point on the az-axis, Oo the zero gradient, corresponds to it. The projection into the gradient sp~ce of the dual line representing an edge may Artificial Intelligence 4 (1973), 121-137 be called the gradient line of that edge. A perpendicular dropped from OG to that line is the gradient of that edge in that its direction and magnitude are the direction and tangent of the angle of dip of that edge relative to the picture plane. A family of mutually parallel planes represented by the coor~nates (ka~,kay, kaz) in D will have coincident representations (a~/az, ay/az) in G. Planes which are steep'y inclined to the picture plane will be relatively remote from O~ in G. Most of the relationships that were shown to hold in D must necessarily hold in G. In particular, the gradients of the interpretation plane and t•e two object surfaces that intersect in an edge must be on the gradient line of that edje.</p><p>The orientation of a picture line determines the direction of the gradient of its interpretation plane in G. Thus a picture line which is parallel to the y-axis, say, will have an interpretation plane whose gradient I~ lies on the ax axis. If we align the x-y (picture) axes with the a~-ay axes of G the direction of I~ relative to Oc will be perpendicular to the picture line.</p><p>The above remarks are all true regardless of the viewing position V and so are true for both orthographic and perspective pictures. We shah now concern ourselves with file gradient space for orthographic pictures. The duals of all the interpretation planes (which must lie on the dual of V) will then be on the a: = 0 plane of D. Projecting them into G will therefore put all their gradients at infinity (they become ideal points in the gradient space). Another way of looking at it is to realize that as V goes further from the picture plane the angles between the picture and the interpretation planes all approach 90 ° and so the lengths of the gradients approach tan 90 ° (-~ oo).</p><p>The distance of !~ from O6 increases with the (presumed) distance in real space of the viewing point V from the picture plane. The projection onto G of the dual of the edje depicted by the picture line, will be a line passing through IG. For any picture line there is an infinite family of such lines in G being the projectioa onto G of deals of the possible edges depicted by the line. As V tends to infinity, the picture tends to an orthographic projection of the scene and Io tends to an ideal point. The family of edge gradient lines in G simultaneously tends toward a set of parallel lines whose orientation is that of the direction of IG, that ;~, perpendicular to the picture line.</p><p>Consider an orthographic picture of a scen~ with a visible edge joining two visible surfaces A and B. (We call such an eOge a "connect" edge). The gradient space configuration corresponding to that consists of the two gradients (GA and GB) joined by a line which is the projection of the dual of the edge. That line is perpendicuJ~r to the picture line if the gradient space is superimposed on the picture space as described above. Moreover, it can e~sily be shown that if the gradients are ordered on the dual line in the same direction as the corresponding surfaces appear at the edge then that edge is Artificial Intelligence 4 (1973), 121-137 convex but if they are ordered in the reverse direction then it is concave.</p><p>(Intuitively, imagine a convex edge, then rotate one of the surfaces until it is concave. When the edge is fiat, the gradients must coincide.) This crucial fact allows the exploitation of the, gradient space for convex/concave interpretations.</p><formula xml:id="formula_0">m i B A Flo. 3. A FORK junction.</formula><p>As a simple example of the use of this consider a FORK junction (Fig. <ref type="figure">3</ref>) where it is known that all the edges are connect. The configuration of the gradients of surfaces A, B, and C (G^, G, and Gc) can only take on one of the two forms of Fig. <ref type="figure" target="#fig_2">4</ref> ff they are to satisfy the requirement that the mutual vector difference be perpendicular to the line depicting the edge that connects the two surfaces. These configurations can, of course, be translated and expanded in the gradient space and still satisfy the requirement. Comparing the relative positions of the gradients in Fig. <ref type="figure" target="#fig_2">4</ref>(a) with the ordering of the regions in the picture shows that all the edges must be convex for that interpretation while for the interpretation given by Fig. <ref type="figure" target="#fig_2">4</ref>(b) all the edges must be concave. That switch of interpretations which can be achieved by mapping every gradient G into its negation -G is known in the literature of psychology as the Necker reversal. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Description of the Program</head><p>The task for POLY can be specified as follows: using these constraints on the coherent interpretation of polyhedra subjected to this picture-taking process, what information can be derived from the picture ? In particular, the program must provide easily accessible answers to questions, such as, Artificial Intelligence 4 (1973), 121-137 Which edges are connect edges ? ,, ,,</p><p>, ? If an edge is occluding, which surface is in front ? How much of the hidden structure of the scene can be recovered ? What is the orientation of each surface and each edge ? and so on. A program POLY will now be described which recovers these attributes and relationships of the scene. POLY is an existence proof that such questions can be answered. It does not purport to be a stand alone scene analysis program but it can be thought of as a useful embodiment of most of the knowledge specific to these picture and scene domains and their interrelationship that a scene-based problem solver would need to have available. The overall structure of POLY is shown in Fig. <ref type="figure" target="#fig_3">5</ref>. The program is written in ALGOL 60 extended to allow for the representation and manipulation of data objects, attributes and binary relationships. The input is obtained by drawing a picture on the graphical display; .*.he input phase passes to the parsing phase the end points of the lines. The parsing phase recovers the picture structure by examining the lines for join relationships, and establishing the junctions and closures and the regions made up of closures. The picture is that given in Fig. <ref type="figure" target="#fig_4">6(a)</ref>. Then the scene correspondents of this data structure are created following the relation of representation [J ] as shown in Fig. <ref type="figure" target="#fig_4">6(b)</ref>.</p><p>The CONNECT part of the program uses the rules of cohe,.'ence sketched earlier tc establish which edges are connect and which are not. This part of ~.he program searches over a binary tree with each level representing a different edge in the scene, the left branches being connect (edge) = true and the fight branches connect (edge) = false. This tree is not searched in either of the conventional depth-first or breadth-first ways. To acifieve the most connected interpretation first, the top level goal reqmres all edges to be connected and then, when that fails, all edges but one and so on. The tree search is affected by the usual backtracMng method with state saving which in this case is achieved by a recursive procedure. The edges are not searched in random order; starting from the background re#on, each region is interpreted in turn: the next re#on chosen is that uninterpreted re#on with the most lines adjacent to the interpreted regions. In this context, to interpret Artificial Intelligence <ref type="bibr">4 (1973)</ref>, 121-137 a region means to fix the position of the corresponding surface in gradient space. Because the region selected by that criterion will correspond-to the most constrained surface, this strategy results in the most efficient search. So, in fact, the order of the search is given in advance by the parser but there is no reason why the program could not modify the order of search dynamically if it were embedded ia a larger system that could supply advice or hypotheses about the orientation of particular surfaces or the status of various edges. A simple example will make the workings of CONNECT clearer. Consider the picture in Fig. <ref type="figure">7</ref>. CONNECT fails to find any interpretation with five or with four connect edges for reasons that will become obvious. So with the goal of establishing three connect edges, CONNECT starts with the background A, and for convenience sets GA at the origin in gradient space. It then examines the lines on the inner closure of A (1, 2, 4 and 5) and finds that none of the regions on the other sides of those lines have been interpreted, so it can say nothing yet about these lines, It then chooses the uninterpreted region that has the most adjacencies to the interpreted regions as the next region to interpret. The ordering of the edges as a tree is determined by this strategy of addressing the picture. Both B and C have two adjacencies, so the choice is arbitrary, say B. Now it examines lines on the Artificial Intelligence 4 (1973), 121-137 outer closure of B in sequence trying to establish connect edges. Say it looks at 1 first. It establishes it as a connect edge which means that Gs must lie on a line perpendicular to I through GA --(0, 0). In general, the posit ion of a gradient is defined by the intersection of two or more dual lines ari:Jing from edges assigned connect status; however, for the first two gradient:~ (G^ and G~, here) there is no loss of generality if we do not use that req16rement to locate them since th~ origin and scale of the gradient space can be subsequently altered. So we put GB at unit distance from GA on that line, The next picture line to be considered is 2, which CONNECT also tries to establish as a connect edge but this would require GB to lie on a line perl endicular to 2 through G^ which is incompatible with the current interpretation of Gs. Thus the interpretation in which both 1 and 2 are connect, edges is said to be incoherent. This makes it clear why CONNECT failed in its original goal of establishing all the edges as connect edges. 2 is established as an occluding edge and CONNECT looks next at 3. Since the region on the other side, C, is not yet interpreted, it says nothing about 3. The remaining region C is then interpreted. 3 is established as a connect edge requiring Gc to lie on a line perpendicular to 3 passing through GB. The actual position of Gc is established by defining its relationship to G A by making 4 or 5 (but not both) connect edges. The interpretation in which i, 3 and 5 are connect and 2 and 4 are occluding edges is rejected by the single rule that three non-collinear points in space (the corners a, b and c) cannot simultaneously lie on two planes (A and B). So one legal connect interpretation is that 1, 3 and 4 are connect edges, while 2 and 5 are not.</p><p>Artificial Intelligence 4 (I 973), 121-137</p><p>Continued search of the tree will only yield one more interpretation with 3 connect edges, viz. 2, 3 and 5 connect, 1 and 4 occluding. For 1, 3 and 4 connect, the final gradient space configuration will be as shown in Fig. <ref type="figure">8</ref>, in which the gradient line of connect edge I is labelled as I' etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O v</head><p>FiG. <ref type="figure">8</ref>. One possible gradient configuration derived from Fig. <ref type="figure">7</ref> by CONNECT.</p><p>Then VEXCAVE takes over and decides which of the connect edges are convex and which concave. VEXCAVE starts by partitioning the gradient space graph into 2-connected subgraphs using the gradient lines of connect edges as arcs. For each subgraph VEXCAVE then determines its two possible interpretations using the ordering rule for gradients. In the example, VEXCAVE will decide in the interpretation for which 1, 3 and 4 are connect edges that the whole graph is 2-connected and that either I and 4 are concave edges while 3 is convex or l and 4 are convex while 3 is concave. Note that, for the latter interpretation, junction b is assigned an "accidental" status.</p><p>Finally, OCCLUDE looks at the non-connect edges and uses two inference rules to achieve a complete interpretation. The first rule expresses the fact that if two surfaces intersect in a connect edge that is known to be, say, convex, then at any position in the picture it will be apparent which surface is in front. Using this rule it becomes clear, for many occluding edges, which surface (of the two that it apparently bounds) the edge actually belongs to.</p><p>The rule also adds a hidden surface attached to that edge. The fact that such a surface is both turned away from the viewing direction and obscured by the visible surface means that it obeys the same constraint as it would if the edge were concave and connect. This rule is used in the example to decide for the case where 1 and 4 are concave and 3 is convex that occluding edges 2 and 5 belong to surfaces B and C, respectively. The second rule for occlusion completes the polygon of gradients corresponding to the visible and hidden surfaces meeting at each corner. It does this by allowing for the hidden surfaces created by the first rule and introducing the minimum number of extra hidden surfaces required. The minimum number is achieved by allowing two occluding edges to share the same hidden surface wherever Artificial Intelligence 4 (1973), 121-137 possible. In the example, the second rule confirms that the polygon of gradients is complete for corner c since the surfaces at that corner, A, B and C, are all visible and there are no occluding edges. For corner d it completes the polygon by introducing a hidd~,~ edge between the hidden surface at edge 5 and the background. Similarly for corner a and the hidden surface at edge 2. Then at corner b it decides that those two hidden surfaces could be the same surface, D, and still obey the constraints. So the final gradient space configuration is Fig. <ref type="figure" target="#fig_6">9</ref> which looks like a picture of a wire-frame tetrahedron because the tetrahedron is the only self-dual polyhed~ron <ref type="bibr" target="#b4">[5]</ref>. The interpretation pursued in the example above is one of the first produced by POLY but the program will continue to generate less connected interp'=etations. For example, the tetrahedron separate from the background surface has only one connect edge, 3', but its gradient space configuration has the same structure as Fig. <ref type="figure" target="#fig_6">9</ref> with the exception that GA in that figure is replaced by th,: gradient of a second hidden surface, G~ and GA is now an isolated point in gradient space, lr.terpretations such as this with complete bodies separate from the background can be easily generated first by giving CONNECT the advice that all the lines on the inner closure of the frame represent non-connect edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gy</head><p>When OCCLUDE has finished, then the interpretation process is complete. Each edge node in the scene data structure is related to other scene entities such as the surface it bounds and the corners which bound it. An edge node also contains attributes such as connect, convex, concave or occluding and its slope relative to the picture plane. Nodes for the original visible surfaces Artificial Intelligence 4 (i 973), 121-137 and the hidden surfaces introduced by OCCLUDE contain the gradient vectors which are relative to the gradient of some other surface, usually the background. These gradients may be uniformly scaled by a positive number before being added to the gradient of that other surface to obtain the true gradient. The scale factor must be positive because the work done by OCCLUDE on the hidden surfaces will not survive the Necker transformation that a negative scale factor would involve. This transformation was allowed for earlier, in VEXCAVE, when two versions of the configuration were generated. Two further points about the program should be made. First, POLY has no difficulty in making sense of cracks as in Fig. <ref type="figure" target="#fig_7">10</ref>. Cracks are simply connect edges where the two adjacent surfaces have identical gradients. Finally, the processing time required to produce the first interpretation is proportional to the number of picture lines if that interpretation is completely connected but that tends towards an exponential relationship if the first interpretation is less cc, nnected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Possible Extensions of POLY</head><p>There are many possible elaborations of this scheme. Since surfaces are represented by their gradients, we learn only the orientation of each surface and not its position in space. It is clear, however, that one could take the results of POLY and by fixing the ~ctual position of one surface propagate the positions of the other surfaces through the connect edges. Alternatively one could use the dual space itself as a representation and build a program that directly exploited the constraints outlined above. Such a program would not have the conceptual simplicity of the implemented scheme.</p><p>In theory, POLY only considers orthographic projections but this is not a practical limitation on a scene analysis program. However, one could reformula(e the program to deal with perspective projection. In outline, this means that the interpretation plane is now represented as a real point in gradient space since it is not, in general, perpendicular to the picture plane. Artificial Intelligence <ref type="bibr">4 (1973)</ref>, 121-137</p><p>The vector from the origin of the gradient space to that point will still be perpendicular to the picture line but the gradient line of the edge is only required to pass through that point and also contain the gradients of the two object planes. Since the gradients of the planes of interpretation of all the picture lines are determined by the geometry of the picture and the position of the viewpoint relative to the picture plane these constraints can be systematically exploited to construct a perspective interpretation of the line drawing.</p><p>If the scene is lit by one or more discrete light sources, the boundaries of the shadows cast are depicted as straight lines. Consider a shadow plane formed by the light source, a shadow-casting edge and the corresponding shadow boundary. The gradient of such a plane must lie on the gradient line of the edge (which is perpendicular to the picture line and contains the gradients of the two object surfaces meeting at the edge). The shadow boundary will also have a grad,~ent line which contains the gradients of the shadow-receiving surface and the shadow plane. Moreover, for a source producing a parallel beam, the gradients of all the shadow planes must lie on a straight line in gradient space that is perpendicular to the direction of illumination in the picture. Such constraints a~low the extension of the scheme to include shadow interpretation. Such an extension could also use the assumption of uniformly reflecting surfaces of constant albedo that would enable the program to infer constraints on the gradient of a surface relative to the light source from the apparent luminance of that surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">POLY and Related Programs</head><p>POLY has particularly interesting relationships with three other vision programs, namely, Guzman's SEE <ref type="bibr" target="#b2">[3]</ref>, Clowes' OBSCENE [I] and Falk's INTERPRET <ref type="bibr" target="#b1">[2]</ref>. SEE accepts input in the same form as POLY does and produces groupings of the picture regions on the basis of the putative body membership of the surfaces depicted. The program starts by classifying each junction into one of a small number of junction categories. It then uses this classification to place links between regions if certain local ~unction configurations exist. The resultant gra#t(with surfaces as nodes and links as arcs) is then examined for well connected subgraphs which are declared to represent bodies. In the lar, guage of POLY, Guzman's links can be thought of as gbod guesses at connect edges and, indeed SEE's graph structure is a weaker version of POLY's gradient space representation. But SEE fails to exploit fully our knowledge of three-dimensional situations; for example, there is no representation in the program for the fact that if two edges between two surfaces are not collinear, they cannot both be connect edges. SEE's tendency to see holes in objects as separate objects <ref type="bibr" target="#b7">[8]</ref> is only one consequence of the fact Artificial Intelligence 4 (I 9'73), 121-137 that the program ignores inherent ambiguities in the interpretation process that are exposed by the next program to be considered here, OBSCENE. OBSCENE (and Huffman's labelling algorithm <ref type="bibr" target="#b5">[6]</ref>) gives each edge in the scene one of four interpretations, namely, convex, concave and the two occluding possibilities. OBSCENE works by mapping junctions into corners using some of the junction categories described by Guzman. Each junction type (ELL, FORK, ARROW and TEE) has a small number of pre-determined corner interpretations. The program then pursues the legal combinations of these using the coh~.rence rule that an edge must have the same interpretation at each end. OBSCENE can be seen as a theory of why SEE works, in that it makes explicit what is implicit in SEE. POLY, in turn, is a theory of why OBSCENE works, in that it shows how to derive the junction categories of OBSCENE.</p><p>POLY can be seen as a descendant of OBSCENE in several ways. The coherence rules for OBSCENE are at the edge level whereas POLY requires each surface to have a unique orientation in space. This higher level of coherence means, for example, that POLY rejects as ill-formed, skewed objects, such as Fig. <ref type="figure" target="#fig_7">10</ref>, that OBSCENE wili accept. but POLY uses the fact that those four categories are really hiding two boolean predicates. POLY's mapping is" lc°nnect } line--. [non-connect edge, and the combiFl~ttorial search is done on this predicate alone with the other predicate determined by non-search procedures.</p><p>Waltz <ref type="bibr" target="#b6">[7]</ref> considerably extended the Huffman-Clowes labelling procedure by sub-dividing the four categories of edge types and adding cracks and shadow boundaries; furthermore, he ingeniously modified the search mechanism to avoid the combinatorial explosion of a straightforward breadth-first procedure. Nevertheless, most of the remarks made here about the Huffman-Clowes procedure seen in terms of POLY apply equally to Waltz's extension. Waltz also ~ssigns to each surface an illumination status" illuminated, turned away from the light or shaded by another surface. Such hypotheses would be better justifie, d if the surface orientations were explicitly represented as in the gradient space. Similarly his treatment of shadows does not include the global consistencies outlined in Section 4 above. Finally, Waltz suggested a scheme to check a labelled picture by using quantized versions of line, edge and surface orientations related through tabulations of possible values. POLY exploits directly a more concise and transparent representation of those relationships to construct rich scene interpretations thereby dispensing with possible corner lists.</p><p>Falk's INTERPRET <ref type="bibr" target="#b1">[2]</ref> is a well-documented account of a complete scene analysis system that interprets line drawings, and so it is instructive to see how POLY could relate to that program. But first, consider Falk's "face adjacency graph". This concept, although not used in the program, is outlined in his paper because it "would be valuable for a scene analysis system which operated in a universe of planar faced solids more complicated" <ref type="bibr">[2, p. 112</ref>] than the nine simple objects his program recognizes. Falk suggests doing a Huffman-Clowes analysis of the picture to determine which edges are connect and then constructing a graph with surfaces as nodes and connect edges as arcs. It is then shcwn that a property of this graph, "mergeability", gives the number of independent points that need to be located in three dimensions in order to specify the scene completely. In particular, if the graph is l-mergeable (2-connected in graph-theoretic terms), then 4 points must be located. These 4 scalars correspond to setting the origin and scale of the gradient space and the..distance of the object from the picture plane. Falk's result applies directly to the gradient space configuration produced by POLY, which is not confined to isolated, degree 3 polyhedra.</p><p>With respect to INTERPRET itself, Falk mentions several times that a Artificial Intelligence <ref type="bibr">4 (1973)</ref>, 121-137</p><p>Huffman-Clowes labelling would have helped the program. Those remarks apply, afortiori, to POLY. In addition, the surface orientations available in POLY would help in support determination and in recognition; also, the inclination of edges relative to the picture plane give the foreshortening factor necessary to calculate true edge length. Finally, consider the seven somewhat opaque heuristics that Falk uses to determine possible base edges. He is forced to use these beck.use at that stage the program is functioning entirely in the picture domaiQ. The analy~is offered by POLY, which constr,Jcts a scene interpretation without "recognizing" the objects, provides a structure in which one would find the lowest hidden surface :qd simply ask which visible edges are attached to it. The caveat should be entered that, as they stand, both OBSCENE and POLY require complete line drawings while Falk interprets pictures in which lines can be missing. However, examination of the manner of failure of POLY on a particular picture will suggest where lines may be missing or extraneous by showing, at the very least, which subpictures can be sensibly int,~rpreted. Furthermore, hypotheses concerning lines to be added or removed can be confirmed by successful analysis by POLY.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Although POLY is restricted to the interpretation of compete line drawings showing an orthographic view of a shadow-free polyhedral scene, the extensions in Section 4 and the discussion in Section 5 (particularly the relationship between POLY and Falk's INTERPRET) suggest that all of these restrictions except the overriding commitment to polyhedra can be overcome. Be that as it may, the program does demonstrate just how much structural information can be inferred from the picture using knowledge of the picturetaking process and the general nature of polyhedra but without using specific polyhedral prototypes. '</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>F1o. 2 .</head><label>2</label><figDesc>Projection of a dual point, I, into gradient space. el :ox,oy.o z ) can be made about G. If the equation of the plane is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Flo. 4 .</head><label>4</label><figDesc>Two gradient space configurations derived from Fig.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F~o. 5 .</head><label>5</label><figDesc>The organization of the program.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIG. 6 .</head><label>6</label><figDesc>FIG.6. The picture and scene data structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FK}. 9 .</head><label>9</label><figDesc>The gradient configuration derived from Fig.8by OCCLUDE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FIG. 10 .</head><label>10</label><figDesc>FIG. 10. Two wedges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>FIG. i I. Skewed tetrahedron with a notch cut in it.The mapping rules for OBSCENE are at the corner level while those for POLY are at the level of edges. For OBSCENL, this results in the rather unsatisfactory predicate table in which are listed all the various 3-surface corners which could be depicted by each junction type. All the entries are worked out in advance by the programmer whereas drawing each junction type as input to POLY would result in interpretations that are the OBSCENE predicate table entries.</figDesc><table><row><cell>OBSCENE's edge mapping is</cell><cell></cell></row><row><cell></cell><cell>convex [</cell></row><row><cell>line -~</cell><cell>concave [ hind 1 ! edge,</cell></row><row><cell></cell><cell>hind 2 ]</cell></row><row><cell>Artificial Intelligence 4 (I 973), ! 2 I-! 37</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>Dr. Max Clowes provided much welcome advice and criticism. The author also acknowledges facilities provided by Professor N. S. Sutherland, the financial support of the National Research Council of Canada and computing made available by the Science Research Council of Great Britain.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On seeing things</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ciowes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="116" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interpretation of imperfect line data as a three dimensional scene</title>
		<author>
			<persName><forename type="first">G</forename><surname>Falk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="144" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decomposition of a visual scene into three-dimensio~al bodies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Joint Comp. Conf</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="291" to="304" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
	<note>AFIPS Proc. F</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph Theory</title>
		<author>
			<persName><forename type="first">F</forename><surname>Harary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="12" to="137" />
			<date type="published" when="1969">1969. 1973</date>
			<publisher>Addison Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hiibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cohn-Vossen</surname></persName>
		</author>
		<title level="m">Geometry and the Imagination</title>
		<meeting><address><addrLine>Chelsea, Ne~ York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Impossible objects as nonsense sentences</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Huffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Meltzer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Michie</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="295" to="323" />
			<date type="published" when="1971">1971</date>
			<publisher>Edinburgh University Press</publisher>
			<pubPlace>Edinburgh</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generating semantic descriptions from drawing of scenes with shadows. Thesis, AI TR-271</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Waltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Massachusetls Inst. of Technol</title>
		<imprint>
			<date type="published" when="1972">1972</date>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A.I. Memo No. 163</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName><surname>Holes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Massachusetts Inst. of Technol</title>
		<imprint>
			<date type="published" when="1970-04">April 1970</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
