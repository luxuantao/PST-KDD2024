<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploiting multi-channels deep convolutional neural networks for multivariate time series classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yi</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Information Systems</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
							<email>cheneh@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<postCode>230027</postCode>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Ge</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
								<address>
									<postCode>28223</postCode>
									<settlement>Charlotte</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">Leon</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Information Systems</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploiting multi-channels deep convolutional neural networks for multivariate time series classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0C2067E23E9232E2084AE102E048F712</idno>
					<idno type="DOI">10.1007/s11704-015-4478-2</idno>
					<note type="submission">Received October 27, 2014; accepted April 29, 2015</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>convolutional neural networks</term>
					<term>time series classification</term>
					<term>feature learning</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Time series classification is related to many different domains, such as health informatics, finance, and bioinformatics. Due to its broad applications, researchers have developed many algorithms for this kind of tasks, e.g., multivariate time series classification. Among the classification algorithms, k-nearest neighbor (k-NN) classification (particularly 1-NN) combined with dynamic time warping (DTW) achieves the state of the art performance. The deficiency is that when the data set grows large, the time consumption of 1-NN with DTW will be very expensive. In contrast to 1-NN with DTW, it is more efficient but less effective for feature-based classification methods since their performance usually depends on the quality of hand-crafted features. In this paper, we aim to improve the performance of traditional feature-based approaches through the feature learning techniques. Specifically, we propose a novel deep learning framework, multi-channels deep convolutional neural networks (MC-DCNN), for multivariate time series classification. This model first learns features from individual univariate time series in each channel, and combines information from all channels as feature representation at the final layer. Then, the learnt features are applied into a multilayer perceptron (MLP) for classification. Finally, the extensive experiments on real-world data sets show that our model is not only more efficient than the state of the art but also competitive in accuracy. This study implies that feature learning is worth to be investigated for the problem of time series classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As the development of information technology, sensors become cheaper and more prevalent in recent years. Hence, a large amount of time series data (e.g., electrocardiograph) can be collected from different domains such as bioinformatics and finance. Indeed, the topic of time series data mining, e.g., univariate time series classification and multivariate time series classification, has drawn a lot of attention <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>.</p><p>Particularly, compared to univariate time series, multivariate time series can provide more patterns and views of the same underlying phenomena, and help improve the classification performance. Therefore, multivariate time series classification is becoming more and more important in a broad range of applications, such as activity recognition and healthcare <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. In this paper, we focus on the classification of multivariate time series. Along this line, there has been a number of classification algorithms developed. As many previous studies claimed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8]</ref>, among these methods, the distancebased method k-nearest neighbor (k-NN) classification is very difficult to beat. On the other hand, more evidences have also shown that the dynamic time warping (DTW) is the best sequence distance measurement for time series in many domains <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. Hence, it could reach the best performance of classification through combining the k-NN and DTW in most scenarios <ref type="bibr" target="#b8">[9]</ref>. As contrasted to the sequence distance based methods, traditional feature-based classification methods could also be applied for time series <ref type="bibr" target="#b0">[1]</ref>, and the performance of these methods depends on the quality of hand-crafted features heavily. However, different from other applications, for time series data, it is difficult to manually design good features to capture the intrinsic properties. As a consequence, the classification accuracy of feature-based approaches is usually worse than that of sequence distance based approaches, particularly 1-NN with DTW method. Recall that both of 1-NN and DTW are effective but cause too much computation in many applications <ref type="bibr" target="#b9">[10]</ref>. Hence, we have the following motivation.</p><p>Motivation Is it possible to improve the accuracy of feature-based methods for multivariate time series? So that the feature-based methods are not only superior to 1-NN with DTW in efficiency but also competitive to it in accuracy.</p><p>Inspired by the deep feature learning for image classification <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>, in our preliminary work <ref type="bibr" target="#b13">[14]</ref>, we introduced a deep learning framework for multivariate time series classification. Deep learning does not need any hand-crafted features, as it can learn a hierarchical feature representation from raw data automatically. Specifically, we proposed an effective multi-channels deep convolutional neural networks (MC-DCNN) model 1) , each channel of which takes a single dimension of multivariate time series as input and learns features individually. After that, the MC-DCNN model combines the learnt features of each channel and feeds them into a multilayer perceptron (MLP) to perform further classification. We adopted the gradient-based method to estimate the parameters of the model. Finally, we evaluated the performance of our MC-DCNN model on several real-world data sets. The experimental results on these data sets reveal that our MC-DCNN model outperforms the baseline methods with significant margins and has a good generalization, especially for weakly labeled data. In this extended version, we integrate novel activation function and pooling strategy, and meanwhile, we compare its rate of convergence with the traditional combinations of activation functions and pooling strategies. To further improve the performance, we also apply an unsupervised initialization to pretrain the convolutional neural networks and propose the pretrained version of MC-DCNN model. Moreover, in order to understand the learnt features intuitively, we provide visualizations of them at two filter layers. Through the new investigation, we summarize several discussions of current study and they guide the directions for our future work.</p><p>The rest of the paper is organized as follows. In Section 2, we provide some preliminaries. In Section 3, we present the architecture of MC-DCNN, and describe how to train the neural networks. In Section 4, we conduct experiments on several real-world data sets and discuss the performance of each model. We make a short review of related work in Section 5. Finally, we conclude the paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>In this section, we first introduce some definitions and notations. Then, we define two distance measures used in the paper. We follow previous work <ref type="bibr" target="#b14">[15]</ref> and extract subsequences from long time series to perform classification instead of directly classifying with the entire sequence. Definition 3 Subsequence is a sequence of consecutive points which are extracted from time series T and can be denoted as S = {t i , t i+1 , . . . , t i+k-1 }, where k is the length of subsequence. Similarly, multivariate subsequence can be denoted as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions and notations</head><formula xml:id="formula_0">Y = {m •i , m •i+1 , . . . , m •i+k-1 }, where m •i is defined in Definition 2.</formula><p>Since we perform classification on multivariate subsequences in our work, in remainder of the paper, we use subsequence standing for both univariate and multivariate subsequence for short according to the context. For a long-term time series, domain experts may manually label and align subsequences based on experience. We define this type of data as well aligned and labeled data. Figure <ref type="figure" target="#fig_1">1</ref> shows a snippet of time series extracted from BIDMC Congestive Heart Failure data set <ref type="bibr" target="#b15">[16]</ref>. Each subsequence is extracted and labeled according to the dotted line by medical staffs. However, to acquire the well aligned and labeled data, it always needs great manual cost. In contrast to well aligned and labeled data, in practice, weakly labeled data can be obtained more easily <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15]</ref>, which is defined as follows.</p><p>Definition 5 Weakly labeled data: A long-term time series is associated with a single global label as shown in Fig. <ref type="figure" target="#fig_2">2</ref>. Due to the alignment-free property of weakly labeled data, it requires to extract subsequences by specific algorithm. The most widely used algorithm is sliding window <ref type="bibr" target="#b16">[17]</ref>, by which a large number of redundant subsequences may be extracted and all kinds of potential subsequences in alignment-free pattern space are covered. We illustrate the pseudo-code of sliding window algorithm in Algorithm 1. The parameters T , L and P denote the long-term time series, the window length and the sliding step. Supposing the length of T is n, it is easy to find that the number of extracted subsequences is n-L+1 P .</p><p>In summary, in this paper, we will primarily concentrate on the time series of the same length and conduct experiments on both labeled data that is well aligned and weakly labeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Time series distance measure</head><p>For time series data, Euclidean distance is the most widely used measure. Suppose we have two univariate time series Algorithm 1 Sliding window algorithm 1: procedure [s]=SlidingWindow(T, L, P)</p><formula xml:id="formula_1">2: i := 0, m := 0;</formula><p>m is the number of subsequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3: s := empty;</head><p>The set of extracted subsequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4: while i + L length(T ) do</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>L is the length of sliding window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>s[m] := T [i..(i + L -1)]; 7:</p><p>i := i + P, m := m + 1; P is the step. 8: end while 9: end procedure Q and C, of the same length n, where Q = {q 1 , q 2 , . . . , q i , . . . , q n } and C = {c 1 , c 2 , . . . , c i , . . . , c n }. The Euclidean distance between Q and C is:</p><formula xml:id="formula_2">ED(C, Q) = n i=1 (c i -q i ) 2 .</formula><p>Furthermore, for two multivariate time series X and Y, the Euclidean distance between them could be defined as follows:</p><formula xml:id="formula_3">ED(X, Y) = l i=1 ED(x i , y i ),</formula><p>where l denotes the number of components, and x i and y i represent the ith univariate time series of them, respectively. As a simple measure, Euclidean distance suffers from several problems <ref type="bibr" target="#b1">[2]</ref>. In the literature, DTW is considered as an alternative that is more robust than Euclidean distance and can align two sequences effectively <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. To align two sequences (e.g., Q and C) using DTW, we need to construct a distance matrix first, which is shown as follows:</p><formula xml:id="formula_4">⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ d(q 1 , c 1 ) d(q 1 , c 2 ) • • • d(q 1 , c n ) d(q 2 , c 1 ) d(q 2 , c 2 ) • • • d(q 2 , c n ) . . . . . . . . . d(q n , c 1 ) d(q n , c 2 ) • • • d(q n , c n ) ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ .</formula><p>Each element d(q i , c j ) of the matrix corresponds to the distance between the ith point of Q and the jth point of C, i.e., d(q i , c j ) = (q ic j ) 2 . In this paper we primarily concentrate on the time series of the same length, thus we use two equal length time series to explain DTW for convenience. Notice that DTW can also be applied to time series with different length.</p><p>A warping path W is a sequence of contiguous matrix elements which defines a mapping between Q and C: W = {w 1 , w 2 , . . . , w k , . . . , w 2n-1 }. Each element of W corresponds to a certain element of the distance matrix (i.e., w k = d(q i , c j )). There are three constraints that the warping path should satisfy, which are shown as follows.</p><p>• Boundary: w 1 = d(q 1 , c 1 ) and w 2n-1 = d(q n , c n ).</p><p>• Continuity: Given w k = d(q i , c j ) and w k-1 = d(q i , c j ), then ii 1 and jj 1.</p><p>• Monotonicity: Given w k = d(q i , c j ) and w k-1 = d(q i , c j ), then ii 0 and jj 0.</p><p>Since there may exist exponentially many warping paths, the aim of DTW is to find out the one which has the minimal warping cost:</p><formula xml:id="formula_5">DTW(Q, C) = minimize W={w 1 ,w 2 ,...,w 2n-1 } 2n-1 k=1 w k ,</formula><p>where W should satisfy these three constraints above. One step further, for two multivariate time series X and Y, similar to Euclidean distance, DTW between X and Y can be defined as follows:</p><formula xml:id="formula_6">DTW(X, Y) = l i=1 DTW(x i , y i ),</formula><p>where l denotes the number of components in multivariate time series, and both of x i and y i represent the ith univariate time series of them, respectively. It is common to apply dynamic programming to compute DTW(Q, C) (or DTW(X, Y)), which is very efficient and has a time complexity O(n 2 ) in this context. However, when the size of data set grows large and the length of time series becomes long, it is very time-consuming to compute DTW combined with k-NN method. Hence, to reduce the time consumption, window constraint DTW has been adopted widely instead of full DTW in many previous work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. On the other hand, from the intuition, the warping path is unlikely to go very far from the diagonal of the distance matrix <ref type="bibr" target="#b9">[10]</ref>. In other words, for any element w k = d(q i , c j ) in the warping path, the difference between i and j should not be too large. By limiting the warping path to a warping window, some previous work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref> showed that relatively tight warping windows actually improve the classification accuracy.</p><p>According to above discussions, we consider both Euclidean distance and window constraint DTW as the default distance measures in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multi-channels deep convolutional neural networks</head><p>In this section, we will introduce a deep learning framework for multivariate time series classification: multi-channels deep convolutional neural networks (MC-DCNN). Traditional convolutional neural networks (CNN) usually include two parts. One is a feature extractor, which learns features from raw data automatically. The other is a trainable fullyconnected MLP, which performs classification based on the learned features from the previous part. Generally, the feature extractor is composed of multiple similar stages, and each stage is made up of three cascading layers: filter layer, activation layer and pooling layer. The input and output of each layer are called feature maps <ref type="bibr" target="#b12">[13]</ref>. In the previous work of CNN <ref type="bibr" target="#b12">[13]</ref>, the feature extractor usually contains one, two or three such three-layer stages. For remainder of this section, we first introduce the components of CNN briefly and more details of CNN can be referred to <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b20">21]</ref>. Then, we show the gradient-based learning of our model. After that, the related unsupervised pretraining is given at the end of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Architecture</head><p>In contrast to image classification, the inputs of multivariate time series classification are multiple 1D subsequences but not 2D image pixels. We modify the traditional CNN and apply it to multivariate time series classification task in this way: We separate multivariate time series into univariate ones and perform feature learning on each univariate series individually, and then a traditional MLP is concatenated at the end of feature learning that is used to do the classification. To be understood easily, we illustrate the architecture of MC-DCNN in Fig. <ref type="figure" target="#fig_3">3</ref>. Specifically, this is an example of two-stage MC-DCNN with pretraining for activity classification. Once the pretraining is completed, the initial weights of network are obtained. Then, the inputs of three channels are fed into a two-stage feature extractor, which learns hierarchical features through filter, activation and pooling layers. At the end of feature extractor, the feature maps of each channel are flatten and combined as the input of subsequent MLP for classification. Note that in Fig. <ref type="figure" target="#fig_3">3</ref>, the activation layer is embedded into filter layer in the form of non-linear operation on each feature map. We describe how each layer works in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Filter layer</head><p>The input of each filter is a univariate time series, which is denoted x l i ∈ n l 2 , 1 i n l 1 , where l denotes the layer which the time series comes from, n l 1 and n l 2 are number and length of input time series. To capture local temporal information, it requires to restrict each trainable filter k i j with a small size, which is denoted m l 2 , and the number of filter at layer l is Recalling the example described in Fig. <ref type="figure" target="#fig_3">3</ref>, in first stage of channel 1, we have n l 1 = 1, n l 2 = 256, m l 2 = 5, and m l 1 = 8. We compute the output of each filter according to this: i x l-1 i * k l i j + b l j , where the * is convolution operator and b l j is the bias term. To determine the size of each filter k i j , we follow the earlier studies <ref type="bibr" target="#b21">[22]</ref> and set it to 5 (m 2 = 5) as they suggested.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Activation layer</head><p>The activation function introduces the non-linearity into neural networks and allows it to learn more complex model. Two activation functions sigmoid(x) = 1/1 + e -x and tanh(x) = e xe -x /e x + e -x are most widely used in artificial neural networks for a long time. In recent years, a novel activation function named as "rectified linear units" (ReLU) has been attempted by many studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. ReLU is defined as: f (x) = max(0, x). When comparing with traditional activation functions (i.e., sigmoid(•) and tanh(•)), the merit of ReLU is that it can improve the generalization and make the training of networks become faster and simpler <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. Besides, this activation function could avoid vanishing gradient issue and be computed efficiently. For easy understanding, we illustrate ReLU and these two common activation functions in Fig. <ref type="figure" target="#fig_0">4</ref>. In this extended version, we consider integrating ReLU into our MC-DCNN models to improve the performance of time series classification. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Pooling layer</head><p>Pooling is also called as subsampling because it usually subsamples the input feature maps by a specific factor. The purpose of pooling layer is to reduce the resolution of input time series, and make it robust to small variations for previous learned features. The simplest yet most popular method is to compute average value in each neighborhood at different positions with or without overlapping. The neighborhood is usually constructed by splitting input feature maps into equal length (larger than 1) subsequences. Another widely used method is max pooling which computes the maximum in the neighborhood in contrast to average pooling. Previous studies <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> claimed that max pooling is superior to average pooling for image classification and it also leads to faster convergence rate by selecting superior invariant features that improve generalization performance. Hence, to further improve the performance, in this extended version, we apply the max pooling strategy in our deep convolutional neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Gradient-based learning of MC-DCNN</head><p>The same as traditional MLP, for multi-class classification task, the loss function of our MC-DCNN model is defined as:</p><formula xml:id="formula_7">E = -t k y * k (t) log(y k (t))</formula><p>, where y * k (t) and y k (t) are the target and predicted values of tth training example at kth class, respectively. To estimate parameters of models, we utilize gradient-based optimization method to minimize the loss function. Specifically, we use simple backpropagation algorithm to train our MC-DCNN model, since it is efficient and most widely used in neural networks <ref type="bibr" target="#b26">[27]</ref>. We adopt stochastic gradient descent (SGD) instead of full-batch version to update the parameters. Because SGD could converge faster than full-batch for large scale data sets <ref type="bibr" target="#b26">[27]</ref>.</p><p>A full cycle of parameter updating procedure includes three cascaded phases <ref type="bibr" target="#b27">[28]</ref>: feedforward pass, backpropagation pass and the gradient applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Feedforward pass</head><p>The objective of feedforward pass is to determine the predicted output of MC-DCNN on input vectors. Specifically, it computes feature maps from layer to layer and stage to stage until obtaining the output. As shown in the previous content, each stage contains three cascaded layers, and activation layer is embedded into filter layer in form of non-linear operation on each feature map. We compute output feature map of each layer as follows:</p><formula xml:id="formula_8">z l j = i x l-1 i * k l i j + b l j , x l j = φ(z l j ), x l+1 j = down(x l j ),</formula><p>where down(•) represents the subsampling function for either average or max pooling, φ(•) represents the activation function (either sigmoid(•) or ReLU here), x l-1 i and z l j denote the input and output of filter layer, z l j and x l j denote the input and output of activation layer, x l j and x l+1 j denote the input and output of pooling layer.</p><p>Eventually, a two-layer fully-connected MLP is concatenated to feature extractor. Due to feedforward pass of MLP is standard and the space is limited, more details of MLP can be referred to Refs. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Backpropagation pass</head><p>Once acquiring predicted output y, the predicted error E can be calculated according to the loss function. By taking advantage of chain-rule of derivative, the predicted error propagates back on each parameter of each layer one by one, which can be used to work out the derivatives of them. We do not present backpropagation pass of final MLP for the same reason of feedforward pass.</p><p>For pooling layer in the second stage of feature extractor, the derivative of x l-1 j is computed by the upsampling function up(•), which is an inverse operation opposite to the subsampling function down(•) for the backward propagation of errors in this layer.</p><formula xml:id="formula_9">∂E ∂x l-1 j = up( ∂E ∂x l j ).</formula><p>For filter layer in second stage of feature extractor, derivative of z l j is computed similar to that of MLP's hidden layer:</p><formula xml:id="formula_10">δ l j = ∂E ∂z l j = ∂E ∂x l j ∂x l j ∂z l j = φ (z l j ) • up( ∂E ∂x l+1 j ),</formula><p>where • denotes element-wise product. Since the bias is a scalar, to compute its derivative, we should summate over all entries in δ l j as follows:</p><formula xml:id="formula_11">∂E ∂b l j = u (δ l j ) u .</formula><p>The difference between kernel weight k l i j and MLP's weight w l i j is the weight sharing constraint, which means the weights between (k l i j ) u and each entry of x l j must be the same. Due to this constraint, the number of parameters is reduced by comparing with the fully-connected MLP, Therefore, to compute the derivative of kernel weight k l i j , it needs to summate over all quantities related to this kernel. We perform this with convolution operation:</p><formula xml:id="formula_12">∂E ∂k l i j = ∂E ∂z l j ∂z l j ∂k l i j = δ l j * reverse(x l-1 i ),</formula><p>where reverse(•) is the function to reverse the sequence with respect to each feature map. Finally, we compute the derivative of x l-1 i as follows:</p><formula xml:id="formula_13">∂E ∂x l-1 i = j ∂E ∂z l j ∂z l j ∂x l-1 i = j pad(δ l j ) * reverse(k l i j ),</formula><p>where pad(•) is a function which pads zeros into δ l j from two ends, e.g., if the size of k l i j is n l 2 , then this function will pad each end of δ l j with n l 2 -1 zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Gradients applied</head><p>Once we obtain the derivatives of parameters, it's time to apply them to update parameters. To converge fast, we utilize decay and momentum strategies <ref type="bibr" target="#b26">[27]</ref>. The weight w l i j in MLP is updated in this way:</p><formula xml:id="formula_14">w l i j = w l i j + Δw l i j , Δw l i j = momentum • Δw l i j -decay • • w l i j -• ∂E ∂w l i j</formula><p>, where w l i j represents the weight between x l-1 i and x l j , Δw l i j denotes the gradient of w l i j , and denotes the learning rate. The kernel weight k l i j , the bias term b l j in filter layer and b l in MLP are updated similar to the way of w l i j . The same as Ref. <ref type="bibr" target="#b28">[29]</ref>, we set momentum = 0.9, decay = 0.000 5 and = 0.01 for our experiments. It is noted that Ref. <ref type="bibr" target="#b29">[30]</ref> claimed that both the initialization and the momentum are crucial for deep neural networks, hence, we consider the way of selecting these values as a part of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pretraining</head><p>One challenge of neural networks especially for deep architectures is how to avoid bad local minima during the learning process. Many previous studies claimed that a greedy layerwise unsupervised initialization could alleviate the local minima issue and achieve better performance <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>. In this subsection, we consider such a kind of unsupervised pretraining for our deep neural networks. Specifically, we first recall conventional pretraining methods (Auto-Encoder and Denoising Auto-Encoder) and then explain how to pretrain the CNN with stacked Convolutional Auto-Encoder (CAE) <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Auto-Encoder</head><p>Basically, an Auto-Encoder is a three layers artificial neural network, which is very similar to traditional MLP. The aim of Auto-Encoder is to learn a transformation from original space to a lower-dimensional space. Through the learnt transformation, the compressed low-dimensional representations could be used as features for many other tasks. Meanwhile, another usage of Auto-Encoder is to initialize the neural networks for better performance. By stacking a series of Auto-Encoders, the constructed deep architecture could be further fine-tuned in the form of supervised learning. Suppose the input is x ∈ R d and the hidden representation is denoted as h ∈ R d . In an Auto-Encoder, h = φ(Wx + b) and y = φ(W h + b ), where y represents the reconstruction of input x and φ denotes the activation function. The only constraint here is W = W T . Analogous to traditional neural networks, we could learn the parameters θ = {W, b, b } through minimizing the reconstructed error: E(θ) = xy 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Denoising Auto-Encoder</head><p>The deficiency of conventional Auto-Encoder is that it may learn the identity transformation if we do not apply any constraints on it. The common solution for this is either adding a regularized sparsity to the cost function or adding random noisy to the inputs. The latter one named as Denoising Auto-Encoder is more popular due to its simplicity. Since the only modification is to add a variable v to each element of inputs. The variable v could follow either a binomial distribution for binary input or common Gaussian distribution for continuous value. The learning process of Denoising Auto-Encoder is identical to that of conventional Auto-Encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Convolutional Auto-Encoder</head><p>The elements in both Auto-Encoder and Denoising Auto-Encoder are fully connected. Different from these two models, Convolutional Auto-Encoder (CAE) has a constrain on the connections, i.e., the weights between two layers are shared in form of convolution. As is shown, such a convolution operation could preserve the spatial and temporal locality. Thus CNN has the advantage of time-shift invariance. Due to the convolutional and pooling operations, the pretraining of CNN with stacked CAEs is different from the other two models. At the same time, the reconstruction of CAE is also different from formal forward and backward passes of CNN. For the convolutional encoder, the hidden feature maps of CAE can be calculated as follows:</p><formula xml:id="formula_15">h j = φ(z j ) = φ( i pad(x i ) * k i j + b j ),</formula><p>where x i represents the ith element of input and h j denotes the jth filter map after convolution and activation. The function pad(•) will pad x i with zeros from two ends, e.g., if the size of k ih is n 2 then this function will pad each end of x i with n 2 -1 zeros. Other symbols have already been explained in previous sections. After that, h j will be processed through a pooling layer. Analogous to conventional Auto-Encoder, the reconstruction of x i should be built based on h j in a reversed procedure of convolutional encoder. The convolutional decoder works in form of the equation below:</p><formula xml:id="formula_16">y i = φ( j h j * reverse(k i j ) + c i ),</formula><p>where the reverse(•) has been mentioned before and c i is the bias term for the reconstruction y i . For the sake of learning the parameters, we need to minimize the cost function of CAE: E(θ) = i x iy i 2 . Similar to CNN, by applying the backpropagation algorithm, the gradient of each parameter could be obtained and then the parameters will be updated until final convergence of CAE.</p><p>Our MC-DCNN model could include multiple stages. Hence, to pretrain the deep architecture we require stacking several CAEs. Recall Fig. <ref type="figure" target="#fig_3">3</ref>, the first stage of this model is pretrained based on CAE at the beginning and then its hidden representations will be fed into the subsequent CAE for the second stage as its input. For MC-DCNN with more stages, the unsupervised pretraining would be performed for these CAEs one by one following the greedy, layer-wise fashion. Once the unsupervised pretraining of all CAEs has been done, then the learnt parameters will be used to initialize our MC-DCNN model. After that, the supervised learning of CNN will be performed as shown in Section 3.1 and 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct experiments on real-world data sets from two application domains, and we will demonstrate: 1) The performance of our MC-DCNN via comparing with baselines on weakly labeled data (Section 4.1) and well aligned data (Section 4.2 and 4.3), respectively; 2) The evaluation of activation functions and pooling strategies (Section 4.4); 3) The visualization of learnt features (Section 4.5); 4) A brief discussion (Section 4.6).</p><p>To the best of our knowledge, there are many public time series data sets available, e.g., the UCR Suite 2) . However, we decide not using the UCR Suite for the following reasons. First, we focus on the classification of multivariate time series, whereas most data sets in UCR Suite only contain univariate time series. Second, data sets in UCR Suite are usually small and CNN may not work well on such small data sets <ref type="bibr" target="#b33">[34]</ref>. One exception is the Non-Invasive Fetal ECG data set. In the UCR Suite, there are two data sets related to Non-Invasive Fetal ECG, both of which were created by recording the heartbeat information. One corresponds to the heartbeat data from left thorax and the other corresponds to that from right. Then, we could combine these two single data sets and obtain a 2D time series data set. Besides, we also choose two data sets that are collected from real-world applications. And we will describe each of these data sets in the next subsections.</p><p>We consider three approaches as baseline methods for evaluation: 1-NN (ED), 1-NN (DTW-5%) and MLP. Here, 1-NN (ED) and 1-NN (DTW-5%) are the methods that combine Euclidean distance and window constraint DTW 3) [10] with 1-NN, respectively. Besides these two state-of-the-art methods, MLP is chosen to demonstrate that the feature learning process can improve the classification accuracy effectively. For the purpose of comparison, we record the performance of each method by tuning their parameters. Notice that some other classifiers are not considered here, since it is difficult to construct hand-crafted features for time series and much previous work have claimed that feature-based methods cannot achieve the accuracy as high as 1-NN methods. Moreover, we do not choose the full DTW due to its expensive time consumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Activity classification (weakly labeled data)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Data set</head><p>We use the weakly labeled PAMAP2 data set for activity classification 4)  <ref type="bibr" target="#b6">[7]</ref>. It records 19 physical activities performed by nine subjects. On a machine with Intel I5-2410 (2.3GHz) CPU and 8G Memory (our experimental platform), according to the estimation, it will cost more than a month for 1-NN (DTW-5%) on this data set if we use all the 19 physical activities 5) . Hence, without loss of generality, currently, we only consider four activities in our work, which are "standing", "walking", "ascending stairs" and "descending stairs". And each physical activity corresponds to a 3D time series. Moreover, seven out of these nine subjects are chosen, because the other two either have different physical activities or have different dominant hand/foot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Experiment setup</head><p>We normalize each dimension of 3D time series as x -μ/σ, where μ and σ are mean and standard deviation of time series. Then we apply the sliding window algorithm as shown in Algorithm 1 to extract subsequences from 3D time series 2) www.cs.ucr.edu/˜eamonn/time_series_data/ 3) Following the discoveries in <ref type="bibr" target="#b9">[10]</ref>, we set the optimal window constraint r as 5% 4) http://www.pamap.org/demo.html 5) There are 240,000 and 60,000 samples in training and test sets, respectively. Each sample includes three components with the length of 256 with different sliding steps. Table <ref type="table" target="#tab_1">1</ref> shows the number of subsequences of each activity for each subject when sliding step is set to 8. To evaluate the performance of different models, we adopt the leave-one-out cross validation (LOOCV) technique. Specifically, each time we use one subject's physical activities as test data, and the physical activities of remaining subjects as training data. Then we repeat this for every subject. To glance the impact of depths, we evaluate two kinds of models: MC-DCNN(1)/MC-DCNN(1)-Pre, MC-DCNN(2)/MC-DCNN(2)-Pre, with respect to 1-stage and 2stage non-pretrained/pretrained models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Experimental results</head><p>To evaluate efficiency and scalability of each model, we get five data splits with different volumes by setting sliding step as 128, 64, 32, 16, 8, respectively. In addition, to ensure each subsequence to cover at least one pattern of time series, we set the sliding window length L as 256.</p><p>Feature-based models have an advantage over lazy classification models (e.g., k-NN) in efficiency. As shown in Fig. <ref type="figure" target="#fig_5">5</ref>, the prediction time of 1-NN model increases linearly as the size of training data set grows. In contrast, the prediction time of our MC-DCNN model is almost constant no matter how large the training data is.</p><p>We also evaluate accuracy of each model on these five data splits. Figure <ref type="figure" target="#fig_6">6</ref> shows the detailed accuracy comparisons of each subject at different step settings (data splits). From this figure we can see that for each subject our MC-DCNN model, particularly the pretrained two-stage one, is either the most accuracy one or very close to the most accuracy one. Especially, for subject 3, the two-stage MC-DCNNs lead to much better classification accuracy than other approaches. We suppose that 2-stage MC-DCNNs may learn higher level and more robust feature representations so that it has a good generalization. The average and standard deviation of accuracy is shown in Table <ref type="table" target="#tab_2">2</ref>. From the table we can see that our MC-DCNN leads to the highest average accuracy and the lowest standard deviation. Especially, the pretrained MC-DCNN is superior to others including the non-pretrained models, which demonstrates that such an unsupervised initialization could indeed improve the performance to some extent. By comparing to 1-stage MC-DCNN, the 2-stage models perform better at each sliding step. This is consistent to the statement of previous studies <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36]</ref> that deep neural networks trained by simple back-propagation work better than shallower ones. On the other hand, by comparing MC-DCNN with traditional MLP, the superiority of MC-DCNN demonstrates that the feature learning process could indeed improve the performance of classification and the MC-DCNN model can learn good internal representations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Data set</head><p>The well aligned BIDMC data set was downloaded from Congestive Heart Failure database 6)  <ref type="bibr" target="#b15">[16]</ref>. Long-term electrocardiograph (ECG) data was recorded from 15 subjects, each of them suffers severe Congestive Heart Failure. Different from PAMAP2 data, in BIDMC data set, each type of heart failure corresponds to a 2D time series, which was recorded by medical instruments. Table <ref type="table" target="#tab_4">3</ref> shows the number of subsequences of each type. In this experiment, we consider four types of heartbeats to evaluate all the models: "N", "V", "S", "r".  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Experiment setup</head><p>We still normalize each univariate of 2D time series as x -μ/σ, where μ and σ are mean and standard deviation of time series. Different from weakly data, we extract subsequences centered at aligned marks (the dotted line in Fig. <ref type="figure" target="#fig_1">1</ref>). And each subsequence still has a length of 256. Similar to the classification of individuals' heartbeats <ref type="bibr" target="#b14">[15]</ref>, we mix all data of 15 subjects and randomly split it into ten folds to perform 10-fold cross validation. Because as Ref. <ref type="bibr" target="#b14">[15]</ref> noted, it can be able to obtain huge amounts of labeled data in this way and an unhealthy individual may have many different types of heart-beats. Similar to the previous experiment, we also evaluate these models to glance the impact of depths and pretraining on this data set. Moreover, to determine the epochs, we separate one third of training data as validation set. As shown in Fig. <ref type="figure" target="#fig_7">7</ref>, we set epoch to 40 and 80 for 1-stage and 2-stage MC-DCNN models respectively. Since the test error is stable when epochs are greater than them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Experimental results</head><p>We show the classification accuracy of each model on BIDMC data set in Fig. <ref type="figure">8</ref>. The accuracies of 1-stage and 2-stages non-pretrained MC-DCNN models are 94.67% and 94.65%. After we pretrained the MC-DCNN models, the MC-DCNN(1)-Pre and MC-DCNN(2)-Pre models improve the classification accuracies to 95.04% and 95.35%. All these MC-DCNN models have better performance than other It is also noted that all of these learning-based methods including MLP perform better than distance-based methods. We consider that it may be due to the precise alignment of each heartbeat signal. For the well aligned data, these learning-based methods could capture the potential important information and obtain good feature representations. Still, MC-DCNN is superior to MLP, which also demonstrates that the feature learning is beneficial for improving the classification accuracy. The experimental result proves that the pretraining process improve the performance indeed. We do not report the prediction time of each model on BIDMC data set. Since, the result is similar to Fig. <ref type="figure" target="#fig_5">5</ref> and it also supports that feature-based models have an advantage over lazy classification methods such as k-NN in efficiency.</p><p>Fig. <ref type="figure">8</ref> The box-and-whisker plot of classification accuracy on BIDMC </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Experimental results</head><p>We show the classification accuracy of each model on NIFE data set in Table <ref type="table" target="#tab_6">4</ref>.</p><p>This result is analogous to that of the previous BIDMC data set. All of the learning-based methods achieve higher DCNN is superior to one-stage model to some extent but also demonstrates the pretraining can improve the classification accuracy indeed. Nonetheless, the improvement of MC-DCNN models is not that remarkable, especially for MLP, which proves our assumption, i.e., with precise alignment time series data (that means without the time-shift involved), even the traditional MLP could obtain good feature representations of data and achieve good classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation of activation functions and pooling strategies</head><p>We treat the traditional sigmoid(•) function and average pooling as a default choice for previous experiments. To further evaluate the effect of activation functions and pooling strategies, in the following, we conduct several experiments on PAMAP2 data set. Specifically, we focus on testing the rate of convergence of the MC-DCNN models integrated with different activation functions and pooling strategies.</p><p>For a better illustration of convergence, we select one subject from PAMAP2 and show the rate of convergence of each model in Fig. <ref type="figure" target="#fig_8">9</ref>. We consider two activation functions (i.e., ReLU and sigmoid(•)) and two sorts of pooling strategies (max and average poolings) here. As the epoch grows from 1 to 100, for each setting of activation function and pooling strategy, the training error decreases with different speed. From this figure, we can see that ReLU is superior to sigmoid(•) function since the training error of ReLU converges faster than that of sigmoid(•) for both one-stage and two-stage MC-DCNN models. For the pooling strategy, average pooling converges a little faster than max pooling but the difference is subtle. By the consideration of generalization ability that mentioned in previous studies, we believe that max pooling is a good choice for our study. Hence, we combine ReLU and max pooling in our MC-DCNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Visualization</head><p>To visualize the learnt features of MC-DCNN model, we trained a 2-stage MC-DCNN model on the PAMAP2 data set. Both of the first and the second filter layers contain 20   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>We first discuss the advantages of our method intuitively. In MC-DCNN, the multi-channels can learn feature representation for each univariate time series automatically and individually. Then, the traditional MLP is used to combine these features and obtain a better representation for each class. According to the experimental results, such feature learning and feature combining approaches improve the classification performance for multivariate time series. We believe that our model can obtain better feature representations from each channel for each univariate time series and also the final feature combining can further learn the weights for each class, which makes our model can distinguish different patterns of the different underlying phenomena effectively and improves the performance finally.</p><p>In the following, we discuss the limitations of this study, and we believe that the discussions will lead to many future work. First, although we conducted these experiments with different parameter settings, there are still many other parameters in our MC-DCNN model. According to the suggestions of previous studies, some parameters were set to constants, while this may not be the optimal choice for our problem. Second, it is time-consuming to train the neural networks since we did not utilize the parallel techniques (e.g., speedup by GPU) but implemented all the models in Matlab. This is also one of the reasons why we only constructed at most twostage MC-DCNN in the experiments. Hence, in the future work, we plan to study and extend other deep learning models for multivariate time series classification on more data sets and parameter settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>We first briefly review previous studies of time series classification methods. Then, we summarize the existing research interest on feature learning by deep neural networks and introduce the related pretraining methods at the end of this section. Many time series classification methods have been proposed based on different sequence distance measurements. Among the previous work, some researchers claimed that 1-NN combined DTW is the current state of the art <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. However, the biggest weakness of 1-NN with DTW model is its expensive computation <ref type="bibr" target="#b9">[10]</ref>. To overcome this drawback, some of the researchers explored to speed up the computation of distance measure (e.g., DTW) in certain methods (e.g., with boundary conditions) <ref type="bibr" target="#b9">[10]</ref>. While some of other researchers tried to reduce the computation of 1-NN by constructing data dictionary <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b36">37]</ref>. When the data set grows large, all these approaches improve the performance significantly in contrast to simple 1-NN with DTW. Though many feature-based models have been explored for time series classification <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b37">38]</ref>, most of previous work extracted the hand-crafted statistical features based on domain knowledge, and achieved the performance not as well as sequence distance based models.</p><p>Feature learning (or representation learning) is becoming an important field in machine learning community for recent years <ref type="bibr" target="#b10">[11]</ref>. The most successful feature learning framework is deep neural networks, which build hierarchical representations from raw data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b38">39]</ref>. Particularly, as a supervised feature learning model, deep convolutional neural networks achieve remarkable successes in many tasks such as digit and object recognition <ref type="bibr" target="#b28">[29]</ref>, which motivates us to investigate the deep learning in time series field. In current literature, there are few studies on time series classification using feature learning and deep neural networks. Ref. <ref type="bibr" target="#b39">[40]</ref> explored an unsupervised feature learning method with convolutional deep belief networks for audio classification, but in frequency domain rather than in time domain. Ref. <ref type="bibr" target="#b40">[41]</ref> proposed a time-delay neural networks (TDNN) for phoneme recognition. The TDNN can be considered as a simplified model of CNN, since it only contains one or two tied connection hidden layers but does not perform pooling like traditional CNN, which makes it not have a good shift invariant ability as well as CNN. Ref. <ref type="bibr" target="#b4">[5]</ref> adopted a special TDNN model for electroencephalography (EEG) classification. However, their TDNN model only included a single hidden layer, which is not deep enough to learn good hierarchical features.</p><p>One challenge of neural networks especially for deep architectures is how to avoid bad local minima during the learning process. To alleviate this issue, a better initialization of weights in neural networks is needed, which can further improve classification performance <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>. For CNN, a greedy layer-wise unsupervised initialization named stacked Convolutional Auto-Encoder (CAE) can be used to pretrain the networks, which has been shown the effectiveness to improve the classification performance <ref type="bibr" target="#b32">[33]</ref>. To the best of our knowledge, none of existing studies on time series classification has considered the supervised feature learning from raw data and also pretraining of networks. Hence, in this paper, we explore a MC-DCNN model for multivariate time series classification and intend to investigate this problem from feature learning view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we developed a novel deep learning framework (MC-DCNN) to classify multivariate time series. Through learning features from individual univariate time series in each channel automatically, this model then combines the outputs of all channels as feature representation at final layer. After that, a traditional MLP concatenated to the final layer of feature representation performs the classification. Meanwhile, we applied an unsupervised initialization to pretrain CNN and proposed the pretrained version of MC-DCNN model. Finally, extensive experimental results on several real-world data sets revealed that the MC-DCNN model indeed outperformed the competing baseline methods, and the improvement of accuracy on weakly labeled data set is significant. We found that the pretrained models outperform the non-pretrained ones, which shows the effectiveness of pretraining to improve the classification performance. We also observed that 2-stage MC-DCNN is superior to onestage model to some extent, which provides the evidence that deeper architecture could learn more robust high-level features for improving the classification. We hope that this study could lead to more future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 4</head><label>4</label><figDesc>Well aligned and labeled data: Subsequences 1) A preliminary version of this work has been published in the proceedings of WAIM 2014 (full paper) are labeled by domain experts, and different subsequences with the same pattern are well aligned.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 A</head><label>1</label><figDesc>Fig.1A snippet of time series which contains two types of heartbeat: normal (N) and ventricular fibrillation (V)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Four 1D samples of 3D weakly labeled physical activities: (a) "standing"; (b) "walking"; (c) "ascending stairs"; (d) "descending stairs"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 A</head><label>3</label><figDesc>Fig.3A two-stage MC-DCNN architecture for activity classification. This architecture consists of three channels input, two filter layers, two pooling layers and two fully-connected layers. Pretraining is performed for two stages gradually and then supervised learning is applied. This architecture is denoted as 8(5)-2-4(5)-2-732-4 based on the template C1(Size)-S1-C2(Size)-S2-H-O, where C1 and C2 are numbers of filters in the first and second stage, Size denotes the kernel size, S1 and S2 are subsampling factors, H and O denote the numbers of units in hidden and output layers of MLP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Illustration of non-linearity, sigmoid(•), tanh(•) and ReLU functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Prediction time of each model on training sets with different size</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Classification accuracy on each subject with different sliding steps</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 Test error on validation set. (a) 1-stage MC-DCNN model; (b) 2-stage MC-DCNN model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9</head><label>9</label><figDesc>Fig. 9 Training error of (a) 1-stage and (b) 2-stage MC-DCNNs with sigmoid(•), ReLU activation functions and average, max pooling strategies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 Visualization of the first filter layer in the model trained on PAMAP2 data set. (a) Channel one: 20 filter weights with the length of 5; (b) and (c) represent the filter weights in the other two channels, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11</head><label>11</label><figDesc>Fig. 11 Visualization of the second filter layer in the model trained on PAMAP2 data set. (a) Channel one: 20 × 20 filter weights with the length of 5; (b) and (c) represent the filter weights in the other two channels, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>The number of subsequences of each activity</figDesc><table><row><cell>Subject</cell><cell>Standing</cell><cell>Walking</cell><cell>Ascending stairs</cell><cell>Descending stairs</cell></row><row><cell>1</cell><cell>2 683</cell><cell>2 750</cell><cell>1 922</cell><cell>1 798</cell></row><row><cell>2</cell><cell>3 166</cell><cell>4 035</cell><cell>2 104</cell><cell>1 838</cell></row><row><cell>3</cell><cell>2 535</cell><cell>3 598</cell><cell>1 235</cell><cell>1 814</cell></row><row><cell>4</cell><cell>3 057</cell><cell>3 960</cell><cell>2 023</cell><cell>1 722</cell></row><row><cell>5</cell><cell>2 735</cell><cell>3 972</cell><cell>1 722</cell><cell>1 527</cell></row><row><cell>6</cell><cell>3 013</cell><cell>3 183</cell><cell>1 598</cell><cell>1 345</cell></row><row><cell>7</cell><cell>3 187</cell><cell>4 183</cell><cell>2 141</cell><cell>1 389</cell></row><row><cell>Total</cell><cell>20 376</cell><cell>25 681</cell><cell>12 745</cell><cell>11 433</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Average and standard deviation of accuracy at different sliding step</figDesc><table><row><cell>Method</cell><cell>Step=128</cell><cell>Step=64</cell><cell>Step=32</cell><cell>Step=16</cell><cell>Step=8</cell></row><row><cell>1-NN (ED)</cell><cell>79.05 (0.076)</cell><cell>80.25 (0.089)</cell><cell>80.74 (0.094)</cell><cell>81.74 (0.096)</cell><cell>82.28 (0.103)</cell></row><row><cell>1-NN (DTW-5%)</cell><cell>83.46 (0.063)</cell><cell>84.51 (0.070)</cell><cell>84.44 (0.080)</cell><cell>84.16 (0.094)</cell><cell>83.61 (0.104)</cell></row><row><cell>MLP</cell><cell>77.89 (0.076)</cell><cell>80.09 (0.098)</cell><cell>82.49 (0.096)</cell><cell>84.34 (0.104)</cell><cell>84.83 (0.115)</cell></row><row><cell>MC-DCNN(1)</cell><cell>88.73 (0.057)</cell><cell>90.38 (0.050)</cell><cell>90.28 (0.063)</cell><cell>90.75 (0.062)</cell><cell>90.53 (0.065)</cell></row><row><cell>MC-DCNN(1)-Pre</cell><cell>89.37 (0.044)</cell><cell>91.47 (0.027)</cell><cell>90.38 (0.049)</cell><cell>91.11 (0.048)</cell><cell>90.55 (0.071)</cell></row><row><cell>MC-DCNN(2)</cell><cell>90.34 (0.031)</cell><cell>91.00 (0.033)</cell><cell>91.14 (0.031)</cell><cell>93.15 (0.019)</cell><cell>93.36 (0.015)</cell></row><row><cell>MC-DCNN(2)-Pre</cell><cell>90.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>94 (0.025) 91.63 (0.032) 92.27 (0.028) 93.22 (0.011) 93.43 (0.013) Note</head><label></label><figDesc></figDesc><table /><note><p>: Bold numbers represent the best results</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>The number of subsequences of each heartbeat type</figDesc><table><row><cell>Type</cell><cell>N</cell><cell>V</cell><cell>S</cell><cell>r</cell><cell>+</cell><cell>Q</cell><cell>E</cell></row><row><cell>Number</cell><cell>31 563</cell><cell>28 166</cell><cell>5 314</cell><cell>10 353</cell><cell>258</cell><cell>293</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Classification accuracy of each model on NIFE</figDesc><table><row><cell>Method</cell><cell>Precision</cell></row><row><cell>1-NN (DTW-5%)</cell><cell>88.19</cell></row><row><cell>MLP</cell><cell>95.32</cell></row><row><cell>1-NN (ED)</cell><cell>89.62</cell></row><row><cell>MC-DCNN(1)</cell><cell>95.93</cell></row><row><cell>MC-DCNN(1)-Pre</cell><cell>96.03</cell></row><row><cell>MC-DCNN(2)</cell><cell>96.13</cell></row><row><cell>MC-DCNN(2)-Pre</cell><cell>96.23</cell></row><row><cell cols="2">accuracy than that of distance-based methods. As we said, the</cell></row><row><cell cols="2">reason of such result may be because the ECG data is aligned</cell></row><row><cell cols="2">precisely. For such well aligned data, these three learning-</cell></row><row><cell cols="2">based methods may capture the potential important infor-</cell></row><row><cell cols="2">mation and acquire good feature representations. Hence, the</cell></row><row><cell cols="2">learning-based methods perform better than distance-based</cell></row><row><cell cols="2">ones. The MC-DCNN models including the pretrained ones</cell></row><row><cell cols="2">are superior to MLP, which proves that feature learning can</cell></row><row><cell cols="2">improve the classification accuracy. Moreover, the pretrained</cell></row><row><cell cols="2">2-stage MC-DCNN outperforms other models and achieves</cell></row><row><cell cols="2">the highest accuracy, which not only proves that 2-stage MC-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p><ref type="bibr" target="#b5">6)</ref> http://www.physionet.org/physiobank/database/chfdb/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was partially supported by the National Science Foundation for Distinguished Young Scholars of China (61325010), the National High Technology Research and Development Program of China (2014AA015203), the National Natural Science Foundation of China (Grant No. 61403358) and the Fundamental Research Funds for the Central Universities of China (WK2350000001, WK0110000042).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A brief survey on sequence classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Querying and mining of time series data: experimental comparison of representations and distance measures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Trajcevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1542" to="1552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining discrete svm and fixed cardinality warping distances for multivariate time series classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Orsenigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vercellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3787" to="3794" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multivariate time series classification with temporal abstractions</title>
		<author>
			<persName><forename type="first">I</forename><surname>Batal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bellazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of FLAIRS Conference</title>
		<meeting>FLAIRS Conference</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using time-dependent neural networks for EEG classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Haselsteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pfurtscheller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="457" to="463" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Heartbeat time series classification with support vector machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kampouraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Manis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nikou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="512" to="518" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Introducing a modular activity monitoring system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Annual International Conference on Engineering in Medicine and Biology Society</title>
		<meeting>IEEE Annual International Conference on Engineering in Medicine and Biology Society</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="5621" to="5624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A complexity-invariant distance measure for time series</title>
		<author>
			<persName><forename type="first">G E A P A</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIAM Conference on Data Mining</title>
		<meeting>SIAM Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Searching and mining trillions of time series subsequences under dynamic time warping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Campana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zakaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast time series classification using numerosity reduction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C R</forename><surname>Shelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1033" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Representation learning: a review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series. The Handbook of Brain Theory and Neural Networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">3361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional networks and applications in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Symposium on Circuits and Systems</title>
		<meeting>IEEE International Symposium on Circuits and Systems</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="253" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Time series classification using multi-channels deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Web-Age Information Management</title>
		<meeting>the 15th International Conference on Web-Age Information Management</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="298" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Time Series Classification under More Realistic Assumptions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIAM International Conference on Data Mining</title>
		<meeting>SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">578</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Physiobank, Physiotoolkit, and Physionet omponents of a new research resource for complex physiologic signals</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="215" to="e220" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Time series shapelets: a new primitive for data mining</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="947" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Making time-series classification more accurate using learned constraints</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIAM International Conference on Data Mining</title>
		<meeting>SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Three myths about dynamic time warping data mining</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIAM International Conference on Data Mining</title>
		<meeting>SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="506" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic time warping constraint learning for large margin nearest neighbor classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2787" to="2796" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Document Analysis and Recognition</title>
		<meeting>the 7th International Conference on Document Analysis and Recognition</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="958" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning</title>
		<meeting>the 27th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On rectified linear units for speech processing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>IEEE International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3517" to="3521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluation of pooling operations in convolutional architectures for object recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Artificial Neural Networks</title>
		<meeting>the 20th International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Max-pooling convolutional neural networks for vision-based hand gesture recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ducatelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G A</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Signal and Image Processing Applications</title>
		<meeting>IEEE International Conference on Signal and Image Processing Applications</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="342" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><surname>Efficient</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">7700</biblScope>
			<biblScope unit="page" from="9" to="48" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Notes on convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bouvrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">6791</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Why is real-world visual object recognition hard?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Flexible, high performance convolutional neural networks for image classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Joint Conference on Artificial Intelligence</title>
		<meeting>the 22nd International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1237" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-column deep neural network for traffic sign classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="333" to="338" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A shapelet transform for time series classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bagnall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Feature-based classification of time-series data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><surname>Alcock R O B</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for audio classification using convolutional deep belief networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Largman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1096" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Phoneme recognition using time-delay neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hanazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="339" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
