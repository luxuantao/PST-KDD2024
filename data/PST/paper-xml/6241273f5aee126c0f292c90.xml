<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UKP-SQUARE: An Online Platform for Question Answering Research</title>
				<funder ref="#_gDPfm7Q">
					<orgName type="full">European Regional Development Fund</orgName>
					<orgName type="abbreviated">ERDF</orgName>
				</funder>
				<funder>
					<orgName type="full">Hessian State Chancellery -Hessian Minister of Digital Strategy and Development</orgName>
				</funder>
				<funder ref="#_ZwscgPW #_REcz2jC #_cUBWJKk">
					<orgName type="full">German Research Foundation (DFG)</orgName>
				</funder>
				<funder ref="#_ae3AVep">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">LOEWE initiative (Hesse, Germany)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tim</forename><surname>Baumg?rtner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kexin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rachneet</forename><surname>Sachdeva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>Eichler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gregor</forename><surname>Geigle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Clifton</forename><surname>Poth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hannah</forename><surname>Sterz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haritz</forename><surname>Puerto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leonardo</forename><forename type="middle">F R</forename><surname>Ribeiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">G?zde</forename><forename type="middle">G?l</forename><surname>?ahin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Ko? University Computer Science and Engineering Department</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technical University of Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">UKP-SQUARE: An Online Platform for Question Answering Research</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in NLP and information retrieval have given rise to a diverse set of question answering tasks that are of different formats (e.g., extractive, abstractive), require different model architectures (e.g., generative, discriminative), and setups (e.g., with or without retrieval). Despite having a large number of powerful, specialized QA pipelines (which we refer to as Skills) that consider a single domain, model or setup, there exists no framework where users can easily explore and compare such pipelines and can extend them according to their needs. To address this issue, we present UKP-SQUARE, an extensible online QA platform for researchers which allows users to query and analyze a large collection of modern Skills via a user-friendly web interface and integrated behavioural tests. In addition, QA researchers can develop, manage, and share their custom Skills using our microservices that support a wide range of models (Transformers, Adapters, ONNX), datastores and retrieval techniques (e.g., sparse and dense). UKP-SQUARE is available on https://square.ukp-lab.de. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Researchers in NLP have devoted significant resources to creating more powerful machine learning models for Question Answering (QA), and collecting high-quality QA datasets. Combined with the recent breakthroughs by large pretrained language models, we have witnessed rapid progress in the field across many different kinds of QA tasks <ref type="bibr" target="#b32">(Rogers et al., 2021)</ref>.</p><p>The great variety in QA tasks has led to specialized, domain-specific models trained on a single QA format such as multiple choice <ref type="bibr" target="#b19">(Lai et al., 2017)</ref> (i.e., selecting the best answer out of multiple options), extractive <ref type="bibr" target="#b27">(Rajpurkar et al., 2016)</ref>  (i.e., finding the answer span in a context) and abstractive <ref type="bibr">(Kocisky et al., 2018) (i.e.</ref>, generating an answer that is not a contiguous span in the context). The format may influence the model architecture (e.g., discriminative objective for multiple choice, generative objective for abstractive). Additionally, systems vary with how the context is provided. It can be given by the user, or retrieved from a Datastore which is commonly referred to as open-domain or retriever-reader setup <ref type="bibr" target="#b2">(Chen et al., 2017)</ref>. The retrieval mechanism can also be chosen from a set of sparse (e.g., BM25, <ref type="bibr" target="#b31">Robertson et al., 1994)</ref> or dense (e.g., DPR, <ref type="bibr" target="#b14">Karpukhin et al., 2020)</ref> techniques.</p><p>The speed of progress in the field makes it essential for researchers to explore, compare, and combine these different QA components as quickly as possible to identify the strengths and weaknesses 3) query embedding [ 0.211 0.116, ?, 0.202, 0.141 ]   2) document retrieval 4) answer extraction of the current state of the art. Even though there exists a number of powerful QA systems <ref type="bibr" target="#b5">(Dibia, 2020;</ref><ref type="bibr" target="#b16">Khashabi et al., 2020)</ref> and frameworks such as Haystack, 2 those approaches focus only on one component (e.g., retrieval, QA format, domain), hence do not allow plug-and-play of different Datastores, domains, model architectures or retrieval techniques. This considerably limits their applicability and reusability across the diverse, rapidly progressing area of QA research, making it infeasible for researchers to quickly integrate novel models and QA pipelines.</p><p>To address this gap, we introduce UKP-SQUARE, a flexible and extensible QA platform to enable users to easily implement, manage and share their custom QA pipelines, which we call Skills, using our microservices. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, UKP-SQUARE also allows users to query and compare different Skills via an easy-to-use user interface and systematically analyze their strengths and weaknesses through integrated behavioural tests. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">UKP-SQUARE</head><p>The system is implemented as a modern microservice architecture using Docker containers. 4 The 2 https://deepset.ai/haystack 3 Screenshots for adding Skills, the outputs of different QA formats and behavioural tests are shown in Appendix D.</p><p>4 https://docker.com major components are Skills, Datastores, Models, Explainability and the User Interface. The process flow across the components is illustrated in Fig. <ref type="figure" target="#fig_2">2</ref> on an open-domain, extractive QA Skill. The central component of the system is the Skill that specifies how a user query is processed (e.g., which QA type, retrieval mechanism, model or adapter to be used in which order). The Skill leverages the other services for query execution.</p><p>Datastores hold multiple collections of documents with sparse indices, e.g., BM25 <ref type="bibr" target="#b31">(Robertson et al., 1994)</ref> and dense indices, e.g., DPR <ref type="bibr" target="#b14">(Karpukhin et al., 2020)</ref>, allowing fast and efficient retrieval of background knowledge in an extensible way. The Model service hosts numerous models, combined with Adapters <ref type="bibr" target="#b9">(Houlsby et al., 2019;</ref><ref type="bibr" target="#b24">Pfeiffer et al., 2020)</ref>, to support a wide range of tasks such as text embedding (for queries in opendomain QA), sequence and token classification (for multiple-choice and extractive QA) and sequenceto-sequence generation (for abstractive QA). The Explainability component performs behavioural tests on the deployed Skills for better understanding of the models. Details of each service are provided in the following sections.</p><p>Furthermore, while we host UKP-SQUARE on our infrastructure and make it available for the community, we also provide the option to set up the system locally. Additionally, the Datastores and Models services are exposed via an API<ref type="foot" target="#foot_1">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Skills</head><p>Skills define how the user query should be processed by the Datastores and Models components and how the respective answers are obtained. For question answering, this might involve retrieving background knowledge, extracting spans from context or selecting an answer from multiple choices.</p><p>Skills are not necessarily equivalent to a model trained on a dataset. Instead a Skill is more general and can use multiple models to arrive at an output. A Skill might work on a specialized domain (e.g. biomedical, movies, etc.) or a specific format (e.g. extractive, abstractive, etc.), but also combinations are possible. For example, a Skill could combine Wikipedia and a news based extractive reader model to answer factoid and news questions. The degree of specialization or generalization of a Skill is up to its developer. In UKP-SQUARE the Skill only defines the pipeline, i.e., pre-processing, information retrieval or answer extraction/generation/classification. These steps are facilitated and executed by the usage of the other components: Models ( ?2.2) and Datastores ( ?2.3).</p><p>Importantly, Skills can be added to the system by the community. They can be added privately, thereby only giving a specific user access to it, or made public, allowing everyone to use it ( ?3.1). This allows great flexibility in the design of question answering pipelines, keeping implementation effort and required compute low, thereby democratizing the usage of question answering models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Models</head><p>The Models component is responsible for hosting NLP models required for document retrieval and answer extraction/generation tasks. Our platform supports a wide variety of models comprising HuggingFace (HF) Transformers <ref type="bibr" target="#b42">(Wolf et al., 2020)</ref>, Adapters, Sentence-Transformers <ref type="bibr" target="#b28">(Reimers and Gurevych, 2019)</ref>, and a limited selection of ONNX (Open Neural Network Exchange) <ref type="bibr" target="#b0">(Bai et al., 2019)</ref> models. Specifically, the inclusion of memory-efficient adapters in our platform allows having a variety of task-specific models while maintaining storage efficiency. Moreover, for faster inference, the high performance inference engine, ONNX Runtime<ref type="foot" target="#foot_2">6</ref> can be used for the ONNX mod-els provided on our platform.</p><p>The Models component comprises of two main services: inference and management. The inference service is responsible for loading models and getting predictions for the input queries. The management service allows the user to list, deploy, update and remove models (available on HF, Adapterhub and Sentence-Transformers) on the UKP-SQUARE platform. This allows to deploy and query models beyond the ones we already provide, for example multilingual models. To maintain a scalable architecture, we host every deployed model in its separate Docker container and use Traefik<ref type="foot" target="#foot_3">7</ref> to route the user query to the specific model instance for inference. The inference service of the model API can be queried using the Skills ( ?2.1) as per the end-user's requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Datastores</head><p>The Datastores are responsible for storing document collections as knowledge bases of QA Skills, supporting retrieval on these collections. Each Datastore contains a collection of documents and several indices of them for retrieval. The document collections are stored by an Elasticsearch<ref type="foot" target="#foot_4">8</ref> instance. Within one Datastore, the document collection is indexed by sparse or dense retrieval models.</p><p>For sparse retrieval, we use BM25 provided by the Elasticsearch instance; for dense retrieval, we use dual-encoder neural networks <ref type="bibr" target="#b14">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b43">Xiong et al., 2021)</ref> with Approximate Nearest Neighbor (ANN) indexing provided by Faiss <ref type="bibr" target="#b11">(Johnson et al., 2021)</ref>. The Datastores are agnostic to the ANN methods. Among them, we use IndexIVFScalarQuantizer <ref type="bibr" target="#b13">(J?gou et al., 2011)</ref> from Faiss as the default choice. For scalability, we maintain each dense-retrieval index within one Docker container and use Traefik to route the queries to the specific index. For each query using dense retrieval, the Datastores forward the query to the Models to get the query embedding (e.g., via the Query Embedder in Fig. <ref type="figure" target="#fig_2">2</ref> and Table <ref type="table" target="#tab_2">2</ref>) and then input this embedding to the ANN search for retrieving relevant documents.</p><p>As the built-in Datastores, Wikipedia<ref type="foot" target="#foot_5">9</ref> with the DPR encoder <ref type="bibr" target="#b14">(Karpukhin et al., 2020)</ref>, PubMed<ref type="foot" target="#foot_6">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimum Functionality Test (MFT)-Taxonomy</head><p>C: There is a tiny purple box in the room. Q: What size is the box? Test: Check if the prediction is tiny INVariance-Robustness C: ...Newcomen designs had a duty of about 7 million, but most were closer to 5 million.... Q: What was the ideal [duty-&gt;udty] of a Newcomen engine? Test: Check whether the prediction changes or not. and Bing web documents 11 with the TAS-B encoder <ref type="bibr" target="#b8">(Hofst?tter et al., 2021)</ref> are supported. We plan to add more Datastores in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Explainability</head><p>Recently, many interpretability techniques to understand black-box neural models such as influence functions and input/token attribution methods <ref type="bibr" target="#b21">(Madsen et al., 2021)</ref> have been introduced. Most of these techniques provide only local explanations and require access to the back-propagation function. One exception is CheckList (Ribeiro et al., 2020), which is a type of behavioural testing that treats models-in our case Skills-as black-boxes and compares their behaviour against the expected one. This is achieved by unit tests designed by the end-users or the system experts. Two most common test types are Minimum Functionality Test (MFT) and INVariance (INV) as shown in Table <ref type="table" target="#tab_0">1</ref>. MFTs are designed to measure a capability (e.g., Taxonomy capacity of matching object properties to categories) via specifying the expected behaviour (e.g., "tiny" in Table <ref type="table" target="#tab_0">1</ref>). INVs tests are similarly refined for capabilities (e.g., robustness under spelling errors in question), however the expected behaviour is already known, i.e., the answer should remain the same. We adapt the machine comprehension tests from Ribeiro et al. ( <ref type="formula">2020</ref>) for behavioural testing of our Skills. In our current setup, the tests for all the deployed Skills are curated manually, saved in as JSON file and made available via the UI. The test results are shown on demand via a separate tab ( ?3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">User Interface</head><p>We host UKP-SQUARE as a web application built with VueJS 12 to make it easily accessible to re-11 From the MS MARCO dataset <ref type="bibr" target="#b23">(Nguyen et al., 2016</ref>  <ref type="bibr" target="#b6">(Dua et al., 2019)</ref> Wikipedia DuoRC <ref type="bibr" target="#b34">(Saha et al., 2018)</ref> Movies Natural Questions <ref type="bibr" target="#b18">(Kwiatkowski et al., 2019)</ref> Wikipedia NewsQA <ref type="bibr" target="#b38">(Trischler et al., 2017)</ref> News Quoref <ref type="bibr" target="#b4">(Dasigi et al., 2019)</ref> Wikipedia SQuAD 1.1 <ref type="bibr" target="#b27">(Rajpurkar et al., 2016)</ref> Wikipedia SQuAD 2.0 <ref type="bibr" target="#b26">(Rajpurkar et al., 2018)</ref> Wikipedia TriviaQA <ref type="bibr" target="#b12">(Joshi et al., 2017)</ref> Wikipedia, Web</p><p>Text Classification (Multiple-Choice QA) BioASQ <ref type="bibr" target="#b39">(Tsatsaronis et al., 2015)</ref> Biomedical BoolQ <ref type="bibr" target="#b3">(Clark et al., 2019)</ref> Wikipedia CommonsenseQA <ref type="bibr" target="#b37">(Talmor et al., 2019)</ref> -CosmosQA <ref type="bibr" target="#b10">(Huang et al., 2019)</ref> Personal Narratives MultiRC <ref type="bibr" target="#b15">(Khashabi et al., 2018)</ref> Fiction, Textbook, Wikipedia, News, etc. Quail <ref type="bibr" target="#b33">(Rogers et al., 2020)</ref> Fiction, News, Blogs, User Stories Quartz <ref type="bibr" target="#b36">(Tafjord et al., 2019)</ref> Relationships RACE <ref type="bibr" target="#b19">(Lai et al., 2017)</ref> News, Stories, Ads, Biography, Philosophy SocialIQA <ref type="bibr" target="#b35">(Sap et al., 2019)</ref> Social Interactions</p><p>Query Embedder (Retrieval) Natural Questions <ref type="bibr" target="#b18">(Kwiatkowski et al., 2019)</ref> Wikipedia MS MARCO <ref type="bibr" target="#b23">(Nguyen et al., 2016)</ref> Bing Web Docs. searchers. Once a Skill has been created by a user ( ?3.1) it can be added, edited, and deleted in the Skill management section of the application in the "My Skills" menu. For each Skill, its URL, metadata, requirements for context, and visibility can be adjusted (see Appendix Fig. <ref type="figure" target="#fig_4">3</ref>). The functionality of the user interface is split into QA and explainability.</p><p>QA Interface. The QA section of the user interface provides access to the Skill by allowing the user to enter their question and optionally a context. Public Skills are accessible to everyone while private Skills require the user to be signed in.</p><p>The UI provides distinct visualizations depending on the selected Skill type. For extractive Skills, e.g., SQuAD <ref type="bibr" target="#b27">(Rajpurkar et al., 2016)</ref>, a document and multiple spans are returned and ranked by the model's confidence. In this setup, we also provide the option to show the span highlighted in its position in the document (see Fig. <ref type="figure" target="#fig_0">1</ref>). Categorical Skills, e.g., BoolQ <ref type="bibr" target="#b3">(Clark et al., 2019)</ref>, show an interface with boolean output scores (see Appendix Fig. <ref type="figure" target="#fig_6">5</ref>). A multiple-choice Skill requires multiple options separated by newlines in the context field. These are then ranked and returned with their respective scores (see Appendix Fig. <ref type="figure" target="#fig_7">6</ref>). When multiple Skills are selected, the user can see and compare their outputs side-by-side and better understand their behavioural differences.</p><p>Explainability Interface. A Skill selector is provided at the top which allows users to visualize and compare the results of the CheckList machine reading tests for the selected Skills. A list of tests with their name, type, capability, and failure rate is shown. The list can be expanded for a detailed description along with a small number of failed examples with their questions, context, and predictions.</p><p>3 Use Cases</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Skill Publishing</head><p>A major contribution of our platform is to support developers creating their own Skills. This allows practitioners to easily make their research publicly available, without having to take care of engineering heavy topics such as infrastructure, web development and security. To publish a new Skill, developers need to implement a single function that defines the question answering pipeline. They are provided with utility functions that facilitate interacting with other components such as the Datastores, Models and the UI. A code snippet implementing a Skill is given in Appendix A.</p><p>Allowing developers to implement their own Skills enables us to greatly extend the system to have stronger models. For instance, multiple Datastores with potentially different retrieval methods can be combined to find complementary background knowledge, e.g., from Wikipedia and biomedical articles. Similarly, different models could be used to precisely answer a diverse set of questions that might require different capabilities, such as answerability <ref type="bibr" target="#b26">(Rajpurkar et al., 2018)</ref>, numerical <ref type="bibr" target="#b6">(Dua et al., 2019)</ref> or multi-hop <ref type="bibr" target="#b44">(Yang et al., 2018)</ref> reasoning. Once a developer creates their Skill, it can be added to UKP-SQUARE via the UI. The Skill developer can further make the Skill publicly available.</p><p>Allowing the community to implement Skills comes with a technical challenge such as deploying unreliable code on our servers. We therefore allow three different ways of hosting Skills. (1) First, Skills can be hosted directly on UKP-SQUARE. For this, a pull request for the new Skill should be submitted to our public repository, which can then be added to the system upon a code review. While processing the submitted Skill requires a human in the loop, this option simplifies the hosting process for the Skill developer. (2) Second, in order to provide an option to make Skills instantly and independently available, we also allow Skills to be hosted on third party cloud platforms such as Amazon Web Services, Google Cloud and Microsoft Azure. All these cloud providers allow to easily host a lightweight function that can be used by UKP-SQUARE. (3) Lastly, we allow developers to host Skills on their own hardware. The only requirement is that the Skill needs to be publicly accessible. In the latter two cases, developers will still have access to UKP-SQUARE's components (e.g., Datastores and Models), but the Skill itself will run on the cloud or on other hardware. For quick development of Skills we recommend using options (2) and (3). For long-term availability and usage of a Skill, adding it via the public github repository is recommended. We provide extensive documentation for all possibilities to host Skills.<ref type="foot" target="#foot_7">13</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Skill Querying</head><p>Once a developer makes their Skill public in UKP-SQUARE, other users can obtain answers from it. Upon release of the system, we make a wide range of question answering Skills available. These span over different QA formats (extractive, multiplechoice, abstractive), setups (open-domain, machine reading comprehension) and to different domains <ref type="bibr">(wikipedia, web, biomedical, etc.)</ref>. The list of available models for different formats is given in Table <ref type="table" target="#tab_2">2</ref>. This allows the public to test current state-of-the-art question answering models. Moreover, researchers can use it for qualitative analysis, for example to discover potentials biases, strengths or weaknesses in models by behavioural testing. Furthermore, we support querying multiple Skills at the same time. This is particularly useful to compare capabilities of different models. For example see Fig. <ref type="figure" target="#fig_0">1</ref>, where two open domain, extractive Skills can be compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Behavioural Testing of Skills</head><p>The users can choose the Skill they want to investigate from the drop-down menu. The selected Skill can be analyzed standalone or alongside two different compatible Skills.</p><p>The tests are displayed showing the Skill fail- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">User Study</head><p>We evaluate the usability of our system by conducting a pilot attitudinal user study with five participants. We recruited graduate students, our main target user group, and instructed them to compare and analyze several Skills. We provided them with a list of predefined questions to input into the system to help them use it. After the students used the system we asked them several questions to discover whether they understood every element of the interface effortlessly (i.e., the input and the output of the Skills, the list of behavioral cards of the Skills, and their specific contents). All users understood the input and output of the Skills and stated that the interface allows them to compare the Skills effortlessly. They also stated that the behavioral cards of the explainability component are useful to analyze the strong and weak points of the models and could help develop new Skills. However, most of them could not understand them in a glimpse. Hence, we will improve the presentation of these cards in a future update. Appendix C provides the list of questions and responses. To finish the study, we employed the System Usability Scale (SUS) questionnaire <ref type="bibr" target="#b1">(Brooke, 1996)</ref> to quantitatively assess the global usability of the system. The average score is 70 out of 100, which refers to a "good usability" (UIUX-Trend, 2021).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>A qualitative comparison with similar frameworks is given in Table <ref type="table" target="#tab_3">3</ref>. The closest work to ours is Haystack, which is an open-source and scalable framework for building search systems over large document collections. Although it supports both sparse and dense retrieval techniques, models from the Huggingface (HF), and different QA types (abstractive and extractive) it lacks support for faster ONNX or memory efficient adapter models. Furthermore, it has to be set up by the users on their own infrastructure which requires technical expertise and sufficient hardware resources. <ref type="bibr" target="#b5">Dibia (2020)</ref> introduce NeuralQA, an interactive tool for QA that leverages the benefits of sparse retrieval along with the HF reader models. However, NeuralQA is limited to extractive QA. <ref type="bibr" target="#b14">Karpukhin et al. (2020)</ref> provide a simple user interface that employs efficient dense retrieval but only support models for opendomain QA. Finally, UnifiedQA <ref type="bibr" target="#b16">(Khashabi et al., 2020)</ref> provides a demo page<ref type="foot" target="#foot_8">14</ref> that employs a custom T5 based model trained on a wide range of QA datasets, hence supports a variety of QA formats. However, (1) it lacks the retrieval component, ( <ref type="formula">2</ref>) is not scalable (to include different model formats), and (3) is not flexible (not possible to use models with different retrieval techniques). Unlike other previous systems, UKP-SQUARE is dynamically extendable allowing users to easily contribute with new Skills. Finally, except from gradient-based explanations in <ref type="bibr" target="#b5">Dibia (2020)</ref>, none of the systems have an explainability component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We introduce the UKP-SQUARE platform that enables researchers and developers to study and compare QA pipelines, i.e., Skills, that comprises a selection of Datastores, retrieval mechanisms and reader models. The platform enables querying ex-isting public Skills, as well as implementing custom ones using UKP-SQUARE's microservices and utility functions that support a large collection of model types and Datastores. Furthermore, users can simultaneously query multiple Skills, and analyze them through integrated behavioural tests.</p><p>Our architecture is scalable and flexible to incorporate most of the latest developments in the QA domain. Future versions will include automated deployment of custom models and Datastores, automated Skill selection by incorporating previous works <ref type="bibr">(Puerto et al., 2021;</ref><ref type="bibr" target="#b7">Geigle et al., 2021)</ref> and increasing the number of supported Datastores (e.g., wikidata, <ref type="bibr" target="#b41">Vrande?i? and Kr?tzsch, 2014)</ref>. We also plan to incorporate specialized models (e.g., using graph encoders, <ref type="bibr" target="#b29">Ribeiro et al., 2021)</ref>, structured reasoning approaches <ref type="bibr" target="#b45">(Yasunaga et al., 2021)</ref> and interpretability techniques such as saliency maps <ref type="bibr" target="#b20">(Li et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics and Broader Impact Statement</head><p>Data This work does not generate new data. All datasets employed in used to construct Skills as described in ?2.2, ?2.3, and Table <ref type="table" target="#tab_2">2</ref>. The datasets are well-known to be safe for research purposes and do not contain any personal information or offensive content. We comply with the licenses and intended uses of each dataset. The licenses of each dataset can be seen in Appendix B.</p><p>Intended Use. The intended use of UKP-SQUARE is i) bringing different QA components together to share them as a skill with the rest of the world and ii) the analysis of these Skills. Our platform allows NLP practitioners to share their Skills with the community removing technical barriers such as configuration and infrastructure so that any person can reuse these models. In addition, users can analyze the available Skills through behavioral tests and compare them thanks to a user-friendly UI. This has a straightforward benefit for the research community (i.e., reproducible research and analysis of prior works), but also to the general public because UKP-SQUARE allows them to run state-of-the-art models without requiring them any special hardware and hiding complex settings such as virtual environments and package management.</p><p>Potential Misuse. Our platform makes use of Skills uploaded by the community. However, this current version does not incorporate any mechanism to ensure that these models are fair and with-out bias. Nonetheless, UKP-SQUARE includes a module for explainability that uses CheckLists <ref type="bibr" target="#b30">(Ribeiro et al., 2020)</ref> to analyze the strong and weak points of the Skills and to detect their biases and unfair content. Thus, we currently delegate the fairness checks to the authors of the models. We are not held responsible for errors, false, or offensive content generated by the Skills. Users should use them at their discretion.</p><p>Environmental Impact. Since UKP-SQUARE empowers the community to run publicly available Skills on the cloud, it has the potential to reduce CO 2 emissions from retraining previous models to make the comparisons needed when developing new models.</p><p>User Study. The participants are junior graduate students recruited on a voluntary basis. They are not part of this work, and never saw the user interface before the study. Before starting the study, they were given detailed instructions on the goals and scope of the study, and how the data was going to be used. Only non-personal data was recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Skill Implementation</head><p>The code below implements an open-domain, extractive QA Skill. First, a set of utility classes are loaded and initialized for facilitating interaction with UKP-SQUARE's Models and Datastore components (lines 1-5). Next, in the predict function, the Datastores are queried for retrieval. The Datastores component takes the user query, the datastore (Wikipeida snapshot from Natural Questions) and what index to use (dense, based on DPR) as input and returns the top documents. From these results, the document text and respective scores are extracted (lines 11-17). Subsequently, the query and the top documents are passed to an to the Models component for span extraction. In this implementation, a BERT base model with a adapter trained on SQuAD V2.0 is used (lines 21-30). Finally, the top answers are returned (lines 32-36). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Dataset Licences</head><p>Table <ref type="table" target="#tab_4">4</ref> shows the license of each dataset. In the case of RACE, the authors did not provide any license but specified that it can only be used for non-commercial research purposes. In the case of the other datasets without any specified license, the authors did not provide any license, but the datasets are freely available to download and use in a research context. BioASQ is available by Courtesy of the U.S. National Library of Medicine. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset License</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NarrativeQA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Questions of the User Study</head><p>Table <ref type="table">5</ref> contains the answers of the participants of the user study ( ?4) to each question we asked to evaluate their understanding of the interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>Avg. Ans.</p><p>SQuARE provides a user interface that allows me to tell the difference between both Skills 4.4</p><p>I understand in a glimpse each card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.6</head><p>I can get a quick overall view of the weak points of the skill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.8</head><p>The examples of each CheckList item are useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.4</head><p>Table <ref type="table">5</ref>: List of questions to understand the usefulness of the system. 1 represents "strongly disagree" and 5 represents "strongly agree."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D User Interface</head><p>UI screenshots for visualizing categorical and multiple choice Skill results are given in Fig. <ref type="figure" target="#fig_6">5</ref> and<ref type="figure" target="#fig_7">6</ref> respectively. In Fig. <ref type="figure" target="#fig_4">3</ref> the UI for managing a Skill is shown. Navigating through behavioural test results is given in Fig. <ref type="figure" target="#fig_5">4</ref>.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: QA page of UKP-SQUARE. The user selects a Skill (in this case, two open-domain Skills are selected), enters a question and then receives an answer.</figDesc><graphic url="image-2.png" coords="1,306.14,212.60,218.25,253.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall architecture of UKP-SQUARE, illustrating an open-domain, extractive QA Skill. (1) First a user selects a Skill and issues a query via the User Interface. (2) The selected QA Skill forwards the query to the respective Datastore for document retrieval. (3) The Datastore gets the query embedding from the Models, uses it for semantic document retrieval and returns the top documents to the Skill. (4) The Skill sends the query and retrieved documents to the reader model for answer extraction. (5) Finally, the answers are shown to the user. (6) Optionally, the user can view the results of the predefined behavioural tests for the Skill.</figDesc><graphic url="image-14.png" coords="2,244.20,120.88,108.59,112.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>19 #)</head><label>19</label><figDesc>d["document"]["text"] for d in data_api_output] 17 context_score = [d["score"] for d in data_api_output] 18 Answer extraction from the top document using the Model API 20 # using bert-base-uncased base model with SQuAD2.0 adapter 21 model_api_request = { 22 "input": [[request.query, c] for c in context], Listing 1: Example Implementation of an open-domain, span extraction Skill.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: User interface for managing a Skill.</figDesc><graphic url="image-23.png" coords="13,93.55,102.20,408.18,235.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: User interface for behavioural tests from CheckList.</figDesc><graphic url="image-24.png" coords="13,93.55,430.65,408.19,287.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: User interface for visualizing categorical Skill results.</figDesc><graphic url="image-25.png" coords="14,93.55,72.87,408.18,269.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: User interface for visualizing multiple choice Skill results.</figDesc><graphic url="image-26.png" coords="14,93.55,464.23,408.17,294.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples for two most common test types. Top: Minimum Functionality Test (MFT), Bottom: Invariance Test (INV). C: refers to context and Q: is the question.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Available Models fine-tuned on various datasets upon the release of UKP-SQUARE.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Qualitative comparison of UKP-SQUARE to previous works. HF: HuggingFace, Expl.: Explainability component, Ext.: Extensible by the end-user , EX: Extractive, AB: Abstractive, MC: Multiple-choice, YN: Yes/No ure rate and the failed examples can be viewed by clicking on the 'Expand' button. An examplary visualization for negation and coreference testing of SQuAD Skills is given in Appendix Fig. 4. For replacement tests, e.g., where names are perturbed, colored markers are used to highlight how the input was modified for the test. This allows the user to quickly identify changes the Skill could not handle. To analyze or process a Skill's test performance in more detail, a full JSON report of all test examples can be downloaded.</figDesc><table><row><cell></cell><cell>Supported Models</cell><cell>Retrieval</cell><cell>QA Types</cell><cell cols="2">Expl. Ext.</cell></row><row><cell>Haystack</cell><cell>HF Transformers</cell><cell cols="2">sparse, dense EX, AB</cell><cell>?</cell><cell>?</cell></row><row><cell>Dibia (2020)</cell><cell>HF Transformers</cell><cell>sparse</cell><cell>EX</cell><cell></cell><cell>?</cell></row><row><cell cols="2">Karpukhin et al. (2020) DPR</cell><cell>dense</cell><cell>EX</cell><cell>?</cell><cell>?</cell></row><row><cell>Khashabi et al. (2020)</cell><cell>T5</cell><cell>?</cell><cell cols="2">EX, AB, MC, YN ?</cell><cell>?</cell></row><row><cell>UKP-SQUARE</cell><cell cols="3">HF Transformers, ONNX, adapters sparse, dense EX, AB, MC, YN</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>License of each dataset.</figDesc><table><row><cell></cell><cell>Apache 2.0</cell></row><row><cell>BioASQ</cell><cell>National Library of</cell></row><row><cell></cell><cell>Medicine Terms and</cell></row><row><cell></cell><cell>Conditions</cell></row><row><cell>DROP</cell><cell>CC BY-SA 4.0</cell></row><row><cell>DuoRC</cell><cell>MIT</cell></row><row><cell cols="2">Natural Questions MIT</cell></row><row><cell>NewsQA</cell><cell>MIT</cell></row><row><cell>Quoref</cell><cell>CC BY 4.0</cell></row><row><cell>SQuAD 1.1</cell><cell>CC BY-SA 4.0</cell></row><row><cell>SQuAD 2.0</cell><cell>CC BY-SA 4.0</cell></row><row><cell>TriviaQA</cell><cell>Apache 2.0</cell></row><row><cell>BoolQ</cell><cell>CC BY-SA 3.0</cell></row><row><cell cols="2">CommonSenseQA NA</cell></row><row><cell>CosmosQA</cell><cell>NA</cell></row><row><cell>MultiRC</cell><cell>NA</cell></row><row><cell>Quail</cell><cell>NA</cell></row><row><cell>Quartz</cell><cell>NA</cell></row><row><cell>RACE</cell><cell>NA</cell></row><row><cell>SocialIQA</cell><cell>NA</cell></row><row><cell>MS MARCO</cell><cell>CC BY 4.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The code is available on https://github.com/ UKP-SQuARE/square-core</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>https://square.ukp-lab.de/docs/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>https://github.com/microsoft/ onnxruntime</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>https://traefik.io</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p>https://elastic.co</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p>The English Wikipedia dump preprocessed by<ref type="bibr" target="#b14">Karpukhin et al. (2020)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6"><p>From the BioASQ8 edition<ref type="bibr" target="#b22">(Nentidis et al., 2020)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_7"><p>https://square.ukp-lab.de/docs/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_8"><p>https://unifiedqa.apps.allenai.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Jan-Christoph Klie</rs> for his insightful feedback and suggestions on a draft of the paper and the project. We thank <rs type="person">Richard Eckart de Castilho</rs> for advice on the general infrastructure and <rs type="person">Nandan Thakur</rs> and <rs type="person">Hossain Shaikh Saadi</rs> for their preliminary work on the project. We also thank <rs type="person">Serkan Bayraktaroglu</rs> for designing our logo.</p><p>This work has been funded by the <rs type="funder">German Research Foundation (DFG)</rs> as part of the <rs type="institution">UKP-SQuARE</rs> and <rs type="projectName">QASciInf</rs> project (grant <rs type="grantNumber">GU 798/29-1</rs> and <rs type="grantNumber">GU 798/18-3</rs>) and within the project "<rs type="projectName">Open Argument Mining</rs>" (<rs type="grantNumber">GU 798/25-1</rs>), associated with the <rs type="programName">Priority Program</rs> "<rs type="projectName">Robust Argumentation Machines (RATIO)</rs>" (<rs type="grantNumber">SPP-1999</rs>) and by the <rs type="programName">DFGfunded research training group "Adaptive Preparation of Information form Heterogeneous Sources</rs>" (AIPHES, <rs type="grantNumber">GRK 1994/1</rs>). Further by the <rs type="funder">European Regional Development Fund (ERDF)</rs> and the <rs type="funder">Hessian State Chancellery -Hessian Minister of Digital Strategy and Development</rs> under the promotional reference 20005482 (TexPrax), and by the <rs type="funder">LOEWE initiative (Hesse, Germany)</rs> within the emergenCITY center.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ZwscgPW">
					<idno type="grant-number">GU 798/29-1</idno>
					<orgName type="project" subtype="full">QASciInf</orgName>
				</org>
				<org type="funded-project" xml:id="_REcz2jC">
					<idno type="grant-number">GU 798/18-3</idno>
					<orgName type="project" subtype="full">Open Argument Mining</orgName>
				</org>
				<org type="funded-project" xml:id="_cUBWJKk">
					<idno type="grant-number">GU 798/25-1</idno>
					<orgName type="project" subtype="full">Robust Argumentation Machines (RATIO)</orgName>
					<orgName type="program" subtype="full">Priority Program</orgName>
				</org>
				<org type="funding" xml:id="_ae3AVep">
					<idno type="grant-number">SPP-1999</idno>
					<orgName type="program" subtype="full">DFGfunded research training group &quot;Adaptive Preparation of Information form Heterogeneous Sources</orgName>
				</org>
				<org type="funding" xml:id="_gDPfm7Q">
					<idno type="grant-number">GRK 1994/1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://github.com/onnx/onnx" />
		<title level="m">Onnx: Open neural network exchange</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Sus-a quick and dirty usability scale. Usability evaluation in industry</title>
		<author>
			<persName><forename type="first">John</forename><surname>Brooke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page">189</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BoolQ: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1300</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Minneapolis, Minnesota. Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2924" to="2936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quoref: A reading comprehension dataset with questions requiring coreferential reasoning</title>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Marasovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1606</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5925" to="5932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">NeuralQA: A usable library for question answering (contextual query expansion + BERT) on large datasets</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Dibia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1246</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Minneapolis, Minnesota. Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2368" to="2378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">TWEAC: transformer with extendable QA agent classifiers</title>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Geigle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno>CoRR, abs/2104.07081</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficiently teaching an effective dense retriever with balanced topic aware sampling</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Hofst?tter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3462891</idno>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event</title>
		<meeting><address><addrLine>Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-07-11">2021. July 11-15, 2021</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for NLP</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruna</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cosmos QA: Machine reading comprehension with contextual commonsense reasoning</title>
		<author>
			<persName><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1243</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2391" to="2401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2019.2921572</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver, Canada. Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName><forename type="first">Herve</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2010.57</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1023</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="252" to="262" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">UNIFIEDQA: Crossing format boundaries with a single QA system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.171</idno>
	</analytic>
	<monogr>
		<title level="m">Find-ings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1896" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The narrativeqa reading comprehension challenge</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RACE: Large-scale ReAding comprehension dataset from examinations</title>
		<author>
			<persName><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualizing and understanding neural models in NLP</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n16-1082</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12">2016. June 12-17, 2016</date>
			<biblScope unit="page" from="681" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<idno>arXiv, abs/2108.04840</idno>
		<title level="m">Post-hoc interpretability for neural NLP: A survey</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Overview of bioasq 2020: The eighth bioasq challenge on large-scale biomedical semantic indexing and question answering</title>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Nentidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Bougiatiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Rodr?guez Penagos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58219-7_16</idno>
	</analytic>
	<monogr>
		<title level="m">Experimental IR Meets Multilinguality, Multimodality, and Interaction -11th International Conference of the CLEF Association, CLEF 2020</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-09-22">2020. September 22-25, 2020</date>
			<biblScope unit="page" from="194" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Computation, NIPS</title>
		<meeting>the Workshop on Cognitive Computation, NIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">AdapterHub: A framework for adapting transformers</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>R?ckl?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifton</forename><surname>Poth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aishwarya</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vuli?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">G?zde G?l Sahin, and Iryna Gurevych. 2021. Metaqa: Combining expert agents for multiskill question answering</title>
		<author>
			<persName><forename type="first">Haritz</forename><surname>Puerto</surname></persName>
		</author>
		<idno>arXiv, abs/2112.01922</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2124</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Structural adapters in pretrained language models for AMR-to-Text generation</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Leonardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.351</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4269" to="4282" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with checklist</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>T?lio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.442</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online</meeting>
		<imprint>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Okapi at TREC-3</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Third Text REtrieval Conference</title>
		<meeting>The Third Text REtrieval Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-11-02">1994. 1994. November 2-4, 1994</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="109" to="126" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST)</orgName>
		</respStmt>
	</monogr>
	<note>TREC</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<idno>arXiv, abs/2107.12708</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Getting closer to ai complete question answering: A set of prerequisite real tasks</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Kovaleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6398</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8722" to="8731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">DuoRC: Towards complex language understanding with paraphrased reading comprehension</title>
		<author>
			<persName><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Aralikatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1156</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1683" to="1693" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Social IQa: Commonsense reasoning about social interactions</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4463" to="4473" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">QuaRTz: An open-domain dataset of qualitative relationship questions</title>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1608</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5941" to="5946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1421</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2623</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergios</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Arti?res</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liliana</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
	</analytic>
	<monogr>
		<title level="m">Ion Androutsopoulos, and Georgios Paliouras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">138</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Measuring and interpreting system usability scale</title>
		<author>
			<persName><surname>Uiux-Trend</surname></persName>
		</author>
		<ptr target="https://uiuxtrend.com/measuring-system-usability-scale-sus" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2022" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Wikidata: A free collaborative knowledgebase</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Vrande?i?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Kr?tzsch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2629489</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">HotpotQA: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1259</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">QA-GNN: Reasoning with language models and knowledge graphs for question answering</title>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.45</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="535" to="546" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
