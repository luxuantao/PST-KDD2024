<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A comprehensive survey of anomaly detection techniques for high dimensional big data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Srikanth</forename><surname>Thudumu</surname></persName>
							<email>sthudumu@swin.edu.au</email>
							<idno type="ORCID">0000-0002-7848-9008</idno>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><surname>Branch</surname></persName>
							<idno type="ORCID">0000-0002-7848-9008</idno>
						</author>
						<author>
							<persName><forename type="first">Jiong</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jack</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<affiliation>
								<orgName>1 School of Software &amp; Electrical Engineering, Swinburne University of Technology, </orgName>
								<address><addrLine>Hawthorn, VIC 3122, Australia Hawthorn, VIC 3122, Australia. Sarawak, Malaysia.</addrLine></address>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> 1 School of Software &amp; Electrical Engineering, Swinburne University of Technology, </orgName>
							</affiliation>
						</author>
						<author>
							<affiliation>
								<orgName> 2 Sarawak State Government,</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A comprehensive survey of anomaly detection techniques for high dimensional big data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C0924CB7A50AAF6CD2F23E746DD2CF3</idno>
					<idno type="DOI">10.1186/s40537-020-00320-x</idno>
					<note type="submission">Received: 21 February 2020 Accepted: 21 June 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Anomaly detection</term>
					<term>Big data</term>
					<term>Big dimensionality</term>
					<term>Big dimensionality tools</term>
					<term>High dimensionality</term>
					<term>The curse of big dimensionality</term>
					<term>The curse of dimensionality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Many data sets continuously stream from weblogs, financial transactions, health records, and surveillance logs, as well as from business, telecommunication, and biosciences <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Referred to as "big data, " a term that describes the large and distributed nature of the data sets, this area has recently become a focus of scholarship. Gartner [3] defines big data as high-volume, high-velocity, and high-variety data sets that demand cost-effective novel data analytics for decision-making and to infer useful insights. In recent years, the core challenges of big data have been widely established. These are contained within the five Vs of big data-value, veracity, variety, velocity, and volume [4]-as shown in Fig. <ref type="figure">1</ref>.</p><p>Value refers to the benefits associated with the analysis of data; veracity refers to the accuracy of the data; and variety refers to the many types of data, such as structured,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>semi-structured, or unstructured. Volume is the amount of data that is being accumulated (i.e., the size of the data)-the larger the dimensionality of the data, the larger the volume. Dimensionality refers to the number of features or attributes or variables within the data available for analysis. By contrast, velocity refers to the "speed" at which the data are generated and may contain many dimensions. These elements of the current definition of big data address basic challenges. However, such a definition ignores another important aspect: "dimensionality, " which plays a crucial role in realworld data analysis <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. The increase in dimensions or features or attributes poses significant challenges for anomaly detection in large data sets.</p><p>Anomaly detection aims to detect abnormal patterns deviating from the rest of the data, called anomalies or outliers. High dimensionality creates difficulties for anomaly detection because, when the number of attributes or features increase, the amount of data needed to generalize accurately also grows, resulting in data sparsity in which data points are more scattered and isolated. This data sparsity is due to unnecessary variables, or the high noise level of multiple irrelevant attributes, that conceal the true anomalies. This issue is widely acknowledged as the "curse of dimensionality" <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. It is an obstacle for many anomaly detection techniques addressing high dimensionality that fail to retain the effectiveness of conventional approaches, such as distancebased, density-based, and clustering-based techniques <ref type="bibr" target="#b7">[8]</ref>.</p><p>This survey aims to document the state of anomaly detection in high dimensional big data by identifying the unique challenges using a triangular representation of vertices: the problem (big dimensionality), techniques/algorithms (anomaly detection), and tools (big data applications/frameworks). Authors' work that falls directly into any of the vertices or closely related to them are taken into consideration for review (see Fig. <ref type="figure" target="#fig_0">2</ref>). Furthermore, the limitations of traditional approaches and current strategies of high dimensional data are discussed along with the recent techniques and applications on big data required for the optimization of anomaly detection. Hence, the contributions of this survey are threefold: Fig. <ref type="figure">1</ref> The high dimensionality problem in big data 1. Review existing literature to highlight the theoretical background and current strategies for managing the big dimensionality problem. 2. Identify unique challenges and review the techniques/algorithms of anomaly detection that address the problems of high dimensionality and big data. 3. Review the big data tools, applications and frameworks for anomaly detection in high dimensional big data.</p><p>This paper highlights techniques concerning anomaly detection as well as covering other closely related machine learning fields, such as pattern recognition, outlier detection, spam detection, suspicious detection, fraud detection, deep learning and novelty recognition. The rest of the paper is structured as follows. "Related work and scope" section provides an overview of differences between this survey and existing surveys. "Anomaly detection in big data" section presents the introduction of big dimensionality problem in anomaly detection. "The high dimensionality problem" section presents the theoretical background including visualization and the curse of dimensionality, and discusses the challenges of traditional models dealing with high dimensionality in anomaly detection. "Strategies for tackling the problem of high dimensionality" section provides strategies to tackle the high dimensionality problem, such as dimensionality reduction methods to ascertain the benefit of one approach over another. "Unique challenges brought by anomaly detection in high-dimensional big data" section provides a taxonomy of big data anomaly detection problems with regard to high dimensionality in the form of a survey of closely related work. "Tools in high dimensional big data" section provides the review of big data tools and frameworks handling big dimensional data. The final section concludes the survey and considers the direction of future research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work and scope</head><p>Anomaly detection in high-dimensional data is becoming a fundamental research area that has various applications in the real world. As such, a large body of research has been devoted towards addressing this problem. Nevertheless, most existing surveys focus on the individual aspects of anomaly detection or high dimensionality. For example, Agrawal and Agrawal <ref type="bibr" target="#b8">[9]</ref> provide a review of various anomaly detection techniques, with the aim of presenting a basic insight into various approaches for anomaly detection. Akoglu et al. <ref type="bibr" target="#b9">[10]</ref> present several real-world applications of graph-based anomaly detection and concluded with open challenges in the field. Chandola et al. <ref type="bibr" target="#b10">[11]</ref> present a survey of several anomaly detection techniques for various applications. Hodge and Austin <ref type="bibr" target="#b6">[7]</ref> present a survey of outlier detection techniques by comparing techniques' advantages and disadvantages. Patcha and Park <ref type="bibr" target="#b11">[12]</ref> have conducted a comprehensive survey of anomaly detection systems and hybrid intrusion detection systems by identifying open problems and challenges. Jiang et al. <ref type="bibr" target="#b12">[13]</ref> present a survey of advanced techniques in detecting suspicious behaviour; they also present detection scenarios for various real-world situations. Sorzano et al. <ref type="bibr" target="#b13">[14]</ref> categorize dimensionality reduction techniques, along with the underpinning mathematical insights. Various other surveys can also be observed, such as those by Gama et al. <ref type="bibr" target="#b14">[15]</ref>, Gupta et al. <ref type="bibr" target="#b15">[16]</ref>, Heydari et al. <ref type="bibr" target="#b16">[17]</ref>, and Jindal and Liu <ref type="bibr" target="#b17">[18]</ref>, Pathasarathy <ref type="bibr" target="#b18">[19]</ref>, Phua et al. <ref type="bibr" target="#b19">[20]</ref>, Tamboli et al. <ref type="bibr" target="#b20">[21]</ref>, and Spirin et al. <ref type="bibr" target="#b21">[22]</ref>, which further highlight the problems either in anomaly detection or in high-dimensional data.</p><p>A limited amount of work has been done that emphasizes anomaly detection and high dimensionality problems together, either directly or indirectly. Zimek et al. <ref type="bibr" target="#b22">[23]</ref> present a detailed survey of specialized algorithms for anomaly detection in highdimensional numerical data; they also highlight important aspects of the curse of dimensionality. Parsons et al. <ref type="bibr" target="#b23">[24]</ref> present a survey of the various subspace clustering algorithms for high-dimensional data and discuss some potential applications in which the algorithms can be used.</p><p>To the best of the authors' knowledge, no surveys directly highlight the problems of anomaly detection and high dimensionality in big data. In this survey, we present an integrated overview of these two problems from the perspective of big data. Table <ref type="table" target="#tab_0">1</ref> summarises the differences between this survey and other related works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anomaly detection in big data</head><p>Anomaly detection is an important technique for recognizing fraud activities, suspicious activities, network intrusion, and other abnormal events that may have great significance but are difficult to detect <ref type="bibr" target="#b24">[25]</ref>. The significance of anomaly detection is that the process translates data into critical actionable information and indicates useful insights in a variety of application domains <ref type="bibr" target="#b10">[11]</ref>. For example, cancer treatment plans need to be formulated based on the readings from an Intensity-modulated Radiation Therapy (IMRT) machine <ref type="bibr" target="#b25">[26]</ref>; locating anomalies is critical before recommending the amount of radiation for a patient. Even if part of the treatment is based on anomaly detection, the accuracy of the data plays a crucial role and may have negative consequences if the data are analyzed ineffectively. As mentioned earlier, Chandola et al. <ref type="bibr" target="#b10">[11]</ref> provided a survey, taxonomy, and analysis of several anomaly detection techniques for various applications, such as manufacturing defects, sensor networks, intrusion detection, and finding abnormal behavior of the data. Most of the applications were important for high dimensional data sets that contained thousands or even millions of attributes. The traditional techniques that detect anomalies in high-dimensional space are complicated, as anomalies are rare and generally appear in fractional views of subsets of dimensions or subspaces <ref type="bibr" target="#b26">[27]</ref>. It has also been suggested by Aggarwal <ref type="bibr" target="#b27">[28]</ref> that almost any anomaly detection algorithm based on the concept of proximity degrades qualitatively in high-dimensional space; therefore, redefinition of the algorithm is necessary. Furthermore, traditional methods become less meaningful with increasing dimensionality, as they use strategies that make certain assumptions about the comparatively low dimensionality of the data <ref type="bibr" target="#b28">[29]</ref>. Moreover, it is possible that only a fraction of data points are informative for data sets with high dimensionality <ref type="bibr" target="#b27">[28]</ref>.</p><p>Anomaly detection that addresses problems of high dimensionality can be applied in either online or offline modes. In an offline mode, anomalies are detected in historical data sets known as "batch processing. " This relates to the "volume" feature of big data. By contrast, in online mode, new data points, known as "data streams, " are continually introduced while anomalies are being detected. This relates to the "velocity" feature of big data. A number of existing surveys and reviews highlight the problem of high dimensionality for various fields, such as machine learning and data mining. The "size" aspect of the volume <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref> and "speed" aspect of the velocity <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> are frequently addressed in the literature; however, the "dimension" aspect remains largely ignored. Zhai et al. <ref type="bibr" target="#b3">[4]</ref> termed this gap "big dimensionality" and we attempt to review the techniques that are related to big dimensionality problem. However, to derive the unique challenges brought by anomaly detection in big dimensionality and to understand the core problem hindering the performance and accuracy of the available techniques, the theoretical background and current strategies are presented in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The high dimensionality problem</head><p>High dimensionality refers to data sets that have a large number of independent variables, components, features, or attributes within the data available for analysis <ref type="bibr" target="#b40">[41]</ref>. The complexity of the data analysis increases with respect to the number of dimensions, requiring more sophisticated methods to process the data. Data sets are growing in terms of sample size n but even more in terms of dimension m. At the same time, in the era of big data, m is commonly misconstrued as high-dimensional, since thousands of dimensions are very common. If a data set has n samples and m dimensions (or features), then the data can be referred to as m-dimensional. In general, a data set can be called high dimensional when the number of dimensions m causes the effect of 'curse of dimensionality' .</p><p>One of the main sources of high-dimensional data sets are organizations with huge transactions and associated databases. Furthermore, it is common to have multiple dimensions in many application areas such as data mining and machine learning <ref type="bibr" target="#b41">[42]</ref>. The advent of cloud-based storage enables organizations to store massive amounts of detailed information easily. A financial organization may monitor its stock price every minute, every hour, or every day, and the stock price may be predicted with linear combinations of thousands of underlying traded portfolios, each of which is a dimension. The other sources might be science or biology related; for example, healthcare data are known for having multiple dimensions, such as treatment plans, radiation therapy, and genetic background. The major difference between these examples (i.e., business and healthcare data) is the number of samples. The number of variables or components can be similar for each (in the thousands); however, the business data set can have millions of records, whereas the health data will rarely involve more than a few thousand samples. A sophisticated approach handles the number of increasing dimensions without affecting accuracy in either situation. High-dimensional data is often referred to as multi-dimensional or multi-aspect or multi-modal data throughout the literature <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. Highly detailed data from diverse platforms such as the web, social media is typically high-dimensional in nature. A generalised term for multi-dimensional data structure, along with arithmetic operations viability can be referred to as a tensor and appears frequently in many web-related applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization in high-dimensional data</head><p>Visualization is the graphic representation of data that aims to convert data to a qualitative understanding that supports effective visual analysis. The visualization of a multidimensional dataset is challenging, and numerous research efforts have focused on addressing the increasing dimensionality <ref type="bibr" target="#b44">[45]</ref>. The scatter plot matrix is a straightforward technique that employs pairwise scatterplots as matrix elements to represent multidimensional datasets; however, a loss of significant detail limits this technique to two-variable projection. Parallel coordinate plots (PCPs) <ref type="bibr" target="#b45">[46]</ref> are proposed as a multivariate visualization technique that overcomes the scatter plot's two-variable limit; it does this by mapping data points of a multidimensional space to a two-dimensional plane by laying the features as parallel vertical axes at a uniform spacing <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Dimensionality reduction that converts a large set of input features into a smaller set of target features is a common method of addressing the issue. It is categorized into "distance" and "neighborhood" preserving methods. The former aims to minimize cost (so-called "aggregated normalized stress"), while the latter maximizes the overlap between the nearest neighborhoods and identifies the patterns <ref type="bibr" target="#b48">[49]</ref>. Techniques such as principal component analysis (PCA) <ref type="bibr" target="#b49">[50]</ref> and multi dimensional scaling (MDS) <ref type="bibr" target="#b50">[51]</ref> are based on dimensionality reduction and aim to preserve as much significant information as possible in the target low-dimensional mapping. PCA is discussed in "Strategies for tackling the problem of high dimensionality" section in detail, MDS is a method for constructing similarity (or dissimilarity) among pairs of generally highdimensional data as distances among points into a target low-dimensional space. The standard distances used are Euclidean and cosine, and the algorithm input is an m × m distance matrix between all paired observations. The advantage of MDS is that it does not require original dimensions; it can generate an output (i.e., a point pattern) by computing a dissimilarity matrix among observations. Conversely, the disadvantage is that it requires analysis and storing of the m × m distance matrix, making the method computationally expensive when m increases <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b51">52]</ref>. The Fastmap algorithm that projects the instance space in the directions of the maximum variability by calculating the dissimilarities is significantly faster than MDS <ref type="bibr" target="#b52">[53]</ref>. Various other methods have been proposed, such as ISOMAP, Landmarks MDS, and Pivot MDS <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>, which can compute the projections in linear time to the number of observations. In other cases, in which the number of dimensions is very high, the distances between paired observations appears similar and, as such, preserving such distances accurately is ineffective. Instead, preserving the neighborhoods in a projection is advantageous and effective in reasoning the patterns (anomalies) in the high-dimensional data <ref type="bibr" target="#b51">[52]</ref>. A most effective technique used in this case is t-stochastic neighbor embedding (t-SNE), which is widely employed in many fields, such as pattern recognition, machine learning, and data mining. t-SNE is designed to capture most of the local structure in the high-dimensional data while simultaneously detailing the global structure, such as number of available clusters <ref type="bibr" target="#b55">[56]</ref>. However, when the projection of dimensionality reduction fails, it is impossible to visualize the data in detail and it can only be comprehended mathematically <ref type="bibr" target="#b56">[57]</ref>. For example, a linear separator in twodimensional space is a line: However, a linear separator in three-dimensional space is a plane: A linear separator in a high-dimensional space can be mathematically represented as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The curse of dimensionality</head><p>The term "curse of dimensionality" was first introduced by Bellman <ref type="bibr" target="#b57">[58]</ref> to describe the problem caused by a rise in the number of dimensions or input variables. When the dimensionality of data increases, data size increases proportionally, leading to data sparsity, and sparse data is difficult to analyze. The curse of dimensionality affects anomaly detection techniques because the level of abnormal nature with respect to the increasing dimensions can be obscured or even concealed by unnecessary attributes <ref type="bibr" target="#b26">[27]</ref>. Since outliers are defined as data instances in sparse regions, an inadequate discriminative region is observed in almost equally sparse locations of high-dimensional space <ref type="bibr" target="#b27">[28]</ref>.</p><p>(1)</p><formula xml:id="formula_0">ax 1 + bx 2 = d (2) ax 1 + bx 2 + cx 3 = d (3) ∞ i=1 x i = d</formula><p>The increase in dimensions makes data points scattered and isolated, and makes it elusive to find the global optima of the data set. The more dimensions that are added to a data set, the more complex it becomes, as each added dimension brings about a substantial number of false positives <ref type="bibr" target="#b41">[42]</ref>. Figure <ref type="figure">3</ref> illustrates the sparsity of the data when projected in one, two, and three dimensions. The curse of dimensionality refers to a number of occurrences that emerge when analyzing and organizing data in high-dimensional spaces. The very nature of these occurrences is that, whenever there is an increase in dimensionality, the volume of the space increases proportionally, such that all other data points become sparse. This sparsity is challenging for any technique that requires statistical value. Further, it produces numerous complications associated with other noise levels, which may be irrelevant features or unnecessary attributes, that could complicate or even conceal the data instances <ref type="bibr" target="#b28">[29]</ref>. This is the main reason why many algorithms struggle with high-dimensional data. As the number of dimensions increases, statistical approaches such as distance measures become less useful, since the points become almost equidistant from each other, due to the curse of dimensionality.</p><p>High-dimensional data requires significant computational memory and brings a huge computational burden. For high-dimensional data, recognizing useful insights or patterns becomes complex and challenging. The simplest approach to handle high dimensionality problem is to minimize the features and can be better understood by studying either the intrinsic or embedding dimensionality of data sets. It is essential to understand the subtle difference between intrinsic and embedding dimensionality. Intrinsic dimensionality is the smallest variety of the features that cover the full representation of the data; embedding dimensionality is the representation of the number of features or columns of the whole data space. Moreover, it is also important to understand how statistical models tackle the problem of high dimensionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Traditional models addressing the high dimensionality problem</head><p>High-dimensional data have special challenges in data mining in general and anomaly detection in particular <ref type="bibr" target="#b22">[23]</ref>. Anomaly detection is difficult for data sets with increasing dimensionality and poses serious issues for many traditional data mining techniques. The problems emerging from the curse of dimensionality are not just specific to anomaly detection; they are also applicable to many other data mining techniques. Statistical Fig. <ref type="figure">3</ref> The effect of the curse of dimensionality when projected in (1) one dimension, (2) two dimensions, and (3) three dimensions models use various methods, such as proximity-based, cluster-based, distance-based, density-based, and classification-based, to tackle the dimensionality problem. However, these methods bring greater computational complexity as the number of dimensions increases, the data instances are scattered and become less dense, affecting data distribution <ref type="bibr" target="#b6">[7]</ref>. It is widely known that numerous issues, such as clustering and similarity of search experience, emerge with the increasing range of dimensions. Zimek et al. <ref type="bibr" target="#b22">[23]</ref> discussed important aspects of the curse of dimensionality in their study of specialized techniques for anomaly identification. They highlighted common issues related to high-dimensional data and examined the difficulties in anomaly detection. They have concluded that more research is needed to tackle the problem of high dimensionality in anomaly detection. Some of the traditional models that address this problem are discussed below.</p><p>Many algorithms build on concepts of proximity to find anomalies that are based on relationships between data points. However, such algorithms suffer from huge computational growth in high-dimensional space and, consequently, fail to retain their effectiveness. This is because computational complexity of the algorithm is directly proportional to both the increased dimensionality of the data m and the number of samples n. The data distribution model interprets sparsity in a completely different way; it implies that every data instance is equidistant to others, which makes it difficult to differentiate close and distant pairs of data instances. The increase in dimensionality scatters the spread of data instances, making them less dense. It has been suggested by Aggarwal <ref type="bibr" target="#b27">[28]</ref> that almost any technique that is primarily based on the concept of proximity would degrade qualitatively in high-dimensional space, and would, therefore, need to be redefined in a more meaningful way. Proximity-based techniques, which involve defining a data instance as a point of reference when its locality or proximity is sparsely distributed, are simple to implement. The locality can be defined in various ways, such as cluster-based, distance-based, and density-based, and no prior assumptions about the data distribution model are made. The difference between various proximity techniques lies in how the locality or proximity is defined.</p><p>When the data become sparse and methods based on the concept of proximity fail to maintain their viability, interpreting the data becomes difficult. This is because the sparsity of high-dimensional data can be comprehended in several ways that suggest that every data instance is an equally good anomaly with regard to the definition of a distance-based algorithm. Aggarwal and Yu <ref type="bibr" target="#b7">[8]</ref> developed a method for outlier detection based on an understanding of the nature of projections. The method focused on lower dimensional projections that are locally sparse and cannot be recognized easily by brute-force techniques due to various possible combinations. They developed the method using a naive brute-force algorithm, which is very slow at identifying the meaningful insights because of its exhaustive search of the entire space, and another faster evolutionary algorithm to quickly discover underpinning patterns of dimensions. Due to the exponentially increasing search space, the brute-force technique is computationally weak for problems of even modest complexity. However, the technique has advantages over simple distance-based outliers that cannot overcome the effects of the curse of dimensionality. Other related studies that address the high dimensionality problem in anomaly detection are discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distance-based techniques</head><p>As mentioned in the above section, distances between pairs of data instances are similar for a wide variety of data distributions and distance functions in high-dimensional space <ref type="bibr" target="#b58">[59]</ref>. Distance concentration is one of the problems associated with sparsity and is related to the hubness phenomenon. Hubness is the tendency of some data instances to occur more frequently than others within the data set. It is dependent on feature representation, normalization, and similarity. Hence, hubs can sometime be interpreted as noise effects. Angiulli and Pizzuti <ref type="bibr" target="#b29">[30]</ref> proposed a distance-based anomaly detection technique called "HilOut" to detect the top n outliers of large and high-dimensional data sets. HilOut uses the notion of the space-filling curve to linearize the data set; it provides an approximate solution before calculating the exact solution by examining the candidate outliers that remain after the first phase. Angiulli and Pizzuti presented both inmemory and disk-based versions of the their proposed HilOut algorithm, as well as a thorough analysis of the method, which scaled well.</p><p>One of the more effective ways to handle sparse data in high-dimensional space is to employ functions based on dissimilarities of the datapoints. An assessment of small portions of the larger data set could help to identify anomalies that would otherwise be obscured by other anomalies if one were to examine the entire data set as a whole. Measuring the similarity of one data instance to other within a data set is a critical part of lowdimensional anomaly detection procedures. This is because an uncommon data point possesses insufficient data instances that are alike in the data set. Several anomaly detection methods practice Manhattan or Euclidian distance to estimate similarity among data instances <ref type="bibr" target="#b34">[35]</ref>; however, when Euclidian distance is used to measure the similarity, the results are often treated as meaningless due to the unwanted nearest neighbors from multiple dimensions. This is due to the distance between two similar data instances and the distance between two non-similar data instances can be almost equal; hence, methods such as k-nearest neighbor with O(n 2 m ) runtime are not viable for high dimen- sionality data sets unless the runtime is improved. Nevertheless, Euclidean distance is the most common distance metric used to calculate the similarity of low-dimensional data sets. Though Euclidean distance is suitable for low-dimensional data sets, it does not work as effectively in high-dimensional data <ref type="bibr" target="#b59">[60]</ref>.</p><p>To address the issue, Koufakou and Georgiopoulos <ref type="bibr" target="#b60">[61]</ref> proposed an anomaly detection strategy where the speedup is achieved by its distributed version which is very close to linear. They called the approach as "fast distributed" and intended for mixed-attribute data sets that deal with sparse high-dimensional data. Their method, which takes the sparseness of the data set into consideration, is extremely scalable, as it has several points and many attributes in the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering-based techniques</head><p>Clustering is an important technique of data analysis. Ertoz et al. <ref type="bibr" target="#b62">[63]</ref> introduced a shared nearest neighbor clustering algorithm to identify clusters of fluctuating shapes, sizes, and densities, along with the anomalies. Their method, which deals with multidimensionality and changing densities, automatically calculates the number of clusters. Initially, the algorithm recognizes the nearest neighbors of each data instance; it then redefines the similarity among pairs of data instances in terms of the number of nearest neighbors the data instances share. The method recognizes core points and constructs clusters around these using the similarity. The shared nearest neighbor definition of similarity diminishes issues with differing densities and increasing dimensions. The authors identified a number of optimizations that allow their technique to process large data sets efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Density-based techniques</head><p>Density-based techniques deal with the dense localities of the data space, identified by various regions of lower object density. These are not effective when the dimensionality of the data increases because, as data points are scattered through a large volume, their density decreases due to the curse of dimensionality, making the relevant set of data points harder to find <ref type="bibr" target="#b6">[7]</ref>. Chen et al. <ref type="bibr" target="#b61">[62]</ref> introduced a density estimator for estimating measures in high-dimensional data and applied this to the problem of recognizing changes in data distribution. They approximated the probability of data µ , aiming to bypass the curse of dimensionality by utilizing the assumption that µ is lying around a low-dimensional sub- set embedded in a high-dimensional space. However, the estimators they proposed for µ are based on a geometric multiscale decomposition of the given data while controlling the overall model complexity. Chen et al. <ref type="bibr" target="#b61">[62]</ref> proved strong finite sample performance bounds for various models and target probability measures that are based only on the intrinsic complexity of the data. The techniques implementing this construction are fast and parallelizable, and showed high accuracy in recognizing the outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification-based techniques</head><p>Regarding classification and high dimensionality, a common problem occurs when the dimensionality m of the feature vector is much larger than the available training sample size n. According to Fan and Fan <ref type="bibr" target="#b63">[64]</ref>, high dimensionality in classification is intrinsic and due to the presence of irrelevant noise effects that do not help in minimizing the classification error. high dimensionality also affects classification accuracy, which is the predictive power and model interpretability, meaning the model can interpret the kind of connection between input and output. When the number of features is high, some of the traditional classification methods yield poor accuracy, with increasing dimensionality resulting in false classifications. The relationship between variables often builds a model that better understands the data; however, too many dimensions can complicate the interpretation model <ref type="bibr" target="#b63">[64]</ref>. The most effective strategies focus on the relevant features and can process large numbers of dimensions within a manageable time span. However, many statistical techniques are vulnerable to increasing dimensionality. See Table <ref type="table">2</ref> for the summary of statistical methods. Some machine learning techniques are based on the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2 Summary of statistical methods and author's work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distance-based</head><p>Density-based Clustering-based Classificationbased</p><formula xml:id="formula_1">[30] ✖ ✖ ✖ [59] ✖ ✖ ✖ [62] ✖ ✖ ✖ [63] ✖ ✖ [64] ✖ ✖ ✖</formula><p>assumption that dimensionality reduction can be achieved by projecting the data onto a lower dimensional space where learning might be easier after such lower dimensional projection <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b65">66]</ref>. Techniques that are based on dimensionality reduction strategy projects data onto a lower dimensional subspace <ref type="bibr" target="#b7">[8]</ref> or PCA <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b67">68]</ref>, as discussed in the following section. This section covered the theoretical background of the high dimensionality problem including 'visualization' and 'the curse of dimensionality' , and also discusses the challenges of traditional models addressing the problem of high dimensionality in anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategies for tackling the problem of high dimensionality</head><p>One way to address the problem of high dimensionality is to reduce the dimensionality which projects the whole data set into a lower dimensional space, either by combining dimensions into linear combinations of attributes <ref type="bibr" target="#b68">[69]</ref> or selecting the subsets of locally relevant and low-dimensional attributes called subspaces. As discussed above, many dimensionality reduction methods, such as PCA, MDS, Karhunen-Loeve Transform, local linear embedding, Laplacian Eigenmaps, and diffusion maps, have been proposed to achieve dimensionality reduction <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref><ref type="bibr" target="#b73">[74]</ref>. In many application areas, data representations consists of dimensions that are dependent on each other, and correlation and redundancy can be noted. The intrinsic dimensionality of those data representation is smaller than the available relevant dimensions. Many techniques have been proposed to measure the intrinsic dimensionality <ref type="bibr" target="#b74">[75]</ref><ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref><ref type="bibr" target="#b77">[78]</ref><ref type="bibr" target="#b78">[79]</ref><ref type="bibr" target="#b79">[80]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Principal component analysis</head><p>PCA was first described by Pearson <ref type="bibr" target="#b49">[50]</ref>. One of the oldest and most popular methods to address multidimensionality, it is used in many scientific disciplines <ref type="bibr" target="#b80">[81]</ref>. Synonyms for PCA, such as empirical orthogonal functions, correspondence analysis, factor analysis, multifactor analysis, Eigenvector analysis, and latent vector analysis, can be found throughout the literature <ref type="bibr" target="#b80">[81]</ref>. PCAs are generally based on the assumption that data are extracted from a single low-dimensional subspace of a high-dimensional space; however, in reality, data may derive from multiple subspaces, including unknown ones <ref type="bibr" target="#b81">[82]</ref>. The aim of PCA is to derive all the significant attributes from the data set and form new orthogonal attributes called principal components. This provides an estimation of a data set which is, a data matrix x in terms of the product of two small matrices T and P. These (T and P) identify the important data patterns of X <ref type="bibr" target="#b82">[83]</ref> to reduce the dimensionality by merging all the relevant attributes, called principal components, before eliminating all other remaining attributes <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b84">85]</ref>. In general, PCA can be used on any data set by estimating the correlation structure of the features of the data set. It has three main goals:</p><p>(1) project the most important dimensions of the data set, (2) combine the selected dimensions and so reduce the size of the data set, and (3) simplify the data set by analyzing the structure of the observations and associated dimensions.</p><p>Wang et al. <ref type="bibr" target="#b85">[86]</ref> presented a PCA, as well as separable compression sensing, to identify different matrices. Compressive sensing (or compressed sampling [CSG]) theory was proposed by Candes and Wakin <ref type="bibr" target="#b86">[87]</ref>, that uses a random measurement matrix to convert a high-dimensional signal to low-dimensional signal until the signal is compressible after which the original signal is restructured from the data of the low-dimensional signal. Moreover, the low-dimensional setting contains the main features of the high-dimensional signal, which means CSG can provide an effective method for anomaly detection in high-dimensional data sets. In the model of Wang et al. <ref type="bibr" target="#b85">[86]</ref>, abnormalities are more noticeable in a matrix of uncompression compared to a matrix of compression. Hence, their model could attain equal performance in volume anomaly detection, as it used the original uncompressed data and minimized the computational cost significantly.</p><p>The major drawback of using dimensionality reduction approaches based on PCA is that they may lead to a significant loss of information. This is because PCA is generally aimed at detecting orthogonal projections of the data set that contain the highest variance possible to identify hidden linear correlations among attributes <ref type="bibr" target="#b72">[73]</ref>. If the attributes of the data set are non-linear or unrelated, PCA may result in complicated, and possibly uninterpretable, false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subspace approach</head><p>The subspace approach is an extension of feature selection that aims to identify local, relevant subspaces instead of the entire data space. Subspaces are the subsets of dimensions of a dataset that use less than the full dimensional space. For example, in applying the subspace approach to clustering, each cluster is a set of data instances recognized by a subset of dimensions, and different subsets of dimensions are represented in different clusters. The difference between traditional clustering and subspace clustering is the simultaneous discovery of cluster memberships of objects and the subspace of each cluster <ref type="bibr" target="#b87">[88]</ref>. Cluster memberships describe similarities in objects and can be referred to as local relevant spaces in a normal subspace approach. Clusters are generally embedded in the subspaces of high-dimensional data. Aggarwal <ref type="bibr" target="#b88">[89]</ref> concluded that by evaluating the nature of data, it is practical to suggest more meaningful clusters that are specific to a particular subspace. This is because anomalies may only be identified in low-dimensional subspaces of the data or in data sets with missing attributes <ref type="bibr" target="#b7">[8]</ref>. Every subspace can be identified with its own patterns. This is due to different regions of the data being dense with respect to different subsets of dimensions. These clusters are referred to as projected clusters or subspace clusters <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b90">91]</ref>.</p><p>Anomaly detection techniques that are based on subspace approaches are complex; they assume that anomalies are rare and can be found only in some subsets (locally relevant subsets) of dimensions. For this reason, statistical aggregates on individual dimensions in a specific region often provide very weak hints in subspace searches, resulting in the omission of useful dimensions, especially when locally relevant subspaces provide only a small view of the total dimensionality of the data. The challenge is identifying relevant subspaces, as the number of possible subspaces is directly proportional to the increasing dimensionality of the data. To build a robust anomaly detection model based on this assumption, it is necessary to simultaneously find relevant subspaces and low-dimensional spaces. Simultaneous discovery plays a crucial role because different subsets of dimensions are relevant to different anomalies. The discovery of multiple subspaces is important because selection of a single or only a few relevant subspaces may cause unpredictable results <ref type="bibr" target="#b27">[28]</ref>. Hence, subspace anomaly detection is an ensemble-centric problem <ref type="bibr" target="#b88">[89]</ref>. Lazervic and Kumar <ref type="bibr" target="#b91">[92]</ref> proposed a model that detects anomalies using a scoring system called "feature bagging" that randomly selects subspaces. However, this results in the rise of irrelevant dimensions due to random subspace selection. To address this problem, Kriegel et al. <ref type="bibr" target="#b22">[23]</ref> adopted a technique to select informative or relevant dimensions. Müller et al. <ref type="bibr" target="#b92">[93]</ref> proposed a subspace method called "OUTERS, " an outrank approach that ranks anomalies in heterogeneous high-dimensional data by introducing a novel scoring algorithm using subspace clustering analysis to detect anomalies in any number of dimensions. Zhang et al. <ref type="bibr" target="#b93">[94]</ref> proposed an angle-based subspace outlier detection approach that selects meaningful features of subspace and executes anomaly detection in the selected subspace projection in order to retain the accuracy of detecting anomalies in high-dimensional data sets. They also included subspace detection approaches and illustrated the steps of relevant subspace selection suitable for analysis. Thudumu et al. <ref type="bibr" target="#b40">[41]</ref> proposed a method to detect outliers, by bifurcating a high-dimensional space into locally relevant and low-dimensional subspaces using Pearson correlation coefficient (PCC) and PCA. They derived candidate subspaces where anomalies may possible be hidden and developed an adaptive clustering approach to filter the anomalies <ref type="bibr" target="#b4">[5]</ref>.</p><p>Another algorithm, called Outlier Detection for Mixed-Attribute Data sets (ODMAD) proposed by Koufakou and Georgiopoulos <ref type="bibr" target="#b60">[61]</ref>, detects anomalies based on their categorical attributes in the first instance, before focusing on subsets of data in the continuous space by utilizing information about the subsets based on those categorical attributes. Their results demonstrated that the speed of the distributed version of ODMAD is close to linear speedup with the number of nodes used in computation. Mixed attributes are addressed by Ye et al. <ref type="bibr" target="#b94">[95]</ref>, who proposed an outlier detection algorithm to detect anomalies in highdimensional mixed-attribute datasets by calculating the anomaly subspace, combined with information entropy. They used a bottom-up method to detect interesting anomaly subspaces and compute the outlying degree of anomalies in high-dimensional mixed-attribute data sets.</p><p>This section provided strategies to tackle the high dimensionality problem, such as subspace methods and principal component analysis to ascertain the benefit of one approach over another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unique challenges brought by anomaly detection in high-dimensional big data</head><p>As discussed in "Introduction", the two features of big data that have the greatest effect on the problem of high dimensionality are "volume" and "velocity. " The high dimensionality problem not only leads to difficulties in detecting anomalies, but also brings additional challenges when data are increasing and arriving at speed as unbounded data streams. The most common strategies to address the problem of high dimensionality are to locate the most important dimensions (i.e., subset of features), known as the variable selection method, or to combine dimensions into a smaller set of new variables, known as the dimensionality reduction method <ref type="bibr" target="#b72">[73]</ref>. However, these strategies become highly complex and ineffective in detecting anomalies due to the challenges associated with large data sets and data streams. This is because anomaly detection techniques are generally based on statistical hypothesis tests, such as the Grubb's test and the Dixon test, which work on an assumed distribution of some underlying mechanism within the data <ref type="bibr" target="#b95">[96]</ref>. However, the underlying distributions are unclear and most of the techniques are generalized to work with few dimensions. When the data size is large, accumulating, and generated with speed, anomaly detection techniques bring further challenges. Many researchers have addressed the challenges of anomaly detection techniques with regard to high dimensionality and big data problems individually, but not jointly or comprehensively.</p><p>Moreover, each problem has their individual challenges, for example, 'velocity' aspect of big data has many challenges <ref type="bibr" target="#b34">[35]</ref> such as transience, arrival rate, and the notion of infinity, but they are insignificant while tackling high dimensionality or anomaly detection problems. Furthermore, big data is still evolving, and there is no specific technique or algorithm to address the increasing 'dimensionality' as it varies from one application to other. To set future directions in this area, we review the works of various authors that are closely related (either directly or indirectly) to the above three problems, thus by, deriving the unique challenges. Here, we present a taxonomy of unique challenges (see Fig. <ref type="figure">4</ref>) brought by anomaly detection in high-dimensional big data. We have described each one of them in the following subsections. Table <ref type="table" target="#tab_1">3</ref> presents the description of challenges of anomaly detection from the perspective of high dimensionality problem.</p><p>Many anomaly detection techniques assume that data sets have only a few features, and most are aimed at identifying anomalies in low-dimensional data. Techniques that address the high dimensionality problem when data size is increasing face challenges in anomaly detection due to a range of factors, as outlined in Table <ref type="table" target="#tab_1">3</ref>. Anomalies are masked in high-dimensional space and are concealed in multiple high-contrast subspace projections. The selection of subspace is both vital and complex, especially when data is increasing. Fabien and Kelloer <ref type="bibr" target="#b99">[100]</ref> proposed to estimate the contrast of subspaces by enhancing the quality of traditional anomaly rankings by calculating the scores of highcontrast projections as evaluated on real data sets. The factor that affects the nature of distance in high-dimensional space, hindering the anomaly detection process, is distance Fig. <ref type="figure">4</ref> Taxonomy of unique challenges brought by anomaly detection in high-dimensional big data concentration: all data points become essentially equidistant <ref type="bibr" target="#b100">[101]</ref>. Tomasev et al. <ref type="bibr" target="#b101">[102]</ref> addressed the problem of clustering in high-dimensional data by evaluating frequently occurring points known as hubs. They developed an algorithm that proved that hubs are the best way of defining the point centrality within a high-dimensional data cluster. Radovanović et al. <ref type="bibr" target="#b102">[103]</ref> provided useful insights using data points, known as anti-hubs; although they appear very infrequently, they clearly distinguish the connection between outliers. The authors evaluated several methods, such as angle-based techniques, the classic k-NN method, density-based outlier detection, and anti-hub-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges in the context of volume aspect of big data</head><p>With the advent of big data, the processing efficiency of anomaly detection techniques becomes increasingly complex. When the underlying probability distribution is unknown, and the data set size is huge, computational requirements increase. The "volume" feature of big data stresses the storage, memory, and computing capacity of the system to handle the increasing data size <ref type="bibr" target="#b103">[104]</ref>. Performance is the major challenge of anomaly detection techniques when dealing with large data sets. When the data size is large, anomaly detection techniques may falter, due to limited computational capacity and associated factors. To overcome this issue, researchers have proposed the use of a parallel and distributed computing model. This section focuses on the challenges of anomaly detection in parallel, distributed environments and ensemble strategies. The unique challenges brought by anomaly detection from the 'volume' aspect of big data when data are high-dimensional is listed in Table <ref type="table" target="#tab_2">4</ref>.</p><p>Managing computational power and disk input/output (I/O) communication can result in improving the efficiency of the technique. Shin et al. <ref type="bibr" target="#b105">[106]</ref> proposed a technique called D-cube, which is a disk-based detection technique to find fraudulent lockstep behaviour in largescale multi-aspect data and runs in a distributed manner across multiple machines. They compared D-cube technique across state-of-the-art methods and proved that D-cube is memory efficient, they have also proved it accurate by successfully spotting network attacks from TCP dumps and synchronised behaviour in rating data with highest accuracy. Hung and Cheung <ref type="bibr" target="#b106">[107]</ref> introduced an efficient and parallel version of the nested loop (NL) algorithm, based on the NL algorithm proposed by Knox and Ng <ref type="bibr" target="#b107">[108]</ref>, that reduces both computation and disk I/O costs. The NL algorithm is a straightforward method to mine outliers in a database. Ramaswamy et al. <ref type="bibr" target="#b108">[109]</ref> proposed a construction model for distance-based anomalies, which is built on the distance of a point from its neighbor, and also developed an effective partition-based algorithm to pull out abnormal patterns in huge data sets. The former segregates input data into separate subsets and prunes partitions that do not contain anomalies, resulting in considerable savings in computation. Angiulli and Fassetti <ref type="bibr" target="#b109">[110]</ref> presented a distance-based anomaly detection approach called "DOLPHIN" (for Detecting OutLiers PusHing data into an INdex)-that works on disk-resident data sets in huge datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensemble strategies</head><p>Some studies aim to improve the efficiency of anomaly detection techniques by using ensemble strategies. To solve the sequential exception problem in large databases, Arning et al. <ref type="bibr" target="#b110">[111]</ref> proposed a linear algorithm using a dissimilarity function to capture the similarity rate of a data point. More and Hall <ref type="bibr" target="#b111">[112]</ref> proposed an algorithm to group largescale datasets without clustering entire data in a single instance. Erfani et al. <ref type="bibr" target="#b5">[6]</ref> introduced an unsupervised technique for high-dimensional large-scale unlabeled data sets to detect anomalies that are a combination of a deep belief network (DBN) and one-class support vector machines (SVM). One-class SVMs (1SVMs) are used for detecting outliers through unsupervised learning and aim to model the underlying distribution of data while not considering irrelevant attributes or outliers in the training records. Features derived from training samples are taken as input to train 1SVMs. Conversely, a DBN is a multiclass semi-supervised approach and dimensionality reduction tool. It uses multilayer generative models (non-linear manifold) that learn one layer of features at a time from unlabeled data. Camacho et al. <ref type="bibr" target="#b112">[113]</ref> presented an interesting outline for anomaly detection, identifying and interpreting unusual events in a forensics system network by addressing the 4Vs of big data-volume, variety, veracity, and velocity. Their framework is based on input from several heterogeneous data sources. First, the system pre-processes incoming data; second, extracted features are calculated from the streaming data; third, all features representing diverse sources are combined and called a parameterization step; and, fourth, these new features are utilized in updating a set of intermediate data structures representing the present stage of the network. The updated strategy follows an exponentially weighted moving average method and uses a PCA model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges in the context of velocity aspect of big data</head><p>Velocity refers to the challenges associated with the continuous generation of data at high speed. A data stream is an infinite set of data instances in which each instance is a set of values with an explicit or implicit time stamp <ref type="bibr" target="#b34">[35]</ref>. Data streams are unbounded sequences and the entry rate is continuously high, as the respective variations repeatedly change over time. Data streams reflect the important features of big data in that the aspects of both volume and velocity are temporally ordered, evolving, and potentially infinite. The data may comprise irrelevant attributes that raise problems for anomaly detection, and there are several other factors involved, such as whether the data are from a single source or multiple sources. Multiple data streams are made up of a set of data streams, and every data stream comprises an infinite sequence of data instances accompanied by an explicit or implicit time stamp history. In a single data stream, anomaly detection compares the history of data instances to determine whether an instance is an outlier or anomaly. By contrast, in multiple data streams, data instances are recognized as anomalies by comparing them to the history of data instances from the same stream or other streams. The unique challenges <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b104">105,</ref><ref type="bibr" target="#b113">[114]</ref><ref type="bibr" target="#b114">[115]</ref><ref type="bibr" target="#b115">[116]</ref><ref type="bibr" target="#b116">[117]</ref> of anomaly detection for data streams are listed in Table <ref type="table">5</ref>.</p><p>Most anomaly detection strategies assume that there is a finite volume of data generated by an unknown, stationary probability distribution, which can be stored and analyzed in various steps using a batch-mode algorithm <ref type="bibr" target="#b118">[119]</ref>. Anomaly detection on streaming data is a highly complex process because the volume of data is unbounded and cannot be stored indefinitely <ref type="bibr" target="#b34">[35]</ref>. Data streams are produced at a high rate of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5 Challenges of anomaly detection in context of big data problem (velocity aspect)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characteristic features Description</head><p>1. Asynchronous instances Multiple asynchronous data streams arrive at different times and are independent of one another. The data instances from any source may be missing at any point of time, or delay in arrival is possible; therefore, to detect anomalies, the specific temporal context should be determined on the data instances of both the streams. In multiple data streams, there are many sources from which data points are generated and these arrive at distinctive times. Such data points are described as asynchronous <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b117">118]</ref> 2. Dynamic relationship The correlation of data points is continuously monitored from multiple data streams that differ due to the asynchronous behavior of data <ref type="bibr" target="#b34">[35]</ref> 3. Heterogeneous schema Data instances arriving from various data sources may have different schemas. Compiling various multiple data instances over different schemas is a complex task, as is detecting an anomaly <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b117">118]</ref> 4. Concept drift The data distribution changes over time, which means that the properties of the target variable that are being predicted by the model also changes over time. This is called concept drift <ref type="bibr" target="#b115">[116]</ref> generation, which makes the task of detecting anomalies and extracting useful insights challenging. This is a main disadvantage that arises in several application areas <ref type="bibr" target="#b36">[37]</ref>. Silva et al. <ref type="bibr" target="#b118">[119]</ref> highlighted the following restrictions for the successful development of algorithms in data streams: (1) the data instances arrive continuously; (2) there is no control over the order of processing or handling of data instances; (3) the size of a data stream can be unbounded; (4) data instances are deleted after processing; and (5) the data generation process can be nonstationary; hence, its probability distribution may evolve over the period.</p><p>A hypothesis behind all data stream models is that the most recent data instances are more than historical data. The simplest model uses sliding windows of fixed size and works on the basis of first in, first out <ref type="bibr" target="#b37">[38]</ref>. A sequence-based sliding window is one in which the size of the window is defined as the number of observations in regard to fixed size and specific time <ref type="bibr" target="#b74">[75]</ref>. There is another type of sliding window called a time stamp window in which the size of the window is representative of the duration of the data <ref type="bibr" target="#b37">[38]</ref>.</p><p>Angiulli and Fasseti <ref type="bibr" target="#b119">[120]</ref> introduced techniques for recognizing distance-based outliers in data streams using a sliding window model in which anomaly queries are executed for the purpose of identifying anomalies in the current window. Their algorithms execute anomaly queries and return an approximate answer based on accurate estimations with a statistical guarantee. These algorithms are based on a method known as stream outlier miner, or STORM, which is used to find outliers on distancebased windowed data streams. A sliding window is used to continuously inspect the object until it expires. Later, Angiulli and Fasseti <ref type="bibr" target="#b120">[121]</ref> presented an additional algorithm for identifying distance-based anomalies in data streams using the sliding window model; although based on their previous approximate algorithm, this algorithm emphasized fixed memory requirements.</p><p>An algorithm based on the sliding window model for mining constrained frequent item sets on uncertain data streams was introduced by Yu et al. <ref type="bibr" target="#b38">[39]</ref>. Known as CUSFgrowth (constrained uncertain data stream frequent item sets growth), the algorithm determines the order of items in transactions and analyzes the properties of constraints. According to the order of items determined by the properties of constraints a CUSF-tree is created; later, after the frequent item sets are satisfied, the constraints are mined from the CUSF-tree.</p><p>Kontaki et al. <ref type="bibr" target="#b121">[122]</ref> also studied the problem of continuous anomaly detection in data streams using sliding windows. They proposed four algorithms that sought effective anomaly monitoring with lesser memory requirements. Apart from assuming that the data are in metric space, their model did not make any assumptions about the behavior of input data. Their techniques have considerable flexibility with regard to parameter values, enabling the execution of multiple distance-based outlier detection tasks with different values, and they reduced the number of distance computations using micro-clusters. Their primary concerns were to improve efficiency and reduce storage consumption. Their methods incorporate an event-based framework that bypasses unneeded computations benefiting from the expiration time of objects.</p><p>A continuous outlier detection algorithm (CODA) is an event-based technique that estimates the expiration time of objects to circumvent undesirable computations. This technique quickly determines the nature of elements by probabilistic pruning, thereby improving efficiency and consuming significantly less storage. Since different users may have different views of outliers, an advanced CODA that can handle numerous values by enabling the concurrent execution of various monitoring strategies has also been proposed. Another algorithm to decrease the quantity of distance computations-microcluster CODA-was inspired by the work of Zhang et al. <ref type="bibr" target="#b122">[123]</ref>.</p><p>The two popular ensemble learning techniques are Bagging and Boosting. Bagging is used for variance reduction and was first introduced by Breiman <ref type="bibr" target="#b123">[124]</ref>. Boosting was first proposed by Schapire <ref type="bibr" target="#b124">[125]</ref> to strengthen the ability of weak learners to achieve arbitrarily high accuracy. Oza and Russell <ref type="bibr" target="#b125">[126]</ref> proposed two online variations of bagging and boosting for data streams. They showed how the training data could be simulated from the data stream perspective. They achieved the simulation of training data from the replication of the sampling bootstrap process. Bifet et al. <ref type="bibr" target="#b126">[127]</ref> developed a model for examining concept drift in data streams with two new adaptations of bagging: ADWIN bagging and adaptive-size Hoeffding tree bagging. The Hoeffding tree is a technique that can learn from data streams that does not change over time. It is an incremental algorithm based on decision tree induction and the hypothesis of distribution generating examples <ref type="bibr" target="#b39">[40]</ref>. The framework and approach of Bifet et al. <ref type="bibr" target="#b126">[127]</ref> was similar to that proposed by Narasimhamurthy and Kuncheva <ref type="bibr" target="#b127">[128]</ref>, which accommodates STAGGER and moving hyperplane generation strategies.</p><p>ADWIN is a change detector and an estimator that interprets the issue of tracking the average of a stream of bits or real-valued numbers in a well-specified way <ref type="bibr" target="#b128">[129]</ref>. The drift detection method introduced by Gama et al. <ref type="bibr" target="#b129">[130]</ref> controls the errors generated by the learning model during the stage of prediction and then evaluates two windows; the first window comprises all the data, the second contains the data until the number of errors increases. These windows are not stored in-memory; only statistics and a window of recent errors using the binomial distribution are kept. Faria et al. <ref type="bibr" target="#b130">[131]</ref> proposed a method for multiclass novelty detection in data streams that associate with novelty patterns, which are recognized by the algorithm through unsupervised learning using a confusion matrix that increases over time. <ref type="bibr">Chu and Zaniolo [36]</ref> proposed a fast and light boosting for adaptive mining of data streams. The technique supports concept drift in data streams via change detection, which is built on a dynamic sample-weight assignment scheme</p><p>The problems that occur when data streams have multidimensional features are caused by the curse of dimensionality and drifting of data streams. To simultaneously address these two challenges, Zhang et al. <ref type="bibr" target="#b26">[27]</ref> presented an unsupervised, online subspace learning approach to anomaly detection from nonstationary high-dimensional data streams. In order to find low-dimensional subspace faults from high-dimensional data sets, an angle-based subspace anomaly detection technique is designed by selecting fault-relevant subspaces and calculating vectorial angles, which compute the local anomaly score of the data instance in its subspace projection. The technique is extended to an online mode to continuously monitor systems and to detect anomalies from data streams based on the sliding window strategy. This section provided a taxonomy of big data anomaly detection problems with regard to high dimensionality in the form of a survey of closely related work. The aim of the review is to provide an understanding of the underlying relations and patterns among variables by evaluating anomaly detection techniques dealing high dimensionality and big data problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tools in high dimensional big data</head><p>Parallel or distributed computing is one of the most important techniques to handle and process big data <ref type="bibr" target="#b131">[132]</ref>. In general, big data requires sophisticated methodologies to handle and process the large volume of data within limited run times efficiently. It distributes intensive computations over numerous computer processors and accelerates the overall run time by running parallelizable parts of the computation concurrently. Therefore, scalability is the major issue to many existing state-of-the-art techniques with big dimensionality problem. Luengo et al. <ref type="bibr" target="#b132">[133]</ref> analysed this issue using two popular data repositories that ranged from 256 to 20 million dimensions and suggested that the future systems are to equip with necessary techniques to handle the big dimensionality issue. Zhai et al. <ref type="bibr" target="#b3">[4]</ref> observed that the dimensionality issue handled by state-of-the-art techniques are not satisfactory and suggested that majority of them might fail to process any data with more than 10,000 dimensions. Hence, techniques based on distributed computing that supports the scalability are needed to handle the complex requirements of big dimensionality enabling quick processing and storage handling. MapReduce is one of the first distributed programming paradigms to handle big data storing and processing. Henceforth, many frameworks for distributed computing such as Apache Hadoop <ref type="bibr" target="#b133">[134]</ref>, Apache Storm <ref type="bibr" target="#b134">[135]</ref>, Apache Spark <ref type="bibr" target="#b135">[136]</ref>, Apache Flink <ref type="bibr" target="#b136">[137]</ref> and MXNet <ref type="bibr" target="#b137">[138]</ref> were developed addressing the increasing demands of big data. Most of these frameworks have in-house machine learning (ML) libraries, and Apache Spark has a powerful ML library than any of the other frameworks <ref type="bibr" target="#b138">[139]</ref>. In this section, we review anomaly detection techniques implemented on these frameworks. Other parallel and distributed models that are focused on the scalability of the algorithms/techniques rather than frameworks are discussed in the following subsection "Other parallel and distributed models" (see "Other models" column in Table <ref type="table" target="#tab_3">6</ref>).</p><p>MapReduce, a programming paradigm for processing vast amounts of data, provides high-level parallelization that runs on clusters or grids of nodes (i.e., computers) to handle big data <ref type="bibr" target="#b155">[156,</ref><ref type="bibr" target="#b156">157]</ref>. MapReduce splits processing into "map" and "reduce" phases and each phase is based on key-value pairs used as input and output <ref type="bibr" target="#b157">[158]</ref>. All operations of each map function are independent of each other and are fully parallelizable as the map function takes a single record. However, the reduce function is processed in parallel based on the intermediate pairs with the same key. Apache Hadoop is one of the most popular large-scale opensource frameworks that is based on the MapReduce <ref type="bibr" target="#b155">[156]</ref>. Hence, we combine both MapReduce and Hadoop into one subsection and present the relevant work related to both as seen in Table <ref type="table" target="#tab_3">6</ref>. Koufakou et al. <ref type="bibr" target="#b139">[140]</ref> proposed a fast parallel anomaly detection approach that is dependent on the attribute value frequency approach, a scalable, high-speed outlier detection process for categorical data that is effortless to parallelize and intended to recognize anomalies in large data mining issues. They used MapReduce because it offers load balancing and fault tolerance, and is extremely scalable concerning a number of nodes. Leung and Jiang <ref type="bibr" target="#b35">[36]</ref> reported a solution which utilizes MapReduce to mine uncertain big data for frequent patterns satisfying user-specified anti-monotonic restrictions. Extant big data mining algorithms mainly focus on association analysis, which amounts to mining interesting patterns from particular databases. Jiang et al. <ref type="bibr" target="#b140">[141]</ref> reported on a tree-based technique, BigSAM, that permits operators to express the patterns to be mined according to their interests via the use of constraints, as MapReduce enables uncertain big data to be mined for common patterns. He et al. <ref type="bibr" target="#b31">[32]</ref> presented a parallel application of a KD-Tree-based anomaly identification technique to manage large data sets, implemented as a parallel KD-Tree-based anomaly detection algorithm. Their experimental results showed that the algorithm not only processed large data sets on commodity hardware efficiently, but also scaled well. Apache Spark(Spark) <ref type="bibr" target="#b135">[136]</ref> is another distributed framework based on MapReduce for processing large volumes of data on a distributed system, however, has a feature called in-memory computation <ref type="bibr" target="#b158">[159,</ref><ref type="bibr" target="#b159">160]</ref>. In contrast to MapReduce two-phase paradigm, Spark's in-memory computing model aims at speed and extensibility to handle both batch and real-time workloads. In Spark, implicit data parallelism is achieved on a cluster of computers that offer fault-tolerance, locality-aware scheduling and automatic load balancing. Jiang et al. <ref type="bibr" target="#b141">[142]</ref> reported a scalable, parallel sequential pattern identification algorithm to identify probable motifs (i.e., non-exact contiguous sequences) from large DNA sequences using the Spark in-memory parallel resilient distributed data set approach. As DNA sequences are detailed using a set of four letters, their algorithm restricts the search space, decreases mining time, and integrates user-specified features in identifying sequential patterns from big uncertain DNA in the Spark framework. Terzi et al. <ref type="bibr" target="#b142">[143]</ref> proposed an unsupervised approach using Apache Spark as their distributed framework. They reported 96% accuracy in the identification of anomalies in a public big network data.</p><p>For real-time processing, Apache Storm <ref type="bibr" target="#b134">[135]</ref> was developed by Twitter an opensource distributed framework with guaranteed features such as scalability, fault-tolerant, and resilience. Zhang et al. <ref type="bibr" target="#b143">[144]</ref> developed a framework built on Apache Storm to support the distributed learning of large-scale Convolutional Neural Networks (CNN) using two datasets, that is suitable for real-time stream processing. Their experiment demonstrates that more reasonable parallelisms can significantly improve the performance speed of their framework. Veen et al. <ref type="bibr" target="#b160">[161]</ref> focused on the elasticity of a streaming analysis platform using virtual machines from a public cloud based on Apache Storm. They chose the framework because of the possibility of adding and removing processing nodes is easier.</p><p>MXNet is an open-source, scalable, memory-efficient, high-performance modular deep learning framework, that offers a range of application programming interfaces(APIs) for programming languages such as C++, Python, Matlab, and R. It runs on heterogeneous systems, starting from mobile devices to distributed GPU clusters <ref type="bibr" target="#b161">[162]</ref>. Abeyrathna et al. <ref type="bibr" target="#b144">[145]</ref> proposed an anomaly proposal-based approach that can establish an efficient architecture for real-time fire detection using MXNet framework. Their architecture is built together with a Convolutional Autoencoder (CAE) module for picking doubtful regions and a Convolution Neural Network (CNN) classifier that can recognize fire as an outlier. For both stream processing and batch processing, Apache Flink <ref type="bibr" target="#b136">[137]</ref> another opensource framework was proposed combining the scalability and programming flexibility of other distributed paradigms such as MapReduce <ref type="bibr" target="#b162">[163,</ref><ref type="bibr" target="#b163">164]</ref>. Toliopoulos et al. <ref type="bibr" target="#b145">[146]</ref> conducted their work on distance-based outlier detection and examined in a massively parallel setting using three real-world and one synthetic dataset. They have considered three main parallel streaming platforms such as Apache Storm, Apache Spark and Apache Flink. However, they mainly targeted to investigate the challenges of customizing state-of-the-art techniques to Apache Flink. Their experiments showed the speed-ups of up to 117 times over a non-parallel solution implemented in Flink. The methods they used are publicly available as open-source software as they intend to offer solutions in the large-scale streaming big data analytics. García-Gil et al. <ref type="bibr" target="#b138">[139]</ref> have performed a comparative study on the scalability of two frameworks Apache Spark and Apache Flink. Their experimental results showed that Spark has better performance and overall runtimes than Flink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other parallel and distributed models</head><p>Many other distributed frameworks have been proposed to support efficient parallel processing of anomaly detection techniques in big data. Angiulli et al. <ref type="bibr" target="#b32">[33]</ref> presented a distributed framework for identifying distance-based anomalies in massive data sets based on the perception of an anomaly detection resolving set, which is a small subset of the data set. The authors also presented a modified method-the "lazy distributed solving set"-that reduced the volume of data to be swapped from the nodes on the distributed solving set by implementing a strategy for the transmission of a condensed number of distances, which, to some extent, simultaneously increased the number of communications. Later, Angiulli et al. <ref type="bibr" target="#b151">[152]</ref> proposed a set of parallel and distributed algorithms for GPUs resulting in two distance-based anomaly detection algorithms: BruteForce and SolvingSet. The difference between them is the way they utilize the architecture and memory hierarchy of GPUs and provide improvements with respect to CPU versions, both regarding scalability and exploitation of parallelism. The authors detailed the algorithms' computational properties, measured their performance with extensive experimentation, and compared several implementations showing significant increases in speed. Matsumoto et al. <ref type="bibr" target="#b152">[153]</ref> published a parallel algorithm for anomaly detection on uncertain data using density sampling, establishing implementation on both graphic processing units (GPUs) and multi-core central processing units (CPUs) through the OpenCL framework.</p><p>Lozano and Acufia <ref type="bibr" target="#b153">[154]</ref> designed two parallel algorithms to identify distance-based anomalies using randomization and a pruning rule to recognize density-based local anomalies. They also constructed parallel versions of Bay and Local Outlier Factor (LOF) procedures, which exhibited good performance in anomaly detection and run time. Bai et al. <ref type="bibr" target="#b33">[34]</ref> focused on the issue of distributed density-based anomaly detection for large data. They proposed a grid-based partition algorithm as a data pre-processing technique that splits the data set into grids before distributing these to data nodes in a distributed environment. A distributed LOF computing method was presented for discovering density-based outliers in parallel by utilizing a few network communications. Reilly et al. <ref type="bibr" target="#b154">[155]</ref> proposed a PCA-based outlier identification approach that works in a distributed environment, demonstrating robustness in its extraction of the principal components of a training set comprising outliers. Minimum volume elliptical PCA can determine principal components more vigorously in the presence of outliers by building a soft-margin, tiniest volume, ellipse around the data that lessens the effects of outliers in the training set. Local and centralized approaches to outlier detection were also studied. The projected outlier detection technique was reformulated using distributed convex optimization, which splits the issue across a number of nodes. Gunter et al. <ref type="bibr" target="#b146">[147]</ref> explored various techniques for identifying outliers in large distributed systems and argued for a lightweight approach to enable real time analysis. No single optimal method was found; therefore, they concluded that combinations of various methods are needed due to the change in effectiveness that depends on the definition of the anomaly.</p><p>It is important to understand whether the anomaly detection technique fits the model and is scalable to the size of the data and dimensionality <ref type="bibr" target="#b6">[7]</ref>. Maruhashi et al. <ref type="bibr" target="#b147">[148]</ref> present a technique to find patterns and anomalies in heterogeneous networks with millions of edges and proved empirically that the technique is scalable to high-dimensional datasets. Shin et al. <ref type="bibr" target="#b148">[149]</ref> develop a novel flexible framework that can identify dense blocks in a large-scale high-order tensor and showed that their method is scalable in real data by spotting network attacks from a TCP dump with near perfect accuracy. Oh et al. <ref type="bibr" target="#b43">[44]</ref> provide a scalable approach that can handle high-dimensional data. In particular, they also prove that their approach is better than many baseline methods in terms of dimensionality. Hooi et al. <ref type="bibr" target="#b149">[150]</ref> propose a scalable densest-subgraph based anomaly detection method called FRAUDAR that can not only detect various fraud attacks in real world graphs but also can detect a large number of previously undetected behaviour in large data. Jiang et al. <ref type="bibr" target="#b150">[151]</ref> propose a scalable algorithm called CROSSSPOT that scores and ranks the level of suspiciousness to find dense, suspicious blocks in real-world large multi-modal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>With the world becoming increasingly data driven and with no generic approach for big data anomaly detection, the problem of high dimensionality is inevitable in many application areas. Moreover, the loss of accuracy is greater and computationally more complex as the volume of data increases. Identifying anomalous data points across large data sets with high dimensionality issues is a research challenge. This survey has provided a comprehensive overview of anomaly detection techniques related to the big data features of volume and velocity, and has; examined strategies for addressing the problem of high dimensionality. It is evident that further study and evaluation of big data anomaly detection strategies that address the high dimensionality problem, are needed. To address this research problem, we propose a future research direction of building a novel framework that enables anomalous data points to be identified across large volumes of data with high dimensionality issues. The main contribution will be improving the balance between performance and accuracy of anomaly detection in big data with high dimensionality problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Scope of the paper</figDesc><graphic coords="3,198.65,94.83,198.48,198.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,127.79,94.83,340.20,169.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,127.97,498.23,340.08,210.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Comparison of our survey to other related survey articles</head><label>1</label><figDesc></figDesc><table><row><cell>Surveys</cell><cell>Anomaly detection</cell><cell>High dimensionality problem</cell><cell>Big data</cell></row><row><cell></cell><cell></cell><cell></cell><cell>aspects</cell></row></table><note><p><p><p><p><p><p><p>[7, 9-11, 14, 20]   </p>✖ ✖</p><ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref></p>] ✖</p><ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21</ref></p>] ✖</p>Our survey</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 Challenges of anomaly detection in context of high dimensionality problem</head><label>3</label><figDesc></figDesc><table><row><cell>Characteristic Features</cell><cell>Description</cell></row><row><cell>1. Relevant attribute identification</cell><cell>This refers to the difficulty of</cell></row><row><cell></cell><cell>describing the relevant quantita-</cell></row><row><cell></cell><cell>tive locality of data instances in</cell></row><row><cell></cell><cell>the high-dimensional space</cell></row><row><cell>2. Distance concentration</cell><cell>Due to the sparsity of data, the</cell></row><row><cell></cell><cell>datapoints become nearly</cell></row><row><cell></cell><cell>equidistant in high dimensional</cell></row><row><cell></cell><cell>space depending on the distance</cell></row><row><cell></cell><cell>measure used [59, 97-99]</cell></row><row><cell>3. Subspace selection</cell><cell>The potential features of subspace</cell></row><row><cell></cell><cell>increase exponentially in line with</cell></row><row><cell></cell><cell>the increasing dimensionality of</cell></row><row><cell></cell><cell>the input data, which results in an</cell></row><row><cell></cell><cell>exponential search space</cell></row><row><cell>4. Hubness</cell><cell>The behavior of high-dimensional</cell></row><row><cell></cell><cell>data containing data instances</cell></row><row><cell></cell><cell>that are frequently appearing in</cell></row><row><cell></cell><cell>nearest neighbors known as hubs</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 Challenges of anomaly detection in context of big data problem (volume aspect)</head><label>4</label><figDesc></figDesc><table><row><cell>Characteristic features</cell><cell>Description</cell></row><row><cell>1. Uncertainty</cell><cell>Data can be uncertain due to</cell></row><row><cell></cell><cell>external events from vulner-</cell></row><row><cell></cell><cell>able sources, such as failing to</cell></row><row><cell></cell><cell>calculate the measure of attrib-</cell></row><row><cell></cell><cell>utes, imprecision, vagueness,</cell></row><row><cell></cell><cell>inconsistency, and ambiguity.</cell></row><row><cell></cell><cell>Data that cannot be depended</cell></row><row><cell></cell><cell>upon with complete certainty are</cell></row><row><cell></cell><cell>known as uncertain [105]</cell></row><row><cell>2. Performance</cell><cell>The performance of the technique</cell></row><row><cell></cell><cell>in terms of time and the amount</cell></row><row><cell></cell><cell>of memory is vital while detect-</cell></row><row><cell></cell><cell>ing anomalies in high-dimen-</cell></row><row><cell></cell><cell>sional data</cell></row><row><cell>3. Scalability</cell><cell>It is the ability of the technique to</cell></row><row><cell></cell><cell>cater the increasing dimensions</cell></row><row><cell></cell><cell>and data size</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 Review of big data tools in context of anomaly detection</head><label>6</label><figDesc></figDesc><table><row><cell>Works</cell><cell>MapReduce</cell><cell>Spark</cell><cell>Storm</cell><cell>MXNet</cell><cell>Flink</cell><cell>Other</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>models</cell></row><row><cell>[32, 36, 140, 141]</cell><cell></cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell></row><row><cell>[139, 142, 143]</cell><cell>✖</cell><cell></cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell></row><row><cell>[144]</cell><cell>✖</cell><cell>✖</cell><cell></cell><cell>✖</cell><cell>✖</cell><cell>✖</cell></row><row><cell>[145]</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell></cell><cell>✖</cell><cell>✖</cell></row><row><cell>[139, 146]</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell></cell><cell>✖</cell></row><row><cell>[44, 147-151]</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell></cell></row><row><cell>[33, 34, 152-155]</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell>✖</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The article processing charge is funded by Swinburne University of Technology, Australia.</p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>All papers studied in this systematic review are available in ACM Digital Library, IEEE Xplore and ScienceDirect. Please see the references below.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>Not applicable.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abbreviations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authors' contributions</head><p>ST conducted the systematic literature review and examined various techniques related to the problems of anomaly detection in high-dimensional big data. ST wrote the first draft of the manuscript. PB, JJ, and JS have made significant contributions to the design and structure of the review. PB, JJ, and JS took on a supervisory role and oversaw the completion of the work by reviewing and editing the manuscript. All authors read and approved the final manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Publisher's Note</head><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Managing and mining sensor data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Big data mining of social networks for friend recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Pazdor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in social networks analysis and mining</title>
		<imprint>
			<publisher>ASONAM</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="921" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Gartner</surname></persName>
		</author>
		<ptr target="https://www.gartner.com/it-glossary/big-data/" />
		<title level="m">Big data definition</title>
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The emerging &quot;big dimensionality</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput Intell Mag</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="14" to="26" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive clustering for outlier identification in high-dimensional data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thudumu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Branch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on algorithms and architectures for parallel processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="215" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High-dimensional and large-scale anomaly detection using a linear one-class svm with deep learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karunasekera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="121" to="134" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey of outlier detection methodologies</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Rev</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="126" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An effective and efficient algorithm for high-dimensional outlier detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB J</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="221" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Survey on anomaly detection using data mining techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Comput Sci</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="708" to="713" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph based anomaly detection and description: a survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining Knowl Discov</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="688" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Anomaly detection: a survey</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An overview of anomaly detection techniques: existing solutions and latest technological trends</title>
		<author>
			<persName><forename type="first">A</forename><surname>Patcha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-M</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Netw</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3448" to="3470" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Suspicious behavior detection: current trends and future directions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intell Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="39" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Cos</forename><surname>Sorzano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Montano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.2877</idno>
		<title level="m">A survey of dimensionality reduction techniques</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Knowledge discovery from data streams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Chapman and Hall/CRC</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Outlier detection for temporal data: a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2250" to="2267" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detection of review spam: a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heydari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ali Tavakoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Heydari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3634" to="3642" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Review spam detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on world wide web</title>
		<meeting>the 16th international conference on world wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1189" to="1190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey of distributed mining of data streams</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghoting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Otey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data streams</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="289" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A comprehensive survey of data mining-based fraud detection research</title>
		<author>
			<persName><forename type="first">C</forename><surname>Phua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gayler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1009.6119.2010</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey of outlier detection algorithms for data streams</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tamboli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shukla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing for sustainable global development (INDIACom), 2016 3rd international conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3535" to="3540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Survey on web spam detection: principles and algorithms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Spirin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor Newsl</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="64" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A survey on unsupervised outlier detection in high-dimensional numerical data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat Anal Data Mining ASA Data Sci J</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="363" to="387" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Subspace clustering for high dimensional data: a review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor Newsl</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="105" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">152173</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Varian</surname></persName>
		</author>
		<author>
			<persName><surname>Imrt</surname></persName>
		</author>
		<ptr target="https://patient.varian.com/en/treatments/radiation-therapy/treatment-techniques" />
		<title level="m">Intensity Modulated Radiation Therapy)</title>
		<imprint>
			<date type="published" when="2020-06-26">26 June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sliding window-based fault detection from high-dimensional data streams</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Karim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Syst Man Cybern Syst</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="303" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">High-dimensional outlier detection: the subspace method</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Outlier analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="149" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">High-dimensional data analysis: the curses and blessings of dimensionality</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMS Math Chall Lect</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Outlier mining in large high-dimensional data sets</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pizzuti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="215" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Scalable and efficient outlier detection in large distributed data sets with mixed-type attributes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Koufakou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<pubPlace>Florida</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Central Florida</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Parallel outlier detection using kd-tree based on mapreduce</title>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cloud computing technology and science (CloudCom)</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distributed strategies for mining outliers in large data sets</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sartori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1520" to="1532" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An efficient algorithm for distributed density-based outlier detection on big data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="19" to="28" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Research issues in outlier detection for data streams</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gruenwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor Newsl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast and light boosting for adaptive mining of data streams</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia conference on knowledge discovery and data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="282" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast memory efficient local outlier detection in data streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vaithianathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3246" to="3260" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A survey on learning from data streams: current and future trends</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progr Artif Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="55" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Uncertain frequent itemsets mining algorithm on data streams with constraints</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on intelligent data engineering and automated learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="192" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mining high-speed data streams</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hulten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the sixth ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Elicitation of candidate subspaces in high-dimensional data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thudumu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Branch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 17th international conference on smart city; IEEE 5th international conference on data science and systems</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1995" to="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Estimation of locally relevant subspace in high-dimensional data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thudumu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Branch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian computer science week multiconference</title>
		<meeting>the Australasian computer science week multiconference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Densealert: Incremental dense-subtensor detection in tensor streams</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1057" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">S-hot: Scalable high-order tucker decomposition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM international conference on web search and data mining</title>
		<meeting>the Tenth ACM international conference on web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Subspace search and visualization to make sense of alternative clusterings in high-dimensional data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maaß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual analytics science and technology</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The plane with parallel coordinates</title>
		<author>
			<persName><forename type="first">A</forename><surname>Inselberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="91" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Smart brushing for parallel coordinates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>'cruze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Vis Comput Graph</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1575" to="1590" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evaluation of parallel coordinates: overview, categorization and guidelines for future research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Vis Comput Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="579" to="588" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph layouts by t-sne</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kruiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobourov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer graphics forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="283" to="294" />
			<date type="published" when="2017">2017</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">on lines and planes of closest fit to systems of points in space</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><surname>Liii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lond Edinb Dublin Philos Mag J Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="559" to="572" />
			<date type="published" when="1901">1901</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kruskal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Beyond the third dimension: visualizing high-dimensional data with projections</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Sci Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="98" to="107" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">FastMap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-I</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>ACM</publisher>
			<biblScope unit="volume">24</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A visual interaction framework for dimensionality reduction based data exploration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 chi conference on human factors in computing systems</title>
		<meeting>the 2018 chi conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">635</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">Maaten</forename><surname>Lvd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The curse of dimensionality in data mining and time series prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>François</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International work-conference on artificial neural networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="758" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Chelmsford</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Courier Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">When is &quot;nearest neighbor&quot; meaningful?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shaft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on database theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="217" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">High-dimensional data anomaly detection framework based on feature extraction of elastic network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning and intelligent communications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A fast outlier detection strategy for distributed high-dimensional data sets with mixed attributes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Koufakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georgiopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining Knowl Discov</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="289" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A fast multiscale framework for data in high-dimensions: measure estimation, anomaly detection, and compressive measurements</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual communications and image processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2012">2012 IEEE. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Finding clusters of different sizes, shapes, and densities in noisy, high dimensional data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ertöz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 SIAM international conference on data mining</title>
		<meeting>the 2003 SIAM international conference on data mining</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="47" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">High dimensional classification using features annealed independence rules</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Stat</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2605</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Large-scale manifold learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2008">2008. 2008. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Graph optimization for dimensionality reduction with sparsity constraints</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1205" to="1210" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Statistical independence and novelty detection with information preserving nonlinear maps</title>
		<author>
			<persName><forename type="first">L</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miesbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Quantifiable data mining using principal component analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Labrinidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kotidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaplunovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perkovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Automatic subspace clustering of high dimensional data for data mining applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gunopulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>ACM</publisher>
			<biblScope unit="volume">27</biblScope>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Ross</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0901.0537</idno>
		<title level="m">Nonlinear dimensionality reduction methods in climate data analysis</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">An algorithm for finding intrinsic dimensionality of data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Olsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Comput</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="176" to="183" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Geometric data analysis: an empirical approach to dimensionality reduction and the study of patterns</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kirby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Dimensionality reduction: a comparative</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Postma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Herik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="66" to="71" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A kernel view of the dimensionality reduction of manifolds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on machine learning</title>
		<meeting>the twenty-first international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">An intrinsic dimensionality estimator from near-neighbor information</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Pettis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Dubes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="37" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Manifold-adaptive dimension estimation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-Y</forename><surname>Audibert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on machine learning</title>
		<meeting>the 24th international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">On local intrinsic dimension estimation and its applications</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Hero</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Signal Process</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="650" to="663" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Danco: an intrinsic dimensionality estimator exploiting angle and norm concentration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ceruti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bassis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Casiraghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Campadelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2569" to="2581" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Data dimensionality estimation methods: a survey</title>
		<author>
			<persName><forename type="first">F</forename><surname>Camastra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2945" to="2954" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Regularized maximum likelihood for intrinsic dimension estimation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1203.3483.2012</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdiscip Rev Comput Stat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="459" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Generalized principal component analysis (GPCA)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1945" to="1959" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Esbensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Geladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemom Intell Lab Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">A tutorial on principal component analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.1100</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Local dimensionality reduction: a new approach to indexing high dimensional spaces</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<editor>VLDB. Citeseer</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="89" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Anomaly detection in big data with separable compressive sensing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 international conference on communications, signal processing, and systems</title>
		<meeting>the 2015 international conference on communications, signal processing, and systems</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="589" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">An introduction to compressive sampling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Wakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process Mag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">An entropy weighting k-means algorithm for subspace clustering of high-dimensional sparse data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1026" to="1041" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Outlier analysis</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="237" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Comparing subspace clusterings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Patrikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="902" to="916" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Clustering high-dimensional data: a survey on subspace clustering, pattern-based clustering, and correlation clustering</title>
		<author>
			<persName><forename type="first">H-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Knowl Discov Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Feature bagging for outlier detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lazarevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh ACM SIGKDD international conference on knowledge discovery in data mining</title>
		<meeting>the eleventh ACM SIGKDD international conference on knowledge discovery in data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Evaluating clustering in subspace projections of high dimensional data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1270" to="1281" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">An angle-based subspace anomaly detection approach to high-dimensional data: with an application to industrial fault detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Karim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliab Eng Syst Saf</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="482" to="497" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Projected outlier detection in high-dimensional mixed-attributes data set</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Orlowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="7104" to="7113" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">An approach to outlier detection and smoothing applied to a trajectography radar data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Júnior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pires</forename><surname>Psdm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Aerosp Technol Manage</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="248" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Geometric representation of high dimension, low sample size data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J R Stat Soc Ser B Stat Methodol</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="427" to="444" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The high-dimension, low-sample-size geometric representation holds under mild conditions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Y</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="760" to="766" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">On the surprising behavior of distance metrics in high dimensional space</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hinneburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on database theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="420" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Hics: high contrast subspaces for density-based outlier ranking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bohm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1037" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">The concentration of fractional distances</title>
		<author>
			<persName><forename type="first">D</forename><surname>Francois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Wertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="873" to="886" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">The role of hubness in clustering high-dimensional data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tomasev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Radovanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mladenic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ivanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="739" to="751" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Reverse nearest neighbors in unsupervised distance-based outlier detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Radovanović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ivanović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1369" to="1382" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Big data dimensional analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gadepally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kepner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High performance extreme computing conference (HPEC)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Streaming data integration: challenges and opportunities</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tatbul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">D-cube: Dense-block detection in terabyte-scale tensors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM international conference on web search and data mining</title>
		<meeting>the tenth ACM international conference on web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="681" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Parallel mining of outliers in large database</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distrib Parallel Database</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="26" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Algorithms for mining distancebased outliers in large datasets</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Knox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on very large data bases</title>
		<meeting>the international conference on very large data bases</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="392" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Efficient algorithms for mining outliers from large data sets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigmod record</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="427" to="438" />
			<date type="published" when="2000">2000</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Very efficient mining of distance-based outliers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fassetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="791" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">A linear method for deviation detection in large databases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="164" to="169" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Scalable clustering: a distributed approach</title>
		<author>
			<persName><forename type="first">P</forename><surname>More</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fuzzy systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="143" to="148" />
			<date type="published" when="2004">2004. 2004. 2004</date>
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Tackling the big data 4 vs for anomaly detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Camacho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Macia-Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Diaz-Verdejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Garcia-Teodoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer communications workshops (INFOCOM WKSHPS), 2014 IEEE conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="500" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Monitoring streams: a new class of data management applications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Çetintemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cherniack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Convey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seidman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tatbul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on very large data bases. VLDB endowment</title>
		<meeting>the 28th international conference on very large data bases. VLDB endowment</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="215" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Models and issues in data stream systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Babcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first ACM SIGMOD-SIGACT-SIGART symposium on principles of database systems</title>
		<meeting>the twenty-first ACM SIGMOD-SIGACT-SIGART symposium on principles of database systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Research issues in data stream association rule mining</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gruenwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigmod Rec</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="19" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">The 8 requirements of real-time stream processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Çetintemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zdonik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigmod Rec</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="47" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Research issues in mining multiple data streams</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gruenwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first international workshop on novel data stream pattern mining techniques</title>
		<meeting>the first international workshop on novel data stream pattern mining techniques</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="56" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Data stream clustering: a survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Faria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput Surv</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Detecting distance-based outliers in streams of data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fassetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixteenth ACM conference on conference on information and knowledge management</title>
		<meeting>the sixteenth ACM conference on conference on information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Detecting outlying properties of exceptional objects</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fassetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Palopoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Database Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Continuous monitoring of distance-based outliers over data streams</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kontaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gounaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsichlas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Birch: an efficient data clustering method for very large databases</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigmod record</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="103" to="114" />
			<date type="published" when="1996">1996</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Bias, variance, and arcing classifiers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">The strength of weak learnability</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="227" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Online bagging and boosting</title>
		<author>
			<persName><forename type="first">Oza</forename><surname>Nikunj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth international workshop on artificial intelligence and statistics</title>
		<editor>
			<persName><forename type="first">Jaakkola</forename><surname>Tommi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Richardson</forename><surname>Thomas</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">New ensemble methods for evolving data streams</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kirkby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gavaldà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="139" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">A framework for generating data to simulate changing environments</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Narasimhamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence and applications</title>
		<imprint>
			<biblScope unit="page" from="415" to="420" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Learning from time-changing data with adaptive windowing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gavalda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 SIAM international conference on data mining</title>
		<meeting>the 2007 SIAM international conference on data mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="443" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Learning with drift detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Medas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brazilian symposium on artificial intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Evaluation of multiclass novelty detection algorithms for data streams</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>De Faria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Goncalves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Acp</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2961" to="2973" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Computational solutions to large-scale data management and analysis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Schadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sorenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Genet</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">647</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Luengo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>García-Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramírez-Gallego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Big data preprocessing</note>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Hadoop</surname></persName>
		</author>
		<ptr target="https://hadoop.apache.org/" />
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Storm</surname></persName>
		</author>
		<ptr target="https://storm.apache.org/" />
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Spark</surname></persName>
		</author>
		<ptr target="https://spark.apache.org/" />
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Flink</surname></persName>
		</author>
		<ptr target="https://flink.apache.org/" />
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Apache</forename><surname>Mxnet</surname></persName>
		</author>
		<ptr target="https://mxnet.apache.org/" />
		<imprint>
			<date type="published" when="2020-02-14">14 Feb 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">A comparison on scalability for batch big data processing on apache spark and apache flink</title>
		<author>
			<persName><forename type="first">D</forename><surname>García-Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramírez-Gallego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data Anal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Fast parallel outlier detection for categorical datasets using mapreduce</title>
		<author>
			<persName><forename type="first">A</forename><surname>Koufakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Secretan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georgiopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international joint conference on neural networks (IEEE world congress on computational intelligence)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="3298" to="3304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Bigsam: mining interesting patterns from probabilistic databases of uncertain big data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ck-S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mackinnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia conference on knowledge discovery and data mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="780" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Mining sequential patterns from uncertain big DNA in the spark framework</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Sarumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE international conference</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="874" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Big data analytics for network anomaly detection from netflow data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagiroglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International conference on computer science and engineering (UBMK)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="592" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on apache storm</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese automation congress (CAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="2399" to="2404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Anomaly proposal-based fire detection for cyber-physical systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Abeyrathna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P-C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International conference on computational science and computational intelligence (CSCI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1203" to="1207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Toliopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gounaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsichlas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sampaio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07901</idno>
		<title level="m">Continuous outlier mining of streaming data in flink</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Log summarization and anomaly detection for troubleshooting distributed systems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Tierney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Swany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bresnahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Schopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grid computing</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Multiaspectforensics: mining large heterogeneous networks using tensor</title>
		<author>
			<persName><forename type="first">K</forename><surname>Maruhashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Web Eng Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="302" to="322" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Joint European conference on machine learning and knowledge discovery in databases</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="264" to="280" />
		</imprint>
	</monogr>
	<note>M-zoom: fast dense-block detection in tensors with quality guarantees</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Bounding graph fraud in the face of camouflage</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><surname>Fraudar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="895" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Spotting suspicious behaviors in multimodal data: a general metric and algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2187" to="2200" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Gpu strategies for distance-based outlier detection</title>
		<author>
			<persName><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sartori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Parallel Distrib Syst</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3256" to="3268" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Parallel outlier detection on uncertain data for gpus. Distrib Parallel Databases</title>
		<author>
			<persName><forename type="first">T</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="417" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Parallel algorithms for distance-based and density-based outliers</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Acufia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data mining</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Distributed anomaly detection using minimum volume elliptical principal component analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gluhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Imran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2320" to="2333" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Mapreduce: simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Clustering very large multidimensional datasets with mapreduce</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Ferreira Cordeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Traina</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Machado</forename><surname>Traina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 17th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="690" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">A survey on geographically distributed big-data processing using mapreduce</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dolev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gudes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Singer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01869.2017</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Apache spark: a unified engine for big data processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wendell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Armbrust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dave</forename><forename type="middle">A</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Mllib: machine learning in apache spark</title>
		<author>
			<persName><forename type="first">X</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sparks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Owen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1235" to="1241" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Dynamically scaling apache storm for the analysis of streaming data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Van Der Veen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Der Waaij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lazovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wijbrandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Meijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE first international conference on big data computing service and applications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Apache flink: stream analytics at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Katsifodimos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schelter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on cloud engineering workshop (IC2EW</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page">193</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Apache flink: stream and batch processing in a single engine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Carbone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katsifodimos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ewen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Markl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tzoumas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull IEEE Comput Soc Tech Comm Data Eng</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
