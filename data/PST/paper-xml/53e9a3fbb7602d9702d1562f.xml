<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Acquisition of Categorized Named Entities for Web Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Marius</forename><surname>Pas</surname></persName>
							<email>mars@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Inc</orgName>
								<address>
									<addrLine>1600 Amphitheatre Parkway Mountain View</addrLine>
									<postCode>94043</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Acquisition of Categorized Named Entities for Web Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8142094181ECC31F96CCC17E3384D978</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: Information Search and Retrieval-search process</term>
					<term>H.3 [Information Storage and Retrieval]: Online Information Services-Web-based services</term>
					<term>I.2 [Artificial Intelligence]: Natural Language Processing-text analysis</term>
					<term>I.2 [Artificial Intelligence]: Learning-knowledge acquisition Algorithms, Experimentation Web information retrieval, lightweight text processing, named entity extraction, related names and categories, information integration</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recognition of names and their associated categories within unstructured text traditionally relies on semantic lexicons and gazetteers. The amount of effort required to assemble large lexicons confines the recognition to either a limited domain (e.g., medical imaging), or a small set of predefined, broader categories of interest (e.g., persons, countries, organizations, products). This constitutes a serious limitation in an information seeking context. In this case, the categories of potential interest to users are more diverse (universities, agencies, retailers, celebrities), often refined (e.g., SLR digital cameras, programming languages, multinational oil companies), and usually overlapping (e.g., the same entity may be concurrently a brand name, a technology company, and an industry leader). We present a lightlysupervised method for acquiring named entities in arbitrary categories. The method applies lightweight lexico-syntactic extraction patterns to the unstructured text of Web documents. The method is a departure from traditional approaches to named entity recognition in that: 1) it does not require any start-up seed names or training; 2) it does not encode any domain knowledge in its extraction patterns; 3) it is only lightly supervised, and data-driven; 4) it does not impose any a-priori restriction on the categories of extracted names. We illustrate applications of the method in Web search, and describe experiments on 500 million Web documents and news articles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION 1.1 Problem</head><p>Within the general goal of information retrieval -finding the documents that are relevant to a user's information need -Web retrieval must cope with additional complications in terms of user input and output. On the input side, users submit queries that usually contain a small number of words. On the output side, there are quantitative limits since most users actually inspect only the first few documents in the search result set <ref type="bibr" target="#b15">[15]</ref>. The combination of these two constraints makes the Web retrieval problem analogous to finding the proverbial needle in the haystack, where the haystack consists of billions of items (Web documents) and the needle is a set of a few (most-relevant) documents.</p><p>When looking closer at the unstructured text in documents and users' queries, it is apparent that terms and phrases are not all equal. Beyond measurements like document frequencies or term proximity, the occurrence of named entities signals prominent pieces of information. Often, users will search for lists of names through queries such as Middle Eastern countries (or Islamic nations), races (or sports events), movies (or home video releases). Even more often, searches refer to popular names such as Paris, Kentucky Derby or Harry Potter, as indicated by the frequent occurrence of such names among the top search engine queries. In other cases, users might search for unfamiliar rather than popular names to address more basic information needs, e.g. figuring out what kind of name they are dealing with (could it be a reptile; a modern programming language; or a Greek dragon?). As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, our haystack of documents can be then considered from a different perspective: that of a goldmine that "hides" valuable information nuggets about various names, including nuggets that encode their categories.</p><p>Traditionally, the recognition of names and their associated categories within unstructured text relies on semantic lexicons and gazetteers. The amount of effort required to assemble large lexicons sometimes confines the recognition  to a limited domain (e.g., medical imaging) for which largecoverage resources already exist. Alternatively, the recognition is limited to a small set of broader, pre-defined categories of interest, e.g. persons, countries, organizations and products. This latter alternative has become the de-facto standard after its introduction in the Message Understanding Conference <ref type="bibr" target="#b6">[6]</ref>. For many information and language processing tasks, such a coarse-grained set of categories is appropriate. It may become a serious limitation, however, in an information seeking context, especially in Web search. In this case, the categories of potential interest to users are more diverse (universities, agencies, retailers, celebrities) and more refined (e.g., SLR digital cameras, programming languages, multinational oil companies). Moreover, the categories are usually overlapping since the same instance may be concurrently a brand name, a technology company, a storage provider, and an industry leader. Ideally, the target instance should be retrieved consistently regardless of which of the legitimate categories is used in a particular query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Approach</head><p>In this paper, we present a lightweight, lightly-supervised method for acquiring named entities in arbitrary categories from Web documents. In the trade-off between method complexity and output coverage, we opted from the start for low complexity. The method is purposely designed to be simple, and thus handle robustly the noise and diversity of Web documents. We focus on textual content rather than structural clues. Shallow lexico-syntactic extraction patterns are applied to the unstructured text of Web documents and Web news articles. Overall, the method is a departure from traditional approaches to named entity recognition in several respects. First, there is no need for training that would pro-vide extraction rules or knowledge about specific categories of names. Second, the method does not require any initial clues or seed names, which would otherwise have to be specified for each category. Third, the extraction patterns do not encode any domain knowledge, which avoids any restriction to a given domain. Furthermore, the method is only lightly supervised, and data-driven. Lastly, it does not impose any a-priori restriction on the categories of extracted names.</p><p>The remainder of the paper is structured as follows. Section 2 illustrates the process of derivation of categorized names from unstructured text. The categorized names can be loosely integrated into existing knowledge resources as shown in Section 3. They also enable several Web search applications, which are described in Section 4. Section 5 presents evaluation results for the extraction method on 12 million Web news articles and 500 million Web documents. After further discussion in Section 6, we glance at future work in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EXTRACTING CATEGORIZED NAMES</head><p>In this section, we introduce a lightweight method for identifying names and their categories within unstructured text. The input consists of a small set of domain-independent, lexico-syntactic patterns. The output is a set of names with their corresponding categories as derived from arbitrary Web documents. As shown in later sections, these kinds of simple methods, when applied to large amounts of data, can open the path towards novel applications to Web search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lightweight Extraction Method</head><p>The extraction is a three-step process consisting of document pre-processing, extraction of categorical facts, and derivation of categories. To ensure robustness on large collections, the extraction relies on minimal tools and resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Document Pre-Processing</head><p>After filtering out HTML tags, the input documents are tokenized, split into sentences and part-of-speech tagged using the TnT tagger <ref type="bibr" target="#b2">[2]</ref>. The tags are only used in the last step to derive the name categories. Languages such as English distinguish proper names from other nouns through capitalization. Therefore each sequence of capitalized terms in the sentence is marked as a potential instance name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Extraction of Categorical Facts</head><p>The presence of potential instance names and simple lexicosyntactic patterns in sentences, inspired by <ref type="bibr" target="#b14">[14]</ref>, is interpreted as a signal of a categorical fact associated with the name. A categorical fact is a sentence nugget that is likely to provide explicitly the category of the associated instance name. The fact and associated instance name are captured with a set of patterns which can be summarized as:</p><p>[StartOfSent] X [such as|including] N [and|,|.] , where N is the potential instance name and X is the categorical fact. The matching of the patterns in the sentences results in pairs (X,N ) of categorical facts and instance names, which are underlined the sample sentence "That is because software firewalls, including Zone Alarm , offer some semblance of this feature". All potential instance names that are not associated with a categorical fact are discarded. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Derivation of Data-Driven Categories</head><p>In the final step, the categorical facts X of the pairs (X,N ) are searched for the noun phrase which encodes the category of the associated name. This phrase is approximated by the rightmost non-recursive noun phrase whose last component is a plural-form noun. While such a coarse approximation would cause certain complex categories to be missed on small collections, it is more scalable to millions of Web documents since it avoids complications related to deeper text understanding, e.g. prepositional phrase attachments. One of the following situations may occur as illustrated in Table 1: 1) No plural-form noun phrase exists near the end of the categorical fact; the pair (X,N ) is discarded; 2) A pluralform noun phrase exists near the end of the categorical fact, but it is immediately (e.g., within 5 tokens) preceded by another plural-form noun phrase; the pair (X,N ) is discarded; 3) Otherwise, the noun phrase is retained as the lexicalized category of the instance name N . Note that one of the categories selected in Table <ref type="table" target="#tab_1">1</ref> is programming languages rather than other programming languages. Non-informative adjectives like other, several, or many are among the Top-20 most-frequent modifiers computed statistically in a postprocessing phase over the entire set of categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extensions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Extraction of Similar Names</head><p>Textual enumerations offer an inexpensive way of extracting multiple, rather than single, categorized names from a given categorical fact. To support multiple-name extraction, the patterns are slightly modified to match enumerations (N1[,N2,. . . and Nm]) in addition to single names (N ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Automatically-Derived Patterns</head><p>Even though the basic method is mostly unsupervised and does not require any clues to start up, it does rely on manually-selected patterns. A logical extension is the identification of additional patterns to increase coverage, i.e. the number of categorized pairs.  The results in Table <ref type="table" target="#tab_2">2</ref> show that, in addition to "recovering" the initial InnerP atterns ("such as" and "including"), the top automatically-derived patterns also "uncover" other useful matches ("and other"; "include"; and "are"). The process continues with a next iteration, in which the new set of patterns generates an expanded set of categorized names, which in turn can be used iteratively to generate another set of potential patterns, as suggested in <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b23">23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CATEGORIZED NAMES AS LEXICAL KNOWLEDGE</head><p>Each categorized name corresponds to an InstanceOf assertion between the name and the category, where the latter is a lexical concept. This section describes the use of the assertions to find related categories, and also to expand existing knowledge resources.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Category Relatedness as Set Overlap</head><p>Ideally, an IsA semantic relation between two categories will be reflected in their sets of instance names, one of which will completely include the other. However, in practice the instance name sets are partial rather than complete. Their overlap, or lack thereof, is no longer a pure reflection of the inter-category relations. On the positive side, overlaps between two sets still indicate a strong relation between the corresponding categories. In fact, set overlap will sometimes reveal something that formal knowledge resources may fail to capture, i.e. category relatedness.</p><p>Figure <ref type="figure" target="#fig_3">3</ref> illustrates categories identified as related based on their set overlap. All categorized names were actually extracted from Web documents, even though only a subset of them is included in the figure for clarity. Empty or very small overlaps correspond to categories that are not directly related. 1 This is the case for languages and search engines, for instance. Medium or large-sized overlaps indicate related categories, e.g. search engines and Internet portals, or search engines and software companies. In some cases, the overlap is complete in the sense of set inclusion. The corresponding categories are classified one under the other, e.g. high-level programming languages and programming languages, or programming languages and languages. But how does this compare to what other knowledge resources encode already? WordNet <ref type="bibr" target="#b11">[11]</ref> is among resources that have been widely studied in the context of information retrieval <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b12">12]</ref>. WordNet is a lexical database which organizes English lexical concepts along several semantic relations. For our example, WordNet explicitly encodes that a programming language is a subconcept (or hyponym, in WordNet terminology) of language. However, WordNet does not encode 1 Instance names that concurrently denote objects of different types, e.g. Orange (in companies, counties, cities) and Taj Mahal (famous buildings and musicians), produce small overlaps that should be ignored. any of the other relatedness relations mentioned above. In fact, software companies, Internet portals and high-level programming languages do not have any corresponding concept in WordNet. This makes the categorized names a useful addition to various knowledge resources, as discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Integration into Existing Knowledge Resources</head><p>An immediate extension to any knowledge resources that organize English concepts hierarchically is to map (some of) the extracted names into new InstanceOf assertions. In the case of WordNet and other similar resources, the new assertion corresponds to a new instance node being linked to an existing node at the bottom of the hierarchies. For example, the categorized names Google (in the category search engines), Swiss National Bank (in central banks), Joschka Fischer (in foreign ministers) and State Farm (in insurance companies) each generates a new leaf node inserted under the WordNet concepts search engine, central bank, foreign minister and insurance company respectively. The process is straightforward only if there is exactly one possible insertion point, i.e. the name belongs to exactly one category, the category matches exactly one WordNet concept (after reduction of the category to its base, singular form), and the latter is a leaf node. <ref type="foot" target="#foot_0">2</ref> In the general case, however, the name belongs to multiple categories, each of which matches zero, one, or multiple WordNet concepts. For example, the category European companies does not match any WordNet concept, whereas the category rappers matches two Word-Net concepts (one with the sense of artists, the other with the sense of knocking devices).</p><p>The conservative insertion algorithm shown in Figure <ref type="figure">4</ref> Input links a name to at most one WordNet concept. 3 Initially, the algorithm matches each category of the input name against WordNet concepts. If a category does not match any WordNet concept, its modifiers are discarded until one or more matches are found. Thus, high-level programming languages, Internet portals and science fiction writers match the WordNet concepts programing language, portal, and writer respectively. For each explicit match into a WordNet concept, there is an implicit match into each of its hyponyms, i.e. concepts in the hierarchy rooted at the matching Word-Net concept. For instance, the explicit match of languages to language entails implicit matches to artificial language, natural language, Indo-European language and so forth. The algorithm selects as insertion point the WordNet leaf concept with the highest number of matches over all categories.</p><p>In case of ties, the least-general unifying concept is selected. The algorithm in Figure <ref type="figure">4</ref> introduces only InstanceOf assertions via the inserted instance names. The hierarchical structures are otherwise preserved. The alternative is to create intermediate concepts as well, which may be missing due to the fact that WordNet is a general-purpose resource that does not aim at fully representing specialized domains <ref type="bibr" target="#b11">[11]</ref>. Intermediate concepts, e.g. software company, high-level programming language act as a middle layer between existing concepts (companies, programming languages) and newly acquired names. Their introduction brings additional complications in terms of consistency (is a search engine a kind of engine or rather a kind of company?) and coverage (what other concepts besides high-level programming language form 3 A more relaxed insertion would insert a name under several WordNet concepts, based on a confidence threshold. a partition over programming language?). On the other hand, the simplifying factor in tackling intermediate concepts is precisely their reliance on the sets of names acquired from Web documents. Each name in the category is equivalent to an anonymous, democratic vote that the category actually corresponds to a useful concept that collectively represents the properties of its members. From this point of view, red car or tall company are less useful or improbable concepts since the Web as a decentralized knowledge repository provides little or no evidence for them. <ref type="foot" target="#foot_1">4</ref>Besides InstanceOf assertions, category relatedness represents another piece of knowledge to integrate in other resources. While less formal and reliable, the knowledge that search engines and Internet portals, or storage providers and companies are related is certainly helpful. Each pair of related categories is represented as an additional RelatedT o link in the existing hierarchical structure. Resources enriched with RelatedT o links become more useful in linguisticoriented applications that search for loose rather than strict relations among pairs of concepts. For example, any application computing lexical chains <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b27">27]</ref> among words, phrases or concepts can use the RelatedT o links as the main raw material in the identified lexical chains. The RelatedT o links are equally useful for query expansion, or suggestions for query refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">APPLICATIONS TO WEB SEARCH</head><p>The categories of names acquired offline from the Web offer an alternative view of the underlying documents -one that transcends document boundaries through the extraction of knowledge captured collectively within disparate document sentences. The names provide enhancements to the search results returned to users' queries, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Processing List-Type Queries</head><p>Let us consider a scenario involving a medical school student. Once she collects lab data, the user would like to find out how to process it automatically. Her next possible action is to submit a query such as statistical packages or statistical package to a Web search engine. The user has no previous experience with any such package. Therefore the set of the most representative software packages available constitutes a very desirable output from the search engine. In this and other scenarios, users search for lists of items by typing their category; other examples of list-type queries are RISC processors or Clinton administration officials.</p><p>To support list-type queries, when the input query matches a known category, the search results also include the top (i.e., most frequent) names as representative elements of that category. For instance, SAS, SPSS, Minitab and BMDP are returned in addition to the top documents for the query statistical packages. Similarly, National Security Adviser Sandy Berger, Vice President Al Gore and Madeleine K. Albright are returned for Clinton administration officials. Thus, categorized names supplement the regular search results for list-type queries.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Retrieval of Siblings</head><p>As mentioned earlier, a significant fraction of search engine logs are direct queries for names. Sometimes the queries refer to names that are completely unknown to the users, who want to find out about them. Concurrently, it is often the case, that the user is already familiar with other similar names. One who searches for Kazaa or Bengali may know already about the similar names Napster or Hindi. Retrieval of similar names, or sibling names, generally anchors the name into a set of possibly-known names, thus guiding the users in their search.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> illustrates the top siblings retrieved from Web news articles for the names Kazaa and Bengali. The rank of a sibling is inversely proportional to its frequency of cooccurrence in the same category as the name being asked about. In the example, the frequency is converted to a threshold-based, three-valued reliability metric (high, medium and low). Note that siblings span across categories, e.g. Tamil is one of the Indian languages whereas Russian is one of the other languages besides Bengali. Table <ref type="table" target="#tab_4">3</ref> shows other ranked siblings, which are extracted from Web documents rather than news articles.</p><p>From a user perspective, very small output sets might fail to anchor the input name. For instance, if the user is unaware what Vodafone is, and only one sibling is returned for it, namely Orange, the output has little use since Orange belongs simultaneously in companies, counties, cities etc. The addition of other, less-ambiguous siblings to the result set will provide the necessary disambiguation context. A similar problem occurs when the input name itself is ambiguous, e.g. the user searches for Orange. Since currently the siblings are retrieved across categories, the siblings of the most frequent category of that name are promoted to the detriment of the other siblings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Query Refinement Suggestions</head><p>In the query refinement application, the goal is to suggest a few related queries, based on the analysis of the current query and its relationships with the acquired names and categories. Therefore query refinement suggestions have the potential of affecting both names and categories. If the query is a known name or a known category, a set of related queries is generated and offered to the user as suggestions for refinement. This is in contrast with list-type queries and retrieval of siblings, which operate on input that matches either categories or names.</p><p>If the input query is a known name, each related query consists of the name and one of its categories. Since a name may belong to many categories, a key issue is to decide which categories are the most representative. We use a ranking criterion that is complementary to the case of list-type queries, where the most representative names in a category are those names that are the most frequently found to belong to that category. For query refinement, the most representative categories for a name are those that are the most frequently found to contain that name. For illustration, according to the set of categorized names that we acquired in an experiment from Web documents, the 10 most representative categories for Orange are in order: counties, operators, areas, companies, cities, topics and flavors, brands, organizations and colors. Therefore the top 10 related queries suggested when the user types "Orange" would be "Orange county", "Orange operator", "Orange area", "Orange company", . . ., "Orange color".</p><p>When the input query is a known category (up to base form normalization), each related query consists of a category that is RelatedT o it. As discussed in Section 3, the concept of category relatedness builds upon the overlap of the instance sets. The overlap is measured by the cardinality of the set intersections relatively to the whole sets. The categories with the highest overlap are the most representative and therefore included in the related queries. The exception handles the high-overlap related categories that are more general based on simple lexical comparison. For illustration, this is the case for companies given software companies, or cities given California cities. Such more-general categories are deemed as useless and discarded from the set of query refinement suggestions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>The experiments are performed on two document collections. They contain Web news articles (NewsData) and Web documents (WebData) respectively (see Table <ref type="table" target="#tab_5">4</ref>).</p><p>The news articles in NewsData are part of the Google News repository; they span from April 2003 until January 2004. The Web documents in WebData are a random selection from a snapshot of the Google index taken last year.</p><p>All documents are in English. Only the textual part of the documents is considered; everything else is ignored. Note that, on average, news articles are cleaner and more reliable than Web documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Table <ref type="table" target="#tab_6">5</ref> illustrates a few of the acquired categories and their instance names from Web documents. In the case of hybrid cars, the displayed set of instances is complete; for the others, only the top subset is shown. Instance names are ranked in decreasing order of their frequency within the given category. Thus, Black, Los Angeles and Linux have the highest frequency for colors, California cities and operating systems respectively. Intuitively, more general categories like cities capture larger sets of instance names than California cities. This was discussed and illustrated earlier in Figure <ref type="figure" target="#fig_3">3</ref>. The results in Table 6 confirm the intuition on both NewsData and WebData. Companies are one of the important categories, followed by players in NewsData and preceded by people in WebData.</p><p>Table <ref type="table" target="#tab_8">7</ref> shows a view opposite to Table <ref type="table" target="#tab_7">6</ref>, that is, instance names that belong to many categories, rather than categories with many instance names. In the WebData collection, the ubiquitous Internet is the instance name associated with the highest number of categories.</p><p>Among the top categories in Table <ref type="table" target="#tab_8">7</ref>, clients and vendors share a common property. Rather than (or in addition to) acting as regular class holders for their instance name sets, they also encode "invisible" functional relations to other instance names. Indeed, a vendor is a vendor of something (e.g., a certain product). Similarly, a client could be a client of a given company. This corresponds to the notion of functions from a constant to another in first-order logic <ref type="bibr" target="#b24">[24]</ref>. When abstracting away from unstructured text to categorized names, these kinds of functional relations are lost. Due to the diversity of the acquired categories, we do not currently have a complete qualitative evaluation in terms of precision and recall of all acquired names. Incipient evaluations indicate an average precision of 88%. The precision was computed over the top 50 instance names (or all names, if less than 50) of 20 randomly-selected, compound-noun categories. Examples of errors are Singapore categorized in European capitals, and Dr. Dean Ornish in medical fields. We plan to perform further evaluations of categories against other resources, e.g., gazetteers for categories that are of geographical nature.</p><p>The ranking induced by category size depends on the data source. For example, California cities are the 1184 th (News-Data) and 8220 th (WebData) largest category. Figure <ref type="figure">6</ref> illustrates the distribution of the largest categories according to the cardinality of their sets of unique instance names.</p><p>As the extraction method progresses through a new chunk of texts, some of the category-name pairs (C, N ) that it en-  <ref type="table" target="#tab_9">8</ref> shows the percentage of unique items (pairs, categories or names) acquired from a new chunk of documents, that were not already acquired from previous chunks. For example, 16% of the unique pairs acquired from the fourth chunk were already seen in the previous chunks (1 through 3). The numbers are higher in the case of the names and categories that were already seen, with 39% and 35%. Over all NewsData chunks, Table <ref type="table" target="#tab_9">8</ref> suggests that the percentage of unseen instances decreases asymptotically. However, it is unclear whether the process would saturate over a News collection that would be larger by several orders of magnitude. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">PREVIOUS WORK</head><p>The importance of semantic lexicons and lists of names has been recognized in many text processing tasks such as prepositional attachment <ref type="bibr" target="#b3">[3]</ref> and coreference resolution <ref type="bibr" target="#b18">[18]</ref>. More importantly, many named entity recognizers traditionally rely on lists of names <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b19">19]</ref>. The lists are compiled by humans, or assembled from authoritative sources. It is also possible to build recognizers that identify names automatically in text <ref type="bibr" target="#b7">[7,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b26">26]</ref>. As opposed to the method presented in this paper, such approaches usually attempt to learn general categories such as persons, organizations, rather than refined categories. They also use a closed, pre-specified set of categories of interest, as a result of both explicit and implicit restrictions. In the first case, the training data introduces explicit restrictions. In the second case, it is the set of seed names, typically used in previous approaches, which introduces implicit restrictions on the acquired categories. Comparatively, we use an initial set of domain-independent patterns which leads to arbitrary categories.</p><p>In order to process natural language robustly, a variety of previous approaches apply lightweight techniques to unrestricted text <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b20">20]</ref>. In <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b14">14]</ref> and other work, it is shown that patterns are useful for acquiring IsA and InstanceOf information from unstructured text. Similarly, we focus on unstructured text as the source of our categorized names. Structural information such as Html tags in Web documents offer a different means of extracting the same kind of relations <ref type="bibr" target="#b25">[25]</ref>. The organization of acquired relations into larger structures <ref type="bibr" target="#b5">[5]</ref>, and the more ambitious objective of constructing knowledge bases from the Web, lead to projects like WebKB <ref type="bibr" target="#b8">[8]</ref> and more recently <ref type="bibr" target="#b10">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>The Web as a whole represents a huge repository of human knowledge. Most of the Web knowledge is not readily available in clean, structured, non-ambiguous form. Instead, it is encoded implicitly and scattered across billions of textual documents. This paper presented a lightly supervised method for accessing, decoding and exploiting a very small part of the information that Web texts wear on their sleeves. We showed that lightweight text processing techniques make it possible to acquire a very broad range of categorized instance names from unstructured text. The collected categories of names effectively fuse and summarize semantic relations detected within initially-isolated documents. In addition to enhancing existing knowledge resources, the acquired categorized names also enable novel Web search applications.</p><p>In our experiments, word capitalization was the only clue used to detect possible names in text. The simplicity of this heuristic cannot cover names containing numbers, for instance 7 Eleven and 49ers. In addition, the heuristic does not generalize to other languages where capitalization alone cannot distinguish between common and proper nouns, e.g. German. To increase precision and recall, we will explore other clues for finding candidate names, as well as a fullfledged iterative learning algorithm for detecting contextual extraction patterns. Some of the semantics of each data-driven category is captured by its instance names. A direction to explore further is the recovery followed by discovery of relations among categories, based on the analysis of their sets of instance names. The relation recovery exploits existing resources to analyze the sets of instance names, e.g. for countries and nations which are known to be sometimes synonymous, or African countries and countries which are known to be in an IsA relation. The relation discovery then identifies relations among previously-unknown categories within unstructured text, e.g. a possible relation between non-steroidal anti-inflammatory drugs and herbal medicines. In a parallel effort, it will be useful to assess the strength of the relations, e.g. to what degree a category is RelatedT o another.</p><p>The extraction patterns used in the paper focus on categorical facts. These facts usually capture the genus of the category to which an instance name belongs, e.g. Prius is an instance of cars. An equally useful piece of information would be the differentia. The differentia can be extracted from unstructured text with a different set of patterns, leading to descriptive rather than categorical facts. Examples of descriptive facts for Prius are "uses a combination gasoline and electric engine" and "runs on electricity and petrol". Descriptive facts are a source of definitions when inserting names in existing knowledge resources like WordNet. In addition, the combination of descriptive and categorical facts is a step towards building large networks of interconnected categories, instance names and their associated facts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Names (middle layer) and their categories (lower layer) are hidden within the unstructured text of Web documents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 Figure 2 :</head><label>22</label><figDesc>Figure 2: Acquisition of extraction patterns from unstructured Web documents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Scheme</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Instance set overlap indicates related categories</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5</head><label>5</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Top sibling names of Kazaa and Bengali</figDesc><graphic coords="6,54.60,54.27,115.64,200.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>8 Figure 6 :</head><label>86</label><figDesc>Figure 6: Frequency distribution of categories acquired from WebData</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 : Selection of categories from categorical facts</head><label>1</label><figDesc></figDesc><table><row><cell>Categorical fact and instance name</cell><cell>Selection</cell></row><row><cell>Anti-GMO food movements sprouted up</cell><cell>Discard</cell></row><row><cell>in European nations in the 1990s,</cell><cell></cell></row><row><cell>including Germany</cell><cell></cell></row><row><cell>Our customers' chipsets compete with</cell><cell>Discard</cell></row><row><cell>products from other vendors of standards-</cell><cell></cell></row><row><cell>based and ADSL chipsets, including Alcatel</cell><cell></cell></row><row><cell>The venture is supported by a number</cell><cell>Retain</cell></row><row><cell>of academics, including Noam</cell><cell>(academics,</cell></row><row><cell>Chomsky</cell><cell>Noam Chomsky)</cell></row><row><cell>API Adapter can be written in other</cell><cell>Retain</cell></row><row><cell>programming languages such as C++</cell><cell>(programming</cell></row><row><cell></cell><cell>languages, C++)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 : Ranked contextual patterns acquired from text</head><label>2</label><figDesc>Table2shows the Top-15 patterns ranked according to their frequency. In this experiment, Lef tContext and RightContext are defined by the part of speech tags of at most 5 terms in the same sentence. Comparatively, InnerP attern is defined by the actual words and their tags.</figDesc><table><row><cell>Lef tContext</cell><cell cols="2">InnerP attern RightContext</cell></row><row><cell>(POS tags)</cell><cell>(words)</cell><cell>(POS tags)</cell></row><row><cell>StartOfSent</cell><cell>such as b</cell><cell>, NNP NNP , NNP</cell></row><row><cell>, NNP , NNP ,</cell><cell>and other a</cell><cell>. EndOfSent</cell></row><row><cell>IN NNP , NNP ,</cell><cell>and other a</cell><cell>. EndOfSent</cell></row><row><cell>StartOfSent</cell><cell>such as b</cell><cell>, NNP NNP CC NNP</cell></row><row><cell cols="2">NNP NNP , NNP , and other a</cell><cell>. EndOfSent</cell></row><row><cell>StartOfSent</cell><cell>such as b</cell><cell>, NNP CC NNP VBP</cell></row><row><cell>StartOfSent</cell><cell>such as b</cell><cell>, NNP , NNP ,</cell></row><row><cell>StartOfSent</cell><cell>, including b</cell><cell>, NNP NNP , NNP</cell></row><row><cell>StartOfSent IN</cell><cell>such as b</cell><cell>, NNP NNP , NNP</cell></row><row><cell>StartOfSent DT</cell><cell>include b</cell><cell>, NNP , NNP ,</cell></row><row><cell>StartOfSent</cell><cell>, including b</cell><cell>CC NNP NNP NNP NNP</cell></row><row><cell cols="2">NNP , NNP NNP , and other a</cell><cell>. EndOfSent</cell></row><row><cell>StartOfSent JJ</cell><cell>, including b</cell><cell>CC NNP NNP , VBP</cell></row><row><cell>StartOfSent JJ</cell><cell>, including b</cell><cell>, NNP NNP CC NNP</cell></row><row><cell>StartOfSent DT</cell><cell>are b</cell><cell>, NNP , NNP ,</cell></row></table><note><p><p><p><p><p>The tags are from the Penn Treebank</p><ref type="bibr" target="#b17">[17]</ref> </p>tag set, e.g. NNP is a proper noun, CC is a conjunction etc. The relative position of C and N is denoted in Table</p>2</p>by the superscript a if N is before C, and b otherwise.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Algorithm for inserting categorized names into hierarchical knowledge resources such as WordNet</head><label></label><figDesc>: a name N and its categories Ci, i=1 . . . n Output: A hierarchy concept to link N to, or None Variables: {W } = set of pairs hierarchy concept, count Steps: 1. {W } = empty set 2. For each category Ci of the name N 3. Match Ci into hierarchy concepts {Wi} 4. If {Wi} is empty 5. Wj in W 14. Find concepts {H} of {W } with the highest count 15. If {H} has one element 16. Return element of {H} 17. Else 18. Compute least-general concept L of elements {H} 19. If L exists and is a leaf concept 20.</figDesc><table><row><cell></cell><cell>Discard a modifier of Ci and goto 3.</cell></row><row><cell cols="2">6. For each matching hierarchy concept Wi</cell></row><row><cell>7.</cell><cell>For all hyponyms Wj of Wi, including Wi</cell></row><row><cell>8.</cell><cell>If Wj is a leaf concept</cell></row><row><cell>9.</cell><cell>Find entry for Wj in {W }</cell></row><row><cell>10.</cell><cell>If no entry found</cell></row><row><cell>11.</cell><cell>Insert entry (Wj, 1) in {W }</cell></row><row><cell>12.</cell><cell>Else</cell></row><row><cell>13.</cell><cell>Increment counter of entry for Return L</cell></row><row><cell cols="2">21. Else</cell></row><row><cell>22.</cell><cell>Return None</cell></row><row><cell cols="2">Figure 4:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 : Samples of siblings extracted from Web documents</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Instance name Top siblings</cell></row><row><cell>BMW M5</cell><cell>S-Type R, Audi S6, Porsche, Dodge Viper,</cell></row><row><cell></cell><cell>Chevrolet Camaro, Ferrari</cell></row><row><cell>Information</cell><cell>Natural Language Processing, Computer</cell></row><row><cell>Retrieval</cell><cell>Vision, Spoken Language Processing,</cell></row><row><cell></cell><cell>Digital Libraries, Human-Computer</cell></row><row><cell></cell><cell>Interaction, Data Mining</cell></row><row><cell>NSA</cell><cell>CIA, FBI, INS, DIA, Navy, NASA, DEA,</cell></row><row><cell></cell><cell>Secret Service, NIST, Army, DOE, NSF</cell></row><row><cell>Tangerine</cell><cell>Kraftwerk, Klaus Schulze, Vangelis, Art of</cell></row><row><cell>Dream</cell><cell>Noise, Jean-Michel Jarre, ELP, Genesis,</cell></row><row><cell></cell><cell>Peter Hammill, Gentle Giant, Pink Floyd</cell></row><row><cell>Cozumel</cell><cell>Cancun, Belize, Jamaica, Puerto Vallarta,</cell></row><row><cell></cell><cell>Bahamas, Mazatlan, Grand Cayman,</cell></row><row><cell></cell><cell>Acapulco, Tulum, Isla Mujeres</cell></row><row><cell>Angels</cell><cell>Narrows, Subway, Hidden Canyon, Emerald</cell></row><row><cell>Landing</cell><cell>Pools, Weeping Rock, Watchman, Grotto</cell></row><row><cell></cell><cell>Picnic Area, Great White Throne</cell></row><row><cell>CSCO</cell><cell>INTC, MSFT, SUNW, DELL, EMC, ORCL,</cell></row><row><cell></cell><cell>AMAT, HET, WPI, WHR, TIN</cell></row><row><cell>Braque</cell><cell>Picasso, Matisse, Chagall, Leger, Dali,</cell></row><row><cell></cell><cell>Kandinsky, Giacometti, Tamayo, Klee</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 : Test collections</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">Collection Document type</cell><cell>Document count</cell></row><row><cell cols="2">NewsData Web news articles</cell><cell>12 million</cell></row><row><cell>WebData</cell><cell>Web documents</cell><cell>â‰ˆ500 million</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 : Samples of categories and their top ranked instance names acquired from WebData</head><label>5</label><figDesc></figDesc><table><row><cell>Category</cell><cell>Top instance names</cell></row><row><cell>colors</cell><cell>Black, Red, White, Blue, Green, Yellow,</cell></row><row><cell></cell><cell>Orange, Pink, Purple, Silver</cell></row><row><cell>hybrid cars</cell><cell>Toyota Prius, Honda Insight</cell></row><row><cell>California</cell><cell>Los Angeles, San Francisco, Sacramento,</cell></row><row><cell>cities</cell><cell>San Diego, San Jose, Oakland, Long Beach</cell></row><row><cell>rappers</cell><cell>Eminem, Jay-Z, Nas, Dmx, Snoop Dogg,</cell></row><row><cell></cell><cell>Dr. Dre, Ja Rule, Mos Def, Nelly, Ice Cube</cell></row><row><cell>high-speed</cell><cell>ATM, Gigabit Ethernet, B-ISDN, FDDI,</cell></row><row><cell>networks</cell><cell>Myrinet, Frame Relay, Fast Ethernet</cell></row><row><cell>anti-</cell><cell>Prozac, Zoloft, Paxil, Wellbutrin, Effexor,</cell></row><row><cell>depressants</cell><cell>Elavil, Luvox, Nortriptyline, SSRIs</cell></row><row><cell cols="2">latin dances Salsa, Merengue, Cha Cha, Rumba, Mambo,</cell></row><row><cell></cell><cell>Tango, Samba, Meringue, Waltz, Cumbia</cell></row><row><cell>operating</cell><cell>Linux, Windows, Windows NT, Unix, DOS,</cell></row><row><cell>systems</cell><cell>Solaris, Microsoft Windows, MS-DOS, HP-UX</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 : Categories containing the highest number of instance names</head><label>6</label><figDesc></figDesc><table><row><cell>Noun</cell><cell></cell><cell>Collection</cell></row><row><cell>Type</cell><cell>NewsData</cell><cell>WebData</cell></row><row><cell cols="2">Single companies, players,</cell><cell>people, companies,</cell></row><row><cell></cell><cell>organizations, areas</cell><cell>names, organizations, artists</cell></row><row><cell>Multi</cell><cell>industry leaders,</cell><cell>professional organizations,</cell></row><row><cell></cell><cell>school districts,</cell><cell>industry leaders,</cell></row><row><cell></cell><cell cols="2">government agencies, government agencies,</cell></row><row><cell></cell><cell>brand names</cell><cell>community organizations</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 : Instance names that belong to the highest number of categories, and their top categories</head><label>7</label><figDesc></figDesc><table><row><cell>Name</cell><cell>Top categories</cell></row><row><cell cols="2">From NewsData:</cell></row><row><cell>China</cell><cell>countries, markets, nations,</cell></row><row><cell></cell><cell>Asian countries, places, economies</cell></row><row><cell>IBM</cell><cell>companies, vendors, industry leaders</cell></row><row><cell></cell><cell>manufacturers, OEMs, competitors</cell></row><row><cell>Japan</cell><cell>countries, nations, markets,</cell></row><row><cell></cell><cell>Asian countries, places, trading partners</cell></row><row><cell cols="2">Microsoft companies, vendors, industry leaders</cell></row><row><cell>France</cell><cell>countries, European countries, nations</cell></row><row><cell cols="2">Australia countries, nations, markets, places</cell></row><row><cell cols="2">From WebData:</cell></row><row><cell>Internet</cell><cell>technologies, networks, media, sources,</cell></row><row><cell></cell><cell>services, resources, areas, electronic media</cell></row><row><cell>IBM</cell><cell>companies, vendors, corporations, industry</cell></row><row><cell></cell><cell>leaders, manufacturers, clients, organizations</cell></row><row><cell cols="2">Microsoft companies, vendors, industry leaders, clients,</cell></row><row><cell></cell><cell>technology companies, corporations</cell></row><row><cell>Japan</cell><cell>countries, nations, markets, regions, Asian</cell></row><row><cell></cell><cell>countries, places, foreign countries, areas</cell></row><row><cell>China</cell><cell>countries, nations, markets, Asian countries,</cell></row><row><cell></cell><cell>places, regions, areas, economies</cell></row><row><cell>Oracle</cell><cell>companies, databases, vendors, industry</cell></row><row><cell></cell><cell>leaders, relational databases, applications</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 : Incremental acquisition of categorized names from NewsData</head><label>8</label><figDesc></figDesc><table><row><cell>Chunk#</cell><cell>Source</cell><cell cols="3">Percentage of unseen unique items</cell></row><row><cell></cell><cell>(month)</cell><cell>Pairs</cell><cell>Names</cell><cell>Categories</cell></row><row><cell></cell><cell></cell><cell cols="2">(C,N) only N</cell><cell>only C</cell></row><row><cell>1</cell><cell>04/03</cell><cell>100%</cell><cell>100%</cell><cell>100%</cell></row><row><cell>2</cell><cell>05/03</cell><cell>91</cell><cell>76</cell><cell>76</cell></row><row><cell>3</cell><cell>06/03</cell><cell>70</cell><cell>69</cell><cell>69</cell></row><row><cell>4</cell><cell>07/03</cell><cell>84</cell><cell>61</cell><cell>65</cell></row><row><cell>5</cell><cell>08/03</cell><cell>82</cell><cell>60</cell><cell>61</cell></row><row><cell>6</cell><cell>09/03</cell><cell>82</cell><cell>57</cell><cell>59</cell></row><row><cell>7</cell><cell>10/03</cell><cell>83</cell><cell>53</cell><cell>58</cell></row><row><cell>8</cell><cell>11/03</cell><cell>80</cell><cell>54</cell><cell>56</cell></row><row><cell>9</cell><cell>12/03</cell><cell>79</cell><cell>52</cell><cell>54</cell></row><row><cell>10</cell><cell>01/04</cell><cell>79</cell><cell>51</cell><cell>54</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>A WordNet concept is considered a leaf node if it is situated towards the bottom of the hierarchy, i.e. some or all of its immediate existing hyponyms are names.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>More precisely, the evidence on the Web may be either truly non-existing, or simply unreachable through the extraction method presented in this paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2"><p>Visualization and user interface design issues, related to how exactly the names are displayed in the search results, are beyond the object of this paper.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGMENTS</head><p>The author would like to thank Thorsten Brants for assistance with the TnT tagger; Vibhu Mittal and Jay Ponte for various suggestions; and Christoph Reichenbach, Mihai Surdeanu and Franz Och for feedback on earlier drafts.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Snowball: Extracting relations from large plaintext collections</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM International Conference on Digital Libraries (DL-00)</title>
		<meeting>the 5th ACM International Conference on Digital Libraries (DL-00)<address><addrLine>San Antonio, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TnT -a statistical part of speech tagger</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Applied Natural Language Processing (ANLP-00)</title>
		<meeting>the 6th Conference on Applied Natural Language Processing (ANLP-00)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A transformation-based approach to prepositional phrase attachment disambiguation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Computational Linguistics (COLING-94)</title>
		<meeting>the 15th International Conference on Computational Linguistics (COLING-94)<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="1198" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extracting patterns and relations from the World Wide Web</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Extending Database Technology (EDBT-98), Workshop on the Web and Databases</title>
		<meeting>the 6th International Conference on Extending Database Technology (EDBT-98), Workshop on the Web and Databases<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="172" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic construction of a hypernym-labeled noun hierarchy from text</title>
		<author>
			<persName><forename type="first">S</forename><surname>Caraballo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Computational Linguistics (ACL-99)</title>
		<meeting>the 37th International Conference on Computational Linguistics (ACL-99)<address><addrLine>College Park, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="120" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MUC-7 information extraction task definition, version 5.1</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chinchor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Message Understanding Conference</title>
		<meeting>the 7th Message Understanding Conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised models for named entity classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)</title>
		<meeting>the 1999 Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)<address><addrLine>College Park, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to construct knowledge bases from the World Wide Web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dipasquo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Slattery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="69" to="113" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Language independent named entity recognition combining morphological and contextual evidence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cucerzan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)</title>
		<meeting>the 1999 Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)<address><addrLine>College Park, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="90" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Web-scale information extraction in KnowItAll</title>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-M</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th World Wide Web Conference</title>
		<meeting>the 13th World Wide Web Conference<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>WWW-04</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database and Some of its Applications</title>
		<editor>C. Fellbaum</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A layered approach to nlp-based information retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Flank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-98)</title>
		<meeting>the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-98)<address><addrLine>Montreal, Quebec</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatically generating hypertext in newspaper articles by computing semantic relatedness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference on Computational Language Learning (CoNLL-98)</title>
		<meeting>the 2nd Conference on Computational Language Learning (CoNLL-98)<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Computational Linguistics (COLING-92)</title>
		<meeting>the 14th International Conference on Computational Linguistics (COLING-92)<address><addrLine>Nantes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The effect of query complexity on Web searching results</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000-10">October 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Description of the NetOwl extractor system as used for MUC-7</title>
		<author>
			<persName><forename type="first">G</forename><surname>Krupka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><surname>Isoquest</surname></persName>
		</author>
		<author>
			<persName><surname>Inc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Message Understanding Conference (MUC-7)</title>
		<meeting>the 7th Message Understanding Conference (MUC-7)<address><addrLine>Fairfax, Virginia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using decision trees for coreference resolution</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95)</title>
		<meeting>the 14th International Joint Conference on Artificial Intelligence (IJCAI-95)<address><addrLine>Montreal, Quebec</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Named entity recognition without gazetteers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL-99)</title>
		<meeting>the 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL-99)<address><addrLine>Bergen, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatically labeling semantic classes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Human Language Technology Conference (HLT-NAACL-04)</title>
		<meeting>the 2004 Human Language Technology Conference (HLT-NAACL-04)<address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploiting strong syntactic heuristics and co-training to learn semantic lexicons</title>
		<author>
			<persName><forename type="first">W</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-02)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP-02)<address><addrLine>Philadelphia, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning surface text patterns for a question answering system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL-02)</title>
		<meeting>the 40th Annual Meeting of the Association of Computational Linguistics (ACL-02)<address><addrLine>Philadelphia, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning dictionaries for information extraction by multi-level bootstrapping</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th National Conference on Artificial Intelligence (AAAI-99)</title>
		<meeting>the 16th National Conference on Artificial Intelligence (AAAI-99)<address><addrLine>Orlando, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="474" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: a Modern Approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Acquiring hyponymy relations from web documents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shinzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Human Language Technology Conference (HLT-NAACL-04)</title>
		<meeting>the 2004 Human Language Technology Conference (HLT-NAACL-04)<address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using corpus-derived name lists for named entity recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gaizauskas</surname></persName>
		</author>
		<idno>ANLP-00</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Applied Natural Language Processing</title>
		<meeting>the 6th Conference on Applied Natural Language Processing<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">First story detection using a composite document representation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Human Language Technology Research (HLT-01)</title>
		<meeting>the 1st International Conference on Human Language Technology Research (HLT-01)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using WordNet for text retrieval</title>
		<author>
			<persName><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WordNet, An Electronic Lexical Database</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="285" to="303" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
