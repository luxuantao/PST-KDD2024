<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reconstructing Out-of-Order Issue Queue</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ipoom</forename><surname>Jeong</surname></persName>
							<email>ipoom.jeong@yonsei.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiwon</forename><surname>Lee</surname></persName>
							<email>jiwon.lee@yonsei.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Myung</forename><surname>Kuk</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Ewha Womans University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Won</forename><surname>Woo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reconstructing Out-of-Order Issue Queue</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/MICRO56248.2022.00023</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-01-01T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dynamic Scheduling</term>
					<term>Data Dependence</term>
					<term>Steering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Out-of-order cores provide high performance at the cost of energy efficiency. Dynamic scheduling is one of the major contributors to this: generating highly optimized issue schedules considering both data dependences and underlying execution resources, but relying heavily on complex wakeup and select operations of an out-of-order issue queue (IQ). For decades, researchers have proposed several complexityeffective dynamic scheduling schemes by leveraging the energy efficiency of an in-order IQ. However, they are either costly or not capable of delivering sufficient performance to substitute for a conventional wide-issue out-of-order IQ.</p><p>In this work, we revisit two previous designs: one classical dependence-based design and the other state-of-the-art readiness-based design. We observe that they are complementary to each other, and thus their synergistic integration has the potential to be a good alternative to an out-of-order IQ. We first combine these two designs, and further analyze the main architectural bottlenecks that incur the underutilization of aggregate issue capability, thereby limiting the exploitation of instruction-level and memory-level parallelisms: 1) memory dependences not exposed by the register-based dependence analysis and 2) wide and shallow nature of dynamic dependence chains due to the long-latency memory accesses. To this end, we propose Ballerino, a novel microarchitecture that performs balanced and cache-miss-tolerable dynamic scheduling via a complementary combination of cascaded and clustered inorder IQs. Ballerino is built upon three key functionalities: 1) speculatively filtering out ready-at-dispatch instructions, 2) eliminating wasteful wakeup operations via a simple steering technique leveraging the awareness of memory dependences, and 3) reacting to program phase changes by allowing different load-dependent chains to share a single IQ while guaranteeing their out-of-order issue. The net effect is minimal scheduling energy consumption per instruction while providing comparable scheduling performance to a fully out-of-order IQ. In our analysis, Ballerino achieves comparable performance to an 8wide out-of-order core by using twelve in-order IQs, improving core-wide energy efficiency by 20%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Out-of-order execution is a fundamental microarchitectural technique to achieve high single-thread performance in modern microprocessors. The essence of out-of-order execution is to parallelize the execution of instructions (i.e., instruction-level parallelism (ILP)), as well as the accesses to the memory hierarchy (i.e., memory-level parallelism (MLP)). Dynamic scheduling plays a central role in exploiting such parallelisms by deriving data dependence chains from the dynamic instruction stream and issuing readyto-execute instructions regardless of their relative order. It is well known that dynamic scheduling generates issue schedules highly optimized for the underlying pipeline and memory hierarchy. Therefore, dynamic scheduling is suitable for wide-issue designs, providing much higher (around 2-3x) performance than in-order scheduling that has limited issue capability <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>.</p><p>Albeit superior performance, it has been claimed that outof-order cores are not appropriate for energy-constrained systems due to the complexity of dynamic scheduling; wakeup and select operations cause significant complexity and energy overhead, which is further exacerbated as the scheduling window grows <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>. A promising solution is to replace an out-of-order issue queue (IQ) with multiple energy-efficient in-order IQs, expecting some degree of dynamic scheduling effects between them <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. However, such limited forms of dynamic scheduling are not very well suited for wide-issue superscalars because most of them focus solely on one aspect of dynamic scheduling, such as MLP, resulting in substantially low performance. We should consider various factors determining the issue order altogether to achieve comparable performance to an out-of-order IQ without the aid of powerhungry wakeup and select operations.</p><p>To address this issue, we revisit two existing microarchitectures -one dependence-based design and the other readiness-based design -and observe that they are complementary to each other, which implies that their combination is a good starting point for reconstructing out-oforder IQ. The former one, complexity-effective superscalar (CES) <ref type="bibr" target="#b2">[3]</ref>, paved the way for concurrently tracking multiple data dependence chains by steering them to parallel inorder IQs (P-IQs). However, CES requires too many P-IQs to achieve near-out-of-order performance because every ready-at-dispatch instruction should allocate a separate P-IQ. The latter one, CASINO <ref type="bibr" target="#b1">[2]</ref>, proposed a simple and effective filtering mechanism that immediately issues readyat-dispatch instructions using a speculative in-order IQ (S-IQ). One serious drawback of this microarchitecture is that it may experience a significant performance degradation under cache misses since non-ready instructions eventually enter the single in-order IQ where they are issued in original program order. To summarize, the speculative issue functionality of CASINO could be a good solution to reduce the steering stalls caused by ready-at-dispatch instructions in CES. Conversely, CES's ability to keep track of multiple data dependences can be applied to CASINO, specifically for the non-ready (and thus not filtered out) instructions, to support out-of-order issue when they become ready.</p><p>Based on this observation, we propose Ballerino, a novel microarchitecture carrying out BALanced and cache-miss-toLERable dynamic scheduling via cascaded and clustered IN-Order IQs. Ballerino is developed in three steps. As a first step, we put together the aforementioned two scheduler designs -the S-IQ ahead of the multiple P-IQs -and analyze the architectural bottlenecks preventing the further exploitation of ILP and MLP. We identify two major bottlenecks: 1) memory dependences not considered in the existing steering mechanism reduce the effective issue bandwidth and 2) loaddependent instructions and their consumers stay inside the scheduling window for a long time, and thus still causing a lack of P-IQs while taking up only a small portion of scheduling window entries.</p><p>To address the first issue, we incorporate the awareness of memory dependences into instruction steering in Step 2. We extend memory dependence prediction (MDP) <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref> to maintain the steering information of producer stores. The following consumer loads are steered based on this information, overriding the existing steering mechanism. By supplementing this feature, the scheduling resources can be utilized more efficiently while expanding the scheduling window as quickly as possible. For the second issue, we introduce the concept of P-IQ sharing that facilitates a single P-IQ to concurrently handle multiple dependence chains from long-latency loads. If a new P-IQ is required but there are no empty P-IQs, a steer logic selects one of the P-IQs and activates sharing mode. In this operation mode, a P-IQ is equally partitioned and each partition acts as a distinct FIFO queue to accommodate instructions from different dependence chains while providing the opportunities for out-of-order issue. By leveraging the behavior of such dependence chains, we also propose a novel implementation that minimizes design cost and complexity. Together, the two architectural techniques augment the effective number of P-IQs and maximize their utilization.</p><p>The contributions of this paper are as follows:</p><p>• We conduct an in-depth analysis on a wide range of microarchitectures pursuing complexity-effective dynamic scheduling. We observe that although they could be promising alternatives for energy-efficient dynamic scheduling, none of them succeed in achieving sufficient performance to substitute for high-end out-oforder processors. • We leverage the observations from two different designs -specifically, their potentially synergistic effectsto reconstruct the instruction scheduler with the aim of achieving comparable performance to the 8-wide, fully out-of-order IQ by only using in-order IQs. Two microarchitectural techniques are also proposed to mitigate the bottlenecks that arise when two designs are joined together. The proposed techniques are adaptive to different phases of execution, thereby maximizing the utilization of scheduling resources. • We present a Ballerino core microarchitecture with its implementation details. The proposed design strikes a good balance between exploiting ILP and MLP while providing high energy efficiency. Our evaluation on a detailed cycle-level simulator demonstrates that twelve in-order IQs with some extended functionalities achieve around 98% of the performance of the out-of-order IQ. As a result, Ballerino shows 20% better energy efficiency than the baseline out-of-order core.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND AND MOTIVATION</head><p>In this section, we first give an overview of dynamic scheduling that lays the foundation for out-of-order execution. We then provide an in-depth analysis on two core microarchitectures pursuing energy-efficient dynamic scheduling: CES <ref type="bibr" target="#b2">[3]</ref> and CASINO <ref type="bibr" target="#b1">[2]</ref>. To this end, we present our key observation that the two scheduling techniques are complementary to each other, and thus their synergistic combination could be a promising alternative to a wide-issue out-of-order IQ for higher energy efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dynamic Scheduling</head><p>A key design philosophy behind dynamic scheduling is to extract ILP and MLP from an instruction window by issuing instructions as quickly as possible. Data dependence is one of the factors that determine such parallelisms, since instructions can be executed only when all of their source operands are ready. There are two types of data dependences: register dependence (R-dependence) and memory dependence (Mdependence). The R-dependence is the producer-consumer relationship via a register tag and identified at the decode of each instruction. On the other hand, the M-dependence occurs through a memory address, and so can be captured after the address calculations of both the producer store and consumer load are completed. Figure <ref type="figure" target="#fig_0">1</ref> illustrates an example data dependence graph of ten dynamic instructions (i0 -i9). We use the term dependence chain (DC) to refer to a sequence of instructions along the R-dependences (solid arrows) <ref type="bibr" target="#b2">[3]</ref>. Within a DC, each instruction is allowed to have up to one producer and one consumer. If two destination registers are read by only one consumer, it terminates one of DCs (chain merge at i5). On the other hand, if a destination register is read by more than one consumer, new DCs are generated at that point (chain split at i6). Within a scheduling window, dependence head and tail refer to the oldest and youngest instruction of a DC, respectively. At any given moment, only dependence heads are eligible for issue. In the figure, a dashed arrow denotes the M-dependence between an older store (i2) and a younger load (i6) targeting the same address Y.</p><p>In modern out-of-order cores, the IQ keeps track of the R-dependences and issues ready-to-execute instructions on a cycle-by-cycle basis. As dynamic instructions are scheduled out of program order honoring the R-dependences, both ILP and MLP can be exploited by fully utilizing the available execution resources. Figure <ref type="figure">2</ref> shows our baseline scheduler, a unified IQ that consists of the CAM-based wakeup logic without compaction (i.e., random queue), the select logic implemented by prefix-sum circuits, and the payload RAM <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Other implementations -such as the matrix-based wakeup logic <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> and select logic that consists of a tree of arbiters <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b17">[18]</ref> -have also been published.</p><p>To support arbitration for the heterogeneous functional units (FUs), the IQ issues instructions through issue ports, each of which has the dedicated FUs (see Table <ref type="table" target="#tab_5">I</ref>). The number of issue ports is equal to the issue width, and each port issues up to one instruction in a cycle. At dispatch, an issue port is assigned to each instruction, according to the opcode of an instruction and the FUs dedicated to each port. If multiple FUs of the same type exist across different ports, simply the one assigned to the least number of inflight (dispatched but not issued) instructions is selected for load balancing. Detailed operations of instruction select in each issue port is further discussed in Section IV-E.</p><p>In Figure <ref type="figure">2</ref>, P ort M −1 is assigned to I 0 at dispatch 1 . When I 0 becomes ready, an issue request (req I 0 ) is sent from the wakeup logic to the select logic (the prefix-sum circuit of P ort M −1 ) that is responsible for selecting an instruction issued in the next cycle 2 . A prefix-sum circuit </p><formula xml:id="formula_0">•• ••• Wakeup logic Dispatch (including port arbitration) ••• Payload RAM ••• req_I 0 req_I N-1 ••• ••• Select logic ••• ••• req_I 1 req_I N-2 ••• grant_I 1 grant_ I N-2 ••• ••• (N reqs) ••• (N reqs) ••• (1 grant) ••• (1 grant) ••• ••• ••• Request signals Grant signals 1 N-2 0 N-1 ••• ••• 0 1 2 3 N-2 N-1 N-3 N-4 ••• ••• 0 1 2 3 N-2 N-1 N-3 N-4 Issued via Port M-1 Issued via Port 0 ••• grant_I 0 grant_ I N-1 0 N-1 N-2 1 Prefix-sum (Port M-1 ) Prefix-sum (Port 0 ) dest_tag_I N-1 dest_tag_I 0 ••• Figure 2:</formula><p>Organization of baseline out-of-order IQ having N entries with M issue ports grants one of the input requests, and then sends a grant signal (grant I 0 ) to the payload RAM 3 . At the same time, the destination register tag of I 0 (dest tag I 0 ) is broadcast to the wakeup logic to update the ready flags of the corresponding source registers 4 . Finally, I 0 is issued from the payload RAM to the FU via P ort M −1 in the next cycle 5 . The wakeup-select scheduling loop determines the critical path of the IQ and cannot be pipelined to support the back-to-back issue of dependent instructions <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b17">[18]</ref>.</p><p>Note that, besides the R-dependences, two other factors should also be considered for better scheduling performance when selecting instructions to issue: 1) the M-dependences between instructions and 2) the ages (i.e., relative order) of them. First, a load must fetch the value from its producer store (i.e., the youngest older store targeting the same address), if any. If a load is issued earlier than its producer store, it would read a wrong value either from a store queue (SQ) or memory hierarchies. When this memory order violation is detected, the core's microarchitectural state must be recovered and the following instructions need to be reexecuted. Our baseline machine performs MDP to detect the M-dependences between stores and loads <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. The key insight is that an M-dependent store-load pair is repeatedly encountered during execution, and such a load has a high probability of being ready earlier than its producer store again in the future. Therefore, once an order violation is detected, future order violations of the same pair can be avoided by delaying the issue of the M-dependent load until its (possible) producer store is issued.</p><p>Second, it is well known that the age of an instruction is heavily correlated with its criticality, and thus assigning higher issue priority to older instructions usually provides better performance <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. Typically, out-oforder cores have employed a compaction circuit <ref type="bibr" target="#b20">[21]</ref> or age</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monitored IQ entry Instruction Dispatch</head><p>Instruction Issue (supplemented from conventional in-order core) Instruction Issue Instruction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•••</head><p>Steering along dependence chains</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•••</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P-IQs</head><p>Out-of-order issue (a) Clustered P-IQs in CES</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S-IQs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speculative issue (out of order)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IQ</head><p>In-order issue Speculative scheduling window Figure <ref type="figure">3</ref>: Design concepts and scheduling performance of CES <ref type="bibr" target="#b2">[3]</ref> and CASINO <ref type="bibr" target="#b1">[2]</ref>, compared to baseline designs matrices <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> to provide the capability of giving higher issue priority to the oldest instruction (i.e., oldestfirst selection), at the cost of extra hardware complexity and lengthened critical path. These mechanisms are essential for wide-issue cores with large instruction windows, since memory order violations and issue port conflicts are frequently observed as more in-flight instructions are examined for outof-order issue. The impacts of MDP and oldest-first selection are discussed in Sections III-B and VI-A, respectively.</p><formula xml:id="formula_1">••• ••• (b) Cascaded S-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Energy-Efficient Dynamic Scheduling</head><p>1) Complexity-Effective Superscalar (CES): CES <ref type="bibr" target="#b2">[3]</ref> is a dependence-based microarchitecture that performs dynamic scheduling by using a group of P-IQs, as depicted in Figure <ref type="figure">3a</ref>. The key insight of CES is that dependent instructions -instructions in the same DC -must be executed in a sequential order. Therefore, a significant amount of scheduling energy can be saved by steering each DC into a single P-IQ and examining only its dependence head (i.e., the instruction at the head of the P-IQ). Instructions in a P-IQ are issued in order but independently from the others steered to different P-IQs. Ideally, this scheduling scheme could offer comparable performance to a fully out-of-order IQ, provided that it has a number of P-IQs sufficient to accommodate all the in-flight DCs. A heuristic proposed in <ref type="bibr" target="#b2">[3]</ref> steers an instruction to a new (empty) P-IQ in three cases: 1) none of its producers are in the P-IQs, since it is ready or some of its producers are under execution; 2) it becomes a dependence head due to chain split (e.g., i8 in Figure <ref type="figure" target="#fig_0">1</ref>); and 3) there are no free entries in the target P-IQs in which its producers wait for issue.</p><p>2) CASINO: CASINO <ref type="bibr" target="#b1">[2]</ref> is built on a stall-on-use inorder core by leveraging the observation that an S-IQ(s) ahead of a conventional in-order IQ can speculatively capture a large amount of ready-to-execute instructions (Figure <ref type="figure">3b</ref>). Each cycle, CASINO examines a predefined number of instructions at the head of each S-IQ (i.e., speculative scheduling window). If some ready instructions are detected, they are issued immediately while the preceding non-ready instructions are passed to the next IQ. In this manner, an S-IQ could issue dependent instructions along a DC on a cycleby-cycle basis. If no ready instructions are detected, an S-IQ moves the speculative scheduling window toward younger instructions by passing a fixed number of instructions to the next IQ. Instructions inserted into the last IQ are issued in program order. Together, they effectively perform a restricted form of dynamic scheduling by using the S-IQ(s) as a filter for a conventional in-order IQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scheduling Performance Analysis</head><p>The above two designs successfully reduce the complexity of dynamic scheduling, while achieving a certain level of performance by applying different insights into the microarchitectures: R-dependence and readiness. The R-dependence is a static feature that is determined by the relative order of instructions and their source and destination operands. On the other hand, the readiness is a dynamic feature that varies with microarchitectural factors such as execution resources and out-of-order issue capability. We observe that these two features can be synergistically integrated to compensate for the inherent drawbacks of the two microarchitectures.</p><p>Figure <ref type="figure">3c</ref> shows the breakdown of the average decode-toissue cycles of dynamic instructions on different microarchitectures: in-order core (InO), CES, CASINO, and outof-order core (OoO). Instructions are subdivided into three types: load (Ld), load consumer (LdC), and the rest (Rst). The dependences to loads are determined at dispatch by checking whether an instruction is directly and/or indirectly dependent on any older loads that are not completed yet. The readiness of source operands are examined after the source registers are renamed. Note that we mark a load as ready only when both M/R-dependences are resolved. In this experiment, we allow up to 160 micro-operations (μops) to be in-flight between decode and issue (the sum of the allocation queue and out-of-order IQ of Skylake <ref type="bibr" target="#b23">[24]</ref>). Our experimental methodology and microarchitectural parameters are presented in Section V.</p><p>From the results of CES, we observe that the parallel ar- rangement of P-IQs incurs significant delays from decode to dispatch. To further investigate this behavior, we measure the instruction steering statistics of CES at dispatch (Figure <ref type="figure" target="#fig_1">4</ref>). According to our evaluation, 27% of the cases successfully steer to the P-IQs along DCs ([Steer] DC); the remainder either allocate new P-IQs, or stall if there are no free P-IQs. Note that most of Allocate and Stall events are caused by Ready instructions; they account for 72% and 79% of P-IQ allocations and steering stalls, respectively. It reveals that the major performance bottleneck of CES is a lack of free P-IQs caused by a large amount of ready-at-dispatch instructions <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b24">[25]</ref>. This is an inherent limitation of CES, because its performance gains are degraded as the number of steering stalls increases, as shown in Figure <ref type="figure" target="#fig_1">4</ref> (applications are sorted from left to right according to [Stall] Ready). OoO has some ready-to-issue delay of Ld, because it frequently reaches the maximum limit of parallel memory accesses (i.e., MLP). Nevertheless, dependence-aware scheduling in CES is still an attractive approach. Once instructions are dispatched and become ready, almost all of them are issued immediately regardless of their order (gray bars in Figure <ref type="figure">3c</ref>). However, counter-intuitively, this mechanism restricts the ILP extraction when the number of in-flight DCs exceeds that of the P-IQs. In this situation, instruction dispatch is stalled and (possibly ready) instructions must wait for the release of the P-IQs allocated to different DCs. Such missed opportunities for issue become a critical performance limiter as more of stalled instructions are ready or dependent on prior ready instructions waiting for dispatch. One brute-force approach is pushing more P-IQs into the pipeline. However, merely increasing the number of the P-IQs is ineffective and impractical considering the growing cost and complexity of circuitry <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b25">[26]</ref>.</p><p>CASINO exhibits remarkably different behavior. First, the S-IQ effectively captures and issues instructions that become ready shortly after dispatch. In Figure <ref type="figure">3c</ref>, such instructions are classified as Rst, and show very small delays not only from dispatch to ready, but also from ready to issue. This implies that speculative issue functionality of CASINO would be a good solution to tackle the dispatch stall issue in CES by filtering out ready-at-dispatch instructions and their consumers before they are steered to the P-IQs. Second, even though CASINO suffers less from dispatch stalls due to the sequential arrangement of the IQs, this characteristic makes CASINO not inherently cache-miss-tolerant. An instruction that directly depends on a load becomes ready after the memory reference is resolved. Therefore, load-dependent instructions and their subsequent consumers (LdC) are likely not to be ready at dispatch. Passing through the S-IQ, they finally enter the last IQ and mixed with other instructions from different DCs. If the last IQ already gets stalled by the older DCs depending on cache-missing load(s), these instructions cannot be issued even though they become ready <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p><p>The sequential nature of CASINO makes it vulnerable to cache misses, and thus not suitable for wider issue superscalar processors. The main reason for this is that instructions dependent on long-latency operations eventually enter the last in-order IQ, and cannot be issued out of order according to the readiness of their source operands. A dependence-based approach in CES could address this issue by buffering such instructions in the separate P-IQs, and keeping track of individual dependence heads. When one of the long-latency operations completes, instructions that belong to the corresponding DC can be issued immediately while bypassing the other instructions in different P-IQs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. REBUILDING OUT-OF-ORDER IQ</head><p>The speculative issue functionality of CASINO could significantly mitigate the burden on the instruction steering of CES. Conversely, the CES's capability to keep track of multiple outstanding DCs can be a good solution to address the cache miss tolerance issue in CASINO. Based on our analysis, we first combine the two IQ designs to completely eliminate the steering stalls caused by readyat-dispatch instructions. Then, we further explore the architectural bottlenecks causing the underutilization of the aggregate issue capabilities. To this end, we propose two simple but effective steering schemes to realize the potential performance benefits. Throughout this section, we assume a 8-wide issue machine using eight in-order IQs following the convention in <ref type="bibr" target="#b2">[3]</ref>. Section VI-E3 discusses the performance impact of different IQ configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Combining Register Dependence and Readiness</head><p>As a first step, we combine the two IQ designs, as depicted in Figure <ref type="figure" target="#fig_2">5a</ref>. To simplify the figures, we assume that the S-IQ examines two instructions in each cycle. In front of the clustered P-IQs, a single S-IQ sequentially issues not only ready instructions but also their consumers. The effectiveness of the S-IQ is maximized when execution enters a phase that encounters multiple DCs not dependent on long-latency operations. In this situation, the S-IQ effectively filters out dynamic instructions along multiple DCs, which otherwise would require multiple P-IQ allocations. In Figure <ref type="figure" target="#fig_2">5a</ref>, i0 and i1 at the head of the S-IQ are ready (i.e., belong to different DCs), and thus issued immediately. Without the S-IQ, they should allocate two separate P-IQs. Instructions not captured by the S-IQ are not ready and (possibly) dependent on longlatency operations. Such instructions are passed to the P-IQs and wait for the resolution of their data dependences. Since they are steered according to DCs, they can be issued as soon as their producers complete execution. The steering at the head of the S-IQ stalls if there are no appropriate P-IQs. More details are explained in Section IV-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. M-Dependence-Aware Steering</head><p>As discussed earlier, MDP is essential for dynamic scheduling to reduce performance-critical memory order violations. According to our evaluation, MDP reduces memory order violations by 96%, resulting in an average speedup of 1.5× in the baseline. However, we observe that MDP could undermine the out-of-order issue capability of the clustered P-IQs, which has not been explored in previous studies. In CES, instructions are steered based solely on the R-dependences. Therefore, a producer store and Mdependent load are always steered to different P-IQs since  the dependence between them is not exposed through a register tag. Furthermore, as the younger load is likely to be ready (i.e., reaching the head of the P-IQ) earlier than its producer store, the M-dependence between them would block the issue of the load's P-IQ until the producer store is issued. The left stacked bar in Figure <ref type="figure" target="#fig_4">6a</ref> shows the breakdown of issue cycles at the heads of the P-IQs and reveals that 9% of issue stalls are caused by M-dependent loads waiting for the issue of the producer stores. At this point, two P-IQs are occupied by instructions along two DCs that are connected through an M-dependence; the former one ending in a producer store (e.g., i2 in Figure <ref type="figure" target="#fig_0">1</ref>) and the latter one starting from an M-dependent load (e.g., i6 in Figure <ref type="figure" target="#fig_0">1</ref>). Thus, we can create new opportunities to exploit further parallelisms by steering them into a single P-IQ and allowing the other P-IQ to be used by the following non-ready instructions. This is achieved by a simple modification to the existing steering mechanism: steering an M-dependent load along the M-dependence rather than the R-dependence (Figure <ref type="figure" target="#fig_2">5b</ref>). Steering these two DCs into a single P-IQ does not impose a negative impact on scheduling performance for two reasons. First, it puts an M-dependent load right after its producer store, and so the M-dependent load reaches the head of the P-IQ exactly when it is eligible  for issue. Second, a store always ends a DC because it does not have R-dependent consumers. Therefore, steering an Mdependent load (and its consumers) to the producer store's P-IQ does not incur the intermingling of instructions from different DCs behind the store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Tolerating Cache Misses via P-IQ Sharing</head><p>Besides the capability of issuing ready instructions as soon as possible, another important feature of out-of-order execution is to tolerate cache misses. State-of-the-art highend processors are equipped with multi-level cache hierarchies having various access latencies. If the memory access of a load misses in the L1 cache, it will take additional tens to hundreds of cycles to complete. In this case, instructions that read the loaded value (and their subsequent consumers) must wait for the completion of the memory access. The situation becomes more complicated when multiple parallel memory accesses hit in the different levels of cache hierarchies. Even though such memory accesses usually take a long time (see dispatch to ready cycles of LdC in Figure <ref type="figure">3c</ref>), their consumers should be issued as soon as possible because they may have blocked the head of the instruction window for a long time, thereby limiting the opportunities for further ILP extraction.</p><p>One promising approach is the dependence-based scheduling of CES that keeps track of individual dependence heads waiting for loaded values, because it is complexity-effective as well as not hurting performance at least within its own scheduling window. However, various shapes and numbers of in-flight DCs would be the sources of inefficiency <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b26">[27]</ref>. A DC longer than the size of the P-IQ will take the secondary P-IQ (Section II-B1), resulting in unnecessary wakeup operations in the middle of the DC. On the other hand, if there are short-length DCs more than the number of the P-IQs, parallelisms are limited while some P-IQ entries are underutilized.</p><p>Rather than adding more P-IQs having large number of entries, we propose a new IQ design capable of accommo-dating multiple DCs in parallel, while providing them with opportunities for out-of-order issue. The proposed design is based on two key observations. First, most of the time dynamic instructions are derived from a bunch of shortlength DCs, and therefore a large portion of P-IQ entries are underutilized; Figure <ref type="figure" target="#fig_4">6b</ref> shows that the performance of the Step 2 design is very sensitive to the number of P-IQs, but not that much to the size of them. Second, with the existing steering mechanism, the actual issue operations are carried out only for a small fraction of the time, resulting in the underutilization of read ports; the right stacked bar in Figure <ref type="figure" target="#fig_4">6a</ref> shows that a P-IQ issues instructions only for, on average, 6% of the time, mainly due to the stalls caused by dependences to long-latency loads.</p><p>Our analysis paves the way for a novel P-IQ sharing technique: allowing a single P-IQ to be shared by multiple DCs while only one DC is selected for issue in a given cycle. As such, the proposed technique maximizes the utilization of both the entries and read port of each P-IQ. In the best-case scenario, it provides scheduling performance comparable to two separate, ordinary P-IQs. In Figure <ref type="figure" target="#fig_2">5c</ref>, i3 and it's consumer i4 are steered to the lowest P-IQ by sharing it with two older instructions, which otherwise would block the head of the S-IQ until they become ready or one of the P-IQs becomes free; in this case, the S-IQ loses opportunities for speculative issue of younger ready instructions, i5. When i3 becomes ready, it can be issued bypassing the older non-ready instructions from a different DC, using its own hardware pointer. See Section IV-D for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Putting It Together</head><p>The proposed instruction scheduler is adaptive to the various execution phases of each application. Ready-atdispatch instructions are proactively filtered out by the S-IQ. The other instructions are spread to the clustered P-IQs along their M/R-dependences, which removes most of wasteful wakeup operations and leads to minimal scheduling energy consumption per instruction. If execution enters a phase that comprises multiple load-dependent DCs, the P-IQs absorb such DCs with minimal scheduling performance penalty. In the next section, we describe the implementation of the proposed microarchitecture in great detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. BALLERINO MICROARCHITECTURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The microarchitecture of Ballerino is illustrated in Figure <ref type="figure" target="#fig_5">7</ref>. Hardware components responsible for out-of-order execution are colored in blue (i.e., area overhead over an in-order core). The S-IQ and P-IQs are the variants of a conventional in-order IQ with the speculative issue and sharing functionalities, respectively. The other pipeline structures are similar to those of the baseline out-of-order core <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Register Renaming</head><p>Instructions are fetched, decoded, and then inserted into the S-IQ. Meanwhile, an issue port is assigned to each instruction by considering both its opcode and load balancing, similar to the baseline (Section II-A). The source and destination operands of instructions are renamed using a register alias table (RAT) and physical register free list. We assume a two-stage, pipelined register renaming <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. In the first stage (Rename1), RAT lookups are performed to get the current architectural-to-physical mappings of source and destination operands; destination mappings are written to a recovery log to restore the RAT when mis-speculations or exceptions are detected. Then, the R-dependences between intra-group instructions are analyzed to honor true data dependences. In Rename2, new mappings of destination operands (from the free list) are written to the RAT and source operand mappings are fixed by reflecting the result of an R-dependence analysis from Rename1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Speculative Issue and Steering</head><p>Instruction steering is conducted in parallel to register renaming, as shown in Figure <ref type="figure" target="#fig_6">8</ref>. For brevity, we present the steering of two instructions (with two source and one destination operand) and omit some control and datapaths. Following the RAT lookups, the steer logic examines a number of instructions (equal to the rename width) within the speculative scheduling window by referring to the corresponding entries of a physical register scoreboard (P-SCB) in Rename2. A P-SCB entry holds not only the readiness of each physical register but also the steering information of its producers that are not issued yet. Using this information, ready instructions send issue requests to the select logic (red arrows), while the others are steered to the P-IQs honoring the M/R-dependences (light blue arrows). If an instruction has multiple source operands whose producers are in the P-IQs, one is selected by their relative order (yellow muxes) <ref type="bibr" target="#b2">[3]</ref>. If both M/R-dependences are detected,  An instruction is steered to a new P-IQ (either empty or sharable) as a new dependence head (green arrows) in the following three cases: 1) none of its producers are in the P-IQs, 2) the target P-IQ is full, and 3) it is ready but its issue request is not granted by the select logic due to the issue port contention. The third case may steer a ready instruction to the P-IQ, but it does not impact scheduling performance because such an instruction is again examined for issue in the next cycle at the head of the P-IQ. Intra-group M/R-dependences are used to determine the speculative issue (an enable logic) and the target P-IQ (a lower blue mux) of a younger instruction. Such M-and R-dependences are detected via SSID comparison (explained later in this section) and R-dependence analysis from Rename1, respectively. If any of the P-IQs cannot accommodate an incoming instruction, steering gets stalled.</p><p>To support speculative issue and steering, Ballerino maintains the states of individual physical registers: readiness and producer location. Such information is stored in each P-SCB entry. The readiness is presented as a 1-bit Ready flag. The producer location is encoded as a combination of an IQ index , the index of the P-IQ where its producer currently resides (if any), and a 1-bit Reserved flag indicating whether any of its consumers has been steered to the same P-IQ. Note that producers only at the tails of the P-IQs are considered to examine the M/R-dependences; otherwise, scheduling performance would degrade due to the multiple DCs intermingled inside a P-IQ (Section II-B1). When an instruction I p allocates a new P-IQ, the P-IQ index is written to the IQ index field of its destination register R p , and the Reserved flag is set to zero. Later, the consumer of R p is steered to the same P-IQ by referring to these two fields, and setting the Reserved flag indicating that the producer of R p (i.e., I p ) is not located at the tail of the P-IQ any more; this prevents another consumer of R p from being steered to the same P-IQ, as the chain split occurs. When I p completes execution, the IQ index and Reserved fields of R p are cleared and the Ready flag is set.</p><p>Ballerino also employs MDP to keep track of the Mdependences. As described in the original paper <ref type="bibr" target="#b10">[11]</ref>, a load has a store set, a set of stores on which the load has ever depended. When a memory order violation occurs, the identifier of the store set (SSID) is recorded in the store set ID table (SSIT) entries corresponding to the producer store and the M-dependent load. In later iterations, the producer store uses the SSID as an index to update the corresponding last fetched store table (LFST) entry that holds the hardware pointer of the most recently fetched (and in-flight) store from the active store set. This pointer consecutively imposes the M-dependences between the producer store and the following load and/or stores in the same store set, and serializes such memory operations to prevent potential memory order violations. If a fetched load has a valid SSID in the SSIT, it accesses the LFST to get the pointer of the most recently fetched store belonging to its store set; a fetched store performs the same operation except that it finally updates the LFST entry with the pointer of its own. The LFST entry is released when the store performing the most recent update to it is issued.</p><p>To support M-dependence-aware steering, we extend an LFST entry with the ability to track the producer location, i.e., the IQ index and Reserved flag. Every time a store belonging to a store set is steered, it updates these two fields (instead of those in the P-SCB) as well as the hardware pointer field. Later, when the following load (or store) in the same store set is steered, this information is used to select the target P-IQ, overriding its R-dependences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. P-IQ Sharing</head><p>The P-IQ operates in two modes: normal mode and sharing mode. In normal mode (Figure <ref type="figure" target="#fig_7">9a</ref>), it behaves identically to a traditional circular FIFO queue and holds instructions belong to a single DC. In sharing mode (Figure <ref type="figure" target="#fig_7">9b</ref>), the P-IQ is divided into equal-sized partitions (two in this example) and they operate as distinct FIFO queues. To support sharing functionality, each P-IQ has additional head and tail pointers for a newly added partition (DhP tr 1 and DtP tr 1 ). As such, instructions from multiple DCs are accommodated in a single P-IQ. Initially, an empty P-IQ is allocated to each dependence head and operates in normal mode. When an instruction at the head of the S-IQ needs to allocate a new P-IQ but there are no empty P-IQs, the steer logic selects one of the eligible P-IQs and activates sharing mode.</p><p>To reduce implementation complexity, we impose three constraints on sharing mode. First, a P-IQ can have up to two partitions. Even though it is feasible to populate three or more partitions, it incurs additional hardware overhead (described below) as well as increasing the complexity of the steer logic. Second, a P-IQ is eligible for sharing only when its head and tail pointers point to physically the same half of the queue (either first or second half in Figure <ref type="figure" target="#fig_7">9a</ref>). Otherwise, two logical partitions might be mapped to three physical partitions (e.g., one to <ref type="bibr">[2:5]</ref> and the other to [0:1] and <ref type="bibr">[6:7]</ref>), which makes pointer manipulation further complicated. Note that this constraint also prevents a P-IQ from being shared if more than half of its entries are already occupied by instructions from a single DC. Third, as discussed in Section III-C, each P-IQ in sharing mode examines only one dependence head in a cycle (i.e., only one head pointer is activated). This eliminates the need for additional ports to support the out-of-order issue of instructions from different DCs. We further investigate the performance impact of the latter two constraints in Section VI-C.</p><p>In Figure <ref type="figure" target="#fig_7">9a</ref>, the P-IQ can be selected for sharing as both of its head and tail pointers are within the first half; every time an instruction is enqueued or dequeued, each P-IQ in normal mode examines the locations of active head and tail pointers and asserts a shareable signal to the steer logic if they are in the same half. The steer logic refers to this signal to activate sharing mode if necessary. In Figure <ref type="figure" target="#fig_7">9b</ref>, sharing mode is activated and P artition 1 serves three instructions from the second DC. At the end of each cycle, the P-IQ selects the next head pointer as follows. If the current head pointer issues an instruction, it is used again in the next cycle to enable back-to-back issue of single-cycle instructions. If not, the producer of the current dependence head would probably be a long-latency load. In this case, the P-IQ activates the other head pointer to provide opportunities for out-of-order issue to the other DC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Select Instructions for Issue</head><p>In this work, we assume the baseline select logic that comprises the prefix-sum circuits <ref type="bibr" target="#b13">[14]</ref>, as shown in Figure <ref type="figure" target="#fig_8">10a</ref>. A prefix-sum circuit has N inputs (reqs) and N outputs (sums), where N is equal to the number of IQ entries. Each req is a 1-bit issue request from the corresponding entry in the wakeup logic, and each sum is the cumulative sum of issue requests from the first wakeup logic entry. As discussed in Section II-A, each prefix-sum circuit is tied to a specific issue port where up to one instruction is allowed to issue in a cycle. Therefore, i th req is granted if it is true and (i − 1) th sum is zero. The number of adders on the critical path is equal to log 2 N .</p><p>Ballerino also uses the prefix-sum circuits as a select logic (Figure <ref type="figure" target="#fig_8">10b</ref>), but there are two major differences. First, each prefix-sum circuit has a smaller number of inputs than its counterpart in the baseline, equivalent to the sum of the number of P-IQs (p-reqs from the P-IQ heads) and the rename width (s-reqs from the S-IQ head). As the P-IQs and S-IQ are implemented using FIFO queues where issue candidates are always positioned at the heads of the queues, the select logic does not necessarily specify the physical locations of granted instructions. Instead, it is sufficient to notify the grant(s) to each FIFO, allowing the issue of an instruction at the head (P-IQ) or instructions indexed by the relative locations from the head (S-IQ). After receiving grant signals, individual FIFOs issue instructions referring to their own head pointers. This significantly reduces the complexity of the select logic (i.e., the number of inputs and adders as well as the length of the critical path), which translates into lower power consumption.</p><p>The second difference is that the proposed select logic partially benefits from oldest-first selection without additional hardware overheads. Ballerino facilitates the oldestfirst selection based on two key insights: 1) the relative order of instructions is already encoded in their locations (either in the P-IQs or S-IQ), and 2) the prefix-sum circuit always gives highest priority to the uppermost input. Therefore, by connecting issue requests from the P-IQs to the upper part of each prefix-sum circuit, older instructions in the P-IQs automatically have higher priority than younger ones in the S-IQ without any extra logic for tracking the ages of instructions. Note that instructions at the heads of the P-IQs are selected randomly because instruction steering is conducted without considering the relative order of instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Execute, Writeback, and Commit</head><p>The rest of the pipeline operates very similarly to a conventional out-of-order core. Up to eight instructions are issued in each cycle, and completed instructions are committed one-by-one at the head of a reorder buffer (ROB). On a mis-speculation, instructions following the wrong path and/or consuming the wrong values are flushed from the pipeline. Such instructions are dequeued from the ROB tail one-by-one, and restore the RAT using the corresponding recovery logs. Each flushed instruction clears the P-SCB entry of its destination operand, and also clears the LFST entry if it is a store that conducts the last update to that entry. Although the Reserved field of each P-SCB and LFST entry is updated by its consumer, a mis-speculated consumer does not restore that field for two reasons. First, to correctly restore the Reserved field, each and every steered instruction must store the location of the P-SCB or LFST entry that it updates, which incurs additional hardware cost and complexity. Second, although skipping the restoration may prevent newly fetched instructions from being steered ℎ = log  following their DCs, it does not affect the correctness of execution. Furthermore, such entries might also be cleared if their non-speculative producers complete execution during recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Discussions on Ballerino</head><p>1) Operating Frequency: Our primary goal is to judiciously design an energy-efficient IQ as an alternative to conventional IQs in high-end processors that consume significant energy (albeit superior performance). As the actual performance is highly correlated with the clock cycle time as well as IPC, the proposal should not increase the delay of the critical path of the core, i.e., the wakeup-select loop. Two sub-paths are changed in Ballerino: 1) accessing the P-SCB registers (Figure <ref type="figure" target="#fig_6">8</ref>) instead of traversing the entire wakeup logic with destination tags ( 4 in Figure <ref type="figure">2</ref>), and 2) selecting issue candidates among instructions at the FIFO heads (Figure <ref type="figure" target="#fig_8">10b</ref>) rather than all in-flight ones (Figure <ref type="figure" target="#fig_8">10a</ref>). These changes do not lengthen the critical path, so we conclude that Ballerino is able to operate at the same frequency as the baseline. We also evaluate the energy efficiency of Ballerino operating at the lower frequency (and voltage) levels in Section VI-E2.</p><p>2) Unified vs. Distributed IQ: A unified IQ has been adopted by Intel, RISC-V, and IBM POWER processors <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. On the other hand, AMD Zen and ARM Cortex-A processors have employed a distributed IQ where each FU has a dedicated IQ <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. The former provides better capacity efficiency by allowing the IQ entries to be shared by any instructions regardless of their opcodes. However, the number of inputs to each prefixsum circuit should be equivalent to the number of the IQ entries, which increases the complexity of the select logic. The latter facilitates the simplified select logic by reducing the number of inputs to each prefix-sum circuit, but the IQ entries cannot be fully utilized because each IQ entry is reserved for specific instruction types. Ballerino takes advantages of both the unified and distributed designs: all the IQ entries are shared by the FUs via port arbitration at dispatch (Section IV-B), while each prefix-sum circuit has a small number of inputs by monitoring only the heads of IQs (Section IV-E). Therefore, the IQ entries can be fully utilized while the select logic is implemented with low complexity similar to the one in a distributed IQ.</p><p>3) Hardware Overhead: The overheads of implementing Ballerino (with eight S/P-IQs) over CES (with eight P-IQs) are as follows: 1) the S-IQ and P-SCB have three and six more read ports than their counterparts, respectively, 2) each P-IQ has one more pair of head and tail pointers, 3) LFST is extended to maintain steering information (64 bytes), 4) the steer logic has four more muxs to support M-dependenceaware steering, and 5) each prefix-sum circuit has three more inputs. Note that, prefix-sum circuits are also required in CES for arbitration to the heterogeneous FUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL METHODOLOGY</head><p>In our experiments, we use an execution-driven, cyclebased x86 processor simulator <ref type="bibr" target="#b36">[37]</ref>. The memory system is modeled by an integrated DDR4 DRAM simulator <ref type="bibr" target="#b37">[38]</ref>. We run the applications from both SPEC CPU2006 and CPU2017 benchmark suites <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. For each application, we use the reference input set and run the most representative region of 300 million instructions chosen using the SimPoint methodology <ref type="bibr" target="#b40">[41]</ref>, after a warm-up phase of 300 million instructions. Energy consumption is estimated via modified version of McPAT <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> at the 22 nm process technology. We also incorporate the modeling of the newly added structures (e.g., MDP) and control logic (e.g., steer logic) on top of an MR2 model introduced in <ref type="bibr" target="#b42">[43]</ref>.</p><p>The microarchitectural parameters and scheduling window configurations of evaluated designs are listed in and Table <ref type="table" target="#tab_5">II</ref>, respectively. We evaluate a wide range of microarchitectures that can be broadly categorized into three groups:</p><p>• Baseline: An in-order core (InO) and an out-of-order core (OoO). • Prior work: CES <ref type="bibr" target="#b2">[3]</ref>, CASINO <ref type="bibr" target="#b1">[2]</ref>, and a front-end execution architecture (FXA) <ref type="bibr" target="#b0">[1]</ref>. • This work: Ballerino (w/ eight S/P-IQs) and its variants. The baseline 8-wide out-of-order core is modeled after Skylake microarchitecture <ref type="bibr" target="#b23">[24]</ref>. For a fair comparison, we use the same pipeline configuration across all of the evaluated microarchitectures. In addition, we set the overall number of IQ entries to the same, except for FXA and Ballerino. In FXA, we set the IQ size to the half of that of the baseline. In Ballerino, the size of the S-IQ does not need to be larger than the 2× dispatch width. In CASINO, we find the optimal combination of the S-IQ(s) and inorder IQ in size that achieves the best performance using the same number of entries as the baseline. For 4-wide and 2-wide out-of-order cores, we set the sizes of the ROB and IQ following the most widely adopted values in previous studies. Then, we perform sensitivity experiments to find the optimal parameter values of the other structures allowing less than 10% performance impact. The IQs in CASINO and FXA are configured according to the conventions in the original papers. The number of IQs in CES and Ballerino is scaled according to the issue width, while the total number of IQ entries is set to the same as the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RESULTS AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ballerino Performance</head><p>Figure <ref type="figure" target="#fig_0">11</ref> compares the performance of Ballerino (normalized to InO) to a wide range of microarchitectures sharing the same purpose: support dynamic scheduling with high energy efficiency. Besides CES and CASINO, we also evaluate FXA <ref type="bibr" target="#b0">[1]</ref> to further explore the efficacy of our proposed techniques. FXA is a readiness-based microarchitecture having an in-order execution unit (IXU) that consists of the functional units and a bypass network, in front of a common out-of-order back-end. The IXU comprises multiple pipeline stages, executing ready-at-dispatch instructions  Figure <ref type="figure" target="#fig_0">11</ref>: Performance gains of different cores with 8-wide issue capability over in-order core. Ballerino with eight and twelve S/P-IQs respectively achieve 2.7× and 2.8× speedups, which are within 7% and 2% of that of OoO.</p><p>as well as their consumers whose data dependences are resolved inside the IXU. Instructions not executed by the IXU are dispatched to the back-end and scheduled out of order by the conventional out-of-order IQ. CES, CASINO, FXA, and Ballerino (w/ eight S/P-IQs) achieve speedups of 2.4×, 2.1×, 2.8×, and 2.7× over InO, respectively. CASINO shows a relatively low speedup since the sequential arrangement of the IQs is not well suited for a wide-issue design (further explored in Section VI-E1). Ballerino achieves significant performance improvements over both CES (11%) and CASINO (29%) by effectively filtering out ready instructions from the speculative scheduling window of the S-IQ as well as tracking the data dependences of the other instructions in the clustered P-IQs. A variant of Ballerino with four more P-IQs (Ballerino-12) delivers comparable performance to FXA. Even though the backend of FXA provides fully out-of-order issue capability, its IQ size is set to one-half of the baseline to reduce energy consumption. Therefore, the effective size of its scheduling window is limited even considering the capacity of the IXU. In some applications, Ballerino outperforms FXA by taking advantage of the larger scheduling window that is adaptively partitioned and allocated to dynamic instructions from different DCs. Using twelve in-order IQs, Ballerino-12 achieves performance within 2% of that of OoO.</p><p>The right-most bas in each application shows the performance impact of the capability to track the criticality of individual instructions (i.e., ages) and prioritize the oldest one in each port. It can be implemented with either the compaction circuit <ref type="bibr" target="#b20">[21]</ref> or age matrices <ref type="bibr" target="#b15">[16]</ref>. Our simulation reveals that supplementing this feature improves the performance of OoO by 2%, assuming that it does not lengthen the clock cycle time. This result infers that, as already discussed in <ref type="bibr" target="#b3">[4]</ref>, the age-based select policy would provide no benefit in some implementations if the reduced execution cycles and the increased cycle time are not properly balanced. On the other hand, Ballerino enables the age-based select mechanism (except for among the instructions at the P-IQ heads), without increasing the critical path of the wakeupselect scheduling loop (i.e., clock cycle time).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scheduling Performance</head><p>According to Figure <ref type="figure" target="#fig_12">12</ref>, Ballerino shows lower decodeto-issue delay compared to CES and CASINO. More specifically, Ballerino has slightly larger decode-to-dispatch delay than CASINO, which is much smaller than CES. In addition, the ready-to-issue delay of LdC in Ballerino is almost zero, similar to CES. As discussed in Section II-C, the readyto-issue delay of Ld indicates that Ballerino reaches the maximum limit of capable MLP exploitation. Note that a load-independent instruction (Rst) in Ballerino experiences some delay from ready to issue, because sometimes they get stalled in the middle of the S-IQ due to the steering stall at its head. CES experiences the same situation in the allocation queue, but such instructions are not counted as ready in CES because they are not renamed yet. Step 1 (S-IQ+7 P-IQs)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Impact of Proposed Techniques</head><p>Step 2 (+MDA steering)</p><p>Step 3 (+P-IQ sharing, Ballerino)</p><p>Step 3 (w/o constraints, ideal)</p><p>Figure <ref type="figure" target="#fig_13">13</ref>: Performance gain over in-order core. Proposed microarchitectural techniques are applied step by step.</p><p>41% of dynamic instructions and improves performance by 7 percentage points. Nevertheless, Step 1 still suffers from a lack of free P-IQs, because 1) individual DCs starting from M-dependent loads unnecessarily the P-IQs and 2) most of the P-IQs are usually occupied by the load-dependent DCs waiting for the resolution of memory accesses. We address the first issue via MDA steering in</p><p>Step 2, which leads to a performance gain of 5 percentage points. Note that applying MDA steering does not change the distribution of instructions that much. This is because each MDA steering event increases the effective number of P-IQs by one only from the steering of a consumer load to the issue of the producer store. Yet, it accelerates the expansion of the scheduling window by allowing younger non-ready instructions to be steered during this period, which otherwise would block the speculative issue at the S-IQ head.</p><p>Step 3 increases the effective number of the P-IQs by allowing up to two DCs to share a single P-IQ. It improves the utilization of the entries and read ports of the P-IQs, which translates into a performance improvement of 13 percentage points over Step 2. In Step 3, a cluster of P-IQs issues 6 percentage points more instructions than Step 2, which facilitates the S-IQ to find ready instructions more aggressively. Step 3 exhibits some performance degradation in leela due to the increased memory order violations caused by its enlarged scheduling window. Step 3 achieves an additional performance gain of 5 percentage points assuming no constraints discussed in Section IV-D (ideal); P-IQ sharing is enabled regardless of the pointer locations and both partitions are able to issue ready instructions in any cycle. In other words, our final design implementation provides comparable performance to an ideal design, while leveraging the P-IQs having the same numbers of entries and ports as those of CES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Energy Consumption and Efficiency</head><p>Figure <ref type="figure" target="#fig_14">15</ref> shows the breakdown of core-wide energy consumption for CES, CASINO, FXA, Ballerino, and Ballerino-12 normalized to that of OoO. We classify the core components into nine categories. Among them, Schedule includes the ROB and various types of the IQs. Note that CES </p><p>62%), respectively. Even though FXA issues about half of dynamic instructions in the IXU, the out-of-order IQ at the back-end consumes significant scheduling energy, which leads to relatively high energy consumption. CASINO also dissipates higher scheduling energy than CES and Ballerino variants, because the sequential arrangement of the S-IQs fundamentally necessitates a number of read ports per S-IQ -equal to the dispatch width -to prevent the front-end from being stalled. Furthermore, non-ready instructions within the speculative scheduling window of an S-IQ are passed to the next IQ, which requires an additional copy operation. CES and Ballerino provide similar energy savings. Figure <ref type="figure" target="#fig_15">16</ref> presents the energy efficiency of each microarchitecture in terms of performance per energy, the inverse of the energy-delay product (EDP), relative to that of OoO. As shown in the figure, Ballerino (Ballerino-12) achieves energy efficiency that is 9% (7%), 42% (39%), 5% (3%), and 22% (20%) higher than CES, CASINO, FXA, and OoO, respectively. The reason is that Ballerino yields performance close to OoO (highest) while consuming energy close to CES (lowest) via the synergistic combination of principal scheduling factors: Readiness, M/R-dependences, and oldest-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Sensitivity Analysis</head><p>1) Issue Width: Figure <ref type="figure" target="#fig_17">17a</ref> shows the speedup (in terms of execution time) of each microarchitecture over 2-wide InO with respect to the issue width (see Table <ref type="table" target="#tab_5">I</ref> and Table <ref type="table" target="#tab_5">II</ref>). The performance of each microarchitecture increases linearly with the issue width and operating frequency. CASINO offers great speedup over InO with a 2-wide issue width, but exhibits relatively poor scalability than others. This is because it is primarily designed as an alternative to a 2wide out-of-order core by focusing solely on one aspect of dynamic scheduling (i.e., readiness). Sequentially adding more S-IQs does not yield a dramatic speedup because 1) each S-IQ cannot precisely handle the back-to-back issue of instructions from multiple DCs and 2) instructions not speculatively issued by the S-IQs are eventually inserted into the last IQ where they are issued in original program order.</p><p>On the other hand, CES and Ballerino show good scalability since they provide functionality to keep track of the individual DCs and issue ready instructions out of program order. For all the configurations, Ballerino achieves higher performance than CES since 1) Ballerino proactively filters out ready-at-dispatch instructions using the S-IQ and 2) MDA steering and P-IQ sharing increase the effective number of the P-IQs. As a synergistic effect, Ballerino's scheduling window grows faster than that of CES, resulting in more aggressive extraction of ILP and MLP. Across all configurations, FXA achieves similar performance improvements to those of OoO by filtering out about half of dynamic instructions in the IXU and performing fully outof-order scheduling for the rest at the back-end. Figure <ref type="figure" target="#fig_17">17a</ref> also shows the speedups on state-of-the-art 10-wide issue designs running at 3.4 GHz <ref type="bibr" target="#b43">[44]</ref>. Beyond the 8-wide issue width, InO and CASINO show negligible speedups since their maximum achievable ILP is not higher than 8. On the other hand, the other microarchitectures provide similar performance gains ranging from 5% to 6%.</p><p>2) Frequency and Voltage: Figure <ref type="figure" target="#fig_17">17b</ref> shows the speedup, power, energy, and energy efficiency of Ballerino and OoO (normalized to CES) with respect to different frequency and voltage levels <ref type="bibr" target="#b45">[45]</ref>. L4, L3, L2, and L1 denote the frequency and voltage levels of [3.4 GHz, 1.04 V], [3.2 GHz, 1.01 V], [3.0 GHz, 0.98 V], and [2.8 GHz, 0.96 V], respectively. As the level goes down, both static and dynamic power consumption decrease. If Ballerino is implemented as an efficiency core operating within the same power budget as CES, it would run at L3, exhibiting 5% higher performance and 9% higher energy efficiency. Assuming the same performance as CES, Ballerino and OoO would run at L2 and L1, providing 9% higher and 27% lower energy efficiency, respectively. Ballerino running at L4 shows 27% higher energy efficiency than OoO running at L3 while providing comparable performance.</p><p>3) Configuration of P-IQs: Figure <ref type="figure" target="#fig_17">17c</ref> demonstrates the effect of a varying number of P-IQs on the performance of  With up to eleven P-IQs, adding a P-IQ to the back-end directly translates into performance improvement. More than eleven P-IQs, however, the performance impact becomes smaller since only a handful of further parallelisms can be exploited. Ballerino with eleven P-IQs (Ballerino-12) offers comparable performance to OoO, with additional overhead of eight more P-SCB read ports, a 1-bit lengthened P-SCB/LFST entry, and four more inputs to each prefix-sum circuit, over the one with seven P-IQs. Note that even with overall twelve S/P-IQs, the critical path of a prefix-sum circuit remains as 4 ( log 2 15 ), and the number of inputs is slightly more than that of a distributed IQ assuming that the IQ entries are equally partitioned across issue ports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RELATED WORK</head><p>Throughout the paper, a large body of prior work has been discussed. This section presents some other related work.</p><p>To reduce the power consumption of dynamic scheduling, hybrid scheduling schemes have been proposed. These schemes handle instructions that will not benefit from the power-hungry wakeup and select logic in a special way, to reduce the size and/or issue width of the out-of-order IQ. Such non-critical instructions are initially steered to the simple in-order IQ. Later, they are either pushed back to the out-of-order IQ to be scheduled with minimal wakeup and select operations <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b47">[47]</ref>, or directly issued from the inorder IQ for energy efficiency <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b48">[48]</ref>. Delay and Bypass (DNB) <ref type="bibr" target="#b24">[25]</ref> classifies dynamic instructions based on both criticality and readiness. Then, it inserts only the critical and non-ready instructions to the out-of-order IQ, while steering the others to the energy-efficient in-order IQs.</p><p>Another approach is to promote some particular instructions using the separate in-order execution engines or scheduling them via the dedicated in-order IQs. Two pass pipelining <ref type="bibr" target="#b49">[49]</ref> uses two in-order back-end pipelines to cope with variable load latencies. Ready-at-dispatch instructions are executed in the advance pipeline, while the others are deferred to the backup pipeline. Recently, slice-out-of-order cores have been explored as a new class of cores aiming at complexity-effective dynamic scheduling on a stall-onuse in-order core <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. These cores primarily focus on exploiting MLP by extracting (backward <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> or forward <ref type="bibr" target="#b9">[10]</ref>) load slices from the original instruction stream and promoting them using the separate in-order IQ(s). These restricted forms of out-of-order execution prevent a conventional in-order pipeline from stalling due to the long-latency memory accesses (i.e., cache misses) by triggering such memory accesses earlier or putting aside the instructions dependent on such memory accesses.</p><p>Replay-based scheduling schemes leverage the repetitive nature of instruction issue schedules <ref type="bibr" target="#b50">[50]</ref>, <ref type="bibr" target="#b51">[51]</ref>, <ref type="bibr" target="#b52">[52]</ref>, <ref type="bibr" target="#b53">[53]</ref>, <ref type="bibr" target="#b54">[54]</ref>. Such scheduling schemes memoize the issue order of dynamic instructions on the out-of-order pipeline, and replay the same schedules in the energy-efficient in-order pipeline in future iterations. Ideally, they could achieve near-out-oforder performance, but must be equipped with the out-oforder IQ as well as handling mechanisms for unexpected microarchitectural events such as mis-speculations during replay phases. Some recent work leverages both criticality and repetitiveness of dynamic instructions <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b55">[55]</ref>. Ando proposed to prioritize the issue of instructions in unconfident branch slices to reduce the mis-speculation penalty <ref type="bibr" target="#b3">[4]</ref>. Some of the out-of-order IQ entries are reserved for such sliced instructions, and they are prioritized over the other instructions when they are granted by the select logic. This effectively expedites the resolution of (possibly) mispredicted branches and subsequent recovery process. Diavastos and Carlson proposed an efficient dynamic scheduling built upon a precise load delay tracking scheme <ref type="bibr" target="#b55">[55]</ref>. They adopted systolic priority queues (SPQs) <ref type="bibr" target="#b56">[56]</ref>, and arranged them in parallel to facilitate out-of-order scheduling with low complexity. Dispatched instructions are steered to one of the SPQs by considering opcodes, data dependences, and load balancing. Each SPQ reorders instructions according to the predicted issue time, and only an instruction at the head is eligible for issue. Ballerino conducts out-of-order scheduling by dynamically examining the readiness, M/Rdependences, and ages of instructions by only using in-order IQs. Therefore, neither the complex out-of-order IQs nor issue time predictions are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this work, we propose a novel microarchitecture named Ballerino, built upon three key principles that drive dynamic scheduling: readiness, M/R-dependences, and oldest-first selection. Starting from a combination of two compatible microarchitecture designs, two simple and effective architectural techniques are supplemented to enable a group of the in-order IQs to generate highly optimized issue schedules comparable to that of the fully out-of-order IQ while consuming much less energy. Ballerino first filters out the readyat-dispatch instructions and their consumers using the S-IQ. Then, the other instructions are partitioned into multiple DCs honoring both M/R-dependences, and scheduled by the individual P-IQs. With a simple modification, we facilitate P-IQ sharing that allows multiple short-length DCs to share a single P-IQ, being provided with the opportunities for outof-order issue. The proposed design partially benefits from the oldest-first selection by leveraging the relative order of instructions encoded in their locations in the scheduler. As a synergistic effect, Ballerino with twelve S/P-IQs achieves performance comparable to the 8-wide out-of-order core while consuming 19% less energy, which leads to a corewide energy efficiency improvement of 20%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Definition of dependence chain. Solid and dashed arrows indicate register dependences and memory dependences, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Breakdown of instruction steering results in CES with eight P-IQs<ref type="bibr" target="#b2">[3]</ref>. From left to right, speedup over in-order core degrades due to increased steering stalls caused by ready-at-dispatch instructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>148Figure 5 :</head><label>5</label><figDesc>Figure 5: Three-step out-of-order issue queue rebuilding process. Four in-order IQs are displayed for brevity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>IPC sensitivity to P-IQ in Step 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Analysis on architectural bottlenecks</figDesc><graphic url="image-1.png" coords="6,434.59,268.31,102.67,86.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Ballerino core microarchitecture. Components for out-of-order execution are colored in blue. P -IQ 2 is shared by two DCs and second partition (P art 1 ) is activated for issue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Instruction steering mechanism in Ballerino</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Two operation modes of P-IQ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Prefix-sum circuit of select logic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>154</head><label></label><figDesc>Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 13:58:35 UTC from IEEE Xplore. Restrictions apply.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>-IQ + 7 P-IQs) Ballerino-12 (1 S-IQ + 11 P-IQs) OoO OoO (w/ oldest-first selection)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>All Ld LdC Rst All Ld LdC Rst All Ld LdC Rst All</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Scheduling performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 and</head><label>13</label><figDesc>Figure 13 and Figure 14 demonstrate the performance impact of the proposed techniques and the breakdown of instructions issued from different IQs on the variants of Ballerino, respectively. CES has eight P-IQs that keep track of up to eight in-flight DCs concurrently. Applying Mdependence-aware (MDA) steering to CES improves performance by 4 percentage points. By substituting one P-IQ with an S-IQ (Step 1), steering stalls caused by ready-atdispatch instructions are completely eliminated. In addition, the S-IQ can issue consecutive instructions from different DCs in a cycle. As a result, the S-IQ speculatively issues</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Energy consumption normalized to OoO. From left to right, each stacked bar indicates the core-wide energy consumption of CES, CASINO, FXA, Ballerino, Ballerino-12, and OoO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: Energy efficiency (performance per energy) normalized to 8-wide out-of-order core</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>157</head><label></label><figDesc>Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 13:58:35 UTC from IEEE Xplore. Restrictions apply.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Sensitivity analysis on various hardware configurations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table I :</head><label>I</label><figDesc>Core and Memory System Configurations</figDesc><table><row><cell>Component</cell><cell>InO</cell><cell>OoO, CES, CASINO, FXA, Ballerino</cell></row><row><cell>Core</cell><cell cols="2">8(/4/2)-wide superscalar @3.4(/2.5/2.0) GHz 4(/4/2)-wide decode &amp; dispatch, 8(/4/2)-wide issue &amp; commit</cell></row><row><cell></cell><cell cols="2">TAGE: 17-bit GHR with one bimodal and</cell></row><row><cell>Branch predictor</cell><cell cols="2">four tagged predictors (overall 32 KiB)</cell></row><row><cell></cell><cell cols="2">512 sets, 4-way set associative BTB</cell></row><row><cell>MDP [11]</cell><cell>-</cell><cell>1024-entry SSIT, 7-bit SSID</cell></row><row><cell>Recovery penalty</cell><cell>8 cycles</cell><cell>11 cycles</cell></row><row><cell>Reorder logic</cell><cell>64(/32/16)-entry scoreboard (SCB)</cell><cell>224(/128/48)-entry reorder buffer (ROB)</cell></row><row><cell>Load queue</cell><cell>-</cell><cell>72(/48/24) entries</cell></row><row><cell>Store queue</cell><cell>16(/8/4) entries</cell><cell>56(/32/16) entries</cell></row><row><cell>Physical registers</cell><cell>-</cell><cell>180(/128/32) int 168(/96/32) fp</cell></row><row><cell></cell><cell cols="2">4 int ALUs (P0, P1, P5, P6), 1 int DIV (P0), 1 int MUL (P1),</cell></row><row><cell>Functional units</cell><cell cols="2">2 fp ADDs (P0, P1), 1 fp DIV (P0), 2 fp MULs (P0, P1)</cell></row><row><cell></cell><cell cols="2">4 AGUs (P2, P3, P4, P7), 2 branches (P0, P6)</cell></row><row><cell>L1 I/D</cell><cell cols="2">32 KiB, 8-way, 4-cycle latency, 8 MSHRs, stride-based prefetcher</cell></row><row><cell>L2 cache</cell><cell cols="2">256 KiB, 8-way, 12-cycle latency, 32 MSHRs</cell></row><row><cell>L3 cache</cell><cell cols="2">1 MiB, 4-way, 42-cycle latency, 64 MSHRs</cell></row><row><cell>Main memory</cell><cell cols="2">4 GiB, DDR4 DRAM, 2400 MT/s, 1 channel, 1 rank</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table I Table II :</head><label>III</label><figDesc>Scheduling Window Configurations</figDesc><table><row><cell>Microarchitecture</cell><cell>Configuration: 8(/4/2)-wide superscalar</cell></row><row><cell>InO</cell><cell>96(/64/32)-entry in-order IQ [8(/4/2)r4(/4/2)w]</cell></row><row><cell>OoO</cell><cell>96(/64/32)-entry out-of-order IQ [8(/4/2)r4(/4/2)w]</cell></row><row><cell>CES [3]</cell><cell>8(/4/2)× 12(/16/16)-entry P-IQ [1r4(/4/2)w]</cell></row><row><cell></cell><cell>8(/6/4)-entry S-IQ0 [4(/3/2)r4(/3/2)w], 40(/52/-)-entry S-IQ1</cell></row><row><cell>CASINO [2]</cell><cell>[4(/3/-)r4(/3/-)w], 40(/-/-)-entry S-IQ2 [4(/-/-)r4(/-/-)w],</cell></row><row><cell></cell><cell>8(/6/28)-entry in-order IQ [4(/3/2)r4(/3/2)w]</cell></row><row><cell>FXA [1]</cell><cell>3-stage IXU [4(/4/2)r4(/4/2)w], 48(/32/16)-entry out-of-order IQ [4(/4/2)r4(/4/2)w]</cell></row><row><cell>Ballerino</cell><cell>8(/8/4)-entry S-IQ [4(/4/2)r4(/4/2)w], 7(/3/1)× 12(/16/16)-entry P-IQ [1r4(/4/2)w]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>156</head><label></label><figDesc>Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 13:58:35 UTC from IEEE Xplore. Restrictions apply.</figDesc><table><row><cell cols="2">CES CASINO FXA Ballerino</cell><cell>Ballerino-12</cell><cell>OoO</cell><cell>L1 I/D$</cell><cell>Fetch/Decode</cell><cell>Rename</cell><cell>Steer</cell><cell>MDP</cell><cell>Schedule</cell><cell>LSQ</cell><cell>PRF</cell><cell>FUs</cell><cell>1.2</cell></row><row><cell>Energy relative to OoO</cell><cell>0.0 0.2 0.4 0.6 0.8 1.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0">Authorized licensed use limited to: Tsinghua University. Downloaded on December 31,2022 at 13:58:35 UTC from IEEE Xplore. Restrictions apply.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank the anonymous reviewers for their valuable comments that helped to improve the quality of the paper. This work was supported in part by Institute of Information communications Technology Planning Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2021-0-00853, Developing Software Platform for Programming of PIM), in part by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2021R1G1A1092196), and in part by Samsung Electronics Company, Ltd., Hwaseong, Korea. W. W. Ro is the corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A front-end execution architecture for high energy efficiency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shioya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchitecture</title>
				<meeting>the 47th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="419" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Casino core microarchitecture: Generating out-of-order schedules using cascaded in-order scheduling windows</title>
		<author>
			<persName><forename type="first">I</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="383" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Complexityeffective superscalar processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual international symposium on Computer architecture</title>
				<meeting>the 24th annual international symposium on Computer architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="206" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Performance improvement by prioritizing the issue of the instructions in unconfident branch slices</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="82" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Runtime power monitoring in high-end processors: Methodology and empirical data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Isci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 36th Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">93</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Energy-effective issue logic</title>
		<author>
			<persName><forename type="first">D</forename><surname>Folegnani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Symposium on Computer Architecture</title>
				<meeting>the 28th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">CMOS VLSI design: a circuits and systems perspective</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Weste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The load slice core microarchitecture</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heirman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Allam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="272" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Freeway: Maximizing mlp for slice-out-of-order execution</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Black-Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="558" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The forward slice core microarchitecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lakshminarasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naithani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feliu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eeckhout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques</title>
				<meeting>the ACM International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="361" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Memory dependence prediction using store sets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="142" to="153" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Streamlining inter-operation memory communication via data dependence prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 30th Annual International Symposium on Microarchitecture</title>
				<meeting>30th Annual International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="235" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On pipelining dynamic instruction scheduling logic</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 33rd Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluation of issue queue delay: Banking tag ram and identifying correct critical path</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE 29th International Conference on Computer Design (ICCD)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="313" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A high-speed dynamic instruction scheduling scheme for superscalar processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>-I. Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 34th ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>34th ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<publisher>MICRO-34. IEEE Computer Society</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="225" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Matrix scheduler reloaded</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sassone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rupley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brekelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An open source fpga-optimized out-of-order risc-v soft processor</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mashimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Akaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koizumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kadomoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Field-Programmable Technology (ICFPT)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="63" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Quantifying the complexity of superscalar processors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences, Tech. Rep.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An oldest-first selection logic implementation for noncompacting issue queues</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buyuktosunoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El-Moursy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Albonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th Annual IEEE International ASIC/SOC Conference</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
	<note>microprocessor power reduction</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Performance improvement with circuitlevel speculation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-L</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-33</title>
				<meeting>33rd Annual IEEE/ACM International Symposium on Microarchitecture. MICRO-33</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="page" from="348" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Issue logic for a 600-mhz outof-order execution microprocessor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="707" to="712" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Design of an 8-wide superscalar risc microprocessor with simultaneous multithreading</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Biro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Bowhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Dever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gammack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Germini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">2002 IEEE International Solid-State Circuits Conference. Digest of Technical Papers (Cat. No. 02CH37315</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="334" to="472" />
			<date type="published" when="2002">2002</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">40-entry unified outof-order scheduler and integer execution unit for the amd bulldozer x86-64 core</title>
		<author>
			<persName><forename type="first">M</forename><surname>Golden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arekapudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vinh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE International Solid-State Circuits Conference</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="80" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inside 6th-generation intel core: New microarchitecture codenamed skylake</title>
		<author>
			<persName><forename type="first">J</forename><surname>Doweck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>.-Y. Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mandelblat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahatekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yoaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="52" to="62" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Delay and bypass: Ready and criticality aware instruction scheduling in out-of-order processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Black-Schaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reducing wire delay penalty through value prediction</title>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Parcerisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture</title>
				<meeting>the 33rd annual ACM/IEEE international symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dependence-based scheduling revisited: A tale of two baselines</title>
		<author>
			<persName><forename type="first">P</forename><surname>Salverda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zilles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th Annual Workshop on Duplicating, Deconstructing, and Debunking. Citeseer</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Computer architecture: a quantitative approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Design of a computer-the control data 6600</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Thornton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>Scott Foresman &amp; Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reno: a rename-based instruction optimizer</title>
		<author>
			<persName><forename type="first">V</forename><surname>Petric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd International Symposium on Computer Architecture (ISCA&apos;05)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="98" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Two-stage, pipelined register renaming</title>
		<author>
			<persName><forename type="first">E</forename><surname>Safi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Veneris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1926" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The xeon® processor e5-2600 v3: A 22 nm 18-core product family</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bowhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Stackhouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Houghton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Franza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Ibm power8 processor core microarchitecture</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Norstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Eickemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leenstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Konigsburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="3" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The amd &quot;zen 2&quot; processor</title>
		<author>
			<persName><forename type="first">D</forename><surname>Suggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subramony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bouvier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="45" to="52" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The amd next-generation &quot;zen 3&quot; core</title>
		<author>
			<persName><forename type="first">M</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="7" to="12" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cortex®-a72 mpcore processor technical reference manual (revision r0p2)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arm</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multi2Sim: A Simulation Framework for CPU-GPU Computing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ubal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mistry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21st International Conference on Parallel Architectures and Compilation Techniques</title>
				<meeting>of the 21st International Conference on Parallel Architectures and Compilation Techniques</meeting>
		<imprint>
			<date type="published" when="2012-09">Sep. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ramulator: A fast and extensible dram simulator</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer architecture letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="49" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Spradling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPEC CPU2006 Benchmark Tools</title>
		<title level="s">SIGARCH Computer Architecture News</title>
		<imprint>
			<date type="published" when="2007-03">March 2007</date>
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spec cpu2017: Next-generation compute benchmark</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bucek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Kistowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of the 2018 ACM/SPEC International Conference on Performance Engineering</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="41" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the 10th International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mcpat: an integrated power, area, and timing modeling framework for multicore and manycore architectures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 42nd Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="469" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Quantifying sources of error in mcpat and potential impacts on architectural studies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA)</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="577" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Ice lake (client) -microarchitectures -intel</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName><surname>Available</surname></persName>
		</author>
		<ptr target="https://en.wikichip.org/wiki/intel/microarchitectures/icelake(client" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A dual-core risc-v vector processor with on-chip fine-grain power management in 28-nm fd-soi</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Dabbelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-F</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asanović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2721" to="2725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Long term parking (ltp) criticality-aware resource allocation in ooo processors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sembrant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hagersten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Black-Shaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seznec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th International Symposium on Microarchitecture</title>
				<meeting>the 48th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="334" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A large, fast instruction window for tolerating cache misses</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koppanalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rotenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture, ser. ISCA &apos;02</title>
				<meeting>the 29th Annual International Symposium on Computer Architecture, ser. ISCA &apos;02<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fiforder microarchitecture: Ready-aware instruction scheduling for ooo processors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Black-Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="716" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Beating in-order stalls with &quot;flea-flicker&quot; two-pass pipelining</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Sias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 36th Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">387</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Discerning the dominant out-of-order performance advantage: Is it speculation or dynamism</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcfarlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zilles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
				<meeting>the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Exploiting instruction level parallelism in processors by caching scheduled groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hopkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
				<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="13" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Execution cache-based microarchitecture for power-efficient superscalar processors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Talpes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Very Large Scale Integration (VLSI) Systems</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="14" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dynamos: dynamic schedule migration for heterogeneous cores</title>
		<author>
			<persName><forename type="first">S</forename><surname>Padmanabha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lukefahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 48th Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="322" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The heterogeneous block architecture</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fallin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Design (ICCD)</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="386" to="393" />
		</imprint>
	</monogr>
	<note>32nd IEEE</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Efficient instruction scheduling using real-time load delay tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Diavastos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.03112</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Systolic priority queues</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; Carnegie-Mellon Univ Pittsburgh Pa Dept Of Computer</forename><surname>Science</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
