<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="laboratory">Advanced Robotics and Intelligent Systems (ARIS) Lab</orgName>
								<orgName type="institution">University of Guelph</orgName>
								<address>
									<postCode>N1G 2W1</postCode>
									<settlement>Guelph</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">De-partment of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Advanced Robotics and Teleoperation (ART) Lab</orgName>
								<orgName type="institution">University of Alberta</orgName>
								<address>
									<addrLine>Ed-monton</addrLine>
									<postCode>T6G 2G7</postCode>
									<region>AB</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CDC6C055280A24D0E6B2B81E90B98FFA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T08:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Network Approaches to Dynamic</head><p>Collision-Free Trajectory Generation Simon X. Yang, Member, IEEE, and Max Meng, Member, IEEE Abstract-In this paper, dynamic collision-free trajectory generation in a nonstationary environment is studied using biologically inspired neural network approaches. The proposed neural network is topologically organized, where the dynamics of each neuron is characterized by a shunting equation or an additive equation. The state space of the neural network can be either the Cartesian workspace or the joint space of multi-joint robot manipulators. There are only local lateral connections among neurons. The real-time optimal trajectory is generated through the dynamic activity landscape of the neural network without explicitly searching over the free space nor the collision paths, without explicitly optimizing any global cost functions, without any prior knowledge of the dynamic environment, and without any learning procedures. Therefore the model algorithm is computationally efficient. The stability of the neural network system is guaranteed by the existence of a Lyapunov function candidate. In addition, this model is not very sensitive to the model parameters. Several model variations are presented and the differences are discussed. As examples, the proposed models are applied to generate collision-free trajectories for a mobile robot to solve a maze-type of problem, to avoid concave U-shaped obstacles, to track a moving target and at the same to avoid varying obstacles, and to generate a trajectory for a two-link planar robot with two targets. The effectiveness and efficiency of the proposed approaches are demonstrated through simulation and comparison studies.</p><p>Index Terms-Dynamic environment, mobile robot, neural dynamics, neural networks, obstacle avoidance, robot manipulators, trajectory generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T RAJECTORY generation with obstacle avoidance is a fundamentally important issue in robotics. Real-time collision-free trajectory generation becomes more difficult when robots are in a dynamic, unstructured environment. There are a lot of studies on trajectory generation for robots using various approaches (e.g., <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b46">[47]</ref>- <ref type="bibr" target="#b53">[54]</ref> and <ref type="bibr" target="#b58">[59]</ref>- <ref type="bibr" target="#b60">[61]</ref>). Some of the previous models (e.g., <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b49">[50]</ref> and <ref type="bibr" target="#b59">[60]</ref>) use global methods to search the pos-sible paths in the workspace, which normally deal with static environment only and are computationally expensive when the environment is complex. Some searching based models (e.g., <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b49">[50]</ref>) suffer from undesired local minima, i.e., the robots may be trapped in some cases such as with concave U-shaped obstacles. Seshadri and Ghosh <ref type="bibr" target="#b46">[47]</ref> proposed a new path planning model using an iterative approach. However this model is computationally complicated, particularly in a complex environment. Li and Bui <ref type="bibr" target="#b27">[28]</ref> proposed a fluid model for robot path planning in a static environment. Ong and Gilbert <ref type="bibr" target="#b37">[38]</ref> proposed a new model for path planning with penetration growth distance, which searches over collision paths instead of searching over free space as most other models do. This model can generate optimal, continuous robot paths in a static environment only. Oriolo et al. <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> proposed a model for real-time map building and navigation for a mobile robot, where a global path planning plus a local graph search algorithm and several cost functions are used.</p><p>Several neural network models (e.g., <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b45">[46]</ref> and <ref type="bibr" target="#b58">[59]</ref>) were proposed to generate real-time trajectories through learning. Ritter et al. <ref type="bibr" target="#b45">[46]</ref> proposed a Kohonen's self-organizing mapping algorithm based neural network model to learn the transformation from Cartesian workspace to the robot manipulator joint space. Li and Öǧmen <ref type="bibr" target="#b26">[27]</ref> proposed a neural network model for real-time trajectory generation by combining an adaptive sensory-motor mapping model and an on-line visual error correction model. However, both models deal with static environment only and assume that there are no obstacles in the workspace. Muñiz et al. <ref type="bibr" target="#b33">[34]</ref> proposed a neural network model for the navigation of a mobile robot, which can generate dynamic trajectories with obstacle avoidance through unsupervised learning. However, this model is computationally complicated since it incorporates the vector associative map model and the direction-to-rotation effector control transform model <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Fujii et al. <ref type="bibr" target="#b9">[10]</ref> proposed a multilayer reinforcement learning based model for path planning with a complicated collision avoidance algorithm. However, the generated trajectories using learning based approaches are not optimal, particularly during the initial learning phase.</p><p>Glasius et al. <ref type="bibr" target="#b12">[13]</ref> proposed a Hopfield-type neural network model for real-time trajectory generation with obstacle avoidance in a nonstationary environment. It is rigorously proved that the generated trajectory does not suffer from undesired local minima <ref type="bibr" target="#b12">[13]</ref>. They later proposed another model <ref type="bibr" target="#b13">[14]</ref> by cascading two neural network layers where each layer has a similar architecture to the model in <ref type="bibr" target="#b12">[13]</ref>. This is an unsupervised model which uses the second layer to find the next robot position. However, it doubles the computational burden as a result. All these models <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref> suffer from slow dynamics and cannot perform properly in a fast changing environment, since they unrealistically require that the robot dynamics must be faster than the target and obstacle dynamics <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>In this paper, inspired by Hodgkin and Huxley's membrane model <ref type="bibr" target="#b19">[20]</ref> for a biological neural system and the later developed Grossberg's shunting model <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b17">[18]</ref>, a novel neural network approach is proposed for dynamic collision-free trajectory generation in an arbitrarily varying environment (which first appeared in <ref type="bibr" target="#b32">[33]</ref> and <ref type="bibr" target="#b57">[58]</ref>). The state space of the topologically organized neural network is either the Cartesian workspace of mobile robots or the joint space of multijoint robot manipulators. The neural dynamics of each neuron is characterized by a shunting equation or a simple additive equation. There are only local, excitatory lateral connections among neurons. Thus the computational complexity linearly depends on the size of the neural network. In addition, the target globally attracts the robot in the whole state space through neural activity propagation, while the obstacles locally push the robot away to avoid collisions, since there is no inhibitory lateral connections among neurons. The real-time optimal robot trajectory is generated through the dynamic activity landscape of the neural network without explicitly searching over the free space nor the collision paths, without explicitly optimizing any global cost functions, without any prior knowledge of the dynamic environment, and without any learning procedures. Therefore, the model algorithm is computationally efficient. The generated solution to a maze-solving type of problem or the generated trajectory in a static environment is globally optimal in the sense of a shortest path from the starting position to the target if it exists. The optimality of the real-time trajectory generation in a nonstationary environment is in the sense that the robot travels a continuous, smooth path toward the target. The term "real-time" is in the sense that the robot trajectory generator responds immediately to the dynamic environment, including the robot, target, obstacles and sensor noise. There are several variations of the proposed model. Although a special case of the proposed simple additive model is similar to the Glasius et al. model <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, there are significant differences between the proposed models and the Glasius et al. model (see Section IV).</p><p>In Section II, the originality, model algorithm and stability analysis of the proposed neural network approach to dynamic collision-free trajectory generation is presented. Simulation studies of the proposed model are presented in Section III, including an optimal solution to a maze-type of problem, trajectory generation of a mobile robot to avoiding concave U-shaped obstacles, to track a moving target, and to avoid moving obstacles, and trajectory generation of a two-link planar robot to catch the closest target. In Section IV, the parameter sensitivity and the model variations are discussed. Finally, a conclusion noticing several feature properties of the proposed neural network approach is addressed in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MODEL</head><p>The proposed novel neural network approach for dynamic collision-free trajectory generation is motivated by the neural dynamics and computation in biological neural systems. The philosophy of the proposed approach is to develop a topologically organized neural network architecture, whose dynamic neural activity landscape represents the dynamically varying environment. By properly defining the external inputs from the varying environment and internal neural connections, the target and obstacles are guaranteed to stay at the peak and the valley of the activity landscape of the neural network, respectively. The target globally attracts the robot in the whole state space through neural activity propagation, while the obstacles have only local effect to avoid collisions. The dynamic collision-free trajectory is generated through the dynamic activity landscape of the neural network.</p><p>In this section, the originality of the proposed neural network approach is introduced. Then, the computational algorithm is presented. Finally, the stability of the proposed model is proved by using both qualitative analysis and Lyapunov stability analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Originality</head><p>Hodgkin and Huxley <ref type="bibr" target="#b19">[20]</ref> proposed a model for a patch of membrane in a biological neural system using electrical circuit elements. This modeling work together with other experimental work led them to a Nobel Prize in 1963 for their discoveries concerning the ionic mechanisms involved in excitation and inhibition in the peripheral and central portions of the nerve cell membrane. In their membrane model, the dynamics of voltage across the membrane can be described using state equation technique as <ref type="bibr" target="#b0">(1)</ref> where membrane capacitance; , , and Nernst potentials (saturation potentials) for potassium ions, sodium ions, and the passive leak current in the membrane, respectively; , and conductance of potassium, sodium, and passive channels, respectively. This model provided the foundation of the shunting model and led to a lot of model variations and applications <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b43">[44]</ref>.</p><p>By substituting , , , , , and in (1), a shunting equation is obtained <ref type="bibr" target="#b41">[42]</ref> (2) where neural activity (membrane potential) of the th neuron; , , and nonnegative constants representing the passive decay rate, the upper and lower bounds of the neural activity, respectively; and excitatory and inhibitory inputs to the neuron <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>.</p><p>This shunting model was first proposed by Grossberg to understand the real-time adaptive behavior of individuals to complex and dynamic environmental contingencies <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b17">[18]</ref>, and has a lot of applications in biological and machine vision, sensory motor control and many other areas <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Model Algorithm</head><p>The neural network architecture of the proposed model is a discrete topologically organized map that has been used in many neural network models such as <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b24">[25]</ref>. The proposed model is expressed in a finite ( -) dimensional ( -D) state space , which can be either the Cartesian workspace of the mobile robots or the joint space of multijoint robot manipulators. For example, a two-dimensional (2-D) workspace has and a 6 degree-of-freedom (DOF) manipulation robot has . The location of the th neuron at the grid in the -D state space , denoted by a vector , represents a position in the workspace or a configuration in the joint space. Each neuron has only local lateral connections to its neighboring neurons that constitute a subset in . The subset is called the receptive field of the th neuron in neurophysiology. The neuron responds only to the stimulus within its receptive field.</p><p>In the proposed model, the dynamics of the th neuron in the neural network is characterized by a shunting equation derived from <ref type="bibr" target="#b1">(2)</ref>. The excitatory input results from the target and the lateral connections from its neighboring neurons, while the inhibitory input results from the obstacles only. Thus the differential equation for the th neuron is given by <ref type="bibr" target="#b2">(3)</ref> where total number of neurons in the neural network; and excitatory and inhibitory inputs, respectively; external input to th neuron defined as if there is a target if there is an obstacle otherwise <ref type="bibr" target="#b3">(4)</ref> where is a very large positive constant. Function is a linear-above-threshold function defined as , and the nonlinear function is defined as . The connection weight from the th neuron to the th neuron is a function of distance defined as <ref type="bibr" target="#b4">(5)</ref> where represents the Euclidean distance between positions and in the state space . The connection weight function is a monotonically decreasing function, e.g., a function defined as if if <ref type="bibr" target="#b5">(6)</ref> where and are positive constants. It is obvious that the weight is symmetric and does not depend on the moving directions of the robot. In addition, the neuron has only local connections in a small region , i.e., its receptive field is the space whose distance to the th neuron is less than . All the neurons having lateral connection to the th neuron is defined its neighboring neurons. Therefore, the dynamics of the th neuron can be further written as <ref type="bibr" target="#b6">(7)</ref> where is the number of neighboring neurons of the th neuron.</p><p>The proposed neural network characterized by <ref type="bibr" target="#b6">(7)</ref> guarantees that the positive neural activity can propagate to the whole state space through lateral neural connections, while the negative activity stays locally only, since there is no inhibitory connections among neurons. Therefore, the target globally influences the whole state space to attract the robot, while the obstacles have only local effect to avoid collisions. In addition, the activity propagation from the target is blocked when it hits the obstacles by choosing . Such a property is very important for maze-solving type of problems.</p><p>The positions of the target and obstacles may vary with time. The activity landscape of the neural network dynamically changes according the varying external inputs and the lateral excitatory connections. From <ref type="bibr" target="#b6">(7)</ref>, each neuron responds to only the real-time inputs from the target and obstacles. Thus no prior knowledge of the varying environment is needed in the proposed model. The real-time trajectory is generated from the dynamic activity landscape by a steepest gradient ascent rule. For a given present position in the state space of the neural network (i.e., a position in the Cartesian workspace or a configuration in the robot manipulator joint space), denoted by , the next position (also called "command position") is obtained by <ref type="bibr" target="#b7">(8)</ref> where is the number of neighboring positions of the th neuron, i.e., all the possible next positions of the present position. After the present position reaches its next position, the next position becomes a new present position (if the found next location is the same as the present location, i.e., the neural activity at all the neighboring positions is not larger than that of the current position, the robot stays there without any movement). The present position adaptively changes according to the varying environment.</p><p>The dynamic activity landscape of the topologically organized neural network is used to determine where the next robot position is. However, when to generate the next robot position is determined by the robot moving speed. In a static environment, the activity landscape of the neural network will reach a steady state, which will later be proved using the Lyapunov stability theory. Mostly the robot reaches the target much earlier than the activity landscape reaches the steady state. When a robot is in a changing environment, the activity landscape will never reach a steady state. Due to the very large external input constant , the target and the obstacles keep staying at the peak and the valley of the activity landscape of the neural network, respectively. The robot keeps moving toward the target with obstacle avoidance till the designated objective is achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Stability Analysis</head><p>In the shunting model in ( <ref type="formula">2</ref>), (3), or <ref type="bibr" target="#b6">(7)</ref> the neural activity increases at a rate of , which is not only proportional to the excitatory input , but also proportional to an auto gain control term . Thus, with an equal amount of input , the closer the values of and are, the slower increases. When the activity is below , the excitatory term is positive causing an increase in the neural activity. If is equal to , the excitatory term becomes zero and will no longer increase no matter how strong the excitatory input is. In case the activity exceeds , becomes negative and the shunting term pulls back to . Therefore, is forced to stay below , the upper bound of the neural activity. Similarly, the inhibitory term forces the neural activity stay above the lower bound . Therefore, once the activity goes into the finite region , it is guaranteed that the neural activity will stay in this region for any value of the total excitatory and inhibitory inputs <ref type="bibr" target="#b55">[56]</ref>.</p><p>The stability and convergence of the proposed model can also be rigorously proved using a Lyapunov stability theory. Introducing the new variables, , the proposed model in ( <ref type="formula">3</ref>) or ( <ref type="formula">7</ref>) can be written into the general form proposed by Grossberg <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> (9) by the following substitutions: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Since</head><p>, then (symmetry). Since varies within the finite interval , where and are non-negative constants, then is a nonpositive number. Hence the amplification function is nonnegative, i.e., (positivity). From the definition of function , have at and at . Hence the signal function has a nonnegative derivation, i.e., (monotonicity). Therefore, ( <ref type="formula">7</ref>) satisfies all the three stability conditions required by Grossberg's general form <ref type="bibr" target="#b17">[18]</ref>. The Lyapunov function candidate for (9) can be chosen as <ref type="bibr" target="#b13">(14)</ref> The time derivative of along all the trajectories is given by <ref type="bibr" target="#b14">(15)</ref> Since and , then along all the trajectories. The rigorous proof of the stability and convergence of ( <ref type="formula">9</ref>) can be found in <ref type="bibr" target="#b16">[17]</ref>. Therefore, the proposed neural network system is stable. The dynamics of the network is guaranteed to converge to an equilibrium state of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SIMULATION STUDIES</head><p>The proposed neural network model is capable of generating real-time optimal trajectory with obstacle avoidance for a robot in an arbitrarily varying environment. The state space can be the Cartesian workspace of a mobile robot or the joint space of a multi-joint robot manipulator. The generated solution to a maze-solving type of problem and the generated trajectory in a static environment is globally optimal in the sense of a shortest path from the starting position to the target, if it exists. Such a property results from the fact that the connection weight of the neural network is a function of the distance only, the neural activity propagation from the target to all directions are exactly in the same manners. In a static environment, the neural activity from the target always reaches the robot along a shortest path. For real-time trajectory generation in a nonstationary environment, the optimality is in the sense that the robot travels a continuous, smooth route toward the target.</p><p>In this section the proposed model is first applied to a point mobile robot in a 2-D workspace. A small and maneuverable mobile robot can be treated as a point robot, when comparing the size of the robot and its maneuvering possibilities to the size of the free workspace. For example, in practice, a car in the traffic planning in large cities or tanks in field military operations can be treated as point robots. Several cases for a point robot are studied here, including a maze-solving type of problem, trajectory generating to avoid concave U-shaped obstacles, a moving target tracking problem, and varying obstacles avoiding problem. Then, this model is applied to a two-link planar robot, where the state space of the neural network is the robot joint space and there are two targets in the state space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Trajectory Generation in a Static Environment</head><p>The proposed model is first applied to the obstacle avoidance problem for a set of U-shaped obstacles. Potential field based methods and other strictly local avoidance schemes cannot deal with these type of problems <ref type="bibr" target="#b33">[34]</ref>. The concave U-shaped obstacles are shown in Fig. <ref type="figure" target="#fig_1">1</ref>(a) by solid squares. The neural network has 30 30 topologically organized neurons, where all the neural activities are initialized to zero. The model parameters are chosen as and for the shunting equation, and for the lateral connections, and for the external inputs. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_1">1</ref>(a) by solid circles. It shows that the generated trajectory is a continuous, smooth route from the starting position to the target with obstacle avoidance. The stable (the time is long enough) activity landscape of the neural network is shown in Fig. <ref type="figure" target="#fig_1">1(b)</ref>, where the peak is at the target location, while the valley is at the obstacle location.</p><p>The solution to a maze-solving type of problem can be treated as a special case of the trajectory generation problem in a 2-D workspace, along which a mobile robot can reach the target from a given starting position with obstacle avoidance. The example of the well-known beam robot competition micromouse maze (solid squares in Fig. <ref type="figure" target="#fig_2">2</ref> shows a typical quarter of the maze) is used. The proposed neural network model is applied to solve this maze-type of problem. The neural network has <ref type="bibr" target="#b16">17</ref> 17 neurons with the same the model parameters as in the previous case. The generated globally optimal solution is shown in Fig. <ref type="figure" target="#fig_2">2</ref>, where the trajectory of the robot is represented by solid circles. Simulation studies demonstrate that the proposed model does not suffer from undesired local minima, i.e., the robot will not be trapped in the situation with concave U-shaped obstacles or with complex maze-solving type of problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Trajectory Generation to Track a Moving Target</head><p>The proposed model is then applied to a real-time trajectory generation problem for a robot to track a moving target. The neural network assumes 30 30 neuron structure with the same model parameters as in previous cases. In a 2-D workspace without any obstacles, the traveling route of the target is shown in Fig. <ref type="figure" target="#fig_3">3</ref>(a) as indicated by hollow triangles, with an initial position at = (5, 5). The target moves at a speed of 25 block/min (it is convenient to assume that the space and time units are block and minute, respectively), and stops at <ref type="bibr" target="#b24">(25,</ref><ref type="bibr" target="#b24">25)</ref> after it arrives there. Note that the proposed neural network responds to the real-time location of the targets and obstacles. No prior knowledge of the varying environment is needed. The robot starts to move from position (0, 0) at a speed of 10 block/min. The generated trajectory of the robot is shown in Fig. <ref type="figure" target="#fig_3">3</ref>(a) by solid circles. The activity landscapes of the neural network at two time instants during the motion are shown in Fig. <ref type="figure" target="#fig_3">3(b)</ref> and<ref type="figure">(c)</ref>.</p><p>When the robot tracks a moving target, the relative moving speed between the target and the robot is an important factor to influence the tacking trajectory. With the same model parameters as in Fig. <ref type="figure" target="#fig_3">3</ref>, Fig. <ref type="figure" target="#fig_4">4</ref>(a) shows the generated real-time trajectory of the robot that moves at a speed of 20 block/min, which is twice of that in Fig. <ref type="figure" target="#fig_3">3</ref>. When the robot moves faster than the target at a speed of 30 block/min, the generated real-time robot trajectory is shown in Fig. <ref type="figure" target="#fig_4">4(b)</ref>. It shows that the target is caught before it reaches its final position. Comparing Figs. <ref type="figure" target="#fig_3">3(a</ref>) and Fig. <ref type="figure" target="#fig_4">4</ref>, it is shown that the robot with a slower moving speed takes less steps (not time) to reach the target, since the robot has more time to "wait and see" which position is to go next. However, the faster moving robot spends less time to reach the target. It takes 0.67, 2.04, and 3.06 min for the robot at speeds of 30 [Fig. same model parameters as in Fig. <ref type="figure" target="#fig_3">3</ref>. The generated trajectory with presence of obstacles is shown in Fig. <ref type="figure" target="#fig_5">5</ref>. The robot takes more steps (and time) to reach the target due to the influence of the obstacles. Note that all the robot trajectories in Figs. <ref type="figure" target="#fig_3">3</ref><ref type="figure" target="#fig_4">4</ref><ref type="figure" target="#fig_5">5</ref>are continuous, smooth routes. The traveling path of the robot is generally shorter than that of the target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Trajectory Generation to Catch a Moving Target with Varying Obstacles</head><p>Next the proposed model is applied to a more complex case, where both the target and the obstacles are moving. The neural network architecture and the model parameters are chosen as the   two possible channels for the robot to reach the target. In addition, there are ten movable obstacles. They initially stop for 0.5 min at positions from <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b18">19)</ref> to <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b18">19)</ref> inside the left channel, where they completely block the left channel. Then the obstacles start to move toward the right at a speed of 20 block/min, and finally stop at positions from <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b18">19)</ref> to <ref type="bibr" target="#b22">(23,</ref><ref type="bibr" target="#b18">19)</ref>, where they completely block the right channel. Note that no prior knowledge of the varying environment is needed in the proposed model. The robot starts to move from position (14, 1) at a speed of 20 block/min. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_6">6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Trajectory Generation of a Multijoint Robot Manipulator with Multiple Targets</head><p>The proposed model is capable of generating real-time trajectory with multiple targets as well, where the task can be designed as either catching the closest target or catching all the targets. In the latter case, a target should disappear from the state space once it is caught. The proposed model is applied to trajectory generation of a two-link planar robot with two targets in the state space of the neural network, which is the joint space of the robot manipulator.  The neural network has 60 60 topologically organized neurons, which represents the joint angles from to with a step of . Since geometrically , the neuron at (0, 0) is an immediate neighboring neuron of the neuron at <ref type="bibr" target="#b58">(59,</ref><ref type="bibr" target="#b58">59)</ref> or (0, 59) in the state space, and likewise. The model parameters are chosen as , , , , and . The dynamic robot performance in Cartesian workspace are shown in Fig. <ref type="figure" target="#fig_8">7</ref>(a) bythealternatinglightanddarktwo-linkplanarrobots.Thetrajectory in joint space are shown in Fig. <ref type="figure" target="#fig_8">7(b</ref>) by solid circles. It shows that the robot travels a smooth, continuous, collision-free route in both the workspace and the joint space, and reaches the closest target (Target 1). The stable (time is long enough) activity landscape of the neural network is shown in Fig. <ref type="figure" target="#fig_8">7(c)</ref>, where two peaks of the activity landscape are at the two target locations, while the valley is at the obstacle locations. When there is no obstacle, the robot performance in workspace and the trajectory in joint space are shown in Fig. <ref type="figure" target="#fig_9">8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PARAMETER SENSITIVITY AND MODEL VARIATIONS</head><p>In this section, the parameter sensitivity of the proposed model is discussed by descriptive analysis and simulation studies. Then three model variations of the proposed model are introduced, and a comparison study among these models is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Parameter Sensitivity</head><p>The sensitivity of a system to parameter variations is a factor of prime importance to be considered when proposing or evaluating a model. An acceptable model should be robust to variations in its parameters. There are few parameters in the proposed model: parameters , , and for the shunting equation, and for the lateral connections, and for the external inputs. 1) Parameters for the Shunting Equation: In the shunting equation ( <ref type="formula">2</ref>) or ( <ref type="formula">7</ref>), parameters and are the upper and lower bounds of the neural activity, respectively. The transient response to an input signal does not depend on and . At steady state the neural activity linearly depends on and <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>. In the proposed model, because only the relative value of the neural activity is concerned, and are not important factors in the proposed model. For example, and can be chosen as constants for all cases. Parameter in <ref type="bibr" target="#b6">(7)</ref> represents the passive decay rate, which solely determines the transient response to an input signal. In addition, the steady-state neural activity is nonlinearly dependent on the value of <ref type="bibr" target="#b55">[56]</ref>. Therefore, plays the most important role in the model dynamics, which is essential when the targets and obstacles are varying. For a detailed qualitative and quantitative study of the parameter sensitivity of the shunting model, see <ref type="bibr" target="#b55">[56]</ref>. To illustrate the importance of , two simulation studies are carried out under the same condition of the case in Fig. <ref type="figure" target="#fig_3">3</ref>, except choosing two different values of parameter .</p><p>First a much smaller value is chosen, instead of as in Fig. <ref type="figure" target="#fig_3">3</ref>. Fig. <ref type="figure" target="#fig_11">9</ref>(b) shows the activity landscape of the neural network when the target arrives at position <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref>, which is at the same time point as in Fig. <ref type="figure" target="#fig_3">3(c</ref>). Comparing Figs. 9(b) and 3(c), it shows that the activity landscape in Fig. <ref type="figure" target="#fig_11">9</ref>(b) has a much longer and wider "tail." This is because that a smaller value results in a slower passive decaying of the neural activity. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_11">9</ref>(a) by solid circles, where the robot follows the target for a few steps and then completely stops at <ref type="bibr" target="#b9">(10,</ref><ref type="bibr" target="#b9">10)</ref>, failing to finally reach the target. The slow decaying of the activity causes a fast increase of the neural activity due to the lateral excitatory connections among neurons, yielding a quick saturation of the neural activity. When the robot moves to (10, 10), the neural activity over there is saturated. The robot cannot find its next position through the activity difference and has to stop there forever. The activity landscape of the neural network at time = 6.0 min is shown in Fig. <ref type="figure" target="#fig_11">9(c)</ref>, where the neural activity is saturated. Therefore, when the value of is too small, this model cannot function properly due to the quick activity saturation.</p><p>Then a much larger value is chosen, instead of as in Fig. <ref type="figure" target="#fig_3">3</ref>. Fig. <ref type="figure" target="#fig_13">10(b)</ref> shows the neural activity landscape when the target arrives at <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref>, which is at the same time point as in Figs. <ref type="figure" target="#fig_3">3(c</ref>) and 9(b). It shows that the activity landscape has a much shorter "tail" than those in Figs. <ref type="figure" target="#fig_3">3(c</ref>) and 9(b). This is because that a larger results in a faster passive decaying of the neural activity. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_13">10(a)</ref>, where the robot takes much less steps to reach the target (the traveling route of the robot becomes a straight line). Since the robot moves at the same speed as in Fig. <ref type="figure" target="#fig_3">3</ref>, it certainly takes less time (2.55 min, in comparison to 3.06 min in Fig. <ref type="figure" target="#fig_3">3</ref>) to catch the target. The faster decaying of the remaining activity after the target passes away makes the travel "history" of the target disappear faster. The activity propagation from target becomes the domain contribution in forming the neuron activities. Hence, the trajectory of the robot highly aims at the current position of the moving target. Therefore, choosing a large enough value is necessary for the robot to aim at the target. However, as shown later in Fig. <ref type="figure" target="#fig_15">12</ref>(a) and Fig. <ref type="figure" target="#fig_22">17</ref>  2) Parameters for the Lateral Connections: Although each neuron has only local connections in a small region and the target is the only positive stimulus, the positive neural activity can propagate to the whole state space of the neural network. Therefore the lateral connections among neurons are essential in forming the dynamic neural activity landscape. It shall be pointed out that the proposed model is not sensitive to the connection weight function in <ref type="bibr" target="#b5">(6)</ref>, which can be chosen as any monotonically decreasing function. The connection weight is solely determined by parameter . Therefore, is an important factor in the proposed model. To illustrate the role played by , a simulation is carried out under the same condition as in Fig. <ref type="figure" target="#fig_3">3</ref>, except choosing a much smaller value, instead of over there. The activity landscape when the target arrives at <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref> is shown in Fig. <ref type="figure" target="#fig_14">11(b)</ref>. It shows that the activity landscape has a much narrower "tail" than in Fig. <ref type="figure" target="#fig_3">3(c</ref>), since a small value results in weak lateral connections. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_14">11(a)</ref>, which is very similar to that in Fig. <ref type="figure" target="#fig_3">3(a)</ref>, since they have the same value and have the same system dynamics. However, there is a difference: The traveling route of the robot in Fig. <ref type="figure" target="#fig_14">11</ref>(a) takes more steps to reach the target. This is because that a smaller value weakens the neural activity propagation from the target, and results in relatively stronger contribution from the remaining activity after the target leaves there. Therefore, to aim at the target, a large enough value is necessary. To further illustrate the role played by , one more case study is carried out under the same condition as in Fig. <ref type="figure" target="#fig_11">9</ref>, except choosing a much smaller value, instead of . Fig. <ref type="figure" target="#fig_15">12(b)</ref> shows the activity landscape when the target arrives at <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref>. As expected, the "tail" is very narrow in comparison to the very wide "tail" in Fig. <ref type="figure" target="#fig_11">9(b)</ref>, where they are at the same time point. It also shows that both of them have a very long "tail" because they have the same very small value , which results in a very slow passive decaying of the neural activity. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_15">12(a)</ref>. It shows that the robot is able to catch the target, whereas the robot in Fig. <ref type="figure" target="#fig_11">9</ref> fails to do so due to the activity saturation. A small value results in weak lateral connections and can prevent the possible saturation in neural activity. In addition, Fig. <ref type="figure" target="#fig_15">12(a)</ref> shows that the traveling route of the robot tightly follows the travel "history" of the target. It results from both the small value and the small value: The small slows down the passive decaying of the neural activity and increases the influence from remain activity; the small weakens the propagation from target activity and decreases the direct influence from the target.</p><p>When parameter , the propagated activity is amplified and the neural activity is very easy to saturate. A case under the same condition as in Fig. <ref type="figure" target="#fig_3">3</ref>, except choosing a larger value, instead of . Fig. <ref type="figure" target="#fig_16">13</ref> shows the activity landscape when the target arrives at <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref>, which is at the same time point of Fig. <ref type="figure" target="#fig_3">3(c)</ref>. It shows that the neural activity landscape has a very long and wide "tail," which is similar to the case in Fig. <ref type="figure" target="#fig_11">9</ref>. This results from the large value. The activity landscape at time = 6.0 min is shown in Fig. <ref type="figure" target="#fig_16">13(b)</ref>, where the neural activity is saturated. The generated trajectory is similar to Fig. <ref type="figure" target="#fig_11">9(a)</ref> where the robot fails to reach the target due to the neural activity saturation that is caused by the very slow passive decay of neural activity. Therefore, to prevent possible neural activity saturation a smaller is necessary; to strengthen the influence from the target, a larger is needed. Therefore, parameter is usually chosen in the region . Parameter determines the size of the receptive field of the neuron, which is not an important factor in the proposed model. A larger value will increase the propagation of the neural activity. However, when applying the model to solve maze-type of problems, a small value is necessary, e.g., , since it is required that the activity cannot pass through any obstacles ("wall"). Therefore is used for all cases. 3) Parameters for the External Inputs: Parameter determines the amplitude of the external inputs from the target and the obstacles. To keep the target and obstacles staying at the peak and valley, respectively, the value should be chosen as a very large value over the total input from the lateral connections. Since the neural activity is bounded at the interval , by choosing and , the maximum total input from lateral connections is eight, then choosing any large value, e.g., is good enough. Therefore, parameter is not an important factor in the proposed model. In summary, only two parameters and are fundamentally important in the proposed model. The model dynamics is determined by the value of . Parameter determines the activity propagation among neurons. Note that the parameter values in the above simulation studies are chosen in a very wide range, e.g., and , and all the simulations for different cases in Section III choose exactly the same model parameters. Therefore, it is obvious that the proposed neural network model is not very sensitive to the model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Model Variations</head><p>The neural network model characterized by <ref type="bibr" target="#b6">(7)</ref> has only excitatory lateral connections. From the philosophy of this biologically inspired neural network approach for real-time dynamic trajectory generation, alternatively a shunting model with only inhibitory lateral connections is proposed. In addition, by lumping together the excitatory and inhibitory terms and removing the auto gain control terms in the shunting models, two simple models characterized by the additive equations are obtained. These simple additive models for dynamic collision-free trajectory generation also satisfy the philosophy of the proposed neural network approaches presented in Section II. Finally, a comparison study with simulations among these models and the Glasius et al. <ref type="bibr" target="#b12">[13]</ref> model is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Shunting Model with Only Inhibitory Lateral Connections:</head><p>The neural network model in ( <ref type="formula">7</ref>) is characterized by shunting equation with only excitatory lateral connections. In the dynamic neural activity landscape, the neural network design guarantees that the target is always at the peak and the obstacles are always at the valley [e.g., see Fig. <ref type="figure" target="#fig_1">1(b)</ref>]. The procedure to generate the real-time robot trajectory can be viewed as that the robot is climbing up the dynamic activity landscape to reach the activity peak. Such a network function is guaranteed by the fact that there are only excitatory connections among neurons.</p><p>Alternatively, based on the same concept of the proposed neural network approach, a different neural network model is proposed, which is characterized by a shunting equation with only inhibitory connections among neurons. In this inhibitory model, the inhibitory input in (2) results from the target and the lateral connections to its neighboring neurons, while the total excitatory input results from the obstacles only. Hence the dynamics of the th neuron activity is characterized by <ref type="bibr" target="#b15">(16)</ref> The definitions of , , and are the same as those defined in <ref type="bibr" target="#b6">(7)</ref>. The external input from the dynamic environment is defined as if there is an obstacle , if there is a target and otherwise. The shunting model characterized by <ref type="bibr" target="#b15">(16)</ref> guarantees that only the negative neural activity can propagate to the other neurons. For a given present position , the next position can be obtained by <ref type="bibr" target="#b16">(17)</ref> The present position adaptively changes according to the varying environment. The procedure to generate the real-time robot trajectory can be viewed as that a ball (the robot) is naturally falling down to reach the valley of the dynamic activity landscape.</p><p>The inhibitory lateral connection shunting model is a stable system, because the neural activity is bounded in the finite region . In addition, the stability and convergence can also be rigorously proved using a Lyapunov stability analysis. Introducing the new variables, , i.e., where is a nonnegative number varying in the finite interval , ( <ref type="formula">16</ref>) can be rewritten into Grossberg general form in (9) via the following substitutions: , = + + + + , = , and = . Obviously, have = (symmetry), and (positivity). From the definition of function , have at and at . Hence, the signal function has (monotonicity). Therefore, ( <ref type="formula">16</ref>) satisfies all the three stability conditions required by the Grossberg's general form in (9) <ref type="bibr" target="#b17">[18]</ref>. Choosing the same Lyapunov function candidate in ( <ref type="formula">14</ref>), have along all the trajectories. Therefore, this inhibitorylateral-connection neural network system is stable.</p><p>A case under the same condition as in Fig. <ref type="figure" target="#fig_1">1</ref> is simulated. The neural network architecture and all the model parameters are chosen as the same as in Fig. <ref type="figure" target="#fig_1">1</ref>. The generated trajectory is exactly the same as in Fig. <ref type="figure" target="#fig_1">1(a)</ref>. The stable (time is long enough) neural activity landscape is shown in Fig. <ref type="figure" target="#fig_17">14</ref>. In contrast to Fig. <ref type="figure" target="#fig_1">1</ref>(b), the activity peak is at the obstacle location, while the valley is at the target location.</p><p>2) Simple Additive Models: If the excitatory and inhibitory terms in the excitatory lateral connection shunting equation in <ref type="bibr" target="#b6">(7)</ref> are lumped together and the auto gain control terms are removed, then <ref type="bibr" target="#b6">(7)</ref> can be written into a simpler form <ref type="bibr" target="#b17">(18)</ref> This is an additive equation, which is widely applied to a lot areas such as vision, associative pattern learning and pattern recognition <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>. The term represents the total input to the th neuron from the external and lateral connections. The definitions of , , and are the same as those in <ref type="bibr" target="#b6">(7)</ref>. The nonlinear function guarantees that only the positive neural activity can propagate to the other neurons. The very large external input guarantees that target and obstacles stay at the peak and valley of the neural activity landscape, respectively. Therefore this simple additive model satisfies the fundamental concept of the proposed neural network approach presented in Section II. This additive model is capable of generating dynamic collision-free robot trajectories in most situations.</p><p>Although the neural activity characterized by the additive equation in <ref type="bibr" target="#b17">(18)</ref> is not bounded as in the shunting model, it is easy to prove that this additive model is a stable system using a Lyapunov stability theory. Equation ( <ref type="formula">18</ref>) can be rewritten into the Grossberg's general form in <ref type="bibr" target="#b8">(9)</ref>  (monotonicity). Thus ( <ref type="formula">18</ref>) satisfies all the three stability conditions required by the Grossberg's general form in (9) <ref type="bibr" target="#b17">[18]</ref>. Therefore this additive neural network system is stable.</p><p>Similarly, a different additive model is obtained from the inhibitory lateral connection shunting model in <ref type="bibr" target="#b15">(16)</ref>. By lumping together the excitatory and inhibitory terms and removing the auto gain control terms in <ref type="bibr" target="#b15">(16)</ref>, the dynamics of the th neuron is given by a simple additive equation <ref type="bibr" target="#b22">(23)</ref> where is the total input to the th neuron from the external and lateral connections. The definitions of , , and are the same as those in <ref type="bibr" target="#b15">(16)</ref>. The nonlinear function guarantees that only the negative neural activity can propagate to the other neurons, and the large external input guarantees that the target and obstacles are at the valley and peak of the neural activity landscape, respectively. Therefore, this additive model with only inhibitory lateral connections follows the philosophy of the proposed neural network approach. It is capable of generating dynamic collision-free trajectories.</p><p>The additive neural network in <ref type="bibr" target="#b22">(23)</ref> can also be proved to be stable using a Lyapunov stability analysis. Equation ( <ref type="formula">23</ref>) can be rewritten into Grossberg's <ref type="bibr" target="#b17">[18]</ref> general form in (9) by the following substitutions: , , , and</p><p>. Again, we have (symmetry), (positivity), and (monotonicity). Therefore, all the three stability conditions required by the general form in <ref type="bibr" target="#b8">(9)</ref> are satisfied by additive model in <ref type="bibr" target="#b22">(23)</ref>. This additive neural network system is stable.</p><p>There are a lot of important differences between the shunting models in ( <ref type="formula">7</ref>) and ( <ref type="formula">16</ref>) and the additive models in ( <ref type="formula">18</ref>) and ( <ref type="formula">23</ref>), although the additive models are computational simpler, and can also generate real-time trajectories with obstacle avoidance in most situations. First, by rewriting the shunting and additive models into the Grossberg general form in <ref type="bibr" target="#b8">(9)</ref>, unlike the additive model in <ref type="bibr" target="#b17">(18)</ref> with a constant and a linear function , for the shunting model in <ref type="bibr" target="#b6">(7)</ref> the amplification function in <ref type="bibr" target="#b9">(10)</ref> is not a constant, and the self-signal function in ( <ref type="formula">11</ref>) is nonlinear. Second, the shunting model in <ref type="bibr" target="#b6">(7)</ref> has two auto gain control terms <ref type="bibr">[ and ]</ref>, which result in that the neural dynamics of (7) remains sensitive to input fluctuations <ref type="bibr" target="#b17">[18]</ref>. Such a property is important for the real-time trajectory generations when the target and obstacles are varying. In contrast, the dynamics of the additive equation may saturate in many situations <ref type="bibr" target="#b17">[18]</ref>. Third, the activity of the shunting model is bounded in the finite interval , while the activity in the additive model does not have any bounds. A detailed analysis of the shunting model and the additive model can be found in <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, and <ref type="bibr" target="#b55">[56]</ref>.</p><p>Glasius et al. <ref type="bibr" target="#b12">[13]</ref> proposed a similar neural network model for real-time trajectory generation, where the output of the th neuron is modeled by <ref type="bibr" target="#b23">(24)</ref> which is derived from a simple discrete model <ref type="bibr" target="#b24">(25)</ref> where is an input-output transfer function that can be any sigmoid function, e.g., a function defined as</p><formula xml:id="formula_0">if , if , if</formula><p>, where is a constant, and . The connection weight is defined as a function of the distance between th and th neurons, e.g., if and otherwise <ref type="bibr" target="#b13">[14]</ref>. This model is a Hopfield-type neural network <ref type="bibr" target="#b12">[13]</ref>.</p><p>Comparing the Glasius et al. model in <ref type="bibr" target="#b23">(24)</ref> and the proposed shunting model in <ref type="bibr" target="#b6">(7)</ref> or the simple additive model in <ref type="bibr" target="#b17">(18)</ref>, the most important difference is that (24) has a constant passive decay rate at . As discussed in Section IV, parameter plays an essential role in dynamic trajectory generation. Although parameters in <ref type="bibr" target="#b17">(18)</ref> or in <ref type="bibr" target="#b23">(24)</ref> can prevent the possible saturation in the neural activity, as discussed in Section IV they do not have any effects to the transient response characteristics of the model, i.e., the system dynamics does not depend on the neural connection parameters or . Therefore, the Glasius et al. model has limitations with fast dynamic systems. It cannot perform properly in a fast changing environment. For example, it requires that the robot dynamics must be faster than that of the target and the obstacle dynamics <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>Another major difference between the Glasius et al. model in <ref type="bibr" target="#b23">(24)</ref> and the proposed shunting model in <ref type="bibr" target="#b6">(7)</ref> or the simple additive model in <ref type="bibr" target="#b17">(18)</ref> is that <ref type="bibr" target="#b23">(24)</ref> describes the dynamics of the neuron output , which is derived from a simple discrete input-output ( versus ) function; while <ref type="bibr" target="#b6">(7)</ref> or <ref type="bibr" target="#b17">(18)</ref> characterizes the dynamics of the neural activity , which is derived from Hodgkin and Huxley's biological model <ref type="bibr" target="#b19">[20]</ref>, and describes the input ( and ), output (</p><p>) and activity ( ) of a neuron. In addition,unliketheGlasiusetal.modelin <ref type="bibr" target="#b23">(24)</ref>thatdoesnotmodel the neural activity, the proposed shunting model has a continuous neural activity with both upper and lower bounds. Therefore, the proposed model is more biologically plausible. By doing a linear, invertible mathematical transformation (note that biologically this is not true, since is the neural activity, while is the total input), a similar equation of (18) in a special case of can be obtained from <ref type="bibr" target="#b23">(24)</ref>. This transformation from a nonlinear signal function of sum, , to a sum of nonlinear signals,</p><p>, is usually called "S exchange" in neural network analysis.</p><p>3) Comparison Study Among Models: A comparison study is carried out to illustrate the differences among these models. A target catching case is designed. In a 2-D Cartesian workspace, the target starts to move from position (10, 5) at a speed of 25 block/min. The traveling route of the target is shown in Fig.  by hollow triangles. After target reaches <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b28">29)</ref> at time = 3.0 min, it disappears, i.e., the target leaves the workspace. The robot moves at a speed of 20 block/min starting from (0, 0). The task of the robot is to catch the target before the target disappears. Since the robot moves slower than the target, it can catch the target only if it can find a shorter traveling route than the target.</p><p>First, the proposed additive model in ( <ref type="formula">18</ref>) is used. The neural network has 30 30 neurons with zero initial neural activities, and the model parameters and are chosen as and . All the other model parameters are chosen as the same as in previous cases, i.e., , and , which will be also used in the following simulations. The activity landscape of the neural network when the target leaves the workspace is shown in Fig. <ref type="figure" target="#fig_19">15(b)</ref>. As expected, it has a very long and very narrow "tail," since a very small value and a very small value are used. The generated trajectory of the robot is shown in Fig. <ref type="figure" target="#fig_18">15</ref>(a) by solid circles. It shows that the robot ends at <ref type="bibr" target="#b11">(12,</ref><ref type="bibr" target="#b4">5)</ref> and fails to catch the target.</p><p>Second, the Glasius et al. model in ( <ref type="formula">24</ref>) is used. Parameter is chosen as <ref type="bibr" target="#b13">[14]</ref>. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_20">16(a)</ref>, where the robot ends at <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b5">6)</ref> and fails to catch the target. The activity landscape when the target leaves the workspace is shown in Fig. <ref type="figure" target="#fig_20">16(b)</ref>, which is qualitatively the same as that in Fig. <ref type="figure" target="#fig_18">15</ref> except some quantitative differences. Third, the proposed shunting model in ( <ref type="formula">7</ref>) is used with and . The neural activity landscape when the target leaves the workspace is shown in Fig. <ref type="figure" target="#fig_22">17(b</ref>). Unlike those in Figs. 17(b) and 16(b), the neural activity in Fig. <ref type="figure" target="#fig_22">17(b</ref>) is bounded in [0, 1], although their activity landscapes are qualitatively the same. The generated trajectory is shown in Fig. <ref type="figure" target="#fig_22">17(a)</ref>. It shows that the robot tightly follows the traveling route of the target. However, the robot also fails to catch the target before the target leaves the workspace because it does not travel a much shorter route than the target. If the task is to detect and follow the traveling route of the target, the robot does a very good job. Unlike the cases in Figs. <ref type="figure" target="#fig_19">15(a</ref>) and 16(a) where the robot ends at a location forever, the robot in Fig. <ref type="figure" target="#fig_22">17</ref> Fourth,theproposedadditivemodelin(18)isusedwith and . The generated trajectory is shown in Fig. <ref type="figure" target="#fig_23">18(a)</ref>. It shows that the robot travels a shorter route than the target and catches the target at position <ref type="bibr" target="#b10">(11,</ref><ref type="bibr" target="#b14">15)</ref>. The neural activity landscape when the robot catches the target is shown in Fig. <ref type="figure" target="#fig_23">18</ref>. As expected, it has a very short "tail" due to the very large value.</p><p>Finally, the proposed shunting model in ( <ref type="formula">7</ref>) is used with the same parameters as in the case depicted in Fig. <ref type="figure" target="#fig_23">18</ref>, i.e., and . The generated trajectory is the same as that shown in Fig. <ref type="figure" target="#fig_23">18(a)</ref>. The neural activity landscape when the robot catches the target is qualitatively the same as that in Fig. <ref type="figure" target="#fig_23">18(b)</ref>. By choosing a difference value, the Glasius et al. model can generate a trajectory similar to Fig. <ref type="figure" target="#fig_22">17</ref>, since the role of is similar to in the proposed models. However, the Glasius et al. model cannot generate a trajectory similar to Fig. <ref type="figure" target="#fig_23">18</ref> that allows the robot to achieve the task, i.e., travel a much shorter trajectory than the target trajectory to catch the target before it disappears. The Glasius et al. model requires that the robot moves faster than the target <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>.</p><p>In summary, the above simulations demonstrate that parameter is fundamental important in real-time trajectory generation, particularly when the environment is changing in a fast manner. The neural dynamics of the additive models may saturate in some situations, but the shunting models do not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, a novel biologically inspired neural network approach is proposed for the dynamic collision-free trajectory generation in an arbitrarily dynamic environment. The state space of the neural network can be the Cartesian workspace of mobile robots or the joint space of multijoint robot manipulators. Several model variations are presented and the differences are compared by descriptive analysis and simulation studies. The proposed approach is applied to the real-time trajectory generation with obstacle avoidance for a mobile robot and a multi-joint robot manipulator. The optimal real-time trajectory is generated through the dynamic activity landscape that represents the varying environment. The stability and convergence of the proposed models are guaranteed by a qualitative analysis and a rigorous Lyapunov stability analysis. Some points are worth to mention about the proposed neural network approach to dynamic collision-free trajectory generation.</p><p>• This model is biologically plausible. It is originally derived from Hodgkin and Huxley's biological membrane model <ref type="bibr" target="#b19">[20]</ref>. The neural activity is a continuous analog signal and has both upper and lower bounds. In addition, the continuous activity prevents the possible oscillations related to parallel dynamics of discrete neurons <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b30">[31]</ref>. • The model algorithm is computationally efficient. The optimal robot trajectory is generated without explicitly searching over the free workspace or the collision paths, without explicitly optimizing any global cost functions, without any prior knowledge of the dynamic environment, and without any learning procedures. • The computational complexity linearly depends on the state space size of the neural network. Each neuron in the neural network has only local lateral connections, which does not depend on the size of the overall neural network. However, if the state space is -D, and each dimension is discretized with neurons, then the total neurons will be . Therefore, the proposed model will be computational expensive for trajectory generation of robot manipulators with many degrees of freedom. • This model can perform properly in an arbitrarily dynamic environment, even with sudden environmental changes, such as suddenly adding or removing obstacles or targets (additional study of this property can be found in <ref type="bibr" target="#b52">[53]</ref> and <ref type="bibr" target="#b53">[54]</ref>). The neural network system is characterized by a continuous shunting model, it is stable and keeps sensitive to variations in the environment <ref type="bibr" target="#b17">[18]</ref>. • The proposed models do not suffer from undesired local minima, i.e., the robot will not be trapped in deadlock situations such as with concave U-shaped obstacles and in a complex maze-solving type of problems. The target globally influences the whole workspace through neural activity propagation to all directions in the same manners. The trajectory is generated through the dynamic activity landscape of the neural network. The negative neural activity from the obstacle location stays locally only without propagating to any other neurons. Thus the obstacles have only local effect to push the robot away to avoid collisions. Therefore, unlike some previous models (e.g., <ref type="bibr" target="#b20">[21]</ref>), the irrelevant obstacles do not influence the global trajectory generation. • The proposed model is capable of generating real-time collision-free trajectories of a robot with multiple moving targets and the trajectories of multiple robots in a common workspace. This study is presented in <ref type="bibr" target="#b53">[54]</ref>. • Based on the proposed model, an extended model is capable of generating a real-time path with safety consideration, i.e., by choosing suitable strength of obstacle clearance, the extended model can plan a "comfortable" path that does not clip the corners of obstacles nor runs down the edges of obstacles. Thus it does not suffer from either the "too close" (narrow safety margin) or "too far" (waste) problems <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>. This study is presented in <ref type="bibr" target="#b51">[52]</ref> and <ref type="bibr" target="#b52">[53]</ref>. • Based on the proposed model, another extended model can be applied to real-time collision-free navigation of holonomic and nonholonomic car-like mobile robots. In many situations, e.g., when the size of the robot is comparable to the free workspace, the robot should be considered with its shape and size. Unlike most other path planning methods for car-like robots where a local collision checking has to be taken at every step of robot movement, no local collision checking procedure is needed in the extended model. This study is presented in <ref type="bibr" target="#b53">[54]</ref> and <ref type="bibr" target="#b54">[55]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Trajectory generation of a mobile robot to avoid a set of concave U-shaped obstacles. (a) Generated robot trajectory. (b) Stable activity landscape of the neural network.</figDesc><graphic coords="5,78.18,252.78,174.00,141.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Solution to a maze-solving type of problem.</figDesc><graphic coords="5,340.32,62.28,175.68,173.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Trajectory generation of a mobile robot to track a moving target. (a) Dynamic trajectories of the target (hollow triangles) and the robot (solid circles). Activity landscapes (b) and (c) when the target arrives at (16, 16) and (20, 21), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Trajectory generation to track a moving target when the robot moves faster than that in Fig. 3. Target moves at 25 block/min. Robot speed in Fig. 3 is 10 block/min. (a) Dynamic trajectory when the robot moves at 20 block/min. (b) Trajectory when robot moves at 30 block/min.</figDesc><graphic coords="6,339.72,482.94,174.00,170.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Trajectory generation to track a moving target with static obstacles. Obstacles are represented by sold squares. same as in the previous cases, i.e., 30 30 neurons, zero initial neural activity, , , , , and . The target starts at position (4, 25) and continuously moves back and forth along the line between (4, 25) and (24, 25) at a speed of 10 block/min (shown in Fig. 6 by hollow triangles). The static obstacles shown in Fig. 6 by solid squares form</figDesc><graphic coords="6,77.04,407.46,173.28,134.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Trajectory generation to catch a moving target with moving obstacles. Moving obstacles are represented by solid hexagons. Target moves back and forth along the hollow triangles.</figDesc><graphic coords="7,77.94,62.28,174.48,170.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>by solid circles. Initially the robot moves toward the right channel, since the left channel is completely blocked while the right channel is open. However, during the time the robot is moving toward the target through the right channel, the obstacles are gradually moving to close the right channel and open the left channel. Before the robot is able to pass through the right channel, the moving obstacles completely block the right channel and leavethe left channel completely open. The robot has to move away from the target, passes around the middle static obstacles, and finally catch the moving targetthroughtheleftchannel.Hereagaintherobottravelingroute is continuous, smooth, and free of collisions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Trajectory generation of a two-link planar robot with two target configurations. (a) Robot performance in the workspace. (b) Trajectory in the joint space. (c) Stable activity landscape of the neural network.</figDesc><graphic coords="7,341.34,443.94,173.76,143.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Trajectory generation of a two-link planar robot without obstacles. (a) Robot performance in the workspace. (b) Trajectory in the joint space.</figDesc><graphic coords="8,77.04,253.02,173.28,170.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(a) and (b), respectively. The robot reaches the closest target (Target 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Trajectory generation with a much smaller A value than in Fig. 3, A = 2 instead of A = 10 as in Fig. 3. (a) Generated trajectory. (b) Neural activity landscapes when the target arrives at (20, 21). (c) Activity landscape at time = 6.0 min.</figDesc><graphic coords="9,77.76,410.70,174.72,144.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>, a smaller value is necessary if the robot is required to tightly follow the traveling route of the target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Trajectory generation with a much larger A value than in Fig. 3, A = 50 instead of A = 10 as in Fig. 3. (a) Generated trajectory. (b) Activity landscapes when the target arrives at (20, 21).</figDesc><graphic coords="9,341.34,251.58,173.76,134.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Trajectory generation with a much smaller value than in Fig. 3, = 0:2 instead of = 1 as in Fig. 3. (a) Generated trajectory. (b) Activity landscapes when the target arrives at (20, 21).</figDesc><graphic coords="10,77.16,252.06,173.04,135.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Trajectory generation with a much smaller value than in Fig. 10, = 0:2 instead of = 1, as in Fig. 10. (a) Generated trajectory. (b) Activity landscapes when the target arrives at (20, 21).</figDesc><graphic coords="10,339.48,252.54,174.48,135.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Trajectory generation with a larger value than in Fig. 3, = 2 instead of = 1, as in Fig. 3. (a) Activity landscapes when the target arrives at (20, 21). (b) Activity landscape at time = 6.0 min.</figDesc><graphic coords="11,78.00,217.62,174.24,144.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Stable neural activity landscape using the inhibitory lateral connection shunting model.</figDesc><graphic coords="12,76.92,62.28,173.52,143.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>15</head><label>15</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Trajectory generation of a mobile robot to catch a moving target using the additive model in (18) with A = 1 and = 0:01. (a) Generated trajectory. (b) Neural activity landscape when the target leaves the workspace.</figDesc><graphic coords="13,341.70,251.94,173.04,144.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Trajectory generation to catch a moving target using the additive model in (24). (a) Generated trajectory. (b) Activity landscape when the target disappears.</figDesc><graphic coords="14,77.04,252.06,173.28,142.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>(a) can continuously follow the traveling route of the target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Trajectory generation to catch a moving target using the shunting model in (7) with A = 1 and = 0:1. (a) Generated trajectory. (b) Activity landscape when the target disappears.</figDesc><graphic coords="14,340.26,251.82,172.80,143.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Trajectory generation to catch a moving target using the additive model in (18) with A = 50 and = 1. (a) Generated trajectory. (b) Activity landscape when the robot catches target.</figDesc><graphic coords="15,78.84,252.54,172.56,133.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>• This model is not very sensitive to the model parameters and the connection weight function. Only two model parameters and are important factors. The model parameters can be chosen in a very wide range. The weight function can be any monotonically decreasing function. • This model is not sensitive to any irrelevant obstacles. There are no inhibitory lateral connections in the neural network.</figDesc></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The work of S. X. Yang was supported by the Natural Sciences and Engineering Research Council (NSERC) under Grant RGPIN227684. The work of M. Meng was supported by the Natural Sciences and Engineering Research Council (NSERC) under Grant RGPIN170446. This paper was recommended by Associate Editor S. Lakshmivarahan. Publisher Item Identifier S 1083-4419(01)05218-9.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new potential field-based algorithm for path planning</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Al-Sultan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Aliyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="265" to="282" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Shortest distance paths for wheeled mobile robots</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="657" to="662" />
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robot motion planning: A distributed representation approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barraquand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Latombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="628" to="649" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Planning shortest bounded-curvature paths for a class of nonholonomic vehicles among obstacles</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bicchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="387" to="405" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A subdivision algorithm in configuration space for findpath with rotation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="224" to="233" />
			<date type="published" when="1985-02">Feb. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural navigation approach for intelligent autonomous vehicles (iav) in partially structured environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Benmehrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="219" to="233" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Navigation for an intelligent mobile robot</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Crowley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="31" to="41" />
			<date type="published" when="1985-01">Jan. 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Path tracking through uncharted moving obstacles</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>De Lamadrid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Gini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1408" to="1422" />
			<date type="published" when="1990-12">Nov./Dec. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A search algorithm for motion planning with six degrees of freedom</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Donald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="353" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multilayered reinforcement learning for complicated collision avoidance problems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Automat</title>
		<meeting>IEEE Int. Conf. Robot. Automat<address><addrLine>Leuven, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="2186" to="2191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An unsupervised neural network for low-level control of a mobile robot: Noise resistance, stability, and hardware implementation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gaudiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zalama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Coronado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="485" to="496" />
			<date type="published" when="1996-06">June 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Population coding in a neural net for trajectory formation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Glasius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network: Computat. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="549" to="563" />
			<date type="published" when="1994-08">Aug. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural network dynamics for path planning and obstacle avoidance</title>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="133" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A biologically inspired neural net for trajectory formation and obstacle avoidance</title>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="511" to="520" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contour enhancement, short term memory, and constancies in reverberating neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="217" to="257" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Studies of Mind and Brain: Neural Principles of Learning, Perception, Development, Cognition, and Motor Control</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Reidel</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Absolute stability of global pattern formation and parallel memory storage by competitive neural networks</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="815" to="926" />
			<date type="published" when="1983-05">May 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonlinear neural networks: Principles, mechanisms, and architecture</title>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="17" to="61" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Conduction of the Nervous Impulse</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Hodgkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964">1964</date>
			<publisher>Liverpool Univ. Press</publisher>
			<pubPlace>Liverpool, U.K.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A quantitative description of membrane current and its application to conduction and excitation in nerve</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Hodgkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Huxley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. Lond</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="500" to="544" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">2d path planning: A configuration space heuristic approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ilari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="91" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Toward efficient trajectory planning: The path-velocity decomposition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="72" to="89" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Real-time obstacle avoidance for manipulators and mobile robots</title>
		<author>
			<persName><forename type="first">O</forename><surname>Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="90" to="98" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-valued distance maps for motion planning on surfaces with moving obstacles</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="427" to="436" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Self-organized formation of topologically correct feature maps</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="49" to="60" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Robot Motion Planning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Latombe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual guided motor control: Adaptive sensorimotor mapping with on-line visual-error correction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ögmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. World Congr</title>
		<meeting>World Congr</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robot path planning using fluid model</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="29" to="50" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spatial planning: A configuration space approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="108" to="320" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic path planning for a mobile automation with limited information on the environment</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Lumelsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Stepanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automat. Contr</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1058" to="1063" />
			<date type="published" when="1986-11">Nov. 1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Associative memory in an analog iterated-map neural network</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. A</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3355" to="3364" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Path planning for robots by stochastic optimization methods</title>
		<author>
			<persName><forename type="first">K</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A neural network approach to real-time trajectory generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. Int. Conf. Robot. Automat</title>
		<meeting><address><addrLine>Leuven, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<biblScope unit="page" from="1725" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neural controller for a mobile robot in a nonstationary environment</title>
		<author>
			<persName><forename type="first">F</forename><surname>Muñiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second IFAC Conf. Intell. Autonom. Veh</title>
		<meeting>Second IFAC Conf. Intell. Autonom. Veh<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-06">June 1995</date>
			<biblScope unit="page" from="279" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cooperative neural field for the path planning of a robot arm</title>
		<author>
			<persName><forename type="first">P</forename><surname>Muraca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="18" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Two dimensional collision-free path planning using linear parametric curve</title>
		<author>
			<persName><forename type="first">I</forename><surname>Namgung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="659" to="673" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A feasible motion-planning algorithm for a mobile robot on a quadtree representation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Noborio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. Automat</title>
		<meeting>IEEE Int. Conf. Robot. Automat</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="327" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robot path planning with penetration growth distance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="57" to="74" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fuzzy maps: A new tool for mobile robot perception and planning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Oriolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ulivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vendittelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="197" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Real-time map building and navigation for autonomous robots in unknown environments</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern. B</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="316" to="333" />
			<date type="published" when="1998-06">June 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural models for sustained and on-off units of insect lamina</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ögmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gagné</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Cybern</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="51" to="60" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural network architecture for motion perception and elementary motion detection in the fly visual system</title>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="487" to="505" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Finding the optimal driving path of a car using the modified constrained distance transformation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="663" to="670" />
			<date type="published" when="1998-10">Oct. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Plonsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Fleming</surname></persName>
		</author>
		<title level="m">Bioelectric Phenomena</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Robust path planning for nonholonomic robots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pruski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rohmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="329" to="350" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Topology-conserving maps for learning visuo-motorcoordination</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Ritter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="159" to="189" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Optimum path planning for robot manipulators amid static and dynamic obstacles</title>
		<author>
			<persName><forename type="first">C</forename><surname>Seshadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst., Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="576" to="584" />
			<date type="published" when="1993-04">Mar./Apr. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning metric-topological maps for indoor mobile robot navigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="71" />
			<date type="published" when="1998-02">Feb. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On-line planning for collision avoidance on the nominal path</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tsoularis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kambhampati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Intell. Robot. Syst</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="327" to="371" />
			<date type="published" when="1998-04">Apr. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A potential maze solving algorithm for a micromouse robot</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wyard-Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-H</forename><forename type="middle">M</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Pacific Rim Conf</title>
		<meeting>IEEE Pacific Rim Conf<address><addrLine>Victoria, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995-05">May 1995</date>
			<biblScope unit="page" from="614" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An efficient neural network approach to dynamic robot motion planning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="148" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An efficient neural network method for real-time motion planning with safety consideration</title>
	</analytic>
	<monogr>
		<title level="j">Robot. Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="115" to="128" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Real-time collision-free path planning of robot manipulators using neural network approaches</title>
	</analytic>
	<monogr>
		<title level="j">Auton. Robots</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">An efficient neural network model for path planning of car-like robots in dynamic environment</title>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A biological inspired neural network approach to real-time collision-free motion planning of a nonholonomic car-like robot</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots Syst<address><addrLine>Takamatsu, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-10">Oct. 2000</date>
			<biblScope unit="page" from="239" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A neural network architecture for visual information processing in vertebrate retina</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Elect. Comput. Eng</title>
		<imprint>
			<date type="published" when="1996-12">Dec. 1996</date>
			<pubPlace>Houston, TX</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Houston</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.S. thesis</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Neural network approaches to real-time motion planning and control of robotic systems</title>
	</analytic>
	<monogr>
		<title level="j">Dept. Elect. Comput. Eng</title>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<pubPlace>Edmonton, AB</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Alberta</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Dynamical trajectory generation with collision free using neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots Syst<address><addrLine>Victoria, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-10">Oct. 1998</date>
			<biblScope unit="page" from="1634" to="1639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A real-time, unsupervised neural network for the lowlevel control of a mobile robot in a nonstationary environment</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zalama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="103" to="123" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Using path transforms to guide the search for findpath in 2d</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zelinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="315" to="325" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">New heuristic for efficient hierarchical path planning for mobile robot</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Latombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot. Automat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="9" to="20" />
			<date type="published" when="1991-02">Feb 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Sc. degree in biophysics from the Chinese Academy of Sciences, Beijing, in 1990, the M.Sc. degree in electrical engineering from the University of Houston, Houston, TX, in 1996, and the Ph.D. degree in electrical and computer engineering from the University of Alberta</title>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">S&apos;97-M&apos;99) received the B.Sc. degree in engineering physics from Beijing University</title>
		<meeting><address><addrLine>Beijing, China; Edmonton, AB, Canada; Guelph, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987. 1999</date>
		</imprint>
	</monogr>
	<note>Currently, he is the Director of the Advanced Robotics and Intelligent Systems (ARIS) Lab, University of Guelph. His research interests include robotics, intelligent systems, control systems, and computational neuroscience. He has published over 60 journal papers, book chapters, and conference proceedings</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">His research interests include robotics, intelligent control systems, and human-machine interface. He has published approximately 100 journal papers and edited volumes, book chapters, and conference proceedings. Dr. Meng is the General Chair of the</title>
		<author>
			<persName><forename type="first">Max</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA&apos;01), and the General Chair of 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS&apos;05)</title>
		<meeting><address><addrLine>Victoria, BC, Canada; Edmonton, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992. 2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Victoria</orgName>
		</respStmt>
	</monogr>
	<note>He is the Chair of IEEE Northern Canada Section. Among many of his awards, he is the recipient of the IEEE Third Millennium Medal award. He is the editor of the IEEE</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
