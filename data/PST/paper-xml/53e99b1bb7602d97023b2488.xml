<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Convergence to Approximate Nash Equilibria in Congestion Games †</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Steve</forename><surname>Chien</surname></persName>
							<email>schien@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Alistair</forename><surname>Sinclair</surname></persName>
							<email>sinclair@cs.berkeley.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science Division</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720-1776</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Silicon Valley Campus</orgName>
								<address>
									<addrLine>1065 La Avenida</addrLine>
									<postCode>94043</postCode>
									<settlement>Mountain View</settlement>
									<region>CA</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Convergence to Approximate Nash Equilibria in Congestion Games †</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0EE8C31551A08BEB23EF5436EB795955</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T15:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the ability of decentralized, local dynamics in non-cooperative games to rapidly reach an approximate Nash equilibrium. For symmetric congestion games in which the edge delays satisfy a "bounded jump" condition, we show that convergence to an ε-Nash equilibrium occurs within a number of steps that is polynomial in the number of players and ε -1 . This appears to be the first such result for a class of games that includes examples for which finding an exact Nash equilibrium is PLS-complete, and in which shortest paths to an exact equilibrium are exponentially long. We show moreover that rapid convergence holds even under only the apparently minimal assumption that no player is excluded from moving for arbitrarily many steps. We also prove that, in a generalized setting where players have different "tolerances" ε i that specify their thresholds in the approximate Nash equilibrium, the number of moves made by a player before equilibrium is reached depends only on his associated ε i , and not on those of the other players. Finally, we show that polynomial time convergence still holds even when a bounded number of edges are allowed to have arbitrary delay functions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The emerging field of algorithmic game theory has led to a fundamental re-examination, from a computational perspective, of the classical concept of Nash equilibrium <ref type="bibr" target="#b26">[20]</ref>. Much of this activity has focused on understanding the structure of Nash equilibria (as expressed, notably, in the "price of anarchy," see e.g. <ref type="bibr" target="#b28">[22,</ref><ref type="bibr" target="#b31">25,</ref><ref type="bibr" target="#b30">24]</ref>) and the computational complexity of finding them (see, e.g., <ref type="bibr" target="#b16">[10,</ref><ref type="bibr">7,</ref><ref type="bibr">4]</ref>). Considerably less is understood about the question of whether selfish players, acting in a decentralized fashion, actually arrive at a Nash equilibrium in a reasonable amount of time. This would seem to be a central consideration in the computational study of Nash equilibria.</p><p>In this paper we address this question in the general arena of congestion games. A congestion game is an n-player game in which each player's strategy consists of a set of resources, and the cost of the strategy depends only on the number of players using each resource, i.e., the cost takes the form e d e (f (e)), where f (e) is the number of players using resource e, and d e is a non-negative increasing function. A standard example is a network congestion game on a directed graph, in which each player must select a path from some source to some destination, and each edge has an associated "delay" function that increases with the number of players using the edge. In what follows, we shall use the terminology of edges and delays even though we will always be discussing general (non-network) congestion games.</p><p>Congestion games have attracted a good deal of attention, partly because they capture a large class of routing and resource allocation scenarios, and not least because they are known to possess pure Nash equilibria <ref type="bibr" target="#b29">[23]</ref>. Thus unlike general games, whose Nash equilibria may involve mixed (i.e., randomized) strategies for the players, congestion games always have a Nash equilibrium in which each player sticks to a single strategy. Further, in congestion games, the natural decentralized mechanism known as the "Nash dynamics", in which at each step some player switches her strategy to a better alternative, is guaranteed to converge to a pure Nash equilibrium. The question then is the following: Starting from an arbitrary initial state, does the Nash dynamics converge rapidly?</p><p>The work of <ref type="bibr" target="#b16">[10]</ref> provides a devastating negative answer, even for symmetric † congestion games: the problem of finding a Nash equilibrium is PLS-complete <ref type="bibr" target="#b20">[14]</ref>, and therefore as difficult as that of finding a local optimum in any local search problem with efficiently computable neighborhoods. Moreover, there are examples of games and initial strategies such that the shortest path to an equilibrium in the Nash dynamics is exponentially long in the number of players n. Thus if we want a notion of Nash equilibrium that is selfishly and efficiently realizable, the best we can hope for is some kind of approximation. (Indeed, given the recent spate of hardness results for finding exact equilibria in most classes of games by any algorithmic means <ref type="bibr" target="#b16">[10,</ref><ref type="bibr">7,</ref><ref type="bibr">4]</ref>, it seems inevitable that attention will now shift to approximation.) Accordingly, we say that a state s (i.e., a collection of strategies for the players) is an ε-Nash equilibrium if no player can improve her cost by more than a factor of ε by unilaterally changing her strategy. This definition has intuitive appeal, for example, if one imagines charging players a percentage of their current cost for the privilege of changing strategy. ‡ Given this definition, we introduce a natural modification of the Nash dynamics called the ε-Nash dynamics, which permits only ε-moves, i.e., moves that improve the cost of the player by a factor of more than ε. Clearly ε-Nash equilibria correspond to fixed points of this dynamics. Our goal is to investigate under what circumstances the ε-Nash dynamics does in fact converge rapidly to an ε-Nash equilibrium.</p><p>To make the ε-Nash dynamics concrete, we assume that among multiple players with ε-moves available, at each step a move is made by the player with the largest incentive to move; i.e., the player who can make the largest relative improvement in cost (with ties broken arbitrarily). This is a minimal coordination mechanism that seems natural in our context; however, as we shall see later, our results hold even with no coordination under only a basic liveness assumption.</p><p>In order to state our results we need one further notion. For any α ≥ 1, we say that an edge in a congestion game satisfies the α-bounded jump condition if its delay function satisfies d e (t + 1) ≤ αd e (t) for all t ≥ 1. We will think of α as being a constant, or at most polynomially bounded in n. The bounded jump condition means that when a new player is added to an edge, † A symmetric game is one in which the allowed strategies of all the players are the same. ‡ An alternative notion of approximate equilibrium (see, e.g., <ref type="bibr" target="#b14">[8,</ref><ref type="bibr" target="#b16">10,</ref><ref type="bibr" target="#b21">15,</ref><ref type="bibr" target="#b22">16]</ref>) is based on an additive error of ε, rather than the relative error we use here. We would argue that our definition is equally natural, and indeed more in line with approximation guarantees in Computer Science and also with the notion of price of anarchy in game theory <ref type="bibr" target="#b28">[22]</ref>.</p><p>the cost to all players using that edge increases by at most a factor of α. This condition is rather weak (see below); in particular, an edge with d e (t) = α t satisfies the α-bounded jump condition.</p><p>We are now ready to state our first main result, which says that in any symmetric congestion game with bounded jumps, the ε-Nash dynamics converges rapidly to an ε-Nash equilibrium. This is apparently the first such result for such a broad class of (atomic) congestion games, and in particular for a class that contains PLS-complete examples.</p><p>Theorem 1.1 In any symmetric congestion game with n players in which all edges satisfy the αbounded jump condition, the ε-Nash dynamics converges from any initial state in nαε -1 log(nC) steps, where C is an upper bound on the cost of any player.</p><p>The proof of this theorem relies on two fundamental principles. First, the existence of an "exact" potential function <ref type="bibr" target="#b29">[23]</ref>, whose decrease under any move reflects exactly the improvement in cost of the moving player. And second, the fact that, under the bounded jump condition, any player can emulate the move of any other with at most an α-factor overhead. This ensures that every move of the dynamics decreases the potential function by an ε αn factor. We now briefly discuss the bounded jump condition. Firstly, as we show later (Section 3.1), the hardness results mentioned above for finding exact equilibria carry over to symmetric games in which all edges have α-bounded jumps. Secondly, we claim that the bounded jump condition is a reasonable assumption in practice, and is similar to conditions imposed in other quantitative studies of transient behavior (e.g., the "bounded relative slope" of <ref type="bibr" target="#b17">[11]</ref> or "bounded slope" of <ref type="bibr">[3]</ref>); it is also much weaker than the polynomial bounds typically used in studies of the price of anarchy <ref type="bibr">[1,</ref><ref type="bibr" target="#b12">6]</ref>. Thirdly, it is questionable how much sense it makes to talk about "symmetric" congestion games without such a condition. This is because of the trick in <ref type="bibr" target="#b16">[10]</ref> (see Section 3.1 below) for making any congestion game symmetric by adjoining to the strategies of each player p i a special edge e i whose delay is small for one player and huge for more than one player. This effectively divides the strategies into sets, one player per set, and is equivalent to the original game up to a relabeling of the players. Thus, if we could prove Theorem 1.1 without the bounded jump condition, we would get rapid convergence for all congestion games. The bounded jump condition can be seen as expressing an alternative, stronger notion of symmetry: no player can effectively "lock out" another by using a resource whose cost would explode if an additional player were to use it.</p><p>Next, we investigate the role of the order of player moves in ensuring rapid convergence. Recall that our ε-Nash dynamics assumed that moves are made by players with the largest available relative cost improvement. We show that our rapid convergence result, Theorem 1.1, is robust under any reasonable variation of the ε-Nash dynamics, including the "largest gain" dynamics (the player who moves is one who can gain the largest absolute cost improvement by an ε-move) and the "heaviest first" dynamics (the player who moves is one with largest current cost among those with an ε-move available). Our most convincing illustration is the "unrestricted" dynamics, in which an adversary may specify which player is allowed to move at each step, subject only to the basic liveness condition that no player is prevented from moving for arbitrarily many steps. This includes, for example, the "round-robin" scheme where in each round all players are selected to move according to some fixed permutation. Theorem 1.2 In any symmetric n-player congestion game whose edges satisfy the α-bounded jump condition, any ε-Nash dynamics in which all players are given an opportunity to move within each time interval of length T converges from any initial state in n(α+1) ε(1-ε) log(nC) T steps.</p><p>We then go on to consider a natural generalization of the ε-dynamics to "heterogeneous" players, each of whom has an individual tolerance value ε = ε i . Thus player p i has an incentive to move only if she can improve her cost by a factor of more than ε i . A straightforward generalization of Theorem 1.1 bounds the number of steps of this dynamics in terms of the smallest tolerance value ε min = min i ε i . However, it is natural to ask if one can say more; in particular, if some player has a relatively large value of ε i (and thus is very "tolerant"), can this player be forced to move very many times because of other, less tolerant players in the system? We prove an intriguing result along these lines. We show that the number of time steps at which a player with tolerance ε i will be "unhappy" (i.e., will have an ε i -move available) is essentially O(nαε -1 i log(nC)), irrespective of the ε j -values of the other players! Thus highly intolerant players are not able to force others to move frequently.</p><p>Theorem 1.3 Let ε max &lt; 1 be the maximum value of ε i among all players p i . Then for any value ε &gt; 0, there are at most nα ε(1-εmax) log(nC) times at which some player p j with ε j ≥ ε will be able to move before the ε-Nash dynamics converges.</p><p>Finally, we investigate the extent to which the bounded jump assumption can be relaxed. Specifically we prove the following: Theorem 1.4 In the setting of Theorem 1.1, the ε-Nash dynamics converges in poly(n, α, ε -1 , log nC) steps even if a fixed number of edges violate the α-bounded jump condition.</p><p>Thus rapid convergence of the dynamics is still assured even if a constant number of edges have arbitrarily large jumps in their delay functions. In light of our earlier discussion of symmetry, we can view this as a step towards extending our results to asymmetric games: Theorem 1.4 allows us to have any constant number of "classes" of players, with each class selecting its strategies from a specific set. (By contrast, a symmetric game has just one class, while a general asymmetric game may have as many as n classes.) The proof of Theorem 1.4 is rather more technical, and involves the introduction of what we call "reduced games" involving certain subsets of the players.</p><p>The remainder of the paper is organized as follows. In Section 1.1 we give a brief summary of related work. In Section 2 we set notation and define our central concepts. Section 3 proves our basic convergence result, Theorem 1.1, including versions based on different orders of player moves. In Section 4 we prove Theorem 1.2, establishing rapid convergence for the unrestricted dynamics. Section 5 considers heterogeneous players and proves Theorem 1.3. Finally, in Section 6 we extend the analysis to the case of a constant number of edges with arbitrary delay functions and prove Theorem 1.4. We conclude with some open problems in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Fabrikant, Papadimitriou and Talwar <ref type="bibr" target="#b16">[10]</ref> systematically studied the complexity of finding Nash equilibria in congestion games; in particular they showed that finding a Nash equilibrium in symmetric congestion games is PLS-complete (and thus hard for local search). They also gave a polynomial time (global) algorithm for the case of symmetric network congestion games, but this algorithm says nothing about convergence of local dynamics.</p><p>Convergence questions similar to those in the present paper (i.e., the Nash dynamics, or some simple local learning algorithm for the players) have been investigated by other authors in various contexts. There are a number of results on "load-balancing" games, which are restricted congestion games in which each strategy consists of just a single edge (or "machine"), but which may be generalized to allow either player-specific cost functions <ref type="bibr" target="#b23">[17]</ref> or weights on the players <ref type="bibr" target="#b14">[8,</ref><ref type="bibr" target="#b15">9,</ref><ref type="bibr" target="#b19">13]</ref>. Milchtaich <ref type="bibr" target="#b23">[17]</ref>, Even-Dar et al. <ref type="bibr" target="#b14">[8]</ref> and Goldberg <ref type="bibr" target="#b19">[13]</ref> establish polynomial time convergence for versions of the Nash dynamics to (exact or approximate) Nash equilibria in these games, while Even-Dar and Mansour <ref type="bibr" target="#b15">[9]</ref> consider a more complex dynamics in which all players move concurrently according to a certain rerouting mechanism. Kearns and Mansour <ref type="bibr" target="#b21">[15]</ref> give polynomial time global and local algorithms that find additive ε-approximate equilibria for "large-population" games under a "bounded influence" assumption; however, this assumption appears not to hold for the general multiple-resource congestion games we consider here.</p><p>Recent papers by Fischer, Räcke and Vöcking <ref type="bibr" target="#b17">[11]</ref> and Blum, Even-Dar and Ligett <ref type="bibr">[3]</ref> consider congestion games at a similar level of generality to ours, each with some version of a "bounded (relative) slope" assumption that is analogous to bounded jumps. However, these papers analyze the non-atomic setting where the number of players is taken to infinity (the so-called "Wardrop traffic model"). Despite its apparent similarity, the non-atomic case is actually quite different from our discrete setting; for example, in the non-atomic case Nash equilibria can be computed in polynomial time <ref type="bibr">[2,</ref><ref type="bibr" target="#b16">10]</ref>. Fischer et al. <ref type="bibr" target="#b17">[11]</ref> establish polynomial bounds on the rate of convergence to approximate Nash equilibria (under a different notion of approximation) of a concurrent dynamics with moves based on "adaptive sampling", while Blum et al. <ref type="bibr">[3]</ref> give polynomial bounds when players use no-regret online learning algorithms.</p><p>We mention also two recent developments for more general games. Goemans, Mirrokni and Vetta <ref type="bibr" target="#b18">[12,</ref><ref type="bibr" target="#b24">18]</ref> study convergence of Nash dynamics not to an (approximate) Nash equilibrium but instead to a "sink equilibrium", for wider classes of games for which pure equilibria need not exist. They quantify the rate of convergence in various cases, and also the quality of the resulting solution as measured by a global utility function, rather than player-specific costs. And a subexponential time non-local algorithm for finding an approximate Nash equilibrium in general games with a fixed number of players and explicitly presented strategies was given by Lipton, Markakis and Mehta <ref type="bibr" target="#b22">[16]</ref>.</p><p>Finally we note that Theorem 1.1 is reminiscent of, and partially inspired by, recent work of Orlin, Punnen, and Schulz <ref type="bibr" target="#b27">[21]</ref>, who show how to find an ε-approximate local minimum for any problem in PLS. However, our setting differs from theirs in two crucial respects. Firstly, their algorithm finds an ε-local minimum of the potential function, which is not necessarily an ε-Nash equilibrium. Secondly, their algorithm would require ostensibly selfish players to somehow be aware of the value of the global potential function and to limit their actions based on this knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Congestion games. A game consists of a finite set of players {p 1 , . . . , p n }, each of which is assigned a finite set of strategies S i and a cost function</p><formula xml:id="formula_0">c i : S 1 × • • • × S n → N that he wishes to minimize. A game is called symmetric if all of the S i are identical. A state s = (s 1 , . . . , s n ) ∈ S 1 × • • • × S n</formula><p>is any combination of strategies for the players. A state s is a pure Nash equilibrium if for all players p i , c i (s 1 , . . . , s i , . . . , s n ) ≤ c i (s 1 , . . . , s i , . . . , s n ) for all s i ∈ S i ; thus at a Nash equilibrium, no player can improve his cost by unilaterally changing his strategy. It is well known that, while every (finite) game has a mixed Nash equilibrium § , not every game has a pure Nash equilibrium.</p><p>We will focus on the class of games known as congestion games, where players' costs are based on the shared usage of a common set of resources, which we shall call edges E = {e 1 , . . . , e m }. A player's strategy set S i ⊆ 2 E is an arbitrary collection of subsets of E; his strategy s i ∈ S i will therefore be a subset of E. Each edge e ∈ E has an associated nondecreasing delay function d e : {1, . . . , n} → N; if t players are using the edge e, they will each incur a cost of d e (t). As a result, in a state s = (s 1 , . . . , s n ), the cost of player p i is c i (s) = e∈s i d e (f s (e)), where f s (e) is the number of players using edge e under s (i.e., f s (e) = |{j : e ∈ s j }|).</p><p>Existence of potential functions and pure Nash equilibria. Congestion games possess several appealing characteristics, including the existence of an exact potential function. This function is defined as</p><formula xml:id="formula_1">φ(s) = e∈E fs(e) t=1 d e (t),<label>(1)</label></formula><p>and has the property that if player p i shifts strategy from s i to s i , the change in φ exactly mirrors the change in the player's cost: i.e., φ(s) -φ(s ) = c i (s) -c i (s ) <ref type="bibr" target="#b29">[23]</ref>.</p><p>An important consequence of this is the observation that, if we follow an iterative process where at each step one player changes strategy to lower his cost (a Nash dynamics), then the potential function φ will decrease until it reaches a local minimum, which must be a pure Nash equilibrium. However, this does not provide a bound on the number of such player moves required to reach a pure Nash equilibrium in a congestion game. Indeed, as mentioned in the Introduction, it has been shown <ref type="bibr" target="#b16">[10]</ref> that there exist (symmetric) congestion games in which the number of player moves required to go from one state to any pure Nash equilibrium is exponentially large.</p><p>Approximate Nash equilibria and ε-Nash dynamics. We define an ε-Nash equilibrium as a state in which no player has more than an ε-incentive to move:</p><formula xml:id="formula_2">Definition 2.1 For ε ∈ [0, 1), a state s = (s 1 , . . . , s n ) ∈ S 1 × • • • × S n is an ε-Nash equilibrium if for all players p i , c i (s 1 , . . . , s i , . . . , s n ) ≥ (1 -ε)c i (s 1 , . . . , s i , . . . , s n ) for all s i ∈ S i .</formula><p>We complement this definition with that of the ε-Nash dynamics, where we require that a player may make only ε-moves, or moves that improve his cost by a factor of more than ε; i.e., if player p i moves from s i to s i then c i (s 1 , . . . , s i , . . . , s n ) &lt; (1-ε)c i (s 1 , . . . , s i , . . . , s n ). Clearly when no further ε-moves are possible, the players have reached an ε-Nash equilibrium. Further, for concreteness, we stipulate that if more than one player has an ε-move available, a player whose relative gain is largest will be the one that moves. Thus a move is made by a player p i who maximizes</p><formula xml:id="formula_3">c i (s)-c i (s 1 ,...,s i ,...,sn) c i (s)</formula><p>. This choice seems the most natural, and unless otherwise stated we shall assume it throughout the paper. However, as we shall demonstrate later our results are not sensitive to this choice, and hold for a wide variety of other natural variations of the dynamics; in particular, they hold for the unrestricted ε-Nash dynamics, which allows an adversarial order of player moves so long as every player is offered the chance to move every so often.</p><p>Bounded jumps. We say that an edge e satisfies the α-bounded jump condition if its delay function satisfies d e (t + 1) ≤ αd e (t) for all t ≥ 1, for some value α ≥ 1. In our applications, we shall think of α as being constant or at most polynomially bounded in n. This still allows delay functions as large as α t , and is therefore a much weaker restriction than the Lipschitz condition (see, e.g., <ref type="bibr" target="#b16">[10]</ref>), which requires that the delay functions be linearly bounded. (Note that one consequence of our definition is that d e (1) &gt; 0; otherwise d e (t) = 0 for all t, and e is essentially irrelevant.) As we will see later (Section 3.1), even for symmetric congestion games with the bounded jump condition on all edges, finding a Nash equilibrium can be PLS-complete; thus in this sense, bounded jumps are not a major restriction on the power of congestion games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The basic convergence theorem</head><p>The main purpose of this section is to show the following, which is a restatement of Theorem 1.1 from the Introduction: Theorem 3.1 In any symmetric congestion game with n players in which all edges satisfy the αbounded jump condition, the ε-Nash dynamics converges from any initial state in nαε -1 log(nC) steps, where C is an upper bound on the cost of any player.</p><p>(Note that here and elsewhere, our bound is undefined for the case of exact Nash equilibria, i.e., when ε = 0.) Before giving the proof, we sketch the basic structure of the argument, which will be used repeatedly in the paper. The key observation is that after polynomially many moves by players with high costs, we must necessarily reach an ε-Nash equilibrium. For this purpose we use the exact potential function φ defined in equation <ref type="bibr">(1)</ref>. Suppose player p i , with current cost c i (s) ≥ φ(s) β , makes an ε-move; this move must reduce c i , and hence φ, by more than εφ(s)  β . After at most about βε -1 log φ max such steps, where φ max is the initial value of the potential function, we must have reached an ε-Nash equilibrium. Since φ(s) ≤ i c i (s), if the highest-cost player moves then we may take β = n and we are done. The main challenge, then, is to show that high-cost players move reasonably frequently, and are not blocked by low-cost players whose moves do not significantly decrease φ.</p><p>In light of the above discussion, the following lemma will be the main tool in the proof.</p><p>Lemma 3.2 In a symmetric congestion game in which every edge has α-bounded jumps, if in the ε-Nash dynamics with state s the next move is made by player p i , then c j (s) ≤ αc i (s) for all j.</p><p>Proof: Suppose player p i moves from s i to s i , taking the game from state s = (s 1 , . . . , s n ) to s = (s 1 , . . . , s i , . . . , s n ). Consider an arbitrary player p j , and the resulting state if p j , rather than p i , had adopted s i ; denote this state s = (s 1 , . . . , s i , . . . , s j = s i , . . . , s n ). Since p i moved and not p j , we can conclude that p j 's relative gain for this move is at most p i 's relative gain, regardless of whether this is an ε-move for p j . (If it is an ε-move, then p i 's relative gain must be at least as large by the definition of the dynamics; if it is not an ε-move, then p j 's relative gain is at most ε while p i 's relative gain is more than ε.) Thus we have</p><formula xml:id="formula_4">c j (s) -c j (s ) c j (s) ≤ c i (s) -c i (s ) c i (s) . (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>Now let us compare the cost p i pays for adopting s i , namely c i (s ), with how much p j would have paid for the same strategy, namely c j (s ). For each edge e ∈ s i , either p i is already occupying it before the move (e ∈ s i ), or not. In the former case, p j may have to pay as much as d e (f s (e) + 1) to use e, while p i only pays d e (f s (e)); by the bounded jump assumption, these differ by at most a factor of α. In the latter case, p i pays d e (f s (e)+1) and p j pays at most the same amount. Summing over all edges e ∈ s i , we obtain c j (s ) ≤ αc i (s ).</p><p>Combining this with inequality (2), we obtain</p><formula xml:id="formula_6">c j (s)-αc i (s ) c j (s) ≤ c i (s)-c i (s ) c i (s)</formula><p>, from which we can see that c j (s) ≤ αc i (s), as required.</p><p>Proof of Theorem 3.1: Lemma 3.2 guarantees that every time any player (say p i ) moves, the cost of that player is at least 1 α times the largest cost of any player. Since for any state s we have that φ(s) ≤ j c j (s), then c i (s) ≥ 1 αn φ(s). But under a move of p i taking the game from state s to s , the decrease in the potential function is φ(s) -φ(s ) = c i (s) -c i (s ) &gt; εc i (s) ≥ ε αn φ(s). Thus at each move φ must decrease by a factor of more than ε αn . But since φ is non-negative integervalued, there can be at most nαε -1 log φ max such decreases, where φ max is the initial value of the potential function. Since clearly φ max ≤ nC, we are done.</p><p>Remark: Note that we may replace log(nC) in Theorem 3.1 by log(φ max /φ min ), where φ max , φ min are upper and lower bounds respectively on the possible values of the potential function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PLS-completeness of bounded jump games</head><p>We complement Theorem 3.1 by observing that the class of congestion games with bounded jumps on all edges includes examples for which it is PLS-complete to find an exact Nash equilibrium; indeed, for such games the shortest path to an exact equilibrium in the Nash dynamics can be exponentially long, while Theorem 3.1 shows that an ε-equilibrium is reached in a polynomial number of steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 3.3</head><p>The problem of finding a Nash equilibrium in symmetric congestion games satisfying the α-bounded jump condition with α = 2 is PLS-complete.</p><p>Proof: We follow the chain of reductions in Theorem 3 of <ref type="bibr" target="#b16">[10]</ref>, but with some modifications to the delay functions. The starting point is Posnae3flip: given an instance of not-all-equal-3sat with weights on the clauses and only positive literals, find a truth assignment such that the total weight of all satisfied clauses cannot be improved by flipping the value of a single variable. This problem is known to be PLS-complete <ref type="bibr" target="#b32">[26]</ref>. In <ref type="bibr" target="#b16">[10,</ref><ref type="bibr">Theorem 3(i)</ref>] this is reduced to the problem of finding a Nash equilibrium in a congestion game as follows. For each 3-clause c there are two edges, e c and e c , with delay functions d(1) = d(2) = 0 and d(t) = w c for t &gt; 2. There is one player for each variable x, and the player has two strategies: one contains all the e c for clauses c that contain x, and the other contains all the e c for the same clauses. Any Nash equilibrium of this game corresponds to a local optimum of Posnae3flip. Now observe that, since both strategies of any player contain the same number of edges, with the same delay functions, the Nash equilibria will not be affected if we add a constant to the delay functions of all edges; i.e., the delay becomes</p><formula xml:id="formula_7">d(1) = d(2) = w c and d(t) = 2w c for t &gt; 2.</formula><p>Finally, following [10, Theorem 3(ii)] we can reduce this game to a symmetric game by adjoining to both the strategies of each player x a new edge e x with delay function d ex (1) = D and d ex (t) = 2D for t &gt; 1, where D = 2mw max + 1. (Here m is the number of clauses, and w max the maximum weight of a clause.) Clearly, in any Nash equilibrium of the symmetric game with the same number of players and all strategies available to all, exactly one strategy from each pair in the original game must in fact be selected. Thus we have arrived at a symmetric congestion game in which the delay function of every edge satisfies the α-bounded jump condition for α = 2, and for which finding a Nash equilibrium is PLS-complete. Moreover, as observed in <ref type="bibr" target="#b16">[10]</ref>, the reductions inherit from <ref type="bibr" target="#b32">[26]</ref> the property that the length of a shortest path to an equilibrium may be exponentially long. This completes the proof of the Proposition.</p><p>Remark: In the above construction, the value φ max /φ min can also be seen to be at most 3, so by the remark following the proof of Theorem 3.1 the convergence time of the ε-Nash dynamics is O(nε -1 ).</p><p>We inject one caveat into the above discussion: altering the delay functions on the edges as we did has no effect on the Nash equilibria, but may have a significant effect on the ε-equilibria. Thus the approximate equilibria found in Theorem 3.1 for the modified game may bear little relationship to those for the original game. Our only purpose here was to demonstrate that Theorem 3.1 can apply to games whose exact Nash equilibria are hard to locate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Variations on the dynamics</head><p>We now discuss some variations on the ε-Nash dynamics, and show that Theorem 3.1 still holds in these cases. Thus the rapid convergence to an ε-equilibrium guaranteed by the theorem does not depend crucially on allowing the player with largest relative gain to move. In the next section, we will show how to dispense with coordination altogether.</p><p>Largest gain dynamics. Define the largest gain ε-Nash dynamics as that in which, at each step, among all players with an ε-move available, the one that moves is one whose (absolute) cost improvement is greatest. We show that Theorem 3.1 still holds under this dynamics: Theorem 3.4 Theorem 3.1 continues to hold under the largest gain ε-Nash dynamics.</p><p>Proof: Consider any move in the dynamics that takes the game from state s to state s . It suffices to show that this causes the potential function φ to drop by a factor of at least ε αn ; i.e., φ(s) -φ(s ) ≥ ε αn φ. To see this, let p i be the player that moves, and consider any other player p j . We examine two cases: either p j has an ε-move available, or p j does not.</p><p>In the first case, p i 's absolute improvement must be at least εc j (s), since p j could have improved by at least εc j (s), but p i was given priority by virtue of having a larger absolute gain. Thus φ(s) -φ(s ) ≥ εc j (s) for p j with ε-moves available.</p><p>In the second case, let s be the resulting state if p j were to move to s i instead of p i . By the same argument as in the proof of Lemma 3.2, we have that c j (s ) ≤ αc i (s ). Since c i (s ) &lt; (1 -ε)c i (s), but (1 -ε)c j (s) ≤ c j (s ), we can conclude that c j (s) &lt; αc i (s). Hence φ(s) -φ(s ) &gt; εc i (s) &gt; ε α c j (s) for all p j with no ε-moves available.</p><p>Combining the two cases, we have that φ(s) -φ(s ) ≥ ε α c j (s) for all players p j . Since at least one player p j has cost c j (s) ≥ 1 n φ(s), we obtain φ(s) -φ(s ) ≥ ε αn φ(s), as required.</p><p>Heaviest first dynamics. If at each step, among all players with an ε-move available, we allow a player with largest current cost to move, we arrive at the heaviest first ε-Nash dynamics. We can show that this version of the dynamics also leads to rapid convergence: Theorem 3.5 Theorem 3.1 continues to hold under the heaviest first ε-Nash dynamics.</p><p>Proof: It suffices to show that Lemma 3.2 still holds under this dynamics. At any given step, let p i be the player that moves, s = (s 1 , . . . , s n ) be the current state, and s = (s 1 , . . . , s i , . . . , s n ) be the state after p i moves. We wish to show that c j (s) ≤ αc i (s) for all players p j . Fix j and define s to be the state that results if p j were to move to s i instead of p i . Since p j did not do so, we conclude that either c j (s) ≤ c i (s), in which case p i had priority over p j in the heaviest first dynamics and the lemma is satisfied (with equality when α = 1), or c j (s) &gt; c i (s) but also (1 -ε)c j (s) ≤ c j (s ).</p><p>To handle this latter case, note first that, as in the proof of Lemma 3.2, we have c j (s ) ≤ αc i (s ). Moreover, as above, since p i makes a move from s i to s i , we must have c i (s ) &lt; (1 -ε)c i (s). Putting all of this together, we get</p><formula xml:id="formula_8">(1 -ε)c j (s) ≤ c j (s ) ≤ αc i (s ) &lt; (1 -ε)αc i (s),</formula><p>so we can conclude that c j (s) &lt; αc i (s) as required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The unrestricted dynamics</head><p>So far our Nash dynamics, while essentially decentralized, has assumed some minimal coordination mechanism whereby players with the largest incentive move first. In this section, we show that our results still hold (with a modest penalty in convergence time) when this coordination is removed. We consider what is in a sense the most liberal possible dynamics, which we call the unrestricted ε-Nash dynamics. In this dynamics, players may move in an arbitrary order (which may even be under the control of an adversary), subject only to a minimal "liveness" condition. This condition just says that every player must be given an opportunity to move ¶ within a bounded amount of time; without such a condition, one or more players could be "locked out" for arbitrarily long and we could not expect to bound the rate of convergence. More formally, the unrestricted dynamics is specified by a sequence q 1 , q 2 , . . ., where each q t denotes a player; at step t, player q t is given the opportunity to move, and actually makes a move if he has an ε-move available. (Otherwise nothing happens at step t.) The sequence (q t ) may be adaptive (i.e., q t may depend in an arbitrary way on the past, the current state etc.) We require only that, for some constant T , in each interval of the sequence of length T every player p i appears at least once. A natural dynamics satisfying this condition is the "round-robin" dynamics, where in each round all players are selected to move according to some fixed permutation.</p><p>We now show that Theorem 3.1 holds for the unrestricted dynamics, with a slightly looser bound on the time until convergence. Note that this seemingly stronger result does not in fact imply polynomial convergence in the setting of Theorem 3.1 (or any of its variants above) because the original ε-Nash dynamics may not satisfy the liveness condition. (Some player may never be in a position of having a move with the largest relative gain.) Theorem 4.1 In any symmetric n-player congestion game whose edges satisfy the α-bounded jump condition, any ε-Nash dynamics in which every player is given an opportunity to move within each time interval of length T converges from any initial state in n(α+1) ε(1-ε) log(nC) T steps, where C is an upper bound on the cost of any player.</p><p>Before proving the theorem, we state and prove an important lemma that allows us to relate improvements in the potential function to a change in the cost of a player, even when the player does not move for many steps. As can be seen from the proof, the lemma is not specific to the unrestricted dynamics but holds for any variant of the ε-Nash dynamics. Moreover, the proof makes In the first line, the first item in the maximum is the improvement gained by p i for his move, while the second item follows from Lemma 4.2. The second line comes from inequality (4) above.</p><p>Finally, this last expression is minimized when c h (s t ) = α α+1-ε c h (s 0 ), and thus the potential function must decrease by at least ε</p><formula xml:id="formula_9">(1-ε) α+1-ε c h (s 0 ) ≥ ε(1-ε) α+1 φ(s 0 )</formula><p>n . This concludes the analysis of case (ii) and hence the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Heterogeneous players</head><p>We now generalize our previous setting by allowing each player p i to have her own value ε = ε i that specifies her "tolerance" for unhappiness. Thus whereas one relaxed player may be content with ε = 0.1, another may be more particular and demand ε = 0.001. Accordingly, given individual player tolerances ε i ∈ [0, 1), we extend our definition of approximate Nash equilibrium as follows:</p><formula xml:id="formula_10">Definition 5.1 For ε = (ε i ) ∈ [0, 1) n , a state s = (s 1 , . . . , s n ) ∈ S 1 × • • • × S n is an ε-Nash equilibrium if for all players p i , c i (s 1 , . . . , s i , . . . , s n ) ≥ (1 -ε i )c i (s 1 , . . . , s i , . . . , s n ) for all s i ∈ S i .</formula><p>The ε-Nash dynamics is also extended in the obvious way. For definiteness, we will go back to our original ε-Nash dynamics of Section 3 in which the player with largest relative gain moves.</p><p>By modifying the proof of Theorem 3.1, it can be shown that this dynamics converges in O(nαε -1  min (1 -ε max ) -1 log(nC)) steps, where ε min = min i ε i and ε max = max i ε i . However, it is natural to ask if one can say more; in particular, if some player has a relatively large value of ε i (and thus is very "tolerant"), can this player be forced to move very many times because of other, less tolerant players in the system?</p><p>We now prove an intriguing result along these lines. We show that the number of time steps at which a player with tolerance ε i will be "unhappy" (i.e., will have an ε i -move available) is essentially O(nαε -1 min log(nC)), irrespective of the ε j -values of the other players. Thus highly intolerant players are not able to force others to move frequently. Theorem 5.2 Let ε max &lt; 1 be the maximum value of ε i among all players p i . Then for any value ε &gt; 0, there are at most nα ε(1-εmax ) log(nC) times at which some player p j with ε j ≥ ε will be able to move before the ε-Nash dynamics converges.</p><p>Proof: Consider a state s = (s 1 , . . . , s n ) in which a player p j with ε j ≥ ε has an ε j -move available. It suffices to show that the decrease in potential function φ is at least</p><formula xml:id="formula_11">ε j (1-εmax ) αn</formula><p>φ(s). Let p i be the player who actually moves from state s, and let s = (s 1 , . . . , s i , . . . , s n ) be the resulting new state. The largest relative gain dynamics implies that φ(s ) -φ(s) &gt; ε j c i (s). Now let p h be the player with largest cost in s. If p h = p i then we are done immediately, since c h (s) ≥ φ(s) n . Otherwise, let s be the state that results from s if p h moves instead of p i and takes p i 's new strategy s i . As in the proof of Theorem 3.1, we have c h (s ) ≤ αc i (s ) &lt; α(1 -ε j )c i (s). Since p h does not actually move from s, either (1) p h moving to s is not an ε h -move for p h ; or (2) the relative gain that p h gets from such a move is no more than the relative gain p i gets from its move. We analyze these two cases separately.</p><p>In the first case, we have that</p><formula xml:id="formula_12">c h (s) -c h (s ) ≤ ε h c h (s). Since c h (s ) &lt; α(1 -ε j )c i (s), we can conclude that c h (s) -αc i (s) &lt; ε h c h (s), and therefore c i (s) ≥ 1-ε h α c h (s). The change in potential function is then at least φ(s) -φ(s ) &gt; ε j (1-ε h ) αn φ(s).</formula><p>In the second case, we have c h (s)-c h (s )</p><formula xml:id="formula_13">c h (s) ≤ c i (s)-c i (s ) c i (s)</formula><p>, or c h (s ) c h (s) ≥ c i (s ) c i (s) . Again, since c h (s ) &lt; αc i (s ), we conclude that c h (s) ≤ αc i (s). Thus φ(s) -φ(s ) ≥ ε j αn φ(s).</p><p>Remarks: 1. The above theorem includes an additional factor (1 -ε max ) -1 , and thus says little when some ε i is very close to 1. We believe that this is a technical artifact of the proof. Moreover, if ε i is very close to 1 then the corresponding player, p i , will move only when he is able to reduce his cost to essentially zero in one move; clearly this is not a scenario of great practical interest.</p><p>2. Unlike our other results, Theorem 5.2 is somewhat sensitive to the choice of ε-Nash dynamics. For example, while it also holds for the largest gain dynamics, it can fail for the heaviest first dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Wait times with heterogeneous players</head><p>Theorem 5.2 leads to the following natural question: Given that all players with ε-values larger than any specific ε will collectively be able to make an ε-move a limited number of times, can we place a polynomial upper bound on the last time at which any such player will be able to move?</p><p>We show that the answer is no. In particular, we construct a symmetric bounded-jump congestion game with n + 1 players, as well as a starting state, in which n of the players, p 1 , . . . , p n , each have ε i = 0 and have to solve a PLS-complete problem before the final player, p * , who has some positive ε * &gt; 0, is able to move.</p><p>We do this by embedding the PLS-complete problem Posnae3flip into our game in a manner similar to that outlined in the proof of Proposition 3.3. Given an instance of Posnae3flip on n variables, the embedded game has a player p i for each variable x i , with tolerance ε i = 0. Again, there are two edges e c and e c for each clause c; both these edges have delay function d(1) = d(2) = w c , and d(3) = 2w c . Each player p i has the same two strategies as before, one containing all edges e c for each clause c containing x i , and one containing all edges e c for the same clauses. Assume that this instance of Posnae3flip is such that there exist states from which any path to a Nash equilibrium is exponentially long; we start the game with the p i in one of these states. We will denote this initial state by s 0 , and subsequent states s 1 , s 2 , . . . until the game reaches a Nash equilibrium s N . Note that each edge in the embedded game has at most three players on it at each step; let σ r denote the set of clauses c for which either e c or e c has exactly three players in state s r .</p><p>We now introduce our new player p * with ε * &gt; 0, who has two strategies available. One strategy s * is p * 's initial strategy, and contains only a single new edge e * , while the other strategy s * contains all previous edges e c and e c for all clauses c.</p><p>We now set the delay function for e * and extend the delay functions for the e c and e c . For each clause c ∈ σ N , we set both d ec (4) and d e c (4) equal to d ec (3) = 2w c , while for all c ∈ σ N , we set both d ec (4) and d e c (4) equal to d ec (3) + γ, where γ is a small constant (say, 2). Finally, we set d e * (1) = β, where with some foresight we set β to be c 3wc 1-ε * + 1 . Since the original n players p i , if left to themselves, will take an exponential number of steps to reach their own Nash equilibrium, we will be done if we can show that the new player p * cannot make an ε * -move until this Nash equilibrium is reached, but will make such a move as soon as this happens. In other words, if we denote by c * (s r ∪ s * ) the cost that p * would pay for using strategy s * when the other players are in state s r , then we need to verify that c * (s r ∪ s * ) ≥ (1 -ε * )β for all r &lt; N , while c * (s N ∪ s * ) &lt; (1 -ε * )β.</p><p>To see this, observe that at any time step 0 ≤ r ≤ N , the cost that p * would pay for his other strategy s * is c * (s r ∪ s * ) = c∈σ r (d ec (4) + d ec (1)) + c ∈σ r (d ec (3) + d ec (2)) = c 3w c + c∈σ r \σ N γ. Since σ r ⊆ σ N for all r &lt; N (if σ r ⊆ σ N , then φ(s r ) ≤ φ(s N ) where φ is the potential function for the original game, before the addition of player p * ), we have that c * (s r ∪s * ) ≥ c 3w c +γ ≥ (1-ε * )β for all r &lt; N , and c * (s</p><formula xml:id="formula_14">N ∪ s * ) = c 3w c &lt; (1 -ε * )β.</formula><p>Finally, we apply the same trick as in the proof of Proposition 3.3 to make the game symmetric. We observe that, as in that proof, the resulting game satisfies the α-bounded jump condition with α = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Congestion games with unbounded jumps</head><p>We now investigate what happens when we relax the requirement that every edge in the congestion game satisfies the bounded jump condition. Our goal is to prove polynomial convergence of the ε-Nash dynamics even when we allow any constant number of edges to have arbitrary delay functions. Specifically, we will prove the following theorem, which is a more precise reformulation of Theorem 1.4 in the Introduction. Theorem 6.1 In any symmetric congestion game with n players in which all but k edges satisfy the α-bounded jump condition, the ε-Nash dynamics converges from any initial state in at most nαε -1 log(nC) 2 k steps, where C is an upper bound on the cost of any player.</p><p>Before presenting the proof we sketch some of the main ideas. First, consider the simple case in which there is only one edge, e * , that is not α-bounded. Our previous analysis fails since Lemma 3.2 no longer holds: now, when player p i makes a move, it is no longer true that another player p j can match that move with an α-factor penalty. To overcome this obstacle, we introduce the concept of a reduced game; the reduced game in state s consists of exactly those players p i whose strategies s i contain e * . When a player in the reduced game gives up e * , or a player outside the reduced game makes a move, then we know that φ must drop by the usual ε αn , since any player could emulate this move; call these moves good moves. To observe that this must happen frequently, note that the reduced game is itself a game with α-bounded jumps! Hence by our previous results the reduced game can only continue for a small number of steps before reaching an ε-equilibrium.</p><p>To extend the analysis to an arbitrary number k of exceptional edges, we apply the above idea recursively. Starting from the global game on all n players, we build a nested sequence of reduced games by repeatedly excluding from the next game the heaviest remaining player p h , along with all players whose exceptional edges are a subset of those held by p h . Thus each successive reduced game contains fewer players than its predecessor, and is indexed by a subset of exceptional edges that is not a subset of any previous reduced game; clearly this sequence of games has length at most 2 k . With this structure in place, we can show that each move in the global game causes a good move in one of the reduced games, and hence only a limited number of these moves can happen before the reduced games reach equilibrium; at this point a good global move must occur. There are several technical details to handle; in particular, when a good move is made in one of the reduced games, all subgames after it in the sequence have to be redefined; and the analysis requires an extension of Lemma 4.2 that applies in this context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Proof of Theorem 6.1</head><p>We now give the details of the proof. Recall that our context is a congestion game in which there are k "exceptional" edges that do not satisfy the α-bounded condition, each of which may have a different, arbitrary nondecreasing delay function. We will denote the set of exceptional edges by E * = {e * 1 , . . . , e * k } ⊆ E. We begin with the following extension of Lemma 4.2. Lemma 6.2 Fix an arbitrary state s and player p i , and let Q ⊆ E * be the subset of exceptional edges held by p i in s. Let s be the state immediately after one of the following first occurs: (1) a player whose exceptional edges are a subset of Q makes a move; or (2) a player makes a move that results in his exceptional edges being a subset of Q. Then φ(s) -φ(s ) &gt; εc i (s) α . This lemma says the following. Consider the first time a player (say, p j ) makes a move that p i could also make without adopting any additional exceptional edges that p j currently holds. Then over the intervening time interval, the decrease in the potential function has at least the same guarantee as if p i himself had moved, up to a factor of α.</p><p>Proof: Let p j denote the player that makes the move resulting in the game reaching s , and let s be the state just before p j makes this move; note that p i has not moved by this point. Then by Lemma 4.2 (which as observed earlier holds even for games with unbounded jumps) we have</p><formula xml:id="formula_15">φ(s) -φ(s ) ≥ ε(c i (s) -c i (s )).<label>(5)</label></formula><p>Now consider the move of player p j that takes the state from s to s (i.e., p j 's strategy changes from s j to s j ); this decreases p j 's cost by more than a factor of ε, so φ(s ) -φ(s ) &gt; εc j (s ). To get a lower bound on this decrease, we consider the cost that p i would pay had he, rather than p j , made the move to s j ; to compute this, we need to consider how much it would cost p i to obtain the edges in s j \ s i . From the statement of the lemma, we have two cases to consider.</p><p>In the first case, the set of exceptional edges held by p j in s j (before the move) is a subset of those held by p i . Thus for each exceptional edge e ∈ s j , p i would only have to pay at most the same cost as p j . Meanwhile, for each bounded jump edge e ∈ s j , p i may have to pay as much as a factor of α more than p j . Summing over both classes of edges yields that p i would pay at most αc j (s ) to adopt s j from the state s . However, since p i did not do so, we know that his relative gain can be at most that of p j , so that</p><formula xml:id="formula_16">c i (s ) -αc j (s ) c i (s ) ≤ c j (s ) -c j (s ) c j (s ) .</formula><p>This implies c i (s ) ≤ αc j (s ), and hence φ(s ) -φ(s ) &gt; εc i (s ) α . Combining this with (5), we conclude that φ(s) -φ(s ) &gt; εc i (s) α . In the second case, the set of exceptional edges held by p j in s j (after the move) is a subset of those held by p i . Again, p i pays at most the same cost as p j for these edges, and the rest of the argument proceeds as in the first case.</p><p>We now formally define the concept of a nested sequence of reduced games, as indicated in the proof sketch. Given a congestion game with k exceptional edges E * in a particular state s, we can describe it as a nested sequence of smaller congestion games as follows:</p><p>• Choose a player p i ; let Q denote the set of exceptional edges held by p i . Identify all players p j (including p i ) whose sets of exceptional edges are a subset of Q; place these players in the top level of the sequence.</p><p>• Recursively perform this same operation on the remaining players until no players are left.</p><p>It is easy to see that when this procedure is completed, the players will have been partitioned into ≤ 2 k levels, with each level being associated with a particular subset of E * . If we number the levels from 0 to -1, with the top level being 0, we see that the subsets Q i associated with each level i form a partial order; namely if Q i ⊆ Q j , then i ≤ j. A player will belong to the first level i at which his set of exceptional edges Q is a subset of Q i . W.l.o.g. we assume that Q -1 = E * .</p><p>Further, for any level i, we can define the reduced game at level i, denoted G i , as the game consisting of all players at levels i, . . . , -1, equipped with delay functions and a potential function φ i that includes only these players. More formally, if P i is the set of players in G i , then the delay function on each edge is d s (e) + t), where f (i) s (e) is the number of players not in G i that utilize e. The set of strategies for each player is as in the original game, excluding strategies whose exceptional edges are a subset of Q j for some j &lt; i. The potential function φ i is defined analogously, with φ i (s) = e∈E fs(e)-f (i) s (e) t=1 d (i) e (t). We make use of this nested sequence as follows. Given a congestion game and an initial state s, we create a sequence of games by choosing, at each level, the heaviest player among all remaining players (with ties broken arbitrarily). This defines a particular initial sequence of games. After each move in the global game, we reorganize this sequence as follows:</p><p>• Consider the set of exceptional edges that the moving player held before his move and after his move, and determine which of these sets falls into a higher level (lower value of i) in the sequence. Let G i be the reduced game corresponding to this level.</p><p>• Consider all players in the reduced game G i , and recreate the sequence from this point down, again choosing the heaviest player to determine each level. We will say that the games G j , j ≥ i have been (re)initialized at this point.</p><p>An important point to realize here is that, while the set of players at level i changes after reinitialization, the set of players in the game G i remains the same, and so the potential function φ i for G i retains its meaning. All games (and potential functions) for j &gt; i are created again from scratch. Lemma 6.3 When a game G i is the highest game to be reinitialized after a move, its corresponding potential function φ i will have decreased by more than ε γ i α since its last initialization, where γ i was the largest cost of any player in game G i at the time of the last initialization of G i .</p><p>Proof: From the description above, it is clear that all moves that have occurred since the last initialization of G i have been made by players in G i ; a move by a player in G j with j &lt; i would have caused G j , and hence G i , to be reinitialized. For G i to be the highest game reinitialized after a move, this means either that a player at level i moved within level i or to a lower level, or that a player moved to level i from a lower level. In both cases we can apply Lemma 6.2 to G i (the first case is case (1) of the lemma, the second is case (2), and in both cases we take p i to be the heaviest player who was used to define level i), which guarantees that we will have gained an improvement of more than εγ i α in φ i since the last initialization. With the above machinery in place, Theorem 6.1 follows from a straightforward induction:</p><p>Proof of Theorem 6.1: The proof proceeds by showing inductively that a game at level i can have at most n i αε -1 log(n i C) 2 k -i moves before reaching an ε-Nash equilibrium (or being prematurely ended by a higher game being reinitialized), where n i is the number of players in G i . The base case, i = 2 k -1, is a game that is necessarily always at the bottom of the sequence. Any move that does not prematurely terminate this game must involve a player moving within this level, and is therefore by Lemma 6.3 a good move for G i . Thus there can be at most n i αε -1 log(n i C) such moves before G i reaches an ε-Nash equilibrium. Now consider a game G i for i &lt; 2 k -1; at any point it may either be the lowest level game in the sequence, or have a game G i+1 below it. In the first case, as above any move is either a good move for G i or else ends G i ; in the second case, by induction G i+1 can run for at most n i+1 αε -1 log(n i+1 C) 2 k -i-1 steps before reaching an ε-Nash equilibrium. After this, the next move must necessarily be by a player outside G i+1 , i.e., by a player in G i or a higher game, resulting in either a good move for G i or termination of G i . As G i can only have n i αε -1 log(n i C) good moves before reaching its own ε-Nash equilibrium, and n i+1 &lt; n i , we obtain our result.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>§  In a mixed Nash equilbrium, a player's strategy can be any probability distribution over available strategies, and no individual player can improve his expected cost by choosing another probability distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>¶ Note that this player need not have an ε-move available! Thus the adversary may attempt to always select players who cannot move.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Lisa Fleischer, Nicole Immorlica, Christos Papadimitriou, Tim Roughgarden and Kunal Talwar for helpful input.</p></div>
			</div>


			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. Supported in part by NSF ITR grant CCR-0121555. Work done in part while this author was visiting Microsoft Research Silicon Valley Campus.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>no use of the bounded jump property; in fact, we shall apply the lemma to games with unbounded jumps in Section 6. Lemma 4.2 Let c i (s) be the cost of player p i in state s, and let c i (s ) be p i 's cost in a future state s in which p i has not moved. Then φ(s) -φ(s ) ≥ ε(c i (s) -c i (s )).</p><p>Proof: Note that c i (s) -c i (s ) = e∈s i d e (f s (e)) -d e (f s (e)), and that the only positive contributions to this sum are from those edges e in which f s (e) &gt; f s (e), i.e., edges that other players have vacated. For each such edge e, the first player p j to give up e must have had cost at least d e (f s (e)) at the time, and hence improved the potential function by at least εd e (f s (e)). Therefore the total improvement to the potential function can be bounded as follows:</p><p>Proof of Theorem 4.1: It is sufficient to show that during any interval in which every player is given an opportunity to move, the potential function φ must decrease by at least ε(1-ε) (α+1)n φ 0 , where φ 0 is the value of the potential function at the beginning of the interval. Denote the states during this interval as s 0 , s 1 , . . . , s T ; note that successive states in this sequence need not be distinct, as the player licensed to move may not in fact be able to move.</p><p>Let p h be the player with largest cost in s 0 ; let t ≥ 0 be the first time during this interval in which p h is given the chance to move. We analyze two cases:</p><p>Case (i): At time t, p h has an ε-move available. From Lemma 4.2, we are guaranteed that φ(s 0 ) -φ(s t ) ≥ ε(c h (s 0 ) -c h (s t )), and thus after p h moves φ will have improved by at least εc h (s 0 ) ≥ ε n φ(s 0 ). So in this case the claim above holds. Case (ii): At time t, p h does not have an ε-move available. In this case, we observe that at time t, we must have c h (s t ) ≤ α 1 -ε c i (s t ) for all other players p i .</p><p>not, for any player p i violating this condition, p h can make an ε-move by simply adopting p i 's strategy at an overall cost of at most αc i (s t ). Now note that at least one player must actually move in the interval [0, . . . , T ]; otherwise, we are already at an ε-Nash equilibrium. Suppose on the one hand that the first player to move, say p i , does so at time t &gt; t, i.e., after p h has been given a chance to move. Then we have c h (s t ) = c h (s 0 ) and c i (s t ) = c i (s t ) = c i (s 0 ), and combining this with (3) we obtain c i (s t ) ≥ 1-ε α c h (s 0 ). The improvement to the potential function caused by this move is then at least ε</p><p>n . Now suppose on the other hand that some player moves before time t, and let p i be the last such player to move, this move taking place at time t &lt; t. We claim that</p><p>To see this, note from (3) that p i must satisfy this condition at time t, and hence also immediately after the move (which is the last before time t); and since the move can only decrease his cost he must satisfy the condition at time t also. Now the change in φ up to time t bounded as follows:</p><p>φ(s 0 ) -φ(s t ) ≥ max εc i (s t ), ε c h (s 0 ) -c h (s t ) ≥ ε max 1 -ε α c h (s t ), c h (s 0 ) -c h (s t ) .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">In the special case where each strategy contains at most one exceptional edge, the exponent in Theorem 6.1 can be improved from 2 k to k. This is a natural case that arises when the edges are used to create &quot;classes</title>
		<imprint/>
	</monogr>
	<note>of players, as discussed in the Introduction</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Theorem 6.1 holds for all variants of the dynamics considered here, including the unrestricted dynamics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Open problems We conclude by mentioning a few open problems arising from this work</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Can one extend the analysis of the ε-Nash dynamics to an arbitrary number of exceptional edges, and achieve at least subexponential convergence time? As mentioned earlier, this would actually cover all (not necessarily symmetric) congestion games. Also, can we say anything about the case of weighted players, where pure Nash equilibria may not necessarily exist?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Motivated by the polynomial time algorithm of [10] for finding an (exact) Nash equilibrium for symmetric network congestion games, can one show that the ε-Nash dynamics in such games converges rapidly (in an appropriate sense) to an exact equilibrium? Note that PLS-completeness is no longer an obstacle here</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">What can one say about the properties of ε-Nash equilibria and their relationship to true equilibria? For example, it is not hard to see that the bounds on price of anarchy in [1,6] for exact equilibria with linear or polynomial delay functions carry over</title>
		<imprint/>
	</monogr>
	<note>with additional ε-dependent factors) to ε-equilibria, even for asymmetric games</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">In our dynamics, only one player moves at each step. It would be interesting also to investigate dynamics in which all players move concurrently</title>
		<imprint/>
	</monogr>
	<note>as in [11] and [3] for the non-atomic case. References</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The price of routing unsplittable flow</title>
		<author>
			<persName><forename type="first">B</forename><surname>Awerbuch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Epstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 37th ACM Symposium on Theory of Computing</title>
		<meeting>37th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Winsten</surname></persName>
		</author>
		<title level="m">Studies in the Economics of Transportation</title>
		<imprint>
			<publisher>Yale University Press</publisher>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Routing without regret: On convergence to Nash equilibria of regret-minimizing algorithms in routing games</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Even-Dar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th ACM Symposium on Principles of Distributed Computing</title>
		<meeting>25th ACM Symposium on Principles of Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="45" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Settling the Complexity of 2-Player Nash-Equilibrium</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 47th IEEE Symposium on Foundations of Computer Science</title>
		<meeting>47th IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computing Nash equilibria: Approximation and smoothed complexity</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 47th IEEE Symposium on Foundations of Computer Science</title>
		<meeting>47th IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The price of anarchy of finite congestion games</title>
		<author>
			<persName><forename type="first">G</forename><surname>Christodoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koutsoupias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 37th ACM Symposium on Theory of Computing</title>
		<meeting>37th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="67" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Complexity of Computing a Nash Equilibrium</title>
		<author>
			<persName><forename type="first">C</forename><surname>Daskalakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38th ACM Symposium on Theory of Computing</title>
		<meeting>38th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convergence time to Nash equilibria</title>
		<author>
			<persName><forename type="first">E</forename><surname>Even-Dar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kesselman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th International Conference on Automata, Languages and Programming</title>
		<meeting>30th International Conference on Automata, Languages and Programming</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="502" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast convergence of selfish rerouting</title>
		<author>
			<persName><forename type="first">E</forename><surname>Even-Dar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th ACM-SIAM Symposium on Discrete Algorithm</title>
		<meeting>16th ACM-SIAM Symposium on Discrete Algorithm</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="772" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The complexity of pure Nash equilibria</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fabrikant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 36th ACM Symposium on Theory of Computing</title>
		<meeting>36th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="604" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast convergence to Wardrop equilibria by adaptive sampling methods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Räcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vöcking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 38th ACM Symposium on Theory of Computing</title>
		<meeting>38th ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sink equilibria and convergence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 46th IEEE Symposium on Foundations of Computer Science</title>
		<meeting>46th IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="142" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bounds for the convergence rate of randomized local search in a multiplayer loadbalancing game</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th ACM Symposium on Principles of Distributed Computing</title>
		<meeting>25th ACM Symposium on Principles of Distributed Computing</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How easy is local search?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="79" to="100" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient Nash computation in large population games with bounded influence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Conference in Uncertainty in Artificial Intelligence</title>
		<meeting>18th Conference in Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Playing large games using simple strategies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Markakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM Conference on Electronic Commerce</title>
		<meeting>4th ACM Conference on Electronic Commerce</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="36" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Congestion games with player-specific payoff functions</title>
		<author>
			<persName><forename type="first">I</forename><surname>Milchtaich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="111" to="124" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convergence issues in competitive games</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Mirrokni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems</title>
		<meeting>7th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="183" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Potential games</title>
		<author>
			<persName><forename type="first">D</forename><surname>Monderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="124" to="143" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Equilibrium points in n-person games</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="49" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Approximate local search in combinatorial optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Orlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Punnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th ACM-SIAM Symposium on Discrete Algorithms</title>
		<meeting>15th ACM-SIAM Symposium on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="587" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Algorithms, games and the Internet</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 33rd ACM Symposium on Theory of Computing</title>
		<meeting>33rd ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="749" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A class of games possessing pure-strategy Nash equilibria</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Game Theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="65" to="67" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<title level="m">Selfish routing and the price of anarchy</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bounding the inefficiency of equilibria in nonatomic congestion games</title>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="389" to="403" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Simple local search problems that are hard to solve</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Schäffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yannakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="56" to="87" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Nash equilibria in competitive societies, with applications to facility location, traffic routing and auctions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 43rd IEEE Symposium on Foundations of Computer Science</title>
		<meeting>43rd IEEE Symposium on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="416" to="425" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
