<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Agent-Based Load Balancing on Homogeneous Minigrids: Macroscopic Modeling and Characterization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-05-20">20 May 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Senior Member, IEEE, Xiaolong</roleName><forename type="first">Jiming</forename><surname>Liu</surname></persName>
							<email>jiming@comp.hkbu.edu.hk..</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Kowloon Tong, Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuanshi</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Kowloon Tong, Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Kowloon Tong, Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Agent-Based Load Balancing on Homogeneous Minigrids: Macroscopic Modeling and Characterization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-05-20">20 May 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">0B521D32D559AF06A08E4017BA48DEA6</idno>
					<note type="submission">received 25 Feb. 2003; revised 14 June 2004; accepted 30 Sept. 2004;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Homogeneous minigrids</term>
					<term>load balancing</term>
					<term>task distribution</term>
					<term>agents</term>
					<term>macroscopic modeling</term>
					<term>steady states</term>
					<term>convergence</term>
					<term>grid simulation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a macroscopic characterization of agent-based load balancing in homogeneous minigrid environments. The agent-based load balancing is regarded as agent distribution from a macroscopic point of view. We study two quantities on minigrids: the number and size of teams where agents (tasks) queue. In macroscopic modeling, the load balancing mechanism is characterized using differential equations. We show that the load balancing we concern always converges to a steady state. Furthermore, we show that load balancing with different initial distributions converges to the same steady state gradually. Also, we prove that the steady state becomes an even distribution if and only if agents have complete knowledge about agent teams on minigrids. Utility gains and efficiency are introduced to measure the quality of load balancing. Through numerical simulations, we discuss the utility gains and efficiency of load balancing in different cases and give a series of analysis. In order to maximize the utility gain and the efficiency, we theoretically study the optimization of agents' strategies. Finally, in order to validate our proposed agentbased load balancing mechanism, we develop a computing platform, called Simulation System for Grid Task Distribution (SSGTD). Through experimentation, we note that our experimental results in general confirm our theoretical proofs and numerical simulation results from the proposed equation system. In addition, we find a very interesting phenomenon, that is, agent-based load balancing mechanism is topology-independent.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>I N order to meet the increasing demand of large-scale scientific computation in the fields of life sciences, biology, physics, and astronomy, the notion of "computational grid" was proposed in mid 1990s <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. It has been observed that computers (such as PCs, workstations, and clusters) in the Internet are often idle. Grid computing aims to integrate idle computational power over the Internet and provide powerful computation capability for users all over the world <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>.</p><p>Since a grid connects numerous geographically distributed computers, and tasks are submitted to grid nodes in a distributed fashion, an important issue is how to evenly distribute submitted tasks to nodes. This is a load balancing problem, one of the scheduling problems on the grid. By solving this problem, we can optimally utilize computational resources of the grid. In this paper, we will propose an agent-based load balancing mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Scheduling on Grids</head><p>The scheduling problem on grids has been widely studied <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Many schedulers for grid computing have been developed <ref type="bibr" target="#b8">[9]</ref>, such as AppLeS <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, Nimrod-G <ref type="bibr" target="#b11">[12]</ref>, GrADs <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, and Condor-G <ref type="bibr" target="#b14">[15]</ref>. The scheduling issues on grids lie in several aspects, among which resource allocation <ref type="bibr" target="#b5">[6]</ref>, i.e., how to allocate computational resources (e.g., CPUhours, storage, and network bandwidth) to submitted tasks, and task allocation <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, i.e., how to allocate tasks to different nodes, attract most attention. In <ref type="bibr" target="#b5">[6]</ref>, Galstyan et al. proposed an agent-based resource allocation model for grid computing. Their model is based on the reinforcement learning technique, and consequently can be adaptive to a dynamically changing grid environment.</p><p>In <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, Casanova et al. have studied the task allocation problem in a grid environment, where the submitted task is arbitrarily divisible. In other words, a task can be divided into arbitrary chunks. Their scheduling mechanism assumed a master/worker architecture, i.e., a master, acting as a scheduler, is responsible for dividing the submitted tasks and allocating the obtained task chunks to different workers. In their work, they paid special attention to task transfer time and network latency. Their algorithm, called uniform multiround (UMR), allocates chunks using multiple rounds so as to overlap communication (i.e., transfer time and network latency) and computation and, consequently, decrease the total time for handling the task, i.e., makespan.</p><p>In Casanova et al.'s work, the main problem lies in the master/worker architecture. Because a grid environment usually involves a large number of nodes and tasks, such a centralized architecture is not feasible <ref type="bibr" target="#b5">[6]</ref>. In the paper, we will provide an agent-based, decentralized task allocation mechanism. Specifically, the paper will focus on load balancing among nodes while allocating tasks rather than makespan. Our mechanism is inspired from real and artificial ants' behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Ant-Based Task Distribution</head><p>In natural environments, a group of ants can collect dispersed objects into piles without any manager. Montresor and Meling have developed an inverse artificial ants system, where artificial ants disperse a group of tasks evenly on idle nodes <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. The detailed behavioral rules of ants are as follows:</p><p>1. SearchMax: an ant wanders across the network, looking for overloaded nodes. 2. SearchMin: an ant wanders across the network, looking for underloaded nodes. 3. Transfer: an ant transfers a task from the most overloaded node to the most underloaded one. In one of their experiments, there are 100 idle nodes on a grid. Initially there are 10,000 tasks on a node. Twenty ants are generated to disperse the tasks. The ants obey the above three rules. After 50 iterations, the tasks are evenly dispersed on the idle nodes, that is, there are 100 tasks on each idle node.</p><p>In the experiments of <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, when a user provides tasks on a node, ants are generated to fulfill the tasks. Ants move from nodes to nodes to distribute the tasks. To obtain more information about nodes, ants indirectly communicate with each other. There is a communication layer in each node. Neighbors of a node are defined as a set of nodes known to that node. In the communication layer, there is a collection of neighbors of that node. A visiting ant may add a new neighbor to the collection if the ant has discovered a new node. A visiting ant may remove an old neighbor if the neighbor is discovered to be unreachable. Therefore, the collection of neighbors for a node is highly dynamic during load balancing. Visiting ants not only make the collection of neighbors dynamic, but also use it to know the network topology (neighbors). This kind of indirect communication is called stigmergy <ref type="bibr" target="#b19">[20]</ref>, which is used by real ants. Based on the detected network topology, ants make decisions such as selecting the best route for accomplishing their tasks. As shown in <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, an ant does not always select the best neighbor as its route, sometimes it selects another route to avoid obstructing as too many ants might select the same route.</p><p>Therefore, an ant's strategies in moving between nodes come from communication layers left by other ants. On the other hand, an ant's strategies also come from its own experience directly since it carries its experience when moving <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. The statistic information from communication layers and its own experience determines an ant's strategies. The strategies change dynamically as the environment is modified by mobile agents. They may be regarded as unchanged during the time period when the change of environment is small. Since ants' strategies in moving between nodes result in the final distributions of load balancing, it is important to establish a relationship between the strategies and the final distributions. In Section 2, we will provide a macroscopic characterization in order to find such a relationship. Furthermore, ants' strategies, which come from statistic information, can be improved to raise the utility gain and the efficiency of load balancing. We will discuss this issue in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Macroscopic Analysis</head><p>Microscopic simulations, as shown in <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, can provide interesting experimental results. However, the results are empirical and cannot directly present the relationship between different factors. On the other hand, macroscopic models can directly describe the dynamic behavior of the system and show how the changes of local factors affect the global dynamics. There is a series of such macroscopic models, such as Web site competition <ref type="bibr" target="#b20">[21]</ref>, coalition formation <ref type="bibr" target="#b21">[22]</ref>, distributed robot collaboration <ref type="bibr" target="#b22">[23]</ref>, cyclic feedback <ref type="bibr" target="#b23">[24]</ref>, infection <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, neural networks <ref type="bibr" target="#b24">[25]</ref>, biological system <ref type="bibr" target="#b26">[27]</ref>, turning patterns <ref type="bibr" target="#b27">[28]</ref>, and chemical reaction-diffusion systems <ref type="bibr" target="#b28">[29]</ref>.</p><p>To give a macroscopic characterization of agent-based load balancing on grids, we should view load balancing from a macroscopic perspective. In the load balancing process of <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, tasks are carried by ants from nodes to nodes. Since what we concern is task distribution on grids, we can assume that we only see tasks' movement between nodes without seeing ants. Therefore, we can regard each task as a mobile ant-like agent. Here, "mobile" means that the agent is active and independent in their decision making. Then, from a macroscopic point of view, the agent-based load balancing becomes a process of agent dispersion. An agent's behaviors in load balancing include: 1) leaving a node where it has queued, 2) wandering on the network, and 3) joining a team in a visited node.</p><p>Quantitatively, the effect of agents' behavior on load balancing is reflected by the number and size of teams on grids. Therefore we can use the quantities to describe the load balancing mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Problem Statements</head><p>As mentioned in Section 1.2, experiments in <ref type="bibr" target="#b17">[18]</ref> show that load balancing through artificial ants converges to a steady state which corresponds to an even distribution. However, results are not the same in other papers. In <ref type="bibr" target="#b29">[30]</ref>, a market mechanism is used to describe an agent-based load balancing. Since agents have incomplete information about nodes, load balancing converges under some conditions, but oscillates and even becomes chaotic under other conditions <ref type="bibr" target="#b29">[30]</ref>. Therefore, the main problems we concern in our work are:</p><p>1. Does load balancing through artificial ants always converge to a steady state? Furthermore, if load balancing converges to a steady state, does the steady state always correspond to an even distribution although agents only have incomplete information about the grid? 2. How to characterize the quality of load balancing? Is load balancing always worth doing? In other words, when load balancing is not worth doing and when high efficiency can be achieved? 3. Can the agents' strategies employed in load balancing be optimized? That is, the optimization of agents' strategies in load balancing should be addressed in order to improve the efficiency.</p><p>In this paper, we will first propose an agent-based load balancing mechanism. Based on our macroscopic characterization and experimental simulations on the mechanism, we study the above problems in depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Organization of the Paper</head><p>The rest of the paper is organized as follows: In Section 2, we describe the homogeneous minigrid environment we will concern and then propose an agent-based load balancing mechanism on grids. In Section 3, the load balancing mechanism is modeled using differential equations and all terms in the equations are explained. The convergence and the perfectness of load balancing are discussed in Section 4. In Section 5, the utility gains and the efficiency of load balancing are discussed. In Section 6, we theoretically show how to optimize agents' strategies. In order to validate our proposed load balancing mechanism, we provide our experimental results on a real computing platform, called Simulation System for Grid Task Distribution (SSGTD) in Section 7. Finally, we conclude our paper and discuss our future work in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">AGENT-BASED LOAD BALANCING</head><p>As we have mentioned, a grid usually involves a large number of nodes and tasks. Particularly, nodes are geographically distributed. Tasks are submitted to different nodes in a decentralized fashion. Generally speaking, grid nodes are not dedicated to a grid environment. Therefore, a grid lacks of a fixed topology. In addition, because of the distributed nature of a grid, it is hard to globally collect accurate status information of nodes <ref type="bibr" target="#b5">[6]</ref>. Given such a situation, a centralized scheduler is not feasible to handling such a complex scheduling problem <ref type="bibr" target="#b5">[6]</ref>. Otherwise, the scheduler will be a bottleneck of the grid. Therefore, we need to provide a scalable and decentralized scheduling mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Minigrid Environments Considered</head><p>Before we present our agent-based load balancing mechanism, we first describe the specific type of grid environments with divisible tasks, which we will consider in this paper.</p><p>1. In our present work, we will focus on load balancing of divisible tasks on grids. Specifically, tasks are divided into independent chunks with the same size before they are submitted to grids. <ref type="foot" target="#foot_0">1</ref> The divisible load/task theory (DLT) has been studied in depth <ref type="bibr" target="#b30">[31]</ref>. In DLT, a load can be arbitrarily partitioned into chunks for a group of processors. There is no precedence relation among the obtained chunks.</p><p>A good example of a divisible load comes from the STAR project, a large international collaboration involving about 400 high energy and nuclear physicists from many countries <ref type="bibr" target="#b31">[32]</ref>. The divisible load in the STAR is to analyze over 250 tera-bytes of raw data. In <ref type="bibr" target="#b31">[32]</ref>, Robertazzi and Yu have discussed how to use the grid computing technology to handle the above mentioned heavy load. In addition, as we have seen, Casanova et al. have discussed the task allocation problem in a grid environment where tasks are also assumed to be divisible and independent <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>  <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. 3. This paper aims at examining whether or not tasks can be distributed to nodes and finally achieve a balanced steady state. Hence, in our work, we assume that the process of load balancing is relative short, during which there is neither new task submitted nor old task finished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Agents</head><p>Multiagent systems have been widely used in distributed problem solving. In our distributed scheduling mechanism, we use agents to carry tasks. Immediately after a task is submitted to a node, an agent will be automatically dispatched to the task. The agent will carry the task to search for appropriate agent teams<ref type="foot" target="#foot_1">2</ref> to queue. In principle, an agent accompanies a task until it is finished on a certain node.</p><p>The goal of an agent is to search suitable nodes for its task, where the agent will obtain a higher utility. Utility may be defined based on different metrics, such as waiting time and service time. Because in our work, nodes are homogeneous and tasks have the same size, we consider the service time for all tasks at any node as being the same. Hence, in the paper, we only consider waiting time. Obviously, here waiting time is only related to the length of the agent team where the agent is queuing. Given such a utility definition, agents prefer to queue at a small agent team so as to achieve a higher utility.</p><p>Utility may also be related to other metrics, such as task transfer time<ref type="foot" target="#foot_2">3</ref> and network latency. In this paper, we assume that as compared to waiting time and service time, task transfer time and network latency may not be significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Load Balancing Mechanism</head><p>The load balancing mechanism we concern is as follows: Initially, a group of tasks is submitted to a minigrid. Then a group of agents, whose number is equal to that of the tasks, are dispatched to these tasks. From now on, agents asynchronously wander on the network of nodes to search for appropriate nodes for their tasks. Then, load balancing becomes the dispersion of agents.</p><p>Consider a system of multiple mobile agents. The agents are dispatched by one or more nodes on a minigrid. Each agent has to obtain a service at a node on the minigrid and each agent's service lasts the same time. Agents have incomplete information about nodes on minigrids. They have to exploit proper nodes and queue for services. To search for small teams, an agent moves among nodes randomly and makes decisions by itself from its own experience and the communication layers it has visited. Because of their goal for obtaining higher utilities, agents will not join a very large team. That is, there is a maximum size for each team. Let m denote the maximum team size, then agents will not join a team whose size is larger than m. Agents probabilistically decide to join the team at a node, or form a new team if there is no other agent. After joining a team, an agent can also probabilistically decide to leave the team and move to other nodes. Therefore, agents' behaviors can be classified into two types: leaving and queuing. The strategies for the two types will determine the global dynamic behavior of the system.</p><p>It should be pointed out that in the paper, without loss of generality, we assume agents properly behave according to their strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL FORMULATION</head><p>In this section, we will provide a macroscopic characterization of the agent-based load balancing mechanism. Our characterization is inspired by the differential equation based modeling work in <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>.</p><p>As described in Section 2, the agent-based load balancing we concern is regarded as agent dispersion. That is, a group of agents wander on the network and search for proper teams to queue. From the macroscopic point of view, the teams of agents on minigrids vary dynamically as agents leave and queue. The number and size of agent teams reflects the performance of the agent-based load balancing mechanism. We use two quantities to macroscopically characterize load balancing: 1) the size, s, of an agent team and 2) the number, n s , of teams whose size is s. It follows from Section 2 that there is a maximum team size. Then, during the period of load balancing, we have 1 s m.</p><p>Initially, agents are created for tasks by nodes. Although a mobile agent will not join a team whose size is larger than m, the maximum team size may be larger than m at the beginning. This case can be explained as follows:</p><p>Suppose that initially the maximum team size is larger than m. It follows from the mechanism in Section 2 that the agents, who are in the pth (p ! m þ 1) position of various teams, will leave the teams. The leaving state is concurrent and asynchronous. Therefore, the leaving process would be completed very rapidly since no decision should be made by the departing agents. The departing agents wander synchronously on networks. Each agent decides by itself whether or not to join the teams it encounters. After all the pth (p ! m þ 1) agents leave their positions and queue in other nodes, the maximum team size in the system will not be larger than m.</p><p>Therefore, we will not concern the case where the maximum team size is larger than m. We will focus on the case where the maximum team size is not larger than m in this paper.</p><p>We use variables n s to represent the load balancing process we concern. At first, we give an example to describe the idea behind our characterization. Consider the change of n 2 , the number of teams of size two. On one hand, consider the increase of n 2 . A team of size three becomes a team of size two after an agent's leaving, then the increase of n 2 is proportional to n 3 , the number of teams of size three. This can be denoted by þl 3 n 3 . Two teams of size one become a team of size two after an agent's queuing, then the increase of n 2 is also proportional to n 1 n 1 . This can be denoted by þj 1 n 2 1 . On the other hand, consider the decrease of n 2 . A team of size two becomes two teams of size one after an agent's leaving, then the decrease of n 2 is proportional to n 2 . This can be denoted by Àl 2 n 2 . A team of size two becomes a team of size three after an agent's queuing, then the decrease of n 2 is also proportional to n 1 n 2 . This can be denoted by Àj 2 n 1 n 2 . Here, j 1 , j 2 , l 2 , and l 3 are proportion values. Therefore, the change rate dn2 dt of n 2 can be expressed as:</p><formula xml:id="formula_0">dn 2 dt ¼ l 3 n 3 þ j 1 n 2 1 À l 2 n 2 À j 2 n 1 n 2 :<label>ð1Þ</label></formula><p>Based on the above idea, we give the following general macroscopic characterization to quantitatively describe the load balancing mechanism we concern:</p><formula xml:id="formula_1">n 0 1 ¼ 2l 2 n 2 À 2j 1 n 2 1 þ X m k¼3 l k n k À n 1 X mÀ1 k¼2 j k n k ; n 0 s ¼ Àl s n s þ j sÀ1 n 1 n sÀ1 À j s n 1 n s þ l sþ1 n sþ1 ; 2 s m À 1; n 0 m ¼ Àl m n m þ j mÀ1 n 1 n mÀ1 ;<label>ð2Þ</label></formula><p>where n 0 1 , n 0 s , and n 0 m describe the quantitative change rate of agent teams of size one, s ð2 s m À 1Þ, and m, respectively; j s and l s are positive coefficients; n s ! 0; 1 s m, <ref type="foot" target="#foot_3">4</ref>and P m s¼1 sn s ð0Þ ¼ S. Here, S is the total number of agents initially.</p><p>It follows from the description in Section 2.1 that there is no net change of agents during the period of load balancing. An interesting verification can be done as follows: According to (2), we have:</p><formula xml:id="formula_2">X m s¼1 sn 0 s ¼ 0; i:e:; X m s¼1 sn s ðtÞ ¼ X m s¼1 sn s ð0Þ ¼ S as t &gt; 0:<label>ð3Þ</label></formula><p>To better understand (2), we give some more detailed descriptions as follows:</p><p>1. Coefficient j s indicates the rate of agents that encounter teams of size s and decide to join those teams. j s is regarded as the strategy of agents' queuing.</p><p>2. Coefficient l s indicates the rate of agents that are queuing at the last position of agent teams of size s and decide to leave now. It is regarded as the strategy of agents' leaving. As mentioned in Section 1.2, strategies j s and l s come from agents' own experience and visited communication layers. They may keep unchanged during the time period when the change of environment is small. Hence, the changes of j s and l s is as follows: During different time periods, they have different constant values. We focus on the case where j s and l s are constants. 3. The second subequation in ( <ref type="formula" target="#formula_1">2</ref>) is a general one, which characterizes the quantitative change rate of teams of size s (2 s m À 1). The rate increases as an agent joins a team of size s À 1, or an agent leaves a team of size s þ 1. The rate decreases as an agent leaves a team of size s, or an agent joins a team of size s.</p><p>. "Àl s n s " denotes that there are l s n s teams of size s, each of which produces one team of size one and one team of size s À 1 after its last agent's leaving. . "þj sÀ1 n 1 n sÀ1 " denotes that j sÀ1 n 1 n sÀ1 teams of size one and j sÀ1 n 1 n sÀ1 teams of size s À 1 produce j sÀ1 n 1 n sÀ1 teams of size s after agents' queuing. . "Àj s n 1 n s " denotes that j s n 1 n s teams of size one and j s n 1 n s teams of size s produce j s n 1 n s teams of size s þ 1 after agents' queuing. . "þl sþ1 n sþ1 " denotes that l sþ1 n sþ1 teams of size s þ 1 produce l sþ1 n sþ1 teams of size one and l sþ1 n sþ1 teams of size s after their last agents' leaving. 4. The first and third subequations in (2) are similar to the second one. For the sake of space limitation, we will not discuss them in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GLOBAL CONVERGENCE oF LOAD BALANCING</head><p>In the experiments of <ref type="bibr" target="#b17">[18]</ref> as shown in Section 1.2, 10,000 tasks are evenly dispersed on 100 idle nodes by ants after 50 iterations. That is, the state of load balancing converges to a steady state which corresponds to perfect balancing.</p><p>Here, perfect balancing is defined as even distribution. It follows from this experimental result that two interesting questions are raised:</p><p>1. Does load balancing always converge to a steady state? Mathematically, the question can be expressed as: whether or not the steady state of (2) is globally stable. 2. Does the final distribution always correspond to perfect balancing? Mathematically, the question can be expressed as: whether or not the steady state of (2) always corresponds to the mathematical form of perfect balancing. In this section, we try to answer these questions through mathematical proofs, numerical simulations, and analysis of strategies. We show that load balancing with different initial distributions will converge to the same distribution finally, which is in agreement with the experiments in <ref type="bibr" target="#b17">[18]</ref>. However, we prove that the final distribution does not always correspond to perfect balancing. An interesting result is given that if agents have complete information about nodes on minigrids, then the steady state corresponds to perfect balancing; otherwise, the steady state does not correspond to perfect balancing. That is, perfect balancing emerges if and only if agents have complete information about nodes on minigrids. This is in agreement with the common knowledge, but is not in agreement with the experiments in <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Uniqueness and Stability</head><p>In this section, we show that load balancing with different initial distributions converges to the same final distribution (steady state). At first, we prove that the steady state of ( <ref type="formula" target="#formula_1">2</ref>) is unique. Then, the steady state is shown to be globally stable by numerical simulations. Finally, we theoretically prove that the steady state is globally stable if the maximum team size is two or three.</p><p>Let n Ã ¼ ðn Ã 1 ; n Ã 2 ; . . . ; n Ã m Þ be an equilibrium (steady state) of <ref type="bibr" target="#b1">(2)</ref>. By definition of equilibrium, the expressions in the right hand side of ( <ref type="formula" target="#formula_1">2</ref>) are zero at n Ã .</p><p>By the third subequation of (2), we have:</p><formula xml:id="formula_3">À l m n Ã m þ j mÀ1 n Ã 1 n Ã mÀ1 ¼ 0; i:e:; n Ã m ¼ j mÀ1 l m n Ã 1 n Ã mÀ1 :<label>ð4Þ</label></formula><p>It follows the subequation for teams of size ðm À 1Þ in (2), we have:</p><formula xml:id="formula_4">À l mÀ1 n Ã mÀ1 þ j mÀ2 n Ã 1 n Ã mÀ2 þ l m n Ã m À j mÀ1 n Ã 1 n Ã mÀ1 ¼ 0; ð5Þ i.e., n Ã mÀ1 ¼ j mÀ2 l mÀ1 n Ã 1 n Ã mÀ2 ;<label>ð6Þ</label></formula><p>by replacing n Ã m with j mÀ1 lm n Ã 1 n Ã mÀ1 . Similarly, we can derive:</p><formula xml:id="formula_5">n Ã s ¼ j sÀ1 l s n Ã 1 n Ã sÀ1 ; 2 s m:<label>ð7Þ</label></formula><p>Inductively, we have:</p><formula xml:id="formula_6">n Ã s ¼ j 1 j 2 . . . j sÀ1 l 2 l 3 . . . l s n Ãs 1 ; 2 s m:<label>ð8Þ</label></formula><p>It can be rewritten as follows: n Ã s ¼ g s n Ãs 1 ; 1 s m, where g 1 ¼ 1, and g s ¼ j 1 j 2 ...j sÀ1 l 2 l 3 ...l s , 2 s m. It follows from P m s¼1 sn Ã s ¼ S that:</p><formula xml:id="formula_7">F ðn Ã 1 Þ ¼ X m s¼1 sg s n Ãs 1 À S ¼ 0:<label>ð9Þ</label></formula><p>Since F ð0Þ &lt; 0, F ðSÞ &gt; 0, and F 0 ðn Ã 1 Þ &gt; 0 as n Ã 1 &gt; 0, according to the continuity of function F , F ðn Ã 1 Þ ¼ 0 has a unique solution in ð0; SÞ. Theorem 1. Equation (2) has a unique equilibrium (steady state).</p><p>According to Theorem 1, if load balancing with different initial distributions converges to steady states, the steady states are the same one and can be expressed as above.</p><p>By numerical simulations in Case Studies 1 and 2, we show that load balancing with different initial distributions converges to the unique steady state. That is, the unique steady state of ( <ref type="formula" target="#formula_1">2</ref>) is shown to be globally stable.</p><p>Case Study 1 (Steady State). Let m ¼ 10, S ¼ 80, j s ¼ l mÀs ¼ 0:1, 0 s 4, j j ¼ l mÀj ¼ 0:001, 6 j 9, j 5 ¼ l 5 ¼ 0:00001. Strategies j s and l s are chosen in order to achieve perfect balancing. The initial load distribution is nð0Þ ¼ ð0; 0; 0; 0; 0; 0; 0; 0; 0; 8Þ, i.e., there are only eight teams of size 10 initially.</p><p>In the result of Case Study 1, Fig. <ref type="figure" target="#fig_1">1a</ref>, we show that the number of teams of each size in load balancing tends to a constant gradually. That is, each component n s ðtÞ of a solution nðtÞ converges to a constant as t ! þ1. In other words, load balancing converges to a steady state. Therefore, the unique steady state of ( <ref type="formula" target="#formula_1">2</ref>) is shown to be globally stable by numerical simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case</head><p>In the following theorem, we theoretically prove that the unique steady state is globally stable if m 3, that is, load balancing converges to the unique steady state in case where the maximum team size is two or three.</p><p>Theorem 2. In case m ¼ 2; 3; the equilibrium of ( <ref type="formula" target="#formula_1">2</ref>) is globally stable.</p><p>Proof. Suppose m ¼ 2, we have</p><formula xml:id="formula_8">n 0 1 ¼ 2l 2 n 2 À 2j 1 n 2 1 ; n 0 2 ¼ Àl 2 n 2 þ j 1 n 2 1 ;<label>ð10Þ</label></formula><p>where</p><formula xml:id="formula_9">n 1 þ 2n 2 ¼ S. Then, n 2 ¼ 1 2 ðS À n 1 Þ</formula><p>, the first equation of ( <ref type="formula" target="#formula_8">10</ref>) is:</p><formula xml:id="formula_10">n 0 1 ¼ Gðn 1 Þ;<label>ð11Þ</label></formula><p>where</p><formula xml:id="formula_11">Gðn 1 Þ ¼ l 2 S À l 2 n 1 À 2j 1 n 2 1 ; 0 n 1 S. Since Gðn 1 Þ 0 &lt; 0 as n 1 &gt; 0,</formula><p>then there is a unique equilibrium of (11) as n 1 &gt; 0. It follows from Gð0Þ &gt; 0; GðSÞ &lt; 0 that the equilibrium is globally stable on ½0; S. That is, the equilibrium of ( <ref type="formula" target="#formula_8">10</ref>) is globally stable.</p><p>A similar proof can be given for m ¼ 3. t u</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Perfectness</head><p>Perfect load balancing in experiments of <ref type="bibr" target="#b17">[18]</ref> is very interesting. However, it is supposed that there are certain idle nodes on grids in the experiments. This is not in agreement with the nature of load balancing on grids. In fact, the network of idle nodes lacks fixed structures. Then, the number of idle nodes is random. Here, we discuss the perfectness of load balancing by the expression of equilibrium of (2). We concern the necessary and sufficient conditions under which there exists perfect balancing.</p><p>Let n Ã 1 be the unique solution of F ðn Ã 1 Þ ¼ 0 in ð0; SÞ. Then, the equilibrium of (2) can be expressed as follows:</p><formula xml:id="formula_12">n Ã ¼ ðg 1 n Ã 1 ; g 2 n Ã2 1 ; g 3 n Ã3 1 ; . . . ; g m n Ãm 1 Þ;<label>ð12Þ</label></formula><p>where</p><formula xml:id="formula_13">g 1 ¼ 1; and g s ¼ j 1 j 2 . . . j sÀ1 l 2 l 3 . . . l s ; 2 s m:<label>ð13Þ</label></formula><p>Perfect balancing corresponds to the form of equilibrium as follows: n Ã ¼ ð0; . . . ; 0; n Ã k ; 0; . . . ; 0Þ; ð14Þ that is, there is k, 1 k m; such that n Ã s ¼ 0 as s 6 ¼ k and n Ã k &gt; 0. Therefore, the equilibrium of (2) does not correspond to perfect balancing generally as j s &gt; 0 and l s &gt; 0.</p><p>When does the equilibrium of (2) correspond to perfect balancing? We return to the definition of equilibrium of (2). Then, we have: The equilibrium of (2) has the form of perfect balancing if and only if there is k, 1 k m such that: 1. j s ¼ 0 as k s m À 1, 2. j s &gt; 0 as 1 s k À 1, 3. l s ¼ 0 as 2 s k, and 4. l s &gt; 0 as k þ 1 s m. The detailed proof can be found in <ref type="bibr" target="#b36">[37]</ref>.</p><p>It follows from the definition of equilibrium that the equilibrium of (2) varies continuously as parameters j s and l s vary. So, the form of perfect balancing can be closely reached if and only if the following conditions are satisfied:</p><p>1. l s is small enough as 2 s k. 2. j s is small enough as k s m À 1. 3. j s remains large enough (relative to the small enough) as 1 s k À 1. 4. l s remains large enough (relative to the small enough)</p><p>as k þ 1 s m. These conditions can be verified in the numerical simulation in Fig. <ref type="figure" target="#fig_1">1a</ref>. From the strategies point of view, these conditions mean that agents have complete information about nodes on minigrids:</p><p>1. It follows from j s (1 s k À 1) is large enough and l s (2 s k) is small enough that: for the teams whose sizes are less than k, agents would like to join the teams and would not leave the teams after joining. 2. It follows from l s (k þ 1 s m) is large enough and j s (k s m À 1) is small enough that: for the teams whose sizes are larger than k, agents would like to leave the teams and would not join these kinds of teams after leaving. Therefore, if the equilibrium has the form of perfect balancing, that is, perfect balancing exists in load balancing, then agents have complete information about nodes on minigrids. On the other hand, it is known that if agents have complete information about nodes on minigrids, the load will be evenly balanced on idle nodes, that is, perfect balancing exists in load balancing. Then, we have: Theorem 3. Perfect balancing exists in load balancing if and only if agents have complete information about nodes on minigrids.</p><p>Generally speaking, agents do not have perfect knowledge about minigrid nodes. Therefore, perfect balancing does not always emerge in load balancing. The perfect load balancing shown in experiments of <ref type="bibr" target="#b17">[18]</ref> exists under the strict conditions we give.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EFFICIENCY OF LOAD BALANCING</head><p>In Section 4, we have shown that load balancing described by (2) converges to a unique steady state. The convergent speed and the final distribution at the steady state present the quality of load balancing. In this section, we will measure the quality of load balancing by analyzing the convergent speed and the distribution at the steady state. The problems we concern are:</p><p>1. Whether or not load balancing is worth doing? 2. How about the utility gains and the efficiency during different balancing periods? It is known that the goal of load balancing is to save time in fulfilling tasks. Since the service time for each agent (task) is assumed the same, we define utility gains of load balancing by waiting time. Let T &gt; 0 be the service time for each agent (task). Let the initial distribution of agents (tasks) be nð0Þ ¼ ðn 1 ð0Þ; n 2 ð0Þ; . . . ; n m ð0ÞÞ. That is, initially the number of teams of size s on minigrids is n s ð0Þ, 1 s m. Let S be the total number of agents (tasks) in the system, then P m s¼1 sn s ð0Þ ¼ S. Suppose there is no load balancing. Consider a team of size m. Then, the first agent in the team need not to wait. The second agent has to wait for time T when the first agent is served. The third agent has to wait for time 2T when the first agent and the second agent are served. Inductively, The mth agent has to wait for time ðm À 1ÞT when the first ðm À 1Þ agents in the team are served. Therefore, the total waiting time of the team is</p><formula xml:id="formula_14">T þ 2T þ 3T þ . . . þ ðm À 1ÞT ¼ X mÀ1 s¼1 sT ¼ 1 2 mðm À 1ÞT<label>ð15Þ</label></formula><p>if there is no load balancing. Since initially the number of teams of size m is n m ð0Þ, then the total waiting time of teams of size m is 1 2 mðm À 1ÞT n m ð0Þ. Inductively, for 1 s m À 1, the total waiting time of teams of size s is 1  2 sðs À 1ÞT n s ð0Þ. Therefore, the total waiting time of the system is 1 2 P m s¼1 sðs À 1ÞT n s ð0Þ if there is no load balancing.</p><p>Suppose there is load balancing under strategies j s and l s , then the distribution tends to steady state n Ã ¼ ðn Ã 1 ; n Ã 2 ; . . . ; n Ã m Þ. The waiting time for n Ã 1 teams of size one is zero. The waiting time for n Ã 2 teams of size two is n Ã 2 T . Inductively, the waiting time for n Ã m teams of size m is 1 2 mðm À 1ÞT n Ã m . Therefore, the total waiting time of the system is 1 2 P m s¼1 sðs À 1ÞT n Ã s after load balancing. Definition 1. The total utility gain E 0 of load balancing is defined as the difference between two waiting times:</p><formula xml:id="formula_15">E 0 ¼ 1 2 X m s¼1 sðs À 1ÞT n s ð0Þ À 1 2 X m s¼1 sðs À 1ÞT n Ã s ¼ 1 2 T X m s¼1 sðs À 1Þðn s ð0Þ À n Ã s Þ;<label>ð16Þ</label></formula><p>where nð0Þ ¼ ðn 1 ð0Þ; n 2 ð0Þ; . . . ; n m ð0ÞÞ is the initial distribution of agents, n Ã ¼ ðn Ã 1 ; n Ã 2 ; . . . ; n Ã m Þ is the final distribution of agents at the steady state.</p><p>When load balancing performs, the distribution nð0Þ is changed into nðtÞ at time t. Then, we have: Definition 2. The utility gain EðnðtÞÞ of load balancing at time t is defined as: </p><formula xml:id="formula_16">EðnðtÞÞ ¼ 1 2 X m s¼1 sðs À 1ÞT n s ð0Þ À 1 2 X m s¼1 sðs À 1ÞT n s ðtÞ ¼ 1 2 T X m s¼1 sðs À 1Þðn s<label>ð0Þ</label></formula><p>where ðtÞ is the fraction of total utility gain that load balancing finishes during time period ½0; t:</p><formula xml:id="formula_18">ðtÞ ¼ EðnðtÞÞ E 0 :<label>ð19Þ</label></formula><p>The definition of efficiency gives the relation between the fraction of utility gains and the consumed time.</p><p>In order to discuss the efficiency clearly, we consider the case where both the attachment rate and the detachment rate are uniform, that is, j s ¼ j, l s ¼ l, 1 s m. Then, (2) can be rewritten as follows:</p><formula xml:id="formula_19">n 0 1 ¼ 2ln 2 À 2jn 2 1 þ l X m k¼3 n k À jn 1 X mÀ1 k¼2 n k ; n 0 s ¼ Àln s þ jn 1 n sÀ1 À jn 1 n s þ ln sþ1 ; 2 s m À 1; n 0 m ¼ Àln m þ jn 1 n mÀ1 :<label>ð20Þ</label></formula><p>Under certain strategy j and l in <ref type="bibr" target="#b19">(20)</ref>, the distribution nðtÞ varies with time t because of load balancing. For different strategy j and l in <ref type="bibr" target="#b19">(20)</ref>, the corresponding steady state n Ã is different. For different strategies j and l and at different time t, both the utility gains and the efficiency of load balancing are different. We show the cases through numerical simulations of <ref type="bibr" target="#b19">(20)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study 3 (Utility Gain and Efficiency</head><formula xml:id="formula_20">). Let m ¼ 6, T ¼ 1,</formula><p>that is, the maximum team size is six and the service time is one unit of time. Consider the initial distribution (condition) nð0Þ ¼ ð0; 0; 0; 0; 0; 100Þ; which means there are 100 teams of size 6 initially. Let l=j ¼ 10 À6 ;10 À4 ;10 À2 ;10 0 , 10 1 ; 10 2 ; t ¼ 1; 10; 100, respectively.</p><p>The simulation result of Case Study 3 is shown in Fig. <ref type="figure" target="#fig_2">2</ref>. In Fig. <ref type="figure" target="#fig_2">2a</ref>, it is shown that as l=j ¼ 10 2 , the utility gain at time t ¼ 10 is equal to that at time t ¼ 100, that is, a little time is enough to reach the maximum utility gain. It is also shown that as l ¼ 10 À6 , the utility gains at time t ¼ 1; 10; 100 are all zero, that is, much time of load balancing has little effect on increasing the utility gain.</p><p>In Fig. <ref type="figure" target="#fig_2">2b</ref>, it is shown that as l=j ¼ 10, the gain fractions at time t ¼ 1; 10; 100 are ð0:01Þ ¼ 8 percent, ð0:1Þ ¼ 30 percent, ð200Þ ¼ 50 percent, that is, high efficiency emerges during the first balancing time. It is also shown that as l=j ¼ 10 À6 , the gain fractions at time t ¼ 1; 10; 100 are close to zero, that is, the efficiency is very low there.</p><p>It follows from the numerical simulation in Fig. <ref type="figure" target="#fig_2">2</ref> that some discussions can be given about the efficiency in load balancing:</p><p>1. As parameter l=j is large, a little time is sufficient for load balancing to reach its maximum utility gain and efficiency, which is shown in both Figs. <ref type="figure" target="#fig_2">2a</ref> and<ref type="figure" target="#fig_2">2b</ref> as l=j ! 10. This is in agreement with the special case where the number of nodes is larger than that of agents (tasks), agents' experiences tell them to disperse without queuing. In fact, let j s ¼ 0, l s &gt; 0, 1 s m. Then, (2) becomes linear differential equations and can be solved. By solutions of the linear (2), a little time is enough for agents' dispersion. Therefore, as parameter l=j is large, high efficiency emerges in the first time period. 2. As parameter l=j is small, much more time is needed for load balancing to reach its steady state, which is shown both in Fig. <ref type="figure" target="#fig_2">2a</ref> as l &lt; 10 À4 . As the time of load balancing increases, the utility gains increase very slowly. On the other hand, the total (final) utility gains are small. Therefore, load balancing is not worth doing in these cases. For example, if there is a little free nodes on the network, load balancing is not worth doing since time is consumed with little gains.</p><p>Here, there is no obvious time period during which high efficiency emerges. 3. As parameter l=j is assigned a medial value, the balance between utility gain and consumed time should be evaluated. Since</p><formula xml:id="formula_21">lim t!þ1 n s ðtÞ ¼ n Ã s ; 1 s m;<label>ð21Þ</label></formula><formula xml:id="formula_22">then dEðnðtÞÞ dt ! 0 as t ! þ1:<label>ð22Þ</label></formula><p>The efficiency ðtÞ becomes very small as time t is large enough. Therefore, if the efficiency ðtÞ is less than a predefined value, load balancing should be stopped; on the other hand, if the gain fraction ðtÞ is greater than a predefined value, load balancing should be stopped.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">OPTIMIZATION OF AGENTS' STRATEGIES</head><p>While wandering on the network, an ant collects information on nodes it has visited <ref type="bibr" target="#b17">[18]</ref>. The information is about the status of other nodes and is left by other ants. According to its own experience and the information from other ants, the ant decides where to go and forms its strategies of leaving and queuing. That is, ants' strategies of leaving and queuing simply come from the statistic information about nodes. Is there any adjustment of strategies to maximize the total utility gains of load balancing? It is known that perfect balancing, where load is evenly balanced, corresponds to the maximum of total utility gains. In this section, we discuss the optimization of strategies in order to maximize total utility gains. It follows from Theorem 1 that the steady state is uniquely determined by agents' strategies of leaving and queuing: different strategies j s and l s result in different distributions at steady states, and the steady states do not always correspond to perfect balancing. In this section, we theoretically give the optimization of strategies from the expression of steady states.</p><p>First, we show our idea about optimization through an example. Second, the abstract discussion is given. Here, we consider the case m ¼ 3, that is, the maximum team size is three.</p><p>Case Study 4 (Nonperfect Load Balancing). Let j 1 ¼ j 2 ¼ 0:001, l 2 ¼ l 3 ¼ 0:1. Initially, there are 200 teams of size three, i.e., nð0Þ ¼ ð0; 0; 200Þ: In other words, there are 600 agents (tasks) to be balanced, S ¼ 600.</p><p>The result in Fig. <ref type="figure" target="#fig_3">3a</ref> shows that under the given strategies, load balancing converges to the steady state n Ã ¼ ð100; 100; 100Þ; where there are 100 teams of size one, 100 teams of size two, and 100 teams of size three, respectively. Then, the load is not perfectly balanced. Now, we revisit the steady state reduced by the given strategies. It follows from the steady state n Ã ¼ ð100; 100; 100Þ that there are 300 idle nodes on minigrids. For the total 600 tasks, the corresponding perfect balancing is ð0; 300; 0Þ. To reach the perfect balancing, agents' strategies j 1 , j 2 , l 2 , and l 3 should be adjusted from the old ones. In fact, it follows from the perfect balancing ð0; 300; 0Þ that there is no teams of size three and there is no teams of size one at the steady state. Therefore, an agent will not join a team of size two to form a team of size three, i.e., j 2 ¼ 0. And, an agent will not leave a team of size two, i.e., l 2 ¼ 0. Then, agents' strategies j 1 , j 2 , l 2 , and l 3 can be optimized as follows:</p><formula xml:id="formula_23">j 2 ¼ l 2 ¼ 0; j 1 &gt; 0; and l 3 &gt; 0:<label>ð23Þ</label></formula><p>Case Study 5 (Perfect Load Balancing). Let m ¼ 3, j 2 ¼ l 2 ¼ 0, j 1 ¼ l 3 ¼ 0:1, nð0Þ ¼ ð0; 0; 200Þ to examine the final steady state.</p><p>The result in Fig. <ref type="figure" target="#fig_3">3b</ref> shows that under the optimized strategies, load balancing converges to a steady state n Ã ¼ ð0; 300; 0Þ; i.e., there are 300 teams of size two and there is no team of size one or three. Perfect balancing emerges in this case.</p><p>We can generalize the optimization of strategies in the example. In fact, the optimization of strategies j s and l s can be obtained from the expression of steady state n Ã . That is, the strategies for perfect balancing can be deduced from current strategies j s and l s . It follows from n Ã that there are l ¼ P m s¼1 n Ã s idle nodes on minigrids. Let k ¼ S l . In order to express our idea more clearly, we assume that k and l are integers. For the case where k and l are not integers, similar discussions can be given.</p><p>Since k and l are integers, there are l idle nodes on minigrids and S agents can be evenly balanced among the l idle nodes with team size k. Therefore perfect load balancing should be:</p><formula xml:id="formula_24">y Ã ¼ ð0; . . . ; 0; y Ã k ; 0; . . . ; 0Þ;<label>ð24Þ</label></formula><p>where y Ã k ¼ l. The perfect load balancing can be reached if strategies j s and l s are properly rearranged:</p><p>1. An agent will not join a team of size s as k s m À 1, that is, j s ¼ 0; k s m À 1. 2. An agent will join a team of size s as 1 s k À 1, that is, j s &gt; 0; 1 s k À 1.</p><p>3. An agent will not leave a team of size s as 2 s k, that is, l s ¼ 0; 2 s k. 4. An agent will leave a team of size Let N Ã ¼ ðN Ã 1 ; N Ã 2 ; . . . ; N Ã m Þ be the new steady state under the new strategies. We give the expression of N Ã by (2). It follows from</p><formula xml:id="formula_25">s as k þ 1 s m, that is, l s &gt; 0; k þ 1 s m.</formula><formula xml:id="formula_26">j s ¼ 0; k s m À 1 that N Ã s ¼ 0; k þ 1 s m: It follows from l s ¼ 0; 2 s k that N Ã s ¼ 0; 1 s k À 1:</formula><p>Therefore, the new steady state determined by the new strategies is N Ã ¼ ð0; . . . ; 0; l; 0; . . . ; 0Þ, which corresponds to perfect load balancing.</p><p>Suppose that strategies j s and l s cannot be determined accurately, that is, there are only estimated ranges for j s and l s . The above discussion is still effective: We can give a range of perfect load balancing y Ã , based on which we can give ranges for new strategies j s and l s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERIMENTAL VALIDATION</head><p>In the previous sections, we have provided a differential equation system for characterizing the agent-based load balancing on minigrids. We have further studied the properties of global convergence and efficiency through theoretical proofs and numerical simulations on the equation system. In order to experimentally validate our system, we have developed a grid computing platform, called Simulation System for Grid Task Distribution (SSGTD), using Java language based on the multithread technique, where each agent is simulated with a thread. On this computing platform, we have implemented the proposed agent-based load balancing mechanism. Through experiments, we have observed that the results in general confirm those found from the numerical simulations. Subsequently, we have validated the effectiveness of our equation system.</p><p>Due to space limitation, in this section, we will show only the results of the experiments, where the settings are similar to those of Case Studies 4 and 5 in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Topology-Independency</head><p>In the following, we will examine the effects of different topologies of minigrids on our agent-based load balancing mechanism.</p><p>As we have seen, ( <ref type="formula" target="#formula_1">2</ref>) does not consider the topology of the minigrid. However, in our experiments on the SSGTD platform, in order to simulate a realistic minigrid environment where agents carry tasks to search for appropriate agent teams, we need to address this important issue. A straightforward question is: Can different topologies affect the performance of the multiagent system as well as the final load balancing result? In order to answer this question, we will investigate three different topologies of minigrids:</p><p>. Fully connected minigrid, where each node is connected to all other nodes. . Lattice-like minigrid, where each node is connected to four neighboring nodes, and all nodes form a lattice-like network. . Scale-free minigrid, where nodes form a scale-free network. It has been proven that the Internet exhibits a scale-free topology <ref type="bibr" target="#b37">[38]</ref>. Since a grid is usually based on the Internet, we believe that a grid more or less has a scale-free topology. Therefore, we use a model in <ref type="bibr" target="#b38">[39]</ref> to generate scale-free networks. In the following experiment, we let the maximum team size m ¼ 3, the initial agent distribution be nð0Þ ¼ ð0; 0; 200Þ, and j 1 ¼ j 2 ¼ 0:001, l 2 ¼ l 3 ¼ 0:1. Note that in the previous sections, j s denotes the ratio of wandering agents that join existing agent teams of size s. In this experiment, j s denotes the probability with which a wandering agent joins an existing agent team of size s when it meets this team. Similarly, l s denotes the probability with which an agent at the last position of an existing team of size s leaves the team.</p><p>In Fig. <ref type="figure" target="#fig_4">4</ref>, we presented our experimental results on a fully connected minigrid and a scale-free minigrid, respectively. Note that due to space limitation, our experimental result on a lattice-like minigrid is omitted, which is similar to those in Fig. <ref type="figure" target="#fig_4">4</ref>. We can note from these figures that for all cases, the final states are not strictly steady. All cases achieve approximately steady states, where the numbers of agent teams of different size oscillate along a certain value. This is because of the probabilistic feature of agents' strategies. Specifically, at each time step, agents probabilistically decide to join teams that they encounter or leave teams where they are queuing. Therefore, as long as not all probabilities j s and l s are zero, at each time step there always exists a few agents joining or leaving existing teams. Although the final states in Fig. <ref type="figure" target="#fig_4">4</ref> are not strictly steady, they are quite close to the steady state shown in Fig. <ref type="figure" target="#fig_3">3a,</ref><ref type="figure" target="#fig_5">5</ref> i.e., n Ã ¼ ð100; 100; 100Þ. That is to say, our experimental results are by and large in agreement with that obtained from our numerical simulation of (2). This validates that our proposed agent-based load balancing characterization system (i.e., ( <ref type="formula" target="#formula_1">2</ref>)) is effective.</p><p>An interesting phenomenon is that as we can see from Table <ref type="table" target="#tab_3">1</ref> and Fig. <ref type="figure" target="#fig_4">4</ref>, for different topologies of the minigrids, the processes of load balancing are similar to each other. In particular, the final approximately steady states are quite close to each other. That means the proposed agent-based load balancing mechanism is insensitive to the topology of the minigrid. It further indicates that no consideration of the minigrid topology in (2) is feasible.</p><p>Remark 1. According to the above observations, we can conclude that:</p><p>1. The topology of the minigrid does not affect the agent-based load balancing mechanism on minigrids, including the process of load balancing and the final approximately steady state. In other words, the proposed mechanism is topologyindependent. 2. Since the proposed load balancing mechanism is insensitive to the topology, the abrupt coming or going of nodes (if there is no agent queuing) will not affect the performance of the load balancing process. In this sense, the proposed load balancing mechanism is fault-tolerant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Approximately Perfect Load Balancing</head><p>In this section, we will examine whether or not the agentbased load balancing mechanism can lead to the perfect load balancing (as discussed in Section 4.2) on the SSGTD platform.</p><p>In the following experiment, we change the probabilities in the previous experiment to j 2 ¼ l 2 ¼ 0; j 1 ¼ l 3 ¼ 0:1. Because of the topology-independency of the proposed mechanism, in this experiment we only use a scale-free network of gird nodes. The result is shown in Fig. <ref type="figure" target="#fig_5">5</ref>.</p><p>From Fig. <ref type="figure" target="#fig_5">5</ref>, we can note that the final approximately steady state is n Ã ¼ ð34; 283; 0Þ, i.e., it is not strictly even balanced as the one shown in Fig. <ref type="figure" target="#fig_3">3b</ref>, but rather approximately even balanced. This is also because of the probabilistic feature of agents' strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, agent-based load balancing on minigrids is regarded as agent dispersion. We have presented a macroscopic characterization of load balancing based on two quantities on minigrids, i.e., the number and size of agent teams. We have shown that load balancing always converges to a steady state, which is in agreement with experiments through artificial ants. As contrary to even distributions in experiments through artificial ants, we have shown an interesting phenomenon, i.e., the steady state does not always correspond to an even distribution. We have theoretically proven that an even distribution emerges if and only if agents have complete knowledge about minigrid nodes. To measure the quality of load balancing, we have defined a utility gain function and have given a series of analysis about the efficiency of load balancing. We have theoretically found that agents' strategies can be optimized to maximize the utility gain of load balancing.</p><p>Finally, we have developed a real platform, called Simulation System for Grid Task Distribution (SSGTD), to validate our proposed agent-based load balancing mechanism. Through experimentation, we have found that the results from our experiments on the SSGTD platform in general confirm those from our theoretical analysis and numerical simulations in <ref type="bibr" target="#b1">(2)</ref>. In addition, we have observed another interesting phenomenon, i.e., the agent-based load balancing mechanism cannot be affected by different topologies of minigrids.   Regarding the future work, the following are three important directions:</p><p>1. Grid environments: In this paper, we have specifically focused on a type of homogeneous minigrid environments. In order to further exploit the functionality of our agent-based load balancing mechanism, in our future work, we will extend the mechanism to more general environments, where nodes may be heterogeneous in terms of their processing speed, memory size, and storage space, and nodes may dynamically come and go. If nodes are heterogeneous, even for the same task, the service time on different nodes may be different. In order to address the load balancing problem in such a grid environment, we need to extend our proposed mechanism to take into account more factors, such as processing speed of nodes. In this paper, we have not considered task transfer time and network latency. In the future work, we will study them both theoretically and experimentally. 2. Task interdependency and granularity: This paper has studied a task distribution environment where tasks are arbitrarily divisible. How to extend our proposed mechanism such that it can work well in the case of more general task environments is an interesting research issue. Some general task environments may have the following characteristics:</p><p>. Tasks may be interdependent rather than independent. . Tasks cannot be divisible. Or, tasks are divisible.</p><p>However, tasks can only be partitioned into chunks of different granularities. . Tasks need coallocation of different computational resources, such as, CPU time and memory. Providing an agent-based task distribution mechanism for the above environments will be a natural extension of this work. 3. Agent behavioral variation: In this paper, we have assumed that agents properly behave according to their strategies. In real world environments, agents perhaps perform without strictly complying their predefined behaviors. For example, because of some unpredictable factors, agents may fail to handle tasks, or agents congest at certain nodes, etc.. In our future work, we need to address the effects of agent behavioral variation on the load balancing mechanism.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Case Study 1 with initial load distribution nð0Þ ¼ ð0; 0; 0; 0; 0; 0; 0; 0; 0; 8Þ. Load balancing converges to steady state n Ã ¼ ð0; 0; 0; 0; 16; 0; 0; 0; 0; 0Þ. (b) Case Study 2 with different initial load distributions. The component n 5 ðtÞ of nðtÞ with different initial values converges to the same value n Ã 5 ¼ 16, which numerically shows the global stability of steady state.</figDesc><graphic coords="6,63.04,69.17,440.40,199.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Case Study 3: For certain strategies l=j ¼ 10 À6 ; 10 À4 ; 10 À2 ; 10 0 ; 10 1 ; 10 2 , utility gains E and gain fraction vary as time increases, where t ¼ 1; 10; 100, respectively.</figDesc><graphic coords="8,292.54,69.17,244.58,216.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Case Study 4, where j 1 ¼ j 2 ¼ 0:001 and l 2 ¼ l 3 ¼ 0:1. The steady state is n Ã ¼ ð100; 100; 100Þ. The load is not even balanced. (b) Case Study 5, where j 2 ¼ l 2 ¼ 0 and j 1 ¼ l 3 ¼ 0:1. The steady state is n Ã ¼ ð0; 300; 0Þ, i.e., the load is absolutely even balanced.</figDesc><graphic coords="9,64.01,69.17,438.46,201.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Let m ¼ 3, j 1 ¼ j 2 ¼ 0:001, l 2 ¼ l 3 ¼ 0:1, nð0Þ¼ð0; 0; 200Þ. (a) Fully connected minigrid. The final approximately steady state is n Ã ¼ ð111; 99; 97Þ. (b) Scale-free minigrid. The final approximately steady state is n Ã ¼ ð109; 92; 102Þ.</figDesc><graphic coords="10,63.04,69.17,440.40,196.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 .</head><label>5</label><figDesc>The ranges of x-axes in Fig.3aand Figs.4a and 4bare different. This is because of their different time scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Let m ¼ 3, j 2 ¼ l 2 ¼ 0, j 1 ¼ l 3 ¼ 0:1, nð0Þ ¼ ð0; 0; 200Þ.The final approximately steady state is n Ã ¼ ð34; 283; 0Þ. The load is approximately even balanced.</figDesc><graphic coords="11,292.54,533.42,244.58,192.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Study 2 (Unique Steady State). Let m ¼ 10, S ¼ 80, j s ¼ l mÀs ¼ 0:1, 0 s 4, j k ¼ l mÀk ¼ 0:001, 6 k 9, j 5 ¼ l 5 ¼ 0:00001. Without loss of generality, we consider the fifth component n 5 ðtÞ. Several initial values nð0Þ are selected randomly with P 10 s¼1 sn s ð0Þ ¼ 80. It follows from the result shown in Fig. 1b that the fifth components of solutions nðtÞ with different initial values nð0Þ converge to the same values n Ã 5 : Other components of solutions nðtÞ with different initial values nð0Þ also converge to the same values but those figures are not shown in this paper. In other words, solutions nðtÞ to (2) with different initial conditions tend to the same steady state as t ! þ1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 1 A</head><label>1</label><figDesc>Comparison of the Final Approximately Steady States in Figs.4a and 4b</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In the latter part of the paper, "task" refers to independent chunks with the same size in terms of processing time.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Here, we refer to the agents queuing at a certain node as an "agent team."</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The time for transferring a task from one node to another one.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>In<ref type="bibr" target="#b36">[37]</ref>, we theoretically prove that during the process of load balancing, n s ðtÞ is guaranteed to be nonnegative.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to express their gratitude to the editors and reviewers for their valuable suggestions. They wish to thank Mr. Hoi Fung Lam for the implementation of the SSGTD platform. We want to acknowledge the support of the following research grants: 1) Hong Kong Research Grant Council (RGC) Central Allocation Grant (HKBU 2/03/C) and Earmarked Research Grants (HKBU 2121/03E)(HKBU 2040/ 02E), 2) Hong Kong Baptist University Faculty Research Grants (FRG), 3) National Grand Fundamental Research 973 Program of China (2003CB317001), and 4) Beijing Municipal Key Laboratory of Multimedia and Intelligent Software Technology (KP0705200379).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Internet Computing And The Emerging Grid</title>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<ptr target="http://www.nature.com/nature/webmatters/Grid/grid.html" />
	</analytic>
	<monogr>
		<title level="j">Nature Web Matters</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Grid Computing: Making the Global Infrastructure a Reality</title>
		<editor>F. Berman, G. Fox, and T. Hey</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">The Grid: Blueprint for a New Computing Infrastructure</title>
		<editor>
			<persName><forename type="first">Morgan</forename><surname>Kaufman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Software Infrastructure for the I-WAY High-Performance Distributed Computing Experiment</title>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nickless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tuecke</surname></persName>
		</author>
		<editor>Berman, G. Fox, and T. Hey</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>John Wiley and Sons</publisher>
			<biblScope unit="page" from="101" to="116" />
		</imprint>
	</monogr>
	<note>Grid Computing: Making the Global Infrastructure a Reality</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Grid Computing: Making the Global Infrastructure a Reality</title>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<editor>F. Berman, G. Fox, and T. Hey</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>John Wiley and Sons</publisher>
			<biblScope unit="page" from="51" to="64" />
		</imprint>
	</monogr>
	<note>The Grid: A New Infrastructure for 21st Century Science</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Resource Allocation in the Grid Using Reinforcement Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Czajkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<ptr target="http://www.isi.edu/lerman/papers/papers.html" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heuristics for Scheduling Parameter Sweep Applications in Grid Environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Legrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zagorodnov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Ninth Heterogeneous Computing Workshop (HCW 2000)</title>
		<meeting>Ninth Heterogeneous Computing Workshop (HCW 2000)</meeting>
		<imprint>
			<date type="published" when="2000-05">May 2000</date>
			<biblScope unit="page" from="349" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Algorithms and Software to Schedule and Deploy Independent Tasks in Grid Environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Distributed Computing, Metacomputing, and Resource Globalization</title>
		<meeting>Workshop Distributed Computing, Metacomputing, and Resource Globalization</meeting>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Survey of a Grid Meta-Scheduler</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<ptr target="http://web.bii.a-star.edu.sg/sebastianh/Scheduler_Survey.pdf" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive Computing on the Grid Using AppLeS</title>
		<author>
			<persName><forename type="first">F</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cirne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Faerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Obertelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Spring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zagorodnov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="369" to="382" />
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Application-Level Scheduling on Distributed Heterogeneous Networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1996 ACM/IEEE Conf. Supercomputing (SC &apos;96)</title>
		<meeting>1996 ACM/IEEE Conf. Supercomputing (SC &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Computational Economy for Grid Computing and Its Implementation in the Nimrod-G Resource Broker</title>
		<author>
			<persName><forename type="first">D</forename><surname>Abramson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Giddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer System</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1061" to="1074" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Decoupled Scheduling Approach for the GrADS Environment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2002 ACM/IEEE Conf. Supercomputing (SC 2002)</title>
		<meeting>2002 ACM/IEEE Conf. Supercomputing (SC 2002)</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Metascheduler for the Grid</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Vadhiyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dongarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Symp. High Performance Distributed Computing (HPDC-11)</title>
		<meeting>11th Symp. High Performance Distributed Computing (HPDC-11)</meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Condor-G: A Computation Management Agent for Multi-Institutional Grids</title>
		<author>
			<persName><forename type="first">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tannenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tuecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th IEEE Symp. High Performance Distributed Computing (HPDC-10)</title>
		<meeting>10th IEEE Symp. High Performance Distributed Computing (HPDC-10)</meeting>
		<imprint>
			<date type="published" when="2001-08">Aug. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Umr: A Multi-Round Algorithm for Scheduling Divisible Workloads</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Casanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int&apos;l Parallel and Distributed Processing Symp. (IPDPS &apos;03)</title>
		<meeting>Int&apos;l Parallel and Distributed essing Symp. (IPDPS &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003-04">Apr. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rumr: Robust Scheduling for Divisible Workloads</title>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th IEEE Symp. High Performance and Distributed Computing (HPDC-12)</title>
		<meeting>12th IEEE Symp. High Performance and Distributed Computing (HPDC-12)</meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Messor: Load-Balancing through a Swarm of Autonomous Agents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Montresor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Babaoglu</surname></persName>
		</author>
		<idno>UBLCS-02-08</idno>
		<imprint>
			<date type="published" when="2002-05">May 2002</date>
			<pubPlace>Bologna, Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Univ. of Bologna</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Anthill: A Framework for the Development of Agent-Based Peer-to-Peer Systems</title>
		<author>
			<persName><forename type="first">O</forename><surname>Babaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montresor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Int&apos;l Conf. Distributed Computing Systems (ICDCS 2002)</title>
		<meeting>22nd Int&apos;l Conf. Distributed Computing Systems (ICDCS 2002)</meeting>
		<imprint>
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><surname>Grasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">La Reconstruction du Nid et Les Coordinations Interindividuelles Chez Bellicositermes Natalensis et Cubitermes Sp</title>
		<imprint>
			<date type="published" when="1959">1959</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="41" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Defining Strategies to Win in the Internet Market</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Sanjuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A</title>
		<imprint>
			<biblScope unit="volume">301</biblScope>
			<biblScope unit="page" from="512" to="534" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coalition Formation for Large-Scale Electronic Markets</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shehory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth Int&apos;l Conf. Multi-Agent Systems (ICMAS 2000)</title>
		<meeting>Fourth Int&apos;l Conf. Multi-Agent Systems (ICMAS 2000)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Macroscopic Analytical Model of Collaboration in Distributed Robotic Systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martinoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ijspeert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="393" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hofbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sigmund</surname></persName>
		</author>
		<title level="m">Evolutionary Games and Replicator Dynamics</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Hoppensteadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pesk</surname></persName>
		</author>
		<title level="m">Mathematics in Medicine and the Life Sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mathematical Analysis of Delay Differential Equation Model of HIV-1 Infection</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Perelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Biosciences</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="73" to="94" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Necessary and Sufficient Conditions for the Existence of Periodic Orbits in a Lotka-Volterra System</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Analysis and Applications</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Chemical Basis of Morphogenesis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Trans. Royal Soc. B</title>
		<imprint>
			<biblScope unit="volume">327</biblScope>
			<biblScope unit="page" from="37" to="72" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sustained Chemical Waves in an Annular Gel Reactor: A Chemical Pinwheel</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Noszticzius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Horsthemke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Swinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="619" to="620" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamics of Large Autonomous Computational Systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Santa Fe Workshop Collective Cognition</title>
		<meeting>Santa Fe Workshop Collective Cognition</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Scheduling Divisible Loads in Parallel and Distributed Systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Robertazzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>IEEE CS Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Divisible Load Scheduling for Grid Computing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Robertazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IASTED Int&apos;l Conf. Parallel and Distributed Computing and Systems (PDCS 2003)</title>
		<meeting>IASTED Int&apos;l Conf. Parallel and Distributed Computing and Systems (PDCS 2003)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Distributed ASCI Supercomputer Project</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Bal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Special Interest Group</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="76" to="96" />
			<date type="published" when="2000-10">Oct. 2000</date>
		</imprint>
	</monogr>
	<note>Operating Systems Rev.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<ptr target="http://www.cs.vu.nl/das/" />
		<title level="m">The Distributed ASCI Supercomputer (DAS)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Computational Mini-Grid Research at Clemson University</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<idno>PARL- 2002-009</idno>
		<imprint>
			<date type="published" when="2002-12">Dec. 2002</date>
		</imprint>
		<respStmt>
			<orgName>Parallel Architecture Research Laboratory, Clemson Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Job Communication Characterization and Its Impact on Meta-Scheduling Co-Allocated Jobs in a Mini-Grid</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ligon</surname></persName>
		</author>
		<idno>PMEO-PDS 2004</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Int&apos;l Workshop Performance Modeling, Evaluation, and Optimization of Parallel and Distributed Systems</title>
		<meeting>Third Int&apos;l Workshop Performance Modeling, Evaluation, and Optimization of Parallel and Distributed Systems</meeting>
		<imprint>
			<date type="published" when="2004-04">Apr. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Characterizing Autonomic Task Distribution and Handling in Grids</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Eng. Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="809" to="823" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Modeling Agent-Based Load Balancing with Time Delays</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2003 IEEE/WIC Int&apos;l Conf. Intelligent Agent Technology (LAT &apos;03)</title>
		<meeting>2003 IEEE/WIC Int&apos;l Conf. Intelligent Agent Technology (LAT &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003-10">Oct. 2003</date>
			<biblScope unit="page" from="189" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Macroscopic Model of Agent Based Load Balancing on Grids</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Second Int&apos;l Joint Conf. Autonomous Agents and Multi-Agent Systems (AAMAS &apos;03)</title>
		<meeting>Second Int&apos;l Joint Conf. Autonomous Agents and Multi-Agent Systems (AAMAS &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Agent-Based Load Balancing on Homogeneous Minigrids: Macroscopic Modeling and Characterization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno>COMP-04-005</idno>
		<imprint>
			<date type="published" when="2004-09">Sept. 2004</date>
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Hong Kong Baptist Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modeling the Internet&apos;s Large-Scale Topology</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Yook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat&apos;l Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="13382" to="13386" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Scale-Free Characteristics of Random Networks: The Topology of the World Wide Web</title>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Barabasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A</title>
		<imprint>
			<biblScope unit="volume">281</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
