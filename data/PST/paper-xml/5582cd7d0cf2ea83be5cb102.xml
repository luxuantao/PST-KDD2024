<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Synthesis Methods for Field Programmable Gate Arrays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">A</forename><forename type="middle">El</forename><surname>Gama1</surname></persName>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Rose</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Depratment of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution" key="instit1">University of Toronto</orgName>
								<orgName type="institution" key="instit2">IO King&apos;s College Road</orgName>
								<address>
									<postCode>M5S 1A4</postCode>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical Engi-neering and Computer Science</orgName>
								<orgName type="institution">University of Califomia</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">IEEE Log Number</orgName>
								<address>
									<postCode>9210743</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Synthesis Methods for Field Programmable Gate Arrays</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA0899FF10A01CA82847D6406D79E10D</idno>
					<note type="submission">received March 23, 1993.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T06:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Field programmable gate arrays (FPGA 's) reduce the turnaround time of application-spec@c integrated circuits from weeks to minutes. However, the high complexity of their architectures makes manual mapping of designs time consuming and error prone thereby offsetting any turnaround advantage. Consequently, effective design automation tools are needed to reduce design time. Among the most important is logic synthesis. While standard synthesis techniques could be used for FPGA's, the quality of the synthesized designs is often unacceptable. As a result, much recent work has been devoted to developing logic synthesis tools targeted to different FPGA architectures. The paper surveys this work. The three most popular types of FPGA architectures are considered, namely those using logic blocks based on lookuptables, multiplexers and wide AND/OR arrays. The emphasis is on tools which attempt to minimize the area of the combinational logic part of a design since little work has been done on optimizing performance or routability, or on synthesis of the sequential part of a design. The different tools surveyed are compared using a suite of benchmark designs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Synthesis tools that automatically map a design composed of simple gates or described with a hardware description language (HDL) into gates from a given library are becoming widely used. Besides simplifying the design process and reducing design time, these tools have had a major impact on the design methodology for applicationspecific integrated circuits (ASIC's), allowing designers to select easily among different implementation options, such as between a standard cell and a mask programmable gate array (MPGA) or among different ASIC vendors, based on accurate estimates of performance and area,.</p><p>The complexity of field programmable gate array (FPGA) architectures makes manual mapping of designs too difficult and time consuming. Indeed the reduction in turnaround time due to the user programmability of an FPGA may be offset by the time spent to map a design manually. As a result much work has been focused recently on developing synthesis tools targeted to different FPGA architectures. Such tools are now yielding good results and becoming commercially viable.</p><p>The most straightforward approach to synthesis for FPGA's is to adapt the synthesis tools developed for MPGA libraries to FPGA's. A design is first mapped into simple gates (such as two input NAND gates), and groups of simple gates are then replaced by logic blocks of the target FPGA. This approach works well for FPGA's with finegrain blocks such as those from Algotronix, Concurrent Logic, Plessey and Toshiba, since a fine-grain block can only implement one or two simple gates. However, for the more widely used FPGA's with coarse-grain logic blocks such as those from Actel, Altera, and Xilinx, this approach does not in general yield acceptable results. A more promising but challenging approach is to map the design directly into logic blocks. Recently developed FPGA synthesis tools employ both the library mapping approach as well as the direct mapping approach.</p><p>In this paper we review the recently developed methods for FPGA synthesis. Even though there is much interest in sequential synthesis for FPGA's, no paper dealing with this topic has been published to date (we are aware of some work that has been submitted for publication <ref type="bibr" target="#b34">[36]</ref>, <ref type="bibr" target="#b50">[51]</ref>). Moreover, most of the developed methods optimize area of a design and only a few optimize performance explicitly. We, therefore, focus our review on combinational synthesis for FPGA's where the registers in the design are explicitly specified by the designer and devote most of the discussion to synthesis methods that optimize area. Since fine-grain FPGA's do not present new challenges to synthesis algorithms we only describe work on synthesis 0018-9219/93$03.00 0 1993 IEEE PROCEEDINGS OF THE IEEE. VOL. 81. <ref type="bibr">NO. 7. JULY 1993</ref> for coarse-grain FPGA's such as those from Actel, Altera, and Xilinx,</p><p>The paper is organized as follows. Basic definitions are given in Section 11. In Section 111 we review the most effective of the known logic minimization and synthesis methods. In Section IV we review several approaches to logic synthesis for FPGA's with "look-up table" logic blocks such as Xilinx's. In Section V we present a similar discussion but for FPGA's with multiplexer-based logic block such as Actel's. In Section VI we briefly discuss synthesis for FPGA's with PLA-based logic blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">BASIC DEFINITIONS</head><p>A logic or Boolean variable x takes on one of two values 0 and 1. Denote by x' the complement of the variable 5 .</p><p>Both x and x' are referred to as literals.</p><p>A Boolean function f : { O , l } n -+ (0, l} is a binary function of logic variables. It is often convenient to represent the n-dimensional Boolean space by an n-dimensional Boolean hypercube. A Boolean hypercube of dimension n contains 2" vertices. The set of vertices of the hypercube where the function takes on the value 1 is referred to as the on-set and the set of vertices where the function takes on the value 0 is referred to as the off-set. At times the value of a logic function is not specified for a set of the vertices. In this case, the function is said to be incompletely spec$ed and the unspecified set of vertices is referred to as the don't-care-set or dc-set. The rest of the vertices (i.e., the on-set and the off-set) constitute the care-set. The set of inputs on which a function is explicitly defined is referred to as its support. In the remainder of the paper we refer to an incompletely specified logic function simply as a logic function unless otherwise stated.</p><p>A cube of a logic function f is a logic function given by the product of literals whose on-set does not have vertices in the off-set of f. The origin of this name rests on the fact that a product of IC literals corresponds to a Boolean hypercube of dimension n -IC in the Boolean space of dimension n. A minterm is a cube where all the variables are assigned a value 0 or 1. This cube is of dimension 0, and contains only one vertex.</p><p>The Shannon cofactor or simply the cofactor of a logic function f with respect to a variable :E, denoted by f x , is the logic function obtained from f by setting the variable z to the constant value 1. The cofactor of f with respect to x', denoted by f,, , is the logic function obtained by setting the variable x in f to the constant value 0.</p><p>A logic function has several representations, e.g., the set of its minterms (which is equivalent to the truth table representation), the sum-ofproduct form, the factored form and the Binary Decision Diagram.</p><p>A sum-of-product expression for f is a set of cubes that contains all the vertices of the on-set of ,f and none of the off-set.</p><p>A factored form is defined recursively as follows: a literal is a factored form; the sum of factored forms is a factored form; the product of factored forms is a factored form Thus for example, a+b, (a+b)(c+(e'( f +g'))), where e', g' denote the complement of the variables e,g, are factored forms.</p><p>An important characteristic of factored forms is that they may be thought of as representing both a function and its complement, since, by De Morgan's laws, the factored form of the complement of a function can be simply obtained from the factored form of the function by interchanging the logic addition and the logic product operations as well as the phases of the variables. Note that in contrast the sumof-products form of the complement of a function can be drastically different from the sum-of-product form of the function.</p><p>A binary decision diagram (BDD) is a simple yet efficient representation of a completely specified logic function. BDD's were proposed many years ago by Akers but their use in logic manipulations has only recently been made practical and effective by <ref type="bibr">Bryant [lo]</ref>. A BDD is a directed acyclic graph (DAG) where a logic function is associated with each node. The completely specified logic function f represented by the BDD is associated with the root node. Every node has two fan-out nodes representing the function obtained by cofactoring the logic function represented at the node with respect to a variable and its complement. This variable indexes the node. Let x be the variable indexing node i and f i the function associated with this node. The high-node corresponds to the cofactor f i x , and the low-node corresponds to f;,,. The leaf nodes are the constant functions 0 and 1. Note that this representation has an exponential number of nodes and is canonical in the sense that given a logic function and an ordering of the variables corresponding to the sequence of cofactoring operations along a path from the root to the leaf nodes, the representation is unique. In fact this representation is equivalent to the truth table representation of the function. As such it is not too interesting. However, if the nodes associated with the same logic function are merged, the complexity of the representation can be reduced. The resulting BDD is referred to as reduced BDD or RBDD. The number of nodes in an RBDD can be dramatically lower than for the unreduced BDD. This fact makes RBDD's quite appealing for a number of applications. A further useful simplification of RBDD's, proposed by Bryant, is to choose the ordering of the variable for all paths from the root to the leaf nodes to be the same. This representation is referred to as the reduced ordered BDD (ROBDD) and is canonical. Figure <ref type="figure">1 (a)</ref> shows an ordered BDD for the function f = ac + a'bd + bc'd' with the order c, a , d and b.</p><p>The root node is indexed by c. Now, we reduce it by seeing that all nodes indexed by b represent the same function, namely b. We merge them all in one node, and get an ROBDD in Fig. <ref type="figure">l(b)</ref>.</p><p>Many operations on this representation are linear in the size of the graph. In addition, verifying whether two logic functions are logically equivalent, amounts to an easy isomorphism check on their ROBDD's, which can be carried out efficiently. Although most functions have an ROBDD representation that is still exponential in the number of variables, many functions appearing in practice have a low complexity ROBDD representation. The complexity of an ROBDD representation is, however, dependent on variable ordering and finding a good ordering is in general not tractable.</p><p>The if-then-else DAG representation is a close relative of the BDD. The if-then-else DAG is a set of nodes each with three children: each node is a two-to-one selector where the first child is connected to the control input of the selector and the second and third children are connected to the signal inputs of the selector. The behavior function of the node is that if the expression that corresponds to the control input is TRUE then the second child is selected else the third child is selected. In the case of the BDD, the nodes can be regarded as two-to-one selectors as well but with the control input connected directly to the variable associated with the node. Thus an if-then-else DAG is more general than a BDD and consequently can yield more compact representations.</p><p>An advantage of the if-then-else DAG over BDD's appears when converting from a sum-of-products form. Select one variable, say q . Let the cubes of the function associated with a node of the Boolean network be partitioned into three sets C1, C2, C, with respect to q : C1 corresponding to the cubes that do not depend on the selected variable V I , C, containing all the cubes that depend on V I , and Cs containing all the cubes that depend on v i , the complement of V I . The corresponding if-then-else DAG implements if C1 then TRUE, else (if111 then C2 else C,) and contains two nodes as shown in Fig. <ref type="figure" target="#fig_13">2</ref>. The first node has the function determined by the cubes in C1 connected to its control input, the constant TRUE connected to its second child, and the output of the second node connected to its third child. The second node has its control input connected to the variable 711, its second child to the cubes in C2 and its third child to the cubes in Cs. Note that this may be a smaller representation than the BDD for the same function since the expressions connected to the high and low children of the BDD node contain duplicate cubes (the ones that are in Cl). In the if-then-else DAG these cubes appear only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="111.">LOGIC SYNTHESIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Introduction</head><p>There are several approaches to logic optimization <ref type="bibr" target="#b8">[9]</ref>.</p><p>The most commonly used approach is to break the synthesis process into two phases: a technology independent phase, followed by a technology mapping phase. The technology independent phase attempts to generate an optimal abstract representation of the logic circuit. The technology mapping phase selects a set of gates from a library' to implement the abstract representation while optimizing area, delay or a combination of the two.</p><p>For combinational logic, the abstract representation chosen in MIS [SI and in many other university and industrial tools, is the Boolean network, a directed acyclic graph G(V, E ) where each of the nodes U E V represents an arbitrarily complex single-output logic function. There is an arc from node j to node i if the function represented by node i depends explicitly on the function represented by j .</p><p>Node j is said to be a fan-in of node i and node i is said to be a fan-out of node j . There are two sets of special nodes: input nodes with no incoming arcs which represent primary inputs, and output nodes with no outgoing arcs which represent primary outputs. An example of a Boolean network is shown in Fig. <ref type="figure" target="#fig_1">3</ref>. The network has four primary inputs a, b, c and d, and one primary output z .</p><p>Each node of the network may represent an arbitrary logic function (general node) or a simple logic function such as a two-input NAND or NOR (generic node). The support of a node is the set of variables that the corresponding logic function explicitly depends on. During optimization, the nodes of the network may be mapped from a general form to a generic form as will be seen later. A general node can be represented in a sum-of-products form, a factored form, or as a BDD.</p><p>Node representation may change from one form to another according to the operations performed. The sum-of-' A library can be given either explicitly as a list of gates, or implicitly with equations or other means of representing a class of logic functions.  products form is convenient in node minimization where a two-level logic minimizer (e.g., Espresso <ref type="bibr" target="#b6">[7]</ref>) is used. The factored form representation is useful since it corresponds to a possible implementation of the function in dynamic CMOS logic where each literal corresponds to a transistor <ref type="bibr" target="#b5">[6]</ref>. Moreover, when static CMOS logic is used there is a correspondence between the number of literals in an optimized factored form and the area occupied by its physical implementation. As a result the total number of literals in an optimized factored form is the most commonly used cost function in logic minimization.</p><p>The problem of finding an optimum factored form for a given logic function is, however, very complex and exact algorithms are not practical for functions of more than six variables. Heuristics are, therefore, used to compute an optimized factored form. Moreover, minimizing the number of literals does not explicitly consider wiring area which is particularly important for FPGA synthesis. This represents a major challenge in adapting existing and well-proven synthesis approaches to FPGA's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Technology Independent Optimization</head><p>The operations performed in the technology independent phase are classified into two classes: network restructuring operations and node minimization. The former includes operations that modify the structure of the Boolean network by introducing new nodes, eliminating others, and by adding and removing arcs, while the latter includes operations that simplify the logic equations associated with nodes <ref type="bibr" target="#b8">[9]</ref>.</p><p>1 ) Restructuring Operations: Network restructuring operations include decomposition, extraction, factoring, resubstitution, and collapsing.</p><p>Decomposition is the process of expressing a given logic function in terms of a number of new functions. For example, let</p><formula xml:id="formula_0">F = ubce f + abde f + n'c'd' + b'c'd' : (1) then a decomposition of F is F = X Y e f + X'Y' :<label>( 2 )</label></formula><p>where X = ab and Y = c + d.</p><p>Note that while the expression representing F before decomposition depends explicitly on six variables, the one after decomposition depends explicitly on four variables only. Decomposition is an essential step in logic optimization for FPGA's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I060</head><p>Extraction is related to decomposition but operates on a number of given functions. With extraction, the given functions are expressed in terms of newly created intermediate functions and variables. For example, extraction when applied to the following functions</p><formula xml:id="formula_1">F = (u'b + nb')cd G = (a'b' + ab) + e + f (3)<label>(4)</label></formula><p>gives</p><formula xml:id="formula_2">F = X c d ( 5 ) G = X ' + e + f (6) X = a'b + ab'<label>(7)</label></formula><p>Common subexpressions are identified and extracted in order to minimize the total number of literals by sharing expressions among logic functions. However, the number of arcs in the resulting Boolean network increases which may increase wiring area.</p><p>Factoring transforms the sum-of-products form of a logic function into a factored form. For example, F of Eq. (1) can be factored as abPf(c+d)+(ab)'(c+d)'. Substitution or resubstitution is the process of expressing a given logic function F in terms of another given function G. For example, let G = abc then</p><formula xml:id="formula_3">F = Gef + abdef + (G + nbd)'.</formula><p>Collapsing, also called elimination or jnttening, is the inverse operation of substitution. If G is a fan-in node of F , collapsing "pushes" G into F so that F is expressed only in terms of its fan-in nodes which also include the fan-in nodes of G.</p><p>All these operations make use of operations analogous to conventional multiplication and division. In fact, decomposition, extraction and factoring depend on finding subexpressions which are "divisors" or "factors" of the representation of the function. The number of divisors and factors of a given Boolean expression, however, can be so large that it is practically impossible to search the space to find one which is optimum with respect to the cost function used in the logic synthesis. As a result in most logic synthesis systems divisors and factors are selected from a restricted space so that the search is much faster and the quality of the result is acceptable.</p><p>2) Algebraic Operations: The restricted space is the space of algebraic expressions. An algebraic expression is a set of cubes such that no cube contains another, i.e., no cube contains all of the vertices of any other cube. A Boolean product o f m o cubes is the product of the literals of the cubes if no literal appears complemented in one cube and uncomplemented in the other and is zero otherwise. The product of two expressions is the set of products of the cubes of the two expressions. A product of two expressions is an algebraic product if they are algebraic expressions and if the two expressions have no input variables in common. The basic task in decomposition, extraction, factoring and resubstitution is the operation of division: given two functions FandP, find Q and R such PROCEEDINGS OF THE IEEE, VOL. X I . NO. <ref type="bibr">7. JULY 1993</ref> that</p><formula xml:id="formula_4">F = P Q + R. The division is algebraic if PQ is an algebraic product.</formula><p>Algebraic division can be carried out very quickly. An algorithm exists which can compute the operation in linear time in the number of cubes in the expressions. To perform an effective restructuring of the network with decomposition, factoring and extraction, it remains to find an effective procedure to determine good algebraic divisors, i.e., given F , we wish to find P so that P, Q and R can be expressed with the smallest number of literals. Since the number of divisors is very large, the optimization problem looks hopelessly complex. Kernels, introduced by <ref type="bibr">Brayton and</ref> McMullen, are a subset of all algebraic divisors of an expression that can be computed effectively with a number of fast algorithms. It can be proven that optimum algebraic divisors and common factors must be kernels and/or kernel intersections. In MIS there are a number of kerneling operations with different speed-quality trade-offs.</p><p>Thus the restructuring operations can be performed quickly and the space searched effectively, but at the expense of the optimality of the solution. Boolean operations such as node minimization can be interspersed with algebraic operations in an attempt to find a better solution.</p><p>3 ) Node Minimization: Node minimization attempts to reduce the complexity of a given network by using Boolean minimization techniques on its nodes. The nodes of the network are Boolean functions that can be minimized using two-level techniques such as the ones used in Espresso. However, considering the functions at the nodes as independent, much optimization is potentially lost. In fact, the inputs of the Boolean functions are related to each other by the nodes of the network that precede the node under consideration and hence are not free to take any combination of values. In addition, for some values of the primary inputs of the network, the output of the node may not be observable at the primary outputs of the network. In both cases the values of the inputs that can never occur at the input of the function and the values of the primary inputs for which the outputs of the nodes are not observable at the primary outputs of the network are don 't cares for the two-level minimization of the node. The first kind of don't cares is called Satisjability Don't Care (SDC) set, while the second is called Observability Don't Care (ODC) set.</p><p>An Unfortunately the SDC's and the ODC's may be very large and it may be impossible to compute them. Hence node minimization in <ref type="bibr" target="#b7">[8]</ref> optimizes the two-level representation of a node using a suitably chosen subset of SDC's and ODC's when they are too big.</p><p>Another method for node minimization, <ref type="bibr" target="#b3">[4]</ref> does not use two-level minimization techniques with don't cares, but rather it simplifies the node function using a tautology checker. Tautology checking determines whether a function is identically equal to 1. It can also be used to determine if two Boolean networks are equivalent by taking the corresponding primary outputs and forming their exclusive NOR. If the two Boolean networks are equivalent, the output of the exclusive NOR will be always 1. In <ref type="bibr" target="#b3">[4]</ref>, a node is tentatively simplified by deleting either literals or cubes from the node representation. The resulting network is checked for equivalence against the original network. If equivalent, the deletion is performed and a simpler representation is obtained. The problem with this method is CPU time since many equivalence checkings need to be performed. On the other hand the previous approach suffers from problems stemming from the size of the SDC and ODC. In most available logic optimization programs, the first minimization technique is adopted using an approximation to the SDC and ODC.</p><p>Node minimization has been proven to be very effective for a wide variety of cases. Node minimization is very often the only Boolean operation that is performed during a network optimization run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Technology Mapping</head><p>After optimizing the network, the technology mapping phase begins. Here the optimized Boolean network is mapped into a network whose nodes are primitive logic functions implemented by the available library gates. In this phase the cost function can be more accurate since the area of the primitive gates is known exactly. However, wiring area is not used as part of the cost function in most of the synthesis systems in use today, even though approaches have been proposed that take wiring into account [l], <ref type="bibr" target="#b38">[40]</ref>,</p><p>The algorithms that are used in technology mapping fall 1. algorithmic approaches (e.g., <ref type="bibr">[29]</ref>, <ref type="bibr" target="#b7">[8]</ref>, [311); 2. rule-based techniques (e.g., 1131, 1241).</p><p>In the first approach, the Boolean network is mapped into a subject graph which is a network consisting of two-input NAND gates. All the gates in the library are also expressed as networks (called pattern graphs) in terms of two-input NAND gates, thus yielding a consistent representation between the network and the gates in the library. The problem is now transformed into a covering problem: find the minimum cost cover of the subject graph by the pattern graphs. Since both the subject graph and the pattern graphs are directed acyclic graphs (DAG's), the problem is called DAG covering by DAG's. Unfortunately the problem is NPhard, and since there is no exact algorithm that yields practical results even for relatively small networks <ref type="bibr" target="#b43">[44]</ref>, heuristics are used.</p><p>The first heuristic to be proposed [29] was inspired by the work on optimizing compilers by Aho et al. <ref type="bibr" target="#b1">[2]</ref>. This heuristic is optimal if the network to be mapped is a tree and the library gates are represented by trees. However, in ~411.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>into two main categories:</head><p>EL GAMAL er ul.: SYNTHESIS METHODS FOR GATE ARRAYS general, the optimized Boolean network is not a tree. For this reason, the network is decomposed into trees. Since most of the gates in widely available commercial libraries can be expressed in terms of trees of two-input NAND gates the mapping problem is transformed into a tree-coveringby-trees problem which is easily solved by covering each of the trees separately. This is an efficient heuristic since it is based on proven optimality properties, the running time of the procedure is linear in the size of the trees, and the quality of the results are quite good.</p><p>An alternative approach was proposed in <ref type="bibr" target="#b29">[31]</ref>. The twoinput NAND-gate network is decomposed into subnetworks that are not necessarily trees; the only requirement in common with tree decomposition is that the connection to the rest of the circuit or to a primary output be a node of fanout one (the sink node). A dynamic programming approach is used to find the optimum matching of the subnetworks in terms of a given set of primitives (library gates). In this approach, Boolean operations are used to find whether a subnetwork is logically equivalent to one of the library functions (Boolean matching). First, a set of cluster functions is defined as the set of functions that correspond to connected subgraphs of the subnetwork rooted in the sink node. The leaves of these DAG'S are the support variables of the cluster functions. The multilevel structure of the subgraphs is flattened obtaining a two-level representation of the cluster function. The cluster function is then checked against all the library gates to identify those gates that are logically equivalent on the care set of the cluster function. This is done by solving a tautology problem, i.e., the exclusive NOR of the cluster function and of the library gate is taken and checked to determine whether the output of the exclusive NOR is identically equal to one on the care set of the cluster function. The minimum cost match is selected and the procedure is repeated for all the functions which are rooted in the nodes that define the support variables for the cluster function. This defines the basic step for the dynamic programming procedure.</p><p>Among the advantages that can be claimed for this approach, we identify: the decomposition of the subject graph is not restricted to be a forest of trees; don't cares can be naturally incorporated to obtain matches that could not have been obtained with a purely structural approach such as the tree-coveringby-trees approach. These advantages did not offer substantial improvements over the tree-covering approach when applied to standard libraries on a set of benchmarks. However, as we shall see in Section V-C5), better results were achieved for libraries containing XOR's, multiplexers and majority functions that are notoriously difficult to handle with the tree approach.</p><p>A drawback of this approach is the high computational requirement; each match attempt requires the solution of a tautology problem. In <ref type="bibr">[18]</ref> and <ref type="bibr" target="#b46">[47]</ref> clever methods have been proposed to minimize the number of tautology operations performed.</p><p>In both approaches, the original DAG has to be mapped into a network of two-input NAND gates. Note that there is potentially a very large number of possible mappings of the original network in terms of two-input NAND gates. Simple heuristics are used to preserve as much of the structure obtained during the technology independent optimization step as possible, while using a small number of NAND gates. The library gates can also have different representations in terms of two-input NAND gates. However, the number of possible two-input NAND gate representations is rather small in most cases. In the tree-covering-by-trees approach, all possible representations of a given gate in terms of twoinput NAND gates are enumerated, thus providing a larger number of matches between the covering trees and the tree to be covered. One limitation of this approach is that it can only be applied to single-output cells. No work has so far been done to address mapping for cells with multiple outputs.</p><p>Rule-based techniques traverse the Boolean network and replace subnetworks with patterns representing the gates in the library that match the function of the subnetwork. Rule-based techniques are slower but could yield better final results since detailed information about the gates in the libraries can be captured, and electrical considerations can be taken into account easily.</p><p>The present trend in industry is to use a mixed approach, where a tree covering approach is followed by a rule-based clean-up phase.</p><p>Timing optimization is carried out using the same approaches but with more difficulty. In the technology independent optimization phase some simple timing model of the network based on the number of levels and the degree of each node can be used to restructure the network to minimize the critical path <ref type="bibr" target="#b48">[49]</ref>. In the technology mapping phase, gate delays are known with good approximation and the mapping can be guided to yield a fast implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SYNTHESIS FOR LUT-BASED FPGAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Zntroduction</head><p>LUT-based logic blocks such as the Xilinx configurable logic block (CLB) can implement any logic function of no more than a fixed number of variables. Additional functions can also be implemented depending on the details of the block. For example, the LUT section of the Xilinx series 3000 architecture (Fig. <ref type="figure" target="#fig_3">4</ref>) can implement any logic function F with up to five inputs a ; b , c , d , e , or any two logic functions F and G with up to four inputs each and five overall variables. In addition, each block has two embedded flip-flops with outputs Q X and &amp;Y for use in sequential design. <ref type="bibr" target="#b1">2</ref> All existing approaches to synthesis for LUT-based FPGA's begin with a network that has been optimized using a technology independent method and, hence, could be 'If the internal flip-flops and the feedback paths from them are considered, the Xilinx 3000 architecture allows up to a total of seven different inputs to the two look-up tables. This section is organized as follows. The most straightforward adaptation of technology mapping approaches to LUT FPGA's is reviewed first. Special algorithms are then presented which take into account practical LUT-based FPGA architectures. Although most approaches published to date deal with area minimization, new techniques which optimize performance are surfacing. These new techniques are reviewed in the last sub-section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Library-Based Technology Mapping</head><p>In the tree-covering-by-trees approach to technology mapping, the gates in the library have to be expressed as trees.</p><p>To use this approach an LUT is viewed as a collection of gates. For example in MIS, all the nonequivalent funct i o n ~~ are explicitly described in terms of two-input NAND gates. While the nonequivalent gates are fewer than all the possible gates, their number still grows superexponentially.</p><p>For k = 2 , 3 the number of nonequivalent functions is reasonable (10 and 78 respectively), but already for k = 4 the number of nonequivalent functions is 9014 <ref type="bibr" target="#b18">[19]</ref>. In addition some of these functions have a large number of possible two-input NAND gate representations (some have more than 700) and MIS cannot handle the resulting complexity in the library. Thus the* number of logic gates represented by the covering trees is restricted. In [ 191, only a relatively small subset of the functions was included in the library. The subset was selected based on the observation of the behavior of the algorithm for k = 3 and the knowledge of the inner operations of MIS. Note that the cost of mapping into any of these functions is constant since all of them can be implemented by a single LUT.</p><p>Even after restricting the set of gates to be included, the time needed to perform the mapping is long and is dominated by the time needed to parse and process the library. In <ref type="bibr" target="#b18">[19]</ref> it was observed that as IC increases, the quality of results deteriorates (not surprisingly since the number of basic functions eliminated from considerations grows quickly). Thus this approach seems inadequate.</p><p>'An LUT with X, inputs can implement 2 2 b functions. A function f is equivalent to another g if it can be obtained from 9 by renaming inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Direct Approaches</head><p>Direct approaches deal with the functionality of the logic block directly and do not require the explicit construction of a library of gates.</p><p>Two direct approaches have been considered: Modification of the tree-covering-by-trees algorithm for technology mapping to significantly reduce the .CPU time required by the standard technology mapping algorithms <ref type="bibr">[19, 201;</ref> A two-step approach where:</p><p>-Starting with a technology-independent-optimized network, the nodes of the network are decomposed so that each depends on no more than k variables. The decomposition operation yields a network that is feasible since each node can now be implemented directly using a single LUT.</p><p>The number of nodes is reduced by combining some of them taking into account the particular features of the LUT's <ref type="bibr" target="#b35">[37]</ref>, [181, [281, [381, -1501. <ref type="bibr" target="#b19">[20]</ref> use the first direct approach to the technology mapping problem for LUT's. Chortle begins with an AND/OR representation of the optimized Boolean network. This representation is obtained in a straightforward way from the sum-of-products representation of MIS by representing each product and each sum as a separate node. Inversions are represented by labels on the edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Modifying the Tree-Covering Approach:Chortle [ 191 and its extension Chortle-ctf</head><p>The network is first decomposed into a forest of trees by clipping the multiple-fan-out nodes. An optimal mapping of each tree into LUT's is then performed using dynamic programming, and the resulting implementations are assembled together according to the interconnection patterns of the forest. These steps are essentially the same as the standard technology mapping algorithm implemented in DAGON and MIS. The main difference is in the way the optimal mapping is done. Note that in the case of LUT's it is not the structure of the logic function that matters in the matching but only the number of variables that the function depends on: given a tree, every subtree that has at most k leaf nodes can be implemented by a single LUT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chortle and Dynamic Programming for LUT's:</head><p>The dynamic programming approach to technology mapping is as follows. The minimum cost implementation of a tree rooted at node i is obtained as the implementation of the subtree Ti rooted at i combined with the minimum cost implementation of the subtrees rooted at the leaf nodes of Ti which yields the minimum overall cost among all such implementations. Thus the optimum technology mapping problem for a tree can be solved recursively starting at its leaf nodes and working towards its root.</p><p>In the case of LUT's, when the mapping extends towards the root of the tree, all subtrees rooted at a node that have a number of leaf nodes less than or equal to IC must be considered to make sure that all applicable solutions are searched. Note that all these subtrees have the same cost of 1.</p><p>In line with the technology mapping algorithms of DAGON and MIS, Chortle's approach guarantees that an optimum solution is found for every tree but cannot guarantee that the technology mapping for the entire network is optimum.</p><p>When i has degree significantly larger than k , the number of subtrees to examine is very large. Since all possible combinations of nodes connected to i of cardinality less than or equal to k must be considered to guarantee an optimal solution, Chortle would spend an inordinate amount of time searching the space of sub tree^.^ To avoid the explosion of CPU time, Chortle predecomposes the nodes of the network that have degree larger than a limit 1,l &gt; k . This is done by splitting the nodes into two nodes with nearly the same degree. By doing this the optimality of the solution is not guaranteed any longer but according to [ 191 the quality of the final solution is hardly affected.</p><p>Several factors limit the quality of the solution, however: the search for a mapping is artificially limited to the tree boundaries; possible duplication of nodes in the network is not considered; some of the special features of the LUT-based FPGA's are not considered, e.g.. the fact that two functions can be mapped onto the same LUT in the Xilinx array.</p><p>Chortle-crfand Bin-Packing: Chortle-crf <ref type="bibr" target="#b19">[20]</ref> extends Chortle by considering node duplication and reconvergent fan-outs. In addition, a key contribution of this work is recogn'izing that the decomposition problem for an LUTbased FPGA could be approximated as a simple variant of the bin-packing problem <ref type="bibr" target="#b22">[23]</ref>. The bin-packing problem is to pack a set of objects of given sizes into the minimum number of bins of fixed capacity. The bin-packing problem is NP-hard but simple and very fast heuristics have been used effectively for its solution <ref type="bibr" target="#b22">[23]</ref>. Furthermore, these heuristics can be guaranteed to find the optimum solution in some special cases, and are in any case within 22% of the optimum.</p><p>Bin-packing heuristics are used in Chortle when the best solution to the mapping problem is sought for a node in a tree during dynamic programming. A two-level representation of a logic function f is considered in this case. The cubes are the set of objects to be packed. The size of an object is given by the number of variables that appear in the corresponding cube. Any set of cubes whose overall size is less than or equal to k is packed into an LUT. In case a cube contains more than k variables, it is considered as a combination of two or more cubes each of which has less than k variables. Note that an LUT implements the OR of the cubes packed into it. Finding the minimum number of bins which contain all the cubes is equivalent to solving the 4This is equivalent to considering all poss,ible decompositions of node i so that the resulting decomposition is implementable by an LUT. bin-packing problem, but does not yield a solution to the decomposition problem. For example, given the function F = abcd + e f g + ha if we pack abcd into one LUT, and the remaining cubes into another, we would still have to build the OR of the two subfunctions ubcd and e f g + hi to implement the original function resulting in a three LUT implementation. If instead we replace e f g + h i with a single literal cube z and we pack z together with abcd, we obtain the following decomposition of F :</p><formula xml:id="formula_5">F = abcd + z ; z = e f g + hi</formula><p>The function can now be implemented using only two LUT's; one LUT implementing z = e f g + hi feeding into a second LUT implementing F = z + abcd.</p><p>Chortle uses the first fit decreasing algorithm to solve the resulting bin-packing problem. The algorithm selects the largest object, i.e., the cube with the largest number of variables, and finds the first bin (LUT) where it fits. If no existing bin (LUT) has enough capacity a new bin is created and the cube is placed there (recall that this can always be done, since all cubes have a number of variables that is at most IC). When all the cubes have been placed in an LUT, the LUT with the fewest unused inputs is selected and closed. A new variable is created and the corresponding one-variable cube is placed in the first LUT where it can be accommodated. If none is found a new one is created. The procedure is repeated until only one LUT remains open. This last LUT is closed but no new variable is created. This last LUT is the one that provides the output corresponding to the original function.</p><p>This algorithm has a remarkable property. It can be proved that if the cubes of the given function are disjoint, i.e., they have disjoint support, then the algorithm generates a tree of LUT's of minimum size that implements the given function for k 5 6 <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b36">[38]</ref>.</p><p>In Chortle-crf, the algorithm is applied to a tree of AND and OR functions. Hence all the cubes indeed have disjoint support and the solution to the technology mapping problem is optimum as in Chortle but it can be obtained much more quickly because of the speed of the packing algorithm (experimentally it has been observed to run up to 28 times faster than the Chortle algorithm).</p><p>The speed of the bin-packing algorithm is the key to addressing two shortcomings of the original Chortle approach, namely optimization across tree boundaries and duplication of logic. The results obtained by Chortle can be improved if local reconvergence is considered in the optimization (see Fig. <ref type="figure" target="#fig_4">5</ref>).</p><p>If the cubes are not disjoint, then the optimization problem is no longer similar to the bin-packing problem, since now the capacity needed to pack a set of cubes into the same LUT is not the sum of the size of each cube as in the case of the standard bin-packing problem. In fact, if two cubes c1 and c2 share p variables, where c1 has p 1 variables and c2 has p2 variables, then the capacity needed is p l + p2 -p and not p l + p2. Thus we could have a Suppose that the function F = ab+cd+de+ fg+hi is to be implemented. Using the First Fit Decreasing algorithm with k = 5, we could have the following decomposition:</p><p>(10)</p><formula xml:id="formula_6">(1 1)<label>(12)</label></formula><p>If cubes cd and de are placed into the same LUT we would have:</p><formula xml:id="formula_7">z1 = ab + cd + de;</formula><p>(13)</p><formula xml:id="formula_8">F = f g + h i + z l . (<label>14</label></formula><formula xml:id="formula_9">) z1 = ab + cd; zz = de + f g + 21; F = hi + 2 2 .</formula><p>However, placing cubes with shared variables in the same LUT a priori may not always yield the optimum solution.</p><p>Furthermore, there may be several cubes that share variables and they may not fit in the same LUT. In this case, the question of which groups of cubes should be "merged" into a single LUT arises. Since the bin-packing algorithm is very fast, the solution chosen by Chortle-crf is to run the algorithm exhaustively on all possible cases, i.e., no merging (equivalent to considering all cubes as disjoint), and all possible mergings of cubes with shared variables. Note that, if the number of cubes with shared variables is large, this approach would be too expensive even if the analysis of each case could be carried out very fast.</p><p>A heuristic has been added recently which searches for maximum sharing in an LUT <ref type="bibr" target="#b19">[20]</ref>.</p><p>A similar approach is taken to optimize across the fanout points of the network. Suppose that the network to implement has two outputs given by: (15) (16)</p><formula xml:id="formula_10">f l = de + z : f 2 = f g + z ; z = abc.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EL GAMAL et al.: SYNTHESIS METHODS FOR GATE ARRAYS</head><p>In this case, the decomposition of the network into a forest of trees would force the implementation of z as the output of an LUT, and would require two more LUT's to implement f l and f z . However, we could merge z into f l and fi to yield:</p><formula xml:id="formula_11">f l = de + abc; (17) fz f g + abc. (18)</formula><p>In this case, some logic is "duplicated" (the cube abc would appear in two LUT's) but the number of LUT's is reduced.</p><p>In Chortle-crf the following approach is taken. Every path starting from a fan-out point has to reach either another fanout point or a primary output U. The node that produces w as output is called a visible node. The optimization process considers all the visible nodes as functions to be implemented. Two possible implementations are then examined, one with the fan-out variable considered as an input variable (corresponding to the standard tree decomposition approach), the other with the fan-out variable replaced by its expression in terms of its fan-ins. The best solution is then selected. If there is more than one reconvergent fanout at a visible node, the process considers all the possible combinations of choices for each of the fan-out points that reconverges to the visible node.</p><p>If there are many reconvergent paths terminating at a node, the optimization may take a long time because of the very large number of cases to be checked. A possible remedy to this situation is to preprocess the network using a decomposition step (e.g., with one of the kerneling algorithms of MIS). It can be shown that the number of reconvergent paths after preprocessing is always less than or at worst equal to the number of reconvergent paths in the network at the end of Chortle's AND-OR decomposition.</p><p>2) The Two-step Approach: This approach, proposed first in <ref type="bibr" target="#b35">[37]</ref> and followed also in [18], <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b49">[50]</ref> begins as in the Chortle case with a network that has already been optimized via technology-independent transformations. The first step in the two step approach is to use decomposition to obtain a feasible network. In the second step, the network is manipulated to reduce the number of LUT's used by exploiting the characteristics of the particular LUT architecture considered.</p><p>Today, many designs are entered directly in a form which guarantees a feasible implementation in an LUTbased FPGA (for example, an XNF description of Xilinx). In this case, the first step is not needed.</p><p>First step: Decomposition: All nodes of the network that have more than k inputs, are decomposed to yield a feasible network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIS-pgal decomposition</head><p>In the first version of MISpga, two decomposition techniques are used: kernel decomposition; the Roth-Karp decomposition <ref type="bibr" target="#b24">[26]</ref>. In kernel decomposition, kernels of the logic function of an infeasible node no are extracted and evaluated with a cost function which attempts to consider not only the number of LUT's but also the wiring resources that may be needed in the implementation. When a kernel is extracted, a new node is created. Its output is then fed into the original node. After the kernel is extracted, input variables have to be provided to the corresponding node. If the original node shares variables with the kernel, then new edges are added to the network. If the two nodes are implemented in separate LUT's, the new edges correspond to signals to be routed in the FPGA. Hence, it makes sense to select for extraction the kernel which creates the minimum number of new edges. This decomposition is referred to as split decomposition.</p><p>Note that, following this procedure, the kernel extracted and node no may have more than IC variables each. Thus the procedure should be applied recursively until all nodes are feasible. However, the recursive decomposition may fail to produce a feasible network if there are no kernels for an infeasible node except itself (e.g., abce f m or ab + c + g h p )</p><p>and a different technique must be used. In MIS-pgal, an AND-OR decomposition is applied until all nodes are feasible. For example, abcefm is split into z = abc and z e f m ; ab + c + g p h is split in z = ab + c and z + gph.</p><p>The Roth-Karp decomposition <ref type="bibr" target="#b24">[26]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.x,)</head><p>The set X = (21: ~2 , .</p><p>. . The set Y = {xSc1,. . . . E , 2 , ) is called the bound set. is called the free set. Figure <ref type="figure" target="#fig_5">6</ref> shows the structure of the decomposition obtained (for We denote by a decomposition chart the truth-table of f where minterms of B'I = (0. l}" are arranged as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IC = 5 ) .</head><p>The minterms in the space B" correspond to the columns of the chart and those in B"-" to the rows. The entries in the chart are the values that f takes for all the possible combinations. For example, if f ( a , b, e ) = abc + a'b'c, the decomposition chart for f for partition ablc is The necessary and sufficient conditions were given in terms of the decomposition chart for f for the partition x122 . . . zs(xs+l . . . z , (also represented as : ; , ": : : ; : ; ). Curtis showed that the decomposition <ref type="bibr" target="#b19">(20)</ref> exists if and only if the corresponding decomposition chart has at most 2t distinct column patterns (or its column multiplicity is at most 2t). To get the functions ai, equivalence classes of minterms in B" are formed. Two minterms in B" are equivalent if they have the same column patterns. If M is the column multiplicity, there will be M equivalence classes. Each class is then assigned a binary code. The minimum code length is rlog2M1 = t. Bit i of the binary code corresponds to the function ai. The function g can then be determined by considering each minterm in the onset of f and replacing its bound part by the binary code for the corresponding equivalence class.</p><p>We illustrate the decomposition technique using previous example. There are two distinct column patterns, resulting in the equivalence classes c1 = (00, ll} and c2 = (01, IO}.</p><formula xml:id="formula_12">M = 2 =$ t = 1. Let e1 be assigned the code 1 and cz 0. Then a l ( a b) = ab + a'b'. Since f = ubc + a'b'c, g = a1c + Q 1 C = a1c.</formula><p>The Roth-Karp decomposition is based on the same theory but avoids building decomposition charts, which always require exponential space, by using a cube representation.</p><p>In order to make an infeasible node feasible, 1 x 1 should be at most k . This ensures that ( ~1 , .</p><p>. . ,at are feasible.</p><p>However if t+ (Y 1 is greater than k , g has to be decomposed further and the procedure is applied recursively, until all nodes involved are feasible. Since a nontrivial disjoint decomposition may not exist, an AND/OR decomposition is used as a last resort.</p><p>The choice of the bound set affects the form of g and t so that different bound sets may yield different decompositions. Since the procedure is computationally expensive, attempting several choices of bound sets to obtain good results is out of the question. The strategy used in MIS-pgal, instead, is to simply pick as bound set the first k variables of the function. More research is needed to find whether a more intelligent choice of bound set would yield significantly better results. It is important to point out that for symmetric functions all bound sets of a given cardinality produce the same 9 and hence the simple minded heuristic used in MIS-pgal does not compromise the quality of the final result for this class of functions.</p><p>It is not possible to prove that the Karp-Roth decomposition strategy is always better than the split decomp~sition.~ Experimental results indicate that the Roth-Karp decomposition is most effective when the node to be decomposed is a symmetric function. However, lacking a general theory, MIS-pgal uses both decompositions and selects the best result among the two.</p><p>Hydra decomposition: Hydra 11 81 is a program specifically targeted to multiple output LUT's.</p><p>In Hydra the decomposition step to make the Boolean network feasible consists of two operations applied in sequence. The first is a simple-disjoint decomposition. The second is an AND-OR decomposition which is applied only if the nodes of the network are still infeasible after the application of simple-disjoint decomposition. Among all possible choices of variables to place in X 6 , Hydra considers only the ones that can be shared with other functions. The rationale for this choice is best explained with an example. Let <ref type="figure">c,</ref><ref type="figure">d,</ref><ref type="figure">e,</ref><ref type="figure">f</ref>.g), <ref type="bibr" target="#b21">(22)</ref> be the network to be implemented with a Xilinx series 3000 FPGA. If the two functions are decomposed independently their implementation would require at least three singleoutput Xilinx CLB's since F1 has support larger than five.</p><formula xml:id="formula_13">Fl = Fl ( a , b, c, d , e , f ) , (<label>21</label></formula><formula xml:id="formula_14">)</formula><formula xml:id="formula_15">F2 = F2(</formula><p>However, if the following decomposition is applied,</p><formula xml:id="formula_16">2 1 = hl(c, 4 e , f ), 22 = b ( C , d, e , f ).</formula><p>(23) <ref type="bibr" target="#b23">(24)</ref> then and two multiple-output Xilinx CLB's would suffice since hl, h2, F1 and Fz have support less than or equal to four and the pairs (hl , h2) , (F1 , F2) have joint support less than or equal to five.</p><p>In Hydra, the choice of the set X 'is guided by the construction of the shared input graph. This graph has as many nodes as the Boolean network and there is an arc between node i and node j if fi and fj, the functions associated with the nodes, share some inputs. A weight equal to the cardinality of the set of shared variables is assigned to each arc. The graph is traversed searching for arcs with largest weight. The set of variables identified by the arcs are tested to see whether a simple disjoint decomposition of both functions that share that set of variables is possible. Note that testing for disjoint decomposition is expensive. It is exponential in the cardinality of the set S.</p><p>Given the cost of testing whether a given function has a simple disjoint decomposition, Hydra performs an AND-OR decomposition preprocessing step on the network after 5As is often the case in many steps of logic optimization even for 'There is a large number of possible choices: O(I.S~!). technology independent optimization so that the number of variables in the support of all the nodes is no larger than a given limit 1. In [ 181, the best results were obtained with 1 = 9.</p><p>Xmap decomposition: Xmap 1281 uses the if-then-else DAG representation discussed in Section 11. Once the Boolean network is converted into an if-then-else DAG, all the nodes are feasible if k &gt; 2 since they have three input^.^ The conversion of the Boolean network into an if-then-else DAG can be considered as a decomposition technique which makes a general network feasible.</p><p>Second step: Node elimination: After obtaining a feasible network, the number of nodes (and hence LUT's) can be reduced substantially by combining some of them. An example is shown in Fig. <ref type="figure" target="#fig_7">7</ref>. Here k = 5. Node p can be collapsed into f and n without making them infeasible. This decreases the number of nodes in the feasible network by 1.</p><p>The following node elimination techniques which can be applied to any LUT-based architecture have been proposed:</p><p>Local elimination <ref type="bibr" target="#b7">[8]</ref>, [ 181 also called partitioning <ref type="bibr" target="#b35">[37]</ref>, where nodes are eliminated by examining only node-fan-out pairs. Covering <ref type="bibr" target="#b35">[37]</ref>, [18], <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr">[SO]</ref>, where nodes are eliminated by considering the overall structure of the network.</p><p>A third technique referred to as Merging is implementation-dependent algorithm that exploits the particular LUT-based architecture 1371, 11 81, <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr">[SO]</ref>.</p><p>Local elimination: The basic idea of local elimination is to examine pairs ( i , j ) of nodes where node i is a fan-in to node j. If the node obtained by collapsing node i into node j is feasible, i.e., the new support set of j has cardinality less than or equal to k , then the new combined node can be implemented by a single LUT. However, creating this new node may substantially increase the number of connections among LUT's and hence make the wiring problem more difficult. While Hydra accepts local eliminations as soon as they are found, MIS-pgal orders all possible local eliminations as a function of the increase in the number of interconnections resulting from each elimination. The best local eliminations are then selected greedily.</p><p>Covering: While local elimination can be used successfully in reducing the number of LUT's, its myopic view of the structure of the network causes it to miss better 'For k = 2, the iffhemelse triple is converted into three nodes with two inputs. Let z = i f a hen h else c be the triple to be converted. Then the three nodes can be constructed as 31 = ab, 22 = a'c and 2 = 31 + 2 2 .</p><p>solutions. Covering takes a global view of the network. It identifies clusters of nodes that could be combined into a single LUT.</p><p>The most general formulation of the covering problem for LUT's is given in Mis-pgal <ref type="bibr" target="#b35">[37]</ref>. Let a supernode of a node i , Si, be a cluster of nodes consisting of i and some nodes in the transitive fan-in of i , such that the maximum number of inputs to Si is IC and if a node j E Si, then all the nodes on some path from j to i are in the supernode as well. Note that each supernode is a feasible node (the number of inputs is less than or equal to IC by definition), and all its nodes could be implemented by a single LUT.</p><p>There may be several supernodes associated to a node i.</p><p>The covering algorithm of <ref type="bibr" target="#b35">[37]</ref> generates all of them.</p><p>Repeating this procedure for all nodes generates a potentially large set of supernodes that can be used to cover the original network. The optimum covering problem is to find the smallest set of supemodes that covers all the nodes of the network. If we did not have any other constraints to satisfy, this problem would be a standard NP-hard set covering problem for which good heuristics as well as relatively fast exact algorithms are known <ref type="bibr" target="#b22">[23]</ref>. This is not the case, however. We have to make sure that each input to the optimum supemode set is an output of some other supernode in the set or be a primary input. This constraint poses a limitation in the way we choose supernodes; choosing a particular supernode may exclude several others from consideration.</p><p>This constraint makes the covering problem much harder: it becomes a binate covering problem <ref type="bibr" target="#b43">[44]</ref> for which no generally effective heuristic or relatively fast exact algorithms have been found. As a result, the computation time for Mis-pgal, which employs both an exact algorithm <ref type="bibr" target="#b31">[33]</ref> and a heuristic, is excessive.</p><p>In <ref type="bibr">[18]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b26">[28]</ref> a variety of greedy heuristics are proposed to solve the covering problem. It is interesting to note that the computation time for these heuristics is very short and that the quality of the final solution does not seem to suffer too much with respect to the optimum solution given the same initial network.</p><p>Hydra [ 181 examines the nodes of the network by ordering them by decreasing number of inputs. The nodes with k inputs are assigned to an LUT (note that the node may have some reconvergent path terminating in it and that by collapsing a number of predecessors, the number of inputs may actually decrease and allow a number of nodes to be mapped into the same LUT; Hydra will miss this). An unassigned node with maximum number of inputs is chosen out of the other nodes. A second node is then chosen so that the two nodes can be merged into the same LUT and a cost function maximized. The cost function is a linear combination of the number of shared inputs and the total number of inputs. The emphasis on shared inputs is aimed at improving the result of the subsequent merging step, as described below. This greedy procedure stops when all unexamined nodes have been considered.</p><p>The procedure used by Xmap <ref type="bibr" target="#b26">[28]</ref> .traverses in a breadth first fashion the if-then-else DAG from inputs to outputs and keeps a log of the number of inputs that are seen in the paths that connect the primary inputs to the node under consideration. If the node has more than IC inputs some of its predecessors have to be placed in a different LUT. These predecessors are chosen according to the number of their inputs. The more inputs they can isolate from the node under consideration the better. This algorithm is very fast because of the lack of any backtracking in the search strategy. It is also in general more powerful than Hydra's since it considers reconvergence. However, it does not consider the possibility of packing two different functions in one LUT while Hydra does.</p><p>The heuristics used in VISMAP [SO] consist of three basic steps. In the first, the network is traversed from inputs to outputs and supemodes are greedily identified as they are encountered in the traversal. The network is then traversed again and all possible clusterings in the supernodes are examined to determine the best. This procedure identifies fewer supernodes as compared to MIS-pgal but solves the covering problem exhaustively and hence optimally. However, if the number of nodes to be considered is large, the exhaustive procedure would be too slow. The network is therefore partitioned into subnetworks before the covering procedure is carried out.</p><p>Merging: In all approaches, except Hydra, single output functions are considered in the decomposition, local elimination and covering steps. However, when industrial FPGA's are considered, the particular features of the architectures must be taken into consideration. The purpose of the merging step is to combine nodes that share some inputs. Figure <ref type="figure" target="#fig_8">8</ref> shows two functions f and g which can be put on the same CLB of a Xilinx 3000 FPGA.</p><p>The approaches presented in [37, 28, 501 perform a postprocessing step to merge pairs of nodes after covering. The problem is formulated as a maximum cardinality matching problem <ref type="bibr" target="#b35">[37]</ref>: let G(X, E ) be a graph where the set of nodes X are nodes of the original network and where the pairs of nodes that can be merged in one Xilinx CLB, i.e., that have support size no larger than four and combined support no larger than five, are adjacent. The maximum reduction in the number of CLB's needed to implement the network is achieved when the largest set of disjoint adjacent pairs are combined. This is the maximum cardinality matching problem in a nonbipartite graph. Even though a polynomial time algorithm (in fact O(n2.')) exists for the solution of this problem, the algorithm is fairly difficult to implement and its running time can be long for large networks. AS a result, heuristics are often used; <ref type="bibr" target="#b26">[28]</ref>, <ref type="bibr" target="#b49">[50]</ref> use greedy matching algorithms which are not guaranteed to find an optimal solution but are very fast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIS-pga2:</head><p>A framework for LUT-logic optimization: Since most of the algorithms used in LUT-based synthesis are heuristic it is very difficult, or even impossible, to compare them in a rigorous way. Extensive experimentation is therefore used.</p><p>Acceptable results over a fairly large number of designs can be obtained using most of the approaches presented. However, no single heuristic can find the best results consistently across all designs. Hence, a system encompassing several different algorithms which can be run sequentially or independently would allow the user to customize the synthesis approach to any particular design or architecture. This is the approach of MIS-pga2. Figure <ref type="figure" target="#fig_9">9</ref> shows the flow-chart of where an initial optimization phase is followed by a sequence of technology mapping algorithms.</p><p>In MIS-pga2, the technology independent phase is not strictly independent of the technology and uses a cost function that is different from the one used in MIS. The reason is that unlike gate arrays and standard cells the number of literals in the factored form may not approximate well the actual implementation cost for FPGA's. A good estimate for the cost of a particular decomposition for an FPGA is produced by the bin-packing algorithm applied to the nodes that are modified during the technology independent optimization. This is practical given the speed of the binpacking algorithm.</p><p>In MIS, the nodes of the Boolean network are represented both in a sum-of-products form and in a factored form. Starting the technology-based optimization with one representation or the other does make a difference in the final cost of the implementation. Since there is no theory which can predict the outcome of the choice, MIS-pga2 optimizes both representations and selects the best result. A similar brute-force approach is followed in decomposition where no single algorithm can outperform all others in all benchmarks.</p><p>El. GAMAL er U / . SYNTHESIS METHODS FOR GATE ARRAYS MIS-pga2 offers four decomposition options in addition to the two offered in MIS-pgal [Roth-Karp and split decomposition described in Section IV-C2)]. These are:</p><p>Bin-packing. Note that since the nodes of the partition have cubes of disjoint support, the bin-packing heuristic when applied to the result will provide a locally optimum decomposition. Thus disjoint decomposition could be an effective preprocessing step for bin-packing. MIS-pga2, local elimination is applied not only to the . _ nodes in a feasible network while maintaining feasibility, but also to nodes in an infeasible network. This algorithm, called partial collapse, is shown in Figure <ref type="figure" target="#fig_10">10</ref>. It collapses nodes of a possibly infeasible network into their fan-outs and recomputes the cost of the network using the binpacking algorithm. The candidate nodes for collapsing are chosen according to the number of inputs. The list of nodes that result in a gain when individually collapsed is formed and an integer programming problem is solved to select the subset that gives the best overall gain. The integer programming problem is computationally expensive to solve but provides the best set of nodes to collapse. If the number of nodes that yield a gain if collapsed is large, this approach becomes computationally infeasible. An alternate greedy approach to the problem selects at each stage the node whose collapsing would yield the best gain.</p><p>In MIS-pga2, covering is performed either with the exact binate-covering algorithm if the network to cover is not too large or otherwise with heuristics. As in MIS-pgal , merging is carried out using the max-cardinality matching algorithm on the covered network. Instead of applying successive covering and merging which may yield suboptimal results a new formulation of a combined covering-merging step as a single, binate covering problem was suggested in <ref type="bibr" target="#b36">[38]</ref>.</p><p>Since MIS-pga is in the public domain, many researchers have been able to use the framework and some of the algorithms to develop their own novel approaches, thus adding to the library of algorithms available to the FPGA designer and tool developer. In MIS-pga2 the cost function in kernel extraction was changed. Fujita and Matsunaga <ref type="bibr" target="#b21">[22]</ref> modified the simplification step to better suit LUT-based architectures. Whereas in the standard simplification step, a minimal representation of the function at each node is sought, in the modified simplification step in <ref type="bibr" target="#b21">[22]</ref>, the target is to minimize the support of each node of the network. Each node 7~ is now simplified as follows. First, candidate nodes are selected which may be used for fan-ins of n. Characteristic functions of n and of the candidate nodes are computed. From these, sets of minimal supports for 71 are computed using the algorithm of Halatsis and Gaintans <ref type="bibr">[25]</ref>. Finally, the irredundant cover for R is computed using a minimal support. The algorithm allows use of don't care sets. After this step, any LUT technology mapper may be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparisons and Observations</head><p>In Table <ref type="table" target="#tab_2">1</ref>, we present results of MIS-pga2, Chortle-crf, and Xmap. The starting networks are the same, except that we had to run decomp -g on the starting network before running Chortle-crf; otherwise Chortle-crf does not complete on many examples in reasonable time. These networks were obtained by repeatedly running several MIS scripts until no improvement was obtained and then picking the best result. MIS-pga2 and Chortle-crf were run on a DEC5500 (a 28 mips machine).</p><p>Xmap was run on a SUN4/370 (a 12.5 mips machine). The table shows the number of jive-input single-output LUT's needed to implement the benchmark and the time taken (in sec.) in columns n and r respectively.</p><p>The following must be noted before comparing the results:</p><p>1 ) The results are sensitive to the starting networks used. Hence some of the results cannot be directly compared. However, some systems such as MIS-pga2 attempt to target the optimization to LUT-based architectures. 2) An implementation with smaller number of LUT's is not necessarily more routable. Interestingly, on benchmarks Sxpl, 9sym, rd84, C499, apex4, rd73, f 5 l m and bw, MIS-pga2 performs much better than other systems. Part of the reason is that some of these circuits are symmetric and, therefore, the Roth-Karp decomposition works very well. Also, exact covering techniques can be applied on some of the small benchmarks to obtain significant improvements. However, the time taken by Chortle-crf and Xmap is much less than MIS-pga2.</p><p>The results for two-output Xilinx 3000 CLB's are presented in Table <ref type="table" target="#tab_3">2</ref>. The results for MIS-pga2, Chortle-crf, Xmap, Hydra, VISMAP and xnfopt (the proprietary system from Xilinx <ref type="bibr" target="#b51">[52]</ref>) are compared. A "-" in the VISMAP column indicates that the results were not available. The starting networks for all systems (except VISMAP) are the same. For xnfopt, the number of passes for each example was set to 10. However, for C499, rot, des, C531. <ref type="bibr" target="#b4">5</ref> and C880, an interrupt was externally generated after 8 passes since xnfopt was taking too much time. MIS-pga2 outperforms Chortle-crf, Xmap and Hydra by 15.6 %, 16.9% and 16.9% respectively.' Note that MIS-pga2, Chortle-crf, Xmap and VISMAP exploit the two-output feature in a post-processing step, whereas Hydra targets mapping from the very beginning for two outputs.</p><p>Comparing the number of two-output LUT's with the number of single output LUT's for each system, Xmap gets significant improvements. One reason is that Xmap uses a cofactoring technique which generates nodes with at most three fan-ins. The possibilities for merging are much higher. MIS-pga2 does not do as well, because it works too hard on minimizing the number of single output LUT's, which may not be good for merging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Synthesis for Routability</head><p>The algorithms presented in the previous sections are primarily concerned with minimizing the number of LUT's needed to implement a given logic function. In the most popular LUT-based FPGA, wiring resources are scarce and as a result a logic function requiring far fewer blocks than available on a single FPGA 9We did not consider des in this set of results, since merge could not finish.</p><p>may not be routable." Hence routability should be carefully considered as a cost function in optimization. However, it is difficult to predict at the logic synthesis stage what routing resources will be needed.</p><p>To establish a link between logic synthesis and layout, a correspondence between nodes in the Boolean network and cells in the layout is assumed [I], <ref type="bibr" target="#b38">[40]</ref>. In this case, the physical implementation has a close resemblance to the topology of the Boolean network in that inputs to the nodes are signals to be routed on the final chip. If the signal sources are fixed (for example, if the pad positions are predetermined) then it makes sense to manipulate the network so that signals arrive to the nodes in an order that is consistent with their positions on the chip. This order is called lexicographical order in <ref type="bibr">[I]</ref>.</p><p>In <ref type="bibr" target="#b39">[41]</ref>, the nodes of the Boolean network are placed in the two dimensional plane with algorithms that are approximate versions of the ones used in actual placement. In this case, wiring area and length can be estimated with better accuracy by considering the nodes of the Boolean networks as physical blocks and the edges in the Boolean network as interconnections.</p><p>However, the results reported in <ref type="bibr" target="#b38">[40]</ref> for technology independent logic synthesis and technology mapping with layout considerations are not as good as one would expect. The average improvements are of the order of a few percents over the standard approach that does not take layout into direct consideration. Contrastingly, in <ref type="bibr" target="#b47">[48]</ref> it is claimed that significantly better area is achieved after layout than with other approaches where the link with layout is not as explicit.</p><p>In the case of LUT-based FPGA's, several algorithms attempt to minimize the needed wiring. For example, the cost functions used by MIS-pga and VISMAP take wiring into account by penalizing the creation of additional signals while operating on the network.</p><p>Synthesis for routability is an area where more research is needed both for FPGA's as well as for more conventional ASICs.</p><p>E. Per$ormunce Optimization Given the high performance requirements of system designs and the added delays due to the programmability of FPGA's, timing optimization is a very important goal of logic synthesis. It is important to note that minimizing area, which is the most common goal of today's synthesis tools, may result in slow implementations. Much research has been done on logic synthesis for timing optimization and its relationship with testability Delay in a circuit is due to delays in gates and interconnects. For mask-programmed design styles implemented in older technologies (above 1 micron), delay is mostly due to logic gates while interconnect delay is negligible. However, for submicron technologies, and for FPGA's, interconnect delays are at least as large as the delays in (e.g., [14l, [491, [451).</p><p>'"Taking layout into account while performing logic synthesis is important also in other ASIC technologies, since for large sea-of-gates and standard cell designs wiring area is often largerthan the area occupied by logic macros. the logic blocks. For example, for LUT-based FPGA's that use pass transistors as switching elements, the delay of a signal through general purpose interconnect could be much larger than that through one logic block.</p><p>There are three basic approaches to synthesis for performance optimization:</p><p>Delay optimization is equated to minimizing the depth in the network <ref type="bibr" target="#b20">[21]</ref>, [ I l l . The delay of the circuit is approximated by a combination of block delay and interconnect delay. Interconnect delay is estimated as a function of number of levels, nodes, and edges in the network <ref type="bibr" target="#b37">[39]</ref>. Critical path analysis with a (possibly simplified) delay model <ref type="bibr" target="#b37">[39]</ref> is performed on a placed circuit. In this approach, logic optimization and actual layout are performed in concert. The first approach is certainly faster. The number of levels in a circuit correlates with the performance of the circuit particularly well when the delay is mostly due to block delays. The third approach is more accurate but is potentially computationally inefficient due to the complexity of the mixed layout-synthesis algorithms used. The second approach is a compromise between the need for better accuracy and compute-time requirements.</p><p>Reducing the number of levels: The approach developed in <ref type="bibr" target="#b20">[21]</ref> is a variation on the basic algorithm of Chortle-crf. The bin-packing algorithm is still used but here the cost function optimized is not the number of LUT's but the number of levels of logic. Assuming that the delay is entirely due to the logic blocks, minimizing this cost function corresponds to minimizing the delays of all paths in the circuit. Unfortunately, the number of LUT's tends to grow large when minimizing all paths. For this reason a post processing step that reduces the number of LUT's without increasing the delay of the circuit has been proposed in <ref type="bibr" target="#b20">[21]</ref>. Minimizing the delay of all paths is in general an overkill since the performance of the circuit depends only on the critical paths." The critical paths are usually not known a priori, however.</p><p>The procedure starts as in Chortle-crf with a network that has been AND/OR decomposed and then split into trees. For each tree, the nodes are grouped according to their levels. Primary inputs are assigned level 0. A node is at level D if the highest level node among its fan-ins is at level D -1. Nodes at the same level are grouped into a set called stratum. The first-fit decreasing algorithm is then applied to minimize the number of LUT's in each stratum.</p><p>After all strata have been processed, the outputs of the LUT's at level D are connected to the available inputs of LUT's at level D + 1. If the number of available inputs is not sufficient, a new LUT is added at level D + 1.</p><p>This algorithm is guaranteed to find the minimum depth implementation of the tree if k 5 6. Otherwise, it may produce a suboptimal solution <ref type="bibr" target="#b20">[21]</ref>.</p><p>" A critical path in a directed acyclic graph (DAG) is a path from the primary inputs to the primary outputs of maximum length, i.e., maximum number of levels.</p><p>Reconvergent fan-outs are taken into account in the optimization process with a heuristic that is essentially the same as the one proposed in Chortle-crf.</p><p>A postprocessor finds the critical paths of the circuit and the network is processed to minimize the number of LUT's but with the constraint that the length of the critical paths must remain the same. First the area minimization of Chortle-crf is applied to the network. The algorithm may change the length of the critical path. To avoid an increase in estimated delay, all paths that have length larger than the critical path in the original network are re-processed using the algorithm for the number of levels described above. The procedure is iterated until all paths meet the target delay constraint.</p><p>The procedure has been observed to yield circuits that have 35% fewer levels than Chortle-crf but with 59% more LUT's.</p><p>Another approach to timing optimization, dag-map [ 111, follows the clustering algorithm by Lawler et al. <ref type="bibr" target="#b28">[30]</ref>. The network is first mapped into a network of two-input NAND gates as in MIS, but with an improved algorithm that guarantees that the number of levels in the transformed circuit is within a constant of the number of levels in the original circuit. A clustering algorithm is then applied which labels nodes of the network beginning with the primary inputs and ending with the primary outputs. Primary inputs are labeled 0. A label is assigned to a node, v, after all its inputs have been labeled. Let input( V ) be the set of input nodes to the set of nodes V . Let Np(v) be the set of predecessors of v with label p . Then if the node v is labeled p , otherwise p + 1. After all nodes are labeled, a backtrack phase begins where nodes are assigned to k-input LU's. This phase begins with the primary outputs which are placed in a queue. For each node in the queue, the node and all nodes that have the same label are assigned to an LUT. The node is then deleted from the queue and the set of nodes that are inputs to the nodes placed in the LUT are now added to the queue. The phase ends when only primary inputs remain in the queue.</p><p>Dag-map operates on the network without decomposing it into trees. If the starting network happens to be a tree, it is optimal. Also it may replicate nodes in order to achieve a lower number of levels. However, the replication in many cases could be too much.</p><p>Approximating the delay with layout information: MIS-pga2 <ref type="bibr" target="#b36">[38]</ref> attempts to find an implementation that meets a set of timing constraints and uses the minimum number of LUT's. The timing constraints are given in terms of required arrival times at the primary outputs. Arrival times are provided for the primary inputs. Given delays on the LUT's and an estimate of interconnect delays, the network can be traced to determine the critical paths. The trace has a forward pass where the arrival times of all the signals are found and a backward pass where the required times of all signals are computed. The difference between the required time and the arrival time is the slack of a node. In this formulation of the delay optimization problem, a negative slack corresponds to a circuit that does not satisfy the timing requirements. Hence, the delay reducing operations are applied to the path where negative slacks are found. Note that if all slacks are nonnegative the circuit meets the timing constraints and no timing optimization is needed. If indeed the fastest circuit is desired, then the required times at the outputs can be tightened until no feasible solution is found. This strategy can be implemented by optimizing the path with minimum slack.</p><p>The starting point for MIS-pga2 in delay mode is a network where technology independent timing optimization has been carried out using the standard MIS script. Note that the network is in terms of two-input gates and hence is feasible.</p><p>The optimization in MIS-pga2 is divided into two basic approaches :</p><p>A placement independent approach, where the optimizations are all performed at the logic level and a rough estimate of the interconnect delay is used; A placement dependent approach where synthesis driven placement using simulated annealing is performed. Here the interconnect delay estimate is accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Placement independent (PI) optimization:</head><p>In this approach, the placement and routing phase is considered to be a stochastic process. An LUT-based FPGA is modeled as a square grid where the nodes of the grid correspond to the LUT locations, and the classical results of Donath [ 151 on average wiring length La, as a function of number of blocks to be placed on the grid and their interconnections can be used. Donath's theory estimated the average wiring length to be where V is the set of LUT's (nodes of the Boolean network) to be placed and E is the set of edges in the network. The empirical delay formula is then given as:</p><formula xml:id="formula_17">Delay = XC + (aL2 + bL + c) (29)</formula><p>where X is the delay of a CLB, C is the number of levels in the network and L = log(&amp;,). This formula has been derived empirically by mapping a fairly large number of examples with Xilinx placement and routing tools and then fitting the data. The parameters in the delay equation, a, b, and c, are used to tune the equation. The delay equation is used to evaluate the performance of a circuit in place of the cruder estimate based on the number of logic levels.</p><p>The overall algorithm has the following form. For each node in the critical path, it tries to collapse the node into its fan-outs. The elimination is then accepted if the node so obtained is feasible, or if it is not feasible, but can be redecomposed so that the delay estimate decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Placement driven (PD) logic resynthesis:</head><p>A more accurate estimate of the delay of the circuit can be achieved after placement. However, in the standard flow of synthesisbased design, placement is performed after logic synthesis is completed and hence there is no feedback from placement to logic synthesis. The placement-dependent approach proposed in MIS-pga2 starts from an optimized feasible network obtained by the previous placement-independent approach.</p><p>The placement problem is formulated as assigning locations to point modules on an n by n grid (in the Xilinx XC3000 series, 7~ can take values from eight to 18). This problem is solved using simulated annealing. The difference from the standard simulated annealing algorithm is in the resynthesis step. At the end of the iterations at each temperature below a threshold, critical sections are identified. Logic synthesis and force directed placement techniques are used to restructure and reposition these sections. The logic synthesis techniques used are decomposition and partial collapse. These techniques are local; i.e., only the neighborhood of a critical section is explored for a better solution. The algorithm is summarized by the pseudo-code in Fig. <ref type="figure">1</ref> 1 .</p><p>The cost function is also particularly tuned for the problem at hand, where 1 is the total estimated net length, d is the estimated delay and P(T) E [0,1] is a temperature-varying parameter monotonically decreasing with T , which gives more weight to total net length at higher temperatures and more weight to delay at lower temperatures. The form of P(T) was determined experimentally. The delay estimate is performed using two models, the Elmore model [ 161 and the Penfield-Rubinstein model <ref type="bibr" target="#b41">[43]</ref>. The choice of the model to use is left to the user. The Penfield-Rubinstein model is in general more accurate but more expensive to compute. In any case, since many moves are in general attempted by simulated annealing, the actual delay calculation when a move is evaluated is camed out with the Elmore model. The delay calculation is performed with the Penfield-Rubinstein model only if the move is accepted.</p><p>Before entering a new simulated annealing inner loop, a placement of the resynthesized part of the network is camed out. The placement algorithm used is a simple forcedirected algorithm that finds a good position for the blocks of the circuit affected by the local resynthesis procedure. The positions of all the other blocks of the network are not changed. Note that the number of blocks may increase as a result of the resynthesis step. However, the capacity of the chip is never exceeded.</p><p>Comparisons and observations: Results on the use of MIS-pga2, Chortle-d and dag-map to optimize performance are reported in this section. First the benchmarks were optimized for area. Then a delay reduction script was used to obtain delay optimized networks in terms of twoinput NAND gates. In Table <ref type="table" target="#tab_4">3</ref>, results after the placement independent optimization phase of MIS-pga2 (column PI) /* a = temp f a c t o r ( a &lt; 1 ) ; T = current temperature; and Chortle-d are reported, using the same starting networks for both programs. We set IC to 5. We are restricting ourselves to single output LUT's. The results for dagmap are taken from [ I l l and the starting networks are not the same as those for the other two systems. For each example, we report the number of levels, nodes, edges and the CPU time (in sec.) on a DEC5500 (a 28 mips machine) in the columns lev, nodes, edges and t respectively. Out of 27 benchmarks, MIS-pga2 generates fewer levels on 9 and more on 13. On average (computed as the arithmetic mean of the percentage improvements for each example), MIS-pga2 needed 2.9% more levels. The number of blocks and the number of edges it needed are 58.7% and 66.2% respectively, of those for Chortle-d.'* As shown later, the number of nodes and edges may play a significant role in determining delay of a network. However, Chortle-d is much faster than MIS-pga2.</p><p>A direct comparison with dag-map is not possible since it uses different starting networks. However, dag-map produces fewer levels on many circuits, sometimes at the expense of higher LUT count.</p><p>The starting networks for placement are obtained from the level reduction algorithms. Two sets of experiments were reported in <ref type="bibr" target="#b36">[38]</ref>:</p><p>1) map: Place and route the network using apr, the Xilinx placement and routing system. This is done for the networks obtained after MIS-pga2 PI phase and for those after Chortle-d.</p><p>2) xln-p: On the networks obtained after MIS-pga2 PI phase, perform a timing-driven placement using the 12A more recent version of Chortle-d has a post-processing stage to reduce the number of blocks without increasing the number of levels in the circuit. IThe starting networks were obtained by running an MIS script and then speed-up and (may) differ from those used for the other two systems.</p><p>placement-dependent algorithm. The logic synthesis phase is entered once at each temperature. The resulting placement is routed using apr (with its placement phase disabled). The routing tool is instructed to route more critical nets first, as determined by the slacks computed for each edge.</p><p>The results of these experiments fhr placement, resynthesis and routing are shown in Table <ref type="table">4</ref>. The table shows the delay through the circuits in nanoseconds after placement and routing. Only benchmarks that were successfully placed and routed on a Xilinx FPGA are shown. The second and third columns give the delays for the designs synthesized using MIS-pga2 PI and Chortle-d respectively. The fourth column refers to the set of experiments x l n p for MIS-pga2 PI. The delay numbers in the table are computed from the placement and routing information generated by apr. This information gives the length of each net in the layout. map (MIS-pga2) gives lower delay than map (Chortle-d) on the majority of the examples. More interestingly, we can study the effect of the number of nodes and edges on the delay.</p><p>For example, although the number of levels in count is 3 for Chortle-d and 4 for MIS-pga2 (Table <ref type="table" target="#tab_4">3</ref>), the map delay through the circuit for Chortle-d is 3 ns more than MIS-pga2. Note that the block delay and hence delay of a level is 9 ns.'* Smaller numbers of nodes and edges obtained by MIS-pga2 (PI) help in offsetting the level advantage of Chortle-d by 6 ns. In fact, the x l n p option makes the difference even larger. For vg2, duke2 and misex2, the map delays for MIS-pga2 are higher than those for Chortle-d, but the difference in delays is less than 9 (difference in levels).</p><p>Experimental results involving synthesis with placement and routing for the Xilinx FPGA show that the delay optimization performed with the statistical approach gives good results, while surprisingly, the placement-dependent algorithm only occasionally improves the results and by no more than 10%. In addition, the results demonstrate that the number of levels is not an accurate measure of the delay of the circuit (although it is important in reducing the delay). In fact, at the expense of extra CPU time, MIS-pga2 in general achieves better delay than Chortle-d with fewer CLB's and edges but overall more levels.</p><p>The disappointing results of the placement-dependent approach are consistent with the unexciting results obtained by combined synthesis and placement in more traditional ASIC styles <ref type="bibr" target="#b39">[41]</ref>, <ref type="bibr" target="#b38">[40]</ref>. These results are counter-intuitive and leads us to believe that much work remains to be done to couple synthesis and layout in a more effective way.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v. LOGIC SYNTHESIS FOR MULTIPLEXER-BASED ARCHITECTURES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Introduction</head><p>Multiplexer-based (MUX-based) FPGA architectures use logic blocks that are combinations of a number of multiplexers and possibly a few additional logic gates such as AND's and/or ORss. Programming is achieved by programmable switches that may connect the inputs of the block to signals coming from other blocks or to the constants 0or 1, or that may bridge together some of these inputs. In Fig. <ref type="figure" target="#fig_15">12</ref>, the ACT-1 and ACT-2 logic modules are illustrated. Note that there are three multiplexers and an OR gate in ACT-1 and three multiplexers, an OR gate and an AND gate in ACT-2.</p><p>These logic blocks can implement a fairly large number of logic functions. For example, for the ACT-I module, shown in Fig. <ref type="figure" target="#fig_15">12</ref>, all two-input functions, most three-input functions <ref type="bibr" target="#b25">[27]</ref> and several functions with more inputs (the maximum number of inputs to the logic block is eight) can be implemented. However, some of these functions are equivalent in the sense that they only differ by permutation of their inputs. In <ref type="bibr" target="#b32">[34]</ref>, 702 unique functions for ACT-1 and 766 for ACT-2 were counted.</p><p>The recently introduced QuickLogic architecture uses a more complex logic block allowing the inputs to the first level multiplexers to come from AND gates with inverted and noninverted inputs, thereby providing programmable inversion for the multiplexer inputs <ref type="bibr" target="#b40">[42]</ref>. Since this architecture has been only recently disclosed an analysis of its power in terms of the number of functions that can be generated is not available at this time.</p><p>As in the case of LUT-based architectures, the number of blocks, the logic functions that these blocks can implement and the wiring resources are the main constraints. And similarly, the architecture-specific mapping also starts with  We first present the most straightforward library-based approach and then review the more complex architecturespecific approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Library-Based Technology Mapping</head><p>A library is created which has gates that represent all the functions obtained from the multiplexer-based logic block either by tying inputs to constants or by bridging some of them. Efficient algorithms that use BDD's can produce all nonequivalent f u n c t i o n ~' ~ implemented by a MUX-based block in a fairly short time. However, the number of library functions may be large, although not as large as in the case of LUT-based architectures (706 for the ACT-1 as compared with 90 14 for a four-input+ne-output LUT).</p><p>Technology mapping algorithms based on dynamic programming are quite effective for libraries with one or two hundred gates, but are considered too slow for significantly larger libraries. Library reduction techniques are therefore several are equivalent and hence they need not be enumerated.</p><p>13The number of functions that can be implemented is very large, but applied to reduce the number of gates. The least frequently used gates are removed. At Texas Instruments, the 766 gates of ACT-2 were reduced to 115 <ref type="bibr" target="#b32">[34]</ref>. Experimental results showed a certain insensitivity with respect to the size of the library <ref type="bibr" target="#b32">[34]</ref>. However, we believe that such reduction may impede significant optimizations.</p><p>An advantage of library-based mapping is that it is completely insensitive to changes in the logic block architecture. The only change that needs to be made is the creation of a new library. In addition, the same tool could be used for other target technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Direct Approaches</head><p>In direct approaches no library is generated. The mapping is performed directly onto the logic blocks.</p><p>All proposed direct approaches for MUX-based architecture are quite similar <ref type="bibr" target="#b35">[37]</ref>, [17], <ref type="bibr" target="#b25">[27]</ref>, <ref type="bibr" target="#b33">[35]</ref> and are not as different from the standard library-based approach as the direct approaches discussed earlier for LUT-based architectures. Since a BDD is simply a network of multiplexers and given the wealth of existing algorithms for manipulating and optimizing BDD's, BDD's have been used as the basis of most proposed direct approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I ) Using BDD's: The MIS-pgal Approach</head><p>Overview: In MIS-pgal <ref type="bibr" target="#b35">[37]</ref>, the dynamic programming approach to technology mapping is extended to pattern graphs and subject graphs described in terms of twoto-one multiplexers (BDD's) instead of two-input NAND gates.</p><p>The first step in this procedure is to represent each node function of the network with a BDD. As in standard technology mapping, the BDD is reduced to a forest of trees and then each tree is mapped.</p><p>If the structure of the logic block consists only of two-toone multiplexers, then only a few pattern graphs are needed to characterize the ''library'' fully. For example only four patterns suffice for describing the simplified structure of the ACT-I logic block where the OR feeding the output multiplexer has been removed. For more complex blocks, taking into consideration the nonhomogeneous structure can yield a larger set of pattern graphs (though never as large as the ones needed for the standard library approach described above), some of which are unusable by the dynamic programming approach since they are not trees. Thus a reduced set of patterns is used; in MIS-pgal only eight patterns are considered. Covering of the subject-graph by patterns is done using dynamic programming. After an initial mapping, an iterative improvement phase is used. It consists of three main operations: partial collapsing, decomposition and phase assignment.</p><p>Building the B D D for the Subject Graph: It would be possible to build a BDD for the entire network in terms of its primary inputs. However, such a BDD may be very inefficient as a starting point for implementation since the structure of the initial network obtained by technology independent optimization would be lost. In addition, there may be cases for which a BDD is too large. For these reasons, the BDD's are only built for the functions stored at each node.</p><p>Two representations are actually used for each node: the reduced-ordered BDD and the BDD. It is well known that the size of the ROBDD for a function depends strongly on the ordering of the inputs. Since the problem of finding the optimum ordering is NP-complete, heuristics are used for this task. However, if a node function has only a few variables, it is worthwhile to generate exhaustively all orderings and choose the best, since the size of the representation is directly related to the size of the implementation.</p><p>To allow the implementation of this strategy, a decomposition step is performed first on the network to force all nodes to have at most IC inputs (in MIS-pgal, the best value of IC is found to be between 3 and 6). Note that this is similar to the LUT problem and in fact a similar sequence of algorithms for decomposition is tried.</p><p>There are some drawbacks for this procedure:</p><p>1) The limitation on the number of inputs is artificial.</p><p>2) The input ordering constraint imposed by the ROBDD may be too severe and may yield a poor result. 3) Nodes in the ROBDD may have multiple parents, and so the tree decomposition may yield many small trees thus reducing the power of the dynamic programming approach. An alternative is to use BDD's where the sequence of variables in the graph is not forced to be the same for all vertices of the BDD. The goal in constructing these BDD's is to minimize the number of nodes as well as the number of nodes with multiple parents. This second goal is important to offer the maximum degree of freedom to the dynamic programming approach.</p><p>The algorithm for building the BDDs uses Shannon cofactoring repeatedly until all leaf functions are unate.I4 A minimum cover problem is then solved to find a good factored form representation of the unate function with respect to the architecture. This is in tune with the general strategy followed in logic minimization <ref type="bibr" target="#b6">[7]</ref> where a generic function is decomposed with the Shannon cofactoring operation until a unate function is reached. In both cases, the variables for the cofactoring operations are chosen so that the leaves become unate quickly.</p><p>While this procedure remedies some of the drawbacks for ROBDD's mentioned above, it too has drawbacks. For example, there may be duplications in the branches of the BDD that would not have appeared in the ROBDD. Since it is not possible to tell a priori which representation yields the best result, in MIS-pgal both are tried and the best result is selected.</p><p>Covering is performed on the forest of trees using dynamic programming. If the logic block is the simplified version of ACT-I shown in Fig. <ref type="figure" target="#fig_16">13</ref>, it can be proved that the four pattern graphs shown in Fig. <ref type="figure" target="#fig_18">14</ref> yield the optimum matching in a selected number of cases <ref type="bibr" target="#b35">[37]</ref>.</p><p>I4A logic function is unate in a variable .I' if it depends only on .r or its complement but not both. A function is mate if it is unate in all its variables.   For the ACT-1 module, a set of eight pattern-graphs is sufficient, given that the subject-graph has no restriction on the number of times a variable may appear on the path from the root to a leaf node, and the covering procedure is exact. Note that if we use the cofactoring technique in constructing the subject-graph (which is the case with BDD's), this set of pattern-graphs is not sufficient. In fact, there are functions which can be realized with one ACT-1 module, but a BDDbased procedure will always use more than one module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STRUCTI</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One such function is</head><formula xml:id="formula_18">f = (a+b)(a'c+ab)+a'b'(lcl+lc'm)</formula><p>Wl.</p><p>Iterative improvement: Since the algorithms used in the dynamic programming algorithm and in building the BDD representation are local in nature (the subject graph is broken into a forest of trees), an iterative improvement phase is used to improve the final results. The strategy used .in MIS-pgal is shown in Fig. <ref type="figure" target="#fig_4">15</ref>.</p><p>The algorithm used in partial collapse is the same as in the case of LUT-based architectures in MIS-pga2 (see Fig. <ref type="figure" target="#fig_10">10</ref>).</p><p>The decomposition phase selects nodes that have a fairly large number of fan-ins and decomposes them using the same approach as for LUT-based FPGA's. Only decompositions that reduce the cost are accepted.</p><p>The phase assignment algorithm operates on one node at a time and greedily selects the least cost polarity of the function associated with the node.</p><p>2 ) The Amap Approach: <ref type="bibr">Karplus [27]</ref> proposed a quick algorithm that carries out a technology mapping into MUXbased architectures by mapping the network into if-then- else DAG'S.</p><p>Here, the selector function at each vertex can be a function of inputs, rather than being only an input. When compared to BDDs this results in more freedom in the mapping phase. In addition, when this representation is built from a sum-of-products form by the cofactoring procedure, duplicate cubes are avoided. In the ITE representation, the if vertex corresponds to the select line of the multiplexer.</p><p>The then and else children correspond to the branches taken when the ifchild evaluates to 1 and 0 respectively and are mapped to the inputs of the multiplexer.</p><p>Amap creates the ITE DAG and then preprocesses it to find an initial good local form for the mapping. In particular, single literal inputs are commuted to bring them to the if part so that the OR function of the ACT-1 module is better utilized. A quick phase assignment is also performed.</p><p>After this preprocessing, the final covering is carried out in a single pass with a greedy procedure. The procedure has to tradeoff the advantage of placing as much of the subject DAG as possible into a block and the disadvantage of hiding a signal that feeds several blocks. In the latter case, logic must be replicated and a larger implementation may result. In fact, if a signal that is shared by a number of vertices is not hidden in all the fan-outs, it has to be the output of a block. Thus pushing logic into a block would not provide any saving in this case.</p><p>The nodes of the ITE DAG are processed in a top-down fashion, starting from the primary outputs. Each node is then mapped into the output multiplexer of the ACT-1 architecture. In doing so. the use of the OR gate in the select input is made as efficient as possible. The then and the else children are then mapped to the input multiplexers. These multiplexers may not be fully utilized and may in fact be used merely as buffers if the variables corresponding to the then and the else children are already implemented or if they have high fan-out (in Amap a high fan-out is a fan-out of three or more).</p><p>After the mapping to the input multiplexers has been done, the output multiplexer is revisited to see whether a more compact representation exists by exploiting the actual function implemented by the block.</p><p>The entire procedure is recursively applied until all nodes are either primary inputs or they have been implemented in some block.</p><p>Since only a single pass is performed on the ITE DAG and the mapping is carried out locally, the algorithm is fast. The experimental results presented in <ref type="bibr" target="#b25">[27]</ref> show that not much is lost with respect to the more complex optimization procedures of MIS-pgal in terms of quality.</p><p>3) The Proserpine Approach: This approach follows the same general structure of the technology mapping algorithms of MIS and Ceres <ref type="bibr" target="#b29">[31]</ref>. First, the network is partitioned into multiple trees, and the nodes of the network are decomposed into two-input AND/OR gates to maximize the granularity of the network and to offer more freedom to the dynamic programming algorithm.</p><p>The basic difference lies in the way matching is performed. The algorithm does not require the explicit representation of the pattern graphs. Instead, it requires the representation of the "largest" logic function implementable by the basic block, i.e., the function computed by the structure with each input connected to a separate variable. The algorithm customizes the block with the correct operation during the matching process.</p><p>The set of functions that can be implemented by a MUXbased logic block corresponds to the set of functions that result from stuck-at and bridging faults. An input connected to a constant corresponds to a stuck-at fault and bridged inputs correspond to a bridging fault.</p><p>The stuck-at inputs belong to the set S , the ones that are bridged to the set B. Then the problem to be solved is: Given a function F(y1, ..., ym) and the module function G(zl. ... ,x,) with m 5 n, find a stuck-at set S , a bridging set B and an ordering of the variables R such that F and Gson are functionally equivalent, i.e., there is a match for F in G.</p><p>The function F to match against the module function G is obtained by examining the nodes of the AND/OR network and collapsing them recursively. A number of different functions are created that are called cluster functions. For each cluster function matching is performed and the dynamic programming algorithm is used to minimize the block count.</p><p>Solving the matching problem is not easy especially when bridging is allowed. We will not review this case and refer the reader to the original papers on the subject [17], <ref type="bibr" target="#b4">[ 5 ]</ref> .</p><p>For the stuck-at faults, an ROBDD is built for the module function and for the cluster function. A sufficient condition for a match is that the ROBDD of the cluster function be isomorphic to a sub-graph of the module ROBDD. It is obvious that the part of the module ROBDD that does not correspond to the cluster function representation can be reduced by setting an appropriate set of inputs to 0 andor 1 . However, there are cases where a match exists but the cluster function ROBDD is not isomorphic to any sub-graph of the module function ROBDD. This is due to the fact that the orderings of the variables used to build the ROBDDs may not be compatible. Hence, to discover if a function matches, all possible variable orderings of the module function should be considered and the corresponding ROBDDs should be checked for isomorphism. Of course, this may be quite expensive and identical subgraphs in separate ROBDDs corresponding to different orderings may end up being checked a large number of times. In [ 171, a new structure called the Global Boolean Decision Diagram, GBDD, is proposed to make the matching algorithm faster. This structure is built by combining the BDDs corresponding to all the orderings. Combining the BDDs in an appropriate way removes all the duplications making the sub-isomorphism check much faster.</p><p>Given the complication of dealing with bridging faults, Proserpine first attempts to find a match with the GBDD as described above. If no matching is found, bridging is then considered. In <ref type="bibr" target="#b4">[5]</ref>, new bridging algorithms are described.</p><p>A few interesting observations were made after running Proserpine on a benchmark set. It was found that the bridging contributed insignificantly to improving the mapping (using the Ceres framework), and at most a single bridge is needed in the vast majority of cases.</p><p>The Proserpine approach is powerful in that it can consider any logic block where the programming mechanism allows the inputs to be connected to constants andor bridged. As such, it is useful as an architectureexploration tool.</p><p>4 ) The MIS-pga2 Approach MIS-pga2 <ref type="bibr" target="#b33">[35]</ref> is based on the same general flow of MIS-pgal but with some key modifications, some of which are borrowed from the other approaches presented above.</p><p>The overall algorithm is as follows:</p><p>Each node of the network is first mapped. If the function f at the node can be implemented by one block (using the matching algorithm described in <ref type="bibr" target="#b33">[35]</ref>), the corresponding match is saved. Otherwise, an ITE of f is constructed. The ITE is covered by the pattern graphs of Figure <ref type="figure" target="#fig_5">16</ref> using dynamic programming <ref type="bibr">[29]</ref>. Both the ITE and its cover are saved.</p><p>An iterative improvement phase using partial collapse and decomposition follows after the initial mapping. Partial collapse tries to collapse a node into all its immediate fanouts. If the sum of the new costs of the fanouts is less than the sum of the old cost of the node and the fanouts, the collapse is accepted. The new cost of a fanout is determined by remapping it using step 1. This process is repeated for all nodes of the network. Using decomp -g of MIS [8] a node is decomposed and the decomposed nodes are mapped.</p><p>If the cost improves, the original node is replaced by its decomposition. Partial collapse and decomposition are repeated for some number of iterations. Each node of the network is replaced by a set of nodes, each of which can be implemented using one basic block of the architecture. This is done by using the cover of the ITE at each node.</p><p>If the number of primary inputs of the network is small (say less than IO), an ROBDD is constructed for the network. This ROBDD is then mapped using the method described in [37]. If this mapping is better, it is accepted. Construction of ROBDDs helps when the circuit is symmetric.</p><p>The algorithm is applicable for both ACT-1 and ACT-2 modules. However, some architecture-specific changes have to be made. The main differences are in the matching algorithm and the pattern graph construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Comparisons and Observations:</head><p>We present the results obtained using these approaches for a set of benchmark examples. These examples were optimized as in Section  <ref type="table" target="#tab_7">5</ref>, results are presented for MIS-pga2, MIS, Ceres, Amap and MIS-pgal with the same starting networks. We also present results for Proserpine, although we do not know if the starting points are the same.I5 For MIS, a library containing around 90 gates was used, whereas for Ceres, a complete library for ACT-I was used and depth of the search while covering was set to S. MIS-pga2, MIS and MIS-pgal were run on a DECS500 (a 28 mips machine), whereas Amap was run on a SUN4/370 (a 12.5 mips machine). The option used for Amap was - an3. The options used for MIS-pgal is act-map -h3n lq -d4 -f3 -M4 -1 -gO.OO1. This means that both an ROBDD and an unordered BDD are constructed for each function. An optimum ROBDD is constructed for any function with at most four inputs. One iteration of the iterative improvement phase is executed. In the partial collapse routine, only the nodes with fanin no greater than three are considered for collapsing. In the decomposition routine, all nodes with fanin of four or more are considered. The phase assignment algorithm is also executed. Finally, a last-gasp routine is entered at the end <ref type="bibr" target="#b35">[37]</ref>. This routine builds a network q(n) from each node n of the final network q, where q(n) has one internal node, one primary output and as many primary inputs as the number of fanins of n. It then performs technology decomposition on q ( n ) and then applies mapping and the iterative improvement phase to get a network ~' ( n ) .</p><p>If the cost of q'(n) is less than that of n, the routine replaces n by rf(n) in 77. MIS-pga2 used two iterations, performed a last-gasp, but did not do a quick phase.</p><p>Table <ref type="table" target="#tab_7">5</ref> shows the number of ACT-1 modules needed to implement the benchmark, and the time taken in seconds in columns n and t respectively. Though Amap also uses ITEs, its way of construction is different. MIS-pga2 runs an iterative improvement phase and uses a matching algorithm prior to the construction of ITEs. MIS-pgal constructs BDD's and hence could replicate parts of the cubes in the 0 and 1 branches. However, by exhaustively generating all reduced ordered BDD's for a function (if it has at most four inputs), MIS-pgal is able to achieve better results on many examples. For the same reason, it is many times slower. However, there are benchmarks (e.g., C1908, C499) where Amap gives better results. This is due to the different mapping technique it uses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. WIDE-AND/OR ARCHITECTURES</head><p>Wide-AND/OR architectures are extensions of the standard two level PLD architectures. The complexity of the logic blocks which are general PLAs with several inputs (from about 20 to 100) connected together by some kind of bus structure is high. The logic synthesis problem is similar to the logic optimization problems encountered in PLA design. Most of the proprietary systems are based on two-level logic optimization programs with some help for decomposition.</p><p>To the best of our knowledge, the only paper that deals with the aspects of Wide-AND/OR arrays with a novel approach is <ref type="bibr" target="#b30">[32]</ref>. This approach is targeted to a general architecture that has as a logic block an AND plane of a PLA whose outputs (ORs of rows of the AND plane) are fed into a set of simple gates and hence implements three-level logic."</p><p>The approach was applied to the architecture offered by PlusLogic, where the simple gates are two-input gates that can implement any logic function of two inputs.</p><p>The basic algorithm of <ref type="bibr" target="#b30">[32]</ref> restricts the use of the twoinput logic to AND gates. The simplified optimization problem solved by <ref type="bibr" target="#b30">[32]</ref> is as follows. Given a logic function F , find two PLAs, PLAz and PLA2, so that if g1 and g2 are the sum-of-products form of the logic implemented by the PLA's, then glg2 covers F and the total number of cubes is minimized.</p><p>If F is incompletely specified, then g1 and g2 must satisfy the following conditions to be valid: let f be the on-set of F . Then, f C gl, f C g2.</p><p>Let T be the off-set of F . Then rglg2 = Q).</p><p>I6There is some evidence that three-level logic has advantages over two-level logic from the point of view of compactness of representation and over multilevel logic from the point of view of speed. Sasao <ref type="bibr" target="#b45">[46]</ref> argued that little is gained by going to more than three levels even though this view is not universally shared.</p><p>The algorithm proposed in <ref type="bibr" target="#b30">[32]</ref> is a heuristic that pro-The algorithm structure is as follows: 1) Choose an initial 91, gy that contains f . 2 ) Using gy, obtain a minimal g2 so that 9yg2 satisfies 3) Using ~2 , obtain a minimal g1 that satisfies the 4) Iterate for several choices of gy and pick the pair that</p><p>The key point in the algorithm is the minimization step for g2 given 91 (or vice versa). This minimization is carried out with Espresso <ref type="bibr" target="#b6">[7]</ref> on appropriate incompletely specified functions that are obtained exploiting the degree of freedom offered by the structure of the implementation.</p><p>To extend the result to the more powerful output logic offered by PlusLogic, the algorithm goes through a phase assignment procedure that optimizes the use of the output logic for all cases except for the exclusive OR and exclusive NOR functions that cannot be reduced to the optimal phase selection.</p><p>The algorithm has been shown to produce very good results as compared with the implementation of the logic using only two-level PLA's. duces gl, g2 so that the conditions above are satisfied. the conditions. conditions. has minimum size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EL GAMAL Cf U / . : SYNTHESIS METHODS FOR GATE ARRAYS</head><p>A final remark is that here also the algorithm is able to cope well with structures that are simpler than those offered by the commercially available architectures. Logic synthesis algorithms are more effective if the logic is uniform and simple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>We have reviewed logic synthesis algorithms and methosa for FPGA's. The paper focused on FPGA's with largegranularity logic blocks, since these yield design problems that are sufficiently different from the standard logic synthesis problems.</p><p>We believe that logic synthesis is an essential step in the design of FPGA's. The commercially available architectures offer difficult challenges for algorithm designers. The algorithms developed so far are mainly targeted towards the minimization of the number of logic blocks used. Only a few deal with the optimization of performance and routability .</p><p>We expect that in the future more powerful algorithms will emerge that can also effectively take into consideration performance constraints and the scarcity of interconnect resources. While FPGA and tool vendors offer some limited logic synthesis capabilities now, they will ultimately offer more sophisticated logic synthesis tools for the most commonly available architectures. We expect that tool vendors will offer logic synthesis environments where it will be easy to go from one FPGA architecture to another and from one ASIC style to another. We also expect to see new architectures that are designed with logic synthesis in mind so that optimization algorithms can be more effective.</p><p>Much work remains to be done to deal with sequential logic synthesis. All architectures offer a number of sequential elements. It is important to evaluate whether the number and type of sequential elements offered is good especially in view of the use of sequential logic synthesis. Timing and retiming of sequential circuits in the presence of a fixed (and possibly large) number of sequential elements is an interesting problem.</p><p>Ultimately logic synthesis will be extended to multiple chip systems. The problem of partitioning logic into multiple chips is a general problem for all ASIC styles but it is particularly relevant for FPGA's given the constraints on resources. While netlist partitioning algorithms are available not much is available to partition a design at a higher level of abstraction. We expect to see a number of partitioning approaches of this kind to appear shortly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .Fig. 1 .</head><label>21</label><figDesc>Fig. 2. Realization of a function with ITE's.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. A Boolean network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>example of SDC is as follows. If node i of the network carries the Boolean function f ( x , y ) , where x = a + b, y = ab + c and a , b, c are primary inputs of the network, then . ( U + b)' + x'(a + b ) and y ( a b + c)' + y'(ab + c ) are SDC's. In other words, the SDCs represent combinations of variables of the Boolean network that can never occur because of the structure of the network itself.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. A CLB of Xilinx 3000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Local reconvergence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Application of Roth-Karp decomposition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>is an efficient algorithm which implements the classical decomposition theory of Ashenhurst and Curtis<ref type="bibr" target="#b2">[ 3 ]</ref> ,[12].Ashenhurst gave necessary and sufficient conditions for the existence of a simple disjoint decomposition of a function f of n variables. A simple disjoint decomposition of f is of the form:Curtis [12]  extended the result to a generalized decomposition of the form: S ( x 1 , 5 2 , . ' . , x,,xs+1,. . =g(a1(21,22, . . . . 2 Z S + l . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Node elimination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Two functions in a CLB</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Flow: MIS-pga2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Partial collapse</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Modi'ing the optimization steps: Several attempts have been made to target the optimization steps to LUT-based FPGA architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>= 1 Fig. 11 .</head><label>111</label><figDesc>Fig. 11. Simulated annealing for placement and resynthesis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>l 2</head><label>2</label><figDesc>Speed grade -70 is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Table 4</head><label>4</label><figDesc>upr after Running Chortle-d; and x l n g Delays of Placed and Routed Designs: map (MIS-pga2) Using apr after Running MIS-pga2 PI Phase; map (Chortle-d) Using Using Just the Routing of apr after Running MIS-pga2 PI and PD phases z41d example I map (MIS-p.ga2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Actel architectures</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Simplified ACT-I architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>.</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Pattem graphs for MIS-pgal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>iterativeimprovement( 7 )Fig. 15 .</head><label>715</label><figDesc>Fig. 15. Iterative improvement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>8 Fig. 16 . 4 . 3 . 3 .</head><label>816433</label><figDesc>Fig. 16. Pattern graphs for MIS-pga2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>'</head><label></label><figDesc>5Proserpine is not being distributed yet and the corresponding column in Table5has been taken from[17].1 = if T = then E = else 0 = muxMIS-pga2 in general performs better than other systems. Some possible explanations are given below.The reason why MIS-pga2 outperforms the MIS technology mapper is because the multiplexer representation of a function used in MIS-pga2 fits nicely into the multiplexer-based architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The algorithm for bin-packing used in MIS-pga2 is the Best-Fit Decreasing heuristic that selects the bin which has the maximum leftover capacity after the cube has been assigned to it.* If the cubes have disjoint support then for k 5 5 an op-</figDesc><table><row><cell>timum tree implementation is found (a similar result</cell></row><row><cell>was proved independently for First-Fit Decreasing in</cell></row><row><cell>[201).</cell></row><row><cell>Co-factoring decomposition. This approach, applied</cell></row><row><cell>only if k 2 3, is particularly effective for func-</cell></row><row><cell>tions where cubes share several variables. Each node</cell></row><row><cell>is decomposed by computing the Shannon cofactor a f a + a'fal until the leaf nodes have support that is</cell></row><row><cell>no larger than k. All nodes of the network after the de-</cell></row><row><cell>composition (except possibly the leaf nodes) have at</cell></row><row><cell>most three inputs. If k 2 4, a simple post-processing</cell></row><row><cell>elimination step similar to the approach proposed in</cell></row><row><cell>Xmap may be tried to reduce the number of nodes</cell></row><row><cell>in the network. It is possible to give an upper bound</cell></row><row><cell>on the number of CLB's needed to implement the</cell></row><row><cell>network obtained by this simple decomposition [38].</cell></row><row><cell>However, this bound is exponential in the number</cell></row><row><cell>of inputs t of the function and hence this procedure</cell></row><row><cell>may not be good if t &gt;&gt; k.</cell></row></table><note><p>AND/OR decomposition. This decomposition breaks up the nodes of the network so that the resulting network has nodes that are either inverters, two-input AND gates or two-input OR gates which can be packed by the covering step. Disjoint decomposition. This decomposition is the decomp -d option in MIS. It partitions the cubes of the function into a set of cubes with disjoint support and then creates a node for each partition and a node that is the OR of the outputs of the partition nodes.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Number of Five-Input LUT Blocks; t</figDesc><table><row><cell cols="6">Number of Five-Input Single-Output LUT Blocks: R</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Run Time in Seconds.</cell><cell></cell></row><row><cell>example z4ml</cell><cell cols="2">MIS-pga2 n 5 --5.0 t</cell><cell cols="2">Chortle-crf n 7 --t 0.1</cell><cell cols="2">Xmar, n 9 __ 2 --0.2</cell></row><row><cell>misexl</cell><cell>11</cell><cell>2.7</cell><cell>11</cell><cell>0.1</cell><cell>11</cell><cell>0.2</cell></row><row><cell>vg2</cell><cell>20</cell><cell>7.4</cell><cell>21</cell><cell>0.1</cell><cell>24</cell><cell>0.2</cell></row><row><cell>5xp 1</cell><cell>18</cell><cell>22.4</cell><cell>28</cell><cell>0.4</cell><cell>31</cell><cell>0.3</cell></row><row><cell>count</cell><cell>31</cell><cell>5.8</cell><cell>31</cell><cell>0.3</cell><cell>31</cell><cell>0.2</cell></row><row><cell>9symml</cell><cell>7</cell><cell>127.2</cell><cell>44</cell><cell>6.4</cell><cell>55</cell><cell>0.4</cell></row><row><cell>9sym</cell><cell>7</cell><cell>339.7</cell><cell>59</cell><cell>12.8</cell><cell>73</cell><cell>0.5</cell></row><row><cell>apex7</cell><cell>60</cell><cell>18.7</cell><cell>60</cell><cell>0.6</cell><cell>65</cell><cell>0.5</cell></row><row><cell>rd84</cell><cell>10</cell><cell>73.7</cell><cell>35</cell><cell>1.3</cell><cell>36</cell><cell>0.4</cell></row><row><cell>e64</cell><cell>80</cell><cell>14.7</cell><cell>80</cell><cell>0.3</cell><cell>80</cell><cell>0.5</cell></row><row><cell>(2880</cell><cell>82</cell><cell>546.8</cell><cell>88</cell><cell>2.2</cell><cell>103</cell><cell>0.8</cell></row><row><cell>apex2</cell><cell>67</cell><cell>388.5</cell><cell>64</cell><cell>2.9</cell><cell>81</cell><cell>0.7</cell></row><row><cell>alu2</cell><cell>109</cell><cell>773.8</cell><cell>116</cell><cell>7.1</cell><cell>126</cell><cell>0.9</cell></row><row><cell>duke2</cell><cell>110</cell><cell>203.7</cell><cell>111</cell><cell>1.7</cell><cell>127</cell><cell>0.8</cell></row><row><cell>c499</cell><cell>68</cell><cell>1074.4</cell><cell>89</cell><cell>2.6</cell><cell>75</cell><cell>0.5</cell></row><row><cell>rot</cell><cell>181</cell><cell>282.1</cell><cell>188</cell><cell>2.7</cell><cell>212</cell><cell>1.4</cell></row><row><cell>apex6</cell><cell>182</cell><cell>243.9</cell><cell>198</cell><cell>2.9</cell><cell>231</cell><cell>1.6</cell></row><row><cell>a h 4</cell><cell>55</cell><cell>887.5</cell><cell>70</cell><cell>2.5</cell><cell>98</cell><cell>0.7</cell></row><row><cell>apex4</cell><cell>412l</cell><cell>198.7</cell><cell>579</cell><cell>98.9</cell><cell>664</cell><cell>6.4</cell></row><row><cell>des</cell><cell>904</cell><cell>3186.3</cell><cell>927</cell><cell>35.4</cell><cell>1042</cell><cell>6.8</cell></row><row><cell>sa02</cell><cell>28</cell><cell>41.9</cell><cell>27</cell><cell>0.5</cell><cell>37</cell><cell>0.4</cell></row><row><cell>rd73</cell><cell>6</cell><cell>24.0</cell><cell>16</cell><cell>0.3</cell><cell>21</cell><cell>0.1</cell></row><row><cell>misex2</cell><cell>28</cell><cell>3.4</cell><cell>28</cell><cell>0.1</cell><cell>28</cell><cell>0.2</cell></row><row><cell>f51m</cell><cell>17</cell><cell>14.4</cell><cell>27</cell><cell>0.4</cell><cell>33</cell><cell>0.3</cell></row><row><cell>clip</cell><cell>28</cell><cell>58.4</cell><cell>31</cell><cell>0.7</cell><cell>38</cell><cell>0.3</cell></row><row><cell>bw</cell><cell>28</cell><cell>17.3</cell><cell>39</cell><cell>0.3</cell><cell>43</cell><cell>0.3</cell></row><row><cell>h9</cell><cell>39 __</cell><cell>27.6</cell><cell>41</cell><cell>0.4</cell><cell>48</cell><cell>0.4</cell></row></table><note><p><p>__ -</p>'Modified kernel extraction and partial collapse could not finish so a faster script was used.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>Number of Two-Output Xilinx CLB's</figDesc><table><row><cell cols="2">example I MIS-pga2</cell><cell>Chortle-crf</cell><cell>Xrriap</cell><cell cols="2">Hydra I VISMAP'</cell><cell>xnfopt</cell></row><row><cell>z4ml</cell><cell>4</cell><cell>4</cell><cell>7</cell><cell>4</cell><cell>4</cell><cell>5</cell></row><row><cell>niisex 1</cell><cell>9</cell><cell>9</cell><cell>9</cell><cell>9</cell><cell>9</cell><cell>10</cell></row><row><cell>vF3</cell><cell>18</cell><cell>20</cell><cell>19</cell><cell>21</cell><cell>20</cell><cell>19</cell></row><row><cell>5xp 1</cell><cell>13</cell><cell>22</cell><cell>20</cell><cell>22</cell><cell>19</cell><cell>22</cell></row><row><cell>count</cell><cell>30</cell><cell>31</cell><cell>22</cell><cell>24</cell><cell></cell><cell>25</cell></row><row><cell>9symml</cell><cell>7</cell><cell>38</cell><cell>38</cell><cell>37</cell><cell>46</cell><cell>50</cell></row><row><cell>9sym</cell><cell>7</cell><cell>51</cell><cell>52</cell><cell>66</cell><cell>50</cell><cell>54</cell></row><row><cell>apex7</cell><cell>43</cell><cell>47</cell><cell>50</cell><cell>44</cell><cell>46</cell><cell>49</cell></row><row><cell>rd84</cell><cell>9</cell><cell>28</cell><cell>28</cell><cell>29</cell><cell>42</cell><cell>36</cell></row><row><cell>e64</cell><cell>56</cell><cell>48</cell><cell>55</cell><cell>47</cell><cell></cell><cell>62</cell></row><row><cell>C880</cell><cell>72</cell><cell>75</cell><cell>79</cell><cell>72</cell><cell>76</cell><cell>113</cell></row><row><cell>apex2</cell><cell>60</cell><cell>53</cell><cell>60</cell><cell>69</cell><cell></cell><cell>94</cell></row><row><cell>a1112</cell><cell>96</cell><cell>94</cell><cell>89</cell><cell>88</cell><cell></cell><cell>85</cell></row><row><cell>duke2</cell><cell>94</cell><cell>83</cell><cell>83</cell><cell>81</cell><cell>93</cell><cell>107</cell></row><row><cell>c499</cell><cell>66</cell><cell>83</cell><cell>57</cell><cell>63</cell><cell>49</cell><cell>81</cell></row><row><cell>rot</cell><cell>143</cell><cell>133</cell><cell>146</cell><cell>145</cell><cell>137</cell><cell>230</cell></row><row><cell>apex6</cell><cell>165</cell><cell>161</cell><cell>182</cell><cell>165</cell><cell>155</cell><cell>159</cell></row><row><cell>a1114</cell><cell>49</cell><cell>63</cell><cell>76</cell><cell>145</cell><cell></cell><cell>161</cell></row><row><cell>apex4</cell><cell>37 1</cell><cell>479</cell><cell>475</cell><cell>503</cell><cell></cell><cell>560</cell></row><row><cell>des</cell><cell>2</cell><cell>707</cell><cell>674</cell><cell>70 1</cell><cell></cell><cell>97 1</cell></row><row><cell>sa02</cell><cell>28</cell><cell>26</cell><cell>28</cell><cell>37</cell><cell>32</cell><cell>50</cell></row><row><cell>rd73</cell><cell>5</cell><cell>15</cell><cell>13</cell><cell>13</cell><cell>14</cell><cell>23</cell></row><row><cell>misex2</cell><cell>25</cell><cell>21</cell><cell>23</cell><cell>21</cell><cell>22</cell><cell>24</cell></row><row><cell>f5lm</cell><cell>15</cell><cell>25</cell><cell>22</cell><cell>17</cell><cell></cell><cell>25</cell></row><row><cell>clip</cell><cell>23</cell><cell>25</cell><cell>24</cell><cell>27</cell><cell></cell><cell>35</cell></row><row><cell>bw</cell><cell>27</cell><cell>31</cell><cell>29</cell><cell>29</cell><cell></cell><cell>38</cell></row><row><cell>b9</cell><cell>32</cell><cell>30</cell><cell>39</cell><cell>36</cell><cell>27</cell><cell>29</cell></row></table><note><p>'The starting networks were obtained by running the MIS script once and may differ from those used for other systems 2Merge could not finish.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Feasible Network; edges Results for Level Reduction: lev Number of Levels in the Feasible Network; nodes Number of Nodes in the number of Edges in the Feasible Network; and t Run Time in Seconds</figDesc><table><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.2</cell></row><row><cell>0.2</cell></row><row><cell>0.2</cell></row><row><cell>0.6</cell></row><row><cell>0.9</cell></row><row><cell>0.2</cell></row><row><cell>0.7</cell></row><row><cell>0.4</cell></row><row><cell>1.8</cell></row><row><cell>1.0</cell></row><row><cell>0.8</cell></row><row><cell>0.3</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>0.1</cell></row><row><cell>2.6</cell></row><row><cell>0.1</cell></row><row><cell>9.2</cell></row><row><cell>3.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>number of ACT-I Blocks: Number of ACT-1 Blocks; and t Run Time in Seconds</figDesc><table><row><cell>example z4ml</cell><cell>__ MIS n 19 ___ -</cell><cell>,ga2 9.4 t</cell><cell cols="2">MIS n 20</cell><cell>2.0</cell><cell>11 Ceres 17</cell><cell>AI n 20 --</cell><cell>Lp 2 0.8 --</cell><cell>MI! n 16 --</cell><cell>P!Pl 19.6 1</cell><cell>proserpine2 n</cell></row><row><cell>misexl</cell><cell>18</cell><cell>6.0</cell><cell>22</cell><cell></cell><cell>1.9</cell><cell>22</cell><cell>25</cell><cell>1.1</cell><cell>20</cell><cell>11.5</cell><cell>25</cell></row><row><cell>5xp 1 vg2</cell><cell>35 40</cell><cell>3.1 10.4</cell><cell>47 51</cell><cell></cell><cell>3.9 4.4</cell><cell>42 47</cell><cell>44 42</cell><cell>1.5 1.7</cell><cell>36 45</cell><cell>18.4 60.0</cell><cell>46 53</cell></row><row><cell>count</cell><cell>39</cell><cell>8.6</cell><cell>63</cell><cell></cell><cell>6.7</cell><cell>62</cell><cell>41</cell><cell>1.5</cell><cell>46</cell><cell>13.2</cell></row><row><cell>9symml</cell><cell>26</cell><cell>50.3</cell><cell>73</cell><cell></cell><cell>10.5</cell><cell>3</cell><cell>74</cell><cell>2.7</cell><cell>80</cell><cell>3123.8</cell></row><row><cell>9sym</cell><cell>26</cell><cell>55.8</cell><cell>99</cell><cell></cell><cell>14.1</cell><cell>136</cell><cell>106</cell><cell>4.1</cell><cell>119</cell><cell>17582.8</cell></row><row><cell>apex7</cell><cell>95</cell><cell>30.7</cell><cell>113</cell><cell></cell><cell>10.6</cell><cell>106</cell><cell>104</cell><cell>3.8</cell><cell>96</cell><cell>42.1</cell><cell>121</cell></row><row><cell>Cl908</cell><cell>168</cell><cell>121.5</cell><cell>188</cell><cell></cell><cell>19.3</cell><cell>192</cell><cell>158</cell><cell>7.6</cell><cell>175</cell><cell>646.5</cell></row><row><cell>rd84</cell><cell>50</cell><cell>30.7</cell><cell>62</cell><cell></cell><cell>6.5</cell><cell>61</cell><cell>62</cell><cell>2.6</cell><cell>61</cell><cell>151.4</cell><cell>70</cell></row><row><cell>e64</cell><cell>94</cell><cell>7.1</cell><cell>95</cell><cell></cell><cell>7.9</cell><cell>95</cell><cell>105</cell><cell>3.3</cell><cell>94</cell><cell>3.9</cell></row><row><cell>C880</cell><cell>169</cell><cell>36.1</cell><cell>175</cell><cell></cell><cell>18.2</cell><cell>177</cell><cell>190</cell><cell>7.2</cell><cell>171</cell><cell>77.2</cell></row><row><cell>apex2</cell><cell>112</cell><cell>36.7</cell><cell>106</cell><cell></cell><cell>11.8</cell><cell>175</cell><cell>122</cell><cell>5.0</cell><cell>124l</cell><cell>8.3</cell></row><row><cell>a h 2</cell><cell>185</cell><cell>48.9</cell><cell>193</cell><cell></cell><cell>24.2</cell><cell>173</cell><cell>188</cell><cell>8.3</cell><cell>208</cell><cell>824.5</cell></row><row><cell>duke2</cell><cell>165</cell><cell>29.3</cell><cell>176</cell><cell></cell><cell>17.9</cell><cell>172</cell><cell>175</cell><cell>6.9</cell><cell>166</cell><cell>403.5</cell><cell>177</cell></row><row><cell>c499</cell><cell>166</cell><cell>55.5</cell><cell>174</cell><cell></cell><cell>17.8</cell><cell>166</cell><cell>136</cell><cell>7.0</cell><cell>166</cell><cell>35.3</cell><cell>170</cell></row><row><cell>rot</cell><cell>285</cell><cell>67.2</cell><cell>313</cell><cell></cell><cell>28.9</cell><cell>418</cell><cell>335</cell><cell>11.9</cell><cell>288</cell><cell>1071.8</cell><cell>465</cell></row><row><cell>apex6</cell><cell>282</cell><cell>76.6</cell><cell>360</cell><cell></cell><cell>34.4</cell><cell>441</cell><cell>392</cell><cell>15.0</cell><cell>289</cell><cell>255.5</cell><cell>396</cell></row><row><cell>alu4</cell><cell>121</cell><cell>19.8</cell><cell>149</cell><cell></cell><cell>31.6</cell><cell>326</cell><cell>160</cell><cell>6.1</cell><cell>132</cell><cell>145.9</cell><cell>350</cell></row><row><cell>des</cell><cell>1351</cell><cell>357.3</cell><cell>1571</cell><cell cols="2">756.6</cell><cell>1638</cell><cell>1634</cell><cell>67.2</cell><cell>1749l</cell><cell>762.9</cell></row><row><cell>sa02</cell><cell>51</cell><cell>24.4</cell><cell>52</cell><cell></cell><cell>8.0</cell><cell>86</cell><cell>56</cell><cell>2.0</cell><cell>62</cell><cell>54.2</cell></row><row><cell>rd73</cell><cell>30</cell><cell>12.1</cell><cell>32</cell><cell></cell><cell>2.7</cell><cell>32</cell><cell>32</cell><cell>1.6</cell><cell>31</cell><cell>37.2</cell></row><row><cell>misex2</cell><cell>40</cell><cell>3.5</cell><cell>46</cell><cell></cell><cell>4.3</cell><cell>42</cell><cell>47</cell><cell>1.5</cell><cell>41</cell><cell>6.1</cell><cell>45</cell></row><row><cell>f51m</cell><cell>44</cell><cell>14.4</cell><cell>52</cell><cell></cell><cell>5.2</cell><cell>54</cell><cell>56</cell><cell>2.2</cell><cell>48</cell><cell>36.6</cell><cell>63</cell></row><row><cell>clip</cell><cell>48</cell><cell>25.1</cell><cell>57</cell><cell></cell><cell>4.9</cell><cell>62</cell><cell>60</cell><cell>2.5</cell><cell>51</cell><cell>91.9</cell><cell>73</cell></row><row><cell>bw</cell><cell>60</cell><cell>11.7</cell><cell>81</cell><cell></cell><cell>7.1</cell><cell>61</cell><cell>83</cell><cell>3.6</cell><cell>65</cell><cell>20.1</cell><cell>67</cell></row><row><cell>b9</cell><cell>66</cell><cell>19.7</cell><cell>64</cell><cell></cell><cell>5.9</cell><cell>101</cell><cell>81</cell><cell>2.7</cell><cell>65</cell><cell>31.6</cell></row><row><cell>C5315</cell><cell>59 1</cell><cell>359.8</cell><cell>704</cell><cell></cell><cell>88.0</cell><cell>725</cell><cell>653</cell><cell>26.9</cell><cell>656</cell><cell>673.1</cell></row></table><note><p>'Used "act-map-n2-h2-d4-f3-gO.001" and "act-map-h3-M4" since the default command timed out. *Starting networks differ from other systems. 'Segmentation fault.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PROCEEDINGS OF THE IEEE, VOL. 81,NO. 7, JULY 1993   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>8Note that MIS-pga2 doea not extract a forest of trees to perform the mapping as Chortle-crf does. Instead, it uses the heuristic to decompose infeasible nodes of the Boolean network.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>PROCEEDlNGS OF THE IEEE, VOL. 81.NO 7. JULY 1993   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>PROCEEDINGS OF THE IEEE, VOL. 81, NO. 7. JULY 1993</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>The authors would like to thank R. Murgai, N. Shenoy and Dana How for editorial help and useful comments on an earlier version of the paper. This work is partially supported by DARPA under contract numbers J-FBI-90-073 (for the first author) and J-FBI-89-101 (for the second author).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conference, 1991, pp. 24&amp;243.</p><p>[29] K. Keutzer, "Dagon: Technology binding and local optimization by DAG matching," in Proc. Design Automation Conference,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multilevel synthesis minimizing the routing factor</title>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abouzeid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakoutan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Saucier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Poirot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automution Conference</title>
		<meeting>Design Automution Conference</meeting>
		<imprint>
			<publisher>ACM-IEEE</publisher>
			<date type="published" when="1990-06">June 1990</date>
			<biblScope unit="page" from="365" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Principles of Compiler Design</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Aho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>NewYork</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The decomposition of switching functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Ashenhurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Theory of Switching Functions</title>
		<meeting>Int. Symp. Theory of Switching Functions</meeting>
		<imprint>
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bold: A multi-level logic optimization system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bostick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lightner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moceyunas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ravenscroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Computer-Aided Design</title>
		<meeting>Int. Conf. Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A new technology mapping algorithm for the design and evaluation of electrically programmable gate arrays</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bedarida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ercolani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Demicheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in 1st Int. ACM/SIGDA Workshop on FPGAs</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Yorktown silicon compiler</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcmullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Otten</surname></persName>
		</author>
		<idno>ISCAS-85</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Symp. Circ. Syst</title>
		<meeting>Int. Symp. Circ. Syst</meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="391" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Logic Minimization Algorithms for VLSI Synthesis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcmullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">MIS: A multiple-level logic optimization system</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rudell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="1062" to="1081" />
		</imprint>
		<respStmt>
			<orgName>IEEE Trans. Computer-Aided Design</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-level logic synthesis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Hachtel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990-02">Feb. 1990</date>
			<biblScope unit="page" from="264" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Graph based algorithms for. Boolean function manipulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bryant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>IEEE Trans. Computers</publisher>
			<biblScope unit="page">667491</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph based fpga technology mapping for delay optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Trajmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">1st Int. ACM/SIGDA Workshop on FPGAs</title>
		<imprint>
			<date type="published" when="1984">1992. 1984</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A generalized tree circuit</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Curtis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LSS: A System for Production Logic Synthesis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Darringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Joyner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gerbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Trevillyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Development</title>
		<imprint>
			<biblScope unit="page" from="537" to="545" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance oriented synthesis of large scale domino CMOS circuits</title>
		<author>
			<persName><forename type="first">G</forename><surname>Demicheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer-Aided Design</title>
		<imprint>
			<biblScope unit="page" from="751" to="765" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Statistical properties of the placement of a graph</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Donath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">439457</biblScope>
			<date type="published" when="1968-04">Apr. 1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The transient response of damped linear networks with particular regard to wideband amplifiers</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Elmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Phys</title>
		<imprint>
			<biblScope unit="page" from="5" to="5" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Technology mapping electrically programmable gate arrays</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ercolani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Demicheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Con</title>
		<meeting>Design Automation Con</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="234" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Technology mapping for a two-output ram-based field-programmable gate arrays</title>
		<author>
			<persName><forename type="first">D</forename><surname>Filo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mailhot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Micheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Design Automation Conf</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="534" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chortle: A technology mapping program for lookup table-based field. programmable gate arrays</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Con$</title>
		<meeting>Design Automation Con$</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="61" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Chortle-crf: Fast technology mapping for lookup table-based fpgas</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vranesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Con</title>
		<meeting>Design Automation Con</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="227" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Technology mapping of lookup table-based fpgas for performance</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vranesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Computer-Aided Design</title>
		<meeting>Int. Con$ Computer-Aided Design</meeting>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page" from="568" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-level logic minimization based on minimal support and its application to the minimization of look-up table type fpgas</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inr. Con$ Computer-Aided Design</title>
		<meeting>Inr. Con$ Computer-Aided Design</meeting>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Inrractabilify</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>W. H. Freeman and Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Socrates: A system for automatically synthesizing and optimizing combinational logic</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gaitanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Conference</title>
		<meeting>Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="1978">1986. Nov. 1978</date>
			<biblScope unit="page" from="1064" to="1068" />
		</imprint>
	</monogr>
	<note>Irredundant normal forms and minimal dependence sets of a boolean function</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Minimization over Boolean graphs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in IBM J. Res. and Development</title>
		<imprint>
			<date type="published" when="1962-04">Apr. 1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Amap: A technology mapper for selector-based field-prorammable gate arrays</title>
		<author>
			<persName><forename type="first">K</forename><surname>Karplus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Conf</title>
		<meeting>Design Automation Conf</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="244" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Xmap: A technology mapper for table-lookup field-programmable gate arrays</title>
		<author>
			<persName><forename type="first">K</forename><surname>Karplus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation</title>
		<meeting>Design Automation</meeting>
		<imprint>
			<biblScope unit="page" from="79" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">1082 PROCEEDINGS OF THE IEEE</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">X I</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Clustering to minimize delay in digital networks</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lawler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Levitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="page" from="47" to="57" />
			<date type="published" when="1969">1987. Jan. 1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Technology mapping using boolean matching and don&apos;t care sets</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mailhot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Demicheli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Design Automation Conf</title>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="2120" to="2216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Three-level decomposition with application to plds</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Computer Design</title>
		<meeting>Int. Con$ Computer Design</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page">628433</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Universal logic design algorithm and its application to the synthesis of two-level switching circuits</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mathony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proc</title>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ALFA: Automatic library generation for logic module based FPGA&apos;s,&quot; in 1st Int</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mehendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wilmoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACMNGDA Workshop on FPGAs</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">An improved synthesis algorithm for multiplexor-based PGAs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<editor>1st Inr</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>ACM/SIGDA Workshop on FPGAs</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sequential synthesis for table look up PGA&apos;s</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Euro ASIC</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Logic synthesis for programmable gate arrays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nishizaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">inProc. Design Automation Conf</title>
		<imprint>
			<biblScope unit="page" from="620" to="625" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improved logic synthesis algorithms for table look up architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Computer-Aided Design</title>
		<meeting>Int. Con$ Computer-Aided Design</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Performance directed synthesis for table look up pragrammable gate arrays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Murgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf Computer-Aided Design</title>
		<meeting>Int. Conf Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="572" to="575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Layout Driven Logic Restructur-ingDecomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf Computer-Aided Design</title>
		<meeting>Int. Conf Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="134" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Layout driven technology mapping</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pedram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Con</title>
		<meeting>Design Automation Con</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A classification and survey of field-programmable gate array architectures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">El</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1993-07">July 1993</date>
			<biblScope unit="volume">81</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Rubinsein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Penfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Horowitz</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="564" to="567" />
		</imprint>
	</monogr>
	<note>signal delay in 1991</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">SYNTHESIS METHODS FOR GATE ARRAYS 1 1 -rc tree networks</title>
		<author>
			<persName><surname>El Gamal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. CAD</title>
		<imprint>
			<biblScope unit="page" from="119" to="127" />
			<date type="published" when="1983-07">July 1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Logic Synthesis for V U 1 Design</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rudell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<pubPlace>Berkeley</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Timing optimization with testability considerations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saldanha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kwang-Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Computer-Aided Design</title>
		<meeting>Int. Con$ Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="4" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the complexity of Three-Level Logic Circuits</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sasao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MCNC Int. Workshap on Logic Synthesis</title>
		<meeting>MCNC Int. Workshap on Logic Synthesis<address><addrLine>Research Triangle Park, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989-05">May 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Boolean Matching in Logic Synthesis</title>
		<author>
			<persName><forename type="first">'</forename><forename type="middle">H</forename><surname>Savoj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Design Automation Con$</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="168" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Automatic synthesis of boolean functions on Xilinx. and actel programmable devices</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sicard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crastes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sakouti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Saucier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euro ASIC</title>
		<imprint>
			<date type="published" when="1991-05">May 1991</date>
			<biblScope unit="page" from="142" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Timing optimization of combinational logic</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Brayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Con$ Computer-Aided Design</title>
		<meeting>Int. Con$ Computer-Aided Design</meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="282" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A heuristic method for FPGA technology mapping based on edge visibility</title>
		<author>
			<persName><forename type="first">N-S</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Design Automation Con$, ACM-IEEE</title>
		<meeting>Design Automation Con$, ACM-IEEE</meeting>
		<imprint>
			<date type="published" when="1991-06">June 1991</date>
			<biblScope unit="page" from="248" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">ATOM: Technology Mapping of Sequential Circuits for Lookup Table-based FPGAs</title>
		<author>
			<persName><forename type="first">N-S</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conf</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Hamilton Ave</title>
		<imprint>
			<date type="published" when="2069">2069</date>
			<publisher>The Programmable Gate Array Book, Xilinx Inc</publisher>
			<pubPlace>San Jose, CA-95125</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Abbas</forename><surname>El</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gamal</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>phy please see the Prolog to the Special Section in this issue of the PROCEEDINGS</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">(</forename><surname>Member</surname></persName>
		</author>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>please see this issue of the PROCEEDINGS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
