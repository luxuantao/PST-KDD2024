<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and Memory-E icient Tucker Decomposition for Answering Diverse Time Range eries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jun-Gi</forename><surname>Jang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University Republic of Korea</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">U</forename><surname>Kang</surname></persName>
							<email>ukang@snu.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="institution">Seoul National University Republic of Korea</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast and Memory-E icient Tucker Decomposition for Answering Diverse Time Range eries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3447548.3467290</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tucker decomposition</term>
					<term>time range query</term>
					<term>e ciency</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given a temporal dense tensor and an arbitrary time range, how can we e ciently obtain latent factors in the range? Tucker decomposition is a fundamental tool for analyzing dense tensors to discover hidden factors, and has been exploited in many data mining applications. However, existing decomposition methods do not provide the functionality to analyze a speci c range of a temporal tensor. The existing methods are one-o , with the main focus on performing Tucker decomposition once for a whole input tensor. Although a few existing methods with a preprocessing phase can deal with a time range query, they are still time-consuming and su er from low accuracy. In this paper, we propose Z T , a fast and memory-e cient Tucker decomposition method for nding hidden factors of temporal tensor data in an arbitrary time range. Z T fully exploits block structure to compress a given tensor, supporting an e cient query and capturing local information. Z T answers diverse time range queries quickly and memory-e ciently, by elaborately decoupling the preprocessed results included in the range and carefully determining the order of computations. We demonstrate that Z T is up to 171.9Ã— faster and requires up to 230Ã— less space than existing methods while providing comparable accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>â€¢ Computing methodologies â†’ Factorization methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ğ€ (ğŸ‘)   ğ€ (ğŸ)   ğ€ (ğŸ)   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğ“–</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time dimension</head><p>Temporal tensor From Jan. <ref type="bibr" target="#b0">1,</ref><ref type="bibr">2008</ref> To May 6, 2020</p><formula xml:id="formula_0">â‘  â‘¡ â‘¢</formula><p>Tucker results for the time range query</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COVID-19</head><p>Start time -Jan. <ref type="bibr" target="#b0">1,</ref><ref type="bibr">2020</ref> End time -Apr. <ref type="bibr" target="#b29">30</ref>, 2020</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given Given Goal</head><p>A time range query Tensor decomposition has played an important role in various applications including data clustering <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref>, concept discovery <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, dimensionality reduction <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36]</ref>, anomaly detection <ref type="bibr" target="#b17">[18]</ref>, and link prediction <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>. Tucker decomposition, one of the tensor decomposition methods, has been recognized as a crucial tool for discovering latent factors and detecting relations between them.</p><p>In practice, we analyze a given temporal tensor from various perspectives. Assume a user is interested in investigating patterns of various time ranges using Tucker decomposition. Given a temporal tensor and a user-provided time range (start time and end time) query, our goal is to nd the patterns of the temporal tensor at the range using Tucker decomposition. For example, given a temporal tensor including matrices collected between Jan. 1, 2008 to May 6, 2020, a user may be interested in Tucker decomposition of a subrange between Jan. 1, 2020 to April 30, 2020 (see Figure <ref type="figure" target="#fig_0">1</ref>). Since Tucker decomposition generates factor matrices and a core tensor to accurately approximate an input tensor, answering time range queries, (i.e., performing Tucker decomposition of di erent sub-tensors) yields di erent Tucker results. However, conventional Tucker decomposition methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref> based on Alternating Least Square (ALS) is not appropriate for answering diverse time range queries since they target performing Tucker decomposition once for a given tensor; the methods require a high computational cost and large storage space since they need to perform Tucker decomposition of the sub-tensor included in a time range query from scratch, every time the query is given. Due to this limitation, the existing methods are not e cient in exploring diverse time ranges for a given temporal tensor.</p><p>A few methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref> with a preprocessing phase can be adapted to the time range query problem; before the query phase, they preprocess a given tensor, and perform Tucker decomposition with the preprocessed tensor for each time range query. However, they su er from an accuracy issue for narrow time ranges since preprocessed results are tailored for performing Tucker decomposition of the whole given temporal tensor. The results fail to capture local patterns that appear only in a speci c range.   In this paper, we propose Z T (Zoomable Tucker decomposition), a fast and memory-e cient Tucker decomposition method to analyze a temporal tensor for diverse time ranges. Z T enables us to discover local patterns in a narrow time range (zoom-in), or global patterns in a wider time range (zoomout). Z T consists of two phases: the preprocessing phase and the query phase. The preprocessing phase of Z T exploits block structure to lay the groundwork in achieving an e cient query phase and capturing local information. In the query phase, Z T addresses the high computational cost and space cost by elaborately decoupling block results and carefully determining the order of computation. Thanks to these ideas, Z T answers an arbitrary time range query with higher e ciency than existing methods. Through extensive experiments, we demonstrate the e ectiveness and e ciency of our method compared to other methods. The main contributions of this paper are as follows:</p><formula xml:id="formula_1">X &lt;i &gt; i-th temporal block tensor (âˆˆ I 1 Ã— ...I N âˆ’1 Ã— b) A &lt;i &gt; (k ) k -th</formula><p>â€¢ Algorithm. We propose Z T , a fast and memorye cient Tucker decomposition method for answering diverse time range queries.</p><p>â€¢ Analysis. We provide both time and space complexities for the preprocessing and query phases of Z T .</p><p>â€¢ Experiment. Experimental results show that Z T answers time range queries up to 171.9Ã— faster and requires up to 230Ã— less space than other methods while providing comparable accuracy, as shown in Figures <ref type="figure" target="#fig_13">2 and 6</ref>.</p><p>â€¢ Discovery. Thanks to Z T , we discover anomalous ranges and trend changes in Stock dataset (Figures <ref type="figure" target="#fig_16">8  and 9</ref>). The code of our method and datasets are available at https: //datalab.snu.ac.kr/zoomtucker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>We describe preliminaries on tensor operations and Tucker decomposition, and then de ne the problem addressed in this paper (Section 2.3). The symbols we use in this paper are described in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tensor and Its Operation</head><p>A tensor is a multi-dimensional array. Each dimension of a tensor is called mode. The length of each mode is called dimensionality and denoted by I 1 , â€¢ â€¢ â€¢ , I N . In this paper, a vector, a matrix, and an N -mode tensor are denoted by the boldface lower case (e.g. a), boldface capitals (e.g. A), and boldface Euler script capital (e.g. X âˆˆ R I 1 Ã—I 2 Ã—â€¢â€¢â€¢Ã—I N ), respectively. Key operations for tensor include Frobenius norm, Kronecker product, mode-n matricization, and n-mode product. We refer the reader to <ref type="bibr" target="#b16">[17]</ref> for their de nitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tucker Decomposition</head><p>Tucker decomposition transforms an N -order tensor X âˆˆ R I 1 Ã—...Ã—I N into a core tensor G âˆˆ R 1 Ã—...Ã— N and factor matrices A (n) âˆˆ R I n Ã— n for n = 1, ..., N . Factor matrices A (n) are column-orthogonal, and a core tensor G is small and dense. Each factor matrix A (n) represents the latent features of the n-th mode of X, and each element of a core tensor G is the weight of the relation composed of columns of factor matrices. Given a tensor X, the goal of Tucker decomposition is to obtain factor matrices A (n) and the core tensor G by minimizing</p><formula xml:id="formula_2">X âˆ’ G Ã— 1 A (1) â€¢ â€¢ â€¢ Ã— N A (N ) 2</formula><p>F as shown in the following equations:</p><formula xml:id="formula_3">X â‰ˆ G Ã— 1 A (1) â€¢ â€¢ â€¢ Ã— N A (N ) â‡” X (n) â‰ˆ A (n) G (n) (âŠ— N k n A (k )T ) (1) Note that X (n) indicates the mode-n matricized version of X, G (n)</formula><p>indicates the mode-n matricized version of G, and (âŠ— N k n A (k)T ) indicates performing the entire Kronecker product of A (k)T in descending order for k = N , ..., n + 1, n âˆ’ 1, ..., 1.</p><p>ALS (Alternating Least Square) is a common approach for Tucker decomposition as described in Appendix A. ALS approach iteratively updates a factor matrix of a mode while xing all factor matrices of other modes. For updating each factor matrix A (n) , a dominant operation is to compute n-mode products between an input tensor X (âˆˆ I 1 Ã— ... Ã— I N ) and factor matrices</p><formula xml:id="formula_4">A (k ) (âˆˆ I k Ã— k ) for k = N , ..., n + 1, n âˆ’ 1, ..., 1 (line 4 of Algorithm 3). Computing X (n) (âŠ— N k n A (k )</formula><p>), the mode-n matricized version of the dominant operation, takes O( N i=1 I i ) time where X (n) is the mode-n matricized version of X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Problem De nition</head><p>We describe the formal de nition of the time range query problem as follows: P 1 (T R T T ). Given: a temporal dense tensor X âˆˆ R I 1 Ã—I 2 â€¢â€¢â€¢Ã—I N and a time range [t s , t e ] where I N is the length of the time dimension, and I n is the dimensionality of mode-n for n = 1, ..., N âˆ’ 1, Find: the Tucker results of the sub-tensor X of X in the time range [t s , t e ] e ciently. The Tucker result includes factor matrices Ãƒ(1) , ..., Ãƒ(N ) , and core tensor G.</p><p>To address the time range query problem, a method should eciently handle various time range queries. Given an arbitrary time range query, existing methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref> performing Tucker decomposition from scratch requires a high computational cost and large space cost. Compared to the aforementioned methods, Tucker decomposition methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref> with a preprocessing phase save time and space costs in that they allow us to compress a whole tensor before a query phase, and then perform Tucker decomposition of a sub-tensor corresponding to a given time range query by exploiting the compressed tensor instead of the input tensor. However, they are still unsatisfactory in terms of time, space, and accuracy for the time range query problem since they are tailored for performing Tucker decomposition of only the whole tensor once. We address the challenges with the following main ideas:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED METHOD</head><formula xml:id="formula_5">Algorithm 1: Preprocessing phase of Z T Input: temporal tensor X âˆˆ R I 1 Ã—I 2 Ã—â€¢â€¢â€¢Ã—I N âˆ’1 Ã—I N Output: result sets C n for n = 1, ..., N + 1 Parameters: block size b 1: compute the number B = I N b of blocks 2: split X into block tensors X &lt;i &gt; âˆˆ R I 1 Ã—. . .Ã—b for i = 1, ..., B 3: for i â† 1 to B do 4: perform Tucker decomposition of X i â‰ˆ G &lt;i &gt; Ã— 1 (A &lt;i &gt; ) (1) â€¢ â€¢ â€¢ Ã— N (A &lt;i &gt; ) (N ) 5:</formula><p>store each factor matrices (A &lt;i &gt; ) (n) in the results set C n , for n = 1, ..., N 6:</p><p>store core tensor G &lt;i &gt; in the result set C N +1 7: end for I1 Exploiting block structure enables a query phase to decrease the number of operations and memory requirements, while capturing local information. I2 Elaborately decoupling block results decreases the computational cost of Tucker decomposition for a tensor obtained in a given time range. I3 Carefully determining the order of computation minimizes intermediate data generation while avoiding redundant computation. Z T e ciently computes Tucker decomposition for various time range queries. Z T consists of two phases: the preprocessing phase and the query phase. The preprocessing phase is computed once for a given temporal tensor, while the query phase is computed using the results of the preprocessing phase for each time range query. Z T compresses a given tensor block by block along the time dimension in the preprocessing phase. Z T performs Tucker decomposition for each block. In the query phase, Z T performs Tucker decomposition for each time range query by 1) adjusting the rst and the last blocks included in the time range to t the range and 2) carefully stitching the block results in the time range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preprocessing Phase</head><p>The objective of the preprocessing phase is to manipulate a given temporal tensor for an e cient query phase. In the query phase, performing Tucker decomposition from scratch requires high computational cost and large space cost as the number of queries increases. To avoid it, compressing a given tensor is inevitable to provide fast processing in the query phase. Additionally, we consider that compressed results need to contain local patterns that appear only in speci c ranges. The preprocessing phase of existing Tucker decomposition methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35]</ref> fails to support high e ciency of the query phase while maintaining local patterns. Then, how can we compress a given tensor to deal with various time range queries? Our main idea is to exploit a block structure: 1) carefully designating the form of a block, and 2) selecting a compression approach for each block. In this paper, we 1) split a given temporal tensor into sub-tensors along the time dimension, and 2) leverage Tucker decomposition for each sub-tensor. The idea allows Z T to support an e cient query phase and capture local patterns. Additionally, the preprocessing phase is extensible for new incoming tensors by performing Tucker decomposition of them.</p><p>To capture local information, we split a given tensor along the time dimension. Let the reconstruction error at each timestep t be  <ref type="table" target="#tab_4">2 0 0 9 2 0 1 1 2 0 1 3 2 0 1 5 2 0 1 7 2 0 2</ref>  </p><formula xml:id="formula_6">X(t )âˆ’ X(t ) 2 F X(t ) 2 F</formula><p>where X(t) is an input sub-tensor obtained at each timestep t and X(t) is the sub-tensor at timestep t reconstructed from Tucker results. Figure <ref type="figure" target="#fig_3">3</ref> shows the reconstruction errors of Stock dataset at each time point. Given a sub-tensor in a range that has relatively high errors, performing Tucker decomposition of the sub-tensor (orange line in Figure <ref type="figure" target="#fig_3">3</ref>) provides lower errors than the preceding result computed from a whole temporal tensor (blue line in Figure <ref type="figure" target="#fig_3">3</ref>). This observation implies that decomposing a sub-tensor allows us to capture local information, leading to low errors. Based on the observation, we construct sub-tensors by splitting a temporal tensor along the time dimension and perform Tucker decomposition of each sub-tensor. It provides lower error than performing Tucker decomposition of a whole tensor on all the timesteps, by capturing local information.</p><p>To support an e cient query phase, we store the Tucker decomposition results of sub-tensors. There are the two bene ts to leveraging Tucker decomposition in the preprocessing phase: 1) saving the space cost due to the small preprocessed results compared to the given tensor, and 2) enabling the query phase to exploit the mixedproduct property applicable to mixing matrix multiplication and Kronecker product, i.e., (</p><formula xml:id="formula_7">A T âŠ— B T )(C âŠ— D) = (A T C âŠ— B T D). Computing (A T C âŠ— B T D) requires less costs than computing (A T âŠ— B T )(C âŠ— D)</formula><p>when the size of the four matrices is I Ã— and I &gt;&gt; . The reason is that the size of A T C and B T D is only Ã— while the size of (A T âŠ— B T ) and (C âŠ— D) is 2 Ã— I 2 and I 2 Ã— 2 , respectively. We further present the exploitation of this property to achieve high e ciency of the query phase in Sections 3.2.3 and 3.2.4.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> presents an overview of the preprocessing phase. Without loss of generality, we assume that the temporal mode is the last mode (N th mode). We express a given tensor X as temporal block tensors</p><formula xml:id="formula_8">X &lt;i &gt; âˆˆ R I 1 Ã—I 2 Ã—â€¢â€¢â€¢Ã—I N âˆ’1 Ã—b for i = 1, ..., I N b (line 2 in Algo- rithm 1)</formula><p>where b is a block size and I N is the dimensionality of the time dimension. Then, we perform Tucker decomposition for each temporal block tensor X &lt;i &gt; (line 4 in Algorithm 1), and store each factor matrix (A &lt;i &gt; ) (n) in a set C n and the core tensor G &lt;i &gt; in a set C N +1 (lines 5 and 6 in Algorithm 1). Since the preprocessing phase is computed once and a ects errors of the query phase, this phase prefers an accurate but slow Tucker decomposition method rather than a fast but approximate Tucker decomposition one. Speci cally, we use Tucker-ALS, which is stable and accurate, in this phase.</p><formula xml:id="formula_9">ğ€ "ğŸ$ (ğŸ) ğ‘ ğ‘ ğ‘ Tucker result of ğ“§ "ğŸ$ Tucker result of ğ“§ "ğŸ$ Tucker result of ğ“§ "ğŸ‘$ ğ“§ "ğŸ$ ğ“§ "ğŸ$ ğ“§ "ğŸ‘$ Time ğ€ "ğŸ$ (ğŸ) ğ“– "ğŸ$ ğ€ "ğŸ$ (ğŸ‘)</formula><p>ğ€ "ğŸ$ (ğŸ)</p><p>ğ€ "ğŸ$ (ğŸ)</p><p>ğ€ "ğŸ$ (ğŸ‘)</p><p>ğ“– "ğŸ$ ğ€ "ğŸ‘$ (ğŸ)</p><p>ğ€ "ğŸ‘$ (ğŸ)</p><p>ğ“– "ğŸ‘$ ğ€ "ğŸ‘$ (ğŸ‘) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Phase</head><p>The objective of the query phase is to e ciently compute Tucker decomposition for a given time range [t s , t e ]. The query phase of Z T operates as follows: S1. Given a time range [t s , t e ], we load Tucker results (i.e., G &lt;i &gt; , (A &lt;i &gt; ) (n) ) of temporal block tensors X &lt;i &gt; for i = S, ..., E where S = t s b and E = t e b are the indices of the rst and the last temporal block tensors including t s and t e , respectively. S2. We adjust the Tucker results of X &lt;S &gt; and X &lt;E &gt; to t the range since a part of them may not be within the given range. S3. Given the Tucker results of X &lt;i &gt; for i = S, .., E included in the range, Z T updates factor matrices by eciently stitching the Tucker results. S4. After that, Z T updates the core tensor using factor matrices updated at Step S3 and the Tucker results. S5. Z T repeatedly performs Steps S3 and S4 until convergence.</p><p>The most important challenge of the e cient query phase is how to minimize the computational cost for updating factor matrices (Step S3) and the core tensor (Step S4) of the time range while minimizing the intermediate data. To tackle the challenge, our main ideas are to 1) elaborately decouple X(n) âŠ— N k n Ãƒ(k)T based on preprocessed results, and 2) carefully determine the order of computation. We rst give an objective function and an update rule for the query phase (Section 3.2.1). Then, we describe how to achieve high e ciency of Z T in detail (Sections 3.2.2 to 3.2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Objective function and update rule.</head><p>In the query phase, our goal is to obtain factor matrices Ãƒ(1) , ..., Ãƒ(N ) , and core tensor G for a given time range query [t s , t e ]. The query phase of Z T alternately updates factor matrices, and core tensor as in ALS. We minimize the following objective function as mode-n matricized form for a time range [t s , t e ]:</p><formula xml:id="formula_10">L (n) = X(n) âˆ’ Ãƒ(n) G(n) (âŠ— N k n Ãƒ(k)T ) 2 F (2)</formula><p>where X(n) is the mode-n matricized version of a tensor obtained in the time range [t s , t e ], and G(n) is the mode-n matricized version of G. From the objective function (2), we derive the following update rule for n-th factor matrix (see the proof in Appendix B.1): L 1 (U ). When xing all but the n-th factor matrix, the following update rule for the n-th factor matrix minimizes the objective function <ref type="bibr" target="#b1">(2)</ref>.</p><formula xml:id="formula_11">Ãƒ(n) â† X(n) âŠ— N k n Ãƒ(k) GT (n) C (n) âˆ’1<label>(3)</label></formula><p>where C (n) âˆˆ R n Ã— n of the n-th mode is given by  2: load (A &lt;i &gt; ) (k ) and G &lt;i &gt; for i = S , ..., E from C k for k = 1, ..., N + 1 3: obtain ( Ä€&lt;S &gt; ) (N ) and ( Ä€&lt;E &gt; ) (N ) by eliminating the rows of (A &lt;S &gt; ) (N ) and (A &lt;E &gt; ) (N ) excluded in the range 4:</p><formula xml:id="formula_12">C (n) = G(n) âŠ— N k n Ãƒ(k)T Ãƒ(k) GT (n)</formula><formula xml:id="formula_13">( Ä€&lt;S &gt; ) (N ) â†’ Q &lt;S &gt; R &lt;S &gt; , ( Ä€&lt;E &gt; ) (N ) â†’ Q &lt;E &gt; R &lt;E &gt; 5: (A &lt;S &gt; ) (N ) â† Q &lt;S &gt; , G &lt;S &gt; â† G &lt;S &gt; Ã— N R &lt;S &gt; , (A &lt;E &gt; ) (N ) â† Q &lt;E &gt; , and G &lt;E &gt; â† G &lt;E &gt; Ã— N R &lt;E &gt; 6: repeat 7: for k = 1...N âˆ’ 1 do 8:</formula><p>update Ãƒ(k) by computing Equation ( <ref type="formula" target="#formula_19">5</ref>) and orthogonalizing it with QR decomposition 9:</p><p>end for 10:</p><p>update Ãƒ(N ) by computing Equation ( <ref type="formula" target="#formula_27">7</ref>) and orthogonalizing it with QR decomposition 11:</p><p>update core tensor G by computing Equation (8) 12: until the variation of an error is less than Ïµ or the number of iterations is larger than the maximum number of iterations 13: return Ãƒ(k) for k = 1, ..., N and G</p><p>In contrast to naively computing Equation (3) with X(n) , Z T e ciently computes Equation ( <ref type="formula" target="#formula_11">3</ref>) by exploiting preprocessed results obtained in the preprocessing phase.</p><p>Before describing an e cient update procedure, we introduce a useful lemma (see the proof in Appendix B.2). L 2. Let S âˆˆ R Ã—...Ã— and S âˆˆ R Ã—...Ã— be N -order tensors, and U (n) and V (n) for n = 1, ..., n âˆ’ 1, n + 1, ..., N be matrices of size I Ã— . Assume our goal is to compute the following equation:</p><formula xml:id="formula_14">S (n) âŠ— N k n U (k )T V (k ) S T (n)<label>(4)</label></formula><p>where S (n) and S (n) are the mode-n matricized version of S and S , respectively. Naively computing Equation (4) by rst comput- For all n = 1, ..., N , C (n) is computed based on Lemma 2, by replacing S (n) , U (k ) , V (k ) , and S (n) with G(n) , Ãƒ(k) , Ãƒ(k) , and G(n) , respectively.</p><formula xml:id="formula_15">ing âŠ— N k n U (k )T V (k )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Adjusting edge blocks of time range query (Step S2</head><p>). Before updates, we adjust the Tucker results of X &lt;S &gt; and X &lt;E &gt; , the temporal block tensors corresponding to t s and t e of the given time range [t s , t e ], respectively. The temporal factor matrices (A &lt;S &gt; ) (N ) of X &lt;S &gt; and (A &lt;E &gt; ) (N ) of X &lt;E &gt; may contain the rows that are not included in the range (see Figure <ref type="figure" target="#fig_8">5(a)</ref>). To t to the given time range, we need to remove the non-included rows of (A &lt;S &gt; ) (N ) and (A &lt;E &gt; ) (N ) , and adjust the Tucker results of X &lt;S &gt; and X &lt;E &gt; .</p><p>Let p be S or E. For the temporal factor matrix (A &lt;p &gt; ) (N ) of X &lt;p &gt; in the range, Z T obtains the manipulated temporal factor matrix ( Ä€&lt;p&gt; ) (N ) by removing the rows of (A &lt;p &gt; ) (N ) that are not included in the time range (line 3 in Algorithm 2). Next, we perform QR decomposition to make ( Ä€&lt;p&gt; ) (N ) maintain as the temporal factor matrix of X &lt;p &gt; and update the core tensor ) where (Q &lt;p &gt; ) (N ) and (R &lt;p &gt; ) (N )  are the results of QR decomposition (line 5 in Algorithm 2).</p><formula xml:id="formula_16">ğ€ !"# (%) ğ’• ğ’” ğ‘¡ " + 1 â‹® ğ‘¡ # âˆ’ 1 ğ’• ğ’† ğ‘¡ " âˆ’ 1 â‹® ğ‘¡ # + 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of range</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out of range</head><formula xml:id="formula_17">â‹® ğ€ !"# (%) ğ€ !'# (%) (a) Example of adjustment ğ€ "(") ğ€ "(") [ğ‘†] ğ€ "(") [ğ‘–] ğ€ "(") [ğ¸] ğ‘¡ $ ğ‘¡ $ + 1 â‹® ğ‘¡ % âˆ’ 1 ğ‘¡ % â‹® (b) Example of division</formula><formula xml:id="formula_18">G &lt;p &gt; â† G &lt;p &gt; Ã— N (R &lt;p &gt; ) (N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">E icient update of factor matrices (Step S3</head><p>). We present how to e ciently update the factor matrix of the non-temporal modes and the temporal mode.</p><p>Updating factor matrix of non-temporal modes. Consider updating the n-th factor matrix, which corresponds to a non-temporal mode. A naive approach is to reconstruct X(n) from the Tucker results of the preprocessing phase and compute Equation (3). However, it requires large time and space costs since the reconstructed tensor is much larger than the preprocessed results. Our main ideas are to 1) elaborately decouple X(n) âŠ— N k n Ãƒ(k) block by block using the preprocessed results, and 2) carefully determine the order of computations, which signi cantly reduces time and space costs compared to the naive approach. We derive Equation <ref type="bibr" target="#b4">(5)</ref> in Lemma 3 to update Ãƒ(n) (see the proof in Appendix B.3). L 3 (U ).</p><p>Assume that X(n) is replaced with the preprocessed results (i.e., (A &lt;i &gt; ) (n)  and G &lt;i &gt; ). Then, the following equation is equal to Equation (3) in Lemma 1 for n-th mode:</p><formula xml:id="formula_19">Ãƒ(n) â† E i=S (A &lt;i &gt; ) (n) (B &lt;i &gt; ) (n) C (n) âˆ’1<label>(5)</label></formula><p>where the i-th block matrix (B &lt;i &gt; ) (n) of the n-th mode is</p><formula xml:id="formula_20">(B &lt;i &gt; ) (n) = G &lt;i &gt; (n) (A &lt;i &gt; ) (N )T Ãƒ(N ) [i] âŠ— âŠ— N âˆ’1 k n (A &lt;i &gt; ) (k )T Ãƒ(k) GT (n) ,<label>(6)</label></formula><p>and</p><formula xml:id="formula_21">C (n) is de ned in Lemma 1. (A &lt;i &gt; ) (k )</formula><p>is the k-th factor matrix of the temporal block tensor X &lt;i &gt; , and G &lt;i &gt; (n) is the mode-n matricized version of the core tensor of X &lt;i &gt; . Ãƒ(N ) [i] is a sub-matrix of the temporal factor matrix Ãƒ(N ) such that,</p><formula xml:id="formula_22">ï£® ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£° Ãƒ(N ) [S]</formula><p>. . . where r S and r E are the number of the rows removed with respect to t s and t e , respectively.</p><formula xml:id="formula_23">Ãƒ(N ) [E] ï£¹ ï£º ï£º ï£º ï£º ï£º ï£» = Ãƒ(N ) To compute (A &lt;i &gt; ) (N )T Ãƒ(N ) [i], we split Ãƒ(N ) into sub-matrices Ãƒ(N ) [i] (i = S,</formula><p>Z T e ciently updates Ãƒ(n) with Equation ( <ref type="formula" target="#formula_19">5</ref>). Z T minimizes the intermediate data and reduces the high computational cost by independently computing C (n) and (B &lt;i &gt; ) (n)  for i = S, ..., E. Note that (B &lt;i &gt; ) (n) for i = S, ..., E is computed based on Lemma 2, by replacing S (n) , U (k ) , V (k) , and S (n) with</p><formula xml:id="formula_24">G &lt;i &gt; (n) , (A &lt;i &gt; ) (k ) , Ãƒ(k) (or Ãƒ(N ) [i]</formula><p>), and G(n) , respectively. Next, we obtain Ãƒ(n) by summing up the results of (A &lt;i &gt; ) (n) </p><formula xml:id="formula_25">(B &lt;i &gt; ) (n) C (n) âˆ’1</formula><p>for i = S, ..., E. For orthogonalization, we then update</p><formula xml:id="formula_26">Ãƒ(n) â† Q(n) after QR decomposition Ãƒ(n) â†’ Q(n) R(n) (line 8 in Algorithm 2).</formula><p>Updating factor matrix of temporal mode. The goal is to update the factor matrix Ãƒ(N ) of the temporal mode by using the preprocessed results instead of X(N ) . Reconstructing X(N ) requires high space and time costs in Equation ( <ref type="formula" target="#formula_11">3</ref>). Based on our ideas used for the non-temporal modes, we e ciently update Ãƒ(N ) by computing Equation <ref type="bibr" target="#b6">(7)</ref> in Lemma 4 (see the proof in Appendix B.4). L 4 (U ). Assume that X(N ) is replaced with the preprocessed results (i.e., (A &lt;i &gt; ) (n)  and G &lt;i &gt; ). Then, the following equation is equal to Equation (3) in Lemma 1 for the temporal mode:</p><formula xml:id="formula_27">Ãƒ(N ) â† ï£® ï£¯ ï£¯ ï£¯ ï£¯ ï£¯ ï£° (A &lt;S &gt; ) (N ) (B &lt;S &gt; ) (N ) . . . (A &lt;E &gt; ) (N ) (B &lt;E &gt; ) (N ) ï£¹ ï£º ï£º ï£º ï£º ï£º ï£» C (N ) âˆ’1<label>(7)</label></formula><p>where the i-th matrix</p><formula xml:id="formula_28">(B &lt;i &gt; ) (N ) âˆˆ R N Ã— N for i = S, ..., E is (B &lt;i &gt; ) (N ) = G &lt;i &gt; (N ) âŠ— N âˆ’1 k =1 (A &lt;i &gt; ) (k )T Ãƒ(k) GT (N ) (A &lt;i &gt; ) (k )</formula><p>is the k-th factor matrix of X &lt;i &gt; , G &lt;i &gt; (N ) is the mode-N matricized version of the core tensor of X &lt;i &gt; , and</p><formula xml:id="formula_29">C (N ) is equal to G(N ) âŠ— N âˆ’1 k =1 Ãƒ(k)T Ãƒ(k) GT (N )</formula><p>. We obtain Ãƒ(N ) by using (C (N ) ) âˆ’1 , (A &lt;i &gt; ) (N ) , and (B &lt;i &gt; ) (N )  for i = S, ..., E. Z T e ciently updates Ãƒ(N ) by independently computing C (N ) and (B &lt;i &gt; ) (N ) for i = S, ..., E. (B &lt;i &gt; ) (N )  is e ciently computed based on Lemma 2, by replacing S (n) , U (k ) , V (k) , and S (n) with G &lt;i &gt; (N ) , (A &lt;i &gt; ) (k ) , Ãƒ(k) , and G(N ) , respectively. For orthogonalization, we update</p><formula xml:id="formula_30">Ãƒ(N ) â† Q(N ) after QR decom- position Ãƒ(N ) â†’ Q(N ) R(N ) (line 10 in Algorithm 2).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">E icient update of core tensor (Step S4). At the end of each iteration, Z</head><p>T updates the core tensor using the factor matrices:</p><formula xml:id="formula_31">G(N ) â† Ãƒ(N )T X(N ) âŠ— N âˆ’1 k =1 Ãƒ(k) (mode-N matricization</formula><p>of line 8 in Algorithm 3). We e ciently compute the core tensor by avoiding reconstruction of X(N ) and carefully determining the order of computation. We replace X(N ) with the preprocessed results and re ne the equation with block decoupling and the mixed-product property (see Equation <ref type="bibr" target="#b9">(10)</ref> in Appendix B.4).</p><formula xml:id="formula_32">G(N ) â† E i =S ( Ãƒ(N )T [i])(A &lt;i &gt; ) (N ) G &lt;i &gt; (N ) âŠ— N âˆ’1 k =1 (A &lt;i &gt; ) (k )T Ãƒ(k)<label>(8)</label></formula><p>With Equation ( <ref type="formula" target="#formula_32">8</ref>), Z T e ciently updates G, reducing the intermediate data and the computational cost. For each i, </p><formula xml:id="formula_33">Z T computes ( Ãƒ(N )T [i])(A &lt;i &gt; ) (N ) G &lt;i &gt; (N ) âŠ— N âˆ’1 k =1 (A &lt;i &gt; ) (k )T Ãƒ(k)</formula><formula xml:id="formula_34">I N âˆ’2 MN 2 ) O(l [ts ,te ] I N âˆ’2 ) Tucker-ALS O(l [ts ,te ] I N âˆ’1 MN ) O(l [ts ,te ] I N âˆ’1 ) MACH [35] O(Sl [ts ,te ] I N âˆ’1 MN ) O(Sl [ts ,te ] I N âˆ’1 ) RTD [5] O(l [ts ,te ] I N âˆ’1 MN ) O(l [ts ,te ] I N âˆ’1 ) Tucker-ts [25] O(l [ts ,te ] I N âˆ’1 N + MN I N ) O(l [ts ,te ] I N âˆ’1 + N I N ) Tucker-ttmts [25] O(l [ts ,te ] I N âˆ’1 N + MN I 2N âˆ’2 ) O(l [ts ,te ] I N âˆ’1 + N I N )</formula><p>after transforming it into n-mode products as in Equation ( <ref type="formula">1</ref>). After that, Z T obtains G(N ) by summing up the results and reshape it to the core tensor G (line 11 in Algorithm 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>We analyze the time and space complexities of Z T in the preprocessing phase and the query phase. We assume that I = I 1 = ... = I N âˆ’1 , and = 1 = ... = N . M is the number of iterations, l [t s ,t e ] = t e âˆ’ t s + 1 is the length of a time range query, N is the order of a given tensor, I is the dimensionality, b is the block size, B is the number of blocks, and is the rank. All proofs are summarized in Appendices B.5 to B.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time complexity.</head><p>We analyze computational cost of Z T in the preprocessing phase and the query phase. Space complexity. We provide analysis for the space cost of Z T in the preprocessing phase and the query phase.  ) + l [t s ,t e ] space in the query phase.</p><p>Table <ref type="table" target="#tab_3">2</ref> shows the time and space complexities of Z T and competitors for a given time range query [t s , t e ]. The time and space complexities of Z T mainly depend on I and l [t s ,t e ] . We also note that the block size b reduces the complexities of Z T . We compare the time and space complexities of Z T with those of the second-best method, D-Tucker. For both time and space complexities, the result of dividing the complexity of Z T by that of D-Tucker is N I N âˆ’3 b . Z T has better time and space complexities than D-Tucker since I N âˆ’3 b is larger than N in real-world datasets; for example, in the experiments, we use 50 as the default block size b while the order of the real-world datasets is 3 or 4. As b increases, the space complexity of the preprocessing and the query phases, and the time complexity of the query phase decrease; however, a large block size b can provoke a high reconstruction error for a narrow time range query since the preprocessing phase with the large b cannot capture local information. In Section 4.4, we experimentally nd a block size that enables the preprocessing phase to capture local information with low reconstruction errors for narrow time range queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head><p>We present experimental results to answer the following questions. Q1 Performance Trade-o (Section 4.2). Does Z T provide the best trade-o between query time and reconstruction error? Q2 Space Cost (Section 4.3). What is the space cost of Z T and competitors for preprocessed results? Q3 E ects of the block size b (Section 4.4). How does a block size b a ect query time and reconstruction error of Z T ? Q4 Discovery (Section 4.5). What pattern does Z T discover in di erent time ranges?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Machine. We run experiments on a workstation with a single CPU (Intel Xeon E5-2630 v4 @ 2.2GHz), and 512GB memory.</p><p>Dataset. We use six real-world dense tensors in Table <ref type="table" target="#tab_4">3</ref>. Boats<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b36">[37]</ref> and Walking Video<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b24">[25]</ref> datasets contain grayscale videos in the form of (height, width, time; value). Stock dataset<ref type="foot" target="#foot_2">3</ref> contains 5 basic features (open price, high price, low price, close price, trade volume) and 49 technical indicators features of Korea Stocks. Stock dataset has the form of (stock, features, date; value). The basic features are collected daily from Jan. 2, 2008 to May 6, 2020. Tra c dataset<ref type="foot" target="#foot_3">4</ref>  <ref type="bibr" target="#b29">[30]</ref> contains tra c volume information in the form of (sensor, frequency, time; measurement). FMA dataset <ref type="foot" target="#foot_4">5</ref> [8] contains music information: (song, frequency, time; value). We convert a time series into an image of a log-power spectrogram for each song. Absorb dataset<ref type="foot" target="#foot_5">6</ref> is about absorption of aerosol in the form of (longitudes, latitudes, altitude, time; measurement).</p><p>Competitors. We compare Z T with 6 Tucker decomposition methods based on ALS approach. Z T and other methods are implemented in MATLAB (R2019b). We use the open sourced codes for 4 competitors: D-Tucker<ref type="foot" target="#foot_6">7</ref> , Tucker-ALS <ref type="bibr" target="#b2">[3]</ref>, Tucker-ts <ref type="foot" target="#foot_7">8</ref> , and Tucker-ttmts 8 . For MACH, we run Tucker-ALS in Tensor Toolbox <ref type="bibr" target="#b2">[3]</ref> for a sampled tensor after sampling elements of a tensor; we use our implementation for a sampling scheme. We use the source code of RTD <ref type="bibr" target="#b4">[5]</ref> provided by the authors.</p><p>Parameters. The parameter settings used for experiments are described in Appendix C. Implementation details. In the time range query problem, Z T , D-Tucker, and MACH preprocess a given tensor, and then perform Tucker decomposition for a time range query using preprocessed results included in the range. In contrast, Tucker-ALS Space Cost (MB)</p><formula xml:id="formula_35">! Ã— $% Ã— &amp;'( Ã— )* Ã— ') Ã—</formula><p>). ,Ã— and RTD perform Tucker decomposition using a sub-tensor included in a time range query. Although Tucker-ts and Tucker-ttmts have a preprocessing phase, they also perform Tucker decomposition from scratch for a time range query since there is an inseparable preprocessed result along the time dimension.</p><p>Reconstruction error. Given an input tensor X and the reconstruction X from the output of Tucker decomposition, reconstruction error is de ned as</p><formula xml:id="formula_36">Xâˆ’ X 2 F X 2 F</formula><p>. Reconstruction error describes how well the reconstruction X of Tucker decomposition represents an input tensor X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Trade-o between Query Time and Reconstruction Error (Q1)</head><p>We compare the running time and reconstruction error of Z T with those of competitors for various time ranges. For each dataset, we use the narrowest and the widest time ranges among the ranges described in Table <ref type="table" target="#tab_4">3</ref>. Figure <ref type="figure" target="#fig_5">2</ref> shows that Z T is the closest method to the best point with the smallest error and running time. Z T is up to 171.9Ã— and 111.9Ã— faster than the second-fastest method, in narrow and wide time ranges, respectively, with similar errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Space Cost (Q2)</head><p>We compare the storage cost of Z T with those of competitors for storing preprocessed results. Note that memory requirements for a time range query are proportional to the storage cost since preprocessed results or an input tensor is the dominant term in the space cost. Figure <ref type="figure" target="#fig_13">6</ref> shows that Z T requires the lowest space; Z T requires up to 230Ã— less space than the second-best method D-Tucker. Z T has more compression rate on the 4-order tensor, Absorb dataset.  Figure <ref type="figure">8</ref>: Anomalous two-month ranges and related events, found by Z T . capturing widespread patterns is more bene cial in reducing errors. Therefore, we select 50, which is the largest value providing small errors for narrow time range queries, for the default block size to preprocess all datasets in other experimental sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discovery (Q4)</head><p>On Stock dataset, we discover interesting results by answering various time range queries with Z T .</p><p>Finding anomalous ranges. The goal is to nd narrow time ranges that are anomalous, compared to the entire time range. For the goal, we select every consecutive two-month interval from Jan. 1, 2008 to Apr. 30, 2020, perform Tucker decomposition for each of the intervals using Z T , and nd anomalous ranges that deviate the most from the entire ranges. Given a two-month range r , and its corresponding sub-tensor X, we compute the anomaly score for r using the di erence ratio</p><formula xml:id="formula_37">Xâˆ’ Å¶ 2 F Xâˆ’ áº 2 F</formula><p>where Å¶ and áº are the sub-tensors for r reconstructed from the Tucker results of 1) the entire range query, and 2) the two-month range query, respectively.</p><p>The leftmost plot of Figure <ref type="figure">8</ref> shows the di erence ratios and the top three anomalous ranges where the threshold indicates 2 standard deviations from the mean. The right three plots of Figure <ref type="figure">8</ref> show that the three anomalies follow the similar plunging pattern of prices from issues a ecting the stock market.</p><p>Analyzing trend change. We analyze the change of yearly trend of Samsung Electronics in the years 2013 and 2018. For each of the range (year 2013 or 2018), we perform Z T and get the feature matrix Ãƒ(1) each of whose rows contain the latent features of a stock. We also manually pick 33 smartphone-related stocks and 46 semiconductor-related stocks, and compare the cosine distance between the latent feature vectors of each stock and Samsung Electronics.</p><p>Figure <ref type="figure" target="#fig_16">9</ref> shows the result. Note that there is a clear change of the distances between year 2013 and 2018: Samsung Electronics is more close to smartphone-related stocks in 2013, but to semiconductorrelated stocks in 2018. This result exactly re ects the sales trend of Samsung Electronics; the annual sales of its smartphone division are 3.7Ã— larger than those of its semiconductor division in 2013, while in 2018 the annual sales of its semiconductor division are 30% larger than those of its smartphone division. Z T enables us to quickly and accurately capture this trend change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>We review related works for e cient tensor decomposition, blockbased tensor decomposition, and time range query for tensors.</p><p>E cient tensor decomposition. Many works have been devoted to computing e cient tensor decomposition in various settings. Previous works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38</ref>] develop e cient tensor decomposition methods on distributed systems. Several tensor decomposition methods <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34]</ref> have been proposed for sparse tensors; however, they target performing tensor decomposition only once for the whole data. There are several works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b38">39]</ref> that perform tensor decomposition in streaming settings. Z T is di erent from the above methods since it handles arbitrary time range queries in a single machine.</p><p>Tensor decomposition with block-wise computation. Many tensor decomposition methods have exploited block-wise computation for parallel computation. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29]</ref> proposed parallel CP decomposition methods which perform CP decomposition block by block and then concatenate the results of the blocks. Austin et al. <ref type="bibr" target="#b1">[2]</ref> proposed a distributed algorithm that computes n-mode product, gram matrix, and eigenvectors with the small blocks of a given tensor. Unlike the above methods which do not consider time ranges, the goal of our Z T is to quickly provide Tucker decomposition results for a given time range query. Time range query for tensors. Zoom-SVD <ref type="bibr" target="#b10">[11]</ref> deals with the time range query problem, but it is suitable only for multiple time series data represented as a matrix. Although there is no existing method that precisely addresses the time range query problem for tensors, there are several methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35]</ref> that can be adapted to solve the problem. They perform a preprocessing phase by exploiting a sampling technique <ref type="bibr" target="#b34">[35]</ref> or randomized SVD <ref type="bibr" target="#b11">[12]</ref> before the query phase, and then obtain Tucker results using the preprocessed results in the query phase. However, they do not satisfy the desired properties for the solution: fast running time, low space cost, and accuracy. On the other hand, Z T e ciently and accurately provides answers to time range queries by exploiting the preprocessed results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this work, we propose Z T , an e cient Tucker decomposition method to discover latent factors in a given time range from a temporal tensor. Z T e ciently answers diverse time range queries with the preprocessing phase and the query phase. In the preprocessing phase, Z T lays the groundwork for an e cient time range query by compressing sub-tensors along time dimension block by block. Given a time range query in the query phase, Z T elaborately stitches compressed results reducing computational cost and space cost. Experiments show that Z T is up to 171.9Ã— faster and requires up to 230Ã— less space than existing methods, with comparable accuracy to competitors. With Z T , we discover interesting patterns including anomalous ranges and trend changes in a real-world stock dataset. Future research includes extending the method for sparse tensors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Given a temporal tensor and a user-provided time range (start time and end time) query, the goal of the timeranged Tucker decomposition is to nd the patterns of the temporal tensor at the range using Tucker decomposition. and tra c volume data are represented as temporal dense tensors.Tensor decomposition has played an important role in various applications including data clustering<ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref>, concept discovery<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, dimensionality reduction<ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36]</ref>, anomaly detection<ref type="bibr" target="#b17">[18]</ref>, and link prediction<ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>. Tucker decomposition, one of the tensor decomposition methods, has been recognized as a crucial tool for discovering latent factors and detecting relations between them.In practice, we analyze a given temporal tensor from various perspectives. Assume a user is interested in investigating patterns of various time ranges using Tucker decomposition. Given a temporal tensor and a user-provided time range (start time and end time) query, our goal is to nd the patterns of the temporal tensor at the range using Tucker decomposition. For example, given a temporal tensor including matrices collected between Jan. 1, 2008 to May 6, 2020, a user may be interested in Tucker decomposition of a subrange between Jan. 1, 2020 to April 30, 2020 (see Figure1). Since Tucker decomposition generates factor matrices and a core tensor to accurately approximate an input tensor, answering time range queries, (i.e., performing Tucker decomposition of di erent sub-tensors) yields di erent Tucker results. However, conventional Tucker decomposition methods<ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref> based on Alternating Least Square (ALS) is not appropriate for answering diverse time range queries since they target performing Tucker decomposition once for a given tensor; the methods require a high computational cost and large storage space since they need to perform Tucker decomposition of the sub-tensor included in a time range query from scratch, every time the query is given. Due to this limitation, the existing methods are not e cient in exploring diverse time ranges for a given temporal tensor.A few methods<ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b34">35]</ref> with a preprocessing phase can be adapted to the time range query problem; before the query phase, they preprocess a given tensor, and perform Tucker decomposition with the preprocessed tensor for each time range query. However, they su er from an accuracy issue for narrow time ranges since preprocessed results are tailored for performing Tucker decomposition of the whole given temporal tensor. The results fail to capture local patterns that appear only in a speci c range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Reconstruction errors at each time point on Stock dataset. The blue line presents reconstruction errors computed from a whole temporal tensor, while the orange line describes reconstruction errors computed from a sub-tensor in a range. Performing Tucker decomposition from a subtensor provides relatively low reconstruction errors. measured by performing Tucker decomposition. The reconstruction error is de ned as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Preprocessing phase of Z T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 2 :</head><label>2</label><figDesc>Query phase of Z T Input: a time range [t s , t e ], and Tucker result sets C n for n = 1, ..., N + 1 Output: factor matrices Ãƒ(n) for n = 1, .., N , and core tensor G Parameters: tolerance Ïµ , and block size b 1: S â† ts b and E â† te</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>and multiply with the remaining matrices requires O(N I 2 + 2N + N +1 ) time and O( 2N + N I ) space. Instead, exploiting Equation (1) enables to compute Equation (4) e ciently: O(N I 2 + N N +1 ) time and O( N + N I ) space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples of adjustment (Section 3.2.2) and division (Section 3.2.3). column-orthogonality (line 4 in Algorithm 2); we use(Q &lt;p &gt; ) (N )as the temporal factor matrix of X &lt;p &gt; and update the core tensorG &lt;p &gt; â† G &lt;p &gt; Ã— N (R &lt;p &gt; )(N ) where (Q &lt;p &gt; )(N ) and (R &lt;p &gt; )(N )  are the results of QR decomposition (line 5 in Algorithm 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>..., E) along the time dimension (see Figure 5(b)); the size of Ãƒ(N ) [i] for i = S + 1, ..., E âˆ’ 1 is b Ã— N , and that of Ãƒ(N ) [S] and Ãƒ(N ) [E] is (b âˆ’ r S ) Ã— N and (b âˆ’ r E ) Ã— N , respectively,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>T 1 .T 2 .</head><label>12</label><figDesc>The preprocessing phase takes O(MN I N âˆ’1 bB) time. Given a time range query [t s , t e ], the query phase of Z T takes O MN 2 l [t s ,t e ] 1 + N I b + N N âˆ’1 b time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>T 3 .</head><label>3</label><figDesc>Z T requires O N I ( I N b ) + I N space to store the Tucker results in the preprocessing phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>T 4 .</head><label>4</label><figDesc>Given a time range query [t s , t e ], Z T requires O N I ( l [ts ,te ] b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Space cost for storing preprocessed results. Input Tensor corresponds to the space cost of Tucker-ALS, Tuckerts, Tucker-ttmts, and RTD. Z T requires up to 230Ã— less space than competitors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>4. 4 E</head><label>4</label><figDesc>ects of Block Size b (Q3) We investigate the e ects of block size b on running time and reconstruction error of Z T . We use block sizes 10, 25, 50, 100, and 200 on Stock, Tra c, and Absorb datasets. As shown in Figures 7(a) to 7(c), there are trade-o relationships between running time and reconstruction error for narrow time range queries. In Figures 7(d) to 7(f), the running time of Z T is inversely proportional to b for a wide range query while the reconstruction error is not sensitive to b. A large b prevents the preprocessing phase from capturing local information so that it is challenging to serve narrow time range queries. For wide time range queries, local information has little e ect on reconstruction errors since</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 :â‘¢</head><label>7</label><figDesc>Figure 7: Sensitivity with respect to block size b on Stock, Tra c, and Absorb datasets. Numbers after the data name represent the length of time ranges; e.g., (128) means the length of time range is t e âˆ’ t s + 1 = 128 timesteps. (a,b,c) There are tradeo relationships between running time and reconstruction error for narrow time range queries. (d,e,f) For wide time range queries, the running times decrease while the errors do not change much, as block size increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Cosine distance between feature vectors of Samsung Electronics and other stocks related to smartphone or semiconductors in 2013 and 2018. Z T helps capture the clear change of the trend, where Samsung Electronics is more close to smartphone-related stocks in 2013, but to semiconductor-related stocks in 2018.close to smartphone-related stocks in 2013, but to semiconductorrelated stocks in 2018. This result exactly re ects the sales trend of Samsung Electronics; the annual sales of its smartphone division are 3.7Ã— larger than those of its semiconductor division in 2013, while in 2018 the annual sales of its semiconductor division are 30% larger than those of its smartphone division. Z T enables us to quickly and accurately capture this trend change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>) time range queries. o.o.t.: out of time (takes more than 20,000 seconds). Numbers after the data name represent the length of time ranges; e.g., (128) means the length of a time range is 128 timesteps. Z T is closest to the best point with the fastest query speed and the lowest reconstruction error. Symbol description.</figDesc><table><row><cell>0.16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.14</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.12</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.08</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.06</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.04</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>1000 Trust</cell><cell>2000 D-Tucker</cell><cell>3000 Tucker-als</cell><cell>Reconstruction Error 4000 MACH</cell><cell>!". $Ã— 5000 Tucker-ts o.o.t.</cell><cell>6000 Tucker-mts</cell><cell>7000</cell><cell>RTD</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>BEST</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(f) Absorb data (64)</cell><cell></cell><cell></cell><cell></cell></row></table><note>SymbolDescriptionX temporal tensor (âˆˆ I 1 Ã— ... Ã— I N ) I n &amp; n dimensionality of the n-th mode of X and G b block size t s &amp; t e starting and ending points of time range query [t s , t e ] time range of a query</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Time and space complexities of Z T and other methods for a time range [t s , t e ]. The optimal complexities are in bold. I , , M, N , and l [t s ,t e ] are described in Section 3.3. S is a sampling rate for MACH.</figDesc><table><row><cell cols="2">Algorithm</cell><cell>Time</cell><cell>Space</cell></row><row><cell>Z</cell><cell>T</cell><cell>O(l [ts,te] IMN 2 J 2 /b)</cell><cell>O(l [ts,te] NIJ/b)</cell></row><row><cell cols="2">D-Tucker [12]</cell><cell>O(l [ts ,te ]</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Description of real-world tensor datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Dimensionality Length l [ts ,te ] of Time Range</cell><cell>Summary</cell></row><row><cell>Boats 1 [37]</cell><cell>320 Ã— 240 Ã— 7000</cell><cell>(128, 2048)</cell><cell>Video</cell></row><row><cell>Walking Video [25]</cell><cell>1080 Ã— 1980 Ã— 2400</cell><cell>(128, 2048)</cell><cell>Video</cell></row><row><cell>Stock 3</cell><cell>3028 Ã— 54 Ã— 3050</cell><cell>(128, 2048)</cell><cell>Time series</cell></row><row><cell>Tra c 4 [30]</cell><cell>1084 Ã— 96 Ã— 2000</cell><cell cols="2">(64, 1024) Tra c volume</cell></row><row><cell>FMA 5 [8]</cell><cell>7994 Ã— 1025 Ã— 700</cell><cell>(32, 512)</cell><cell>Music</cell></row><row><cell>Absorb 6</cell><cell>192 Ã— 288 Ã— 30 Ã— 1200</cell><cell>(64, 1024)</cell><cell>Climate</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">http://changedetection.net/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://github.com/OsmanMalik/tucker-tensorsketch</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://datalab.snu.ac.kr/zoomtucker</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://github.com/ orinsch/BigTra cData</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4">https://github.com/mde /fma</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5">https://www.earthsystemgrid.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6">https://datalab.snu.ac.kr/dtucker/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7">https://github.com/OsmanMalik/tucker-tensorsketch</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the National Research Foundation of Korea(NRF) funded by MSIT(2019R1A2C2004990). The Institute of Engineering Research and ICT at Seoul National University provided research facilities for this work. U Kang is the corresponding author.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>A TUCKER-ALS Algorithm 3: Tucker-ALS (HOOI) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20]</ref> Input: tensor X âˆˆ R I 1 Ã—. . .Ã—I N and dimensionalities 1 , ..., N of core tensor</p><p>Output: core tensor G âˆˆ R 1 , . . ., N and factor matrices A (n) âˆˆ R In Ã— n (n = 1, ..., N ) 1: initialize: factor matrices A (n) (n = 1, ..., N ) 2: repeat 3:</p><p>for n = 1, ..., N do 4:</p><p>A (n) â† n leading left singular vectors of Y (n) 6:</p><p>end for 7: until convergence criterion is met; 8:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PROOFS B.1 Proof of Lemma 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head><p>. After xing all factor matrices except for the n-th factor matrix, the partial derivative of the Equation ( <ref type="formula">2</ref>) with respect to the factor matrix Ãƒ(n) is as follows:</p><p>We set</p><p>âˆ‚ Ãƒ(n) to zero, and solve the equation with respect to the factor matrix Ãƒ(n) :</p><p>A naive approach computing Equation ( <ref type="formula">4</ref>) is to explicitly compute the entire Kronecker product âŠ— N k n U (k)T V (k ) of the size N âˆ’1 Ã— N âˆ’1 . We compute matrix multiplication between the preceding result S (n) and S (n) . Therefore, the time and space complexities are O(N I 2 + 2N + N +1 ) and O( 2N + N I ), respectively.</p><p>We compute Equation (4) using n-mode product instead of Kro- k ) where I (n) âˆˆ R Ã— is an identity matrix. Then, we transform Z into Equation (9) using Equation <ref type="bibr" target="#b0">(1)</ref>.</p><p>Based on Equation ( <ref type="formula">9</ref>), we compute Equation (4) in the following order: 1) <ref type="figure">and 3</ref>)</p><p>). In addition, the size of intermediate data is always no larger than N so that the space complexity is O( N + N I ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Proof of Lemma 3</head><p>block by block so that we represent the term as a summation of block matrices:</p><p>Next, we express i-th block matrix X &lt;i &gt; (n) as the result</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Proof of Lemma 4</head><p>P . From Equation (3), we decouple X(N ) for updating N -th factor matrix. We rst re-express</p><p>Ãƒ(k) using temporal block tensors X &lt;i &gt; for i = S, .., E as follows:</p><p>. . .</p><p>(N ) with the tucker results obtained at the preprocessing phase.</p><p>Next, we obtain the following equation by inserting the right term of the above equation into Equation (3):</p><p>. . .</p><p>. . .</p><p>Research Track Paper KDD '21, August 14-18, 2021, Virtual Event, Singapore B.5 Proof of Theorem 1 P . We split a tensor X into B temporal block tensors X &lt;i &gt; , and then perform Tucker decomposition of X &lt;i &gt; for i = 1, ..., B. Since we use Tucker-ALS in the preprocessing phase, the time complexity for each temporal block tensor X &lt;i &gt; is O(MN I N âˆ’1 b). Therefore, the preprocessing phase takes O(MN I N âˆ’1 bB) time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Proof of Theorem 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P</head><p>. The time complexity of the query phase depends on updating factor matrices and core tensor. Updating a factor matrix or core tensor takes</p><p>which contains the time complexity of updating factor matrices and core tensor, the number of iterations, and the number of factor matrices.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7 Proof of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C PARAMETERS SETTINGS</head><p>We use the following parameters.</p><p>(  Other parameters for competitors are set to the values proposed in each paper. To compare the running time, we run each method 5 times, and report the average.</p><p>Research Track Paper KDD '21, August 14-18, 2021, Virtual Event, Singapore</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gtensor: Fast and Accurate Tensor Analysis System using GPUs</title>
		<author>
			<persName><forename type="first">Dawon</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangjun</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3361" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Parallel Tensor Compression for Large-Scale Scienti c Data</title>
		<author>
			<persName><forename type="first">Woody</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grey</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPDPS</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="912" to="922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">MATLAB Tensor Toolbox Version 3.0-dev</title>
		<author>
			<persName><forename type="first">Brett</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<ptr target="https://www.tensortoolbox.org" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust Face Clustering Via Tensor Decomposition</title>
		<author>
			<persName><forename type="first">Xiaochun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingxing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yahong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdai</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybernetics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2546" to="2557" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Randomized algorithms for the approximations of Tucker and the tensor train decompositions</title>
		<author>
			<persName><forename type="first">Maolin</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yimin</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Comput. Math</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="395" to="428" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">H-PARAFAC: Hierarchical Parallel Factor Analysis of Multidimensional Big Data</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPDS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1091" to="1104" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">S3CMTF: Fast, accurate, and scalable method for incomplete coupled matrix-tensor factorization</title>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Gi</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">FMA: A Dataset for Music Analysis</title>
		<author>
			<persName><forename type="first">MichaÃ«l</forename><surname>De Errard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirell</forename><surname>Benzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">ISMIR.arXiv:1612.01840</idno>
		<ptr target="https://arxiv.org/abs/1612.01840" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SamBaTen: Sampling-based Batch Incremental Tensor Decomposition</title>
		<author>
			<persName><forename type="first">Ekta</forename><surname>Gujral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravdeep</forename><surname>Pasricha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="387" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simultaneous tensor subspace selection and clustering: the equivalence of high order svd and k-means clustering</title>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">H Q</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dijun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Zoom-SVD: Fast and Memory E cient Method for Extracting Key Patterns in an Arbitrary Time Range</title>
		<author>
			<persName><forename type="first">Jun-Gi</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhong</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1083" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">D-Tucker: Fast and Memory-E cient Tucker Decomposition for Dense Tensors</title>
		<author>
			<persName><forename type="first">Jun-Gi</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE. IEEE</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1850" to="1853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SCouT: Scalable coupled matrix-tensor factorization -algorithm and discoveries</title>
		<author>
			<persName><forename type="first">Byungsoo</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inah</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Sael</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="811" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">HaTen2: Billion-scale tensor decompositions</title>
		<author>
			<persName><forename type="first">Inah</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1047" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable sparse tensor decompositions in distributed memory systems</title>
		<author>
			<persName><forename type="first">Oguz</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bora</forename><surname>UÃ§ar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC. ACM</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications</title>
		<author>
			<persName><forename type="first">Yong-Deok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunhyeok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungjoo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taelim</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjun</forename><surname>Shin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06530</idno>
		<ptr target="http://arxiv.org/abs/1511.06530" />
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tensor Decompositions and Applications</title>
		<author>
			<persName><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brett</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">SliceNStitch: Continuous CP Decomposition of Sparse Tensor Streams</title>
		<author>
			<persName><forename type="first">Taehyung</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inkyu</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kijung</forename><surname>Shin</surname></persName>
		</author>
		<idno>CoRR abs/2102.11517</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tensor Decompositions for Temporal Knowledge Base Completion</title>
		<author>
			<persName><forename type="first">TimothÃ©e</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">ICLR. OpenReview</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the Best Rank-1 and Rank-(R 1 , R 2 , ... , R N ) Approximation of Higher-Order Tensors</title>
		<author>
			<persName><forename type="first">Lieven</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lathauwer</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bart De Moor, and Joos Vandewalle</title>
				<imprint>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast Tucker Factorization for Large-Scale Tensor Completion</title>
		<author>
			<persName><forename type="first">Dongha</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehyung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1098" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Robust Factorization of Real-world Tensor Streams with Patterns, Missing Values, and Outliers</title>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kijung</forename><surname>Shin</surname></persName>
		</author>
		<idno>CoRR abs/2102.08466</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">2PCP: Two-phase CP decomposition for billion-scale dense tensors</title>
		<author>
			<persName><forename type="first">Xinsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>SelÃ§uk Candan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">Luisa</forename><surname>Sapino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="835" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Generalizing Tensor Decomposition for N-ary Relational Knowledge Bases</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<idno>WWW. ACM / IW3C2</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1104" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Low-Rank Tucker Decomposition of Large Tensors Using TensorSketch</title>
		<author>
			<persName><forename type="first">Asif</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="10117" to="10127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">High-Performance Tucker Factorization on Heterogeneous Platforms</title>
		<author>
			<persName><forename type="first">Sejoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Namyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Gi</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Sael</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distributed Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2237" to="2248" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Scalable Tucker Factorization for Sparse Tensors -Algorithms and Discoveries</title>
		<author>
			<persName><forename type="first">Sejoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Namyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Sael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kang</surname></persName>
		</author>
		<idno>ICDE. 1120-1131</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BIGtensor: Mining Billion-Scale Tensor Made Easy</title>
		<author>
			<persName><forename type="first">Namyong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byungsoo</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungwoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2457" to="2460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PARAFAC algorithms for large-scale problems</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Huy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Andrzej</forename><surname>Cichocki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1970" to="1984" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tra c forecasting in complex urban networks: Leveraging big data and machine learning</title>
		<author>
			<persName><forename type="first">Florin</forename><surname>Schimbinschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Vinh Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rao</forename><surname>Kotagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1019" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distributed Methods for High-Dimensional and Large-Scale Tensor Factorization</title>
		<author>
			<persName><forename type="first">Kijung</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="989" to="994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fully Scalable Methods for Distributed Tensor Factorization</title>
		<author>
			<persName><forename type="first">Kijung</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Sael</surname></persName>
		</author>
		<author>
			<persName><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="100" to="113" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Streaming Tensor Factorization for In nite Data Sources</title>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM. SIAM</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="81" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SPLATT: E cient and Parallel Sparse Tensor-Matrix Multiplication</title>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjay</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPDPS</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">MACH: Fast Randomized Tensor Decompositions</title>
		<author>
			<persName><forename type="first">Charalampos</forename><forename type="middle">E</forename><surname>Tsourakakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="689" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Tensor Approximation Approach to Dimensionality Reduction</title>
		<author>
			<persName><forename type="first">Hongcheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narendra</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="217" to="229" />
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">CDnet 2014: An Expanded Change Detection Benchmark Dataset</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Marc</forename><surname>Jodoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatih</forename><surname>Murat Porikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janusz</forename><surname>Konrad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannick</forename><surname>Benezeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakash</forename><surname>Ishwar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="393" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanhua</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuzhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinfeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunjian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruihao</forename><surname>Zhao</surname></persName>
		</author>
		<title level="m">LFTF: A Framework for E cient Tensor Analytics at Scale. Proc. VLDB Endow</title>
				<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="745" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Accelerating Online CP Decompositions for Higher Order Tensors</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Vinh Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhe</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1375" to="1384" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
