<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">User-robot personality matching and assistive robot behavior adaptation for post-stroke rehabilitation therapy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-02-13">13 February 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Adriana</forename><surname>Tapus</surname></persName>
							<email>adriana.tapus@ieee.org</email>
						</author>
						<author>
							<persName><forename type="first">Cristian</forename><surname>Ţȃpuş</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maja</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
							<email>mataric@usc.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Robotics Research Lab/Interaction Lab</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Mojave Research Lab</orgName>
								<orgName type="institution">California Institute of Technology (Caltech)</orgName>
								<address>
									<settlement>Pasadena</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">User-robot personality matching and assistive robot behavior adaptation for post-stroke rehabilitation therapy</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-02-13">13 February 2008</date>
						</imprint>
					</monogr>
					<idno type="MD5">DFE819FC5C08D04D4740CD0D081CBAF5</idno>
					<idno type="DOI">10.1007/s11370-008-0017-4</idno>
					<note type="submission">Received: 22 May 2007 / Accepted: 6 December 2007 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Rehabilitation robotics</term>
					<term>Socially assistive robotics</term>
					<term>Social human-robot interaction</term>
					<term>Learning and adaptive systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a hands-off socially assistive therapist robot designed to monitor, assist, encourage, and socially interact with post-stroke users engaged in rehabilitation exercises. We investigate the role of the robot's personality in the hands-off therapy process, focusing on the relationship between the level of extroversion-introversion of the robot and the user. We also demonstrate a behavior adaptation system capable of adjusting its social interaction parameters (e.g., interaction distances/proxemics, speed, and vocal content) toward customized post-stroke rehabilitation therapy based on the user's personality traits and task performance. Three validation experiment sets are described. The first maps the user's extroversion-introversion personality dimension to a spectrum of robot therapy styles that range from challenging to nurturing. The second and the third experiments adjust the personality matching dynamically to adapt the robot's therapy styles based on user personality and performance. The reported results provide first evidence for user preference for personality matching in the assistive domain and demonstrate how the socially assistive robot's This work was supported by USC Women in Science and Engineering (WiSE) Program and the Okawa Foundation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent trend toward developing a new generation of robots capable of operating in human-centered environments, interacting with people, and participating and helping us in our daily lives, has introduced the need for robotic systems capable of learning to use their embodiment to communicate and to react to their users in a social and engaging way. Social robots that interact with humans have thus become an important focus of robotics research.</p><p>Nevertheless, Human-Robot Interaction (HRI) for assistive applications is still in its infancy. Socially assistive robotics <ref type="bibr" target="#b14">[15]</ref>, which focuses on aiding through social rather than physical interaction between the robot and the human user, has the potential to enhance quality of life for large user populations, including the elderly <ref type="bibr" target="#b52">[55]</ref>, people with physical impairments and those involved in rehabilitation therapy (e.g., post-stroke patients) <ref type="bibr" target="#b9">[10]</ref>, and people with cognitive disabilities and social and developmental disorders (e.g., children with autism, children with attention deficit/hyperactivity disorder (AD/HD)) <ref type="bibr" target="#b40">[43,</ref><ref type="bibr" target="#b42">45,</ref><ref type="bibr" target="#b43">46]</ref>. Hence, one of the main goals of socially assistive robotics is to create stimulating and engaging interactions in which a user actively participates for an extended period of time in order to achieve the goals of the task (therapy, rehabilitation, training, etc.).</p><p>In this work, the target user population is post-stroke patients. Stroke is the leading cause of serious, long-term disability among adults, with over 750,000 people suffering a new stroke each year in the US alone <ref type="bibr">[38]</ref>. Rehabilitation helps stroke survivors re-learn skills that are lost when part of the brain is damaged. Paralysis affecting the face, an arm, a leg, or an entire side of the body is one of the most common disabilities resulting from stroke. Stroke patients with one-sided paralysis have difficulty with everyday activities such as walking and grasping objects. This loss of function, termed " learned disuse", can be diminished with intensive rehabilitation therapy during the critical months of the poststroke period. One of the most important elements of any rehabilitation program is the practice of carefully directed, well-focused and repetitive exercises, which can be passive or active. In passive exercises (also known as hands-on rehabilitation), the patient is helped by a human (or robotic) therapist to appropriately exercise the affected limb(s). In contrast, in active exercises, the patient performs the exercises with no physical assistance.</p><p>The majority of existing work in rehabilitation robotics focuses on hands-on robotic systems for passive exercise, attempting to recover upper-limb function primarily through robotic manipulation of the affected-limb. Burgar et al. <ref type="bibr" target="#b6">[7]</ref> developed a robot-assisted arm therapy workstation, in which patients can exercise their upper limbs and evaluate their performance. A similar device, which also depends on handson robotic technology, was developed by Krebs et al. <ref type="bibr" target="#b21">[23]</ref>. Other related systems have been investigated in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">42]</ref>.</p><p>Recent results from physical therapy research show that hands-on therapy may not be the most effective means of recovery from stroke, and is certainly not the only necessary type of needed treatment <ref type="bibr" target="#b9">[10]</ref>. Consequently, our work focuses on hands-off therapist robots that assist, encourage, and socially interact with patients during their active exercises. Previous work by Eriksson et al. <ref type="bibr" target="#b9">[10]</ref> demonstrated that the physical embodiment, including shared physical context and physical movement of the robot, encouragement, and continuous monitoring play key roles in stroke patient compliance with rehabilitation exercises. We also studied the role of physically embodied interaction in such assistive contexts <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b49">52]</ref>; those results form the foundation for the work described here.</p><p>Achieving a psychological " common ground" between the human user and the robot is necessary for a natural, nuanced, and engaging interaction. Therefore, in this work we investigated the role of the robot's personality in the assistive therapy process. We focus on the relationship between the level of extroversion-introversion (as defined in the Eysenck Model of Personality <ref type="bibr" target="#b12">[13]</ref>) of the robot and the user, addressing the following research questions:</p><p>• Is there a relationship between the extroversionintroversion personality spectrum (assessed with the Eysenck model <ref type="bibr" target="#b10">[11]</ref>) and the challenging vs. nurturing style of patient encouragement? • How should the behavior and encouragement of the therapist robot adapt as a function of the user's personality and task performance?</p><p>Examining and answering these questions will begin to address the role of assistive robot personality in enhancing patient task performance in rehabilitation exercises as well as other task domains.</p><p>Creating robotic systems capable of adapting their behavior to user personality, user preferences, and user profile in order to provide an engaging and motivating customized protocol is a very difficult task, especially when working with vulnerable user populations. Various learning approaches for human-robot interaction have been proposed in the literature <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b36">39,</ref><ref type="bibr" target="#b45">48]</ref>, but none include the user's profile, preferences, and/or personality. To the best of our knowledge, no work has yet tackled the issue of robot personality and behavior adaptation as a function of user personality in the assistive humanrobot interaction context. In the work described here, we address those issues and propose a methodology for evaluating the user-robot personality match and a reinforcementlearning-based approach to robot behavior adaptation. In the learning approach, the robot incrementally adapts its behavior and thus its expressed personality as a function of the user's extroversion-introversion level and the amount of performed exercises, attempting to maximize that amount. The result is a novel stroke rehabilitation tool that provides individualized and appropriately challenging/nurturing therapy style that measurably improves user task performance.</p><p>The rest of the paper is structured as follows. In Sect. 2, our research is placed in the context of the relevant work in assistive robotics. Section 3 presents the Eysenck Model of Personality. Section 4 overviews our human-robot interaction design. Section 5 describes the proposed behavior adaptation system. Section 6 provides a description of the experimental test-bed, the experimental setup, and the experimental results. Section 7 discusses future work and concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work and open challenges</head><p>In this section we briefly review related work in assistive robotics to which our research most directly contributes.</p><p>An active component of assistive robotics research is focused on designing robotic systems for eventual in-home use, mainly involving contact-based interaction. A common theme of the work is a high degree of task specialization toward capabilities that would enable elderly and/or disabled people to accomplish tasks they could not do otherwise and to be commanded in some form by a user with one or more communication disabilities. Movement aides that have been developed include the GuideCane <ref type="bibr" target="#b0">[1]</ref>, a robotic guide cane for the blind, the PAMM intelligent walker <ref type="bibr" target="#b46">[49]</ref>, Wheelesey <ref type="bibr" target="#b56">[59]</ref>, and the NavChair <ref type="bibr" target="#b22">[24]</ref>, which involved speech control of the wheelchair <ref type="bibr" target="#b44">[47]</ref>. Some work has addressed the safety aspects of such systems <ref type="bibr" target="#b44">[47,</ref><ref type="bibr" target="#b56">59]</ref> and suggested common metrics for their testing and evaluation.</p><p>Another target domain of assistive robotics consists of hospitals, nursing homes, and managed care homes. The research in that domain has ranged from robotic companions <ref type="bibr" target="#b52">[55]</ref>, to story telling robots <ref type="bibr" target="#b38">[41]</ref>, to robots that serve as guides and schedule reminders <ref type="bibr" target="#b41">[44]</ref>, to aides in rehabilitation therapy <ref type="bibr" target="#b9">[10]</ref>.</p><p>Animal-assisted activities (AAA) and animal-assisted therapies (AAT) have served as inspiration for past work in socially assistive robotics. First efforts focused on robotic pets, companions that attempt to reduce stress and depression <ref type="bibr" target="#b52">[55]</ref>. Companion robots are designed to fulfill some of the roles of animal pets, but without the associated pet care. Researchers have used robotic animal toys, such as a seal (i.e., PARO <ref type="bibr" target="#b52">[55,</ref><ref type="bibr" target="#b54">57]</ref>), a cat <ref type="bibr" target="#b52">[55]</ref>, a dog (i.e., SONY AIBO), and a teddy bear (i.e., the Huggable <ref type="bibr" target="#b47">[50]</ref>) to attempt to improve psychological health in elderly patients. These studies have shown that elderly users smiled and laughed more, and became less hostile to their caretakers and more socially communicative as a result of interacting with the robots. However, the impact of the novelty factor of such systems has not yet been studied <ref type="bibr" target="#b19">[21]</ref>.</p><p>Flo, and later Pearl, were mobile nurse's assistant robots for use in tele-presence, data collection in a hospital or nursing home, as a cognitive prosthetic for patients, and as a vehicle for social interaction <ref type="bibr" target="#b41">[44]</ref>. The robots were controlled through a remote tele-operation GUI, speech recognition, or a touch screen. The possible demeanor for such robots was studied <ref type="bibr" target="#b17">[18]</ref>; it was found that while a playful robot generated a positive response from patients, a serious robot received more cooperation. Pearl was a more complex system <ref type="bibr" target="#b23">[25]</ref> that allowed for the study of the intricacies of temporal planning in an assistive setting, determining an effective plan based on user inputs by creating a personalized cognitive orthotic. The resulting systems combined the guide functions of previous systems to create a nurses' assistant and cognitive orthotic for patients, and was evaluated in a nursing home setting <ref type="bibr" target="#b30">[32]</ref>.</p><p>We propose a fundamentally different approach to robotassisted convalescence and rehabilitation, one that involves no physical contact between the patient and the robot. Our approach fits within a new research area termed Socially Assistive Robotics <ref type="bibr" target="#b14">[15]</ref>, which has a broad focus on gaining new insights about human-robot social interactions in the assistive context and using those to develop and deploy robotic systems that assist people. Making those systems safe and affordable predominantly implies hands-off, non-contact interaction between the robot and its user(s). The Nursebot project <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b41">44]</ref> is one of the most mature efforts in this new field, involving a mobile robot that roams the hospital, makes deliveries, and verbally interacts with patients. Another active area of socially assistive robotics is studying robots as tools toward automated diagnosis and socialization therapy for children with autism, where robots have been shown to have great potential <ref type="bibr" target="#b25">[27]</ref><ref type="bibr" target="#b26">[28]</ref><ref type="bibr" target="#b27">[29]</ref><ref type="bibr" target="#b28">[30]</ref><ref type="bibr" target="#b42">45]</ref>.</p><p>Our research program addresses a new niche of assistive robotics, one that involves an autonomous robot providing contact-free rehabilitation monitoring, assistance, and encouragement to stroke patients, while also being capable of providing detailed reports of patient progress to physicians and therapists. The robot's physical embodiment, its physical presence and appearance, its shared context with the user, its personality, and its empathetic traits are all fundamental in time-extended, sustained, personalized exercise supervision, motivation, and encouragement in rehabilitation therapy. In the work described here, we focus on user-robot personality matching and robot behavior adaptation to user's personality and preferences, aiming toward a customized therapy protocol for stroke and other rehabilitation and exercise application domains. We start by describing the model of personality we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Eysenck model of personality</head><p>Personality is a key determinant in human social interactions. A direct relationship between personality and behavior has long been recognized <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b35">37]</ref>. In <ref type="bibr" target="#b31">[33]</ref>, Morris indicated that, to a personality psychologist, the behaviors of greatest importance are those that are:</p><p>1. relatively pervasive in the person's life-style in that they show some consistency across situations; 2. relatively stable in the person's life-style across time; 3. indicative of the uniqueness of the person.</p><p>Consequently, personality is also a key factor in humanrobot interactions (HRI) <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>. It has been argued that robot personality should match that of the human user <ref type="bibr" target="#b34">[36]</ref>. While there is no generic definition of personality, our working definition, based on the literature <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">33,</ref><ref type="bibr" target="#b55">58]</ref>, defines personality as the pattern of collective character, behavioral, temperamental, emotional and mental traits of an individual that have consistency over time and situations.</p><p>To date, little research into human-robot personality matching has been performed. In <ref type="bibr" target="#b55">[58]</ref>, Woods et al. explored the topic, showing that subjects perceived themselves as having stronger personality traits than robots. A similar study <ref type="bibr" target="#b17">[18]</ref> found that people enjoyed interacting with humorous robots but complied with the more serious ones.</p><p>Quantification of personality is controversial since there is no universally accepted number of personality dimensions. The Eysenck model of personality (3 model factor -PEN) <ref type="bibr" target="#b11">[12]</ref>, the Five-factor model of personality (Big5) <ref type="bibr" target="#b24">[26]</ref> (extroversion-introversion, neuroticism, agreeableness, conscientiousness, and openness) and the Myers-Briggs model <ref type="bibr" target="#b32">[34]</ref> (extroversion-introversion, sensation-intuition, thinking-feeling, and judging-perceiving) are the dominant models in the literature. In this work, we use the biologically based Eysenck <ref type="bibr" target="#b12">[13]</ref> Model of Personality (PEN) that advocates three major dimensions or super-factors in the description of personality: (P) Psychoticism, (E) Extroversion, and (N) Neuroticism. Psychoticism is associated with rebelliousness, aggressiveness, and impulsiveness, and is related to testosterone levels. The extroversion vs. introversion dimension is related to the social interest and positive affect. Eysenck showed that extroversion-introversion is a matter of the balance of neural "inhibition" and "excitation", since extroversion is based on cortical arousal, measurable through skin conductance. Neuroticism or emotional stability vs. instability corresponds to the stability of behavior over time and the person's adaptation to the environment. Finally, neuroticism is based on activation thresholds in the sympathetic nervous system, measurable through heart rate, blood pressure, hand temperature, perspiration, and muscular tension.</p><p>We chose the PEN model of personality because of its biologically inspired nature and its explicit treatment of introversion and extroversion, factors that are specifically relevant to the assistive context. Previous work with stroke patients <ref type="bibr" target="#b9">[10]</ref> demonstrated significant personality differences in patient response to the robot therapist. This work aims to address those differences directly, by focusing on the extroversionintroversion personality dimension. Another inspiration for this work is the observed influence of the pre-stroke personality on post-stroke recovery. It has been noted that subjects classified as extroverted before the stroke mobilize their strength easier to recover than do introverted subjects <ref type="bibr" target="#b15">[16]</ref>. Since the extroversion dimension (see Fig. <ref type="figure">1</ref>) comprises many different factors, habits, and behaviors, in this study we give higher importance to extroversion-introversion traits, to map them to the spectrum of therapy styles that range from nurturing to challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Interaction design</head><p>To date, none of the existing robotic systems for socially assistive applications integrate personality in their behavioral model. Inspired by Bandura's model of reciprocal influences on behavior <ref type="bibr" target="#b2">[3]</ref>, we believe that it is helpful to incorporate personality in order to facilitate human-robot interaction (HRI) and robot behavior selection. Figure <ref type="figure" target="#fig_1">2</ref> depicts our Fig. <ref type="figure">1</ref> The Eysenck <ref type="bibr" target="#b12">[13]</ref> introvert and extrovert adjectives of human personality general robot behavior control architecture, which integrates the Eysenck model.</p><formula xml:id="formula_0">I N T R O V E R T E D N E S S E X T R O V E R T E D N E S S</formula><p>The extroversion-introversion dimension is based on the observed inter-correlations between traits such as sociability, activity, impulsiveness, liveliness and excitability, all of which strongly influence behavior. In our interaction design, we chose to use two of those traits: (1) sociability and ( <ref type="formula">2</ref>) activity. These traits can be most readily emulated in robot behavior. We expressed those traits through three main parameters that define the therapist robot behavior: (1) interaction distance/proxemics, (2) speed and amount of movement, and (3) verbal and para-verbal communication. These are described in more detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sociability</head><p>Sociability is the trait that most clearly expresses a person's level of extroversion-introversion. A large body of research in social psychology has shown that individual behavioral differences are most apparent in social situations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b31">33]</ref>. In [20], Harkins et al. empirically illustrated that both the presence of others and their social activities are typically more enjoyed by extroverts than by introverts. In <ref type="bibr" target="#b9">[10]</ref>, Eysenck described the extrovert as sociable, friendly, talkative and outgoing. In contrast, the introvert is quiet, introspective, and prefers small groups of intimate friends. We posit that these are directly related to verbal and non-verbal communication patterns. Hence, we identified proxemics and vocal features (i.e., content, volume, and speech rate) as relevant aspects to be embodied in the robot's behavior. Each is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Proxemics</head><p>The interpersonal space in human interactions has been widely studied in social psychology, since the seminal paper by Hall <ref type="bibr" target="#b18">[19]</ref> who coined the term proxemics. Recently, -Intimate: Up to 0.25 m from the body; usually involves contact (e.g., embracing, comforting), can be uncomfortable and intrusive; -Personal: Between 0.3 and 1 m; typically used for family and friend interactions; -Social: About 1-3 m; used in business meetings and public spaces; -Public: Beyond 3 m; e.g., the distance between an audience and speaker.</p><p>The robot must ensure its own appropriate use of and respect for interaction space so that a human user can feel safe, comfortable, and in concordance with his/her personality preferences. In this work, we focus only on personal and social interaction spaces. Neither intimate space nor public space is appropriate for our application; the former implies contact while we are using a non-contact (hands-off) HRI approach and the latter involves no one-to-one interaction. Hall <ref type="bibr" target="#b18">[19]</ref> found a strong link between human sense of space and human behavior and personality type. We posit that extroverted individuals, who like social interactions, may prefer to have the robot physically closer than introverted individuals, who may perceive the robot as invading their space. Therefore, proxemics can be encoded as function of the individual extroversion-introversion level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Verbal and para-verbal communication</head><p>Both vocal content and paralinguistic cues, such as volume and speech rate, play important roles in human interactions, and express personality and emotion <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b37">40,</ref><ref type="bibr" target="#b51">54]</ref>. The similarity-attraction principle, which assumes that indivi-duals are more attracted to others who manifest the same personality, has been studied in human-machine interaction (HCI) (e.g., <ref type="bibr" target="#b35">[37]</ref>). Also, studies <ref type="bibr" target="#b5">[6]</ref> have found that prosodic characteristics are linked with features of personality, e.g., excitement or arousal (extroversion-introversion) are strongly correlated to prosodic features such as pitch level <ref type="bibr" target="#b50">[53]</ref>, pitch range, and tempo <ref type="bibr" target="#b1">[2]</ref>. The interaction scripts that we designed in this work display extroverted and introverted personality type through the choice of words and paralinguistic cues. More details about the different interaction scripts are given in Experimental Validation (Sect. 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Activity</head><p>In addition to sociability, we also considered the activity trait. Eysenck <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> linked the human extroversion-introversion personality trait with the activity level and showed that people with high activity scores are generally energetic and favor physical activity, while individuals with low scores tend to be physically inactive. He suggested that high activity is an extrovert characteristic, while low activity tends to characterize introversion. In our system, the activity of the robot is correlated/matched to the user's movement and sociability, and is expressed through the robot's speed and amount of movement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Behavior adaptation system</head><p>The main goal of our robot behavior adaptation system is to enable us to dynamically optimize the three main parameters (interaction distance/proxemics, speed, and vocal content) that define the behavior (and thus personality) of the therapist robot, so as to adapt it to the user's personality and thus improve the user's task performance. Task performance is measured as the number of exercises performed in a given 123 period of time; the learning system changes the robot's personality, expressed through the robot's behavior, in an attempt to maximize the task performance metric.</p><p>We formulated the problem as policy gradient reinforcement learning (PGRL) and developed a learning algorithm that consists of the following steps: (a) parametrization of the behavior; (b) approximation of the gradient of the reward function in the parameter space; and (c) movement towards a local optimum. More details about the PGRL algorithm can be found in <ref type="bibr" target="#b20">[22]</ref> and <ref type="bibr" target="#b48">[51]</ref>. Other reinforcement learning techniques, such as Q-Learning, learn an action-value function. However, Q-learning, designed for Markov decision processes, cannot directly be applied to our problem since there is no obvious notion of state.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the pseudo-code of our PGRL algorithm. The n-dimensional policy gradient algorithm implemented for this work starts from an initial policy π = {θ 1 , θ 2 , . . . , θ n } (where n = 3 in our case, corresponding to the three main interaction parameters: interaction distance/proxemics, speed and amount of movement, and verbal and para-verbal communication). For each parameter θ i we also define a perturbation step i to be used in the adaptation process. The perturbation step defines the amount by which the parameter may vary to provide a gradual migration toward the locally optimal policy. The use of PGRL requires the creation of a reward function to evaluate the behavior of the robot as parameters change. The robot is started with the initial policy π , and its learning process can be summarized as the following steps:</p><p>1. The robot acts given the current set of parameters (π run ). 2. The reward function is evaluated to measure the performance of the robot. 3. The loop returns to step 1, possibly with an updated policy due to the adaptation process, until the time limit for the exercise is reached.</p><p>The reward function is monitored to prevent it from falling under a given threshold, which would indicate that the robot's current behavior does not provide the patient with an ideal recovery scenario. This triggers the activation of the adaptive phase of the PGRL algorithm, to adjust the behavior of the robot to the continually changing factors that determine the efficiency of the recovery process. The adaptation algorithm has the following main steps:</p><p>1. Generate k random policies in the vicinity of the current parameter set π run (lines 15-20). Each of the perturbed arrays in the set P = {π 1 , π 2 , . . . , π k } is calculated by randomly adding either + i , 0, ori to each of the parameters in the current policy π run . 2. Record the performance of the robot (the reward function) for each perturbed array. 3. When all the k perturbed arrays have been evaluated proceed to compute the new "stable" parameter set that will presumably increase the performance of the robot (lines 22-40).</p><p>Computing the direction in which to change each parameter to maximize the user's task performance is done over the recorded reward functions for the k perturbed arrays. This has itself three steps, as follows:</p><p>1. For each parameter p i compute the average reward over the k perturbed runs for each of the types of perturbations (i.e., + , 0, -) of the parameter. The average rewards are recorded in the array avg, as described between lines 25 and 27 in the algorithm presented in Figure <ref type="figure" target="#fig_2">3</ref>. These three averages give an estimate of the benefit of altering parameter i by + i , 0, ori . 2. The direction in which each parameter moves is computed between line 28 and line 32 in the algorithm. If the best performance was obtained with the parameter being unchanged then the parameter should remained unchanged (thus a i = 0). Otherwise, compute which direction (+ or -) produced better results (line 31). 3. Use the contents of a to compute the new set of parameters for use in the steady (non-adaptive) state.</p><p>The selection of the reward function for evaluating the behavior of the robot was one of the major challenges in implementing the adaptive algorithm. The main issues with computing the reward function and applying the adaptive algorithm in our approach were the following: (1) the events that mark the interaction between the robot and the participant are discrete, so computing the reward function can only occur at discrete points in time; (2) the evaluation of the reward function must take into consideration both: (i) the fact that as the user performs the exercises s/he will become fatigued which results in slowing down of performance regardless of the personality of the robot and the other parameters that we considered, and (ii) the fact that the robot adapts and acts differently can distract the patient, slowing down his/her response. With these factors in mind, we designed the reward function as follows: (1) we counted the number of exercises performed by the user during a given period of time, and (2) we adjusted the threshold value to reduce the effects of fatigue and distraction caused by the adaptation procedure.</p><p>Other research that uses the same mechanism for adaptation has been been conducted either in more consistent environments than ours, or with the ability to continuously evaluate the reward function, which makes adaptation take place in real-time. For applications like the one described in Kohl and Stone <ref type="bibr" target="#b20">[22]</ref>, where the authors try to maximize the speed of a robot, the reward function is clearly determined; it is the speed of the robot. In our application, the efficiency of the robot in encouraging and directing the patient through the recovery process, a highly subjective measure, must somehow be assessed. Furthermore, in <ref type="bibr" target="#b20">[22]</ref>, the same robot was used in the same environment for each variation of the parameters. This allowed for an accurate account of improvements for each variations of the parameters by reducing the number of uncontrolled factors that can affect the computation of the reward function. In our application, the reward function depends not only on the robot's parameters, but also on the user, who can be unpredictable and inconsistent, which necessarily makes the evaluation of the reward function more difficult, and possibly inaccurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental validation</head><p>In this section we present a series of hypothesis about the matching between the personality of the user and that of the robot it interacts with and we validate them using a set of experiments. Our experiments try to address two issues. First, we investigate the user-robot personality matching. Second, using the results of the first experiment, we refine the matching process between the user and the robot using our adaptation algorithm to increase the user's efficiency in performing the task at hand. We analyze how varying minor characteristics of the robot's personality impacts the efficiency of the user and whether the robot is able to converge to a set of characteristics that are in consensus with the user's preferences.</p><p>To date, our system has been validated only with healthy participants. In order to be able to obtain more relevant results, the healthy volunteers used their non-dominant limb (their weaker side) while doing the specified tasks. They were also encouraged to establish a social relationship with the robot based on its personality and act as they would normally do when interacting with a person with similar personality characteristics.</p><p>We begin this section by introducing the robot system that was used in our experiments and continue with the overview of the experiments we conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Robot test-bed</head><p>Our experimental test-bed, shown in Fig. <ref type="figure" target="#fig_3">4</ref>, consisted of an ActiveMedia Pioneer 2-DX mobile robot base, equipped with a SICK LMS200 laser rangefinder used to track and identify people in the environment by detecting reflective fiducials worn by users. On the stroke-affected limb, the users wore a light-weight motion-capture system based on inertial measurement units (IMU) that allowed the robot to detect and track the user's limb movement <ref type="bibr" target="#b29">[31]</ref>.</p><p>Physical form and appearance of the robot were not a focus of the presented research. Eriksson et al. <ref type="bibr" target="#b9">[10]</ref> successfully used the same platform to assess a socially assistive robot that interacted with post-stroke patients. Our future work will make use of a new biomimetic humanoid torso mounted on the mobile platform illustrated above, in order to test the effectiveness of an anthropomorphic vs. a nonanthropomorphic robot in a rehabilitation scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">User-robot personality matching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Hypotheses</head><p>Based on the principle of similarity attraction <ref type="bibr" target="#b35">[37]</ref>, the following hypotheses were formulated in order to test the userrobot personality matching. Hypothesis 1: A robot that challenges the user during rehabilitation therapy rather than praising her/him will be preferred by users with extroverted personalities and will be less appealing to users with introverted personalities.</p><p>Hypothesis 2: A robot that focuses on nurturing praise rather than on challenge-based motivation during the training program will be preferred by users with introverted personalities and will be less appealing to users with extroverted personalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Experimental design</head><p>The robot could manifest (non)social and (low)high activity traits through its behavior to express the extroversion (challenging) or introversion (nurturing) therapy styles. The vocal content and para-verbal cues used in this experiment are described in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Before participating in the experiment, each subject was asked to complete two questionnaires: one for determining personal details such as gender, age, occupation, and educational background, and another for establishing the subject's personality traits based on the Eysenck Personality Inventory (EPI) <ref type="bibr" target="#b13">[14]</ref>. The four experimental tasks were intended </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extroversion</head><p>• challenging language (e.g., "You can do it!", "Concentrate on your exercise!") • high pitch and volume as functional exercises similar to those used during standard stroke rehabilitation:</p><p>• Drawing up and down, or left and right on an easel; • Lifting and moving books from a desktop to a raised shelf;</p><p>• Moving pencils from one bin to another;</p><p>• Turning pages of a newspaper.</p><p>The participants were asked to perform the four tasks in a sequence as part of a predefined scenario, but they could stop the experiments at any time by saying "stop". Each task lasted 4 minutes, after which the robot verbally advised the user to change the task. At the end of each experiment, the experimenter presented a short debriefing.</p><p>Vocal data were collected from the user using a microphone and interpreted using automatic voice analysis software. The robot was capable of understanding the following four utterances: "yes", "agree", "no", and "stop". The participant wore a motion sensor on the (non-dominant/weaker) upper arm to monitor movement. A reflective laser fiducial was strapped around one of their calves to allow the robot to identify him/her, as shown in Fig. <ref type="figure" target="#fig_4">5</ref>.</p><p>Each participant was exposed to two different assistive personalities of the robot: one that matched his/her personality according to the Eysenck Personality Inventory (EPI) and one that was randomly chosen from the remaining options. The system evaluation was performed based on user introspection (questionnaires). After each experiment, the participant completed two questionnaires designed to evaluate impression of the robot's personality (e.g., "Did you find the robot's character unsociable?") and about the interaction with the robot (e.g., "The robot's personality is a lot like mine."). All questions were presented on a 7-point Likert scale ranging from "strongly agree" to "strongly disagree".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Experimental results</head><p>The subject pool for this experiment consisted of 19 participants (13 male, 6 female; 7 introverted and 12 extroverted). To test the match between the user's and robot's personality, we asked the participants to rate whether they felt that the "robot's personality was a lot like yours", on a Likert scale from 1 (strongly disagree) to 7 (strongly agree). Table <ref type="table" target="#tab_1">2</ref> shows averaged results.</p><p>While the overall mean of the responses was very close to the midpoint, "neither agree, nor disagree", for both the interaction with the introverted and the extroverted robot, the participants tended to match their personality to the robot's as described below. Extroverted users rated the extroverted robot as significantly closer to their personality than the introverted robot (extroverted robot M = 4.91, introverted robot M = 3.16). Introverted users thought that the introverted robot matched their personality better (M = 4.57) than the extroverted one (M = 3.57). To validate our hypotheses and to make sure that the variation in the means between extroverted and introverted users for interaction with each type of robot personality is significant and that it is due to the variation between the treatment levels (the user's personality) and not due to random error, we performed an analysis of variance (ANOVA).</p><p>The first set of data consisted of the answers provided by all participants during their interaction with the extroverted robot. The results obtained in this case for a significance level α = 0.05 were: M extro-user = 4.91, M intro-user = 3.57, F 0.05 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref> = 10.7680, p = 0.0044. Thus, our hypothesis was validated by the results in this case. The probability ( p = 0.0044) of the null hypothesis, which affirms that the variation is only due to random error, is extremely low. The results obtained from data collected during the interaction with the introverted robot validated our hypothesis as well: M intro-user = 4.57, M extro-user = 3.16, F 0.05 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref> = 15.810, p = 0.0010. In this case the validity of the null hypothesis is even lower ( p = 0.001).</p><p>By design, the extroverted robot had a challenge-based style of user encouragement, while the introverted robot used a nurturing therapy style. We also analyzed the correlation between the extroversion-introversion personality of the robot and the user's perception of challenge-based vs. nurturing style of encouragement that it used. The users were asked to rate the robot encouragement style on a Likert scale from 1 (Nurturing) to 7 (Challenging). On average, the participants classified the introverted robot as more nurturing (M = 3.21) and the extroverted robot as more challenging (M = 5.10).</p><p>None of the 38 trials was terminated by the experimenter. The end of a trial was either a sequence of "stop" utterances said by the user or the end of the four exercises. Because of the high sensitivity of the speech recognition system, participant breathing and ambient noise were on occasion incorrectly detected as a "stop" or "no", ending the interaction prematurely. Figure <ref type="figure">6</ref> shows the average interaction time (in minutes) spent by the extroverted/introverted users with extroverted/introverted robots, respectively. To validate our hypothesis that the interaction time with each type of robot personality was significant we performed an analysis of the variance (ANOVA). The results strongly supported our hypothesis, as follows. For the interaction with the introverted robot the means and probability of the null hypothesis being true were: M intro-user = 7.41, M extro-user = 5.21, F 0.05 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref> = 10.4337, p = 0.0049. For the interaction 123 Fig. <ref type="figure">6</ref> The average interaction time (minutes) spent by introverted/ extroverted users with introverted/extroverted robots, respectively with the extroverted robot the results were: M intro-user = 6.1, M extro-user = 8.11, F 0.05 <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17]</ref> = 9.8092, p = 0.0061.</p><p>Another interesting finding resulting from the participant debriefings was that a large percentage of participants (77%) would have preferred to speak more with the robot and to have a more complex dialog with it. Our future work will enrich the verbal communication between the participants and the robot.</p><p>In summary, the experimental studies validated our two hypotheses. The participants with extroverted personalities had a preference for a robot that challenged them during exercises over the one that focused the interaction on praise. Analogously, users with introverted personalities preferred the robot that focuses on nurturing praise rather than on challenge-based motivation during the training program. Thus, the results show user preference for human-robot personality matching in the socially assistive context. Further experiments with larger and more representative participant pools (i.e., stroke patients) are being addressed in our continuing work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Robot behavior adaptation</head><p>Two experiments were designed to test the adaptability of the robot's behavior to the participant's personality and preferences. In each experiment, the human participant stood and faced the robot. The experimental task was a common object transfer task used in post-stroke rehabilitation and consisted of moving pencils from one bin on the left side of the participant to another bin on his/her right side. The bin on the right was on a scale in order to measure the user's task performance. The system monitored the number of exercises performed by the user.</p><p>The participants were asked to perform the task for 15 min, but they could stop the experiment at any time. At the end of each experiment, the experimenter presented a short debriefing. Before starting the experiments, the participants were asked to complete the same two questionnaires as in the previous experiment: (1) a general introductory questionnaire in which personal details such as gender, age, occupation, and educational background were determined and (2) a personality questionnaire based on the Eysenck Personality Inventory (EPI) <ref type="bibr" target="#b13">[14]</ref> for establishing the user's personality traits.</p><p>The robot used the algorithm described in Sect. 5 to adapt its behavior to match each participant's preferences in terms of therapy style, interaction distance, and movement speed. The learning algorithm was initialized with parameter values that were in the vicinity of what was thought to be acceptable for both extroverted and introverted individuals, based on the user-robot personality matching study described above. The values are shown in Table <ref type="table" target="#tab_2">3</ref>.</p><p>The PGRL algorithm used in our experiments evaluated the performance of each policy over a period of 60 s. The reward function, which counted the number of exercises performed by the user in the previous 15 s was computed every second and the results over the 60 s "steady" period were averaged to provide the final evaluation for each policy.</p><p>To adjust for the fatigue incurred by the participant, the threshold for the reward function that triggered the adaptation phase of the algorithm was set to 7 exercises at each evaluation for the first 10 min of the exercise and was lowered to 6 exercises thereafter. The threshold and the time ranges are all customizable parameters in our algorithm. The values for these parameters were chosen based on empirical data collected during trial runs before the actual experiments. In the post-experiment survey, the participants were asked to provide their preferences related to the therapy styles of the robot, including the robot's vocal cues, interaction distances, and speed, as described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Robot behavior adaptation to user personality-based therapy styles</head><p>Experimental design The goal of this experiment was to test the adaptability of the robot behavior to the user personalitybased therapy style preference. Four different scenarios were designed for both extroverted and introverted personality types: the therapy styles ranged from coach-like therapy to encouragement-based therapy for extroverted personality types, and from supportive therapy to nurturing therapy for introverted personality types (see Table <ref type="table">4</ref>). The words and phrases for each of these scenarios were selected in concordance with encouragement language used by professional rehabilitation therapists. The coach-like therapy script was composed of strong and aggressive language (e.g., "Move! Move!", "You can do more than that!"). Higher volume and faster speech rate were used in the pre-recorded transcript voice, based on the evidence that those cues are associated with high extroversion <ref type="bibr" target="#b35">[37]</ref>. The aggressiveness of the terms used, the volume, and the speech rate diminished along with the robot's movement toward the nurturing therapy style of the interaction spectrum. The nurturing therapy script contained only empathetic, gentle, and comforting language (e.g., "I'm glad you are working so well.", "I'm here for you.", "Please continue just like that", "I hope it's not too hard"). The voice used had lower volume and pitch. A set of 3 interaction distances and speeds were chosen for each introverted and extroverted personality type, as shown in Table <ref type="table" target="#tab_3">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental results</head><p>The subject pool consisted of 12 participants (7 male and 5 female). The participants ranged in age between 19 and 35, 27% were coming from a nontechnological field, while 73% worked in a technologyrelated area. Figure <ref type="figure">7</ref> summarizes the collected data as a graph of the participants and therapy style choices. For each participant and possible therapy style, we display a bar representing the percentage of time spent by the robot in the given therapy style while interacting with the participant. The relative size of the bars for the same participant illustrates the percentage of time spent in each of the four therapy styles of the robot. The crosses represent the top preference of the participant as reported in the post-experiment survey. As shown in Fig. <ref type="figure">7</ref>, Fig. <ref type="figure">7</ref> The percentage of time that the 12 participants interacted with each of the four therapy styles of the robot (for extroverted and introverted participants, as described in Table <ref type="table">4</ref>). The crosses represent the participants' preferences Fig. <ref type="figure">8</ref> The percentage of time that the 12 participants interacted with the robot at a certain distance (for extroverted and introverted participants, as described in Table <ref type="table" target="#tab_3">5</ref>). The crosses represent the participants' interaction distances preference the robot adapted to match the preference of the participant in almost every case.</p><p>The only exception was the interaction with participant 8. Despite the fact that the time spent in the preferred training style of that participant was smaller than the time spent in other training styles, the robot converged to it at the end of the exercise period. The cause for this inconsistency was the fact that the initial state of the robot was in a training style that was furthest from the preference of the participant. Since our approach only allowed perturbations to neighboring training styles, and the duration of the exercise was short, the optimal match was not found in time.</p><p>Figure <ref type="figure">8</ref> shows the adaptability of the robot to the interaction distance preferred by the participant. Results are shown on the same type of graph, but here there were only three options for the parameter. The results support our hypothesis that the robot could adapt its behavior to both introverted and extroverted participants. The graph shows small inconsistencies (3 cases) between the preferred interaction distance and the distance that was used most by the robot during the exercise. It is worth noting however that in all three cases the time spent in each of the two options (the robot's choice and the user's preference) were almost equal. After a more detailed analysis of the data we realized that the mitigating factors for this effect were: (1) the user performed almost indistinguishably when the robot found itself in either of the two options, which prevented the robot from having any basis for discerning between the two; and (2) both options were in the social space, making it harder to distinguish between them. We believe that increasing the length of the exercises and using a different reward function for this parameter might improve the adaptation process.</p><p>On a general note, both the extroverted and the introverted personalities chose the interaction distance within the personal space rather than in the social space.</p><p>The results obtained for the third parameter in our system, the speed of the robot when moving around the user, were subject to more misses than those for the first two parameters. While the robot used higher speeds for interacting with extroverted participants and lower speeds for interacting with introverted participants, it overshot the preference of the user in many cases. We believe this was due to the fact that this had a comparatively lower impact on user's performance. Also, as reported in the debriefings, many participants were taken somewhat by surprise by the questions regarding the preference in speed, as they were not able to clearly identify the three speeds used by the robot during the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Robot behavior adaptation to user preferences</head><p>Experimental design In the third experiment, we wanted to ensure the robot was able to adapt to the user's preferences, in order to build an engaging and motivating customized protocol. People are more influenced by certain voices and accents than others. Two main scenarios were designed, one for extroverted and one for introverted individuals, respectively (see Table <ref type="table" target="#tab_0">1</ref>). The scenario for the extroverted group was challenge-based while the scenario for the introverted individuals was more nurturing, in accordance with the results of our previous study. We pre-recorded the same scenario with 2 males (one with an accent of a French native speaker, and one without an accent as an American native English speaker) and 2 females (one with an accent of a Romanian native speaker, and one without an accent as an American native English speaker), as shown in Table <ref type="table" target="#tab_4">6</ref>.</p><p>The choice of interaction distances/proxemics and robot movement speeds was the same as in the previous experiment (see <ref type="bibr">Table 5)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental results</head><p>The experimental group for the third experiment consisted of 12 participants (7 male and 5 female). The participants ranged in age between 19 and 35, 27% were coming from a non-technological field, while 73% had a technology-related occupation.</p><p>The results of the third experiment, which tested the ability of the robot to adapt to the user's preference of a certain robot's personality as expressed through accent and voice gender are presented next. The results were again consistent with our assumption that the algorithm we employed would allow the robot to adapt and match the participant's preferences in most cases.</p><p>Figure <ref type="figure">9</ref> shows the results in the same format as used in our previous experiment. The results show three special cases. In all three cases a detailed analysis shows that the performance of the participant (number 4, 5 and 7) was almost indistin- Fig. <ref type="figure">9</ref> The percentage of time that the 12 participants interacted with each of the four therapist robot's personality as expressed through accent and voice gender (gender and English accent, as described in Table <ref type="table" target="#tab_4">6</ref>).</p><p>The crosses represent the participant's preferences guishable when the robot acted under the participant's first choice of robot's personality as expressed through accent and voice gender and the state in which the robot spent most time.</p><p>In fact, the second choice of the user, as rated in the postexperiment survey, was in fact the one in which the robot spent most time.</p><p>For this experiment the distance between the robot and the user (see Fig. <ref type="figure">10</ref>) did not perfectly match the preference of the user. We believe that this was caused by several factors:</p><p>-The number of adaptation steps was rather small compared to the size of the state space of the parameters (we used 5 variations of the parameters with each adaptation sequence out of the 36 possible variations). -The changes in the robot's personality expressed through accent and voice gender parameter were too distracting (male-to-female or female-to-male changes in robot's voice), which diminished the importance of other parameters involved in the adaptation process. -This parameter had a rather lower impact on the user performance compared to the other parameters.</p><p>To improve the adaptation process we plan on varying only one of the parameters at a time. This will allow for more accurately measuring the impact of each variation on Fig. <ref type="figure">10</ref> The percentage of time that the 12 participants interacted with the robot at a certain distance (for extroverted and introverted participants, as described in Table <ref type="table" target="#tab_3">5</ref>). The crosses represent the participants' interaction distances preference user performance and for adapting more efficiently to each dimension of the parameters space. Finally, the results obtained for the third parameter (the speed of the robot) were similar to those for the distance. This supports our interpretation that in certain cases where changes in one parameter are more distracting and have a stronger impact on the participant, the analysis should be separated by varying one parameter at a time. We will consider implementing this option as another component of the adaptation process.</p><p>The results obtained in the adaptation experiments point out one possible limitation of our approach. Due to the large number of combinations of parameter values that have to be investigated during the adaptation phase, the optimal policy might be obtained only after a period of time that exceeds our exercise sessions (which were 15 min long). However, we feel that this does not reduce the efficiency of our approach or the relevance of our results, as our research targets interaction with patients for an extended period of time, when many therapy sessions are required for complete rehabilitation. Thus, if the optimal policy is not reached during one therapy session, the adaptation process can be extended over several sessions, with most of the interaction occurring with the optimal policy in place. This is similar to real-life situations where therapists get to know patients over several therapy sessions and improve in their ability to respond to clues to provide a more efficient recovery environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion and conclusion</head><p>We presented a non-contact therapist robot intended for monitoring, assisting, encouraging, and socially interacting with post-stroke users during rehabilitation exercises. The role of the robot's personality in the hands-off therapy process was investigated, with a focus on the relationship between the level of extroversion-introversion of the robot and the user and the ability of the robot to adapt its behavior to user personality and preferences expressed through task performance. The experimental results provide first evidence for the preference of personality matching in the assistive domain and the effectiveness of robot behavior adaptation to user personality and performance.</p><p>Our future work is aimed at evaluating the approach in a time-extended user study with post-stroke patients. The longitudinal study will allow us to eliminate the effects of novelty, and will also enable the robot to adapt better to the user given vastly more learning trials. Further, it will allow us to investigate various reward functions toward understanding the impact of each parameter over the success rate of the adaptation process. Continuing research will also focus on including empathy in the robot's behavior control architecture and using physiological data as a way of measuring and interpreting the user's internal state.</p><p>Our work to date demonstrates the promises of socially assistive robotics, a new research area with large horizons of fascinating and much needed societally-relevant research. Our ongoing efforts are aimed at developing effective embodied assistive systems, and expanding our understanding of human social behavior. Socially assistive robotic technology is still in its infancy, but near future promises assistive robotic platforms and systems that will be used in hospitals, schools, and homes in therapeutic programs that monitor, encourage, and assist their users.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig.2HRI information processing using the personality model of the user. The sensory input of the robotic system consisted of (1) a laser range finder used for navigation and people detection; (2) a microphone for speech detection and recognition; (3) a motion capture device for detecting the human user movement. The robot's behavior is based on its current sensory input, human user personality, and its previous interaction with the environment</figDesc><graphic coords="5,196.87,108.56,97.96,89.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Pseudo-code for the Policy Gradient Reinforcement Learning (PGRL) Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Robot test-bed; an ActiveMedia Pioneer 2-DX mobile robot equipped with a SICK laser range scanner, a camera, and speakers</figDesc><graphic coords="8,53.56,56.45,232.84,302.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5</head><label>5</label><figDesc>Fig.<ref type="bibr" target="#b4">5</ref> The first experimental setup: the participant is performing Task 4 (turning pages of a newspaper) with the robot at a social distance. The laser fiducial is on the participant's right leg, the motion sensor on the right arm, and a microphone is worn on standard headphones</figDesc><graphic coords="9,53.56,57.05,232.84,311.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Choice of vocal content and para-verbal cues for testing the user-robot personality matching</figDesc><table><row><cell>Personality</cell></row></table><note><p><p>trait Vocal content and para-verbal cues Introversion</p>• nurturing, script containing gentle and supportive language (e.g., "I know it's hard, but remember it's for your own good.", "Very nice, keep up the good work.") • low pitch and volume</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Average of results obtained for testing the matching between the user's and robot's personality (disagreement = 1, agreement = 7)</figDesc><table><row><cell></cell><cell>Extroverted</cell><cell>Introverted</cell><cell>Overall</cell></row><row><cell></cell><cell>users mean</cell><cell>users mean</cell><cell>mean</cell></row><row><cell>Extroverted robot</cell><cell>4.91</cell><cell>3.57</cell><cell>3.68</cell></row><row><cell>Introverted robot</cell><cell>3.16</cell><cell>4.57</cell><cell>4.42</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>Initial parameters for the behavior adaptation</cell><cell>Robot behavior parameters</cell><cell></cell><cell>Initial values</cell><cell>Step size</cell></row><row><cell>algorithm</cell><cell cols="2">Therapy style and robot's personality as expressed</cell><cell>Id = 1</cell><cell>1</cell></row><row><cell></cell><cell cols="2">through vocal content and para-verbal cues</cell><cell></cell></row><row><cell></cell><cell>Interaction distance/proxemics</cell><cell>Extroverted</cell><cell>0.7 m</cell><cell>0.5 m</cell></row><row><cell></cell><cell></cell><cell>Introverted</cell><cell>1.2 m</cell><cell>0.5 m</cell></row><row><cell></cell><cell>Speed</cell><cell>Extroverted</cell><cell>0.1 m/s</cell><cell>0.1 m/s</cell></row><row><cell></cell><cell></cell><cell>Introverted</cell><cell>0.1 m/s</cell><cell>0.05 m/s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>The choice of interaction distances/proxemics and robot's speed parameters as a function of the user-personality</figDesc><table><row><cell>Parameter</cell><cell cols="2">Extroverted</cell><cell></cell><cell cols="2">Introverted</cell><cell></cell></row><row><cell cols="7">Interaction distance/ Id = 1 Id= 2 Id= 3 Id= 1 Id= 2 Id= 3</cell></row><row><cell>proxemics (m)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell>1.2</cell><cell>1.7</cell><cell>1.2</cell><cell>1.7</cell><cell>2.2</cell></row><row><cell>Speed (m/s)</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.1</cell><cell>0.15</cell><cell>0.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 The</head><label>6</label><figDesc></figDesc><table><row><cell>choice of therapist robot's personality as expressed</cell><cell>Parameter</cell><cell>Id = 1</cell><cell>I d = 2</cell><cell>I d = 3</cell><cell>I d = 4</cell></row><row><cell>through english accent and voice gender as a function of the user-preferences</cell><cell>Therapist robot's personality as expressed through English accent and voice gender</cell><cell>Female with accent</cell><cell>Male with accent</cell><cell>Male without accent</cell><cell>Female without accent</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors thank Yann Petiot, Emily Mower, and Nate Koenig for lending their voices to the therapist robot.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shared control framework applied to a robotic aid for the blind</title>
		<author>
			<persName><forename type="first">P</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccarragher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation (ICRA&apos;98)</title>
		<meeting>the IEEE international conference on robotics and automation (ICRA&apos;98)<address><addrLine>Leuven, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="712" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Effects of pitch and speech rate on personal attributions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Apple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Krauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Personal Soc Psychol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="715" to="727" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Principles of behavior modification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bandura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<pubPlace>Holt, Rinehart &amp; Wilson, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Perspective taking: an organizing principle for learning in human-robot interaction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Berlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st national conference on artificial intelligence (AAAI)</title>
		<meeting>the 21st national conference on artificial intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Feedback distortion to overcome learned nonuse: a system overview</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Brewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klatzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Eng Med Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1613" to="1616" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Acoustic determinants of the perceptions of personality from speech</title>
		<author>
			<persName><forename type="first">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rencher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Sociol Language</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Development of robots for rehabilitation therapy: the palo alto va/stanford experience</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Burgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Shor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Loos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Rehabil Res Develop</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="639" to="652" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Embodied social interaction for robots</title>
		<author>
			<persName><forename type="first">H</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pacchierotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and simulation of behavior convention (AISB&apos;05)</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="40" to="45" />
		</imprint>
	</monogr>
	<note>Hertsfordshire, UK pp</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Personality theories: a guide to human nature</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Dicaprio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>Holt, Rinehart &amp; Wilson, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hands-off assistive robotics for post-stroke arm rehabilitation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Winstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on rehabilitation robotics (ICORR&apos;05)</title>
		<meeting>the IEEE international conference on rehabilitation robotics (ICORR&apos;05)<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An introduction to theories of personality</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Ewen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The structure of human personality</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Eysenck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1953">1953</date>
			<pubPlace>Methuen, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dimensions of personality: 16, 5 or 3? criteria for a taxonomic paradigm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Eysenck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personal Individ Diff</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="773" to="790" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Eysenck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Eysenck</surname></persName>
		</author>
		<title level="m">Manual: Eysenck Personality Inventory. Educational and Industrial Testing Service</title>
		<meeting><address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Defining socially assistive robotics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Feil-Seifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on rehabilitation robotics (ICORR&apos;05)</title>
		<meeting>the IEEE international conference on rehabilitation robotics (ICORR&apos;05)<address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="465" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Personality influences psychological adjustment and recovery from stroke</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghahramanlou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arnoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wozniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kittner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Stroke Association&apos;s 26th international stroke conference</title>
		<meeting>the American Stroke Association&apos;s 26th international stroke conference<address><addrLine>Fort Lauderdale, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Encouraging physical therapy compliance with a hands-off mobile robot</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gockley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first international conference on human-robot interaction (HRI&apos;06)</title>
		<meeting>the first international conference on human-robot interaction (HRI&apos;06)<address><addrLine>Salt Lake City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="150" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cooperation with a robotic assistant</title>
		<author>
			<persName><forename type="first">J</forename><surname>Goetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiesler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international conference on computer-human interaction (CHI&apos;02)</title>
		<meeting>the international conference on computer-human interaction (CHI&apos;02)<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="578" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extraversionintroversion and the effects of favorability and set size on impression formation</title>
		<author>
			<persName><forename type="first">Et ;</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stonner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull Psychonomic Soc</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="300" to="302" />
			<date type="published" when="1966">1966. 1975</date>
		</imprint>
	</monogr>
	<note>Hidden dimension. Doubleday, Gordon City 20</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A robot workstation for use in education of the physically handicapped</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Harwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ginige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="131" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Policy gradient reinforcement learning for fast quadrupedal locomotion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation (ICRA&apos;04)</title>
		<meeting>the IEEE international conference on robotics and automation (ICRA&apos;04)<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2619" to="2624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robot-aided neurorehabilitation: from evidence-based to science-based rehabilitation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Krebs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Volpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fasoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Palazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rohrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Edelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top Stroke Rehabil</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="54" to="70" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The navchair assistive wheelchair navigation system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="443" to="451" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A plan-based personalized cognitive orthotic</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international conference on AI planning and scheduling</title>
		<meeting>the 6th international conference on AI planning and scheduling<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Toward a new generation of personality theories: theoretical contexts for the five factor model. The five factor model of personality: Theoretical perspectives</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mccrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Costa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="51" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robotoy contest -designing mobile robotic toys for autistic children</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clavet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Society for engineering education (ASEE&apos;01)</title>
		<meeting>the American Society for engineering education (ASEE&apos;01)<address><addrLine>Alberqueque, NM, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Asutonomous spherical mobile robot to study child development</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Laplante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larouche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Duquette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Masson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Syst Man Cybern</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="480" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Perspectives on mobile robots used as tools for pediatric rehabilitation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Duquette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Laplante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Assist Technol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="14" to="29" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Socially intelligent agents -creating relationships with computers and robots</title>
		<author>
			<persName><forename type="first">F</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Theberge-Turmel</surname></persName>
		</author>
		<editor>Billard A, Dautenhahn K, Canamero L, Edmonds B</editor>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Mobile robotic toys and autism</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Motion capture from inertial sensing for untethered humanoid teleoperation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kallmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Drumwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-RAS international conference on humanoid robotics (Humanoids-2004)</title>
		<meeting>the IEEE-RAS international conference on humanoid robotics (Humanoids-2004)<address><addrLine>Santa Monica, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Experiences with a mobile robotics guide for the elderly</title>
		<author>
			<persName><forename type="first">M</forename><surname>Montemerlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th AAAI national conference on artificial intelligence</title>
		<meeting>the 18th AAAI national conference on artificial intelligence<address><addrLine>Edmonton, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="587" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Extraversion and introversion: an interactional perspective</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Morris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Hemisphere, Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Review of research on the myers-briggs type indicator</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Percept Motor Skills</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1187" to="1202" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Social intelligence in a human-machine collaboration system: Social responses to agents with mind model and personality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Morishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Jpn Soc Artif Intell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="184" to="196" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The functionality of human-machine collaboration systems mind model and social behavior</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sbc</forename><surname>Nass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Morishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on systems, man, and cybernetics</title>
		<meeting>the IEEE conference on systems, man, and cybernetics<address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="2381" to="2387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Does computer-synthesized speech manifest personality? experimental tests of recognition, similarityattraction, and consistency-attraction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Appl</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="181" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning and interacting in human-robot domains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nicolescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans Syst Man Cybernet special issue on Socially Intelligent Agents -The Human in the Loop</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Voice in social interaction: an interdisciplinary approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pittman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Sage, Thousand Oaks</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A storytelling robot for pediatric rehabilitation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Druin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dakhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Vice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montemayor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM/SIGCAPH conference on assistive technologies (ASSETS&apos;00)</title>
		<meeting>the 4th ACM/SIGCAPH conference on assistive technologies (ASSETS&apos;00)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="50" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Webbased tele-rehabilitation of the upper extremity after stroke</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Reinkensmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nesseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Painter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="102" to="108" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Robotic assistants in therapy and education of children with autism: can a small humanoid robot help encourage social interaction skills?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boekhorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>Universal Access in the Information Society (UAIS</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Towards personal service robots for the elderly</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baltus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gemperle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Magaritis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montemerlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on interactive robots and entertainment</title>
		<meeting>the workshop on interactive robots and entertainment<address><addrLine>Pittsburgh, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How social robots will help us to diagnose, treat and understand autism</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scassellatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th international symposium of robotics research (ISSR&apos;05)</title>
		<meeting>the 12th international symposium of robotics research (ISSR&apos;05)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Quantitative metrics of social response for autism diagnosis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Scassellatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IEEE international workshop on robot and human interactive communication (RO-MAN&apos;05)</title>
		<meeting>the 14th IEEE international workshop on robot and human interactive communication (RO-MAN&apos;05)<address><addrLine>Nashville, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Development and evaluation of voice control for a smart wheelchair</title>
		<author>
			<persName><forename type="first">R</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the rehabilitation engineering society of North America annual conference</title>
		<meeting>the rehabilitation engineering society of North America annual conference<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="417" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Intrinsically motivated reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chentanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the advances in neural information processing systems 17 (NIPS)</title>
		<meeting>the advances in neural information processing systems 17 (NIPS)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pamm -a robotic aid to the elderly for mobility assistance and monitoring</title>
		<author>
			<persName><forename type="first">D</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hisamitsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Haoyong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on robotics and automation ICRA&apos;00</title>
		<meeting>the IEEE international conference on robotics and automation ICRA&apos;00<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="570" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The huggable: a therapeutic robotic companion for relational, affective touch</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Stiehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lieberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Basel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maymin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Purchase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE consumer communications and networking conference</title>
		<meeting>the IEEE consumer communications and networking conference<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Neural Informat Process Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1057" to="1063" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Towards socially assistive robotics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tapus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Robotics Soc Jpn</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="14" to="16" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>JRSJ)</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The prosody of excitement in horse race commentaires</title>
		<author>
			<persName><forename type="first">J</forename><surname>Trouvain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ISCA -Workshop on speech and emotion</title>
		<meeting>the ISCA -Workshop on speech and emotion<address><addrLine>Newcastle, Northern Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="86" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The sounds of dominance: Vocal precursors of perceived dominance during interpersonal influence</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Tusing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Commun Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="148" to="171" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Analysis of factors that bring mental effects to elderly people in robot assisted activity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/RSJ international conference on intelligent robots and systems (IROS&apos;02)</title>
		<meeting>the IEEE/RSJ international conference on intelligent robots and systems (IROS&apos;02)<address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1152" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Close encounters: spatial distances between people and a robot of mechanistic appearance</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Koay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boekhorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nehaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Werry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-RAS international conference on humanoid robots (Humanoids&apos;05)</title>
		<meeting>the IEEE-RAS international conference on humanoid robots (Humanoids&apos;05)<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Tsukuba International Congress Center</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="450" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Meet paro, the therapeutic robot seal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Walton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>CNN</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Is this robot like me? links between human and robot personality traits</title>
		<author>
			<persName><forename type="first">S</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boekhorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Koay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-RAS international conference on humanoid robots (Humanoids&apos;05)</title>
		<meeting>the IEEE-RAS international conference on humanoid robots (Humanoids&apos;05)<address><addrLine>Tsukuba, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Tsukuba International Congress Center</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="375" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Evaluating the performance of assistive robotic systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on performance metrics for intelligent systems</title>
		<meeting>the workshop on performance metrics for intelligent systems<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
