<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FPGAs vs. CPUs: Trends in Peak Floating-Point Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Keith</forename><surname>Underwood</surname></persName>
							<email>kdunder@sandia.gov</email>
							<affiliation key="aff0">
								<orgName type="department">Sandia National Laboratories</orgName>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<postBox>PO Box 5800</postBox>
									<postCode>MS-1110, 87185-1110</postCode>
									<settlement>Albuquerque</settlement>
									<region>NM</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">FPGA&apos;04</orgName>
								<address>
									<postCode>22-24, 2004</postCode>
									<settlement>February, Monterey</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FPGAs vs. CPUs: Trends in Peak Floating-Point Performance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC11ED6F87974E22262911D23FA8EF76</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Performance Attributes; C.1.3 [Other Architecture Styles]: Adaptable Architectures FPGA</term>
					<term>floating point</term>
					<term>supercomputing</term>
					<term>trends</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Moore's Law states that the number of transistors on a device doubles every two years; however, it is often (mis)quoted based on its impact on CPU performance. This important corollary of Moore's Law states that improved clock frequency plus improved architecture yields a doubling of CPU performance every 18 months. This paper examines the impact of Moore's Law on the peak floating-point performance of FPGAs. Performance trends for individual operations are analyzed as well as the performance trend of a common instruction mix (multiply accumulate). The important result is that peak FPGA floating-point performance is growing significantly faster than peak floating-point performance for a CPU.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The consistency of Moore's law has had a dramatic impact on the semiconductor industry. Advances are expected to continue at the current pace for at least another decade yielding feature sizes of 45 nm by 2009 <ref type="bibr" target="#b1">[1]</ref>. Every two years the feature size for CMOS technology drops by over 40%. This translates into a doubling of transistors per unit area and a doubling of clock frequency every two years. The microprocessor industry has translated this into a doubling of CPU performance every 18 months. Over the last six years, clock rate has yielded a 12× improvement in CPU performance while architectural changes have only yielded a 1× to 4× improvement (depending on the operation considered). The additional transistors are typically used to compensate for the "memory wall" <ref type="bibr" target="#b2">[2]</ref>. Design constraints and legacy instruction sets prevent CPU architects from moving the necessary state closer to the computation; thus, additional functional units would go underutilized.</p><p>Unlike CPUs, FPGAs have a high degree of hardware configurability. Thus, while CPU designers must select a resource allocation and a memory hierarchy that performs well across a range of applications, FPGA designers can leave many of those choices to the application designer. Simultaneously, the dataflow nature of computation implemented in field programmable gate arrays (FPGAs) overcomes some of the issues with the memory wall. There is no instruction fetch and much more local state can be maintained (i.e. there is a larger "register set"). Thus, data retrieved from memory is much more likely to stay in the FPGA until the application is "done" with it. As such, applications implemented in FPGAs are free to utilize the improvements in area that accompany Moore's law.</p><p>Beginning with the Xilinx XC4085XL, it became possible to implement IEEE compliant, double-precision, floatingpoint addition and multiplication; however, in that era, FP-GAs were much slower than commodity CPUs. Since then, FPGA floating-point performance has been increasing dramatically. Indeed, the floating-point performance of FP-GAs has been increasing more rapidly than that of commodity CPUs. Using the Moore's law factors of 2× the area and 2× the clock rate every two years, one would expect a 4× increase in FPGA floating-point performance every two years. This is significantly faster than the 4× increase in CPU performance every three years. But area and clock rate are not the entire story. Architectural changes to FPGAs have the potential to accelerate (or decelerate) the improvement in FPGA floating-point performance. For example, the introduction of 18 × 18 multipliers into the Virtex-II architecture dramatically reduce the area needed to build a floating-point multiplier. Conversely, the introduction of extremely high speed I/O and embedded processors consumed area that could have been used to implement additional programmable logic 1 .</p><p>These trends, coupled with the potential of FPGAs to sustain a higher percentage of peak performance, prompted this analysis of floating-point performance trends. Modern science and engineering is becoming increasingly dependent on supercomputer simulation to reduce experimentation requirements and to offer insight into microscopic phenomena. Such scientific applications at Sandia National Labs depend on IEEE standard, double precision operations. In fact, many of these applications depend on full IEEE compliance (including denormals) to maintain numerical stability. Thus, this paper presents the design of IEEE compliant single and double precision floating-point addition, multiplication, and division. The performance and area requirements of these operators, along with the multiply accumulate composite operator, is given for five FPGAs over the course of 6 years. From this data, long term trend lines are plotted and compared against known CPU data for the same time period. Each line is extrapolated to determine a long term "winner".</p><p>The remainder of this paper is organized as follows. Section 2 presents related work on floating-point in FPGAs. The implementation of the floating-point operations is then presented in Section 3. Section 4 presents the comparison of FPGA and CPU performance trends. Finally, Section 5 presents conclusions and Section 6 presents future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>This work is motivated by an extensive body of previous work in floating-point for FPGAs. A long series of work <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr">7]</ref> has investigated the use of custom floating-point formats in FPGAs. There has also been some work in the translation of floating-point to fixed point <ref type="bibr" target="#b8">[8]</ref> and the automatic optimization of the bit widths of floating-point formats <ref type="bibr" target="#b9">[9]</ref>. In most cases, these formats are shown to be adequate for some applications, to require significantly less area to implement than IEEE formats <ref type="bibr" target="#b10">[10]</ref>, and to run significantly faster than IEEE formats. Most of these efforts demonstrate that such customized formats enable significant speedups for certain chosen applications. Unfortunately, many scientific applications depend on both the dynamic range and high precision of IEEE double-precision floating-point to maintain numerical stability. Thus, this work focuses on the IEEE standard. Indeed, some application developers within the DOE labs are beginning to discuss the need for greater precision than the standard IEEE formats, and such formats may be the topic of future work.</p><p>The earliest work on IEEE floating-point <ref type="bibr" target="#b11">[11]</ref> focused on single precision and found that, although feasible, it was extremely slow. Later work <ref type="bibr" target="#b12">[12]</ref> found that the performance was improving, but still relatively poor. Eventually, it was demonstrated <ref type="bibr" target="#b13">[13]</ref> that while FPGAs were uncompetitive with CPUs in terms of peak FLOPs, they could provide competitive sustained floating-point performance. Since then, a variety of work <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr">7,</ref><ref type="bibr" target="#b15">15]</ref> has demonstrated the growing feasibility of IEEE compliant, single precision floatingpoint arithmetic and other floating-point formats of approximately that complexity. Indeed, some work <ref type="bibr" target="#b16">[16]</ref> suggests that a collection of FPGAs can provide dramatically higher 1 This is not to say that these innovations are not good or not important to the future of FPGAs in computing. A number of these works have focused on optimizing the format and the operators to maximize FPGA performance. In <ref type="bibr" target="#b14">[14]</ref> a delayed addition technique is used to achieve impressive clock rates. In other work, <ref type="bibr" target="#b4">[4,</ref><ref type="bibr">7]</ref>, the details of the floating-point format are varied to optimize performance. The specific issues of implementing floating-point division in FPGAs has been studied <ref type="bibr" target="#b15">[15]</ref>. Similarly, <ref type="bibr" target="#b17">[17]</ref> studied how to leverage new FPGA features to improve general floatingpoint performance, but neither covered double precision arithmetic. Indeed, little work has considered the performance of IEEE double precision floating-point and no work to date has considered the trends in FPGA performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">IMPLEMENTATION</head><p>Three IEEE 754 compliant arithmetic operations (addition, multiplication, and division) were implemented for both single precision and double precision formats. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the IEEE format. The exponents are maintained in biased notation (bias-127 or bias-1023 as noted). Exponents of zero and the maximum value of the field (255 and 2047, respectively) are reserved for special values. The mantissa is maintained with an implied one. That is, in all but special cases, the mantissa is formed by adding a "1" before the value stored. The decimal place is always immediately to the left of the stored value. This requires numerous normalization elements in compliant implementations.</p><p>The IEEE 754 standard has a number of interesting features that must be taken into account for a compliant implementation. First, there are exception conditions that require the generation of NaN, infinity, and zero. Second, these special values must be handled as inputs to the operations. Third, gradual underflow (or denormal processing) must be provided. Finally, IEEE specifies four rounding modes.</p><p>These floating-point units provide correct output in all exception conditions, but do not provide special exception signals. It is unclear how such signals would be used in an FPGA design, but addition of these signals would be trivial if needed. They also provide proper handling of all special values and provide full denormal processing. Roundto-nearest-even is the IEEE rounding mode provided in the initial implementation, but other rounding modes could be added as options.</p><p>Each of these experiments used Synplify 7.3 from Synplicity running on a Redhat 9 platform for synthesis. IOB flip-flops were prohibited and aggressive clock rate targets (relative to realized clock rates) were used. Each design was synthesized for 5 parts from Xilinx families spanning the last 6 years (the choice of parts will be discussed in Section 4). Xilinx 4.2i tools on a Solaris platform were used to place and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Addition Implementation</head><p>IEEE floating-point addition consists of three major functions: pre-normalization, operation (including rounding), and post-normalization. Pre-normalization and post-normalization are shift operations requiring shifts (in increments of one) from 0 to N , where N is the width of the mantissa including the implied 1. The nature of these shifts provides proper handling of denormal cases with very little modification. The operation at the core of floating-point addition is either an addition or subtraction (depending on the signs of the inputs) that is N + 4 bits wide. The increase in width is necessary to handle the possibility of carry out and to handle all rounding cases.</p><p>The floating-point addition units accept one parameter -a maximum latency. This parameter controls the number of pipeline registers that are inserted. This is handled by inserting a total of 14 register components (for double precision, 13 for single precision) that accept a boolean to indicate if a register should be inserted. If more than half of the registers are requested, additional registers are added at the start of the pipeline (where the stages are slightly more complicated). Register insertion points were chosen with a number of metrics. Heavy emphasis was placed on regularity of the pipeline with registers preferentially placed in places that would yield an approximately constant width. Pre-normalization and post-normalization shifts were broken into smaller shifts to reduce routing and logic complexity with an optional register at each shift stage. Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table">2</ref> give the area requirements and performance of the double and single precision floating-point adders when pipelined to their maximum depth. This table does not show 3-LUT usage for the XC4000 series because 3- LUTs seldom dominate area usage. There is a slight variation in the area usage across device families. These relatively minor variations are an artifact of the optimizations performed by the tool chains (including such optimizations as logic replication to reduce fan-out). One clear trend is that the mapper uses far more slices than would appear to be necessary. Some experimentation was done to determine if a "more full" device would prompt the mapper to pack the logic more densely, but there was no significant impact observed. Careful hand optimization would likely cut the number of slices used by almost 30%. Another striking trend observed in Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table">2</ref> is the relatively small performance gain when moving from double to single precision. This is because the longest pipeline stage is an early pipeline stage which is handling exponent calculations and manipulating the mantissa. These stages change little between the single and double precision operations -the exponent only changes in length by three bits and mux width has relatively little impact on performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multiplication Implementation</head><p>The fundamental multiplication operation is conceptually simple: multiply the mantissas, round, and add the exponents. The multiply (of the mantissas) is not required to maintain the full precision of an N × N multiply. All of the partial products must be generated, but the summation can accumulate most of the lower bits into a single "sticky bit". The result only needs to be maintained to two bits wider than the mantissa (plus the sticky bit) to preserve enough information for proper rounding. Unfortunately, compliance with the IEEE standard complicates this significantly. First, the inputs could be denormal. If so, maintaining proper precision (without a full N × N multiplier) requires the smaller number to be normalized. If the larger input is denormal, the result will underflow. Second, one input could be the special value, NaN. If so, the exact value of the NaN input must be preserved and propagated. Finally, two non-denormal inputs could produce a denormal result. This requires that the final output be normalized, or rather denormalized, appropriately.</p><p>In this implementation, the multiply of the mantissas was separated into a separate component. This hides the multiply implementation from the rest of the design (save for the pipeline depth of the multiply which must be specified in the upper level design). This was important because there is a wide variety of multiply implementations offering optimizations for such things as datapath regularity, latency, or use of the embedded multipliers. Two multiplier implementations were developed in this design -one that uses the embedded multipliers (and requires nine of them for dou- The floating-point multiplier design has three parameters. The maximum latency specifies the pipeline stages which are allocated as they are in the adder. The worst case latency is 20 cycles for the double precision multiplier (or 39 with no embedded multipliers) and 16 cycles for the single precision multiplier (or 24 with no embedded multipliers). The second parameter provides the option to support denormals. Eliminating denormals implies that denormal numbers are treated as zeroes for both inputs and outputs and saves significant area. The final parameter provides optional use of the embedded multipliers. This parameter must be false for XC4000, Virtex, and VirtexE designs and may be false for newer parts if desired.</p><p>Tables <ref type="table" target="#tab_1">3</ref> and<ref type="table" target="#tab_2">4</ref> highlight the performance characteristics of the double precision and single precision multipliers, respectively. Area requirements drop substantially when the embedded multipliers are used. Performance of the Virtex-II implementation would be significantly higher, but Stepping-0 parts were used instead of the Stepping-1 parts<ref type="foot" target="#foot_0">2</ref> , which would provide significantly higher performance embedded multipliers. As with the adder, hand placement of the multiplier could probably reduce the slice utilization by as much as 30%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Division Implementation</head><p>The implementation of floating-point division is very similar to that of floating-point multiplication. It must divide the mantissas, round, and subtract the exponents. A full precision divide is required, but the first N steps can be skipped because the inputs are normalized. The remainder is used to calculate the "sticky" bit. As with the multiplier, compliance with the IEEE standard is complicated. Denormal inputs must be normalized, but in this case if both inputs are denormal, both must be normalized. Similarly, NaN inputs must be preserved and non-denormal inputs can create a denormal output that requires normalization.</p><p>As with the floating-point multiplier, the divide of the mantissas is separated from the rest of the design to simplify the substitution of better divide implementations. Only one divide implementation (pipelined bit serial) was provided. This is probably not the best divide option (in terms of area); however, it is adequate to be competitive with a commodity CPU. Two parameters are available for the divider. The first is a maximum latency that is used to allocate reg- isters in the design in the same way it is used in the multiplier and adder. The worst case latency is 67 cycles for the double precision divider and 37 cycles for the single precision divider. The second parameter enables (or disables) the support of denormals, which can provide a substantial area savings at the cost of IEEE compliance. Tables <ref type="table" target="#tab_3">5</ref> and<ref type="table">6</ref> list the performance and area requirements of the double precision and single precision dividers. The double precision divider did not fit on the XC4085XLA so the performance was estimated using the ratio between double and single precision multiply (a similar operation) on the same device. Surprisingly, a single double precision floatingpoint unit in an FPGA has throughput to match that of a commodity CPU. The latency (in terms of clock cycles and absolute time) is substantially worse in the FPGA, but the advantage in throughput is substantial. As with the other components, the slice utilization is substantially higher than seems necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multiply Accumulate Implementation</head><p>Multiply accumulate is the fundamental composite operator for a number of operations including matrix multiply, matrix vector multiply, and a number of matrix solution methods including the popular LINPACK benchmark <ref type="bibr" target="#b18">[18]</ref> that qualifies supercomputers for the Top500 list <ref type="bibr" target="#b19">[19]</ref>. As such, multiply accumulate was chosen for comparison along with the other basic operations. The implementation of multiply accumulate simply combines a multiplier and an adder with some appropriate control logic. Because both the multiplier and adder are deeply pipelined, multiple concurrent multiply accumulates must occur to maximize performance (although correctness is maintained in either case). The multiply accumulate operator accepts all of the parameters available on the multiplier or adder as well as CONCURRENCY, which controls the number of concurrent multiply accumulates, and VLENGTH, which controls the number of results from the multiplier that are accumulated into one result.</p><p>Tables <ref type="table" target="#tab_4">7</ref> and<ref type="table">8</ref> list the characteristics of the double and Note that performance of the double precision multiply accumulate on the XC4085XLA must be estimated as it did not fit in the device. The performance of the slower component from the composite operation (the double precision multiplier) was used for this estimate. Again, some variation in the 4-LUT, FF, and Slice counts is seen between families with minor variations in the optimization done by the synthesizer. In each case, the latency of the multiplier and the adder in the multiply accumulate is the same as was used in the stand alone tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PERFORMANCE PROJECTIONS</head><p>In this section, the peak floating-point performance of FP-GAs is derived from the implementation data in Section 3. Peak FPGA performance is calculated as the number of functional units that can be instantiated times the clock rate. In turn, the number of functional units that can be instantiated is simply the number of slices (or CLBs in the case of the XC4000 series) available divided by the number of slices required for the functional unit. Although these are first order approximations, this number is approximately as realistic as peak performance numbers for a commodity microprocessor. Peak performance is presented for five FPGA devices over six years and is compared with three commodity microprocessors over the same time period.</p><p>Peak floating-point performance is extrapolated for both the microprocessors and FPGAs. For the microprocessor, performance is doubled every 18 months to represent the well known corollary of Moore's law. The trend line is forced through the 2003 data point for microprocessors. Since no such corollary has been established for FPGAs, the trend line is derived by starting with the 1997 data point, selecting a very conservative fit, and rounding the slope down.</p><p>Table <ref type="table" target="#tab_5">9</ref> lists the parts chosen for the performance comparison. The commodity microprocessor with the highest peak performance was chosen for each of three years (regardless Virtex-II 6000-5 2003 Virtex-II Pro 100-6 Pentium-4 3.2 GHz of the release date during the year). Since microprocessor performance trends are well known, only three data points were deemed necessary. Similarly, five FPGAs were chosen for data points over the course of the same 6 years. An effort was made to choose the largest, fastest speed grade part with reasonable availability during that year<ref type="foot" target="#foot_1">3</ref> . For 2001, a stepping 0 Virtex-II 6000-5 device was chosen. Device stepping 1 was released early the next year and significantly improved the embedded multiplier performance. The part chosen for 1997 was chosen to be as representative as possible of the devices that would have been available; however, there was a constraint on which devices could be placed and routed for these experiments. The oldest tools that were available were Xilinx 4.2i, which do not support parts older than the XC4000XLA series. The XC4085XL-2 might have been a better choice, but the tools available would not target that device.</p><p>Admittedly, there are limitations to this type of analysis; however, the conservative assumptions that were made and the dramatic performance improvements projected should compensate for such limitations so that the "answer" is unchanged. For example, the order of magnitude performance advantage in 2009 may carry the same cost premium as current large devices. However, cheaper members of the same FPGA family will likely achieve a cost and performance advantage since FPGA performance is typically linear within a family, but cost is almost exponential. A second limitation is the lack of accounting for structures such as address generation and integer computation units. Such units are typically very simple in an FPGA. Furthermore, a hand placed version of the floating-point functional units should yield at least a 10% clock rate increase and a 25% reduction in area. The space that is freed (including the removal of 10% of the functional units while maintaining performance) should be more than adequate to support address generation structures. Finally, I/O between the CPU and FPGA is not considered. The underlying assumption is that FP-GAs (with embedded CPUs) will either replace the primary CPU in a supercomputer or will be important enough to be coupled into a supercomputing system in such a way as to mitigate the I/O issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Addition</head><p>Figures <ref type="figure" target="#fig_1">2 (a)</ref> and<ref type="figure">(b</ref>) indicate that FPGAs have significantly higher floating-point addition performance than commodity CPUs. This is a surprising revelation since FPGAs are generally considered to provide poor floating-point performance at best. More surprising still is the fact that FP-GAs have been ahead for almost four years. The trend line for floating-point addition on FPGAs projects a growth rate of 4× every two years. This trend line is diverging from the performance trend line for CPUs, which is only 2× every 18 months. Notably, double precision addition performance on CPUs has been growing slower than the trend line for the last 6 years, but the single precision addition performance has been growing slightly faster than the trend line. This is primarily attributable to a dramatic one time architectural improvement that was achieved with the addition of multimedia instructions.</p><p>FPGAs achieve this significant advantage over CPUs because their resources are configurable. If an application requires a very addition rich mixture of instructions, the FPGA can provide that. In contrast, commodity CPUs have a fixed allocation of resources that can be successful for a well mixed instruction stream, but has significant limitations in code that is dominated by one instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multiplication</head><p>FPGAs have not dominated CPUs in floating-point multiplication performance for nearly as long they have in floatingpoint addition performance. Figures <ref type="figure" target="#fig_1">2(c</ref>) and (d) indicate that FPGAs have only exceeded CPUs in multiplication performance for three years in single precision arithmetic and two years in double precision arithmetic. However, the trend lines are diverging more rapidly with multiplication performance growing at an average rate of 5× per year over the last 6 years. This is primarily because of the addition of 18 × 18 fixed multipliers in recent parts. The use of these components to implement the multiply of the mantissas (9 for double precision, 4 for single precision) dramatically reduced the area required. This trend is likely to continue since architectural improvements (notably faster, wider, fixed multipliers) are likely to continue.</p><p>The CPU performance in Figures <ref type="figure" target="#fig_1">2 (c</ref>) and (d) has grown slightly faster than the Moore's law trend line over the last 6 years. For double precision, this is primarily because of a change between 1997 and 2000 to allow multiplies to issue every cycle. For single precision, it is primarily from the addition of multimedia instructions that utilize SIMD parallelism. In both cases, similar improvements are not on the processor roadmaps over the next few years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Division</head><p>As seen in Figures <ref type="figure" target="#fig_1">2 (e</ref>) and (f), FPGAs have long exceeded CPUs in floating-point division performance -with one minor caveat. An XC4085XLA is not big enough (by a significant margin) to implement a double precision divider. Thus, the "performance" of a double precision divider on that part is the fraction of the divider it can implement times the estimated clock rate. This explains why the 4× trend line overestimates the performance of the 2003 part: components that can implement the operation are constrained to integer multiples of divide units. The XC4085XLA had a second artificial performance inflation because the mapper packed the CLBs much tighter to try (in vain) to make it fit. Thus, the area estimate is significantly smaller than it would otherwise be. For the single precision divider, performance of FPGAs has tracked a 4× trend line fairly well.</p><p>Commodity microprocessors are not well optimized for divide operations. This is a significant issue for some scientific applications <ref type="bibr" target="#b20">[20]</ref>. Slow divides have first and second order effects: the division instructions are slow (and unpipelined) and these slow instructions clog the issue queue for modern microprocessors. This makes divide rich applications a good target for FPGA implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multiply Accumulate</head><p>Multiply accumulate is somewhat different from the other operations considered in that it is a composite operation. More importantly, it is a composite operation that is fundamental to a number of matrix operations (including LIN-PACK). Unfortunately, Figure <ref type="figure" target="#fig_2">3</ref> indicates that FPGAs are still somewhat slower than CPUs at performing this operation. FPGAs are, however, improving at a rate of 4.5× every two years. This improvement rate (effectively a composite of the performance improvements in addition and multiplication) yields a significant win for FPGAs by the end of the decade.</p><p>It would be easy to suggest that the comparison between FPGA and CPU in this case is not "fair" because the FPGA requires many concurrent multiply accumulates (in one multiply accumulate functional unit) to overcome the latency of the adder and achieve the projected performance; however, it should be noted that the Pentium-4 must alternate issuing two adds and two multiplies<ref type="foot" target="#foot_2">4</ref> with 4 cycle and 6 cycle latency, respectively, to achieve its peak performance <ref type="bibr" target="#b21">[21]</ref>. With the small register set in the IA-32 ISA, this is not necessarily easier to exploit than the concurrency and parallelism available on the FPGA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis</head><p>A common theme among the performance graphs is the flattening of the performance trend line from 2000 to 2003. This is supported by the data in Figure <ref type="figure" target="#fig_3">4</ref>, which clearly indicates a flattening in the growth of area, increase in clock rate, and feature size reduction. This appears to bode ill for the projected performance trends; however, a closer look at Figure <ref type="figure" target="#fig_3">4</ref> indicates differently. In Figure <ref type="figure" target="#fig_3">4</ref>(a), the trend in FPGA feature size broke sharply between 2001 and 2003, but it is still on the same overall trend line for the 6 year period as CPUs. Indeed, low cost FPGAs have already been introduced on the 90 nm process -well ahead of CPUs. High performance parts are expected to be introduced next year concurrently with CPUs based on 90 nm technology. Similarly, Figure <ref type="figure" target="#fig_3">4</ref>(b) shows that the pace of FPGA density improvements has dropped sharply from 2000 to 2003, but overall density increases are still above the Moore's law projection. Even if a much larger device (the XC40125EX) was used as the 1997 baseline, the overall density improvement would remain slightly above the Moore's law projection.</p><p>Figure <ref type="figure" target="#fig_3">4</ref>(c) seems to tell a slightly different story with regards to clock rate. The "Moore's law" trend line for clock rate provides a reference that clearly indicates that clock rate has not scaled as expected. However, this seeming discrepancy is relatively easy to explain. This device used as representative of 1997 technology for these experiments was the XC4085XLA-09. A more accurate part would have been the XC4085XL-2, but the Xilinx 4.2i tools that were available for these experiments would not process such a device. A XC4085XL-2 part is approximately 40% slower than the XC4085XLA-09 part used. Combining this with the significant performance increase that Virtex-II Pro parts   should receive as the tool chain develops trends in clock rates that meet the expectations of Moore's law. Improvement in addition and division performance are derived strictly from technology improvement; however, the 5× every two years performance growth of multipliers will be difficult to maintain indefinitely. Fortunately, only minor improvements are needed each generation to realize this gain. This should be readily achievable through 2009 (wider embedded multipliers, enhanced support for shifting, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>This paper has presented designs for single and double precision IEEE compliant floating-point addition, multiplication, and division. For each of these operations, an FPGA has a higher peak floating-point performance than a CPU. This occurs because FPGAs are able to customize the allocation of resources to meet the needs of the application while CPUs have fixed functional units. CPUs currently have higher peak performance than FPGAs for applications that fully utilize the CPU's fixed resources. An excellent example of this is the multiply accumulate primitive which is the core of matrix multiplication and matrix vector multiplication. Preliminary work <ref type="bibr" target="#b22">[22]</ref>, however, indicates that real applications can have instruction mixes that are highly biased toward a single type of operation.</p><p>The more important result is the illustration of the trends in floating-point performance for both FPGAs and CPUs. While CPUs are following a well known corollary of Moore's law (doubling in performance every 18 months), FPGA performance is increasing by 4× every two years. For operations that use the architectural improvements in FPGAs, performance is increasing at a rate of 5× every two years. Projecting these trends forward yields an order of magnitude advantage in peak performance for FPGAs by 2009. This has important implications for the design of supercomputers in that era since FPGAs should sustain as high, and potentially higher, percentage of peak than CPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">FUTURE WORK</head><p>Peak performance is the metric most commonly used when announcing the latest supercomputer acquisition. If for no other reason, this makes it an important metric to study; however, in the end, sustained performance is a better metric for how quickly a system can perform work. As an example, the Top500 list <ref type="bibr" target="#b19">[19]</ref> uses LINPACK <ref type="bibr" target="#b18">[18]</ref> performance as a metric. Unfortunately, for many applications, LINPACK performance is closer to peak performance than sustained performance on real applications. Future work will focus on floating-point computational cores that are representative of the workload at Sandia. These cores will be implemented to compare the sustained performance of FPGAs and CPUs. Furthermore, a portion of these studies will focus on how an FPGA might be integrated in future supercomputers to leverage these performance advantages. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: IEEE floating-point formats: (a) single precision and (b) double precision</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Floating-point addition performance for: (a) double precision, and (b) single precision. Floatingpoint multiplication performance trend for: (c) double precision, and (d) single precision. Floating-point division performance trend for: (e) double precision, and (f ) single precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Floating-point multiply accumulate performance trend for: (a) double precision, and (b) single precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Basic FPGA property trends including: (a) CMOS Feature size, (b) density in 4-LUTs, and (c) clock rate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>IEEE double precision floating-point adder characteristics.</figDesc><table><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>1334</cell><cell>1226</cell><cell>960</cell><cell>33</cell></row><row><cell>Virtex 1000-5</cell><cell>1433</cell><cell>1408</cell><cell>1096</cell><cell>78</cell></row><row><cell>Virtex-E 3200-7</cell><cell>1458</cell><cell>1349</cell><cell>1075</cell><cell>94</cell></row><row><cell>Virtex-II 6000-5</cell><cell>1407</cell><cell>1408</cell><cell>1090</cell><cell>125</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>1406</cell><cell>1408</cell><cell>1090</cell><cell>143</cell></row><row><cell cols="5">Table 2: IEEE single precision floating-point adder</cell></row><row><cell>characteristics.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>587</cell><cell>600</cell><cell>441</cell><cell>38</cell></row><row><cell>Virtex 1000-5</cell><cell>622</cell><cell>651</cell><cell>487</cell><cell>85</cell></row><row><cell>Virtex-E 3200-7</cell><cell>622</cell><cell>693</cell><cell>501</cell><cell>110</cell></row><row><cell>Virtex-II 6000-5</cell><cell>611</cell><cell>696</cell><cell>496</cell><cell>165</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>611</cell><cell>696</cell><cell>495</cell><cell>195</cell></row></table><note><p>route the XC4000XLA series part and Xilinx 5.2i tools on a Solaris platform were used for all other parts. Timing constraints were adjusted to optimize final timing results with an "extra effort level" of 2. No floorplanning or placement constraints were used at this time.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>IEEE double precision floating-point multiplier characteristics.</figDesc><table><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>4381</cell><cell>4940</cell><cell>2954</cell><cell>25</cell></row><row><cell>Virtex 1000-5</cell><cell>4535</cell><cell>5047</cell><cell>3810</cell><cell>50</cell></row><row><cell>Virtex-E 3200-7</cell><cell>4535</cell><cell>5171</cell><cell>3844</cell><cell>68</cell></row><row><cell>Virtex-II 6000-5</cell><cell>2016</cell><cell>2354</cell><cell>1607</cell><cell>105</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>2016</cell><cell>2354</cell><cell>1608</cell><cell>142</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>IEEE single precision floating-point multiplier characteristics.</figDesc><table><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>1661</cell><cell>1579</cell><cell>1103</cell><cell>38</cell></row><row><cell>Virtex 1000-5</cell><cell>1268</cell><cell>1487</cell><cell>1080</cell><cell>89</cell></row><row><cell>Virtex-E 3200-7</cell><cell>1279</cell><cell>1487</cell><cell>1087</cell><cell>113</cell></row><row><cell>Virtex-II 6000-5</cell><cell>772</cell><cell>821</cell><cell>598</cell><cell>124</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>762</cell><cell>821</cell><cell>592</cell><cell>176</cell></row><row><cell cols="5">ble precision) in Virtex-II and Virtex-IIPro and a second</cell></row><row><cell cols="5">(pipelined bit serial) that is very regular in structure for use</cell></row><row><cell cols="3">in XC4000 and Virtex series parts.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>IEEE double precision floating-point divider characteristics.</figDesc><table><row><cell>Part</cell><cell cols="3">4-LUTs FFs Slices</cell><cell>MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>4910</cell><cell>9199</cell><cell>4821</cell><cell>23 (est.)</cell></row><row><cell>Virtex 1000-5</cell><cell>8061</cell><cell>9231</cell><cell>6856</cell><cell>50</cell></row><row><cell>Virtex-E 3200-7</cell><cell>8076</cell><cell>9323</cell><cell>6909</cell><cell>58</cell></row><row><cell>Virtex-II 6000-5</cell><cell>7981</cell><cell>9391</cell><cell>6858</cell><cell>83</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>7976</cell><cell>9391</cell><cell>6880</cell><cell>98</cell></row><row><cell cols="5">Table 6: IEEE single precision floating-point divider</cell></row><row><cell>characteristics.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>1583</cell><cell>2380</cell><cell>1498</cell><cell>28</cell></row><row><cell>Virtex 1000-5</cell><cell>2207</cell><cell>2475</cell><cell>1925</cell><cell>60</cell></row><row><cell>Virtex-E 3200-7</cell><cell>2214</cell><cell>2473</cell><cell>1928</cell><cell>78</cell></row><row><cell>Virtex-II 6000-5</cell><cell>2200</cell><cell>2476</cell><cell>1929</cell><cell>100</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>2199</cell><cell>2476</cell><cell>1927</cell><cell>120</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 :</head><label>7</label><figDesc>IEEE double precision floating-point multiply accumulate characteristics.</figDesc><table><row><cell>Part</cell><cell cols="3">4-LUTs FFs Slices</cell><cell>MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>5812</cell><cell>6512</cell><cell>3679</cell><cell>25 (est.)</cell></row><row><cell>Virtex 1000-5</cell><cell>6333</cell><cell>6512</cell><cell>5031</cell><cell>50</cell></row><row><cell>Virtex-E 3200-7</cell><cell>6333</cell><cell>6528</cell><cell>5034</cell><cell>63</cell></row><row><cell>Virtex-II 6000-5</cell><cell>3804</cell><cell>3818</cell><cell>2877</cell><cell>100</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>3806</cell><cell>3818</cell><cell>2875</cell><cell>140</cell></row><row><cell cols="5">Table 8: IEEE single precision floating-point multi-</cell></row><row><cell cols="3">ply accumulate characteristics.</cell><cell></cell><cell></cell></row><row><cell>Part</cell><cell cols="4">4-LUTs FFs Slices MHz</cell></row><row><cell>XC4085XLA-09</cell><cell>2339</cell><cell>2363</cell><cell>1673</cell><cell>37</cell></row><row><cell>Virtex 1000-5</cell><cell>2125</cell><cell>2242</cell><cell>1699</cell><cell>78</cell></row><row><cell>Virtex-E 3200-7</cell><cell>2137</cell><cell>2242</cell><cell>1707</cell><cell>110</cell></row><row><cell>Virtex-II 6000-5</cell><cell>1617</cell><cell>1573</cell><cell>1206</cell><cell>127</cell></row><row><cell>Virtex-IIP 100-6</cell><cell>1612</cell><cell>1573</cell><cell>1203</cell><cell>175</cell></row><row><cell cols="5">single precision multiply accumulate operations, respectively.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 9 :</head><label>9</label><figDesc>Parts used for performance comparison</figDesc><table><row><cell>Year</cell><cell>FPGA</cell><cell>CPU</cell></row><row><cell>1997</cell><cell>XC4085XLA-09</cell><cell>Pentium 266 MHz</cell></row><row><cell>1999</cell><cell>Virtex 1000-5</cell><cell></cell></row><row><cell>2000</cell><cell>Virtex-E 3200-7</cell><cell>Athlon 1.2 GHz</cell></row><row><cell>2001</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Stepping-1 is a silicon revision of the Virtex-II parts that provides a significant boost in the performance of the embedded multipliers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>These selections were made based on input from Chuck Cremer at Quatra Associates, Jason Moore at Xilinx, and personal memory.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The throughput of the SSE2 multiplier is one instruction per 2 cycles. Each instruction can do two multiplies.</p></note>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>* Sandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin Company, for the United States Department of Energy under contract DE-AC04-94AL85000.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">International Technology Roadmap for Semiconductors</title>
		<imprint>
			<date type="published" when="2003-12">December 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hitting the memory wall: Implications of the obvious</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Wulf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mckee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="20" to="24" />
			<date type="published" when="1995-03">March 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Quantitative analysis of floating point arithmetic on fpga based custom computing machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Athanas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on FPGAs for Custom Computing Machines</title>
		<meeting>the IEEE Symposium on FPGAs for Custom Computing Machines</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A library of parameterized floating-point modules and their use</title>
		<author>
			<persName><forename type="first">P</forename><surname>Belanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leeser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Field Programmable Logic and Applications</title>
		<meeting>the International Conference on Field Programmable Logic and Applications</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A flexible floating-point format for optimizing data-paths and operators in fpga based dsps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Geraudie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Loiseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Payeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Savaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poirier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Symposium on Field Programmable Gate Arrays</title>
		<meeting>the ACM International Symposium on Field Programmable Gate Arrays<address><addrLine>Monterrey, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-02">February 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automating customisation of floating-point designs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Gaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Field Programmable Logic and Applications</title>
		<meeting>the International Conference on Field Programmable Logic and Applications</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Floating point unit generation and evaluation for fpgas</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tessier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mencer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Field-Programmable Custom Computing Machines</title>
		<meeting>the IEEE Symposium on Field-Programmable Custom Computing Machines<address><addrLine>Napa Valley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-04">April 2003</date>
			<biblScope unit="page" from="185" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic floating to fixed point translation and its application to post-rendering 3d warping</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H W</forename><surname>Leong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Field-Programmable Custom Computing Machines</title>
		<meeting>the IEEE Symposium on Field-Programmable Custom Computing Machines<address><addrLine>Napa Valley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-04">April 1999</date>
			<biblScope unit="page" from="240" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Floating point bitwidth analysis via automatic differentiation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Gaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shirazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Field Programmable Technology</title>
		<meeting>the International Conference on Field Programmable Technology</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Hong Kong</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">IEEE standard for binary floating-point arithmetic</title>
		<author>
			<persName><forename type="first">Board</forename><surname>Standards</surname></persName>
		</author>
		<idno>ANSI/IEEE Std. 754-1985</idno>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>The Institute of Electrical and Electronics Engineers</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Field programmable gate arrays and floating point arithmetic</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Renard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on VLSI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="365" to="367" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Implementation of ieee single precision floating point addition and multiplication on fpgas</title>
		<author>
			<persName><forename type="first">L</forename><surname>Louca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on FPGAs for Custom Computing Machines</title>
		<meeting>the IEEE Symposium on FPGAs for Custom Computing Machines</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A re-evaluation of the praticality of floating-point on FPGAs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Ligon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schoonover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Underwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on FPGAs for Custom Computing Machines</title>
		<meeting>the IEEE Symposium on FPGAs for Custom Computing Machines<address><addrLine>Napa Valley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-04">April 1998</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accelerating pipelined integer and floating-point accumulations in configurable hardware with delayed addition techniques</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tradeoffs of designing floating-point division and square root on virtex fpgas</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Field-Programmable Custom Computing Machines</title>
		<meeting>the IEEE Symposium on Field-Programmable Custom Computing Machines<address><addrLine>Napa Valley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-04">April 2003</date>
			<biblScope unit="page" from="195" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards and RCC-based accelerator for computational fluid dynamics applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Schnore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="226" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Novel Optimizations for Hardware Floating-Point Units in a Modern FPGA Architecture</title>
		<author>
			<persName><forename type="first">E</forename><surname>Roesler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Workshop on Field Programmable Logic and Applications (FPL&apos;2002)</title>
		<meeting>the 12th International Workshop on Field Programmable Logic and Applications (FPL&apos;2002)</meeting>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
			<biblScope unit="page" from="637" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The linpack benchmark: An explanation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Dongarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st International Conference on Supercomputing</title>
		<imprint>
			<date type="published" when="1987-06">June 1987</date>
			<biblScope unit="page" from="456" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Top 500 web site</title>
		<ptr target="http://www.top500.org" />
		<imprint>
			<date type="published" when="2003-09">September 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An empirical performance evaluation of scalable scientific applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Supercomputing</title>
		<meeting>the 2002 Conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2002-11">Nov. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">IA-32 Intel Architecture Optimization: Reference Manual. USA: Intel Corporation</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="248966" to="248969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Characterizing a new class of threads in scientific applications for high end supercomputers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kogge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Underwood</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in in Preparation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
