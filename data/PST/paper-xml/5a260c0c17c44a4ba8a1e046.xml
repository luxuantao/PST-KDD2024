<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-11-02">2 Nov 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Luigi</forename><surname>Acerbi</surname></persName>
							<email>luigi.acerbi@nyu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><forename type="middle">Ji</forename><surname>Ma</surname></persName>
							<email>weijima@nyu.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Center for Neural Science &amp; Dept. of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Département des neurosciences fondamentales</orgName>
								<orgName type="institution">Université de Genève, CMU</orgName>
								<address>
									<addrLine>1 rue Michel-Servet</addrLine>
									<postCode>1206</postCode>
									<settlement>Genève</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-11-02">2 Nov 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">201FCE6CFBDB6421DF32AC49A20735FF</idno>
					<idno type="arXiv">arXiv:1705.04405v2[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T09:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computational models in fields such as computational neuroscience are often evaluated via stochastic simulation or numerical approximation. Fitting these models implies a difficult optimization problem over complex, possibly noisy parameter landscapes. Bayesian optimization (BO) has been successfully applied to solving expensive black-box problems in engineering and machine learning.</p><p>Here we explore whether BO can be applied as a general tool for model fitting. First, we present a novel hybrid BO algorithm, Bayesian adaptive direct search (BADS), that achieves competitive performance with an affordable computational overhead for the running time of typical models. We then perform an extensive benchmark of BADS vs. many common and state-of-the-art nonconvex, derivativefree optimizers, on a set of model-fitting problems with real data and models from six studies in behavioral, cognitive, and computational neuroscience. With default settings, BADS consistently finds comparable or better solutions than other methods, including 'vanilla' BO, showing great promise for advanced BO techniques, and BADS in particular, as a general model-fitting tool.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many complex, nonlinear computational models in fields such as behaviorial, cognitive, and computational neuroscience cannot be evaluated analytically, but require moderately expensive numerical approximations or simulations. In these cases, finding the maximum-likelihood (ML) solutionfor parameter estimation, or model selection -requires the costly exploration of a rough or noisy nonconvex landscape, in which gradients are often unavailable to guide the search.</p><p>Here we consider the problem of finding the (global) optimum x * = argmin x∈X E [f (x)] of a possibly noisy objective f over a (bounded) domain X ⊆ R D , where the function f can be intended as the (negative) log likelihood of a parameter vector x for a given dataset and model, but is generally a black box. With many derivative-free optimization algorithms available to the researcher <ref type="bibr" target="#b0">[1]</ref>, it is unclear which one should be chosen. Crucially, an inadequate optimizer can hinder progress, limit the complexity of the models that can be fit, and even cast doubt on the reliability of one's findings.</p><p>Bayesian optimization (BO) is a state-of-the-art machine learning framework for optimizing expensive and possibly noisy black-box functions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. This makes it an ideal candidate for solving difficult model-fitting problems. Yet there are several obstacles to a widespread usage of BO as a general tool for model fitting. First, traditional BO methods target very costly problems, such as hyperparameter tuning <ref type="bibr" target="#b4">[5]</ref>, whereas evaluating a typical behavioral model might only have a moderate computational cost (e.g., 0.1-10 s per evaluation). This implies major differences in what is considered an acceptable algorithmic overhead, and in the maximum number of allowed function evaluations (e.g., hundreds vs. thousands). Second, it is unclear how BO methods would fare in this regime against commonly used and state-of-the-art, non-Bayesian optimizers. Finally, BO might be perceived by non-practitioners as an advanced tool that requires specific technical knowledge to be implemented or tuned.</p><p>We address these issues by developing a novel hybrid BO algorithm, Bayesian Adaptive Direct Search (BADS), that achieves competitive performance at a small computational cost. We tested BADS, together with a wide array of commonly used optimizers, on a novel benchmark set of model-fitting problems with real data and models drawn from studies in cognitive, behaviorial and computational neuroscience. Finally, we make BADS available as a free MATLAB package with the same user interface as existing optimizers and that can be used out-of-the-box with no tuning. <ref type="foot" target="#foot_0">1</ref>BADS is a hybrid BO method in that it combines the mesh adaptive direct search (MADS) framework <ref type="bibr" target="#b5">[6]</ref> (Section 2.1) with a BO search performed via a local Gaussian process (GP) surrogate (Section 2.2), implemented via a number of heuristics for efficiency (Section 3). BADS proves to be highly competitive on both artificial functions and real-world model-fitting problems (Section 4), showing promise as a general tool for model fitting in computational neuroscience and related fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>There is a large literature about (Bayesian) optimization of expensive, possibly stochastic, computer simulations, mostly used in machine learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref> or engineering (known as kriging-based optimization) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Recent work has combined MADS with treed GP models for constrained optimization (TGP-MADS <ref type="bibr" target="#b8">[9]</ref>). Crucially, these methods have large overheads and may require problem-specific tuning, making them impractical as a generic tool for model fitting. Cheaper but less precise surrogate models than GPs have been proposed, such as random forests <ref type="bibr" target="#b9">[10]</ref>, Parzen estimators <ref type="bibr" target="#b10">[11]</ref>, and dynamic trees <ref type="bibr" target="#b11">[12]</ref>. In this paper, we focus on BO based on traditional GP surrogates, leaving the analysis of alternative models for future work (see Conclusions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Optimization frameworks 2.1 Mesh adaptive direct search (MADS)</head><p>The MADS algorithm is a directional direct search framework for nonlinear optimization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>. Briefly, MADS seeks to improve the current solution by testing points in the neighborhood of the current point (the incumbent), by moving one step in each direction on an iteration-dependent mesh. In addition, the MADS framework can incorporate in the optimization any arbitrary search strategy which proposes additional test points that lie on the mesh. MADS defines the current mesh at the k-th iteration as M k = x∈S k x + ∆ mesh k Dz : z ∈ N D , where S k ⊂ R n is the set of all points evaluated since the start of the iteration, ∆ mesh k ∈ R + is the mesh size, and D is a fixed matrix in R D×n D whose n D columns represent viable search directions. We choose D = [I D , -I D ], where I D is the identity matrix in dimension D.</p><p>Each iteration of MADS comprises of two stages, a SEARCH stage and an optional POLL stage. The SEARCH stage evaluates a finite number of points proposed by a provided search strategy, with the only restriction that the tested points lie on the current mesh. The search strategy is intended to inject problem-specific information in the optimization. In BADS, we exploit the freedom of SEARCH to perform Bayesian optimization in the neighborhood of the incumbent (see Section 2.2 and 3.3). The POLL stage is performed if the SEARCH fails in finding a point with an improved objective value. POLL constructs a poll set of candidate points, P k , defined as</p><formula xml:id="formula_0">P k = x k + ∆ mesh k v : v ∈ D k ,</formula><p>where x k is the incumbent and D k is the set of polling directions constructed by taking discrete linear combinations of the set of directions D. The poll size parameter</p><formula xml:id="formula_1">∆ poll k ≥ ∆ mesh k defines the maximum length of poll displacement vectors ∆ mesh k v, for v ∈ D k (typically, ∆ poll k ≈ ∆ mesh k ||v||).</formula><p>Points in the poll set can be evaluated in any order, and the POLL is opportunistic in that it can be stopped as soon as a better solution is found. The POLL stage ensures theoretical convergence to a local stationary point according to Clarke calculus for nonsmooth functions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>If either SEARCH or POLL are a success, finding a mesh point with an improved objective value, the incumbent is updated and the mesh size remains the same or is multiplied by a factor τ &gt; 1. If neither SEARCH or POLL are successful, the incumbent does not move and the mesh size is divided by τ . The algorithm proceeds until a stopping criterion is met (e.g., maximum budget of function evaluations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bayesian optimization</head><p>The typical form of Bayesian optimization (BO) <ref type="bibr" target="#b1">[2]</ref> builds a Gaussian process (GP) approximation of the objective f , which is used as a relatively inexpensive surrogate to guide the search towards regions that are promising (low GP mean) and/or unknown (high GP uncertainty), according to a rule, the acquisition function, that formalizes the exploitation-exploration trade-off.</p><p>Gaussian processes GPs are a flexible class of models for specifying prior distributions over unknown functions f : X ⊆ R D → R <ref type="bibr" target="#b14">[15]</ref>. GPs are specified by a mean function m : X → R and a positive definite covariance, or kernel function k : X ×X → R. Given any finite collection of n points X = x (i) ∈ X n i=1 , the value of f at these points is assumed to be jointly Gaussian with mean (m(x (1) ), . . . , m(x (n) )) and covariance matrix K, where K ij = k(x (i) , x (j) ) for 1 ≤ i, j ≤ n. We assume i.i.d. Gaussian observation noise such that f evaluated at x (i) returns y (i) ∼ N f (x (i) ), σ 2 , and y = (y (1) , . . . , y (n) ) is the vector of observed values. For a deterministic f , we still assume a small σ &gt; 0 to improve numerical stability of the GP <ref type="bibr" target="#b15">[16]</ref>. Conveniently, observation of such (noisy) function values will produce a GP posterior whose latent marginal conditional mean µ(x; {X, y} , θ) and variance s 2 (x; {X, y} , θ) at a given point are available in closed form (see Supplementary Material), where θ is a hyperparameter vector for the mean, covariance, and likelihood. In the following, we omit the dependency of µ and s 2 from the data and GP parameters to reduce clutter.</p><p>Covariance functions Our main choice of stationary (translationally-invariant) covariance function is the automatic relevance determination (ARD) rational quadratic (RQ) kernel,</p><formula xml:id="formula_2">k RQ (x, x ) = σ 2 f 1 + 1 2α r 2 (x, x ) -α , with r 2 (x, x ) = D d=1 1 2 d (x d -x d ) 2 ,<label>(1)</label></formula><p>where σ 2 f is the signal variance, 1 , . . . , D are the kernel length scales along each coordinate direction, and α &gt; 0 is the shape parameter. More common choices for Bayesian optimization include the squared exponential (SE) kernel <ref type="bibr" target="#b8">[9]</ref> or the twice-differentiable ARD Matérn 5/2 (M 5/2 ) kernel <ref type="bibr" target="#b4">[5]</ref>, but we found the RQ kernel to work best in combination with our method (see Section 4.2). We also consider composite periodic kernels for circular or periodic variables (see Supplementary Material).</p><p>Acquisition function For a given GP approximation of f , the acquisition function, a : X → R, determines which point in X should be evaluated next via a proxy optimization x next = argmin x a(x). We consider here the GP lower confidence bound (LCB) metric <ref type="bibr" target="#b16">[17]</ref>,</p><formula xml:id="formula_3">a LCB (x; {X, y} , θ) = µ (x) -νβ t s 2 (x), β t = 2 ln Dt 2 π 2 /(6δ)<label>(2)</label></formula><p>where ν &gt; 0 is a tunable parameter, t is the number of function evaluations so far, δ &gt; 0 is a probabilistic tolerance, and β t is a learning rate chosen to minimize cumulative regret under certain assumptions. For BADS we use the recommended values ν = 0.2 and δ = 0.1 <ref type="bibr" target="#b16">[17]</ref>. Another popular choice is the (negative) expected improvement (EI) over the current best function value <ref type="bibr" target="#b17">[18]</ref>, and an historical, less used metric is the (negative) probability of improvement (PI) <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bayesian adaptive direct search (BADS)</head><p>We describe here the main steps of BADS (Algorithm 1). Briefly, BADS alternates between a series of fast, local BO steps (the SEARCH stage of MADS) and a systematic, slower exploration of the mesh grid (POLL stage). The two stages complement each other, in that the SEARCH can explore the space very effectively, provided an adequate surrogate model. When the SEARCH repeatedly fails, meaning that the GP model is not helping the optimization (e.g., due to a misspecified model, or excess uncertainty), BADS switches to POLL. The POLL stage performs a fail-safe, model-free optimization, during which BADS gathers information about the local shape of the objective function, so as to build a better surrogate for the next SEARCH. This alternation makes BADS able to deal effectively and robustly with a variety of problems. See Supplementary Material for a full description. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Initial setup</head><formula xml:id="formula_4">∆ mesh k ← 1 2 ∆ mesh k , ∆ poll k ← 1 2 ∆ poll k 15:</formula><p>k ← k + 1 16: until fevals &gt; MaxFunEvals or ∆ poll k &lt; 10 -6 or stalling stopping criteria 17: return x end = arg min k f (x k ) (or x end = arg min k q β (x k ) for noisy objectives, Section 3.4) <ref type="foot" target="#foot_1">2</ref> Plausible bounds identify a region in parameter space where most solutions are expected to lie. Hard upper/lower bounds can be infinite, but plausible bounds need to be finite. Problem variables whose hard bounds are strictly positive and UB d ≥ 10 • LB d are automatically converted to log space. All variables are then linearly rescaled to the standardized box [-1, 1] D such that the box bounds correspond to [PLB, PUB] in the original space. BADS supports bound or no constraints, and optionally other constraints via a provided barrier function c (see Supplementary Material). The user can also specify circular or periodic dimensions (such as angles); and whether the objective f is deterministic or noisy (stochastic), and in the latter case provide a coarse estimate of the noise (see Section 3.4).</p><formula xml:id="formula_5">requirement that for each dimension 1 ≤ d ≤ D, LB d ≤ PLB d &lt; PUB d ≤ UB d .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial design</head><p>The initial design consists of the provided starting point x 0 and n init = D additional points chosen via a space-filling quasi-random Sobol sequence <ref type="bibr" target="#b19">[20]</ref> in the standardized box, and forced to lie on the mesh grid. If the user does not specify whether f is deterministic or stochastic, the algorithm assesses it by performing two consecutive evaluations at x 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GP model in BADS</head><p>The default GP model is specified by a constant mean function m ∈ R, a smooth ARD RQ kernel (Eq. 1), and we use a LCB (Eq. 2) as a default acquisition function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters</head><p>The default GP has hyperparameters θ = ( 1 , . . . , D , σ 2 f , α, σ 2 , m). We impose an empirical Bayes prior on the GP hyperparameters based on the current training set (see Supplementary Material), and select θ via maximum a posteriori (MAP) estimation. We fit θ via a gradient-based nonlinear optimizer, starting from either the previous value of θ or a weighted draw from the prior, as a means to escape local optima. We refit the hyperparameters every 2D to 5D function evaluations; more often earlier in the optimization, and whenever the current GP is particularly inaccurate at predicting new points, according to a normality test on the residuals,</p><formula xml:id="formula_6">z (i) = y (i) -µ(x (i) ) / s 2 (x (i) ) + σ 2 (assumed independent, in first approximation).</formula><p>Training set The GP training set X consists of a subset of the points evaluated so far (the cache), selected to build a local approximation of the objective in the neighborhood of the incumbent x k , constructed as follows. Each time X is rebuilt, points in the cache are sorted by their -scaled distance r 2 (Eq. 1) from x k . First, the closest n min = 50 points are automatically added to X. Second, up to 10D additional points with r ≤ 3ρ(α) are included in the set, where ρ(α)</p><p>1 is a radius function that depends on the decay of the kernel. For the RQ kernel, ρ RQ (α) = √ α √ e 1/α -1 (see Supplementary Material). Newly evaluated points are added incrementally to the set, using fast rank-one updates of the GP posterior. The training set is rebuilt any time the incumbent is moved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation of the MADS framework</head><p>We initialize ∆ poll 0 = 1 and ∆ mesh 0 = 2 -10 (in standardized space), such that the initial poll steps can span the plausible region, whereas the mesh grid is relatively fine. We use τ = 2, and increase the mesh size only after a successful POLL. We skip the POLL after a successful SEARCH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search stage</head><p>We apply an aggressive, repeated SEARCH strategy that consists of up to n search = max{D, 3 + D/2 } unsuccessful SEARCH steps. In each step, we use a search oracle, based on a local BO with the current GP, to produce a search point x search (see below). We evaluate f (x search ) and add it to the training set. If the improvement in objective value is none or insufficient, that is less than (∆ poll k ) 3/2 , we continue searching, or switch to POLL after n search steps. Otherwise, we call it a success and start a new SEARCH from scratch, centered on the updated incumbent.</p><p>Search oracle We choose x search via a fast, approximate optimization inspired by CMA-ES <ref type="bibr" target="#b20">[21]</ref>. We sample batches of points in the neighborhood of the incumbent x k , drawn ∼ N (x s , λ 2 (∆ poll k ) 2 Σ), where x s is the current search focus, Σ a search covariance matrix, and λ &gt; 0 a scaling factor, and we pick the point that optimizes the acquisition function (see Supplementary Material). We remove from the SEARCH set candidate points that violate non-bound constraints (c(x) &gt; 0), and we project candidate points that fall outside hard bounds to the closest mesh point inside the bounds. Across SEARCH steps, we use both a diagonal matrix</p><formula xml:id="formula_7">Σ with diagonal 2 1 /| | 2 , . . . , 2 D /| | 2</formula><p>, and a matrix Σ WCM proportional to the weighted covariance matrix of points in X (each point weighted according to a function of its ranking in terms of objective values y i ). We choose between Σ and Σ WCM probabilistically via a hedge strategy, based on their track record of cumulative improvement <ref type="bibr" target="#b21">[22]</ref>.</p><p>Poll stage We incorporate the GP approximation in the POLL in two ways: when constructing the set of polling directions D k , and when choosing the polling order. We generate D k according to the random LTMADS algorithm <ref type="bibr" target="#b5">[6]</ref>, but then rescale each vector coordinate 1 ≤ d ≤ D proportionally to the GP length scale d (see Supplementary Material). We discard poll vectors that do not satisfy the given bound or nonbound constraints. Second, since the POLL is opportunistic, we evaluate points in the poll set according to the ranking given by the acquisition function <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stopping criteria</head><p>We stop the optimization when the poll size ∆ poll k goes below a threshold (default 10 -6 ); when reaching a maximum number of objective evaluations (default 500D); or if there is no significant improvement of the objective for more than 4 + D/2 iterations. The algorithm returns the optimum x end (transformed back to original coordinates) with the lowest objective value y end .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Noisy objective</head><p>In case of a noisy objective, we assume for the noise a hyperprior ln σ ∼ N (ln σ est , 1), with σ est a base noise magnitude (default σ est = 1, but the user can provide an estimate). To account for additional uncertainty, we also make the following changes: double the minimum number of points added to the training set, n min = 100, and increase the maximum number to 200; increase the initial design to n init = 20; and double the number of allowed stalled iterations before stopping.</p><p>Uncertainty handling Due to noise, we cannot simply use the output values y i as ground truth in the SEARCH and POLL stages. Instead, we replace y i with the GP latent quantile function <ref type="bibr" target="#b22">[23]</ref> </p><formula xml:id="formula_8">q β (x; {X, y} , θ) ≡ q β (x) = µ (x) + Φ -1 (β)s (x) , β ∈ [0.5, 1),<label>(3)</label></formula><p>where Φ -1 (•) is the quantile function of the standard normal (plugin approach <ref type="bibr" target="#b23">[24]</ref>). Moreover, we modify the MADS procedure by keeping an incumbent set {x i } k i=1 , where x i is the incumbent at the end of the i-th iteration. At the end of each POLL we re-evaluate q β for all elements of the incumbent set, in light of the new points added to the cache. We select as current (active) incumbent the point with lowest q β (x i ). During optimization we set β = 0.5 (mean prediction only), which promotes exploration. We use a conservative β end = 0.999 for the last iteration, to select the optimum x end returned by the algorithm in a robust manner. Instead of y end , we return either µ(x end ) or an unbiased estimate of E[f (x end )] obtained by averaging multiple evaluations (see Supplementary Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We tested BADS and many optimizers with implementation available in MATLAB (R2015b, R2017a) on a large set of artificial and real optimization problems (see Supplementary Material for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design of the benchmark</head><p>Algorithms Besides BADS, we tested 16 optimization algorithms, including popular choices such as Nelder-Mead (fminsearch <ref type="bibr" target="#b24">[25]</ref>), several constrained nonlinear optimizers in the fmincon function (default interior-point <ref type="bibr" target="#b25">[26]</ref>, sequential quadratic programming sqp <ref type="bibr" target="#b26">[27]</ref>, and active-set actset <ref type="bibr" target="#b27">[28]</ref>), genetic algorithms (ga <ref type="bibr" target="#b28">[29]</ref>), random search (randsearch) as a baseline <ref type="bibr" target="#b29">[30]</ref>; and also less-known state-of-the-art methods for nonconvex derivative-free optimization <ref type="bibr" target="#b0">[1]</ref>, such as Multilevel Coordinate Search (MCS <ref type="bibr" target="#b30">[31]</ref>) and CMA-ES <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b31">32]</ref> (cmaes, in different flavors). For noisy objectives, we included algorithms that explicitly handle uncertainty, such as snobfit <ref type="bibr" target="#b32">[33]</ref> and noisy CMA-ES <ref type="bibr" target="#b33">[34]</ref>. Finally, to verify the advantage of BADS' hybrid approach to BO, we also tested a standard, 'vanilla' version of BO <ref type="bibr" target="#b4">[5]</ref> (bayesopt, R2017a) on the set of real model-fitting problems (see below). For all algorithms, including BADS, we used default settings (no fine-tuning).</p><p>Problem sets First, we considered a standard benchmark set of artificial, noiseless functions (BBOB09 <ref type="bibr" target="#b34">[35]</ref>, 24 functions) in dimensions D ∈ {3, 6, 10, 15}, for a total of 96 test functions. We also created 'noisy' versions of the same set. Second, we collected model-fitting problems from six published or ongoing studies in cognitive and computational neuroscience (CCN17). The objectives of the CCN17 set are negative log likelihood functions of an input parameter vector, for specified datasets and models, and can be deterministic or stochastic. For each study in the CCN17 set we asked its authors for six different real datasets (i.e., subjects or neurons), divided between one or two main models of interest; collecting a total of 36 test functions with D ∈ {6, 9, 10, 12, 13}.</p><p>Procedure We ran 50 independent runs of each algorithm on each test function, with randomized starting points and a budget of 500 × D function evaluations (200 × D for noisy problems). If an algorithm terminated before depleting the budget, it was restarted from a new random point. We consider a run successful if the current best (or returned, for noisy problems) function value is within a given error tolerance ε &gt; 0 from the true optimum f min (or our best estimate thereof). <ref type="foot" target="#foot_2">3</ref> For noiseless problems, we compute the fraction of successful runs as a function of number of objective evaluations, averaged over datasets/functions and over ε ∈ [0.01, 10] (log spaced). This is a realistic range for ε, as differences in log likelihood below 0.01 are irrelevant for model selection; an acceptable tolerance is ε ∼ 0.5 (a difference in deviance, the metric used for AIC or BIC, less than 1); larger ε associate with coarse solutions, but errors larger than 10 would induce excessive biases in model selection. For noisy problems, what matters most is the solution x end that the algorithm actually returns, which, depending on the algorithm, may not necessarily be the point with the lowest observed function value. Since, unlike the noiseless case, we generally do not know the solutions that would be returned by any algorithm at every time step, but only at the last step, we plot instead the fraction of successful runs at 200 × D function evaluations as a function of ε, for ε ∈ [0.1, 10] (noise makes higher precisions moot), and averaged over datasets/functions. In all plots we omit error bars for clarity (standard errors would be about the size of the line markers or less).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results on artificial functions (BBOB09)</head><p>The BBOB09 noiseless set <ref type="bibr" target="#b34">[35]</ref> comprises of 24 functions divided in 5 groups with different properties: separable; low or moderate conditioning; unimodal with high conditioning; multi-modal with adequate / with weak global structure. First, we use this benchmark to show the performance of different configurations for BADS. Note that we selected the default configuration (RQ kernel, a LCB ) and other algorithmic details by testing on a different benchmark set (see Supplementary Material).  </p><formula xml:id="formula_9">(i) = f (x (i) ) + σ(x (i) )η (i)</formula><p>, with η (i) ∼ N (0, 1). We consider a variant with moderate homoskedastic (constant) noise (σ = 1), and a variant with heteroskedastic noise with σ(x) = 1+0.1×(f (x)-f min ), which follows the observation that variability generally increases for solutions away from the optimum. For many functions in the BBOB09 set, this heteroskedastic noise can become substantial (σ 10) away from the optimum. Notably, BADS performs well even on problems with non-stationary (location-dependent) features, such as heteroskedastic noise, thanks to its local GP approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results on real model-fitting problems (CCN17)</head><p>The objectives of the CCN17 set are deterministic (e.g., computed via numerical approximation) for three studies (Fig 2 ), and noisy (e.g., evaluated via simulation) for the other three (Fig <ref type="figure" target="#fig_3">3</ref>).</p><p>The algorithmic cost of BADS is ∼ 0.03 s to 0.15 s per function evaluation, depending on D, mostly due to the refitting of the GP hyperparameters. This produces a non-negligible overhead, defined as 100% × (total optimization time / total function time -1). For a fair comparison with other methods with little or no overhead, for deterministic problems we also plot the effective performance of BADS by accounting for the extra cost per function evaluation. In practice, this correction shifts rightward the performance curve of BADS in log-iteration space, since each function evaluation with BADS has an increased fractional time cost. For stochastic problems, we cannot compute effective performance as easily, but there we found small overheads (&lt; 5%), due to more costly evaluations (more than 1 s).</p><p>For a direct comparison with standard BO, we also tested on the CCN17 set a 'vanilla' BO algorithm, as implemented in MATLAB R2017a (bayesopt). This implementation closely follows <ref type="bibr" target="#b4">[5]</ref>, with optimization instead of marginalization over GP hyperparameters. Due to the fast-growing cost of BO as a function of training set size, we allowed up to 300 training points for the GP, restarting the BO algorithm from scratch with a different initial design every 300 BO iterations (until the total budget of function evaluations was exhausted). The choice of 300 iterations already produced a large average algorithmic overhead of ∼ 8 s per function evaluation. In showing the results of bayesopt, we display raw performance without penalizing for the overhead.</p><p>Causal inference in visuo-vestibular perception Causal inference (CI) in perception is the process whereby the brain decides whether to integrate or segregate multisensory cues that could arise from the same or from different sources <ref type="bibr" target="#b38">[39]</ref>. This study investigates CI in visuo-vestibular heading  perception across tasks and under different levels of visual reliability, via a factorial model comparison <ref type="bibr" target="#b35">[36]</ref>. For our benchmark we fit three subjects with a Bayesian CI model (D = 10), and another three with a fixed-criterion CI model (D = 10) that disregards visual reliability. Both models include heading-dependent likelihoods and marginalization of the decision variable over the latent space of noisy sensory measurements (x vis , x vest ), solved via nested numerical integration in 1-D and 2-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian confidence in perceptual categorization</head><p>This study investigates the Bayesian confidence hypothesis that subjective judgments of confidence are directly related to the posterior probability the observer assigns to a learnt perceptual category <ref type="bibr" target="#b36">[37]</ref> (e.g., whether the orientation of a drifting Gabor patch belongs to a 'narrow' or to a 'wide' category). For our benchmark we fit six subjects to the 'Ultrastrong' Bayesian confidence model (D = 13), which uses the same mapping between posterior probability and confidence across two tasks with different distributions of stimuli. This model includes a latent noisy decision variable, marginalized over via 1-D numerical integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural model of orientation selectivity</head><p>The authors of this study explore the origins of diversity of neuronal orientation selectivity in visual cortex via novel stimuli (orientation mixtures) and modeling <ref type="bibr" target="#b37">[38]</ref>. We fit the responses of five V1 and one V2 cells with the authors' neuronal model (D = 12) that combines effects of filtering, suppression, and response nonlinearity <ref type="bibr" target="#b37">[38]</ref>. The model has one circular parameter, the preferred direction of motion of the neuron. The model is analytical but still computationally expensive due to large datasets and a cascade of several nonlinear operations.</p><p>Word recognition memory This study models a word recognition task in which subjects rated their confidence that a presented word was in a previously studied list <ref type="bibr" target="#b39">[40]</ref> (data from <ref type="bibr" target="#b40">[41]</ref>). We consider six subjects divided between two normative models, the 'Retrieving Effectively from Memory' model <ref type="bibr" target="#b41">[42]</ref> (D = 9) and a similar, novel model<ref type="foot" target="#foot_3">4</ref> (D = 6). Both models use Monte Carlo methods to draw random samples from a large space of latent noisy memories, yielding a stochastic log likelihood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target detection and localization</head><p>This study looks at differences in observers' decision making strategies in target detection ('was the target present?') and localization ('which one was the target?') with displays of 2, 3, 4, or 6 oriented Gabor patches. <ref type="foot" target="#foot_4">5</ref> Here we fit six subjects with a previously derived ideal observer model <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref> (D = 6) with variable-precision noise <ref type="bibr" target="#b44">[45]</ref>, assuming shared parameters between detection and localization. The log likelihood is evaluated via simulation due to marginalization over latent noisy measurements of stimuli orientations with variable precision.</p><p>Combinatorial board game playing This study analyzes people's strategies in a four-in-a-row game played on a 4-by-9 board against human opponents ([46], Experiment 1). We fit the data of six players with the main model (D = 10), which is based on a Best-First exploration of a decision tree guided by a feature-based value heuristic. The model also includes feature dropping, value noise, and lapses, to better capture human variability. Model evaluation is computationally expensive due to the construction and evaluation of trees of future board states, and achieved via inverse binomial sampling, an unbiased stochastic estimator of the log likelihood <ref type="bibr" target="#b45">[46]</ref>. Due to prohibitive computational costs, here we only test major algorithms (MCS is the method used in the paper <ref type="bibr" target="#b45">[46]</ref>); see Fig <ref type="figure" target="#fig_3">3 right</ref>.</p><p>In all problems, BADS consistently performs on par with or outperforms all other tested optimizers, even when accounting for its extra algorithmic cost. The second best algorithm is either some flavor of CMA-ES or, for some deterministic problems, a member of the fmincon family. Crucially, their ranking across problems is inconsistent, with both CMA-ES and fmincon performing occasionally quite poorly (e.g., fmincon does poorly in the causal inference set because of small fluctuations in the log likelihood landscape caused by coarse numerical integration). Interestingly, vanilla BO (bayesopt) performs poorly on all problems, often at the level of random search, and always substantially worse than BADS, even without accounting for the much larger overhead of bayesopt. The solutions found by bayesopt are often hundreds (even thousands) points of log likelihood from the optimum. This failure is possibly due to the difficulty of building a global GP surrogate for BO, coupled with strong non-stationarity of the log likelihood functions; and might be ameliorated by more complex forms of BO (e.g., input warping to produce nonstationary kernels <ref type="bibr" target="#b46">[47]</ref>, hyperparameter marginalization <ref type="bibr" target="#b4">[5]</ref>). However, these advanced approaches would substantially increase the already large overhead. Importantly, we expect this poor perfomance to extend to any package which implements vanilla BO (such as BayesOpt <ref type="bibr" target="#b47">[48]</ref>), regardless of the efficiency of implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have developed a novel BO method and an associated toolbox, BADS, with the goal of fitting moderately expensive computational models out-of-the-box. We have shown on real model-fitting problems that BADS outperforms widely used and state-of-the-art methods for nonconvex, derivativefree optimization, including 'vanilla' BO. We attribute the robust performance of BADS to the alternation between the aggressive SEARCH strategy, based on local BO, and the failsafe POLL stage, which protects against failures of the GP surrogate -whereas vanilla BO does not have such failsafe mechanisms, and can be strongly affected by model misspecification. Our results demonstrate that a hybrid Bayesian approach to optimization can be beneficial beyond the domain of very costly black-box functions, in line with recent advancements in probabilistic numerics <ref type="bibr" target="#b48">[49]</ref>.</p><p>Like other surrogate-based methods, the performance of BADS is linked to its ability to obtain a fast approximation of the objective, which generally deteriorates in high dimensions, or for functions with pathological structure (often improvable via reparameterization). From our tests, we recommend BADS, paired with some multi-start optimization strategy, for models with up to ∼ 15 variables, a noisy or jagged log likelihood landscape, and when algorithmic overhead is 75% (e.g., model evaluation 0.1 s). Future work with BADS will focus on testing alternative statistical surrogates instead of GPs <ref type="bibr" target="#b11">[12]</ref>; combining it with a smart multi-start method for global optimization; providing support for tunable precision of noisy observations <ref type="bibr" target="#b22">[23]</ref>; improving the numerical implementation; and recasting some of its heuristics in terms of approximate inference. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Construction of the training set</head><p>We construct the training set X according to a simple subset-of-data <ref type="bibr" target="#b49">[50]</ref> local GP approximation. Points are added to the training set sorted by their -scaled distance r 2 from the incumbent x k . The training set contains a minimum of n min = 50 points (if available in the cache of all points evaluated so far), and then up to 10 × D additional points with r ≤ 3ρ(α), where ρ(α) is a radius function that depends on the decay of the kernel. For a given stationary kernel of the form k(x, x ) = k(r 2 (x, x )), we define ρ as the distance such that k(2ρ 2 ) ≡ 1/(σ 2 f e). We have then</p><formula xml:id="formula_10">ρ SE = 1, ρ M 52 ≈ 0.92, and ρ RQ (α) = α(e 1/α -1), (<label>S5</label></formula><formula xml:id="formula_11">)</formula><p>where for example ρ RQ (1) ≈ 1.31, and lim α→∞ ρ RQ (α) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Treatment of hyperparameters</head><p>We fit the GP hyperparameters by maximizing their posterior probability (MAP), p(θ|X, y) ∝ p(θ, X, y), which, thanks to the Gaussian likelihood, is available in closed form as <ref type="bibr" target="#b14">[15]</ref> ln p(y, X, θ) = -</p><formula xml:id="formula_12">1 2 ln |K + σ 2 I n | - 1 2 y K + σ 2 I n -1 y + ln p hyp (θ) + const, (<label>S6</label></formula><formula xml:id="formula_13">)</formula><p>where I n is the identity matrix in dimension n (the number of points in the training set), and p hyp (θ) is the prior over hyperparameters, described in the following.</p><p>Hyperparameter prior We adopt an approximate empirical Bayes approach by defining the prior based on the data in the training set, that is p hyp = p hyp (θ; X, y). Empirical Bayes can be intended as a quick, heuristic approximation to a proper but more expensive hierarchical Bayesian approach. We assume independent priors for each hyperparameter, with bounded (truncated) distributions.</p><p>Hyperparameter priors and hard bounds are reported in Table <ref type="table">S1</ref>. In BADS, we include an observation noise parameter σ &gt; 0 also for deterministic objectives f , merely for the purpose of fitting the GP, since it has been shown to yield several advantages <ref type="bibr" target="#b15">[16]</ref>. In particular, we assume a prior such that σ decreases as a function of the poll size ∆ poll k , as the optimization 'zooms in' to smaller scales. Another distinctive choice for BADS is that we set the mean for the GP mean equal to the 90-th percentile of the observed values in the current training set y, which encourages the exploration to remain local.</p><p>Hyperparameter optimization We optimize Eq. S6 with a gradient-based optimizer (see Section D), providing the analytical gradient to the algorithm. We start the optimization from the previous hyparameter values θ prev . If the optimization seems to be stuck in a high-noise mode, or we find an unusually low value for the GP mean m, we attempt a second fit starting from a draw from the prior averaged with θ prev . If the optimization fails due to numerical issues, we keep the previous value of the hyperparameters. We refit the hyperparameters every 2D to 5D function evaluations; more often earlier in the optimization, and whenever the current GP is particularly inaccurate at predicting new points. We test accuracy on newly evaluated points via a Shapiro-Wilk normality test on the residuals <ref type="bibr" target="#b50">[51]</ref>, z (i) = y (i) -µ(x (i) ) / s 2 (x (i) ) + σ 2 (assumed independent, in first approximation), and flag the approximation as inaccurate if p &lt; 10 -6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Acquisition functions</head><p>Besides the GP lower confidence bound (LCB) metric <ref type="bibr" target="#b16">[17]</ref> described in the main text (and default in BADS), we consider two other choices that are available in closed form using Eq. S1 for the GP predictive mean and variance. GP mean m m ∼ N Q 0.9 (y), 1 5 2 (Q 0.9 (y)</p><formula xml:id="formula_14">-Q 0.5 (y)) 2 (-∞, ∞)</formula><p>Table <ref type="table">S1</ref>: GP hyperparameter priors. Empirical Bayes priors and bounds for GP hyperparameters. N µ, σ 2 denotes the normal pdf with mean µ and variance σ 2 , and N T (•, •) the truncated normal, defined within the bounds specified in the last column. r max and r min are the maximum (resp., minimum) distance between any two points in the training set; ∆ poll min is the minimum poll size (default 10 -6 ); L d is the parameter range (UB d -LB d ), for 1 ≤ d ≤ D; SD(•) denotes the standard deviation of a set of elements; ∆ poll k is the poll size parameter at the current iteration k; Q q (•) denotes the q-th quantile of a set of elements (Q 0.5 is the median).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probability of improvement (PI)</head><p>This strategy maximizes the probability of improving over the current best minimum y best <ref type="bibr" target="#b18">[19]</ref>. For consistency with the main text, we define here the negative PI,</p><formula xml:id="formula_15">a PI (x; {X n , y n } , θ) = -Φ (γ(x)) , γ(x) = y best -ξ -µ (x) s (x)<label>(S7)</label></formula><p>where ξ ≥ 0 is an optional trade-off parameter to promote exploration, and Φ (•) is the cumulative distribution function of the standard normal. a PI is known to excessively favor exploitation over exploration, and it is difficult to find a correct setting for ξ to offset this tendency <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expected improvement (EI)</head><p>We then consider the popular predicted improvement criterion <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b1">2]</ref>. The expected improvement over the current best minimum y best (with an offset ξ ≥ 0) is defined as E [max {y best -y, 0}]. For consistency with the main text we consider the negative EI, which can be computed in closed form as</p><formula xml:id="formula_16">a EI (x; {X, y} , θ) = -s (x) [γ(x)Φ (γ(x)) + N (γ(x))]<label>(S8)</label></formula><p>where N (•) is the standard normal pdf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B The BADS algorithm</head><p>We report here extended details of the BADS algorithm, and how the various steps of the MADS framework are implemented (expanding on Sections 3.1 and 3.3 of the main text). Main features of the algorithm are summarized in Table <ref type="table">S2</ref>. Refer also to Algorithm 1 in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Problem definition and initialization</head><p>BADS solves the optimization problem</p><formula xml:id="formula_17">f min = min x∈X f (x) with X ⊆ R D (optional) c(x) ≤ 0 (S9)</formula><p>where X is defined by pairs of hard bound constraints for each coordinate, Algorithm input The algorithm takes as input a starting point x 0 ∈ X ; vectors of hard lower/upper bounds LB, UB; optional vectors of plausible lower/upper bounds PLB, PUB; and an optional barrier function c. We require that, if specified, c(x 0 ) ≤ 0; and for each dimension</p><formula xml:id="formula_18">LB d ≤ x d ≤ UB d for 1 ≤ d ≤ D,</formula><formula xml:id="formula_19">1 ≤ d ≤ D, LB d ≤ (x 0 ) d ≤ UB d and LB d ≤ PLB d &lt; PUB d ≤ UB d .</formula><p>Plausible bounds identify a region in parameter space where most solutions are expected to lie, which in practice we usually think of as the region where starting points for the algorithm would be drawn from. Hard upper/lower bounds can be infinite, but plausible bounds need to be finite. As an exception to the above bound ordering, the user can specify that a variable is fixed by setting</p><formula xml:id="formula_20">(x 0 ) d = LB d = UB d = PLB d = PUB d .</formula><p>Fixed variables become constants, and BADS runs on an optimization problem with reduced dimensionality. The user can also specify circular or periodic dimensions (such as angles), which change the definition of the GP kernel as per Section A.1. The user can specify whether the objective f is deterministic or noisy (stochastic), and in the latter case provide a coarse estimate of the noise (see Section B.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformation of variables and constraints</head><p>Problem variables whose hard bounds are strictly positive and UB d ≥ 10 • LB d are automatically converted to log space for all internal calculations of the algorithm. All variables are also linearly rescaled to the standardized box [-1, 1] D such that the box bounds correspond to [PLB, PUB] in the original space. BADS converts points back to the original coordinate space when calling the target function f or the barrier function c, and at the end of the optimization. BADS never violates constraints, by removing from the POLL and SEARCH sets points that violate either bound or non-bound constraints (c(x) &gt; 0). During the SEARCH stage, we project candidate points that violate a bound constraint to the closest mesh point within the bounds. We assume that c(•), if provided, is known and inexpensive to evaluate.</p><p>Objective scaling We assume that the scale of interest for differences in the objective (and the scale of other features, such as noise in the proximity of the solution) is of order ∼ 1, and that differences in the objective less than 10 -3 are negligible. For this reason, BADS is not invariant to arbitrary rescalings of the objective f . This assumption does not limit the actual values taken by the objective across the optimization. If the objective f is the log likelihood of a dataset and model (e.g., summed over trials), these assumptions are generally satisfied. They would not be if, for example, one were to feed to BADS the average log likelihood per trial, instead of the total (summed) log likelihood. In cases in which f has an unusual scale, we recommend to rescale the objective such that the magnitude of differences of interest becomes of order ∼ 1.</p><p>Initialization We initialize ∆ poll 0 = 1 and ∆ mesh 0 = 2 -10 (in standardized space). The initial design comprises of the provided starting point x 0 and n init = D additional points chosen via a low-discrepancy Sobol quasirandom sequence <ref type="bibr" target="#b19">[20]</ref> in the standardized box, and forced to be on the mesh grid. If the user does not specify whether f is deterministic or stochastic, the algorithm assesses it by performing two consecutive evaluations at x 0 . For all practical purposes, a function is deemed noisy if the two evaluations at x 0 differ more than 1.5 • 10 -11 .<ref type="foot" target="#foot_5">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 SEARCH stage</head><p>In BADS we perform an aggressive SEARCH stage in which, in practice, we keep evaluating candidate points until we fail for n search consecutive steps to find a sufficient improvement in function value, with n search = max{D, 3 + D/2 }; and only then we switch to the POLL stage. At any iteration k, we define an improvement sufficient if f prev -f new ≥ (∆ poll k ) 3/<ref type="foot" target="#foot_6">2</ref> , where ∆ poll k is the poll size. In each SEARCH step we choose the final candidate point to evaluate, x search , by performing a fast, approximate optimization of the chosen acquisition function in the neighborhood of the incumbent x k , using a two-step evolutionary heuristic inspired by CMA-ES <ref type="bibr" target="#b20">[21]</ref>. This local search is governed by a search covariance matrix Σ, and works as follows.</p><p>Local search via two-step evolutionary strategy We draw a first generation of candidates s (i)</p><formula xml:id="formula_21">I ∼ N (x k , (∆ poll k ) 2 Σ) for 1 ≤ i ≤ n search ,</formula><p>where we project each point onto the closest mesh point (see Section 2.1 in the main text); Σ is a search covariance matrix with unit trace, 2 and n search = 2 11 by default. For each candidate point, we assign a number of offsprings inversely proportionally to the square root of its ranking according to a(s (i) I ), for a total of n search offsprings <ref type="bibr" target="#b20">[21]</ref>. We then draw a second generation s</p><formula xml:id="formula_22">(i) II ∼ N (s (πi) I , λ 2 (∆ poll k ) 2 Σ</formula><p>) and project it onto the mesh grid, where π i is the index of the parent of the i-th candidate in the 2nd generation, and 0 &lt; λ ≤ 1 is a zooming factor (we choose λ = 1/4). Finally, we pick x search = arg min i a(s (i) II ). At each step, we remove candidate points that violate non-bound constraints (c(x) &gt; 0), and we project candidate points that fall outside hard bounds to the closest mesh point inside the bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hedge search</head><p>The search covariance matrix can be constructed in several ways. Across SEARCH steps we use both a diagonal matrix Σ with diagonal 2 1 /| | 2 , . . . , 2 D /| | 2 , and a matrix Σ WCM proportional to the weighted covariance matrix of points in X (each point weighted according to a function of its ranking in terms of objective values y i , see <ref type="bibr" target="#b20">[21]</ref>). At each step, we compute the probability of choosing Σ s , with s ∈ { , WCM}, according to a hedging strategy taken from the Exp3 HEDGE algorithm <ref type="bibr" target="#b21">[22]</ref>,</p><formula xml:id="formula_23">p s = e βHgs s e βHg s (1 -γ H n Σ ) + γ H (S10)</formula><p>where β H = 1, γ H = 0.125, n Σ = 2 is the number of considered search matrices, and g s is a running estimate of the reward for option s. The running estimate is updated each SEARCH step as</p><formula xml:id="formula_24">g new s = α H g old s + ∆f s p s ∆ poll k (S11)</formula><p>where α H = 0.1 1/(2D) is a decay factor, and ∆f s is the improvement in objective of the s-th strategy (0 if s was not chosen in the current SEARCH step). This method allows us to switch between searching along coordinate axes (Σ ), and following an approximation of the local curvature around the incumbent (Σ WCM ), according to their track record of cumulative improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 POLL stage</head><p>We perform the POLL stage only after a SEARCH stage that did not produce a sufficient improvement after n search steps. We incorporate the GP approximation in the POLL in two ways: when constructing the set of polling directions D k , and when choosing the polling order.</p><p>Set of polling directions At the beginning of the POLL stage, we generate a preliminary set of directions D k according to the random LTMADS algorithm <ref type="bibr" target="#b5">[6]</ref>. We then transform it to a rescaled set D k based on the current GP kernel length scales: for v ∈ D k , we define a rescaled vector v</p><formula xml:id="formula_25">with v d ≡ v d • ω d , for 1 ≤ d ≤ D, and ω d ≡ min{max{10 -6 , ∆ mesh k , d /GM( )}, UB d -LB d },</formula><p>where GM(•) denotes the geometric mean, and we use PLB d (resp. PUB d ) whenever UB d (resp. LB d ) is unbounded. This construction of D k deviates from the standard MADS framework. However, since the applied rescaling is bounded, we could redefine the mesh parameters and the set of polling directions to accomodate our procedure (as long as we appropriately discretize D k ). We remove from the poll set points that violate constraints, if present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Benchmark</head><p>We tested the performance of BADS on a large set of artificial and real problems and compared it with that of many optimization methods with implementation available in MATLAB (R2015b, R2017a). 3  We include here details that expand on Section 4.1 of the main text.  The list of tested algorithms is reported in Table <ref type="table" target="#tab_4">S3</ref>. For all methods, we used their default options unless stated otherwise. For BADS, CMA-ES, and bayesopt, we activated their uncertainty handling option when dealing with noisy problems (for CMA-ES, see <ref type="bibr" target="#b33">[34]</ref>). For noisy problems of the CCN17 set, within the fmincon family, we only tested the best representative method (active-set), since we found that these methods perform comparably to random search on noisy problems (see For the combinatorial game-playing problem subset in the CCN17 test set, we used the settings of MCS provided by the authors as per the original study <ref type="bibr" target="#b45">[46]</ref>. We note that we developed algorithmic details and internal settings of BADS by testing it on the CEC14 test set for expensive optimization <ref type="bibr" target="#b56">[57]</ref> and on other model-fitting problems which differ from the test problems presented in this benchmark. For bayesopt, we allowed up to 300 training points for the GP, restarting the BO algorithm from scratch with a different initial design every 300 BO iterations (until the total budget of function evaluations was exhausted). The choice of 300 iterations already produced a large average algorithmic overhead of ∼ 8 s per function evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Algorithms</head><p>As acquisition function, we used the default EI-per-second <ref type="bibr" target="#b4">[5]</ref>, except for problems for which the computational cost is constant across all parameter space, for which we used the simple EI. All algorithms in Table <ref type="table" target="#tab_4">S3</ref> accept hard bound constraints lb, ub, which were provided with the BBOB09 set and with the original studies in the CCN17 set. For all studies in the CCN17 set we also asked the original authors to provide plausible lower/upper bounds plb, pub for each parameter, which we would use for all problems in the set (if not available, we used the hard bounds instead). For all algorithms, plausible bounds were used to generate starting points. We also used plausible bounds (or their range) as inputs for algorithms that allow the user to provide additional information to guide the search, e.g. the length scale of the covariance matrix in CMA-ES, the initialization box for MCS, and plausible bounds in BADS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Procedure</head><p>For all problems and algorithms, for the purpose of our benchmark, we first transformed the problem variables according to the mapping described in 'Transformation of variables and constraints' (Section B.1). In particular, this transformation maps the plausible region to the [-1, 1] D hypercube, and transforms to log space positive variables that span more than one order of magnitude. This way, all methods dealt with the same standardized domains. Starting points during each optimization run were drawn uniformly randomly from inside the box of provided plausible bounds.</p><p>For deterministic problems, during each optimization run we kept track of the best (lowest) function value y t best found so far after t function evaluations. We define the immediate regret (or error) at time t as y t best -y min , where y min is the true minimum or our best estimate thereof, and we use the error to judge whether the run is a success at step t (error less than a given tolerance ε). For problems in the BBOB09 set (both noiseless and noisy variants), we know the ground truth y min . For problems in the CCN17 set, we do not know y min , and we define it as the minimum function value found across all optimization runs of all algorithms (≈ 3.75 • 10 5 × D function evaluations per noiseless problem), with the rationale that it would be hard to beat this computational effort. We report the effective performance of an algorithm with non-negligible fractional overhead o &gt; 0 by plotting at step t × o its performance at step t, which corresponds to a shift of the performance curve when t is plotted in log scale (Fig 2 <ref type="figure">in</ref> the main text). <ref type="foot" target="#foot_7">11</ref>For noisy problems, we care about the true function value(s) at the point(s) returned by the algorithm, since, due to noise, it is possible for an algorithm to visit a neighborhood of the solution during the course of the optimization but then return another point. For each noisy optimization run, we allowed each algorithm to return up to three solutions, obtained either from multiple sub-runs, or from additional outputs available from the algorithm, such as with MCS, or with population-based methods (CMA-ES, ga, and particleswarm). If more than three candidate solutions were available, we gave precedence to the main output of the algorithm, and then we took the two additional solutions with lowest observed function value. We limited the number of candidates per optimization run to allow for a fair comparison between methods, since some methods only return one point and others potentially hundreds (e.g., ga) -under the assumption that evaluating the true value of the log likelihood for a given candidate would be costly. For the combinatorial game-playing problem subset in the CCN17 set, we increased the number of allowed solutions per run to 10 to match the strategy used in the original study <ref type="bibr" target="#b45">[46]</ref>. For noisy problems in the CCN17 set, we estimated the log likelihood at each provided candidate solution via 200 function evaluations, and took the final estimate with lowest average.</p><p>For plotting, we determined ranking of the algorithms in the legend proportionally to the overall performance (area under the curve), across iterations (deterministic problems) or across error tolerances (noisy problems.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Alternative benchmark parameters</head><p>In our benchmark, we made some relatively arbitrary choices to assess algorithmic performance, such as the range of tolerances ε or the number of function evaluations. We show here that our findings are robust to variations in these parameters, by plotting results from the BBOB09 set with a few key changes (see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Numerical implementation</head><p>BADS is currently freely available as a MATLAB toolbox, bads (a Python version is planned).</p><p>The basic design of bads is simplicity and accessibility for the non-expert end user. First, we adopted an interface that resembles that of other common MATLAB optimizers, such as fminsearch or fmincon. Second, bads is plug-and-play, with no requirements for installation of additional toolboxes or compiling C/C++ code via mex files, which usually requires specific expertise. Third, bads hides most of its complexity under the hood, providing the standard user with thoroughly tested default options that need no tweaking.</p><p>For the expert user or developer, bads has a modular design, such that POLL set generation, the SEARCH oracle, acquisition functions (separately for SEARCH and POLL), and initial design can be freely selected from a large list (under development), and new options are easy to add.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GP implementation</head><p>We based our GP implementation in MATLAB on the GPML Toolbox <ref type="bibr" target="#b57">[58]</ref> (v3.6), modified for increased efficiency of some algorithmic steps, such as computation of gradients, <ref type="foot" target="#foot_8">12</ref> , and we added specific functionalities. We optimize the GP hyperparameters with fmincon in MATLAB (if the Optimization Toolbox is available), or otherwise via a the minimize function provided with the GPML package, modified to support bound constraints.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig 1  (left)  shows aggregate results across all noiseless functions with D ∈ {3, 6, 10, 15}, for alternative choices of kernels and acquisition functions (only a subset is shown, such as the popular M 5/2 , EI combination), or by altering other features (such as setting n search = 1, or fixing the search covariance matrix to Σ or Σ WCM ). Almost all changes from the default configuration worsen performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig 1 (right)  shows aggregate results for the heteroskedastic set (homoskedastic results are similar). BADS outperforms all other optimizers, with CMA-ES (active, with or without the noisy option) coming second.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Real model-fitting problems (CCN17, deterministic). Fraction of successful runs (ε ∈ [0.01, 10]) vs. # function evaluations per # dimensions. Left: Causal inference in visuo-vestibular perception [36] (6 subjects, D = 10). Middle: Bayesian confidence in perceptual categorization [37] (6 subjects, D = 13). Right: Neural model of orientation selectivity [38] (6 neurons, D = 12).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Real model-fitting problems (CCN17, noisy). Fraction of successful runs at 200 × D objective evaluations vs. tolerance ε. Left: Confidence in word recognition memory [40] (6 subjects, D = 6, 9). Middle: Target detection and localization [44] (6 subjects, D = 6). Right: Combinatorial board game playing [46] (6 subjects, D = 10).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>for 1 ≤</head><label>1</label><figDesc>d ≤ D, where L d is the period in the d-th coordinate dimension, and the length scale d of k 0 is shared between (d, d + |P |) pairs when d ∈ P . In BADS, the period is determined by the provided hard bounds as L d = UB d -LB d (where the hard bounds are required to be finite).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>d ln d ∼ N T 1 2</head><label>1</label><figDesc>(ln r max + ln r min ),1  4 (ln r max -ln r min ) 2 [∆ poll min , L d ] Signal variability σ f ln σ f ∼ N T ln SD(y),2 2 [10 -3 , 10 9 ] RQ kernel shape α ln α ∼ N T (1, 1) [-5, 5] GP observation noise σ ln σ ∼ N T (ln σ est , 1) [4 • 10 -4 , 150] deterministic f σ est = 10 -3 ∆ poll k noisy f σ est = 1 (or user-provided estimate)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Feature 0 = 2 - 10 , ∆ poll k = 1</head><label>02101</label><figDesc>and we allow LB d ∈ R ∪ {-∞} and similarly UB d ∈ R ∪ {∞}. We also consider optional non-bound constraints specified via a barrier function c : X → R that returns constraint violations. We only consider solutions such that c is zero or less. size n max 70 (D = 2), 250 (D = 20) (min 200 for noisy problems) POLL directions generation LTMADS with GP rescaling SEARCH set generation Two-step ES algorithm with search matrix Σ SEARCH evals. (n search ) max{D, 3 + D/2 } Aquisition function LCB Supported constraints None, bound, and non-bound via a barrier function c Initial mesh size ∆ mesh Implementation bads (MATLAB) Table S2: Summary of features of BADS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Fig S1 right, and Fig 1, right panel, in the main text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure S1 :</head><label>S1</label><figDesc>Figure S1: Artificial test functions (BBOB09). Same as Fig 1 in the main text, but with with alternative benchmark parameters (in bold). Left &amp; middle: Noiseless functions. Fraction of successful runs (ε ∈ [0.1, 1]) vs. # function evaluations per # dimensions, for D ∈ {3, 6, 10, 15} (96 test functions); for different BADS configurations (left) and all algorithms (middle). Right: Heteroskedastic noise. Fraction of successful runs at 500 × D objective evaluations vs. tolerance ε.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Bayesian Adaptive Direct Search Input: objective function f , starting point x 0 , hard bounds LB, UB, (optional: plausible bounds PLB, PUB, barrier function c, additional options)</figDesc><table><row><cell cols="2">1: Initialization: ∆ mesh 0</cell><cell cols="3">← 2 -10 , ∆ poll 0 ← 1, k ← 0, evaluate f on initial design</cell><cell>Section 3.1</cell></row><row><cell cols="2">2: repeat</cell><cell></cell><cell></cell></row><row><cell>3:</cell><cell cols="4">(update GP approximation at any step; refit hyperparameters if necessary)</cell><cell>Section 3.2</cell></row><row><cell>4:</cell><cell>for 1 . . . n search do</cell><cell></cell><cell></cell><cell>SEARCH stage, Section 3.3</cell></row><row><cell>5:</cell><cell cols="2">x search ← SEARCHORACLE</cell><cell></cell><cell>local Bayesian optimization step</cell></row><row><cell>6:</cell><cell cols="4">Evaluate f on x search , if improvement is sufficient then break</cell></row><row><cell>7:</cell><cell cols="2">if SEARCH is NOT successful then</cell><cell></cell><cell>optional POLL stage, Section 3.3</cell></row><row><cell>8:</cell><cell cols="2">compute poll set P k</cell><cell></cell></row><row><cell>9:</cell><cell cols="4">evaluate opportunistically f on P k sorted by acquisition function</cell></row><row><cell>10:</cell><cell cols="2">if iteration k is successful then</cell><cell></cell></row><row><cell>11:</cell><cell cols="2">update incumbent x k+1</cell><cell></cell></row><row><cell>12: 13:</cell><cell cols="2">if POLL was successful then ∆ mesh k else</cell><cell>← 2∆ mesh k</cell><cell>, ∆ poll k ← 2∆ poll k</cell></row><row><cell>14:</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>Problem specification</p>The algorithm is initialized by providing a starting point x 0 , vectors of hard lower/upper bounds LB, UB, and optional vectors of plausible lower/upper bounds PLB, PUB, with the Algorithm 1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Artificial test functions (BBOB09). Left &amp; middle: Noiseless functions. Fraction of successful runs (ε ∈ [0.01, 10]) vs. # function evaluations per # dimensions, for D ∈ {3, 6, 10, 15} (96 test functions); for different BADS configurations (left) and all algorithms (middle). Right: Heteroskedastic noise. Fraction of successful runs at 200 × D objective evaluations vs. tolerance ε.Noiseless functionsWe then compared BADS to other algorithms (Fig1 middle). Depending on the number of function evaluations, the best optimizers are BADS, methods of the fmincon family, and, for large budget of function evaluations, CMA-ES with active update of the covariance matrix.Noisy functionsWe produce noisy versions of the BBOB09 set by adding i.i.d. Gaussian observation noise at each function evaluation, y</figDesc><table><row><cell>Fraction solved</cell><cell cols="4">0 0.25 0.5 0.75 1 BBOB09 noiseless (BADS variants) bads (rq,lcb,default) bads (search-wcm) bads (m5/2,ei) bads (search-ℓ) bads (se,pi) bads ( =1) search n</cell><cell>Fraction solved</cell><cell>0 0.25 0.5 0.75 1</cell><cell cols="2">BBOB09 noiseless bads fmincon (actset) fmincon fmincon (sqp) cmaes (active) mcs fminsearch cmaes global patternsearch simulannealbnd particleswarm ga randsearch</cell><cell>Fraction solved at 200×D func. evals.</cell><cell cols="4">0 0.25 0.5 BBOB09 with heteroskedastic noise 1 bads cmaes (noisy,active) cmaes (noisy) snobfit ga simulannealbnd fmincon (actset) randsearch fmincon fmincon (sqp) fminsearch global particleswarm 0.75 patternsearch mcs</cell></row><row><cell></cell><cell>10</cell><cell>50</cell><cell>100</cell><cell>500</cell><cell></cell><cell>10</cell><cell>50</cell><cell>100</cell><cell>500</cell><cell>10</cell><cell>3</cell><cell>1</cell><cell>0.3</cell><cell>0.1</cell></row><row><cell></cell><cell cols="3">Function evaluations / D</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Function evaluations / D</cell><cell></cell><cell></cell><cell cols="3">Error tolerance ε</cell></row><row><cell cols="2">Figure 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table S3 :</head><label>S3</label><figDesc>Tested</figDesc><table /><note><p>algorithms. Top: Freely available algorithms. Bottom: Algorithms in MATLAB's Optimization, Global Optimization, and Statistics and Machine Learning toolboxes. For all algorithms we note whether they explicitly deal with noisy objectives (noise column), and whether they are local or global algorithms (global column). Global methods ( ) potentially search the full space, whereas local algorithms () can only find a local optimum, and need a multi-start strategy. We denote with (≈) semi-local algorithms with intermediate behavior -semi-local algorithms might be able to escape local minima, but still need a multi-start strategy.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code available at https://github.com/lacerbi/bads.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>A variable d can be fixed by setting (x0) d = LB d = UB d = PLB d = PUB d . Fixed variables become constants, and BADS runs on an optimization problem with reduced dimensionality.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Note that the error tolerance ε is not a fractional error, as sometimes reported in optimization, because for model comparison we typically care about (absolute) differences in log likelihoods.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Unpublished; upcoming work from Aspen H. Yoo and Wei Ji Ma.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Unpublished; upcoming work from Andra Mihali and Wei Ji Ma.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_5"><p>Since this simple test might fail, users are encouraged to actively specify whether the function is noisy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_6"><p>Unit trace (sum of diagonal entries) for Σ implies that a draw ∼ N (0, Σ) has unit expected squared length.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7"><p>We did not apply this correction when plotting the results of vanilla BO (bayesopt), since the algorithm's performance is already abysmal even without accounting for the substantial overhead.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p>We note that version 4.0 of the GPML toolbox was released while BADS was in development. GPML v4.0 solved efficiency issues of previous versions, and might be supported in future versions of BADS.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Will Adler, Robbe Goris, Andra Mihali, Bas van Opheusden, and Aspen Yoo for sharing data and model evaluation code that we used in the CCN17 benchmark set; Maija Honig, Andra Mihali, Bas van Opheusden, and Aspen Yoo for providing user feedback on earlier versions of the bads package for MATLAB; Will Adler, Andra Mihali, Bas van Opheusden, and Aspen Yoo for helpful feedback on a previous version of this manuscript; John Wixted and colleagues for allowing us to reuse their data for the CCN17 'word recognition memory' problem set; and three anonymous reviewers for useful feedback. This work has utilized the NYU IT High Performance Computing resources and services.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>In this Supplement, we expand on the definitions and implementations of Gaussian Processes (GPs) and Bayesian optimization in BADS (Section A); we give a full description of the BADS algorithm, including details omitted in the main text (Section B); we report further details of the benchmark procedure, such as the full list of tested algorithms and additional results (Section C); and, finally, we briefly discuss the numerical implementation (Section D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Gaussian processes for Bayesian optimization in BADS</head><p>In this section, we describe definitions and additional specifications of the Gaussian process (GP) model used for Bayesian optimization (BO) in BADS. Specifically, this part expands on Sections 2.2 and 3.2 in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GP posterior moments</head><p>We consider a GP based on a training set X with n points, a vector of observed function values y, and GP mean function m(x) and GP covariance or kernel function k(x, x ), with i.i.d. Gaussian observation noise σ 2 &gt; 0. The GP posterior latent marginal conditional mean µ and variance s 2 are available in closed form at a chosen point as</p><p>where</p><p>), . . . , k(x, x (n) )) is the n-dimensional column vector of cross-covariances, and θ is the vector of GP hyperparameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Covariance functions</head><p>Besides the automatic relevance determination (ARD) rational quadratic (RQ) kernel described in the main text (and BADS default), we also considered the common squared exponential (SE) kernel</p><p>and the ARD Matérn 5/2 kernel <ref type="bibr" target="#b4">[5]</ref>,</p><p>where σ 2 f is the signal variance, and 1 , . . . , D are the kernel length scales along each coordinate. Note that the RQ kernel tends to the SE kernel for α → ∞.</p><p>The Matérn 5/2 kernel has become a more common choice for Bayesian global optimization because it is only twice-differentiable <ref type="bibr" target="#b4">[5]</ref>, whereas the SE and RQ kernels are infinitely differentiable -a stronger assumption of smoothness which may cause extrapolation issues. However, this is less of a problem for a local interpolating approximation (as in BADS) than it is for a global approach, and in fact we find the RQ kernel to work well empirically (see main text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Composite periodic kernels</head><p>We allow the user to specify one or more periodic (equivalently, circular) coordinate dimensions P ⊆ {1, . . . , D}, which is a feature of some models in computational neuroscience (e.g., the preferred orientation of a neuron, as in the 'neuronal selectivity' problem set <ref type="bibr" target="#b37">[38]</ref> of the CCN17 benchmark; see Section 4.3 in the main text). For a chosen base stationary covariance function k 0 (e.g., RQ, SE, M 5/2 ), we define the composite ARD periodic kernel as</p><p>Polling order Since the POLL is opportunistic, we evaluate points in the poll set starting from most promising, according to the ranking given by the chosen acquisition function <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Update and termination</head><p>If the SEARCH stage was successful in finding a sufficient improvement, we skip the POLL, move the incumbent and start a new iteration, without changing the mesh size (note that mesh expansion under a success is not required in the MADS framework <ref type="bibr" target="#b5">[6]</ref>). If the POLL stage was executed, we verify if overall the iteration was successful or not, update the incumbent in case of success, and double (halven, in case of failure) the mesh size (τ = 2). If the optimization has been stalling (no sufficient improvement) for more than three iterations, we accelerate the mesh contraction by temporarily switching to τ = 4.</p><p>The optimization stops when one of these conditions is met:</p><p>• the poll size ∆ poll k goes below a threshold ∆ poll min (default 10 -6 ); • the maximum number of objective evaluations is reached (default 500 × D);</p><p>• the algorithm is stalling, that is there has no sufficient improvement of the objective f , for more than 4 + D/2 iterations.</p><p>The algorithm returns the optimum x end (transformed back to original coordinates) that has the lowest objective value y end . For a noisy objective, we return instead the stored point with the lowest quantile q β across iterations, with β = 0.999; see Section 3.4 in the main text. We also return the function value at the optimum, y end , or, for a noisy objective, our estimate thereof (see below, Section B.5). See the online documentation for more information about the returned outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Noisy objective</head><p>For noisy objectives, we change the behavior and default parameters of the algorithm to offset measurement uncertainty and allow for an accurate local approximation of f . First, we:</p><p>• double the minimum number of points added to the GP training set, n min = 100;</p><p>• increase the total number of points (within radius ρ) to at least 200, regardless of D;</p><p>• increase the initial design set size to n init = 20 points;</p><p>• double the number of allowed stalled iterations before stopping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncertainty handling</head><p>The main difference with a deterministic objective is that, due to observation noise, we cannot simply use the output values y i as ground truth in the SEARCH and POLL stages. Instead, we adopt a plugin approach <ref type="bibr" target="#b23">[24]</ref> and replace y i with the GP latent quantile function q β <ref type="bibr" target="#b22">[23]</ref> (see Eq. 3 in the main text). Moreover, we modify the MADS procedure by keeping an incumbent set {x i } k i=1 , where x i is the incumbent at the end of the i-th iteration. At the end of each POLL stage, we re-evaluate q β for all elements of the incumbent set, in light of the new points added to the cache which might change the GP prediction. We select as current (active) incumbent the point with lowest q β (x i ). During optimization, we set β = 0.5 (mean prediction only), which promotes exploration. For the last iteration, we instead use a conservative β end = 0.999 to select the optimum x end returned by the algorithm in a robust manner. For a noisy objective, instead of the noisy measurement y end , we return either our best GP prediction µ(x end ) and its uncertainty s(x end ), or, more conservatively, an estimate of E[f (x end )] and its standard error, obtained by averaging N final function evaluations at x end (default N final = 10). The latter approach is a safer option to obtain an unbiased value of E[f (x end )], since the GP approximation may occasionally fail or have substantial bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise estimate</head><p>The user can optionally provide a noise estimate σ est which is used to set the mean of the hyperprior over the observation noise σ (see Table <ref type="table">S1</ref>). We recommend to set σ est to the standard deviation of the noisy objective in the proximity of a good solution. If the problem has tunable precision (e.g., number of samples for log likelihoods evaluated via Monte Carlo), we recommend to set it, compatibly with computational cost, such that the standard deviation of noisy evaluations in the neighborhood of a good solution is of order 1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Derivative-free optimization: A review of algorithms and comparison of software implementations</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Sahinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1247" to="1293" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient global optimization of expensive black-box functions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schonlau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="455" to="492" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Cora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1012.2599</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Taking the human out of the loop: A review of Bayesian optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="148" to="175" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Practical Bayesian optimization of machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2951" to="2959" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mesh adaptive direct search algorithms for constrained optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Audet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dennis</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on optimization</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="188" to="217" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bayesian guided pattern search for robust local optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Taddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="389" to="401" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Noisy kriging-based optimization methods: A unified implementation within the DiceOptim package</title>
		<author>
			<persName><forename type="first">V</forename><surname>Picheny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ginsbourger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1035" to="1053" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The mesh adaptive direct search algorithm with treed Gaussian process surrogates</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Gramacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Le Digabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="419" to="447" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequential model-based optimization for general algorithm configuration</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LION</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="507" to="523" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Algorithms for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kégl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2546" to="2554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical surrogate formulations for simulationbased design optimization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Talgorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Le Digabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kokkolaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mechanical Design</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="21405" to="21406" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Erratum: Mesh adaptive direct search algorithms for constrained optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Audet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Custódio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dennis</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1501" to="1503" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Optimization and Nonsmooth Analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Clarke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Gaussian Processes for Machine Learning</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cases for the nugget in modeling computer experiments</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Gramacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="713" to="722" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gaussian process optimization in the bandit setting: No regret and experimental design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1015" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Mockus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tiesis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zilinskas</surname></persName>
		</author>
		<title level="m">Towards Global Optimisation. (North-Holland Amsterdam)</title>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="117" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kushner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Algorithm 659: Implementing Sobol&apos;s quasirandom sequence generator</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bratley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="88" to="100" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Portfolio allocation for Bayesian optimization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="327" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Quantile-based optimization of noisy computer experiments with tunable precision</title>
		<author>
			<persName><forename type="first">V</forename><surname>Picheny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ginsbourger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Richet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Caplin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A benchmark of kriging-based infill criteria for noisy optimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Picheny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ginsbourger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural and Multidisciplinary Optimization</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="607" to="626" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convergence properties of the Nelder-Mead simplex method in low dimensions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lagarias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Reeds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="112" to="147" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An interior algorithm for nonlinear optimization that combines line search and trust region steps</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Waltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="391" to="408" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Numerical Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Springer Series in Operations Research</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Genetic Algorithms in Search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization &amp; Machine Learning</title>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Global optimization by multilevel coordinate search</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neumaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="331" to="355" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Improving evolution strategies through active covariance matrix adaptation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Jastrebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Arnold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
			<publisher>CEC</publisher>
			<biblScope unit="page" from="2814" to="2821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>Csendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pál</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O H</forename><surname>Sendin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Banga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The GLOBAL optimization method revisited</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="445" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A method for handling uncertainty in evolutionary optimization with an application to feedback control of combustion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Niederberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guzzella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="180" to="197" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Real-parameter black-box optimization benchmarking</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Finck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Noiseless functions definitions</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Bayesian comparison of explicit and implicit causal inference strategies in multisensory heading perception</title>
		<author>
			<persName><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dokka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Angelaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">150052</biblScope>
		</imprint>
	</monogr>
	<note>bioRxiv preprint bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Human confidence reports account for sensory uncertainty but in a non-Bayesian way</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv preprint bioRxiv</title>
		<imprint>
			<biblScope unit="page">93203</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Origin and function of tuning diversity in macaque visual cortex</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Goris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="819" to="831" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Causal inference in multisensory perception</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Körding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Beierholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">943</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fechner&apos;s law in metacognition: A quantitative model of visual working memory confidence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="197" to="214" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A direct test of the unequal-variance signal detection model of recognition memory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mickes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Wais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="858" to="865" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A model for recognition memory: REM-retrieving effectively from memory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="145" to="166" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Behavior and neural basis of near-optimal visual search</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Navalpakkam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="783" to="790" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Does precision decrease with set size?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mazyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Vis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Variability in encoding precision accounts for visual short-term memory limitations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci U S A</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="8780" to="8785" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bnaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Galbiati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<title level="m">Do people think like computers? International Conference on Computers and Games</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="212" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Input warping for Bayesian optimization of non-stationary functions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1674" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">BayesOpt: A Bayesian optimization library for nonlinear optimization, experimental design and bandits</title>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez-Cantin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3735" to="3739" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Probabilistic numerics and uncertainty in computations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hennig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<date type="published" when="2015">2015. 20150142</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Quiñonero Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Approximation methods for Gaussian process regression. Large-scale kernel machines</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="203" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An extension of Shapiro and Wilk&apos;s W test for normality to large samples</title>
		<author>
			<persName><forename type="first">J</forename><surname>Royston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Statistics</title>
		<imprint>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lizotte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>University of Alberta)</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">SNOBFIT-stable noisy optimization by branch and fit</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neumaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Optimization by direct search: New perspectives on some classical and modern methods</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Torczon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="385" to="482" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A new optimizer using particle swarm theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Symposium on Micro Machine and Human Science</title>
		<meeting>the Sixth International Symposium on Micro Machine and Human Science</meeting>
		<imprint>
			<date type="published" when="1995">1995. 1995</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Problem definitions and evaluation criteria for the CEC 2014 special session and competition on single objective real-parameter numerical optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suganthan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Gaussian processes for machine learning (GPML) toolbox</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3011" to="3015" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
