<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IDENTIFYING COMPUTER GRAPHICS USING HSV COLOR MODEL AND STATISTICAL MOMENTS OF CHARACTERISTIC FUNCTIONS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wen</forename><surname>Cheni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><forename type="middle">Q</forename><surname>Shii</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">New Jersey Institute of Technology</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">2Dept. of Computer Science</orgName>
								<orgName type="institution">Tongji University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">IDENTIFYING COMPUTER GRAPHICS USING HSV COLOR MODEL AND STATISTICAL MOMENTS OF CHARACTERISTIC FUNCTIONS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4126B49BC61B84D2CA39A4BD1693E085</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Computer graphics generated by advanced rendering software come to appear so photorealistic that it has become difficult for people to visually differentiate them from photographic images. Consequently, modern computer graphics may be used as a convincing form of image forgery. Therefore, identifying computer graphics has become an important issue in image forgery detection. In this paper, a novel approach to distinguishing computer graphics from photographic images is introduced. The statistical moments of characteristic function of the image and wavelet subbands are used as the distinguishing features. In addition, we investigate the influence of different image color representations on the feature effectiveness. Specifically, the efficiency of using RGB and HSV color models is investigated. The experiments have shown that the features extracted from HSV color space, which decouples brightness from chromatic components, have demonstrated better performance than that from RGB color model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This paper aims at the development of a novel method to automatically separate computer graphics from photographic images. In this paper, computer graphics will be used to refer to images which are created by a variety of rendering software, and photographic images are the output of imaging acquisition devices such as digital camera.</p><p>The identification of computer graphics is challenging. Computer graphics can now achieve such a photorealistic level that people cannot identify it with high confidence. From a practical point of view, an automatic classification system is useful to deal with this issue. On the one hand, the breakthrough made in this research area will defeat the image forgery in the following areas: criminal investigation, journalism, intelligence, etc. On the other hand, it will help to improve the rendering technology to generate more photorealistic computer graphics used in movie industry.</p><p>The detection of computer graphics can be considered as a two-class pattern recognition problem. The goal is to determine appropriate features and develop a classification system to differentiate computer graphics from photographic images. In the prior works, several classification systems based on different types of image features have been developed. In <ref type="bibr" target="#b0">[1]</ref> the classification problem was addressed by modeling the characteristics of cartoon. The features are extracted from the color saturation, color histogram, edge histogram, compression ratio, pattern spectrum and the ratio of image pixels with brightness greater than a threshold. The total number of features is 108. The prior work <ref type="bibr" target="#b1">[2]</ref> uses image wavelet decomposition to capture regularities inherent to photographic images. The approach collects features from the first four order statistics -mean, variance, skewness and kurtosis -of horizontal, vertical and diagonal subbands. The same four statistics are computed from the linear prediction error for the wavelet coefficients. The dimension of feature vector is 216. In <ref type="bibr" target="#b2">[3]</ref> the geometry features are extracted by analyzing physical differences between the generative process of computer graphics and photographic images. The 192 geometry features are characterized by differential geometry, fractal geometry and local patch statistics. In addition, there are other related works on broad image classification such as city images vs. landscapes images <ref type="bibr" target="#b3">[4]</ref>, and photographs vs. paintings <ref type="bibr" target="#b4">[5]</ref>.</p><p>A color image can be represented in different color space for different applications. In the previous works, RGB (Red, Green, Blue) color space was used to extract all [2] or part [3] of the features. In <ref type="bibr" target="#b1">[2]</ref>, the wavelet-based image statistics are computed for RGB three channels. In <ref type="bibr" target="#b2">[3]</ref>, the joint spatial-color patch statistics, fractal geometry and differential geometry are formed in RGB space. In <ref type="bibr" target="#b0">[1]</ref>, some features are collected in HSV (Hue, Saturation, Value (brightness)) color space. In this paper, the proposed method constructs all features in the HSV color space. The distinguishing features have been successfully used in our previous work on steganalysis for gray-scale image <ref type="bibr" target="#b5">[6]</ref>. The features are the moments of characteristic function of wavelet subbands. We investigate the effect of image color representation on the classification performance. Specifically, the classification performance of HSV color models is compared with that of RGB model.</p><p>To evaluate the proposed approach, we use images from the Columbia Image Dataset photographic images contain both natural and artificial scenes. For computer graphics, only those with high level of photorealism are considered. All images are restricted to color images. The rest of this paper is organized as follows. In Section 2, the proposed features for differentiation of computer graphics from photographic images are described. The selection of color model is discussed. Section 3 contains experimental results. Finally, the conclusions are drawn and some future works are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">IMAGE FEATURES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Selection of color model</head><p>In color image processing, there are various color models in use today. The RGB model is mostly used in hardware- oriented application such as color monitor. In the RGB model, images are represented by three components, one for each primary color -red, green and blue. Although human eye is strongly perceptive to red, green, and blue, the RGB representation is not well suited for describing color image from human perception point of view. Moreover, a color is not simply formed by these three primary colors.</p><p>When viewing a color object, human visual system characterizes it by its brightness and chromaticity. The latter is defined by hue and saturation. Brightness is a subjective measure of luminous intensity. It embodies the achromatic notion of intensity. Hue is a color attribute and represents a dominant color. Saturation is an expression of the relative purity or the degree to which a pure color is diluted by white light. The HSV model is motivated by the human visual system. In the HSV model, the luminous component (brightness) is decoupled from color-carrying information (hue and saturation). The HSV color model is defined as follows <ref type="bibr" target="#b6">[8]</ref>:</p><formula xml:id="formula_0">I60(G-B) H | 60(BR+ 2) 60(RG + 4) not defined r{ x S= MA 0 if MAX=R if MAX= G if MAX=B if MAX= 0 if MAXO 0 if MAX= 0 V =MAX</formula><p>where 6 = (MAX -MIN), MAX = max(R, G, B), and MIN = min(R, G, B). Note that the R, G, B values in Equation <ref type="bibr" target="#b0">(1)</ref> are scaled to [0, 1]. In order to confine H within the range of [0, 360],</p><p>H=H + 360, if H&lt;0.</p><p>It is more natural for human visual system to describe a color image by the HSV model than by the RGB model.</p><p>Intuitively, the features extracted in the HSV color space can capture the distinct characteristics of computer graphics better. For example, computer graphics is more color smooth than photographic images in the texture area. Fewer colors are contained in computer graphics. Intensity of computer graphics reveals different characteristic of edge and shade. These differences between computer graphics and photographic images are best described by decoupling the intensity from chromatic information, say, hue and saturation.</p><p>Inspired by the way human visual system perceives the color object, we propose to construct features from the HSV color space. For the purpose of performance comparison, the features are also extracted in the RGB color space. As shown in the next section, HSV features have better classification performance than RGB features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Moments of wavelet characteristic function</head><p>To accurately separate computer graphics from photographic images, determination of distinguishing features is a critical step. In the following, we describe the features proposed in this approach which are the statistical moments of wavelet characteristic function.</p><p>Image histogram has been widely used in image analysis. It is well-known that the histogram of a digital image or its wavelet subband is essentially the probability mass function (pmf), if the image grayscale values or the wavelet coefficient values are treated as a random variable. Any pmf Px may be expressed as a probability density function (pdf)f, by using the relation</p><formula xml:id="formula_1">fx (x0 ) = E Px (a)5(x0 -a) a (2)</formula><p>That is, if each component of the histogram is multiplied by a correspondingly shifted unit impulse, we then have the pdf. The pmf and pdf is exchangeable in the context of digital signal processing, e.g., in that of discrete Fourier transform (DFT). Thus the pdf can treated as the normalized version of a histogram. According to [9, pp. 145-148], the characteristic function (CF) is simply the Fourier transform of the pdf (with a reversal in the sign of the exponent).</p><p>Denote histogram and its CF by h(f) and H(f), respectively, we propose to use the statistical moments of the CFs of both a test image and its wavelet subbands as features, which are defined as follows.</p><p>(N12) /(N12) j=l j=l where H(f) is the CF component at frequency f, n is the moment order, and N is the total number of points in the horizontal axis of the histogram. These moments are called as features generated from the test image for short.</p><p>In addition to the moments of the test image, we also extract features in the same manner from the prediction-error image. The prediction-error image is the difference between the test image and its predicted version. The prediction algorithm used here is given by <ref type="bibr" target="#b8">[10]</ref> max(a, b) c &lt; min(a, b)</p><formula xml:id="formula_2">x = min(a, b) c &gt; max(a, b) a+b -c otherwise<label>(4)</label></formula><p>where a, b, c are the context of the pixel x under considerations. x is the prediction value of x. The locations of a, b, c are illustrated as in Fig. <ref type="figure">1</ref>.</p><p>|x |b| la lc Fig. <ref type="figure">1</ref>: Prediction context</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature extraction</head><p>To collect image features, i.e. moments of characteristic functions, a test image of either a computer graphic or a photographic image is represented by the H, S and V components. Each component image is first decomposed into three levels based on, say, Haar wavelet. At each level i, i 1, 2, 3, there are four subbands (approximation, horizontal, vertical and diagonal). Totally, there are 13 subbands involved in the feature extraction if the component image itself is considered as a subband at level 0. For each subband, the first three moments are derived according to Equation (3), resulting in 39 features. For the predictionerror image of each component image, the same wavelet decomposition is employed and another 39 features are collected. Therefore 78 features are extracted from each component image and its prediction-error image. Since there are three component images and three prediction-error component images, the total number of features is 234. These features will be referred to as HSV-based features. To compare the performance, the test image is also represented by the R, G, B component images and another set of 234 features is collected following the same procedure as described above. We call them as RGB-based features.  The block diagram of feature generation procedure is shown in Fig. <ref type="figure" target="#fig_1">2</ref> where the component are H, S, V for HSV model and R, G, B for RGB model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Image database</head><p>In the experiment, we used 1900 photographic images and 800 computer graphics in the Columbia Image Dataset [7]. As introduced in [7], the computer graphics were obtained from a variety of 3D graphics websites. The highly photorealistic computer graphics contain diverse content in various artistic styles. The photographic images are obtained from three sources: eight hundred images were taken by the authors of [7], four hundred were obtained from Philip Greenspun's personal collection <ref type="bibr" target="#b9">[11]</ref>, and the rest were downloaded from Google Image Search. Some examples are illustrated in Fig. <ref type="figure">3</ref> and Fig. <ref type="figure">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Experimental results</head><p>The Support Vector Machine (SVM) classifier with RBF kernel was employed in the classification experiment. We used the "grid-search" method of LIBSVM <ref type="bibr" target="#b10">[12]</ref> to find the optimal penalty parameter C and kernel parameter y of RBF kernel. The classification performance is obtained by the 20 runs of experiment with the best parameters C and y. To train the classifier, we randomly selected the training samples to include 5/6 of image set (1580 photographic mages and 665 computer graphics). The testing samples from the rest 1/6 of image set contain 135 photographic images and 135 computer graphics which are not involved in the training stage. The average detection rate is shown in Table <ref type="table">1</ref> where TP (true positive) represents the detection rate of computer graphics, TN (true negative) represents the detection rate of photographic images, and the accuracy is the arithmetic average of TP and TN. The receiver operating characteristics (ROC) curves are shown in Fig. <ref type="figure">5</ref>. The experimental results in Table <ref type="table" target="#tab_0">I</ref> show that the accuracy is 82.1% for HSV-based features, which is 5.2% higher than the accuracy of RGB-based features. The results indicate that the color model has an obvious influence on the effectiveness of image features. We also found that the proposed HSV-based features outperform the 216 wavelet features proposed in [2] which collects features in RGB space. However, the performance of [2] is better than that of our RGB-based features. This can be explained as follows.</p><p>That is, the correlation between color channels is exploited to derive statistics as part of features in <ref type="bibr" target="#b1">[2]</ref>, which has enhanced the distinguishing power of features; while our RGB-based features are collected from each color channel independently. The observation of performance can also be verified by the ROC curves in Fig. <ref type="figure">5</ref>. Here we did not compare the proposed approach with [3] for the reason that the source code of algorithm in <ref type="bibr" target="#b2">[3]</ref> is not publicly available. Finally, Table <ref type="table" target="#tab_0">II</ref> contains the classification performance for three different component combinations -HV (hue and brightness), SV (saturation and brightness) and HS (hue and saturation). The 156 features from the hue and brightness components can achieve accuracy of 79.6% which is better than the 234 RGB-based features and comparable to the 216 wavelet features <ref type="bibr" target="#b1">[2]</ref>.</p><p>HSV RGB <ref type="bibr" target="#b1">[2]</ref> -1--H- Fig. <ref type="figure">5</ref>: ROC curves (x axial for FP, y axial for TP)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION AND FUTURE WORKS</head><p>A novel approach to the identification of computer graphics is proposed in this paper. The distinguishing features are formed by using statistical moments of characteristic function of wavelet subbands and their prediction-errors.</p><p>The effect of the color space representation on the classification performance has been investigated. The proper selection of color image representations is important to extract effective features. There are many color models in use today in the area of color image processing. In this paper, we investigate only two commonly used color representation, i.e. HSV and RGB. It is highly expected that there exists an optimal color model which contributes to the most effective distinguishing features. One of our works in progress is to design an optimization algorithm to search for the best color model. Furthermore, once the features have been derived, it is possible that there may be redundant or unnecessary features among the derived features. The results in Table <ref type="table" target="#tab_0">II</ref> indicate that the classification accuracy can be achieved even only a subset of the image features is used. Hence, another future work is to design an algorithm to select a reduced feature set without significant degradation in classification performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[7]. The contents of 1-4244-1017-7/07/$25.00 C2007 IEEE 1123 ICME 2007</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: Feature extraction from each image component</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>Fig.3: Some examples of computer graphics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table I :</head><label>I</label><figDesc>Detection rate</figDesc><table><row><cell></cell><cell>TP</cell><cell>TN</cell><cell></cell><cell>Accuracy</cell></row><row><cell></cell><cell cols="3">71.9%T 92.3%</cell><cell>82.1%</cell></row><row><cell></cell><cell cols="3">64.0%T 89.9%</cell><cell>76.9%</cell></row><row><cell></cell><cell cols="3">68.6%T 92.9%</cell><cell>80.8%</cell></row><row><cell>0.8</cell><cell></cell><cell cols="2">0.80</cell></row><row><cell>0.6</cell><cell></cell><cell cols="2">0.6</cell></row><row><cell>0.4</cell><cell></cell><cell cols="2">0.4</cell></row><row><cell>0.2</cell><cell>234D-HSV-</cell><cell cols="2">0.2</cell><cell>234D-HSV</cell></row><row><cell cols="3">234D-RGB 00 0 0.2 0.4 0.6 0.8 1</cell><cell>0</cell><cell>216D 0.2 0.4 0.6 0.8</cell><cell>1</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detecting cartoons: a case study in automatic video-genre classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Laneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rohrig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expro</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="449" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How realistic is photorealistic?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="845" to="850" />
			<date type="published" when="2005-02">February 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Physics-motivated features for distinguishing photographic images and computer graphics</title>
		<author>
			<persName><forename type="first">T.-T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-P</forename><surname>Tsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-11">November 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On image classification: city vs. landscapes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vailaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="1921" to="1936" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distinguishing paintings from photographs</title>
		<author>
			<persName><forename type="first">Florin</forename><surname>Cutzu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riad</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Leykin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="249" to="273" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Steganalysis based on moments of characrteristic functions using wavelet decomposition, predictionerror image and neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICME</title>
		<imprint>
			<date type="published" when="2005-07">July 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Color gamut transform pairs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Leon-Garcia</surname></persName>
		</author>
		<title level="m">Probability and Random Processes for Electrical Engineering</title>
		<meeting><address><addrLine>2nd Edition, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley Publishing Company</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LOCO-I: A low complexity content-based lossless image compression algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Seroussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ofIEEE Data Compression Conf</title>
		<meeting>ofIEEE Data Compression Conf</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="http:Hphilip.greenspun.com" />
		<title level="m">Philip Greenspun&apos;s collection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A practical guide to support vector classification</title>
		<author>
			<persName><forename type="first">C. -W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C. -C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C. -J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
