<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-scale Kernel based Residual Convolutional Neural Network for Motor Fault Diagnosis Under Non-stationary Conditions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Ruonan</forename><surname>Liu</surname></persName>
							<email>liuruonan04@163.com</email>
						</author>
						<author>
							<persName><roleName>Student Member, IEEE</roleName><forename type="first">Fei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Boyuan</forename><forename type="middle">Ruonan</forename><surname>Yang</surname></persName>
							<email>yangboyuanxjtu@163.com</email>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">S</forename><forename type="middle">Joe</forename><surname>Qin</surname></persName>
							<email>sqin@usc.edu.</email>
						</author>
						<author>
							<persName><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Intelligence and Computing</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Institute of Cyberspace Research</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<postCode>310007</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Boyuan Yang is with School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution" key="instit2">Uni-versity of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Department of Chemical Engineering and Materials Science</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-scale Kernel based Residual Convolutional Neural Network for Motor Fault Diagnosis Under Non-stationary Conditions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9F3E9C90161E11851A4DEE0E5109366F</idno>
					<idno type="DOI">10.1109/TII.2019.2941868</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T13:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Motor fault diagnosis</term>
					<term>multi-scale kernel convolutional neural network</term>
					<term>residual learning</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Motor fault diagnosis is imperative to enhance the reliability and security of industrial systems. However, since motors are often operated under non-stationary conditions, the high complexity of vibration signals raises notable difficulties for fault diagnosis. Therefore, considering the special physical characteristics of motor signals under non-stationary conditions, a multi-scale kernel based residual network (MK-ResCNN) is proposed in this paper for motor fault diagnosis. Our contributions mainly fall into two aspects. First, we notice that each motor fault category has various patterns in vibration signals due to the changing operational conditions of the motor. To capture these patterns, a multi-scale kernel algorithm are applied in the CNN architecture. Second, since the motor vibration signals are made up of many different components from different transfer paths, they are very complex and variable. To enable the architecture to extract fault features from deep and hierarchical representation spaces, sufficient depth of the network is needed, which will lead to the degradation problem. In the proposed method, residual learning is embedded into the multi-scale kernel CNN to avoid performance degradation and build a deeper network. To validate the effectiveness of the proposed networks, a normal motor and five motors with different failures are tested. The results and comparisons with state-of-the-art methods highlight the superiority of the proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>M OTORS have been widely used in modern industrial systems, such as wind turbines and vehicles. However, as motors have become more and more complex and expensive, the tolerance for performance degradation, productivity decrease, and safety hazards is also becoming less and less <ref type="bibr" target="#b0">[1]</ref>. On the other hand, no matter how good-quality the products are, they will deteriorate over time <ref type="bibr" target="#b1">[2]</ref>. Therefore, as an effective means to estimate the reliability of motors and reduce the risk of unplanned shutdowns, fault diagnosis is of vital importance in modern industrial systems <ref type="bibr" target="#b2">[3]</ref>.</p><p>Because shallow learning models are unable to extract complex features, traditional fault diagnosis methods usually combine feature extractors with shallow learning models such as artificial neural networks (ANNs) or support vector machines (SVMs) <ref type="bibr" target="#b3">[4]</ref>. Feature extractors transform the raw signals into low-dimensional vectors so that they can be easily matched, and are relatively invariant with respect to transformations and distortions <ref type="bibr" target="#b4">[5]</ref>. As the most commonly used feature extractors, Fourier transform, wavelet transform [6], empirical mode decomposition (EMD) <ref type="bibr" target="#b6">[7]</ref>, spectral kurtosis (SK) <ref type="bibr" target="#b7">[8]</ref> and sparse representations <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> are all widely used in industrial practice. The performance of the shallow learning models depends heavily on the quality of the extracted features from the collected signals <ref type="bibr" target="#b10">[11]</ref>.</p><p>The construction of feature extractor needs relevant prior knowledge and is rather specific to the task. However, motors have become increasingly complicated and diversified, which make it time-consuming to construct a feature extractor for each type of motor. On the other hand, with the advancement of sensor techniques, the collection of industrial data becomes more convenient. Therefore, traditional fault diagnosis methods have been re-examined from the point of big data <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Recently, deep learning technologies have led to a series of breakthroughs in the field due to its attractive characteristic that directly learns the high-level and hierarchical representations from massive raw data <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Convolutional neural networks (CNNs) <ref type="bibr" target="#b15">[16]</ref>, deep belief networks (DBNs) <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, residual CNN (ResCNN) <ref type="bibr" target="#b18">[19]</ref> and auto-encoders (SAEs) <ref type="bibr" target="#b19">[20]</ref> are popular deep learning methods used for various fault diagnosis applications. In <ref type="bibr" target="#b20">[21]</ref>, a deep auto-encoder is used for fault feature mining and intelligent diagnosis of rotating machinery with massive data. Gan et al. proposed a hierarchical diagnosis network (HDN) by collecting DBNs for the hierarchical identification of mechanical fault pattern recognition of rolling element bearings <ref type="bibr" target="#b16">[17]</ref>. An enhanced deep feature fusion method for rotating machinery fault diagnosis is proposed in <ref type="bibr" target="#b10">[11]</ref>. Hu et al. developed an intelligent fault diagnosis method for high-speed train based on deep neural networks <ref type="bibr" target="#b21">[22]</ref>. Oh et al. proposed a scalable and unsupervised feature engineering method using vibrationimaging and deep learning for rotor system diagnosis <ref type="bibr" target="#b14">[15]</ref>. Shao et al. designed a convolutional deep belief network model with Gaussian visible units for bearing fault diagnosis <ref type="bibr" target="#b22">[23]</ref>. Inspired by convolutional neural networks and wavelet transform, <ref type="bibr">Pan et</ref>  without prior knowledge <ref type="bibr" target="#b23">[24]</ref>. Many other fault diagnosis tasks have also been greatly benefited from deep models <ref type="bibr" target="#b24">[25]</ref>. However, mechanical vibration signals are usually long 1dimensional (1D) complex signals. Due to the varying operational conditions and noisy background, deeper and more complicated features should be extracted for mechanical fault diagnosis. In addition, the mechanical signals under nonstationary conditions can be much more complex. Thus, if deep networks are used to diagnose mechanical malfunctions, deep 1D architectures are needed to extract features from such complicated signals. However, experiments find that when deep networks start converging, a problem has been exposed: with the network depth increasing, accuracy tends to saturate and then degrade, which is not caused by over-fitting <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Therefore, the increase of deep network layers may lead to even more serious degradation problems. On the other hand, due to the fixed single-scale convolutional kernel and pooling size, the input signals are analyzed with a fixed scale in traditional deep networks, while industrial systems are always working under variable conditions, which lead to time-varying signals. Therefore, although deep learning is a powerful tool for data analysis, it is less effective to extract features from time varying signals.</p><p>To address the above problems, a multi-scale kernel-based residual convolutional neural network (MK-ResCNN) architecture is proposed in this paper for motor fault diagnosis. The main contributions of this paper are summarized as follows.</p><p>1) We propose a well-designed deep network, termed MK-ResCNN, for motor fault diagnosis. In MK-ResCNN, multiscaled convolutional kernels are used to capture the characteristics of raw fault signals from multiple scales, which promote the robustness and represent ability of the captured characteristics even under non-stationary conditions. In addition, we apply the identity mapping and residual mapping to make very deep networks applicable for learning efficient fault characteristics, meanwhile to overcome the performance degradation problem that appears in traditional deep networks.</p><p>2) Since the proposed method is based on CNN, it inherits the advantages of CNN that can extract features and recognize faults from raw time series signals without the help of signal processing techniques.</p><p>3) The proposed approach is evaluated through a motor fault simulation experiment with a comprehensive performance evaluation. The results are compared with state-of-the-art results in the field of fault diagnosis under non-stationary conditions to demonstrate the superiority of our method.</p><p>The rest of the paper is organized as follows. Section II describes the details of the proposed approach. Experimental setup and data description are illustrated in Section III. In Section IV, the proposed method, and five classical and stateof-the-art methods are applied to analyze the same experimental signals to show the effectiveness of the proposed method. Finally, conclusions are drawn in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED APPROACH A. Residual Learning</head><p>The analysis object for industrial system fault diagnosis is usually a long 1-dimensional (1D) complex vibration signal. In  addition, the changeable operational conditions of motors can even increase the difficulty. If we want to use deep networks to diagnose mechanical malfunctions, deeper 1D architectures are needed, because generally the deeper a network is, the more complex features it can extract, and the better the performance is. However, previous experiments show that there exists a degradation problem in deep networks: when the network depth increases, accuracy saturates and then degrades, and the addition of more layers can lead to an even higher training error, which is not caused by over-fitting <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>.</p><p>The degradation problem illustrates that a deep network is not easy to train. Theoretically, if the additional layer does not learn anything, but just copies the features of last layer (which is called identity mapping), the training error should not increase. Inspired by this intuition, residual learning <ref type="bibr" target="#b26">[27]</ref> is embedded in the proposed framework. For a deep network architecture, and the input x, the learned feature is denote as H(x). Now, we expect the network to learn the residual F (x) = H(x) -x because residual learning is easier than traditional feature learning. The residual learning is adopt every few stacked layers, as shown in Fig. <ref type="figure" target="#fig_1">1</ref>. The output y is obtained by a shortcut connection operation:</p><formula xml:id="formula_0">y = F (x, W i ) + x<label>(1)</label></formula><p>where x and y are the input and output vectors of the layers considered. Every building block has a multilayer architecture. F (x, W i ) is the residual function, which represents the residual mapping to be learned. Take the building block in Fig. <ref type="figure" target="#fig_1">1</ref> as an example: there are two layers, F (x, W i ) can be represented as:</p><formula xml:id="formula_1">F = W 2 σ(W 1 x)<label>(2)</label></formula><p>where σ represents the activation function. In this paper, σ is set to be the rectified linear unit (ReLU) function. The biases are omitted here to simplify the expression. The dimensions of x and y must be equal. If the input and output dimension are unequal, a linear projection W s can be performed by the shortcut connections to match the dimensions:</p><formula xml:id="formula_2">y = F (x, {W i }) + W s x<label>(3)</label></formula><p>If the residual value is not equal to 0, the network performance can still improve by adding the number of layers in the network. On the other hand if the residual value is 0, then the current layer is just an identity mapping, which will neither improve nor degrade. In this way, the degradation problem can be avoided, and therefore a deeper network can be built. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Convolutional Neural Networks</head><p>CNN is a variant of neural networks, which consists of convolutional layers, activation function layer and pooling layers.</p><p>Each convolutional layer consists of several convolutional units. The loss function is optimized by a backpropagation algorithm, such as the gradient descent algorithm <ref type="bibr" target="#b27">[28]</ref>, conjugate gradient method <ref type="bibr" target="#b28">[29]</ref> and AdaBoost algorithm <ref type="bibr" target="#b29">[30]</ref>. The aim of convolution operation is to extract different levels of hierarchical features from raw data. The first convolutional layer may only can extract some low level features. The more convolutional layers are, the more complex features can be extracted. Compared with other networks, CNN exploits sparse connectivity by making the kernel smaller than the input and enforcing a local connectivity pattern among neurons of adjacent layers. Thus, the complicated interactions between units can be described more efficiently, and the over-fitting risk can also be reduced. Each kernel (or weight matrix) in CNN is used across the entire visual field, but learnt only once instead of learning a separate set of weights for every location. Therefore, CNN is an extremely efficient way that applies the same linear transformation of a local region across the entire input to describe transformations.</p><p>In the activation function layer, ReLU is widely used because it can improve the training speed significantly <ref type="bibr" target="#b30">[31]</ref>. It is defined as:</p><formula xml:id="formula_3">f (x) = max(0, x)<label>(4)</label></formula><p>The pooling layer is another important part in CNN. It is sub-sampling in essence. Intuitively, this mechanism can be effective because, the precise location of a feature is far less important than its relative position. Pooling will continuously reduce the size of the data space, so the number of parameters and calculation cost will also decrease, which also controls over-fitting <ref type="bibr" target="#b31">[32]</ref>. The pooling operation also makes the feature maps extracted by CNN invariant to small translations of the input. In general, the pooling layer is periodically inserted between the convolutional layers of the CNN. Max pooling uses the maximum value from each of a cluster of neurons at the prior layer, which is the most common pooling technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multi-scale Kernel Convolutional Neural Networks</head><p>Industrial system fault diagnosis is a time series signal recognition or regression problem. However, there are still some challenges to solve the problem: first, the single-scale convolutional kernel size makes the network extract features from only one scale. However, signals will not stay in the same scale due to the change of components, systems or sampling frequency <ref type="bibr" target="#b32">[33]</ref>, which means that a fixed convolutional kernel size is not suitable for every signal. Secondly, industrial systems are usually not working under ideal conditions. Many factors may cause the change of signals, such as variable wind speed for wind turbines, changing loads and mission profiles for engines. Consequently, the ability to analyze signals over changing operation conditions must be considered if we want a fault diagnosis method to be widely applied in industrial systems.  To address these problems, a multi-scale kernel convolutional neural network (MK-ResCNN) is proposed in this paper. Firstly, we constructed a basic CNN block:</p><formula xml:id="formula_4">y = W ⊗ x + b s = BN (y) h = ReLU (s) (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>where ⊗ is the convolution operator. BN is batch normalization operation <ref type="bibr" target="#b33">[34]</ref>, which can improve generalization and allow us to use much higher learning rates. Then, the sub-block of MK-CNN is constructed by stacking two basic CNN blocks, as shown in Fig. <ref type="figure" target="#fig_2">2</ref>. As described before, residual learning extends the network to a very deep structure without degradation problem, so the residual learning structure is explored between each CNN sub-block to construct a deep network for complex feature extraction. Let Basic denotes the basic CNN block, which is corresponding to Eq. ( <ref type="formula" target="#formula_4">5</ref>), the sub-block is formalized as:</p><formula xml:id="formula_6">h 1 = Basic(x) h 2 = Basic(h 1 ) y = h 2 + x ĥ = ReLU (y)<label>(6)</label></formula><p>Then, a CNN block can be constructed by stacking several sub-blocks, as shown in Fig. <ref type="figure" target="#fig_5">3</ref>. Let subblock denotes the subblock, which is corresponding to Eq. ( <ref type="formula" target="#formula_6">6</ref>), then the block can be formalized as:  Thus, the MK-CNN architecture is constructed by multiple CNN blocks with different convolutional kernel sizes.</p><formula xml:id="formula_7">ĥ1 = subblock(x) ĥ2 = subblock( ĥ1 ) ĥ3 = subblock( ĥ2 )<label>(7</label></formula><p>We noticed that multi-scale CNN has been successfully applied for fault diagnosis of wind turbine gearboxes recently <ref type="bibr" target="#b34">[35]</ref>. However, the multi-scale in this paper means the flexible convolutional kernels, and multi-scale in <ref type="bibr" target="#b34">[35]</ref> represents flexible averaging strides. That is, in <ref type="bibr" target="#b34">[35]</ref>, the original input is converted by three ways: s = 1, s = 2 and s = 3, where s is the length of a nonoverlapping window. For example, the s = 2 is computing the average of every two items in the original signals with a stride of 2. The s = 3 is computing the average of every three items in the original signals with a stride of 3. In this way, the proposed method in <ref type="bibr" target="#b34">[35]</ref> can generate multi-scale lengths of original signals by computing average as samples. The proposed method in this paper applies different scale of convolutional kernels instead of down-sampling or taking averages on original signals. This is because downsampling and taking averages cannot change the outline shape of original signals, which may limit the performance of CNN. Using different sizes of kernels can learn features from original signals with different views with multiple scales, making CNN learn features in multi-scale views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. End-to-end Multi-scale Residual Learning Architecture</head><p>The structure of MK-ResCNN is graphically illustrated in Fig. <ref type="figure" target="#fig_3">4</ref>. In the experiment, time series signal segments are used as inputs of MK-ResCNN directly. Since CNN shows advantage in feature extraction, we construct a MK-ResCNN architecture with three CNN blocks. In order to extract features from different receptive fields, each block has different convolutional kernels. The kernel sizes of different MK-ResCNN blocks are set to be 1 × 3, 1 × 5 and 1 × 7. This is because the feature map obtained by a layer with big convolutional kernel can also be obtained by multiple layers with small convolutional kernels. Big convolutional kernel may lead to an increase of complexity and computation <ref type="bibr" target="#b35">[36]</ref>. Therefore, small convolutional kernels are used more often in practice. Then, unlike traditional CNN models, the pooling operation is excluded in a CNN block here in order to extract more detailed features. After the convolution blocks, the features are fed into a global average pooling layer to keep the robustness against translation of the framework and reduce the number of weights and prevent overfitting <ref type="bibr" target="#b31">[32]</ref>. We decided to use an average pooling layer to keep the global feature maps obtained from the convolutional layers (Average pooling uses the average value from each of a cluster of neurons at the prior layer). The feature vectors after pooling layers in different blocks are concatenated into a vector as the input of a fully connected network, which is followed by a softmax layer for fault recognition.</p><p>There are two reasons why just one fully connected network is added here. First, the parameters in fully connected networks are more than those in CNN, which makes it hard to train and can lead to the overfitting problem; second, only one fully connected layer means features are mostly extracted by CNN, so the network architecture can be estimated directly from results. That is, if the network is strong enough, only one fully connected layer is needed for classification; if the network is not strong enough, the addition of fully connected layer will not improve the performance a lot. And the adding parameters of the fully connected network will also cause overfitting.</p><p>Since mechanical signals are variable and noisy, deeper networks are always needed to extract the deep-hierarchical features, which makes the degradation problem an inevitable problem. To the best of our knowledge, we are the first to provide multi-scale kernel CNN embedded with residual learning for fault diagnosis, which can guarantee the performance cannot be influenced by the depth of the network <ref type="bibr" target="#b31">[32]</ref>. The flowchart of the MK-ResCNN based fault diagnosis method is shown in Fig. <ref type="figure" target="#fig_4">5</ref>. There are four steps in this framework:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motor Data Acquistion</head><note type="other">Sample Sample</note><p>Step 1: Data acquisition. The motor vibration signals are by data acquisition system and sensors that installed in the test motor.</p><p>Step 2: Data segmentation. Since we aim to build an endto-end diagnose system to make the system more intelligent, the collected vibration signals are cut into samples and used as training samples directly.</p><p>Step   fault diagnosis under non-stationary conditions is much more difficult than that of a constant speed. Studies about the non-stationary operational conditions mostly focus on timefrequency feature extraction of a signal segment, which can be time-consuming and poor generalized. Such features also cannot be used for fault recognition with machine learning methods directly. To verify the effectiveness of the proposed framework in dealing with nonlinear signals, an experiment on an electric machine fault simulator under non-stationary conditions is conducted.</p><p>The experiment setup consists of motor, tachometer, bearing, shaft and so on, as shown in Fig. <ref type="figure" target="#fig_6">6</ref>. The power supply frequency is 50 Hz. The accelerometer is used to collect the vertical vibration signal. The location of sensor is shown in Fig. <ref type="figure" target="#fig_7">7</ref>. The sampling frequency is 12800 Hz. The rotating speed is controlled manually, which ranges from 0 to 3600 r/min. The rotating speed variation of the test motors are similar with each other, as shown in Fig. <ref type="figure">8</ref>  <ref type="table" target="#tab_4">II</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS AND COMPARISONS</head><p>After data collection, the proposed MK-ResCNN method is applied to analyze the vibration signals. Both the training and test procedures are carried out offline. The loss function of the framework is set to be cross entropy loss. To graphically illustrate the learned essential features, t-distributed stochastic neighbor embedding (t-SNE) method <ref type="bibr" target="#b36">[37]</ref> is employed to provide 3-D visual representations of the original signals and the feature maps of last layers, as shown in Fig. <ref type="figure" target="#fig_9">10</ref>.</p><p>The feature map dimensions of the first layer (inputs) and the last layer (fully connect network) are all reduced to 3 dimensions for feature visualization and easier comparison, as shown in Fig. <ref type="figure" target="#fig_9">10</ref>. Different color represents different failure feature. It can be seen that different health states (or classes)</p><p>1551-3203 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.   <ref type="table" target="#tab_6">III</ref>. In Table <ref type="table" target="#tab_6">III</ref>, the number from 1 to 6 in the first column represents the test data labels in nine different conditions. The number from 1 to 6 in the first row represents the classification result of test data. In addition, the precision ratio p, recall ratio r and F1 score are used as evaluation indexes for method performance, which are defined as:</p><formula xml:id="formula_8">p = T P T P + F P r = T P T P + F N F 1 = 2p × r p + r<label>(8)</label></formula><p>where T P represents the true positive samples, that is, the positive samples that are correctly classified as positive; F P represents the false positive samples, that is, the negative samples but are misclassified as positive samples; F N represents the false negative samples, that is, the positive samples but are misclassified as negative samples. And the positive sample means the sample that is belong to current failure type; negative sample means the sample that is not belong to current failure type. p, r and F1 score of the MK-ResCNN method results are shown in Table <ref type="table">IV</ref>.</p><p>To verify the advantage of the proposed multi-scale framework in dealing with nonlinear signals, we compared our results to the 5 different approaches: manual feature selection with support vector machine (SVM), ResCNNs with kernel size 1 × 3,   <ref type="table" target="#tab_6">III</ref> and Table IV that both the p, r and F1 score of the proposed method are over 90%, which means that the probability of diagnosis two successive samples falsely is 0.01%. If a sample is diagnosed by mistake for once, we can continuously diagnosis the next sample, which will push the result to 100%.</p><p>On the other hand, as shown in Table <ref type="table">IV</ref>, it can be concluded that class 1 is the most difficult class that can be easily diagnosed incorrectly; and the results of class 6 perform the best. These conclusions are the same as the MK-ResCNN results. SVM with wavelet packet features performs worst. Because the feature dimensions of wavelet transform (WT) method need to be aligned, each feature dimension should has its physical significance. However, chronological feature extractors cannot make sure the information and physical significance of each dimension in WT remain the same. For example, the first dimensional information of the first sample that extracted by WT is the sum energy from 1 to 32 points. And the first dimensional information of the second 1551-3203 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A block of residual learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A MK-ResCNN sub-block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The structure of MK-ResCNN. The architecture consists of three CNN blocks with kernel sizes of 1 × 3, 1 × 5 and 1 × 7 respectively. Residual learning is applied in each CNN sub-block to avoid the degradation problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The flowchart of MK-ResCNN based fault diagnosis method.</figDesc><graphic coords="5,181.09,195.86,112.05,234.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 :</head><label>3</label><figDesc>Training MK-ResCNN model. After the vibration signals are cut into samples, the samples are used for MK-ResCNN model training. The Adam algorithm is applied here to optimize the loss function. Step 4: Fault diagnosis. The vibration signals of the test motor are also cut into samples in the same way as training samples, and used as the input of the trained MK-ResCNN model for fault recognition. The output of softmax regression can reflect the condition or the failure type of the test motor. III. EXPERIMENT AND DATA DESCRIPTION In practice, the working conditions of motors are always non-stationary. Because of the variable scales of features,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Experimental setup: (1) induction motor; (2) tachometer; (3) bearing; (4) shaft; (5) load disc; (6) belt; (7) bevel gearbox; (8) magnetic load; (9) reciprocating mechanism; and (10) variable speed controller.</figDesc><graphic coords="5,329.51,56.07,215.99,152.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Sensor location.</figDesc><graphic coords="5,347.51,260.89,179.99,134.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. The rotating speed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Feature embedding visualizations of high-dimensional feature maps at different layers in the proposed MK-ResCNN: (a) the original data; and (b) the output of fully connected layer. Feature maps in the last layer of MK-ResCNN are semantically separable compared to original data, suggesting that the extracted feature maps by the proposed framework are better features for fault diagnosis. Each sample is visualized as a point and samples belonging to the same class have the same color.</figDesc><graphic coords="6,347.15,307.74,197.22,175.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>ResCNN 1 × 5 ,</head><label>15</label><figDesc>ResCNN 1 × 7, and MK-CNN. SVM is used to analyze the sample vibration signal segments, with 5-layer wavelet packet energies as features. Three different ResCNNs with filter sizes 1×3, 1×5, 1×7 are tested respectively. Finally, a multi-scale kernel CNN without residual learning step (MK-CNN) is also used to analyze the vibration signals for comparison. The architecture of the MK-CNN stays the same with MK-ResCNN in Fig. 4 except that there is no residual learning. All of the models are trained and tested on the same datasets. The overall accuracies of the comparison methods are 93.19%, 93.47%, 92.59% and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. (a) The training accuracy trends and (b) its local enlargement of the proposed MK-ResCNN method, ResCNN with kernel size of 1 × 5 and MK-CNN. The blue line represents the training accuracy trend of MK-ResCNN, the red line represents that of ResCNN, and the green line represents that of MK-CNN.</figDesc><graphic coords="8,181.74,61.04,118.51,78.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1551-3203 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TII.2019.2941868, IEEE Transactions on Industrial Informatics</figDesc><table><row><cell>IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS</cell><cell>3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II NUMBERS</head><label>II</label><figDesc>OF TRAINING AND TEST SAMPLES.</figDesc><table><row><cell cols="2">BN+ReLU Conv1-32</cell><cell cols="2">(3×3@256)</cell><cell cols="2">BN+ReLU</cell><cell></cell><cell>Max Pooling</cell><cell>Feature Vector 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>total samples</cell><cell cols="2">1798 1798</cell><cell>1773 1898</cell><cell>1748 1773</cell></row><row><cell cols="2">BN+ReLU Conv2-32</cell><cell cols="2">(5×5@256)</cell><cell cols="2">BN+ReLU</cell><cell></cell><cell>Max Pooling</cell><cell>Feature Vector 2</cell><cell></cell><cell>Concatenate</cell><cell>Feature Vector</cell><cell>Fully Connected Network</cell><cell>Softmax</cell><cell>training samples testing samples</cell><cell>1451 347</cell><cell>1440 358</cell><cell>1416 357</cell><cell>1531 367</cell><cell>1385 363</cell><cell>1407 366</cell><cell>95% 100%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>90%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>80%</cell></row><row><cell cols="2">BN+ReLU Conv3-32</cell><cell cols="2">(7×7@256)</cell><cell cols="2">BN+ReLU</cell><cell></cell><cell>Max Pooling</cell><cell>Feature Vector 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85% 90% 95% 100%</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>90%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell cols="5">Conv1-32 Conv1-32 (1×3@256) (1×3@256) ReLU BN</cell><cell>BN</cell><cell>ReLU +</cell><cell>Average Pooling</cell><cell>Feature Vector 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BN ReLU BN ReLU</cell><cell cols="2">Conv2-32 Conv3-32</cell><cell cols="2">(1×5@256) (1×7@256)</cell><cell>BN BN</cell><cell>ReLU + ReLU +</cell><cell>Average Pooling Average Pooling</cell><cell>Feature Vector 2 Feature Vector 3</cell><cell>Feature Vector (768×1)</cell><cell>Fully Connected Network</cell><cell>Softmax</cell><cell></cell><cell></cell><cell>Input x Convolutional layer BN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Convolutional layer</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Convolutional layer</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Convolutional layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">BN+ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Convolutional layer</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Convolutional layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">BN+ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Convolutional layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Convolutional layer</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Convolutional layer BN+ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(1×3@256) Convolutional layer BN Conv1-32 ReLU</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">BN+ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BN</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ReLU</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Citation information: DOI 10.1109/TII.2019.2941868, IEEE Transactions on Industrial Informatics</figDesc><table><row><cell>IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE III CONFUSION</head><label>III</label><figDesc>MATRIX OF THE PROPOSED MK-RESCNN. And the different failure features extracted by MK-ResCNN can be easily distinguished or classified this time, thus shows a better diagnose performance, which verifies the effectiveness of the proposed method in learning a discriminative set of features for nonlinear signal fault diagnosis.The overall accuracy of the MK-ResCNN is 95.69%. To give a more concrete illustration, the confusion matrix of the MK-ResCNN results is shown in Table</figDesc><table><row><cell>label</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>1</cell><cell cols="2">318 14</cell><cell>2</cell><cell>7</cell><cell>13</cell><cell>0</cell></row><row><cell>2</cell><cell>11</cell><cell>332</cell><cell>0</cell><cell>4</cell><cell>4</cell><cell>0</cell></row><row><cell>3</cell><cell>4</cell><cell>2</cell><cell cols="2">353 0</cell><cell>1</cell><cell>0</cell></row><row><cell>4</cell><cell>9</cell><cell>9</cell><cell>0</cell><cell cols="2">354 3</cell><cell>0</cell></row><row><cell>5</cell><cell>5</cell><cell>0</cell><cell>2</cell><cell>2</cell><cell>342</cell><cell>0</cell></row><row><cell>6</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>366</cell></row><row><cell cols="7">are heavily overlapped at the input layer, which demonstrates</cell></row><row><cell cols="7">that the feature information of raw signals hardly differen-</cell></row><row><cell>tiable.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work was supported in part by the National Science and Technology Major Project (2017-I-0001-0001, IEEE Transactions on Industrial Informatics IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS 9 Ruonan Liu received the B.S., M.S. and PhD</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Electric motor fault detection and diagnosis by kernel density estimation and kullback-leibler divergence based on stator current measurements</title>
		<author>
			<persName><forename type="first">A</forename><surname>Giantomassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferracuti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iarlori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ippoliti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1770" to="1780" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enhanced restricted boltzmann machine with prognosability regularization for prognostics and health assessment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pavel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7076" to="7083" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Artificial intelligence for fault diagnosis of rotating machinery: A review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="33" to="47" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Time-frequency atoms-driven support vector machine method for bearings incipient fault diagnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="345" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wavelets for fault diagnosis of rotary machines: A review with applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fault feature extraction of gearbox by using overcomplete rational dilation discrete wavelet transform on signals measured from vibration sensors</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="275" to="298" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast computation of the kurtogram for the detection of transient faults</title>
		<author>
			<persName><forename type="first">J</forename><surname>Antoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="124" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fault diagnosis for wind turbine generator bearing via sparse representation and shift-invariant k-svd</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse time-frequency representation for incipient fault diagnosis of wind turbine drive train</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An enhancement deep feature fusion method for rotating machinery fault diagnosis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="200" to="220" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Big data deep learning: challenges and perspectives</title>
		<author>
			<persName><forename type="first">X.-W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="514" to="525" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Process data analytics in the era of big data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIChE Journal</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3092" to="3100" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Capturing highdiscriminative fault features for electronics-rich analog system via deep learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Informat</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1213" to="1226" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable and unsupervised feature engineering using vibration-imaging and deep learning for rotor system diagnosis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Youn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3539" to="3549" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dislocated time series convolutional neural architecture: An intelligent fault diagnosis approach for electric machine</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Construction of hierarchical diagnosis network based on deep learning and its application in the fault pattern recognition of rolling element bearings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The optimized deep belief networks with improved logistic sigmoid units and their application in fault diagnosis for planetary gearboxes of wind turbines</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multiple wavelet coefficients fusion in deep residual networks for fault diagnosis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4696" to="4706" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using multiple-feature-spaces-based deep learning for tool condition monitoring in ultraprecision manufacturing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Panoutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3794" to="3803" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep neural networks: A promising tool for fault characteristic mining and intelligent diagnosis of rotating machinery with massive data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="303" to="315" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intelligent fault diagnosis of the high-speed train with big data based on deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2106" to="2116" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Electric locomotive bearing fault diagnosis using novel convolutional deep belief network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ind. Electron</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2727" to="2736" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Liftingnet: a novel deep learning network with layerwise feature learning from noisy mechanical data for fault classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4973" to="4982" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep residual networks with dynamically weighted wavelet coefficients for fault diagnosis of planetary gearboxes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4290" to="4300" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Highway networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional neural networks at constrained time cost</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="5353" to="5360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Conjugate gradient methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="101" to="134" />
		</imprint>
	</monogr>
	<note>Numerical optimization</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Soft margins for adaboost</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Onoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="320" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multivariate process monitoring and fault diagnosis by multi-scale pca</title>
		<author>
			<persName><forename type="first">M</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemical Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1281" to="1293" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multiscale convolutional neural networks for fault diagnosis of wind turbine gearbox</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3196" to="3207" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
