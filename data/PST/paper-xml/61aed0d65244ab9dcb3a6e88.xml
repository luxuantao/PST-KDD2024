<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Augmentation-Free Self-Supervised Learning on Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-12-05">5 Dec 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Namkyeong</forename><surname>Lee</surname></persName>
							<email>namkyeong96@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Industrial and Systems Engineering</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junseok</forename><surname>Lee</surname></persName>
							<email>junseoklee@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Industrial and Systems Engineering</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
							<email>cy.park@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Industrial and Systems Engineering</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Artificial Intelligence</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Augmentation-Free Self-Supervised Learning on Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-12-05">5 Dec 2021</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2112.02472v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Inspired by the recent success of self-supervised methods applied on images, self-supervised learning on graph structured data has seen rapid growth especially centered on augmentation-based contrastive methods. However, we argue that without carefully designed augmentation techniques, augmentations on graphs may behave arbitrarily in that the underlying semantics of graphs can drastically change. As a consequence, the performance of existing augmentationbased methods is highly dependent on the choice of augmentation scheme, i.e., hyperparameters associated with augmentations. In this paper, we propose a novel augmentation-free self-supervised learning framework for graphs, named AF-GRL. Specifically, we generate an alternative view of a graph by discovering nodes that share the local structural information and the global semantics with the graph. Extensive experiments towards various node-level tasks, i.e., node classification, clustering, and similarity search on various realworld datasets demonstrate the superiority of AFGRL. The source code for AFGRL is available at https://github.com/ Namkyeong/AFGRL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, self-supervised learning paradigm <ref type="bibr" target="#b19">(Liu et al. 2021)</ref>, which learns representation from supervision signals derived from the data itself without relying on human-provided labels, achieved great success in many domains including computer vision <ref type="bibr" target="#b8">(Gidaris, Singh, and Komodakis 2018;</ref><ref type="bibr" target="#b22">Noroozi and Favaro 2016)</ref>, signal processing <ref type="bibr" target="#b1">(Banville et al. 2021</ref><ref type="bibr" target="#b0">(Banville et al. , 2019))</ref>, and natural language processing <ref type="bibr" target="#b7">(Devlin et al. 2018;</ref><ref type="bibr" target="#b4">Brown et al. 2020</ref>). Specifically, contrastive methods, which are at the core of selfsupervised learning paradigm, aim to build effective representation by pulling semantically similar (positive) pairs together and pushing dissimilar (negative) pairs apart <ref type="bibr" target="#b12">(Hjelm et al. 2018;</ref><ref type="bibr" target="#b23">Oord, Li, and Vinyals 2018)</ref>, where two augmented versions of an image are considered as positives, and the remaining images are considered as negatives. Inspired by the success of the contrastive methods in computer vision applied on images, these methods have been recently adopted to graphs <ref type="bibr" target="#b38">(Xie et al. 2021)</ref>. Although self-supervised contrastive methods have been shown to be effective on various graph-related tasks, they pay little attention to the inherent distinction between images and graphs: while augmentation is well defined on images, it may behave arbitrarily on graphs. For example, in the case of images, even after randomly cropping and rotating them, or distorting their color, their underlying semantic is hardly changed (Figure <ref type="figure" target="#fig_0">1</ref> (a)), and even if the semantic changes, humans can readily recognize the change visually, and choose an alternative augmentation approach that preserves the semantic. On the other hand, when we perturb (drop or add) edges/nodes, and their features of a graph, we cannot ascertain whether the augmented graph would be positively related to the original graph, and what is worse, it is non-trivial to verify the validity of the augmented graph since graphs are hard to visualize. For example, in molecular graphs, dropping a carbon atom from the phenyl ring of aspirin breaks the aromatic system and results in a alkene chain (Figure <ref type="figure" target="#fig_0">1(b)</ref>). Moreover, perturbing the connection of aspirin might introduce a molecule of totally different property, namely, five-membered lactone <ref type="bibr">(Sun et al. 2021a)</ref>. Likewise, in social graphs, randomly dropping edges might also lead to semantic changes, especially when these edges are related to hub nodes. For example, as shown in Figure <ref type="figure" target="#fig_0">1</ref>(c), if the edge between Bob and Alice is dropped, it would take much longer distance for Bob to reach Community 3 (i.e., from 2-hops to 5-hops), which also alters the relationship between Community 1 and Community 3. We argue that this is mainly because graphs contain not only the semantic but also the structural information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Cropping Color Distortion</head><p>Due to the aforementioned arbitrary behavior of augmentation on graphs, the quality of the learned graph representations of previous augmentation-based contrastive methods <ref type="bibr" target="#b10">(Hassani and Khasahmadi 2020;</ref><ref type="bibr" target="#b44">Zhu et al. 2020</ref><ref type="bibr" target="#b45">Zhu et al. , 2021;;</ref><ref type="bibr" target="#b34">Thakoor et al. 2021;</ref><ref type="bibr">Sun et al. 2021a;</ref><ref type="bibr" target="#b36">Veli?kovi? et al. 2018</ref>) is highly dependent on the choice of the augmentation scheme. More precisely, in order to augment graphs, these methods perform various augmentation techniques such as node/edge perturbation and node feature masking, and the amount by which the graphs are augmented is controlled by a set of hyperparameters. However, these hyperparameters should be carefully tuned according to which datasets, and which downstream tasks are used for the model evaluation, otherwise the model performance would vary greatly <ref type="bibr" target="#b39">(You et al. 2021)</ref>. Moreover, it is also shown that the performance on downstream tasks highly resort to which combinations of the augmentation techniques <ref type="bibr" target="#b40">(You et al. 2020;</ref><ref type="bibr">Sun et al. 2021a</ref>) are used.</p><p>Furthermore, even after discovering the best hyperparameters for augmentations, another limitation arises due to the inherent philosophy of contrastive learning. More precisely, inheriting the principle of instance discrimination <ref type="bibr" target="#b37">(Wu et al. 2018)</ref>, contrastive methods treat two samples as a positive pair as long as they are two augmented versions of the same instance, and all other pairs are treated as negatives. Although this approach is effective for learning representations of images <ref type="bibr" target="#b5">(Chen et al. 2020;</ref><ref type="bibr" target="#b11">He et al. 2020)</ref>, simply adopting it to graphs by treating all other nodes apart from the node itself as negatives overlooks the structural information of graphs, and thus cannot benefit from the relational inductive bias of graph-structured data <ref type="bibr" target="#b2">(Battaglia et al. 2018)</ref>. Lastly, due to the nature of contrastive methods, a large amount of negative samples is required for improving the performance on the downstream tasks, requiring high computational and memory costs, which is impractical in reality <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref>. Contribution. We propose a self-supervised learning framework for graphs, called Augmentation-Free Graph Representation Learning (AFGRL), which requires neither augmentation techniques nor negative samples for learning representations of graphs. Precisely, instead of creating two arbitrarily augmented views of a graph and expecting them to preserve the semantics of the original graph, we use the original graph per se as one view, and generate another view by discovering, for each node in the original graph, nodes that can serve as positive samples via k-nearest-neighbor (k-NN) search in the representation space. Then, given the two semantically related views, we aim to predict, for each node in the first view, the latent representations of its positive nodes in the second view. However, naively selecting positive samples based on k-NN search to generate an alternative view can still alter the semantics of the original graph.</p><p>Hence, we introduce a mechanism to filter out false positives from the samples discovered by k-NN search. In a nutshell, we consider a sample to be positive only if either 1) it is a neighboring node of the target node in the adjacency matrix (local perspective), capturing the relational inductive bias inherent in the graph-structured data, or 2) it belongs to the same cluster as the target node (global perspective).</p><p>Moreover, by adopting BYOL <ref type="bibr" target="#b9">(Grill et al. 2020)</ref> as the backbone of our model, negative samples are not required for the model training, thereby avoiding the "sampling bias" <ref type="bibr" target="#b18">(Lin et al. 2021)</ref>, i.e. the negative samples may have the same semantics with the query node, which would result in less effective representation <ref type="bibr" target="#b28">(Saunshi et al. 2019)</ref>.</p><p>Our extensive experiments demonstrate that AFGRL outperforms a wide range of state-of-the-art methods in terms of node classification, clustering and similarity search. We also demonstrate that compared with existing methods that heavily depend on the choice of hyperparameters, AFGRL is stable over hyperparameters. To the best of our knowledge, AF-GRL is the first work that learns representations of graphs without relying on manual augmentation techniques and negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contrastive Methods on Graphs. Recently, motivated by the great success of self-supervised methods on images, contrastive methods have been increasingly adopted to graphs. DGI <ref type="bibr" target="#b36">(Veli?kovi? et al. 2018)</ref>, a pioneering work highly inspired by Deep InfoMax <ref type="bibr" target="#b12">(Hjelm et al. 2018)</ref>, aims to learn node representations by maximizing the mutual information between the local patch of a graph. i.e., node, and the global summary of the graph, thereby capturing the global information of the graph that is overlooked by vanilla graph convolutional networks (GCNs) <ref type="bibr" target="#b17">(Kipf and Welling 2016;</ref><ref type="bibr" target="#b35">Veli?kovi? et al. 2017)</ref>. DGI is further improved by taking into account the mutual information regarding the edges <ref type="bibr" target="#b24">(Peng et al. 2020</ref>) and node attributes <ref type="bibr" target="#b15">(Jing, Park, and Tong 2021)</ref>. Inspired by SimCLR <ref type="bibr" target="#b5">(Chen et al. 2020)</ref>, GRACE <ref type="bibr" target="#b44">(Zhu et al. 2020)</ref> first creates two augmented views of a graph by randomly perturbing nodes/edges and their features. Then, it learns node representations by pulling together the representation of the same node in the two augmented graphs, while pushing apart representations of every other node. This principle <ref type="bibr" target="#b37">(Wu et al. 2018</ref>) has also been adopted for learning graph-level representations of graphs that can be used for graph classification, <ref type="bibr" target="#b30">(Sun et al. 2019;</ref><ref type="bibr" target="#b40">You et al. 2020;</ref><ref type="bibr" target="#b10">Hassani and Khasahmadi 2020)</ref>. Despite the success of contrastive methods on graphs, they are criticized for the problem raised by the "sampling bias" <ref type="bibr" target="#b3">(Bielak, Kajdanowicz, and Chawla 2021)</ref>. Moreover, these methods require a large amount of negative samples for the model training, which incurs high computational and memory costs <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>.</p><p>To address the sampling bias issue, BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021</ref>) learns node representations without using negative samples. It learns node representations by encoding two augmented versions of a graph using two separate encoders: one is trained through minimizing the cosine loss between the representations generated by the two encoders, while the other encoder is updated by an exponential moving average of the first encoder. Although the sampling bias has been addressed in this way, BGRL still requires augmentations on the original graph, which may lead to semantic drift <ref type="bibr">(Sun et al. 2021a</ref>) as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. On the other hand, our proposed method learns node representations without any use of negative samples or augmentations of graphs.</p><p>Augmentations on Graphs. Most recently, various augmentation techniques for graphs have been introduced. e.g., node dropping <ref type="bibr" target="#b40">(You et al. 2020)</ref>, edge modification <ref type="bibr" target="#b14">(Jin et al. 2021;</ref><ref type="bibr" target="#b27">Qiu et al. 2020;</ref><ref type="bibr" target="#b42">Zhao et al. 2020)</ref>, subgraph extraction <ref type="bibr" target="#b13">(Jiao et al. 2020;</ref><ref type="bibr">Sun et al. 2021b</ref>), attribute masking <ref type="bibr" target="#b44">(Zhu et al. 2020</ref><ref type="bibr" target="#b45">(Zhu et al. , 2021) )</ref> and others <ref type="bibr" target="#b10">(Hassani and Khasahmadi 2020;</ref><ref type="bibr" target="#b16">Kefato and Girdzijauskas 2021;</ref><ref type="bibr" target="#b33">Suresh et al. 2021)</ref>. GRACE <ref type="bibr" target="#b44">(Zhu et al. 2020</ref>) randomly drops edges and masks node features to generate two augmented views of a graph. GCA <ref type="bibr" target="#b45">(Zhu et al. 2021)</ref> further improves GRACE by introducing advanced adaptive augmentation techniques that take into account both structural and attribute information. However, due to the complex nature of graphs, the performance on downstream tasks is highly dependent on the selection of the augmentation scheme, as will be shown later in our experiments (Table <ref type="table" target="#tab_0">1</ref>). Moreover, previous work <ref type="bibr" target="#b40">(You et al. 2020;</ref><ref type="bibr">Sun et al. 2021a</ref>) have shown that there is no universally outperforming data augmentation scheme for graphs. Lastly, <ref type="bibr">Sun et al. (2021a)</ref> demonstrates that infusing domain knowledge is helpful in finding proper augmentations, which preserves biological assumption in molecular graph. However, domain knowledge is not always available in reality. In this work, we propose a general framework for generating an alternative view of the original graph without relying on existing augmentation techniques that may either 1) change the semantics of the original graph or 2) require domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement</head><p>Notations. Let G = (V, E) denote a graph, where V = {v 1 , ..., v N } represents the set of nodes, and E ? V ? V represents the set of edges. G is associated with a feature matrix X ? R N ?F , and an adjacency matrix</p><formula xml:id="formula_0">A ? R N ?N where A ij = 1 iff (v i , v j ) ? E and A ij = 0 otherwise.</formula><p>Task: Unsupervised Graph Representation Learning. Given a graph G along with X and A, we aim to learn a encoder f (?) that produces node embeddings H = f (X, A) ? R N ?D , where D &lt;&lt; F . In particular, our goal is to learn node embeddings that generalize well to various downstream tasks without using any class information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Preliminary: Bootstrap Your Own Latent</head><p>Before explaining details of our proposed method, we begin by introducing BYOL <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>, which is the backbone of our proposed framework. The core idea of BYOL is to learn representations of images without using negative samples <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>. Given two augmented views of an image, BYOL trains two separate encoders, i.e., online encoder f ? and target encoder f ? , and learns representations of images by maximizing the similarity of the two representations produced by each encoder. More formally, BYOL generates two views x 1 ? t(x), and x 2 ? t (x) of an image x given a set of transformations t ? T and t ? T , and these two generated views of an image are fed into the online and target encoders. Precisely, the online encoder f ? produces online representation h 1 = f ? (x 1 ), while the target encoder f ? produces target representation h 2 = f ? (x 2 ). Then, both online and target representations are projected to smaller representations z 1 = g ? (h 1 ) and z 2 = g ? (h 2 ) using projectors g ? and g ? , respectively. Finally, an additional predictor q ? is applied on top of the projected online representation, i.e., z 1 , to make the architecture asymmetric. The objective function is defined as L ?,? = q? (z 1 ) -z2</p><p>2 , where q? (z 1 ) and z2 denote l2normalized form of q ? (z 1 ) and z 2 , respectively. A symmetric loss L ?,? is obtained by feeding x 2 into the online encoder and x 1 into the target encoder, and the final objective is to minimize</p><formula xml:id="formula_1">L BYOL ?,? = L ?,? + L ?,? . At each training itera- tion, a stochastic optimization step is performed to minimize L BYOL ?,?</formula><p>with respect to ? only, while ? is updated using the exponential moving average (EMA) of ?, which is empirically shown to prevent the collapsing problem (Chen and He 2021). More formally, the parameters of BYOL are updated as ? ? optimizer ?,</p><formula xml:id="formula_2">? ? L BYOL ?,? , ? , ? ? ? ? + (1 -? )?,</formula><p>where ? is learning rate for online network, and ? ? [0, 1] is the decay rate that controls how close ? remains to ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Proposed Method</head><p>We first introduce how BYOL has been previously employed on graphs <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref>, and discuss about the several limitations of augmentation-based methods for graphs. Finally, we present our proposed method, called AFGRL. Generating Alternative Views via Augmentation. BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021</ref>) is a recently proposed fully non-contrastive method for learning node representations that does not leverage negative samples benefiting from the framework of BYOL <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>. Precisely, BGRL generates two different views of a graph via manual augmentations, i.e., node feature masking and edge masking as done by previous methods <ref type="bibr" target="#b44">(Zhu et al. 2020</ref><ref type="bibr" target="#b45">(Zhu et al. , 2021))</ref>, and the amount by which the graphs are augmented is controlled by a set of hyperparameters. Then, two encoders, i.e., online and target encoders, generate embeddings given the augmented views of a graph as inputs, and the two generated embeddings are learned to be close to each other. To prevent the representations from collapsing to trivial solutions, BGRL introduces a symmetry-breaking technique (refer to Section 4 for more detailed explanation). It is also worth noting that BGRL intentionally considers simple augmentation techniques to validate the benefit of fully non-contrastive scheme applied on graphs. Limitation of Augmentation-based Methods on Graphs. Although BGRL has been shown to be effective in a fully non-contrastive manner, i.e., without using negative samples, we observe that the quality of the learned node representations relies on the choice of the augmentation scheme.</p><p>In other words, performance on various downstream tasks evaluated based on the representations learned by BGRL varies greatly according to the choice of hyperparameters associated with augmentations, and the best hyperparameters are different for different datasets. This phenomenon becomes even clearer when stronger augmentations, such as diffusion <ref type="bibr" target="#b10">(Hassani and Khasahmadi 2020)</ref>, adaptive techniques <ref type="bibr" target="#b45">(Zhu et al. 2021</ref>) and the infusion of domain knowledge <ref type="bibr">(Sun et al. 2021a)</ref>  ? 100. The hyperparameters (i.e., probability of edge drop and node feature masking) are chosen within the range from 0.0 to 0.5 to prevent a significant distortion of graphs.</p><p>the performance of augmentation-based methods varies according to the hyperparameters associated with augmentations. More precisely, we report the relative performance of the best performing case compared to the worst performing case, i.e., -4.00% indicates that the worst case performs 4% worse than the best case. We observe that the performance in both tasks is sensitive to the hyperparameters, and that it aggravates when a stronger augmentation technique is employed, i.e., GCA, in which case the role of augmentation becomes even more important. Thus, we need a more stable and general framework for generating an alternative view of the original graph without relying on augmentation techniques introduced in existing works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Augmentation-Free GRL (AFGRL)</head><p>We propose a simple yet effective self-supervised learning framework for generating an alternative view of the original graph taking into account the relational inductive bias of graph-structured data, and the global semantics of graphs. For each node v i ? V in graph G, we discover nodes that can serve as positive samples based on the node representations learned by the two encoders. i.e., online encoder f ? (?) and target encoder f ? (?) 1 . More precisely, these encoders 1 AFGRL adopts the architecture of BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref>, which is slightly modified from BYOL <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>. In initially receive the adjacency matrix A and the feature matrix X of the original graph as inputs, and compute the online and target representations. i.e., H ? = f ? (X, A) and H ? = f ? (X, A) whose i-th rows, h ? i and h ? i , are representations for node v i ? V. Then, for a given query node v i ? V, we compute the cosine similarity between all other nodes in the graph as follows:</p><formula xml:id="formula_3">sim(v i , v j ) = h ? i ? h ? j h ? i h ? j , ?v j ? V (1)</formula><p>where the similarity is computed between the online and the target representations. Given the similarity information, we search for k-nearest-neighbors for each node v i , and denote them by a set B i , which can serve as positive samples for node v i . Essentially, we expect the nearest neighbors in the representation space to belong to the same semantic class as the query node, i.e., v i in this case. Although B i can serve as a reasonable set of positive candidates for node v i , 1) it is inherently noisy as we do not leverage any label information, i.e., B i contains samples that are not semantically related to the query node v i . Moreover, only resorting to the nearest neighbors in the representation space may not only overlook 2) the structural information inherent in the graph, i.e., relational inductive bias, but also 3) the global semantics of the graph. To address these limitations, we introduce a mechanism to filter out false positives from the samples discovered by k-NN search, while also capturing the local structural information and the global semantics of graphs.</p><p>Capturing Local Structural Information. Recall that we expected the nearest neighbors found by k-NN search, i.e., B i , to share the same class label as the query node v i . To verify whether our expectation holds, we perform analysis on two datasets, i.e., Amazon Computers and WikiCS datasets as shown in Figure <ref type="figure">3</ref>. First, we obtain node embeddings from a randomly initialized 2-layer GCN (Kipf and Welling 2016), i.e., H Rand-GCN = Rand-GCN(X, A), and perform k-NN search for each node given the node embeddings H Rand-GCN . Then, for each node, we compute the ratio Figure <ref type="figure">3</ref>: Analysis on the ratio of its neighboring nodes being the same label as the query node across different ks. of its neighboring nodes being the same label as the query node. In Figure <ref type="figure">3</ref>, we observe that although the ratio is high when considering only a small number of neighbors, e.g., k = 4, the ratio decreases as k gets larger in both datasets. This implies that although our expectation holds to some extent, there still exists noise. Hence, to filter out false positives from the nearest neighbors found by k-NN search, i.e., B i for each node v i , we leverage the local structural information among nodes given in the form of an adjacency matrix. i.e., relational inductive bias. More precisely, for a node v i , its adjacent nodes N i tend to share the same label as the query node v i , i.e., smoothness assumption <ref type="bibr" target="#b43">(Zhu, Ghahramani, and Lafferty 2003)</ref>. In Figure <ref type="figure">3</ref>, we indeed observe that the ratio of the adjacent nodes being the same label as the query node ("Adj") is about 70% in both datasets, which demonstrates the validity of the smoothness assumption. Therefore, to capture the relational inductive bias reflected in the smoothness assumption, while filtering out false positives from noisy nearest neighbors, we compute the intersection between the nearest neighbors and adjacent nodes, i.e., B i ? N i . We denote the set of these intersecting nodes as local positives of v i . Indeed, Figure <ref type="figure">3</ref> shows that the local positives ("Rand. GCN + Adj") consistently maintain high correct ratio even when k increases. Capturing Global Semantics. To capture the semantics of nodes in a global perspective, we leverage clustering techniques. The intuition is to discover non-adjacent nodes that share the global semantic information with the query node. For example, in an academic collaboration network whose nodes denote authors and edges denote collaboration between authors, even though two authors work on the same research topic (i.e., same label), they may not be connected in the graph since they neither collaborated in the past nor share any collaborators. We argue that such semantically similar entities that do not share an edge can be discovered via clustering in a global perspective. In this regard, we apply K-means clustering algorithm on the target representation H ? to cluster nodes into a set of K clusters, i.e. G = {G 1 , G 2 , ..., G K }, and c(h ? i ) ? {1, ..., K} denotes the cluster assignment of h ? i , i.e., v i ? G c(h ? i ) . Then, we consider the set of nodes that belong to the same cluster as v i , i.e., C i = {v j |v j ? G c(h ? i ) }, as its semantically similar nodes in the global perspective. Finally, we obtain the intersection between the nearest neighbors and the semantically similar nodes in the global perspective, i.e., B i ? C i , and we denote the set of these intersecting nodes as global positives of v i . In other words, nodes that are among the nearest neighbors of v i and at the same time belong to the same cluster as v i are considered as globally positive neighbors. It is important to note that as K-means clustering algorithm is sensitive to the cluster centroid initialization, we perform multiple runs to ensure robustness of the clustering results. Specifically, we perform K-means clustering M times and obtain M sets of clusters, i.e., {G (j) } M j=1 , where</p><formula xml:id="formula_4">G (j) = G (j) 1 , G (j) 2 , ..., G (j) K</formula><p>is the result of j-th run of the clustering. Then, we define</p><formula xml:id="formula_5">C i = M j=1 G (j) c (j) (h ? i )</formula><p>, where c (j) (h ? i ) ? {1, ..., K} denotes the cluster assignment of h ? i in the j-th run of clustering.</p><p>Objective Function. In order to consider both the local and global information, we define the set of real positives for node v i as follows:</p><formula xml:id="formula_6">P i = (B i ? N i ) ? (B i ? C i )<label>(2)</label></formula><p>Our objective function aims to minimize the cosine distance between the query node v i and its real positives P i :</p><formula xml:id="formula_7">L ?,? = - 1 N N i=1 vj ?Pi z ? i h ? j z ? i h ? j ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_8">z ? i = q ? (h ? i ) ? R D</formula><p>is the prediction of the online embedding h ? i ? R D , and q ? (?) is the predictor network. Following BYOL, AFGRL's online network is updated based on the gradient of its parameters with respect to the loss function (Equation <ref type="formula" target="#formula_7">3</ref>), while the target network is updated by smoothing the online network. We also symmetrize the loss function. In the end, the online embeddings, i.e., H ? ? R N ?D are used for downstream tasks. Figure <ref type="figure" target="#fig_1">4</ref> illustrates the overview of obtaining real positives of node v i .</p><p>In summary, 1) AFGRL does not rely on arbitrary augmentation techniques for the model training, thereby achieving stable performance. 2) AFGRL filters out false positives from the samples discovered by k-NN search, while also capturing the local structural information, i.e., relational inductive bias, and the global semantics of graphs. 3) AF-GRL does not require negative samples for the model training, thereby avoiding sampling bias and alleviating computational/memory costs suffered by previous contrastive methods. Compared. We primarily compare AF-GRL against GRACE <ref type="bibr" target="#b44">(Zhu et al. 2020)</ref>, BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref> and GCA <ref type="bibr" target="#b45">(Zhu et al. 2021)</ref>, which are the current state-of-the-art self-supervised methods for learning representations of nodes in a graph. For all baselines but BGRL, we use the official code published by the authors. As the official code for BGRL is not available, we implement it by ourselves, and try our best to reflect the details provided in the original paper <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref>. We also report previously published results of other representative methods, such as DeepWalk <ref type="bibr" target="#b26">(Perozzi, Al-Rfou, and Skiena 2014)</ref>, DGI <ref type="bibr" target="#b36">(Veli?kovi? et al. 2018)</ref>, GMI <ref type="bibr" target="#b24">(Peng et al. 2020)</ref>, and MVGRL <ref type="bibr" target="#b10">(Hassani and Khasahmadi 2020)</ref>, as done in <ref type="bibr" target="#b34">(Thakoor et al. 2021;</ref><ref type="bibr" target="#b45">Zhu et al. 2021)</ref>.</p><p>Evaluation protocol. We evaluate AFGRL on three nodelevel tasks, i.e., node classification, node clustering and node similarity search. We first train all models in an unsupervised manner. For node classification, we use the learned embeddings to train and test a simple logistic regression classifier <ref type="bibr" target="#b36">(Veli?kovi? et al. 2018)</ref>. We report the test performance when the performance on validation data gives the best result. For node clustering and similarity search, we perform evaluations on the learned embeddings at every epoch and report the best performance.</p><p>Implementation details. We use a GCN <ref type="bibr" target="#b17">(Kipf and Welling 2016</ref>) model as the encoders, i.e., f ? (?) and f ? (?). More formally, the encoder architecture is defined as:</p><formula xml:id="formula_9">H (l) = GCN (l) (X, A) = ?( D-1/2 ? D-1/2 XW (l) ), (4)</formula><p>where H (l) is the node embedding matrix of the l-th layer for l ? [1, ..., L], ? = A + I is the adjacency matrix with selfloops, D = i ?i is the degree matrix, ?(?) is a nonlinear activation function such as ReLU, and W (l) is the trainable weight matrix for the l-th layer. We perform grid-search on several hyperparameters, such as learning rate ?, decay rate ? , node embedding dimension size D, number of layers of GCN encoder L, for fair comparisons.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance Analysis</head><p>Overall evaluation. Table <ref type="table">2</ref> shows the node classification performance of various methods. We have the following observations: 1) Our augmentation-free AFGRL generally performs well on all datasets compared with augmentationbased methods, i.e., GRACE, GCA and BGRL, whose reported results are obtained by carefully tuning the augmentation hyperparameters. Recall that in Table <ref type="table" target="#tab_0">1</ref> we demonstrated that their performance is highly sensitive to the choice of augmentation hyperparameters. This verifies the benefit of our augmentation-free approach. 2) We also evaluate AFGRL on node clustering (Table <ref type="table" target="#tab_3">3</ref>) and similarity search (Table <ref type="table" target="#tab_4">4</ref>). Note that the best hyperparameters for node classification task were adopted. Table <ref type="table" target="#tab_3">3</ref> shows that AFGRL generally outperforms other methods in node clustering task. We argue that this is mainly because AF-GRL also considers global semantic information unlike the compared methods.</p><p>3) It is worth noting that methods built upon instance discrimination principle <ref type="bibr" target="#b37">(Wu et al. 2018)</ref>, i.e., GRACE and GCA, are not only memory consuming (OOM on large datasets), but also generally perform worse than their counterparts on various tasks (especially on clustering). This indicates that instance discrimination, which treats all other nodes except itself as negatives without considering the graph structural information, is not appropriate for graph-structured data, especially for clustering in which the global structural information is crucial. 4) AFGRL generally performs well on node similarity search (Table <ref type="table" target="#tab_4">4</ref>). This is expected because AFGRL aims to make nearest neighbors of each node share the same label with the query node by discovering the local and the global positives.</p><formula xml:id="formula_10">(Global) (Local) (Global) (Local) (Local+Global) (Local+Global)</formula><p>6: Ablation study on AFGRL.</p><p>Ablation Studies. To verify the benefit of each component of AFGRL, we conduct ablation studies on two datasets that exhibit distinct characteristics, i.e., Amazon Computers (E-commerce network) and WikiCS (Reference network).</p><p>In Figure <ref type="figure">6</ref>, we observe that considering both local structural and global semantic information shows the best performance. Moreover, we observe that the global semantic information is more beneficial than the local structural information. This can be explained by the performance of "k-NN only" variant, which performs on par with "k-NN + Adj" variant. That is, we conjecture that performing k-NN on the node representations learned by our framework can capture sufficient local structural information contained in the adjacency matrix. Based on the ablation studies, we argue that AFGRL still gives competitive performance even when the adjacency matrix is sparse, which shows the practicality of our proposed framework. Finally, the low performance of "Clus-only" variant implies the importance of considering the local structural information in graph-structured data. Hyperparameter Analysis. Figure <ref type="figure">5</ref> shows the sensitivity analysis on the hyperparameters k and M of AFGRL. We observe that k = 4 and M &gt; 1 generally give the best performance, while the performance is rather stable over various M s. This verifies that our augmentation-free approach can be easily trained compared with other augmentationbased methods, i.e., stable over hyperparameters, while outperforming them in most cases. Moreover, in Figure <ref type="figure" target="#fig_2">7</ref>, we conduct experiments across various sizes of node embedding dimension D. We observe that AFGRL benefits from high-dimensional embeddings, while other methods rapidly saturate when the dimension of embeddings increase. Note that <ref type="bibr" target="#b41">Zbontar et al. (2021)</ref> recently showed similar results indicating that methods based on instance discrimination <ref type="bibr" target="#b37">(Wu et al. 2018</ref>) is prone to the curse of dimensionality.</p><p>Sampled Sampled Each point represents a node, and the color represents the node label. We observe that node embeddings generated by both methods are grouped together according to their corresponding node labels. However, the major difference is that AFGRL captures more fine-grained class information compared with GCA. That is, for AFGRL, there tend to be small clusters within each label group. To emphasize this, we sample the same set of nodes from each label, and compare their embeddings (Figure <ref type="figure" target="#fig_3">8</ref> bottom). We clearly observe that nodes are more tightly grouped in AFGRL compared with GCA, which implies that AFGRL captures more finegrained class information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Compared methods</head><p>In this section, we explain methods that are compared with AF-GRL in the experiments, and we summarize their properties in Table 6.</p><p>? DGI <ref type="bibr" target="#b36">(Veli?kovi? et al. 2018</ref>): A pioneering work for selfsupervised graph representation learning, which is motivated by Deep InfoMax <ref type="bibr" target="#b12">(Hjelm et al. 2018)</ref>. DGI aims to learn node representations by maximizing the mutual information between the node and global summary vector of the graph. ? GMI <ref type="bibr" target="#b24">(Peng et al. 2020</ref>): An advanced version of DGI that learns node representations by leveraging more fine-grained information, i.e. subgraph. Specifically, GMI proposes to directly measure the mutual information between input and node/edge representations within one-hop neighbor, without explicit data augmentation. ? MVGRL (Hassani and Khasahmadi 2020): It constructs views of a graph with diffusion kernel and subgraph sampling. Then, it learns to contrast node representations with global summary vector across the two views.</p><p>? GRACE <ref type="bibr" target="#b44">(Zhu et al. 2020)</ref>. Inspired by SimCLR <ref type="bibr" target="#b5">(Chen et al. 2020)</ref>, it first creates two augmented views of a graph by randomly perturbing nodes/edges and their features. Then, following the principle of instance discrimination, it learns node representations by contrasting it with all other nodes in the two augmented graphs, while matching with the same node from the two augmented graphs. ? GCA <ref type="bibr" target="#b45">(Zhu et al. 2021</ref>): An advanced version of GRACE, which proposes multiple augmentation schemes regarding the importance of nodes, edges and their features. The main idea is to selectively augment a graph by keeping important parts of the graph intact, while augmenting unimportant parts. ? BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021</ref>): Inspired by BYOL <ref type="bibr" target="#b9">(Grill et al. 2020)</ref>, it learns node representations without using negative samples. As conventional contrastive methods, BGRL leverages siamese structured network with augmentation scheme. However, even without relying on negative samples, BGRL prevents a trivial solution through asymmetric model architecture and stop gradient operations.</p><p>No Augmentation No Negative Sampling DGI GMI MVGRL GRACE GCA BGRL AFGRL Table <ref type="table">6</ref>: Properties of methods that are compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Implementation details</head><p>As described in Section 6.1 of the submitted manuscript, we use GCN <ref type="bibr" target="#b17">(Kipf and Welling 2016)</ref> encoders. The base encoder of AF-GRL is a GCN model followed by batch normalization and nonlinearity. Following BGRL <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref>, the predictor q ? of AFGRL is defined as a multi-layer perceptron (MLP) with batch normalization. Note that since a single-layer GCN (i.e., GCN with L = 1) works the best for AFGRL, the hidden size of f ? is not defined. i.e., there is no hidden layer. For GCA and BGRL, we adopt the best hyperparameter specifications that are reported in their original paper, that is, Table <ref type="table" target="#tab_5">5</ref> of <ref type="bibr" target="#b45">(Zhu et al. 2021)</ref> for GCA, and Table <ref type="table" target="#tab_5">5</ref> of <ref type="bibr" target="#b34">(Thakoor et al. 2021)</ref> for BGRL. For GRACE, since the original paper <ref type="bibr" target="#b44">(Zhu et al. 2020)</ref> did not evaluate on the datasets used in our experiments, we follow the best hyperparameter specifications that are reported in the GCA paper <ref type="bibr" target="#b45">(Zhu et al. 2021)</ref>, since GRACE is equivalent to the GCA-T-A ablation of GCA, which is also proposed by the same authors. Refer to Table <ref type="table">7</ref> for more detailed hyperparameter specifications of AFGRL.</p><p>It is important to note that AFGRL does not have hyperparameters associated with graph augmentation, whose best performing combinations is non-trivial to find<ref type="foot" target="#foot_0">2</ref> . Instead, AFGRL newly introduced several hyperparameters, i.e., k, K, and M . However, we observe that the model performance is stable over these hyperparameters as shown in Figure <ref type="figure">5</ref> of the submitted manuscript and Figure <ref type="figure">2</ref> of this supplementaty material. Hence, we fixed K to 100, M to 5, and selected k ? {4, 8}. This demonstrates the practicality of AFGRL.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Augmentations on images ((a)) keep the underlying semantics, whereas augmentations on graphs ((b),(c)) may unexpectedly change the semantics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An overview of obtaining real positives of node v i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Effect of embedding dimension size (D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8</head><label>8</label><figDesc>Figure 8: t-SNE embeddings of nodes in Photo dataset. Visualization of embeddings. To provide a more intuitive understanding of the learned node embeddings, we visualize node embeddings of GCA (Figure 8(a)) and AFGRL (Figure 8(b)) by using t-SNE (Van der Maaten and Hinton 2008).Each point represents a node, and the color represents the node label. We observe that node embeddings generated by both methods are grouped together according to their corresponding node labels. However, the major difference is that AFGRL captures more fine-grained class information compared with GCA. That is, for AFGRL, there tend to be small clusters within each label group. To emphasize this, we sample the same set of nodes from each label, and compare their embeddings (Figure8bottom). We clearly observe that nodes are more tightly grouped in AFGRL compared with GCA, which implies that AFGRL captures more finegrained class information.</figDesc><graphic url="image-18.png" coords="7,337.26,211.71,200.17,79.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>are applied. Table1shows how Figure2: The overall architecture of AFGRL. Given a graph, f ? and f ? generate node embeddings H ? and H ? both of which are used to obtain k-NNs for node v i , i.e., B i . Combining it with N i , we obtain local positives, i.e., B i ? N i . To obtain global positives for node v i , K-means clustering is performed on H ? , and the result C i is combined with B i , i.e., B i ? C i . Finally, we combine local and global positives to obtain real positives, i.e., P i . A predictor q ? projects H ? to Z ? , which is used to compute the final loss along with H ? . Note that f ? is updated via gradient descent of the loss, whereas f ? is updated via EMA of f ? .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(?? ?? , ??)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(?? ?? , ??)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>?? ??</cell><cell></cell></row><row><cell></cell><cell>(??, ??)</cell><cell>?? ??</cell><cell></cell><cell>?? ?? ??</cell><cell></cell><cell>Adj.</cell><cell>(?? ?? )</cell><cell>Local (?? ?? ? ?? ?? )</cell><cell>?? ?? ??</cell></row><row><cell></cell><cell>?? ??</cell><cell cols="2">EMA</cell><cell>(?? ?? , ??)</cell><cell></cell><cell cols="2">??-NN(?? ?? )</cell><cell>?? ??</cell></row><row><cell></cell><cell></cell><cell>?? ??</cell><cell></cell><cell>?? ?? ?</cell><cell>?? ?? ?</cell><cell cols="3">Global (?? ?? ? ?? ?? ) Stop-Gradient K-means (?? ?? )</cell><cell>-</cell><cell>1 ??</cell><cell>? ?? = 1 ??</cell><cell>? ?? ? ????</cell><cell>?? i ?? ?? ?? ? ? ? ? ?? i ?? ? ? ?? i ?? ?? ?? ?</cell></row><row><cell></cell><cell>Comp.</cell><cell>Photo</cell><cell>CS</cell><cell>Physics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Node</cell><cell>BGRL -4.00%</cell><cell>-1.06%</cell><cell cols="2">-0.20% -0.69%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Classi.</cell><cell>GCA -19.18%</cell><cell>-5.48%</cell><cell>-0.27%</cell><cell>OOM</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Node</cell><cell cols="4">BGRL -11.57% -13.30% -0.78% -6.46%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Clust.</cell><cell cols="3">GCA -26.28% -23.27% -1.64%</cell><cell>OOM</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p>Performance sensitivity according to the hyperparameters for augmentations (i.e., edge drop and node feature masking) on node classification and clustering. Each value indicates the relative performance difference between the best vs. worst performing cases, i.e. -</p>(best-worst)   </p>best</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? 0.12 86.51 ? 0.54 92.42 ? 0.22 93.03 ? 0.31 95.65 ? 0.16 Raw feats. 71.98 ? 0.00 73.81 ? 0.00 78.53 ? 0.00 90.37 ? 0.00 93.58 ? 0.00 node2vec 71.79 ? 0.05 84.39 ? 0.08 89.67 ? 0.12 85.08 ? 0.03 91.19 ? 0.04 DeepWalk 74.35 ? 0.06 85.68 ? 0.06 89.44 ? 0.11 84.61 ? 0.22 91.77 ? 0.15 DW + feats. 77.21 ? 0.03 86.28 ? 0.07 90.05 ? 0.08 87.70 ? 0.04 94.90 ? 0.09 DGI 75.35 ? 0.14 83.95 ? 0.47 91.61 ? 0.22 92.15 ? 0.63 94.51 ? 0.52 GMI 74.85 ? 0.08 82.21 ? 0.31 90.68 ? 0.17 OOM OOM MVGRL 77.52 ? 0.08 87.52 ? 0.11 91.74 ? 0.07 92.11 ? 0.12 95.33 ? 0.</figDesc><table><row><cell></cell><cell>WikiCS</cell><cell>Computers</cell><cell>Photo</cell><cell>Co.CS</cell><cell>Co.Physics</cell></row><row><cell>Sup. GCN</cell><cell cols="5">77.19 03</cell></row><row><cell>GRACE</cell><cell cols="4">77.97 ? 0.63 86.50 ? 0.33 92.46 ? 0.18 92.17 ? 0.04</cell><cell>OOM</cell></row><row><cell>GCA</cell><cell cols="4">77.94 ? 0.67 87.32 ? 0.50 92.39 ? 0.33 92.84 ? 0.15</cell><cell>OOM</cell></row><row><cell>BGRL</cell><cell cols="5">76.86 ? 0.74 89.69 ? 0.37 93.07 ? 0.38 92.59 ? 0.14 95.48 ? 0.08</cell></row><row><cell>AFGRL</cell><cell cols="5">77.62 ? 0.49 89.88 ? 0.33 93.22 ? 0.28 93.27 ? 0.17 95.69 ? 0.10</cell></row><row><cell cols="6">Table 2: Performance on node classification (OOM: Out of memory on 24GB RTX3090).</cell><cell>Figure 5: Sensitivity analysis.</cell></row><row><cell></cell><cell cols="2">6 Experiments</cell><cell></cell><cell></cell></row><row><cell cols="2">6.1 Experimental Setup</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Datasets. To evaluate AFGRL, we conduct experiments</cell><cell></cell></row><row><cell cols="4">on five widely used datasets, including WikiCS, Amazon-</cell><cell></cell></row><row><cell cols="4">Computers (Computers), Amazon-Photo (Photo), Coauthor-</cell><cell></cell></row><row><cell cols="4">CS (Co.CS), and Coauthor-Physics (Co.Physics).</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance on node clustering in terms of NMI and homogeneity.</figDesc><table><row><cell></cell><cell></cell><cell>GRACE</cell><cell>GCA</cell><cell cols="2">BGRL AFGRL</cell></row><row><cell>WikiCS</cell><cell cols="2">Sim@5 Sim@10 0.7645 0.7754</cell><cell cols="2">0.7786 0.7739 0.7673 0.7617</cell><cell>0.7811 0.7660</cell></row><row><cell>Computers</cell><cell cols="2">Sim@5 Sim@10 0.8643 0.8738</cell><cell cols="2">0.8826 0.8947 0.8742 0.8855</cell><cell>0.8966 0.8890</cell></row><row><cell>Photo</cell><cell cols="2">Sim@5 Sim@10 0.9106 0.9155</cell><cell cols="2">0.9112 0.9245 0.9052 0.9195</cell><cell>0.9236 0.9173</cell></row><row><cell>Co.CS</cell><cell cols="2">Sim@5 Sim@10 0.9059 0.9104</cell><cell cols="2">0.9126 0.9112 0.9100 0.9086</cell><cell>0.9180 0.9142</cell></row><row><cell>Co.Physics</cell><cell>Sim@5 Sim@10</cell><cell>OOM OOM</cell><cell>OOM OOM</cell><cell>0.9504 0.9464</cell><cell>0.9525 0.9486</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance on similarity search. (Sim@n: Average ratio among n nearest neighbors sharing the same label as the query node.)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>We evaluated the performance of AFGRL on node-level tasks, i.e., node classification, node clustering, and node similarity search. We conduct experiments on five widely used datasets, including Wiki-CS, Amazon-Computers, Amazon-Photo, Coauthor-CS, and Coauthor-Physics. The detailed statistics are summarized in Table 5.? WikiCS (Mernyei and Cangea 2020) is reference network constructed from Wikipedia references. Nodes denote articles about computer science, and edges denote hyperlinks between the articles. Articles are labeled with 10 related subfields, and their features are average of Glove<ref type="bibr" target="#b25">(Pennington, Socher, and Manning 2014)</ref> embeddings of all words in the article. ? Amazon-Computers and Amazon-Photo<ref type="bibr" target="#b20">(McAuley et al. 2015)</ref> are two networks of co-purchase relationships constructed from Amazon. Nodes denote products, and edges exist between nodes if the products are frequently co-purchased. In each dataset, products are labeled with 10 and 8 classes, respectively, based on product category, and the node feature is a bag-of-words representation of words in the product review. ? Coauthor-CS and Coauthor-Physics<ref type="bibr" target="#b29">(Sinha et al. 2015)</ref> are two academic networks containing co-authorship relationship based on Microsoft Academic Graph. Nodes in these graphs denote authors, and edges denote co-authored relationship. In each dataset, authors are classified into 15 and 5 classes, respectively, based on the author's research field, and the node feature is a bag-of-words representation of the paper keywords. For WikiCS dataset, which provides 20 canonical train/valid/test splits, we directly used the given splits. For Amazon and Coauthor datasets, we randomly split nodes 20 times into train/valid/test (10/10/80) as these datasets do not provide standard splits. Statistics for datasets used in this paper.</figDesc><table><row><cell>this paper, we propose a self-supervised learning frame-</cell></row><row><cell>work for graphs, which requires neither augmentation tech-</cell></row><row><cell>niques nor negative samples for learning representations of</cell></row><row><cell>graphs. Instead of creating two arbitrarily augmented views</cell></row><row><cell>of a graph and expecting them to preserve the semantics of</cell></row><row><cell>the original graph, AFGRL discovers nodes that can serve</cell></row><row><cell>as positive samples by considering the local structural in-</cell></row><row><cell>formation and the global semantics of graphs. The major</cell></row><row><cell>benefit of AFGRL over other self-supervised methods on</cell></row><row><cell>graphs is its stability over hyperparameters while maintain-</cell></row><row><cell>ing competitive performance even without using negative</cell></row><row><cell>samples for the model training, which makes AFGRL prac-</cell></row><row><cell>tical. Through experiments on multiple graphs on various</cell></row><row><cell>downstream tasks, we empirically show that AFGRL is su-</cell></row><row><cell>perior to the state-of-the-art methods that are sensitive to</cell></row><row><cell>augmentation hyperparameters.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>The values of the best performing hyperparameters (i.e., p f,1 , p f,2 , pe,1, and pe,2) vary greatly in range from 0.1 to 0.5. Refer to Table5of<ref type="bibr" target="#b45">(Zhu et al. 2021;</ref><ref type="bibr" target="#b34">Thakoor et al. 2021)</ref> </p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">8</ref> shows the github links to the source codes we used for evaluation. All the compared methods but BGRL were publicly available, and thus we implemented BGRL using PyTorch on our framework.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Self-supervised representation learning from electroencephalography signals</title>
		<author>
			<persName><forename type="first">H</forename><surname>Banville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-A</forename><surname>Engemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MLSP</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2019">2019</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Uncovering the structure of clinical EEG signals with self-supervised learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Banville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chehab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-A</forename><surname>Engemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neural Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46020</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Graph Barlow Twins: A self-supervised representation learning framework for graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bielak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kajdanowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02466</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<title level="m">Language models are few-shot learners</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<meeting><address><addrLine>Bert</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<title level="m">Bootstrap your own latent: A new approach to selfsupervised learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Contrastive multi-view representation learning on graphs</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Khasahmadi</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4116" to="4126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06670</idno>
		<title level="m">Learning deep representations by mutual information estimation and maximization</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sub-graph contrast for scalable self-supervised graph representation learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="222" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.05682</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hdmi: High-order deep multiplex infomax</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2414" to="2424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Self-supervised Graph Neural Networks without explicit negative sampling</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">T</forename><surname>Kefato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Girdzijauskas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14958</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09645</idno>
		<title level="m">Prototypical Graph Contrastive Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-supervised learning: Generative or contrastive</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Mernyei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cangea</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02901</idno>
		<title level="m">Wiki-cs: A wikipediabased benchmark for graph neural networks</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V D</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Graph representation learning via graphical mutual information maximization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="259" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gcc: Graph contrastive coding for graph neural network pre-training</title>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1150" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Khandeparkar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5628" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">An overview of microsoft academic service (mas) and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization</title>
		<author>
			<persName><forename type="first">F.-Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.01000</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04509</idno>
		<title level="m">MoCL: Contrastive Learning on Molecular Graphs with Multi-level Domain Knowledge</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">SUGAR: Subgraph neural network with reinforcement pooling and self-supervised mutual information mechanism</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="2081" to="2091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05819</idno>
		<title level="m">Adversarial Graph Augmentation to Improve Graph Contrastive Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thakoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06514</idno>
	</analytic>
	<monogr>
		<title level="m">Bootstrapped representation learning on graphs</title>
		<imprint>
			<date type="published" when="2008">2021. 2008</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Van der</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Graph attention networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10341</idno>
		<title level="m">Deep graph infomax</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Selfsupervised learning of graph neural networks: A unified review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.10757</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07594</idno>
		<title level="m">Graph Contrastive Learning Automated</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with augmentations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5812" to="5823" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Barlow twins: Self-supervised learning via redundancy reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deny</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03230</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Woodford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06830</idno>
		<title level="m">Data augmentation for graph neural networks</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semisupervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="912" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04131</idno>
		<title level="m">Deep graph contrastive representation learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Graph contrastive learning with adaptive augmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WWW</publisher>
			<biblScope unit="page" from="2069" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
