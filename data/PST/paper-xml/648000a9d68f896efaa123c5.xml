<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs</title>
				<funder ref="#_Nfumnha">
					<orgName type="full">NSF of China for Distinguished Young Scholars</orgName>
				</funder>
				<funder ref="#_8XMmnd2 #_HVEusGz">
					<orgName type="full">Technology and Innovation Major Project of the Ministry of Science and Technology of China</orgName>
				</funder>
				<funder ref="#_AA7aguj">
					<orgName type="full">NSF of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-06-06">6 Jun 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tinglin</forename><surname>Huang</surname></persName>
							<email>tinglin.huang@yale.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
							<email>yuxiaod@tsinghua.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Rex</forename><surname>Ying</surname></persName>
							<email>rex.ying@yale.edu</email>
						</author>
						<author>
							<persName><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yangliao</forename><surname>Geng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="department">KDD &apos;23</orgName>
								<address>
									<addrLine>August 6-10</addrLine>
									<postCode>2023</postCode>
									<settlement>Long Beach</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-06-06">6 Jun 2023</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3580305.3599263</idno>
					<idno type="arXiv">arXiv:2306.03355v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Mini-Batch Sampling</term>
					<term>Global Hard Negatives</term>
					<term>Contrastive Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In-Batch contrastive learning is a state-of-the-art self-supervised method that brings semantically-similar instances close while pushing dissimilar instances apart within a mini-batch. Its key to success is the negative sharing strategy, in which every instance serves as a negative for the others within the mini-batch. Recent studies aim to improve performance by sampling hard negatives within the current mini-batch, whose quality is bounded by the mini-batch itself. In this work, we propose to improve contrastive learning by sampling mini-batches from the input data. We present BatchSampler 1 to sample mini-batches of hard-to-distinguish (i.e., hard and true negatives to each other) instances. To make each mini-batch have fewer false negatives, we design the proximity graph of randomly-selected instances. To form the mini-batch, we leverage random walk with restart on the proximity graph to help sample hard-to-distinguish instances. BatchSampler is a simple and general technique that can be directly plugged into existing contrastive learning models in vision, language, and graphs. Extensive experiments on datasets of three modalities show that BatchSampler can consistently improve the performance of powerful contrastive models, as shown by significant improvements of SimCLR on ImageNet-100, SimCSE on STS (language), and GraphCL and MVGRL on graph datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Contrastive learning <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35]</ref> is one of the dominant strategies for self-supervised representation learning across various data domains, such as MoCo <ref type="bibr" target="#b19">[20]</ref> and SimCLR <ref type="bibr" target="#b9">[10]</ref> in computer vision, SimCSE <ref type="bibr" target="#b15">[16]</ref> in natural language processing, and GraphCL <ref type="bibr" target="#b58">[59]</ref> in graph representation learning. The essence of self-supervised contrastive learning is to make similar instances close to each other and dissimilar ones farther away in the learned representation space.</p><p>The course of self-supervised contrastive models usually starts with loading each mini-batch of ? instances sequentially from the input data (e.g., the images in Figure <ref type="figure" target="#fig_14">2 (a)</ref>). In each batch, each instance ? is associated with its augmentation ? + as the positive samples and the other instances as negatives {? -}. Commonly by using the InfoNCE loss <ref type="bibr" target="#b34">[35]</ref>, the goal of contrastive learning is to discriminate instances by mapping positive pairs (?, ? + ) to similar embeddings and negative pairs (?, ? -) to dissimilar embeddings.</p><p>Given the self-supervised contrastive setting, the negative samples {? -}-with unknown labels-play an essential role in the contrastive optimization process. To improve in-batch contrastive learning, there are various attempts to take on them from different perspectives. Globally, SimCLR <ref type="bibr" target="#b9">[10]</ref> shows that simply increasing the size ? of the mini-batch (e.g., 8192)-i.e., more negative samplesoutperforms previously carefully-designed strategies, such as the memory bank <ref type="bibr" target="#b50">[51]</ref> and the consistency improvement of the stored V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A E S + Q J A = = &lt; / l a t e x i t &gt; V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt; T o L F X d g / K 7 t l + q X K c j T q P L W x j l + Z 5 i A q q q K F O 3 g M 8 4 g n P V t U K r d S 6 / U y 1 c p l m E 9 + W 9 f A B N y + Q N A = = &lt; / l a t e x i t &gt; V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A E S + Q J A = = &lt; / l a t e x i t &gt; V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt;</p><p>x 4</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 e Y j X m l K 5 t l + q X K c j T q P L W x j l + Z 5 i A q q q K F O 3 g M 8 4 g n P V t U K r d S 6 / U y 1 c p l m E 9 + W 9 f A B N y + Q N A = = &lt; / l a t e x i t &gt;</p><formula xml:id="formula_0">1 x S l Y U R c 7 A Z I / 9 m R m Y = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S V F N 1 1 W t A + o p S T T a R 1 M k z C Z q K U I / o B b / T T x D / Q v v D O m o B b R C U n O n H v P m b n 3 + n E g E u U 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N J I o l Y z X W R R E s u V 7 C Q 9 E y O t K q I C 3 Y</formula><p>x B</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 5</p><formula xml:id="formula_1">1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N H A N K M G s W l R 8 w S V 6 i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W a r e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v V U l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt; x 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x W k f X y D G 9 f I 2 N N m 9 g K O M X e k x 8 N s = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u g f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</formula><p>V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A E S + Q J A = = &lt; / l a t e x i t &gt;</p><p>x 2</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0 a</p><formula xml:id="formula_2">L h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</formula><p>V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt;</p><p>x 4</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 e Y j X m l K 5 t l + q X K c j T q P L W x j l + Z 5 i A q q q K F O 3 g M 8 4 g n P V t U K r d S 6 / U y 1 c p l m E 9 + W 9 f A B N y + Q N A = = &lt; / l a t e x i t &gt;</p><formula xml:id="formula_3">1 x S l Y U R c 7 A Z I / 9 m R m Y = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S V F N 1 1 W t A + o p S T T a R 1 M k z C Z q K U I / o B b / T T x D / Q v v D O m o B b R C U n O n H v P m b n 3 + n E g E u U 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N J I o l Y z X W R R E s u V 7 C Q 9 E y O t K q I C 3 Y</formula><p>x B</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = "</p><formula xml:id="formula_4">x W k f X y D G 9 f I 2 N N m 9 g K O M X e k x 8 N s = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u g f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</formula><p>V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A E S + Q J A = = &lt; / l a t e x i t &gt;</p><p>x 2</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 5</p><formula xml:id="formula_5">1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N H A N K M G s W l R 8 w S V 6 i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W a r e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v V U l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt; x 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0 a L h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W</formula><p>e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6 V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt; w E e 8 Y R n q 2 a F V m r d f q Z a u U y z j W / L e v g A G q + Q K A = = &lt; / l a t e x i t &gt;</p><p>x 6</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 5  V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt;</p><formula xml:id="formula_6">1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h</formula><formula xml:id="formula_7">a L h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f</formula><p>x 4</p><p>( , )</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 5 V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A E S + Q J A = = &lt; / l a t e x i t &gt;</p><formula xml:id="formula_8">1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h</formula><p>x 2 ( , )</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0 a V 3 f P D U u X U j D q P H e x i n + Z 5 j A q q q K F O 3 g M 8 4 g n P V t W K r M y 6 / U y 1 c k a z j W / L e v g A F e + Q J g = = &lt; / l a t e x i t &gt; </p><formula xml:id="formula_9">L h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f</formula><formula xml:id="formula_10">P Q q k z S i L U 4 Z H 7 D V 9 B 7 R r G z a k v f J M t Z r R K Q G 9 C S l t 7 J A m o r y E s D r N 1 v F M O y v 2 N + + x 9 l R 3 G 9 H f N 1 5 D Y i W u i P 1 L N 8 n 8 r 0 7 V I t H H s a 5 B U E 2 x Z l R 1 z L h k u i v q 5 v a X q i Q 5 x M Q p 3 K N 4 Q p h p 5 a T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z i n Q W O v 7 B 6 W 3 b P 9</formula><p>U u X E j D q P L W x j l + Z 5 h A q q q K F O 3 g M 8 4 g n P V t U K r c y 6 / U y 1 c k a z i W / L e v g A G E + Q J w = = &lt; / l a t e x i t &gt;</p><p>x 5</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4</p><formula xml:id="formula_11">= " P 3 Y / p G 4 m l v p L x r N f 2 G U 9 l h Z o c p k = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R L x t Z K C m y 4 r 2 g f U U p L p t A 6 m S U g m a i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 / T g Q q X S c 1 5 w 1 M z s 3 v 5 B f L C w t r 6 y u F d c 3 G m m U J Y z X W R R E S c v 3 U h 6 I k N e l k A F v x Q n 3 h n 7 A m / 7 1 q Y o 3 b 3 i S i i i 8 k K O Y d 4 b e I B R 9 w T x J 1 P l d 9 6 B b L D l l R y 9 7 G r g G l G B W L S q + 4 B I 9 R G D I M A R H C E k 4 g I e U n j Z c O I i J 6 2 B M X E J I 6 D j H P Q q k z S i L U 4 Z H 7 D V 9 B 7 R r G z a k v f J M t Z r R K Q G 9 C S l t 7 J A m o r y E s D r N 1 v F M O y v 2 N + + x 9 l R 3 G 9 H f N 1 5 D Y i W u i P 1 L N 8 n 8 r 0 7 V I t H H s a 5 B U E 2 x Z l R 1 z L h k u i v q 5 v a X q i Q 5 x M Q p 3 K N 4 Q p h p 5 a T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z i n Q W O v 7 B 6 W 3 b P 9 U u X E j D q P L W x j l + Z 5 h A q q q K F O 3 g M 8 4 g n P V t U K r c y 6 / U y 1 c k a z i W / L e v g A G E + Q J w = = &lt; / l a t e x i t &gt; x 5 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P 3 Y / p G 4 m l v p L x r N f 2 G U 9 l h Z o c p k = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R L x t Z K C m y 4 r 2 g f U U p L p t A 6 m S U g m a i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 / T g Q q X S c 1 5 w 1 M z s 3 v 5 B f L C w t r 6 y u F d c 3 G m m U J Y z X W R R E S c v 3 U h 6 I k N e l k A F v x Q n 3 h n 7 A m / 7 1 q Y o 3 b 3 i S i i i 8 k K O Y d 4 b e I B R 9 w T x J 1 P l d 9 6 B b L D l l R y 9 7 G r g G l G B W L S q + 4 B I 9 R G D I M A R H C E k 4 g I e U n j Z c O I i J 6 2 B M X E J I 6 D j H P Q q k z S i L U 4 Z H 7 D V 9 B 7 R r G z a k v f J M t Z r R K Q G 9 C S l t 7 J A m o r y E s D r N 1 v F M O y v 2 N + + x 9 l R 3 G 9 H f N 1 5 D Y i W u i P 1 L N 8 n 8 r 0 7 V I t H H s a 5 B U E 2 x Z l R 1 z L h k u i v q 5 v a X q i Q 5 x M Q p 3 K N 4 Q p h p 5 a T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z i n Q W O v 7 B 6 W 3 b P 9 U u X E j D q P L W x j l + Z 5 h A q q q K F O 3 g M 8 4 g n P V t U K r c y 6 / U y 1 c k a z i W / L e v g A G E + Q J w = = &lt; / l a t e x i t &gt;</formula><p>x 5</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4</p><formula xml:id="formula_12">= " P 3 Y / p G 4 m l v p L x r N f 2 G U 9 l h Z o c p k = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R L x t Z K C m y 4 r 2 g f U U p L p t A 6 m S U g m a i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 / T g Q q X S c 1 5 w 1 M z s 3 v 5 B f L C w t r 6 y u F d c 3 G m m U J Y z X W R R E S c v 3 U h 6 I k N e l k A F v x Q n 3 h n 7 A m / 7 1 q Y o 3 b 3 i S i i i 8 k K O Y d 4 b e I B R 9 w T x J 1 P l d 9 6 B b L D l l R y 9 7 G r g G l G B W L S q + 4 B I 9 R G D I M A R H C E k 4 g I e U n j Z c O I i J 6 2 B M X E J I 6 D j H P Q q k z S i L U 4 Z H 7 D V 9 B 7 R r G z a k v f J M t Z r R K Q G 9 C S l t 7 J A m o r y E s D r N 1 v F M O y v 2 N + + x 9 l R 3 G 9 H f N 1 5 D Y i W u i P 1 L N 8 n 8 r 0 7 V I t H H s a 5 B U E 2 x Z l R 1 z L h k u i v q 5 v a X q i Q 5 x M Q p 3 K N 4 Q p h p 5 a T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z i n Q W O v 7 B 6 W 3 b P 9</formula><p>U u X E j D q P L W x j l + Z 5 h A q q q K F O 3 g M 8 4 g n P V t U K r c y 6 / U y 1 c k a z i W / L e v g A G E + Q J w = = &lt; / l a t e x i t &gt;</p><p>x 5 negatives in MoCo <ref type="bibr" target="#b19">[20]</ref>. Locally, given each mini-batch, recent studies such as the DCL and HCL <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39]</ref> methods have focused on identifying true or hard negatives within this batch. In other words, existing efforts have largely focused on designing better negative sampling techniques after each mini-batch of instances is loaded.</p><p>Problem. In this work, we instead propose to globally sample instances from the input data to form mini-batches. The goal is to have mini-batches that naturally contain as many hard negatives {? -}-that have different (underlying) labels from ? (true negatives) but similar representations with ?-for each instance ? as possible. In this way, the discrimination between positive and negative instances in each mini-batch can better inform contrastive optimization.</p><p>Uniform &amp; kNN Samplers. Traditionally, there are two ways to form mini-batches (Cf. Figure <ref type="figure" target="#fig_1">2</ref> (a)). The common option is the Uniform Sampler that sequentially loads or uniformly samples a batch of instances for each training step <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b58">59</ref>]. However, the Uniform Sampler neglects the effect of hard negatives <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39]</ref>, and the batches formed contain easy negatives with low gradients that contribute little to optimization <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b55">56]</ref>. In order to have hard negatives, it is natural to cluster instances that are nearest to each other in the representation space to form each batch, that is, the kNN Sampler. Unfortunately, the instances with the same underlying labels are also expected to cluster together <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>, resulting in high percentages of false negatives in the batch (Cf. Figure <ref type="figure" target="#fig_14">2 (c)</ref>).</p><p>Contributions: BatchSampler. We present BatchSampler to sample mini-batches of hard-to-distinguish instances for in-batch contrastive learning. Fundamentally, each mini-batch is required to cover hard yet true negatives, thus addressing the issues faced by Uniform and kNN Samplers. To achieve this, we design the proximity graph of randomly-selected instances in which each edge is used to control the pairwise similarity of their representations-that is, the hardness of negative samples. The false negative issue in the kNN Sampler is mitigated when random instances are picked to construct the graph. To form one batch, we leverage random walk with restart on the proximity graph to draw instances. The premise is that the local neighbors sampled by the walkers are similar, that is, hard-to-distinguish.</p><p>BatchSampler is a simple and general technique that can be directly plugged into in-batch contrastive models in vision, language, and graphs. The experimental results show that the well-known contrastive learning models-SimCLR <ref type="bibr" target="#b9">[10]</ref> and MoCo v3 <ref type="bibr" target="#b10">[11]</ref> in vision, SimCSE <ref type="bibr" target="#b15">[16]</ref> in language, and GraphCL <ref type="bibr" target="#b58">[59]</ref> and MVGRL <ref type="bibr" target="#b18">[19]</ref> in graphs-can benefit from the mini-batches formed by BatchSampler. We also theoretically and empirically show that how BatchSampler balances the challenges faced in the Uniform and kNN Samplers.</p><p>Differences from Pairwise Negative Sampling. The problem of mini-batch sampling is different from the pairwise negative sampling problem. As shown in Figure <ref type="figure" target="#fig_13">1</ref>, the pairwise negative sampling method samples negative instances for each positive pair, whereas the mini-batch sampling methods focus on sampling mini-batches that reuses other instances as negatives in the batch. Massive previous works in pairwise negative sampling <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b55">56]</ref> have attempted to improve performance by globally selecting similar negatives for a given anchor from the entire dataset. However, our focus is on globally sampling mini-batches that contain many hard negatives rather than only selecting hard negatives for each pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contrastive learning in different modalities. Contrastive learning follows a similar paradigm that contrasts similar and dissimilar observations based on noise contrastive estimation (NCE) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b34">35]</ref>. The primary distinction between contrastive methods of different modalities is how they augment the data. As for computer vision, MoCo <ref type="bibr" target="#b19">[20]</ref> and SimCLR <ref type="bibr" target="#b9">[10]</ref> augment data with geometric transformation and appearance transformation. Besides simply using data augmentation, WCL <ref type="bibr" target="#b64">[65]</ref> additionally utilizes an affinity graph to construct positive pairs for each example within the mini-batch. Wu et al. <ref type="bibr" target="#b48">[49]</ref> design a data replacement strategy to mine hard positive instances for contrastive learning. As for language, CLEAR <ref type="bibr" target="#b49">[50]</ref> and COCO-LM <ref type="bibr" target="#b32">[33]</ref> augment the text data through word deletion, reordering, and substitution, while SimCSE <ref type="bibr" target="#b15">[16]</ref> obtains the augmented instances by applying the standard dropout twice. As for graphs, DGI <ref type="bibr" target="#b36">[37]</ref> and InfoGraph <ref type="bibr" target="#b42">[43]</ref> treat the node representations and corresponding graph representations as positive pairs. Besides, InfoGCL <ref type="bibr" target="#b52">[53]</ref>, JOAO <ref type="bibr" target="#b57">[58]</ref>, GCA <ref type="bibr" target="#b67">[68]</ref>, GCC <ref type="bibr" target="#b37">[38]</ref> and GraphCL <ref type="bibr" target="#b58">[59]</ref> augment the graph data by graph sampling or proximity-oriented methods. MVGRL <ref type="bibr" target="#b18">[19]</ref> proposes to compare the node representation in one view with the graph representation in the other view. Zhu et al. <ref type="bibr" target="#b66">[67]</ref> compares different kinds of graph augmentation strategies. Our proposed BatchSampler is a general mini-batch sampler that can directly be applied to any in-batch contrastive learning framework with different modalities.</p><p>Negative sampling in contrastive learning. Previous studies about negative sampling in contrastive learning roughly fall into two categories: (1) Memory-based negative sampling strategy, such as MoCo <ref type="bibr" target="#b19">[20]</ref>, maintains a fixed-size memory bank to store negatives which are updated regularly during the training process. MoCHI <ref type="bibr" target="#b26">[27]</ref> and m-mix <ref type="bibr" target="#b62">[63]</ref> propose to mix the hard negative candidates at the feature level to generate more challenging negative pairs. MoCoRing <ref type="bibr" target="#b47">[48]</ref> samples hard negatives from a defined conditional distribution which keeps a lower bound on the mutual information. (2) In-batch negative sharing strategy, such as SimCLR <ref type="bibr" target="#b9">[10]</ref> and MoCo v3 <ref type="bibr" target="#b10">[11]</ref>, adopts different instances in the current mini-batch as negatives. To mitigate the false negative issue, DCL <ref type="bibr" target="#b11">[12]</ref> modifies the original InfoNCE objective to reweight the contrastive loss. Huynh et al. <ref type="bibr" target="#b23">[24]</ref> identifies the false negatives within a mini-batch by comparing the similarity between negatives and the anchor image's multiple support views. Additionally, HCL <ref type="bibr" target="#b38">[39]</ref> revises the original InfoNCE objective by assigning higher weights for hard negatives among the mini-batch. Recently, Un-ReMix <ref type="bibr" target="#b43">[44]</ref> is proposed to sample hard negatives by effectively capturing aspects of anchor similarity, representativeness, and model uncertainty. However, such locally sampled hard negatives cannot exploit hard negatives sufficiently from the dataset.</p><p>Global hard negative sampling methods on triplet loss have been widely investigated, which aim to globally sample hard negatives for a given positive pair. For example, Wang et al. <ref type="bibr" target="#b46">[47]</ref> proposes to take rank-k hard negatives from some randomly sampled negatives. Xiong et al. <ref type="bibr" target="#b51">[52]</ref> globally samples hard negatives by an asynchronously-updated approximate nearest neighbor (ANN) index for dense text retrieval. Different from the above methods which are applied to a triplet loss for a given pair, BatchSampler samples mini-batches with hard negatives for InfoNCE loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem: Mini-Batch Sampling for Contrastive Learning</head><p>In-Batch Contrastive Learning. In-batch contrastive learning commonly follows or slightly updates the following objective <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b34">35]</ref> across different domains, such as graphs <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b58">59]</ref>, vision <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, and language <ref type="bibr" target="#b15">[16]</ref>:</p><formula xml:id="formula_13">min E {? 1 ... ? ? }?D ? ? ? ? ? ? - ? ?? ?=1 log ? ? (? ? ) ? ? (? + ? ) ? ? (? ? ) ? ? (? + ? ) + ? ?? ? ? (? ? ) ? ? (? ? ) ? ? ? ? ? ? ,<label>(1)</label></formula><p>where {? 1 ... ? ? } is a mini-batch of samples (usually) sequentially loaded from the dataset D, and ? + ? is an augmented version of ? ? . The encoder ? (?) learns to discriminate instances by mapping different data-augmentation versions of the same instance (positive pairs) to similar embeddings, and mapping different instances in the mini-batch (negative pairs) to dissimilar embeddings.</p><p>Usually, the in-batch negative sharing strategy-every instance serves as a negative to the other instances within the mini-batch-is used to boost the training efficiency <ref type="bibr" target="#b9">[10]</ref>. It is then natural to have hard negatives in each mini-batch for improving contrastive learning. Straightforwardly, we could attempt to sample hard negatives within the mini-batch <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref>. However, the batch size of a minibatch is-by definition-far smaller than the size of the input dataset, and existing studies show that sampling such a local sampling method fails to effectively explore all the hard negatives <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b63">64]</ref>.</p><p>Problem: Mini-Batch Sampling. The goal of this work is to have a general mini-batch sampling strategy to support different modalities of data. Specifically, given a set of data instances D = {? 1 , ? ? ? , ? ? }, the objective is to design a modality-independent sampler to sample a mini-batch of instances where each pair of instances are hard to distinguish across the dataset.</p><p>There are two existing strategies-Uniform Sampler and kNN Sampler-adopted in contrastive learning.</p><p>Uniform Sampler is the most common strategy used in contrastive learning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b58">59</ref>]. The pipeline is to first randomly sample a batch of instances for each training step, then feed them into the model for optimization.</p><p>Though simple and model-independent, Uniform Sampler neglects the effect of hard negatives <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39]</ref>, and the batches formed contain negatives with low gradients that contribute little to optimization. Empirically, we show that Uniform Sampler results in a low percentage of similar instance pairs in a mini-batch (Cf. Figure <ref type="figure" target="#fig_2">4</ref>). Theoretically, Yang et al. <ref type="bibr" target="#b55">[56]</ref> and Xiong et al. <ref type="bibr" target="#b51">[52]</ref> also prove that the sampled negative should be similar to the query instance since it can provide a meaningful gradient to the model.</p><p>kNN Sampler globally samples a mini-batch with many hard negatives. As its name indicates, it tries to pick an instance at random and retrieve a set of nearest neighbors to construct a batch.</p><p>However, the instances of the same 'class' will be clustered together in the embedding space <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>. Hence the negatives retrieved by it are hard at first but would be replaced by false negatives (FNs) as the training epochs increase, misguiding the model training.</p><p>In summary, Uniform Sampler leverages random negatives to guide the optimization of the model; whereas the kNN one explicitly samples hard negatives but suffers from false negatives. Thus, an ideal negative sampler for in-batch contrastive learning should balance between kNN and Uniform Samplers, ensuring both the exploitation of hard negatives and the mitigation of the FN issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The BatchSampler Method</head><p>To improve contrastive learning, we propose the BatchSampler method with the goal of forming mini-batches with 1) hard-todistinguish instances while 2) avoiding false negatives. BatchSampler is a simple and general strategy that can be directly plugged into existing in-batch contrastive learning models in vision, language, and graphs. Figure <ref type="figure" target="#fig_0">3</ref> shows the overview of BatchSampler.</p><p>The basic idea of BatchSampler is to form mini-batches by globally sampling instances based on the similarity between each pair of them, which is significantly different from previous local sampling methods in contrastive learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39]</ref>. To achieve this, the first step of BatchSampler is to construct the proximity graph of instances with edges measuring the pairwise similarity. Second, we perform mini-batch sampling as a walk by leveraging a simple and commonly-used graph sampling technique, random walk with restart, to sample instances (nodes) from the proximity graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Proximity Graph Construction</head><p>The goal of the proximity graph is to collect candidate instances that alleviate the issues faced by Uniform and kNN Sampler by connecting similar instances while reducing the false negative pairs. If neighbors of an instance are randomly chosen from the dataset, sampling on the resulting graph resembles Uniform Sampler. Conversely, if the most similar instances are chosen as neighbors, it resembles the behavior of kNN Sampler. In BatchSampler, we propose a simple strategy to construct the proximity graph as follows.</p><p>Given a training dataset, we have ? instances {? ? |? = 1, ? ? ? , ? } and their corresponding representations {e ? |? = 1, ? ? ? , ? } generated by the encoder ? (?). The proximity graph is formulated as:</p><formula xml:id="formula_14">? = (V, E),<label>(2)</label></formula><p>where the node set </p><formula xml:id="formula_15">V = {? 1 , ? ? ? , ? ? }</formula><formula xml:id="formula_16">N ? = TopK ? ? ? C ? (e ? ? e ? ) ,<label>(3)</label></formula><p>where ? is the inner product operation. ? is used to control the similarity between the center node and its immediate neighbor nodes, which can be demonstrated by the following proposition:</p><p>Proposition 1. Given an instance ? ? with the corresponding representation e ? , assume that there are at least ? instances whose inner product similarity with ? ? is larger than ?, i.e.,</p><formula xml:id="formula_17">? ? ? V | e ? ? e ? &gt; ? ? ?. (<label>4</label></formula><formula xml:id="formula_18">)</formula><p>Then in the proximity graph ?, the similarity between ? ? and its neighbors is larger than ? with proximate probability at least:</p><formula xml:id="formula_19">P e ? ? e ? &gt; ?, ?? ? ? N ? ? 1 -? ? ? ,<label>(5)</label></formula><p>where ? = ? -? ? , and ? is the number of neighbors.</p><p>Proof. Since ? ? ? , we can approximately assume that the sampling is with replacement. In this case, we have</p><formula xml:id="formula_20">P e ? ? e ? &gt; ?, ?? ? ? N ? = 1 - ? -1 ?? ?=0 ? ? ? ? -? 1 -? ? .<label>(6)</label></formula><p>Then let us prove (5) by induction. When ? = 1, the conclusion clearly holds.</p><p>Assuming that the conclusion holds when ? = ? -1, let us consider the case when ? = ?. We have</p><formula xml:id="formula_21">1 - ?-1 ?? ?=0 ? ? ? ? -? (1 -? ) ? ? 1 -? ? ?-1 - ? ? -1 ? ? -?+1 1 -? ?-1 . (7)</formula><p>To prove the conclusion, we only need to show</p><formula xml:id="formula_22">1 -? ? ?-1 ? ? ? ? ? -1 ? ? -?+1 1 -? ?-1 ,<label>(8)</label></formula><p>or equivalently</p><formula xml:id="formula_23">1 -? ? ?-1 ? ?-1 = 1 -? ? ?-1 ? -? ? ?-1 ? ? ? -1 ? ? ?-1 = ? ? -1 1 -? ?-1 .<label>(9)</label></formula><p>On the other hand, according to <ref type="bibr" target="#b29">[30]</ref>, we have</p><formula xml:id="formula_24">? ? -1 ? ?? ? -1 ?-1 ,<label>(10)</label></formula><p>where ? denotes the Euler's number. Substituting (10) into (9), we only need to show</p><formula xml:id="formula_25">(? -?)(? -1) 1 -? ? ? ???.<label>(11)</label></formula><p>The above relation holds depending on the choices of ?, ? and ?, which can be satisfied in our scenario in most cases. ? Proposition 1 suggests that the candidate set size ? can control the similarity between each center node and its immediate neighbor nodes. A larger ? indicates a greater probability that two adjacent nodes are similar, and the proximity graph constructed would be more like the graph of nodes clustered by kNN. If ? is small and close to ?, the instances in the proximity graph can be considered as randomly-selected ones, that is, by Uniform Sampler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Proximity Graph Sampling</head><p>We perform the mini-batch sampling as a walk in the proximity graph, which collects the visited instances as sampling results from a sourced node. Here we propose to apply Random Walk with Restart (RWR), which offers a theoretically supported ability to control the walker's behavior.</p><p>As shown in Algorithm 3, starting from a node, the sampler moves from one node to another by either teleporting back to the start node with probability ? or moving to a neighboring node    </p><formula xml:id="formula_26">M i Z v H C j r N 4 D H 5 F t Q = " &gt; A A A C x H i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d V k U x G U L 9 g G 1 S J J O a 2 h e z E z E U v Q H 3 O q 3 i X + g f + G d c Q p q E Z 2 Q 5 M y 5 9 5 y Z e 6 + f R a G Q j v N a s O b m F x a X i s u l l d W 1 9 Y 3 y 5 l Z L p D k P W D N I o 5 R 3 f E + w K E x Y U 4 Y y Y p 2 M M y / 2 I 9 b 2 R 2 c q 3 r 5 l X I R p c i n H G e v F 3 j A J B 2 H g S a I a d 9 f l i l N 1 9 L J n g W t A B W b V 0 / I L r t B H i g A 5 Y j A k k I Q j e B D 0 d O H C Q U Z c D x P i O K F Q x x n u U S J t T l m M M j x i R / Q d 0 q 5 r 2 I T 2 y l N o d U C n R P R y U t r Y I 0 1 K e Z y w O s 3 W 8 V w 7 K / Y 3 7 4 n 2 V H c b 0 9 8 3 X j G x E j f E / q W b Z v 5 X p 2 q R G O B E 1 x B S T Z l m V H W B c c l 1 V 9 T N 7 S 9 V S X L I i F O 4 T 3 F O O N D K a Z 9 t r R G 6 d t V b T 8 f f d K Z i</formula><formula xml:id="formula_27">c K H j j R G X i Y j C a z W O e X v o U P R E x T R D V b S g R d P r m b d k S n W H L K j l n P H A z U E K q l H x B S E Y E h x R A c I R T h A B S e p p w S A m r o J c Z K Q M H G O K Q r k T U n F S e E R O B v n b N j A p r M m x s o l I B e S U b B + S J S C c J N s E N Z s + l n t i c u q j e n v Z m G x C r c E v u X b b r / X o t D D m a l B U E x Y X R L M u S m q o m t f q l K U I S Z O y F J W F m n L M + a T m N p b z T f z N K z e o y Q p v U t a c D u z H O g / p R T p u f H p c p N u o r C P Q r n K S q R B U / F H P O H Z q l o j a r d f q t X O b Z x b d l P X w A m U F Q = = &lt; / l a t e x i t &gt; xi &lt; l a t e x i t s h a _ b a s e = " / j o h q O u B A O P W j J Z T h j x b c = " &gt; A A A C z n i c j V H L S s N A F D N r p f V Z d u g k V w V R I R d V l K C f U B b S p J O i S C b F U o p b f C t f p b B / o X h m n o B b R C U n O n H v O n b n u r H P U F Z r z l j Y X F p e S W / W l h b j c K m v N M o S z x W y I / S p q u k z K f h w m u P B Z M Y E g + a j D C x l v j F i S i i F u O Y d Q J n E P I + x x B V K s t u N j k t p Z b L F l l S y z H t g a l K B X N S q + o I e I n j I E I A h h C D s w F K T w s L M T E d T A h L i H E V Z x h i g J M I x U j j E D u k o F L s y H t Z c U u T x a c I a e J A / J E p E s I y N M F c U Z s n + l n u i c s q j e n v l w B s Q I x P l m y n / O C P R x p m r g V F O s G F m d p N k q i v y u a X q g R l i I m T u E f x h L C n n L M + m q T q t p l b x V f N K y c q p U Z u U t a c D z H O g / p R T p f H p c q H n U e e j H I c z F B V c o o q a v g j n v B s V I R M T X u P V G T n t W Z D x / u G Z Q W &lt; / l a t e x i t &gt; xj &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 N 8 0 w F R y s x E M X q 2 2 4 H h q a W 4 i E A c = " &gt; A A A C z 3 i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w S K 4 K o m I u i y 6 c d m C f U B b S p J O 6 9 C 8 m E z U U i p u / Q G 3 + l f i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v d W O f J 9 K y X u e M + Y X F p e X c S n 5 1 b X 1 j s 7 C 1 X U + i V H i s 5 k V + J J q u k z C f h 6 w m u f R Z M x b M C V y f N d z h u Y o 3 r p l I e B R e y l H M O o E z C H m f e 4 4 k q t 2 W 7 F a 6 / T G b d H m 3 U L R K l l 7 m L L A z U E S 2 K l H h B W 3 0 E M F D i g A M I S R h H w 4 S e l q w Y S E m r o M x c Y I Q 1 3 G G C f K k T S m L U Y Z D 7 J C + A 9 q 1 M j a k v f J M t N q j U 3 x 6 B S l N 7 J M m o j x B W J 1 m 6 n i q n R X 7 m / d Y e 6 q 7 j e j v Z l 4 B s R J X x P 6 l m 2 b + V 6 d q k e j j V N f A q a Z Y M 6 o 6 L 3 N J d V f U z c 0 v V U l y i I l T u E d x Q d j T y m m f T a 1 J d O 2 q t 4 6 O v + l M x a q 9 l + W m e F e 3 p A H b P 8 c 5 C + q H J f u 4 Z F e P i u W z b N Q 5 7 G I P B z T P E 5 R x g Q p q 5 B 3 j E U 9 4 N q r G j X F n 3 H + m G n O Z Z g f f l v H w A Q 1 4 l I c = &lt; / l a t e x i t &gt;</formula><formula xml:id="formula_28">E i b U h a n D I f Y A X 3 7 t G t q N q C 9 9 E y U m t E p P r 0 x K U 3 s k S a k v J i w P M 1 U 8 V Q 5 S / Y 3 7 7 H y l H c b 0 d / V X k N i B S 6 J / U s 3 z f y v T t Y i 0 M O J q s G j m i L F y O q Y d k l V V + T N z S 9 V C X K I i J O 4 S / G Y M F P K a Z 9 N p U l U 7 b K 3 j o q / q U z J</formula><formula xml:id="formula_29">P S V 1 Q l r f s l K D 8 y M 5 O Z Q H 8 q / g = " &gt; A A A C y 3 i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w S L U T U l E 1 G X R j R u h g n 1 A W y S Z T u v Q N B O S i V C r S 3 / A r f 6 X + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 4 9 5 8 7 c e / 0 o E I l y n N c Z a 3 Z u f m E x t 5 R f X l l d W y 9 s b N Y T m c a M 1 5 g M Z N z 0 v Y Q H I u Q 1 J V T A m 1 H M v a E f 8 I Y / O N X x x g 2 P E y H D S z W K e G f o 9 U P R E 8 x T R D V 7 p T b r S r V 3 V S g 6 Z c c s e x q 4 G S g i W 1 V Z e E E b X U g w p B i C I 4 Q i H M B D Q k 8 L L h x E x H U w J i 4 m J E y c 4 x 5 5 8 q a k 4 q T w i B 3 Q t 0 + 7 V s a G t N c 5 E + N m d E p A b 0 x O G 7 v k k a S L C e v T b B N P T W b N / p Z 7 b H L q u 4 3 o 7 2 e 5 h s Q q X B P 7 l 2 + i / K 9 P 1 6 L Q w 7 G p Q V B N k W F 0 d S z L k p q u 6 J v b X 6 p S l C E i T u M u x W P C z D g n f b a N J z G 1 6 9 5 6 J v 5 m l J r V e 5 Z p U 7 z r W 9 K A 3 Z / j n A b 1 / b J 7 W H Y v D o q V k 2 z U O W x j B y W a 5 x E q O E M V N T P H R z z h 2 T q 3 E u v W u v u U W j O Z Z w v f l v X w A e N I k g 4 = &lt; / l a t e x i t &gt; f (?)</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y m b P S  </p><formula xml:id="formula_30">V 1 Q l r f s l K D 8 y M 5 O Z Q H 8 q / g = " &gt; A A A C y 3 i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w S L U T U l E 1 G X R j R u h g n 1 A W y S Z T u v Q N B O S i V C</formula><formula xml:id="formula_31">J 7 W H Y v D o q V k 2 z U O W x j B y W a 5 x E q O E M V N T P H R z z h 2 T q 3 E u v W u v u U W j O Z Z w v f l v X</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>w D S j C r H h d f c I U + Y j B k G I M j g i Q c w k N K T w c u H C T E d T E l T h A K d J z j H g X S Z p T F K c M j d k T f I e 0 6 h o 1 o r z x T r W Z 0 S k i v I K W N A 9 L E l C c I q 9</head><p>N s H c + 0 s 2 J / 8 5 5 q T 3 W 3 C f 1 9 4 z U m V u K a 2 L 9 0 s 8 z / 6 l Q t E g N U d A 0 B 1 Z R o R l X H j E u m u 6 J u b n + p S p J D Q p z C f Y o L w k w r Z 3 2 2 t S b V t a v e e j r + p j M V q / b M 5 G Z 4 V 7 e k A b s / x z k P m k d l 9 6 T s n h + X q j U z 6 j z 2 s I 9 D m u c p q q i h j g Z 5 D / G I J z x b N S u y M u v 2 M 9 X K G c 0 u v i 3 r 4 Q M i c Z A 0 &lt; / l a t e x i t &gt; x 8 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U N 7 g p 2 b c n I f q A I W 2 8 2 g K    </p><formula xml:id="formula_32">A I / R 1 o M = " &gt; A A A C x 3 i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R 6 7 L g p u 4 q 2 A f U U p L p t A 1 N M i G Z l J b i w h 9 w q 3 8 m / o H + h X f G F N Q i O i H J m X P v O T P 3 X j f y v U R</formula><formula xml:id="formula_33">I R s 1 U X x B X f o Q 4 A h R Q C O E J K w D w c J P R 3 Y s B A R 1 8 W c u J i Q p + M c 9 y i Q N q U s T h k O s W P 6 D m n X y d i Q 9 s o z 0 W p G p / j 0 x q Q 0 c U I a Q X k x Y X W a q e O p</formula><formula xml:id="formula_34">W O W R U Z Y E t Q = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d V l w 0 2 V F 2 w q 1 l G Q 6 r</formula><formula xml:id="formula_35">k h a 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R L x t S y 4 6 b K i f U A t J Z l O 6 9 A 0 C Z O J W o r g D 7 j V T x P / Q P / C O 2 M K a h G d k O T M u f e c m X u v H w c i U Y 7 z m r P m 5 h c W l / L L h Z X V t f W N 4 u Z W I 4 l S y X i d R U E k W 7 6 X 8 E C E v K 6 E C n g r l t w b + Q F v + s M z H W / e c J m I K L x U 4 5 h 3 R t 4 g F H 3 B P E X U x V 3 3 q F s s O W X H L H s W u B k o I V u 1 q P i C K / Q Q g S H F C B w h F O E A H h J</formula><formula xml:id="formula_36">U + z f M E F V R R Q 5 2 8 B 3 j E E 5 6 t q h V a q X X 7 m W r l M s 0 2 v i 3 r 4 Q M b U Z A x &lt; / l a t e x i t &gt; x 5</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N W J c 9 i n P   </p><formula xml:id="formula_37">P I l V z I a d M v t + F 4 0 X 4 w I = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d V l w 0 2 V F + 4 B a S j K d 1 q F p E i Y T t R T B</formula><formula xml:id="formula_38">T I R U X i p x j H v j L x B K P q C e Y q o i 7 v u Y b d Y c s q O W f Y s c D N Q Q r Z q U f E F V + g h A k O K E T h C K M I B P C T 0 t O H C Q U x c B x P i J C F h 4 h z 3 K J A 2 p S x O G R 6 x Q / o O a N f O 2 J D 2 2 j M x</formula><formula xml:id="formula_39">i i h j p 5 D / C I J z x b V S u 0 U u v 2 M 9 X K Z Z p t f F v W w w c W k Z A v &lt; / l a t e x i t &gt; x 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Z V v n J g F O G e v E Y y t Z 0 i + 9 t h X 9 i + Q = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R K R 6 r L g p s u K 9 g G 1 l G Q 6 r a F p E i Y T t R T B H 3 C r n y b + g f 6 F d 8 Y p q E V 0 Q p I z</formula><formula xml:id="formula_40">U + Y j B k G I M j g i Q c w k N K T w c u H C T E d T E l T h A K d J z j H g X S Z p T F K c M j d k T f I e 0 6 h o 1 o r z x T r W Z 0 S k i v I K W N A 9 L E l C c I q 9 N s H c + 0 s 2 J / 8 5 5 q T 3 W 3 C f 1 9 4 z U m V u K a 2 L 9 0 s 8 z / 6 l Q t E g O c 6 h o C q i n R j K q O G Z d M d 0 X d 3 P 5 S l S S H h D i F + x Q X h J l W z v</formula><p>p s a 0 2 q a 1 e 9 9 X T 8 T W c q V u 2 Z y c 3 w r m 5 J A 3 Z / j n M e N I / K b q X s n h + X q j U z 6 j z 2 s I 9 D m u c J q q i h j g Z 5 D / G I J z x b N S u y M u v 2 M 9 X K G c 0 u v i 3 r 4 Q M d s Z A y &lt; / l a t e x i t &gt; N s H c + 0 s 2 J / 8 5 5 q T 3 W 3 C f 1 9 4 z U m V u K a 2 L 9 0 s 8 z / 6 l Q t E g O c 6 h o C q i n R j K q O G Z d M d 0 X d 3 P 5 S l S S H h D i F + x Q X h J l W z v p s a 0 2 q a 1 e 9 9 X T 8 T W c q V u 2 Z y c 3 w r m 5 J A 3 Z / j n M e N C t l 9 7 j s n h + V q j U z 6 j z 2 s I 9 D m u c J q q i h j g Z 5 D / G I J z x b N S u y M u v 2 M 9 X K G c 0 u v i 3 r 4 Q M U M Z A u &lt; / l a t e x i t &gt;</p><p>x 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c b H u T s B + T C K</head><formula xml:id="formula_41">Q t f U Q o l 7 R e k m c 6 J o = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R H 7 u C m y 4 r 2 g f U U p L p t A 5 N k z C Z q K U I / o B b / T T x D / Q v v D O m o B b R C U n O n H v P m b n 3 + n E g E u U 4 r z l r b n 5 h c S m / X F h Z X V v f K G 5 u N Z I o l Y z X W R R E s u V 7 C Q 9 E y O t K q I C 3 Y s m 9 k R / w p j 8 8 0 / H m D Z e J i M J L N Y 5 5 Z + Q N Q t E X z F N E X d x 1 T 7 v F k l N 2 z L J n g Z u B E r J V i 4 o v u E I P E R h S j M A R Q h E O 4 C G h p w 0 X D m L i O p g Q J w k J E + e 4 R 4 G 0 K W V x y v C I H d J 3 Q L t 2 x o a 0 1 5 6 J U T M 6 J a B X k t L G H m k i y p O E 9 W m 2 i a f G W b O / e U + M p 7 7 b m P 5 + 5 j U i V u G a 2 L 9 0 0 8 z / 6 n Q t C n 2 c m B o E 1 R Q b R l f H M p f U d E X f 3 P 5 S l S K H m D i N e</formula><p>x S X h J l R T v t s G 0 1 i a t e 9 9 U z 8 z W R q V u 9 Z l p v i X d + S B u z + H O c s a B y U 3 a O y e 3 5 Y q l S z U e e x g 1 3 s 0 z y P U U E V N d T J e 4 B H P O H Z q l q h l V q 3 n 6 l W L t N s 4 9 u y H j 4 A J N G Q N Q = = &lt; / l a t e x i t &gt; N s H c + 0 s 2 J / 8 5 5 q T 3 W 3 C f 1 9 4 z U m V u K a 2 L 9 0 s 8 z / 6 l Q t E g O c 6 h o C q i n R j K q O G Z d M d 0 X d 3 P 5 S l S S H h D i F + x Q X h J l W z v p s a 0 2 q a 1 e 9 9 X T 8 T W c q V u 2 Z y c 3 w r m 5 J A 3 Z / j n M e N I / K 7 n H Z P a + U q j U z 6 j z 2 s I 9 D m u c J q q i h j g Z 5 D / G I J z x b N S u y M u v 2 M 9 X K G c 0 u v i 3 r 4 Q M Y 8 Z A w &lt; / l a t e x i t &gt; x 4</p><p>Step 1</p><p>Step 2 ?? Proposition 2. For all 0 &lt; ? ? 1 and S ? V, the probability that a Lazy Random Walk with Restart starting from a node ? ? S escapes S satisfies ? ? ( V -S) p ? (?) ? 1-? 2? ?(S), where p ? is the stationary distribution, and ?(S) is the graph conductance of S.</p><p>Proof. We first introduce the definition of graph conductance <ref type="bibr" target="#b68">[69]</ref> and Lazy Random Walk <ref type="bibr" target="#b41">[42]</ref>: Graph Conductance. For an undirected graph ? = (V, E), the graph volume of a node set S ? V is defined as vol(S) = ? ? S ? (?), where ? (?) is the degree of node ?. The edge boundary of a node set is defined to be ?(S) = {(?, ?) ? E |? ? S, ? ? S}. The conductance of S is calculated as followed:</p><formula xml:id="formula_42">?(S) = |?(S)| min(vol(S), vol(V -S))<label>(12)</label></formula><p>Lazy Random Walk. Lazy Random Walk (LRW) is a variant of Random Walk, which first starts at a node, then stays at the current position with a probability of 1/2 or travels to a neighbor. The transition matrix of a lazy random walk is M ? (I + AD -1 )/2, where the I denotes the identity matrix, A is the adjacent matrix, and D is the degree matrix. The ?-th step Lazy Random Walk distribution starting from a node ? is defined as q (? ) ? M ? 1 ? .</p><p>We then present a theorem that relates the Lazy Random Walk to graph conductance, which has been proved in Spielman and Teng <ref type="bibr" target="#b41">[42]</ref>: Theorem 1. For all ? ? 0 and S ? V, the probability that a ?-step Lazy Random Walk starting at ? ? S escapes S satisfies q (? ) (V -S) ? ??(S)/2. Theorem 1 guarantees that given a non-empty node set S ? V and a start node ? ? S, the Lazy Random Walker will be more likely stuck at S. Here we extend the LRW to Lazy Random Walk with Restart (LRWR) which will return to the start node with probability ? or perform Lazy Random Walk. According to the previous studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b45">46]</ref>, we can obtain a stationary distribution p ? by recursively performing Lazy Random Walk with Restart, which can be formulated as a linear system:</p><formula xml:id="formula_43">p ? = ?1 ? + (1 -?)Mp ? (<label>13</label></formula><formula xml:id="formula_44">)</formula><p>where ? denotes the restart probability. p ? can be expressed as a geometric sum of Lazy Random Walk <ref type="bibr" target="#b12">[13]</ref>:</p><formula xml:id="formula_45">p ? = ? ? ?? ?=0 (1 -?) ? M ? 1 ? = ? ? ?? ?=0 (1 -?) ? q (? ) ?<label>(14)</label></formula><p>Applying Theorem 1, we have:</p><formula xml:id="formula_46">?? ? ? ( V -S) p ? (?) = ? ? ?? ?=0 ?? ? ? ( V -S) (1 -?) ? q (? ) ? (?) ? ? ? ?? ?=0 ? (1 -?) ? ?(S)/2 = 1 -? 2? ?(S)<label>(15)</label></formula><p>where the element p ? (?) represents the probability of the walker starting at ? and ending at ?. The desired result is obtained by comparing two sides of <ref type="bibr" target="#b14">(15)</ref>. ?</p><p>The only difference between Lazy Random with Restart and Random Walk with Restart is that the former has a probability of remaining in the current position without taking action. They are equivalent when sampling a predetermined number of nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Constrative Learning with BatchSampler</head><p>Input: </p><formula xml:id="formula_47">Dataset D = {? ? |? = 1, ? ? ? , ? },</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update the parameters of ? (?). end</head><p>Overall, Proposition 2 indicates that the probability of RWR escaping from a local cluster <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b41">42]</ref> can be bounded by the graph conductance <ref type="bibr" target="#b68">[69]</ref> and the restart probability ?. Besides, RWR can exhibit a mixture of two straightforward sampling methods Breadthfirst Sampling (BFS) and Depth-first Sampling (DFS) <ref type="bibr" target="#b16">[17]</ref>:</p><p>? BFS collects all of the current node's immediate neighbors, then moves to its neighbors and repeats the procedure until the number of collected instances reaches batch size. ? DFS randomly explores the node branch as far as possible before the number of visited nodes reaches batch size.</p><p>Specifically, higher ? indicates that the walker will approximate BFS behavior and sample within a small locality, while a lower ? encourages the walker to explore nodes further away, like in DFS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion on BatchSampler</head><p>As shown in Algorithm 1, BatchSampler serves as a mini-batch sampler and can be easily plugged into any in-batch contrastive learning methods. Specifically, during the training process, BatchSampler first constructs the proximity graph, which will be updated after ? training steps, then selects a start node at random and samples a mini-batch on proximity graph by RWR.</p><p>Connects to the Uniform and kNN Samplers. As shown in Figure <ref type="figure" target="#fig_2">4</ref>, the number of candidates ? and the restart probability ? are the key to flexibly controlling the hardness of a sampled batch. When we set ? as the size of dataset and ? as 1, proximity graph is equivalent to kNN graph and graph sampler will only collect the immediate neighbors around a central node, which behaves similarly to a kNN Sampler. On the other hand, if ? is set to 1 and ? is set to 0, the RWR degenerates into the DFS and chooses the neighbors that are linked at random, which indicates that Batch-Sampler performs as a Uniform Sampler. We provide an empirical criterion of choosing ? and ? in Section 5.3.</p><p>Complexity. The time complexity of building a proximity graph is ? (? ??) where ? is the dataset size, ? is the candidate set size and ? denotes the embedding size. It is practically efficient since usually ? is much smaller than ? , and the process can be accelerated by embedding retrieval libraries such as Faiss <ref type="bibr" target="#b25">[26]</ref>. The space cost of BatchSampler mainly comes from graph construction and graph storage. The total space complexity of BatchSampler is ? (?? +? ?) where ? is the number of neighbors in the proximity graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We plug BatchSampler into typical contrastive learning algorithms on three modalities, including vision, language, and graphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>Results on Vision. We first adopt SimCLR <ref type="bibr" target="#b9">[10]</ref> and MoCo v3 <ref type="bibr" target="#b10">[11]</ref> as the backbone based on ResNet-50 <ref type="bibr" target="#b20">[21]</ref>. We start with training the model for 800 epochs with a batch size of 2048 for SimCLR and 4096 for MoCo v3, respectively. We then use linear probing to evaluate the representations on ImageNet. As shown in Table <ref type="table" target="#tab_3">1</ref>, our proposed model can consistently boost the performance of original SimCLR and MoCo v3, demonstrating the superiority of BatchSampler. Besides, we evaluate BatchSampler on the other benchmark datasets: two small-scale (CIFAR10, CIFAR100) and two medium-scale (STL10, ImageNet-100), which can be found in Appendix B.1.</p><p>Results on Language. We evaluate BatchSampler on learning the sentence representations by SimCSE <ref type="bibr" target="#b15">[16]</ref> framework with pretrained BERT <ref type="bibr" target="#b14">[15]</ref> as the backbone. The results of Table <ref type="table" target="#tab_4">2</ref> suggest that BatchSampler consistently improves the baseline models with an absolute gain of 1.09%?2.91% on 7 semantic textual similarity (STS) tasks <ref type="bibr">[1-5, 32, 45]</ref>. Specifically, we observe that when applying DCL and HCL, the performance of the self-supervised language model averagely drops by 2.45% and 3.08% respectively. As shown in Zhou et al. <ref type="bibr" target="#b65">[66]</ref> and Appendix B.6, the pretrained language model offers a prior distribution over the sentences, leading to a high cosine similarity of both positive pairs and negative pairs. So DCL and HCL, which leverage the similarity of positive and negative scores to tune the weight of negatives, are inapplicable because the high similarity scores of positives and negatives will result in homogeneous weighting. However, the hard negatives explicitly sampled by our proposed BatchSampler can alleviate it, with an absolute improvement of 1.64% on DCL and 2.64% on HCL. The results of RoBERTa <ref type="bibr" target="#b30">[31]</ref> are reported in Appendix B.2.</p><p>Results on Graphs. We test BatchSampler on graph-level classification task using GraphCL <ref type="bibr" target="#b58">[59]</ref> and MVGRL <ref type="bibr" target="#b18">[19]</ref> frameworks. Similar to language modality, we replace the original InfoNCE loss function in GraphCL with the DCL and HCL.   performance comparison on 7 benchmark datasets: IMDB-B, IMDB-M, COLLAB, REDDIT-B, PROTEINS, MUTAG, and NCI1 <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b61">62]</ref>. We can observe that BatchSampler consistently boosts the performance of GraphCL and MVGRL, with an absolute improvement of 0.4% ? 2.9% across all the datasets. Besides, equipped with Batch-Sampler, DCL and HCL can achieve better performance in 12 out of 14 cases. It can also be found that BatchSampler can reduce variance in most cases, showing that the exploited hard negatives can enforce the model to learn more robust representations. We also compare BatchSampler with 11 graph classification models including the unsupervised graph learning methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b56">57]</ref>, graph kernel methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55]</ref>, and self-supervised graph learning methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref>] (See Appendix B.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Why does BatchSampler Perform Better?</head><p>In this section, we conduct experiments to investigate why Batch-Sampler performs better, using the example of vision modality. We evaluate SimCLR on CIFAR10 and CIFAR100, comparing the performance and false negatives of Uniform Sampler, kNN Sampler, and BatchSampler to gain a deeper understanding of BatchSampler. Figure <ref type="figure" target="#fig_2">4</ref> presents the histogram of cosine similarity for all pairs within a sampled batch, and the corresponding percentage of false negatives during training.</p><p>The results indicate that although kNN Sampler can explicitly draw a data batch with similar pairs, it also leads to a substantially higher number of false negatives, resulting in a notable degradation of performance. Uniform Sampler is independent of the model so the percentage of false negatives within the sampled batch remains consistent during training, but it fails to effectively sample the hard negatives. BatchSampler can modulate ? and ? to control the hardness of the sampled batch, which brings about the best balance between these two sampling methods, resulting in a mini-batch of hard-to-distinguish instances with fewer false negatives compared to the kNN Sampler. Specifically, BatchSampler can sample hard mini-batch but only exhibits a slightly higher percentage of false negatives than Uniform Sampler with optimal parameter setting, which enables BatchSampler to achieve the best performance. A similar phenomenon on CIFAR100 can be found in Appendix B.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Empirical Criterion for BatchSampler</head><p>BatchSampler modulates the hardness of the sampled batch by two important parameters ? and ? to achieve better performance on three modalities. To analyze the impact of these, we vary the ? and ? in the range of {500, 1000, 2000, 4000, 6000} and {0.1, 0.3, 0.5, 0.7} respectively, and apply SimCLR, SimCSE and GraphCL as backones. We summarize the performance of BatchSampler with different ? and ? in Table <ref type="table" target="#tab_6">4</ref>. It shows that in most cases, the performance of the  model peaks when ? = 1000 but plumbs quickly with the increase of ?. Such phenomena are consistent with the intuition that higher ? raises the probability of selecting similar instances as neighbors, but the sampler will be more likely to draw the mini-batch with false negatives, degrading the performance.</p><p>Besides, to better understand the effect of ?, we visualize the histograms of cosine similarity for all pairs from a sampled batch after training and plot the corresponding percentage of false negatives during training on CIFAR10 (See Figure <ref type="figure" target="#fig_32">5</ref>). We can observe that ? moving from 0.1 to 0.7 causes cosine similarities to gradually skew left, but introduces more false negatives in the batch, creating a trade-off. This phenomenon indicates that the sampler with a higher ? sample more frequently within a local neighborhood, which is more likely to yield similar pairs. A similar phenomenon can also be found on CIFAR100 (See Appendix B.5). However, as training progresses, the instances of the same class tend to group together, increasing the probability of collecting false negatives. To find the best balance, we linearly decay ? from 0.2 to 0.05 as the training epoch increases, which is presented as 0.2 ? 0.05 in Table <ref type="table" target="#tab_6">4</ref>. It can be found that this dynamic strategy achieves the best performance in all cases except SimCSE which only trains for one epoch. Interestingly, SimCSE achieves the best performance by a large margin when ? = 0.7 since hard negatives can alleviate the distribution issue brought by the pre-trained language model. More analysis can be found in Section 5.1 and Appendix B.6.</p><p>Criterion. From the above analysis, the suggested ? would be 500 for the small-scale dataset, and 1000 for the larger dataset. The suggested ? should be relatively high, e.g., 0.7, for the pre-trained language model-based method. Besides, dynamic decay ?, e.g., 0.2 to 0.05, is the best strategy for the other methods. Such an empirical criterion provides critical suggestions for selecting the appropriate ? and ? to modulate the hardness of the sampled batch.  <ref type="table" target="#tab_7">5</ref>, from which we make the following observations: (1) Sampling a mini-batch Cost ? takes an order of magnitude less time than training with a batch Cost ? at most cases. (2) Although it takes 100? for BatchSampler to construct a proximity graph in ImageNet, the cost shares across ? training steps, which take only Cost ?/? = 0.2 per batch. A similar phenomenon can be found in other datasets as well. In particular, SimCSE trains for one epoch, and proximity graph is built once.  To develop an intuitive understanding of how proximity graph alleviates the false negative issue, Figure <ref type="figure" target="#fig_22">7</ref> plots the changing curve of false negative ratio in a batch. The results show that the proximity graph could discard the false negative significantly: by the end of the training, kNN will introduce more than 22% false negatives in a batch, while the proximity graph brings about 13% on CIFAR10. A similar phenomenon can also be found on CIFAR100.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we study the problem of mini-batch sampling for in-batch contrastive learning, which aims to globally sample minibatches of hard-to-distinguish instances. To achieve this, we propose BatchSampler to perform mini-batch sampling as a walk on the constructed proximity graph. Specifically, we design the proximity graph to control the pairwise similarity among instances and leverage random walk with restart (RWR) on the proximity graph to form a batch. We theoretically and experimentally demonstrate that BatchSampler can balance kNN Sampler and Uniform Sampler. Besides, we conduct experiments with 5 representative contrastive learning algorithms on 3 modalities (e.g. vision, language, and graphs) to evaluate our proposed BatchSampler, demonstrating that BatchSampler can consistently achieve performance improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Algorithm Details</head><p>Here </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Experiments B.1 Extensive studies on Vision</head><p>Here we evaluate the BatchSampler on two small-scale (CIFAR10, CIFAR100) and two medium-scale (STL10, ImageNet-100) benchmark datasets, and equip DCL <ref type="bibr" target="#b11">[12]</ref> and HCL <ref type="bibr" target="#b38">[39]</ref> 2 with BatchSampler to investigate its generality. Experimental results in Table <ref type="table" target="#tab_11">8</ref> show that BatchSampler can consistently improve SimCLR and its variants on all the datasets, with an absolute gain of 0.3%?2.5%. We also can observe that the improvement is greater on mediumscale datasets than on small-scale datasets. Specifically, the model equipped with HCL and BatchSampler achieves a significant improvement (6.23%) on STL10 over the original SimCLR. 2 DCL and HCL are more like variants of InfoNCE loss, which adjust the weights of negative samples in the original InfoNCE loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Experiments with Roberta on Language</head><p>We also apply BatchSampler to the SimCSE with the pretrained RoBERTa <ref type="bibr" target="#b30">[31]</ref> and present the results in Table <ref type="table" target="#tab_12">9</ref>. Similar to the results of BERT, BatchSampler can consistently improve the performance of the baseline model. Besides, as discussed in Section 5.1 and Section B.6, the hard negative sampled by BatchSampler explicitly can alleviate the low distribution gap between positive score and negative score distribution caused by the pretrained language model, alleviating the performance degradation of DCL and HCL.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Comparison with baselines on Graphs</head><p>In Table <ref type="table" target="#tab_3">10</ref>, we comprehensively compare different kinds of baselines on graph classification tasks, including the unsupervised graph learning methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b56">57]</ref>, graph kernel methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55]</ref>, and selfsupervised graph learning methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref>]. It can be found that InfoGCL achieves state-the-of-art performance among the self-supervised methods, and even outperforms the supervised methods on some datasets. BatchSampler can consistently improve the performance of both GraphCL and MVGRL on all the datasets, demonstrating the effectiveness of global hard negatives.</p><p>Benefiting from the performance gain brought by BatchSampler, MVGRL achieves the best performance on 4 datasets, outperforming InfoGCL and supervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Restart Probability Analysis on CIFAR100</head><p>Figure <ref type="figure" target="#fig_29">9</ref> shows cosine similarities and percentage of false negatives in the sampled batch among various restart probabilities ? on CI-FAR100. It can be observed that cosine similarities gradually skew left with the increase of ? from 0.1 to 0.7, indicating the higher ? brings about more hard negative instances similar to positive anchor. However, higher ? suffers from more serious FN issues, which significantly increases the percentage of false negatives in the sampled batch. Thus, we linearly decay ? from 0.2 to 0.05, achieving a trade-off between hard negatives and false negatives. More analyses are discussed in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Similarity Comparison Between Positive and Negative Pairs</head><p>To explain the performance degradation of DCL and HCL objectives, we select 12 representative mini-batches and plot the cosine similarity histogram of positive and negative pairs on BERT (top) and RoBERTa (bottom) in Figure <ref type="figure" target="#fig_37">10</ref>. We observe the following: (1) At the start of and throughout the training, the positive pairs are assigned a high cosine similarity (around 0.9) by the pretrained language model; (2) The negative similarities begin with a relatively high score and gradually skew left because of the self-supervised learning. Such phenomenon is consistent to Zhou et al. <ref type="bibr" target="#b65">[66]</ref>. DCL and HCL which leverage the difference between positive and negative similarity to reweight the negative scores are inapplicable since the low distribution gap between positive and negative similarities will lead to homogeneous weighting in the objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7 Impact of Sampling Method on CIFAR100</head><p>We conduct different strategies of proximity graph sampling on CIFAR100 to investigate the impact of sampling methods. As shown in Figure <ref type="figure" target="#fig_23">11</ref>, BFS achieves more similar pairs in the sampled batch compared with other proximity graph sampling methods but it introduces a higher percentage of false negatives, which obviously degrades the downstream performance. Conversely, DFS explores paths far away from the selected central node, which can not guarantee that the sampled path (i.e. batch) is within a local cluster. Thus, we theoretically leverage RWR to flexibly modulate the hardness of the sampled batch and achieve a balance between hard negatives and false negatives.  <ref type="table" target="#tab_13">11</ref>. In vision modality, it can be found that a larger batchsize leads to better results, which is consistent with the previous studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>. In language domain, BatchSampler reaches its optimum at ? = 64, which aligns with the results in SimCSE <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.8 Parameter Analysis</head><p>For graphs, we can observe that the performance improves slightly with increasing batch size.</p><p>B.8.2 Impact of Neighbor Number ? In Figure <ref type="figure" target="#fig_23">12</ref>, we investigate the impact of the neighbor number ? on ImageNet-100 dataset with the default BatchSampler setting. We observe an absolute improvement of 1.1% with the increasing size of neighbors. Specifically, model achieves an absolute performance gain of 0.9% from ? = 100 to ? = 300, while only obtaining 0.2% from ? = 300 to ? = 500.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.9 Training Curve</head><p>We plot the training curves on STL10 and ImageNet-100 respectively. As shown in Figure <ref type="figure" target="#fig_39">13</ref>, on STL10 dataset, BatchSampler takes only about 600 epochs to achieve a similar performance as the original SimCLR, which takes 1000 epochs. A similar phenomenon can be seen on ImageNet-100. All these results manifest that BatchSampler can bring model better and faster learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C InfoNCE Objective and its Variants</head><p>Here we describe in detail the objective functions of three in-batch contrastive learning methods, including SimCLR <ref type="bibr" target="#b9">[10]</ref>, GraphCL <ref type="bibr" target="#b58">[59]</ref> and SimCSE <ref type="bibr" target="#b15">[16]</ref>. Besides, we cover two variants, i.e., DCL <ref type="bibr" target="#b11">[12]</ref> and HCL <ref type="bibr" target="#b38">[39]</ref>, which are also applied in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 SimCLR</head><p>SimCLR <ref type="bibr" target="#b9">[10]</ref> first uniformly draws a batch of instances {? 1 ... ? ? } ? D, then augments the instances by two randomly sampled augmentation strategies ? ??? (?), ? ? ??? (?) ? T , resulting in 2? data points. Two augmented views (? ? , ? ?+? ) of the same image are treated as a positive pair, while the other 2(? -1) examples are negatives. The objective function applied in SimCLR for a positive pair (? ? , ? ?+? ) is formulated as:</p><formula xml:id="formula_48">? ?,?+? = -log ? ? (? ? ) ? ? (? ?+? )/? 2? ??? ? ? (? ? ) ? ? (? ? )/? , (<label>16</label></formula><formula xml:id="formula_49">)</formula><p>where ? is the temperature and ? (?) is the encoder. The loss is calculated for all positive pairs in a mini-batch, including (? ? , ? ?+? ) and (? ?+? , ? ? ). It can be found that SimCLR takes all 2(? -1) augmented instances within a mini-batch as negatives.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 GraphCL and SimCSE</head><p>Similar to SimCLR, the objective function of GraphCL <ref type="bibr" target="#b58">[59]</ref> and SimCSE <ref type="bibr" target="#b15">[16]</ref> is defined on the augmented instance pairs within a mini-batch. Given a sampled mini-batch {? </p><p>Compared with the SimCLR, GraphCL and SimCSE only take the other ? -1 augmented instances as negatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 DCL and HCL</head><p>DCL <ref type="bibr" target="#b11">[12]</ref> and HCL <ref type="bibr" target="#b38">[39]</ref> are two variants of InfoNCE objective function, which aim to alleviate the false negative issue or mine the hard negatives by reweighting the negatives in the objective. The main idea behind them is using the positive distribution to correct for the negative distribution.</p><p>For simplicity, we annotate the positive score ? ? (? ? ) ? ? (? + ? )/? as ???, and negative score ? ? (? ? ) ? ? (? + ? )/? as ??? ? ? . Given a mini-batch and a positive pair (? ? , ? + ? ), the reweighting negative distribution proposed in DCL and HCL are:</p><formula xml:id="formula_51">max ? ?? ?=1 -? ??? ? ? + ? ??? + ? ? ? ? ??? ? ? 1 -? + , ? -1/? ,<label>(18)</label></formula><p>where ? ??? is the number of the negatives in mini-batch, ? + is the class probability, ? is the temperature, and ? ? ? is concentration parameter which is simply set as 1 in DCL or calculated as ? ? ? = ? ???? ? ? ??? ? ? /? ??? in HCL. All of ? + , ?, ? are tunable hyperparameters. The insight of Eq.18 is that the negative pair with a score closer to a positive score will be assigned a lower weight in the loss function. In other words, the similarity difference between positive and negative pairs dominates the weighting function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Dataset Details</head><p>For image representation learning, we adopt five benchmark datasets, comprising CIFAR10, CIFAR100, STL10, ImageNet-100 and Ima-geNet ILSVRC-2012 <ref type="bibr" target="#b39">[40]</ref>. Information on the statistics of these datasets is summarized in Table <ref type="table" target="#tab_15">13</ref>. For graph-level representation learning, we conduct experiments on IMDB-B, IMDB-M, COLLAB, REDDIT-B, PROTEINS, MUTAG, and NCI1 <ref type="bibr" target="#b54">[55]</ref>, the details of which are presented in Table <ref type="table" target="#tab_16">14</ref>. For text representation learning, we evaluate the method on a one-million English Wikipedia dataset which is used in the SimCSE and can be downloaded from HuggingFace repository 3 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Experimental Details E.1 Image Representations</head><p>In image domain, we apply SimCLR <ref type="bibr" target="#b9">[10]</ref> and MoCo v3 <ref type="bibr" target="#b10">[11]</ref> as the baseline method, with ResNet-50 <ref type="bibr" target="#b20">[21]</ref> as an encoder to learn image representations. The feature map generated by ResNet-50 block is projected to a 128-D image embedding via a two-layer MLP (2048-D hidden layer with ReLU activation function). Besides, the output vector is normalized by ? 2 normalization <ref type="bibr" target="#b50">[51]</ref>. We employ two sampled data augmentation strategies to generate positive pairs and implicitly use other examples in the same mini-batch as negative samples. For CIFAR10, CIFAR100 and STL10, all models are trained for 1000 epochs with the default batch size ? of 256. We use the Adam optimizer <ref type="bibr" target="#b28">[29]</ref> with a learning rate of 0.001 for optimization. The temperature parameter is set as 0.5 and the dimension of image embedding is set as 128. For ImageNet-100 and ImageNet, we train the models with 100 and 400 epochs respectively, and use LARS optimizer <ref type="bibr" target="#b59">[60]</ref> with a learning rate of 0.3 ? ?/256 and weight decay of 10 -6 . Here, the batch size is set as 2048 for ImageNet and 512 for ImageNet-100, respectively. We fix the temperature parameter as 0.1 and the image embedding dimension as 128. After the unsupervised 3 https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/ wiki1m_for_simcse.txt learning, we train a supervised linear classifier for 100 epochs on top of the frozen learned representations.</p><p>As for BatchSampler, we update the proximity graph per 100 training iterations. We fix the number of neighbors ? as 100 for CIFAR10, CIFAR100 and STL10. The size of the neighbor candidate set ? is set as 1000 for CIFAR100 and STL10, and 500 for CIFAR10. Besides, the initial restart probability ? of RWR (Random Walk with Restart) is set to 0.2 and decays linearly to 0.05 with the training process. For ImageNet-100 and ImageNet, we keep ? as 1000 and ? as 500. The restart probability ? is fixed as 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Graph Representations</head><p>In graph domain, we use the GraphCL <ref type="bibr" target="#b58">[59]</ref> framework as the baseline and GIN <ref type="bibr" target="#b53">[54]</ref> as the backbone. We run BatchSampler 5 times with different random seeds and report the mean 10-fold crossvalidation accuracy with variance. We apply Adam optimizer <ref type="bibr" target="#b28">[29]</ref> with a learning rate of 0.01 and 3-layer GIN with a fixed hidden size of 32. We set the temperature as 0.2 and gradually decay the restart probability of RWR (0.2 ? 0.05). Proximity graph will be updated after ? iterations. The overall hyperparameter settings on different datasets are summarized in Table <ref type="table" target="#tab_17">15</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Text Representations</head><p>In text domain, we use SimCSE <ref type="bibr" target="#b15">[16]</ref> as the baseline method and adopt the pretrained BERT and RoBERTa provided by HuggingFace<ref type="foot" target="#foot_0">4</ref> for sentence embedding learning. Following the training setting of SimCSE, we train the model for one epoch in an unsupervised manner and evaluate it on 7 STS tasks. Proximity graph will be only built once based on the pretrained language models before training. For BERT, we set the batch size to 64 and the learning rate to 3 ? 10 -5 . For RoBERTa, the batch size is set as 512 and the learning rate is fixed as 10 -5 . We keep the temperature as 0.05, the number of neighbor candidates ? as 1000, the number of neighbors ? as 500, and the restart probability ? as 0.7 for both BERT and RoBERTa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Case Study</head><p>To give an intuitive impression of the mini-batch sampled by Batch-Sampler, we show some real cases of the negatives sampled by Uniform Sampler, kNN Sampler, and BatchSampler in Figure <ref type="figure" target="#fig_42">14</ref>.</p><p>For a given anchor (a cat or a dog), we apply Uniform Sampler, kNN Sampler, and BatchSampler to draw a mini-batch of images, and randomly pick 10 images from the sampled batch to show inbatch negatives for the positive anchor. Obviously, compared with   Uniform Sampler, the images sampled by BatchSampler are more semantically relevant to the anchor in terms of texture, background, or appearance. Furthermore, kNN Sampler introduces so many false negatives that belong to the same class with positive anchor, degrading downstream performance. Thus, the proposed BatchSampler can effectively balance the exploitation of hard negatives and the FN issue. Furthermore, we provide a visualization of language to demonstrate the effectiveness and generalizability of BatchSampler in Figure <ref type="figure" target="#fig_43">15</ref>. Here, we also take a vision as an example and visualize the process of updating the proximity graph in Figure <ref type="figure" target="#fig_44">16</ref>. We maintain the default starting image and randomly sample a predetermined number of neighboring images at a specific iteration in each proximity graph.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 &lt;</head><label>3</label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " N 5 1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0= " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N H A N K M G s W l R 8 w S V 6 i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W a r e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v V U l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt;x l a t e x i t s h a 1 _ b a s e 6 4 = "x W k f X y D G 9 f I 2 N N m 9 g K O M X e k x 8 N s = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u g f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z Dh h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>x 2 &lt;</head><label>2</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0 aL h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z hp 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>x 4 &lt;</head><label>4</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " 5 e Y j X m l K 51 x S l Y U R c 7 A Z I / 9 m R m Y = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S V F N 1 1 W t A + o p S T T a R 1 M k z C Z q K U I / o B b / T T x D / Q v v D O m o B b R C U n O n H v P m b n 3 + n E g E u U 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N J I o l Y z X W R R E s u V 7 C Q 9 E y O t K q I C 3 Ys m 9 o R / w p n 9 9 q u P N G y 4 T E Y U X a h T z z t A b h K I v m K e I O r / r n n S L J a f s m G V P A z c D J W S r F h V f c I k e I j C k G I I j h C I c w E N C T x s u H M T E d T A m T h I S J s 5 x j w J p U 8 r i l O E R e 0 3 f A e 3 a G R v S X n s m R s 3 o l I B e S U o b O 6 S J K E 8 S 1 q f Z J p 4 a Z 8 3 + 5 j 0 2 n v p u I / r 7 m d e Q W I U r Y v / S T T L / q 9 O 1 K P R x Z G o Q V F N s G F 0 d y 1 x S 0 x V 9 c / t L V Y o c Y u I 0 7 l F c E m Z G O e m z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 &lt;</head><label>3</label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " N 5 1 1 K z N R Y g Z f D q h v 6 V m U 1 5 8 q g R 0 = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p fV Z d u g k V w V R I V d S U F N 1 1 W t A + o p S T T a R 1 M k 5 B M 1 F I E f 8 C t f p r 4 B / o X 3 h m n o B b R C U n O n H v P m b n 3 + n E g U u k 4 r z l r Z n Z u f i G / W F h a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N H A N K M G s W l R 8 w S V 6 i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W a r e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v VU l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt; x l a t e x i t s h a 1 _ b a s e 6 4 = " x W k f X y D G 9 f I 2 N N m 9 g K O M X e k x 8 N s= " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c cJ 7 4 y 8 Q R T 0 A + Z J o i 7 u u g f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>x 2 &lt;</head><label>2</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0 a L h N L W g Z T R h F h G F X M e t / U n 8 = " &gt; AA A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E 5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z Dh h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>s m 9 o R / w p n 9 9 q u P N G y 4 T E Y U X a h T z z t A b h K I v m K e I O r / r n n S L J a f s m G V P A z c D J W S r F h V f c I k e I j C k G I I j h C I c w E N C T x s u H M T E d T A m T h I S J s 5 x j w J p U 8 r i l O E R e 0 3 f A e 3 a G R v S X n s m R s 3 o l I B e S U o b O 6 S J K E 8 S 1 q f Z J p 4 a Z 8 3 + 5 j 0 2 n v p u I / r 7 m d e Q W I U r Y v / S T T L / q 9 O 1 K P R x Z G o Q V F N s G F 0 d y 1 x S 0 x V 9 c / t L V Y o c Y u I 0 7 l F c E m Z G O e m z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 z T o L F X d g / K 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>s m 9 o R / w p n 9 9 q u P N G y 4 T E Y U X a h T z z t A b h K I v m K e I O r / r n n S L J a f s m G V P A z c D J W S r F h V f c I k e I j C k G I I j h C I c w E N C T x s u H M T E d T A m T h I S J s 5 x j w J p U 8 r i l O E R e 0 3 f A e 3 a G R v S X n s m R s 3 o l I B e S U o b O 6 S J K E 8 S 1 q f Z J p 4 a Z 8 3 + 5 j 0 2 n v p u I / r 7 m d e Q W I U r Y v / S T T L / q 9 O 1 K P R x Z G o Q V F N s G F 0 d y 1 x S 0 x V 9 c / t L V Y o c Y u I 0 7 l F c E m Z G O e m z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 z T o L F X d g / K 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>x 4 &lt;</head><label>4</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " G Y P 0 n m x M + X 4 V m s 2 6 u b / w R j G u Y y o = " &gt; AA A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R K R 6 k o K b r q s a B + g p S T T a R 2 a J m E y U U s R / A G 3 + m n i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 e N A J M p x X n P W 3 P z C 4 l J + u b C y u r a + U d z c a i Z R K h l v s C i I Z N v 3 E h 6 I k D e U U A F v x 5 J 7 I z / g L X 9 4 q u O t G y 4 T E Y U X a h z z z s g b h K I v m K e I O r / r V r r F k l N 2 z L J n g Z u B E r J V j 4o v u E I P E R h S j M A R Q h E O 4 C G h 5 x I u H M T E d T A h T h I S J s 5 x j w J p U 8 r i l OE R O 6 T v g H a X G R v S Xn s m R s 3 o l I B e S U o b e 6 S J K E 8 S 1 q f Z J p 4 a Z 8 3 + 5 j 0 x n v p u Y / r 7 m d e I W I V r Y v / S T T P / q 9 O 1 K P R x b G o Q V F N s G F 0 d y 1 x S 0 x V 9 c / t L V Y o c Y u I 0 7 l F c E m Z G O e 2 z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 y z o H l Q d i t l 9 + y w V D 3 J R p 3 H D n a x T / M 8 Q h U 1 1 N E g 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>3 &lt;</head><label>3</label><figDesc>a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N HA N K M G s W l R 8 w S V 6 i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W ar e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v V U l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt;x l a t e x i t s h a 1 _ b a s e 6 4 = " N y R 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>3 &lt;</head><label>3</label><figDesc>a X l l d K 6 5 v N N I o S x i v s y i I k p b v p T w Q I a 9 L I Q P e i h P u D f 2 A N / 3 r U x V v 3 v A k F V F 4 I U c x 7 w y 9 Q S j 6 g n m S q P O 7 7 n 6 3 W H L K j l 7 2 N H A N K M G s W l R 8 w S V 6i M C Q Y Q i O E J J w A A 8 p P W 2 4 c B A T 1 8 G Y u I S Q 0 H G O e x R I m 1 E W p w y P 2 G v 6 D m j X N m x I e + W Z a j W j U w J 6 E 1 L a 2 C F N R H k J Y X W a r e O Z d l b s b 9 5 j 7 a n u N q K / b 7 y G x E p c E f u X b p L 5 X 5 2 q R a K P Y 1 2 D o J p i z a j q m H H J d F f U z e 0 v V U l y i I l T u E f x h D D T y k m f b a 1 J d e 2 q t 5 6 O v + l M x a o 9 M 7 k Z 3 t U t a c D u z 3 F O g 8 Z e 2 T 0 s u 2 c H p c q J G X U e W 9 j G L s 3 z C B V U U U O d v A d 4 x B O e r a o V W p l 1 + 5 l q 5 Y x m E 9 + W 9 f A B E 4 + Q J Q = = &lt; / l a t e x i t &gt; x l a t e x i t s h a 1 _ b a s e 6 4 = " G Y P 0 n m x M + X 4 V m s 2 6 u b / w R j G u Y y o = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R K R 6 k o K b r q s a B + g p S T T a R 2 a J m E y U U s R / A G 3 + m n i H + h f e G d M Q S 2 i E 5 K c O f e e M 3 P v 9 e N A J M p x X n P W 3 P z C 4 l J + u b C y u r a + U d z c a i Z R K h l v s C i I Z N v 3 E h 6 I k D e U U A F v x 5 J 7 I z / g L X 9 4 q u O t G y 4 T E Y U X a h z z z s g b h K I v m K e I O r / r V r r F k l N 2 z L J n g Z u B E r J V j 4 o v u E I P E R h S j M A R Q h E O 4 C G h 5 x I u H M T E d T A h T h I S J s 5 x j w J p U 8 r i l O E R O 6 T v g H a X G R v S Xn s m R s 3 o l I B e S U o b e 6 S J K E 8 S 1 q f Z J p 4 a Z 8 3 + 5 j 0 x n v p u Y / r 7 m d e I W I V r Y v / S T T P / q 9 O 1K P R x b G o Q V F N s G F 0 d y 1 x S 0 x V 9 c / t L V Y o c Y u I 0 7 l F c E m Z G O e 2 z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 y z o H l Q d i t l 9 + y w V D 3 J R p 3 H D n a x T / M 8 Q h U 1 1 N E g 7 w E e 8 Y R n q 2 a F V m r d f q Z a u U y z j W / L e v g A G q + Q K A = = &lt; / l a t e x i t &gt; x 6 ( , ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " x W k f X y D G 9 f I 2 N N m 9 g K O M X e k x 8 N s = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R d S U F N 1 1 W t A + o p S T T a Q 1 N k z C Z q K U I / o B b / T T x D / Q v v D N O Q S 2 i E5 K c O f e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u g f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>e e M 3 P v 9 Z M w S K X j v O a s u f m F x a X 8 c m F l d W 1 9 o 7 i 5 1 U j j T D B e Z 3 E Y i 5 b v p T w M I l 6 X g Q x 5 K x H c G / k h b / r D M x V v 3 n C R B n F 0 K c c J 7 4 y 8 Q R T 0 A + Z J o i 7 u u o f d Y s k p O 3 r Z s 8 A 1 o A S z a n H x B V f o I Q Z D h h E 4 I k j C I T y k 9 L T h w k F C X A c T 4 g S h Q M c 5 7 l E g b U Z Z n D I 8 Y o f 0 H d C u b d i I 9 s o z 1 W p G p 4 T 0 C l L a 2 C N N T H m C s D r N 1 v F M O y v 2 N + + J 9 l R 3 G 9 P f N 1 4 j Y i W u i f 1 L N 8 3 8 r 0 7 V I t H H i a 4 h o J o S z a j q m H H J d F f U z e 0 v V U l y S I h T u E d x Q Z h p 5 b T P t t a k u n b V W 0 / H 3 3 S m Y t W e m d w M 7 + q W N G D 3 5 z h n Q e O g 7 B 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>x 4 &lt;</head><label>4</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " P 3 Y / p G 4 m l v p L x r N f 2 G U 9 l h Z o c p k = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R L x t Z K C m y 4 r 2 g f U U p L p t A 6 m S U g m a i m C P + B W P 0 3 8 A / 0 L 7 4 x T U I v o h C R n z r 3 n z N x 7 / T g Q q X S c 1 5 w 1 M z s 3 v 5 B f L C w t r 6 y u F d c 3 G m m U J Y z X W R R E S c v 3 U h 6 I k N e l k A F v x Q n 3 h n 7 A m / 7 1 q Y o 3 b 3 i S i i i 8 k K O Y d 4 b e I B R 9 w T x J 1 P l d 9 6 B b L D l l R y 9 7 G r g G l G B W L S q + 4 B I 9 R G D I M A R H C E k 4 g I e U n j Z c O I i J 6 2 B M X E J I 6 D j H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Technical comparison between Mini-Batch Sampling, Pairwise Negative Sampling (NS), and In-Batch Negative Sampling. The blue nodes are hard negatives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: A motivating illustration of BatchSampler, using vision as an example. Uniform Sampler randomly samples a batch of instances, which contains easy negatives. kNN Sampler selects the nearest instances to form a batch, resulting in so many false negatives. BatchSampler samples a mini-batch with hard yet true negatives based on proximity graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " f 5 w 0 a v 1 p 9 6 b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>1 T 4 w u T n e 1 S 1 p w O 7 P c c 6 C 1 k H V P a q 6 j c N K 7 d S M u o g d 7 G K f 5 n m M G i 5 Q R 1 N 7 P + I J z 9 a 5 F V n C y j 9 T r Y L R b O P b s h 4 + A G 0 U j 4 M = &lt; / l a t e x i t &gt; x Input Views Representations &lt; l a t e x i t s h a _ b a s e = " J P p r E m J U p h U b g s W Y W a v P m d c = " &gt; A A A C z n i c j V H L T s J A F D U F + I L d e m m k Z i I q x p L o x i U m A i Z A S D s M O K G z X R K J I S Q f c m c Z / D / w j t j S V R i d J q Z c e / E I l y n N e c t b C t L y S X y s r W s b h W d + p J l E r G a y w K I n n j e w k P R M h r S q i A S S e M / A /</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>e i &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k J F n 3 Y m 7 n k 6 / y qL L + u S X k W H F d z I = " &gt; A A A C z 3 i c j V H L T s J A F D 3 U F + I L d e m m k Z i 4 I q 0 x 6 p L o x i U k 8 k i A k H Y Y s F L a p p 2 q h G D c + g N u 9 a + M f 6 B / 4 Z 1 x S F R i d J q 2 Z8 6 9 5 8 z c e 9 3 I 9 x J h W a 8 Z Y 2 5 + Y X E p u 5 x b W V 1 b 3 8 h v b t W S M I 0 Z r 7 L Q D + O G 6 y T c 9 w J e F Z 7 w e S O K u T N 0 f V 5 3 B 2 c y X r / m c e K F w Y U Y R b w 9 d P q B 1 / O Y I 4 h q t Q S / F W 5 v z C e d q 0 6 + Y B U t t c x Z Y G t Q g F 7 l M P + C F r o I w Z B i C I 4 A g r A P B w k 9 T d i w E B H X x p i 4 m J C n 4 h w T 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>y j 3 T u S n e 5 S 1 p w P b P c c 6 C 2 k H R P i r a l c N C 6 V S P O o s d 7 G K f 5 n m M E s 5 R R p W 8 I z z i C c 9 G x b g x 7 o z 7 z 1 Q j o z X b + L a M h w 8 P 2 J S I &lt; / l a t e x i t &gt; e j Contrastive Loss &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y m b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>r S 3 / A r f 6 X + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 4 9 5 8 7 c e / 0 o E I l yn N c Z a 3 Z u f m E x t 5 R f X l l d W y 9 s b N Y T m c a M 1 5 g M Z N z 0 v Y Q H I u Q 1 J V T A m 1 H M v a E f 8 I Y / O N X x x g 2 P E y H D S z W K e G f o 9 U P R E 8 x T R D V 7 p T b r S r V 3 V S g 6 Z c c s e x q 4 G S g i W 1 V Z e E E b X U g w p B i C I 4 Q i H M B D Q k 8 L L h x E x H U w J i 4 m J E y c 4 x 5 5 8 q a k 4 q T w i B 3 Q t 0 + 7 V s a G t N c 5 E + N m d E p A b 0 x O G 7 v k k a S L C e vT b B N P T W b N / p Z 7 b H L q u 4 3 o 7 2 e 5 h s Q q X B P 7 l 2 + i / K 9 P 1 6 L Q w 7 G p Q V B N k W F 0 d S z L k p q u 6 J v b X 6 p S l C E i T u M u x W P C z D g n f b a N J z G 1 6 9 5 6 J v 5 m l J r V e 5 Z p U 7 z r W 9 K A 3 Z / j n A b 1 / b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>w A e N I k g 4 = &lt; / l a t e x i t &gt; f (?) t e x i t s h a 1 _ b a s e 6 4 = " i C d / T I V 0 T u l u P 2 0 R L 7 o L 3 M v 9 O b Y= " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I R 7 b L g p s u K 9 g G 1 l G Q 6 r a F p E i Y T t R T BH 3 C r n y b + g f 6 F d 8 Y p q E V 0 Q p I z 5 9 5 z Z u 6 9 f h I G q X S c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 m m m c C c Y b L A 5 j 0 f a 9 l I d B x B s y k C F v J 4 J 7 Y z / k L X 9 0 p u K t G y 7 S I I 4 u 5 S T h 3 b E 3 j I J B w D x J 1 M V d r 9 I r l p y y o 5 c 9 D 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>a 1 m v O W F l d W 9 / I b x a 2 t n d 2 9 4 r 7 B 8 1 E p D H j D S Z 8 E b d d J + G + F / K G 9 K T P 2 1 H M n c D 1 e c s d X 6 l 4 a 8 L j x B P h r Z x F v B s 4 w 9 A b e M y R i p r 2 K o V e s W S V L b 3 M Z W B n o</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>7 &lt;</head><label>7</label><figDesc>d l b s b 9 5 z 7 a n u N q O / m 3 k F x E q M i P 1 L t 8 j 8 r 0 7 V I j H A p a 7 B o 5 o i z a j q W O a S 6 q 6 o m 5 t f qp L k E B G n c J / i M W G m l Y s + m 1 q T 6 N p V b x 0 d f 9 O Z i l V7 l u W m e F e 3 p A H b P 8 e 5 D J p n Z f u i b N + c l 6 q 1 b N R 5 H O E Y p z T P C q q o o Y 4 G e Y / w i C c 8 G 9 e G M C b G 9 D P V y G W a Q 3 x b x s M H X q O Q R w = = &lt; / l a t e x i t &gt; x l a t e x i t s h a 1 _ b a s e 6 4 = " x S e m l z 3 w o R s T P u C q 7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>1 &lt;</head><label>1</label><figDesc>a F 5 M Z m o p Q j + g F v 9 N P E P 9 C + 8 M 0 5 B L a I T k p w 5 9 5 4 z c + / 1 0 z D I p O O 8 F q y 5 + Y X F p e J y a W V 1 b X 2 j v L n V y p J c M N 5 k S Z i I S 9 / L e B j E v C k D G f L L V H A v 8 k P e 9 k e n K t 6 + 4 S I L k v h C j l P e j b x h H A w C 5 k m i z u 9 6 b q 9 c c a q O X v Y s c A 2 o w K x G U n 7 B F f p I w J A j A k c M S T i E h 4 y e D l w 4 S I n r Y k K c I B T o O M c 9 S q T N K Y t T h k f s i L 5 D 2 n U M G 9 N e e W Z a z e i U k F 5 B S h t 7 p E k o T x B W p 9 k 6 n m t n x f 7 m P d G e 6 m 5 j + v v G K y J W 4 p r Y v 3 T T z P / q V C 0 S A 5 z o G g K q K d W M q o 4 Z l 1 x 3 R d 3 c / l K V J I e U O I X 7 F B e E m V Z O + 2 x r T a Z r V 7 3 1 d P x N Z y p W 7 Z n J z f G u b k k D d n + O c x a 0 D q r u U d U 9 O 6 z U 6 m b U R e x g F / s 0 z 2 P U U E c D T f I e 4 h F P e L b q V m z l 1 u 1 n q l U w m m 1 8 W 9 b D B x H R k C 0 = &lt; / l a t e x i t &gt; x l a t e x i t s h a 1 _ b a s e 6 4 = " 8 6 i h B K a 7 k M R 9 m O A e J v e 1 C Q y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>6 2 n D h I C a u g w l x k p A w c Y 5 7 F E i b U h a n D I / Y I X 0 H t G t n b E h 7 7 Z k Y N a N T A n o l K W 3 s k S a i P E l Y n 2 a b e G q c N f u b 9 8 R 4 6 r u N 6 e 9 n X i N i F a 6 J / U s 3 z f y v T t e i 0 M e p q U F Q T b F h d H U s c 0 l N V / T N 7 S 9 V K X K I i d O 4 R 3 F J m B n l t M + 2 0 S S m d t 1 b z 8 T f T K Z m 9 Z 5 l u S n e 9 S 1 p w O 7 P c c 6 C x k H Z P S 6 7 5 4 e l S j U b d R 4 7 2 M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>H 3 C r n y b + g f 6 F d 8 Y U 1 C I 6 I c m Z c + 8 5 M / d e P w 5 E o h z n N W f N z S 8 s L u W X C y u r a + s b x c 2 t R h K l k v E 6 i 4 J I t n w v 4 Y E I e V 0 J F f B W L L k 3 8 g P e 9 I d n O t 6 8 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>a k a n B P R K U t r Y I 0 1 E e Z K w P s 0 2 8 d Q 4 a / Y 3 7 4 n x 1 H c b 0 9 / P v E b E K l w T + 5 d u m v l f n a 5 F o Y 9 T U 4 O g m m L D 6 O p Y 5 p K a r u i b 2 1 + q U u Q Q E 6 d x j + K S M D P K a Z 9 t o 0 l M 7 b q 3 n o m / m U z N 6 j 3 L c l O 8 6 1 v S g N 2 f 4 5 w F j Y O y e 1 x 2 z 4 9 K l W o 2 6 j x 2 s I t 9 m u c J K q</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>5 9 5 z Z u 6 9 f h I G q X S c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 m m m c C c Y b L A 5 j 0 f a 9 l I d B x B s y k C F v J 4 J 7 Y z / k L X 9 0 p u K t G y 7 S I I 4 u 5 S T h 3 b E 3 j I J B w D x J 1 M V d r 9 I r l p y y o 5 c 9 D 1 w D S j C r H h d f c I</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>x 6 &lt;</head><label>6</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " B O i F s j M C m e o o a k M 8/ W 2 + W X U U T M U = " &gt; A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z I i 6 r L g p s u K 9 g G 1 l G Q 6 r a F p E i Y T t R T B H 3 C r n y b + g f 6 F d 8 Y p q E V 0 Q p I z5 9 5 z Z u 6 9 f h I G q X S c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 m m m c C c Y b L A 5 j 0 f a 9 l I d B x B s y k C F v J 4 J 7 Y z / k L X 9 0 p u K t G y 7 S I I 4 u 5 S T h 3 b E 3 j I J B w D x J 1 M V d r 9 I r l p y y o 5 c 9 D 1 w D S j C r H h d f c I U + Y j B k G I M j g i Q c w k N K T w c u H C T E d T E l T h A K d J z j H g X S Z p T F K c M j d k T f I e 0 6 h o 1 o r z x T r W Z 0 S k i v I K W N A 9 L E l C c I q 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>x 9 &lt;</head><label>9</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " J t B H K i a S Z v l 3 2 s P k v g 4 h f / 6 H e 2 I = " &gt; AA A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V R I p 6 r L g p s u K 9 g G 1 l G Q 6 r a F p E i Y T t R T B H 3 C r n y b + g f 6 F d 8 Y p q E V 0 Q p I z5 9 5 z Z u 6 9 f h I G q X S c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 m m m c C c Y b L A 5 j 0 f a 9 l I d B x B s y k C F v J 4 J 7 Y z / k L X 9 0 p u K t G y 7 S I I 4 u 5 S T h 3 b E 3 j I J B w D x J 1 M V d r 9 I r l p y y o 5 c 9 D 1 w D S j C r H h d f c I U + Y j B k G I M j g i Q c w k N K T w c u H C T E d T E l T h A K d J z j H g X S Z p T F K c M j d k T f I e 0 6 h o 1 o r z x T r W Z 0 S k i v I K W N A 9 L E l C c I q 9</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The framework of BatchSampler, using the vision modality as an example. The proximity graph is first constructed based on generated image representations and will be updated every ? training step. Next, a proximity graph-based negative sampler is applied to generate a batch with hard negatives for in-batch contrastive learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Cosine similarity and percentage of false negatives among various mini-batch sampling methods on CIFAR10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Cosine similarity and percentage of false negatives among various restart probabilities on CIFAR10. 5.4 Efficiency Analysis Here, we introduce three metrics to analyze the time cost of minibatch sampling by BatchSampler: (1) Batch Sampling Cost (Cost ? ) is the average time of RWR taken to sample a mini-batch from a proximity graph; (2) Proximity Graph Construction Cost (Cost ? ) refers to the time consumption of BatchSampler for constructing a proximity graph; (3) Batch Training Cost (Cost ? ) is the average time taken by the encoder to forward and backward; (4) Proximity Graph Construction Amortized Cost (Cost ?/? ) is the ratio of Cost ? to the graph update interval ?. The time cost of BatchSampler is shown in Table5, from which we make the following observations: (1) Sampling a mini-batch Cost ? takes an order of magnitude less time than training with a batch Cost ? at most cases. (2) Although it takes 100? for BatchSampler to construct a proximity graph in ImageNet, the cost shares across ? training steps, which take only Cost ?/? = 0.2 per batch. A similar phenomenon can be found in other datasets as well. In particular, SimCSE trains for one epoch, and proximity graph is built once.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Percentage of false negatives using different graph building methods over the training step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>B. 8 . 1</head><label>81</label><figDesc>Batchsize ? To analyze the impact of the batchsize ?, we vary ? in the range of {16, 32, 64, 128, 256} and summarize the results in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Figure 8 : 7 Figure 9 :</head><label>879</label><figDesc>Figure 8: Cosine similarity, false negative ratio, and performance comparison on CIFAR100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Histograms of cosine similarity on BERT (top) and RoBERTa (bottom).</figDesc><graphic url="image-110.png" coords="15,53.80,83.69,504.39,163.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Training curves for image classification task on STL10 and ImageNet-100.</figDesc><graphic url="image-111.png" coords="15,60.71,290.31,110.96,97.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 11 :Figure 12 :</head><label>1112</label><figDesc>Figure 11: Histograms of cosine similarity and Percentage of false negative of all pairs in a batch for embeddings trained using different sampling methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head></head><label></label><figDesc>1 ... ? ? } ? D, both GraphCL and SimCSE apply data augmentation to obtain positive pairs, and the loss function for a positive pair (? ? , ? + ? ) can be formulated as: ? ? =log ? ? (? ? ) ? ? (? + ? )/? ? ?=1 ? ? (? ? ) ? ? (? + ? )/? .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Figure 14 :</head><label>14</label><figDesc>Figure 14: Case study of the negatives sampled by Uniform Sampler, kNN Sampler, and BatchSampler based on the encoder trained for 100 epochs on ImageNet. Given an anchor image (Cat or Dog), (Left) in-batch negatives sampled by Uniform Sampler, (Middle) in-batch negatives sampled by kNN Sampler, and (Right) in-batch negatives sampled by BatchSampler based on proximity graph.</figDesc><graphic url="image-114.png" coords="17,53.80,348.77,504.40,65.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 15 :</head><label>15</label><figDesc>Figure 15: Case study of the negatives sampled by Uniform Sampler, kNN Sampler, and BatchSampler on language domain.</figDesc><graphic url="image-115.png" coords="17,53.03,438.99,508.50,141.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Figure 16 :</head><label>16</label><figDesc>Figure 16: A visualization of the process of updating the proximity graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Encoder ? (?), Batchsize ?, Graph update interval ?, Modality-specific augmentation functions T . / Standard Contrastive Pipeline in Different Modalities Load the mini-batch {? ? } ? . Obtain positive pairs {(? ? , ? + ? )} ? by augmentations T . Generate representations {(e ? , e + ? )} ? by Encoder ? (?). Compute the loss by treating {(e ? , e ? )} ??? as negatives.</figDesc><table><row><cell>for iter ? 0, 1, ? ? ? do</cell></row><row><cell>// BatchSampler</cell></row><row><cell>if iter%? == 0 then</cell></row><row><cell>// Proximity Graph Construction</cell></row><row><cell>Build the proximity graph ? by Algorithm 2.</cell></row><row><cell>end</cell></row><row><cell>// Proximity Graph Sampling</cell></row><row><cell>Perform sampling in ? by Algorithm 3.</cell></row></table><note><p>/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Extensive experiments are conducted with 5 algorithms and 19 datasets, a total of 31 experimental settings. Additional experiments are reported in Appendix B, including batchsize ?, neighbor number ?, proximity graph update interval ?, and the training curves. InfoNCE objective and its variants are described in Appendix C. The statistics of the datasets are reported in Appendix D, and the detailed experimental setting can be found in Appendix E.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Table 3 reports the detailed Top-1 accuracy under the linear evaluation with the ResNet-50 backbone on ImageNet.</figDesc><table><row><cell>Method</cell><cell>100 ep</cell><cell>400 ep</cell><cell>800 ep</cell></row><row><cell>SimCLR</cell><cell>64.0</cell><cell>68.1</cell><cell>68.7</cell></row><row><cell>w/ BatchSampler</cell><cell>64.7</cell><cell>68.6</cell><cell>69.2</cell></row><row><cell>MoCo v3</cell><cell>68.9</cell><cell>73.3</cell><cell>73.8</cell></row><row><cell>w/ BatchSampler</cell><cell>69.5</cell><cell>73.7</cell><cell>74.2</cell></row></table><note><p>* Only conduct experiments on BatchSampler.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Overall performance comparison with the BERT backbone on STS tasks.</figDesc><table><row><cell>Method</cell><cell>STS12</cell><cell>STS13</cell><cell>STS14</cell><cell>STS15</cell><cell>STS16</cell><cell>STS-B</cell><cell>SICK-R</cell><cell>Avg.</cell></row><row><cell>SimCSE-BERT ????</cell><cell>68.62</cell><cell>80.89</cell><cell>73.74</cell><cell>80.88</cell><cell>77.66</cell><cell>77.79</cell><cell>69.64</cell><cell>75.60</cell></row><row><cell>w/ kNN Sampler</cell><cell>63.62</cell><cell>74.86</cell><cell>69.79</cell><cell>79.17</cell><cell>76.24</cell><cell>74.73</cell><cell>67.74</cell><cell>72.31</cell></row><row><cell>w/ BatchSampler</cell><cell>72.37</cell><cell>82.08</cell><cell>75.24</cell><cell>83.10</cell><cell>78.43</cell><cell>77.54</cell><cell>68.05</cell><cell>76.69</cell></row><row><cell>DCL-BERT ????</cell><cell>65.22</cell><cell>77.89</cell><cell>68.94</cell><cell>79.88</cell><cell>76.72</cell><cell>73.89</cell><cell>69.54</cell><cell>73.15</cell></row><row><cell>w/ kNN Sampler</cell><cell>66.34</cell><cell>76.66</cell><cell>72.60</cell><cell>78.30</cell><cell>74.86</cell><cell>73.65</cell><cell>67.92</cell><cell>72.90</cell></row><row><cell>w/ BatchSampler</cell><cell>69.55</cell><cell>82.66</cell><cell>73.37</cell><cell>80.40</cell><cell>75.37</cell><cell>75.43</cell><cell>66.76</cell><cell>74.79</cell></row><row><cell>HCL-BERT ????</cell><cell>62.57</cell><cell>79.12</cell><cell>69.70</cell><cell>78.00</cell><cell>75.11</cell><cell>73.38</cell><cell>69.74</cell><cell>72.52</cell></row><row><cell>w/ kNN Sampler</cell><cell>61.12</cell><cell>75.73</cell><cell>68.43</cell><cell>76.64</cell><cell>74.78</cell><cell>71.22</cell><cell>68.04</cell><cell>70.85</cell></row><row><cell>w/ BatchSampler</cell><cell>66.87</cell><cell>81.38</cell><cell>72.96</cell><cell>80.11</cell><cell>77.99</cell><cell>75.95</cell><cell>70.89</cell><cell>75.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Accuracy on graph classification task under LIBSVM<ref type="bibr" target="#b8">[9]</ref> classifier.</figDesc><table><row><cell>Method</cell><cell>IMDB-B</cell><cell>IMDB-M</cell><cell>COLLAB</cell><cell>REDDIT-B</cell><cell>PROTEINS</cell><cell>MUTAG</cell><cell>NCI1</cell></row><row><cell>GraphCL</cell><cell>70.90?0.53</cell><cell>48.48?0.38</cell><cell>70.62?0.23</cell><cell>90.54?0.25</cell><cell>74.39?0.45</cell><cell>86.80?1.34</cell><cell>77.87?0.41</cell></row><row><cell>w/ kNN Sampler</cell><cell>70.72?0.35</cell><cell>47.97?0.97</cell><cell>70.59?0.14</cell><cell>90.21?.74</cell><cell>74.17?0.41</cell><cell>86.46?0.82</cell><cell>77.27?0.37</cell></row><row><cell>w/ BatchSampler</cell><cell>71.90?0.46</cell><cell>48.93?0.28</cell><cell>71.48?0.28</cell><cell>90.88?0.16</cell><cell>75.04?0.67</cell><cell>87.78?0.93</cell><cell>78.93?0.38</cell></row><row><cell>DCL</cell><cell>71.07?0.36</cell><cell>48.93?0.32</cell><cell>71.06?0.51</cell><cell>90.66?0.29</cell><cell>74.64?0.48</cell><cell>88.09?0.93</cell><cell>78.49?0.48</cell></row><row><cell>w/ kNN Sampler</cell><cell>70.94?0.19</cell><cell>48.47?0.35</cell><cell>70.49?0.37</cell><cell>90.26?1.03</cell><cell>74.28?0.17</cell><cell>87.13?1.40</cell><cell>78.13?0.52</cell></row><row><cell>w/ BatchSampler</cell><cell>71.32?0.17</cell><cell>48.96?0.25</cell><cell>70.44?0.35</cell><cell>90.73?0.34</cell><cell>75.02?0.61</cell><cell>89.47?1.43</cell><cell>79.03?0.32</cell></row><row><cell>HCL</cell><cell>71.24?0.36</cell><cell>48.54?0.51</cell><cell>71.03?0.45</cell><cell>90.40?0.42</cell><cell>74.69?0.42</cell><cell>87.79?1.10</cell><cell>78.83?0.67</cell></row><row><cell>w/ kNN Sampler</cell><cell>71.14?0.44</cell><cell>48.36?0.93</cell><cell>70.86?0.74</cell><cell>90.64?0.51</cell><cell>74.06?0.44</cell><cell>87.53?1.37</cell><cell>78.66?0.48</cell></row><row><cell>w/ BatchSampler</cell><cell>71.20?0.38</cell><cell>48.76?0.39</cell><cell>71.70?0.35</cell><cell>91.25?0.25</cell><cell>75.11?0.63</cell><cell>88.31?1.29</cell><cell>79.17?0.27</cell></row><row><cell>MVGRL</cell><cell>74.20?0.70</cell><cell>51.20?0.50</cell><cell>-</cell><cell>84.50?0.60</cell><cell>-</cell><cell>89.70?1.10</cell><cell>-</cell></row><row><cell>w/ kNN Sampler</cell><cell>73.30?0.34</cell><cell>50.70?0.36</cell><cell>-</cell><cell>82.70?0.67</cell><cell>-</cell><cell>85.08?0.66</cell><cell>-</cell></row><row><cell>w/ BatchSampler</cell><cell>76.70?0.35</cell><cell>52.40?0.39</cell><cell>-</cell><cell>87.47?0.79</cell><cell>-</cell><cell>91.13?0.81</cell><cell>-</cell></row></table><note><p><p>* </p>The results not reported are due to the unavailable code or out-of-memory caused by the backbone model itself.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Empirical criterion for BatchSampler on neighbor candidate size ? and restart probability ?. 93?.28 48.68?.35 48.88?.94 48.71?.93 48.12?.75 48.48?1.07 48.27?.67 48.72?.41 48.78?.60 48.93?.28 COLLAB 70.47?.33 71.48?.28 70.93?.50 70.46?.28 70.24?.56 70.36?.28 70.63?.53 70.63?.54 70.31?.37 71.48?.28 REDDIT-B 90.88?.16 89.45?.99 90.64?.38 89.92?.75 90.37?.89 90.22?.38 89.51?.61 90.44?.48 90.28?.89 90.88?.16</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Neighbor Candidate Size ?</cell><cell></cell><cell></cell><cell cols="3">Restart Probability ?</cell><cell></cell></row><row><cell>Modality</cell><cell>Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>500</cell><cell>1000</cell><cell>2000</cell><cell>4000</cell><cell>6000</cell><cell>0.1</cell><cell>0.3</cell><cell>0.5</cell><cell>0.7</cell><cell>0.2?0.05</cell></row><row><cell></cell><cell>CIFAR10</cell><cell>92.54</cell><cell>92.49</cell><cell>91.83</cell><cell>91.72</cell><cell>91.43</cell><cell>92.41</cell><cell>92.26</cell><cell>92.12</cell><cell>92.06</cell><cell>92.54</cell></row><row><cell>Image</cell><cell>CIFAR100</cell><cell>67.92</cell><cell>68.68</cell><cell>67.05</cell><cell>66.19</cell><cell>65.55</cell><cell>68.31</cell><cell>67.98</cell><cell>68.20</cell><cell>68.00</cell><cell>68.68</cell></row><row><cell></cell><cell>STL10</cell><cell>84.16</cell><cell>84.38</cell><cell>82.80</cell><cell>81.91</cell><cell>80.92</cell><cell>83.01</cell><cell>80.69</cell><cell>83.93</cell><cell>82.56</cell><cell>84.38</cell></row><row><cell></cell><cell>ImageNet-100</cell><cell>59.6</cell><cell>60.8</cell><cell>60.1</cell><cell>59.1</cell><cell>58.4</cell><cell>60.8</cell><cell>59.6</cell><cell>58.1</cell><cell>57.7</cell><cell>60.8</cell></row><row><cell>Text</cell><cell>Wikipedia</cell><cell>71.36</cell><cell>76.69</cell><cell>76.09</cell><cell>75.76</cell><cell>75.11</cell><cell>71.74</cell><cell>72.13</cell><cell>72.41</cell><cell>76.69</cell><cell>-</cell></row><row><cell></cell><cell>IMDB-B</cell><cell cols="10">71.90?.46 71.28?.51 71.13?.48 70.86?.56 70.68?.59 71.26?.29 71.00?.46 71.06?.21 70.78?.58 71.90?.46</cell></row><row><cell>Graph</cell><cell>IMDB-M</cell><cell>48.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>The time cost of mini-batch sampling by BatchSampler on an NVIDIA V100 GPU.</figDesc><table><row><cell>Metric</cell><cell>STL10</cell><cell>ImageNet-100</cell><cell>Wikipedia</cell><cell>ImageNet</cell></row><row><cell>Cost ?</cell><cell>0.013s</cell><cell>0.015s</cell><cell>0.005</cell><cell>0.15s</cell></row><row><cell>Cost ?</cell><cell>2s</cell><cell>3s</cell><cell>79s</cell><cell>100s</cell></row><row><cell>Cost ?</cell><cell>0.55s</cell><cell>1.1s</cell><cell>0.08s</cell><cell>1.1s</cell></row><row><cell cols="5">Cost ?/? 0.02(? = 100) 0.03(? = 100) 0.005(? = 15625) 0.2(? = 500)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Overall performance comparison with different graph sampling methods. It can be observed that although BFS brings the most similar pairs in the mini-batch, it performs worse than the original SimCLR since it introduces substantial false negatives. While having a slightly lower percentage of false negatives than RWR, DFS, and RW do not exhibit higher performance since they are unable to collect the hard negatives in the mini-batch. The restart property allows RWR to exhibit a mixture of DFS and BFS, which can flexibly modulate the hardness of the sampled batch and find the best balance between hard negatives and false negatives. Figure 6: Histograms of cosine similarity and percentage of false negatives in a batch using different sampling methods.Proximity Graph vs. kNN Graph. To demonstrate the effectiveness of proximity graph, we do an ablation study by replacing proximity graph with kNN graph which directly selects ? neighbors with the highest scores for each instance from the whole dataset. The neighbor number ? is 100 by default. The comparison results are shown in Table7, from which we can observe that proximity graph outperforms the kNN graph by a margin. BatchSampler with kNN graph even performs worse than the original contrastive learning method because of the false negatives.</figDesc><table><row><cell></cell><cell></cell><cell>Vision</cell><cell></cell><cell>Language</cell><cell cols="2">Graphs</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">CIFAR10 CIFAR100 STL10 Wikipedia IMDB-B COLLAB</cell></row><row><cell>BFS</cell><cell>91.03</cell><cell>65.15</cell><cell>77.08</cell><cell>74.39</cell><cell>70.48</cell><cell>69.98</cell></row><row><cell>DFS</cell><cell>92.14</cell><cell>68.29</cell><cell>83.05</cell><cell>73.40</cell><cell>71.12</cell><cell>70.60</cell></row><row><cell>RW</cell><cell>92.28</cell><cell>68.33</cell><cell>83.54</cell><cell>75.56</cell><cell>71.26</cell><cell>70.72</cell></row><row><cell>RWR</cell><cell>92.54</cell><cell>68.68</cell><cell>84.38</cell><cell>76.69</cell><cell>71.90</cell><cell>71.48</cell></row><row><cell cols="4">5.5 Further Analysis</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Strategies of Proximity Graph Sampling. We conduct experi-</cell></row><row><cell cols="7">ments to explore different choices of graph sampling methods, in-</cell></row><row><cell cols="7">cluding (1) Depth First Search (DFS); (2) Breadth First Search (BFS);</cell></row><row><cell cols="7">(3) Random Walk (RW); (4) Random Walk with Restart (RWR). Ta-</cell></row><row><cell cols="7">ble 6 presents an overall performance comparison with different</cell></row><row><cell cols="7">graph sampling methods. As expected, RWR consistently achieves</cell></row><row><cell cols="7">better performance since it samples hard yet true negatives within</cell></row><row><cell cols="7">a local cluster on proximity graph. Besides, we illustrate the his-</cell></row><row><cell cols="7">tograms of cosine similarity for all pairs from a sampled batch and</cell></row><row><cell cols="7">plot the corresponding percentage of false negatives during training</cell></row><row><cell cols="2">in Figure 6.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Performance comparison of different graph construction methods.</figDesc><table><row><cell></cell><cell cols="2">Vision</cell><cell>Language</cell><cell cols="2">Graphs</cell></row><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">CIFAR10 CIFAR100 Wikipedia IMDB-B COLLAB</cell></row><row><cell>Default</cell><cell>92.13</cell><cell>68.14</cell><cell>75.60</cell><cell>70.90</cell><cell>70.62</cell></row><row><cell>kNN graph</cell><cell>90.47</cell><cell>62.67</cell><cell>75.13</cell><cell>70.10</cell><cell>69.96</cell></row><row><cell cols="2">proximity graph 92.54</cell><cell>68.68</cell><cell>76.69</cell><cell>71.90</cell><cell>71.48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>we present the details of Proximity Graph Construction and Random Walk with Restart, as shown in Algorithm 2 and Algorithm 3 respectively. Random Walk with Restart(RWR) Input: Proximity graph ? = {V, E}, seed node ?, restart probability ?, number of sampled node ?;</figDesc><table><row><cell>Algorithm 2: Proximity Graph Construction</cell></row><row><cell>Input: Dataset D = {? ? }, Candidate set size ?, Neighbor</cell></row><row><cell>number ?;</cell></row><row><cell>Output: A proximity graph ?;</cell></row><row><cell>for ? in D do</cell></row><row><cell>Randomly select ? neighbor candidates from D;</cell></row><row><cell>Select the ? closest candidates N ? by Eq. 3;</cell></row><row><cell>? [?] ? N ? ;</cell></row><row><cell>end</cell></row><row><cell>return ?</cell></row><row><cell>Algorithm 3: Output: A sampled node set S;</cell></row><row><cell>S ? {}, ? ? ?;</cell></row><row><cell>while len(S) &lt; ? do</cell></row><row><cell>if ? not in S then</cell></row><row><cell>S.insert(?)</cell></row><row><cell>end</cell></row><row><cell>Sample ? from Uniform distribution ? (0, 1);</cell></row><row><cell>if ? &lt; ? then ? ? ?;</cell></row><row><cell>end</cell></row><row><cell>else</cell></row><row><cell>Randomly sample v from ?'s neighbors;</cell></row><row><cell>? ? v;</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>return S</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Overall performance comparison on image classification task in terms of Top-1 Accuracy.</figDesc><table><row><cell>Method</cell><cell cols="4">CIFAR10 CIFAR100 STL10 ImageNet-100</cell></row><row><cell>SimCLR</cell><cell>92.13</cell><cell>68.14</cell><cell>83.26</cell><cell>59.30</cell></row><row><cell>w/ kNN Sampler</cell><cell>90.16</cell><cell>62.30</cell><cell>79.25</cell><cell>57.70</cell></row><row><cell>w/ BatchSampler</cell><cell>92.54</cell><cell>68.68</cell><cell>84.38</cell><cell>60.80</cell></row><row><cell>DCL</cell><cell>92.28</cell><cell>68.52</cell><cell>84.92</cell><cell>59.90</cell></row><row><cell>w/ BatchSampler</cell><cell>92.74</cell><cell>68.91</cell><cell>86.39</cell><cell>60.14</cell></row><row><cell>HCL</cell><cell>92.39</cell><cell>68.92</cell><cell>88.20</cell><cell>60.60</cell></row><row><cell>w/ BatchSampler</cell><cell>92.41</cell><cell>69.13</cell><cell>89.49</cell><cell>61.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Performance comparison for sentence embedding learning based on RoBERTa.</figDesc><table><row><cell>Method</cell><cell>STS12 STS13 STS14 STS15 STS16 STS-B SICK-R Avg.</cell></row><row><cell cols="2">SimCSE-RoBERTa ???? 67.90 80.91 73.14 80.58 80.74 80.26 69.87 76.20</cell></row><row><cell>w/ kNN Sampler</cell><cell>68.78 79.49 73.34 81.05 80.15 77.09 67.18 75.30</cell></row><row><cell>w/ BatchSampler</cell><cell>68.29 81.96 73.86 82.16 80.94 80.77 69.30 76.75</cell></row><row><cell>DCL-RoBERTa ????</cell><cell>66.60 79.16 71.05 80.40 77.76 77.94 67.57 74.35</cell></row><row><cell>w/ kNN Sampler</cell><cell>65.39 79.04 69.71 78.37 75.98 74.72 64.39 72.51</cell></row><row><cell>w/ BatchSampler</cell><cell>65.53 80.09 71.00 80.64 78.35 77.75 67.52 74.41</cell></row><row><cell>HCL-RoBETa ????</cell><cell>67.20 80.47 72.44 80.88 80.57 78.79 67.98 75.49</cell></row><row><cell>w/ kNN Sampler</cell><cell>65.99 77.32 73.71 80.59 79.78 77.70 65.40 74.36</cell></row><row><cell>w/ BatchSampler</cell><cell>66.01 80.79 73.58 81.25 80.66 79.22 68.52 75.72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Performance comparison of different batchsize ?. Proximity Graph Update Interval ? Proximity graph will be updated per ? training iterations, and to analyze the impact of ?, we vary ? in the range of {50,100,200,400} for vision and {10,25,50,100} for graphs respectively. Table12summarizes the experimental results on different update interval ?. It can be observed that update intervals that are too short or too long will degrade the performance. The possible reason is that sampling on a proximity graph that is frequently updated results in unstable learning of the model.</figDesc><table><row><cell></cell><cell></cell><cell>Vision</cell><cell></cell><cell>Language</cell><cell cols="2">Graphs</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">CIFAR10 CIFAR100 STL10 Wikipedia IMDB-B COLLAB</cell></row><row><cell>16</cell><cell>79.93</cell><cell>46.69</cell><cell>56.31</cell><cell>76.26</cell><cell>71.50</cell><cell>71.32</cell></row><row><cell>32</cell><cell>84.64</cell><cell>56.24</cell><cell>68.61</cell><cell>74.16</cell><cell>71.60</cell><cell>71.40</cell></row><row><cell>64</cell><cell>89.09</cell><cell>61.30</cell><cell>74.24</cell><cell>76.69</cell><cell>71.65</cell><cell>71.42</cell></row><row><cell>128</cell><cell>91.03</cell><cell>65.96</cell><cell>82.56</cell><cell>76.64</cell><cell>71.83</cell><cell>71.48</cell></row><row><cell cols="2">256 92.54</cell><cell>68.68</cell><cell>84.38</cell><cell>76.11</cell><cell>71.90</cell><cell>71.35</cell></row><row><cell cols="7">Such experimental results are consistent with our prior philosophy,</cell></row><row><cell cols="7">in which sampling more neighbors always increases the scale of</cell></row><row><cell cols="7">proximity graph and urges BatchSampler to explore smaller-scope</cell></row><row><cell cols="7">local clusters (i.e. sample harder negatives within a batch), leading</cell></row><row><cell cols="7">to a significant improvement in performance at first. However, per-</cell></row><row><cell cols="7">formance degrades after reaching the optimum, because larger ?</cell></row><row><cell cols="4">introduces more easy negatives.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>B.8.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Besides, the distribution of instances in the embedding space will change during the training process, resulting in a shift in hard negatives. As a result, after a few iterations, the lazy-updated graph cannot adequately capture the similarity relationship.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Performance comparison with different update interval ? on vision and graph modality.</figDesc><table><row><cell></cell><cell>Update Interval ?</cell><cell>50</cell><cell>100</cell><cell>200</cell><cell>400</cell></row><row><cell>Vision</cell><cell>CIFAR10</cell><cell cols="2">92.29 92.54</cell><cell>92.34</cell><cell>92.26</cell></row><row><cell></cell><cell>CIFAR100</cell><cell cols="2">68.37 68.68</cell><cell>67.83</cell><cell>68.59</cell></row><row><cell></cell><cell>Update Interval ?</cell><cell>10</cell><cell>25</cell><cell>50</cell><cell>100</cell></row><row><cell>Graphs</cell><cell>IMDB-B</cell><cell cols="2">71.30 71.90</cell><cell>71.40</cell><cell>71.10</cell></row><row><cell></cell><cell>COLLAB</cell><cell>71.06</cell><cell>70.36</cell><cell cols="2">71.48 70.62</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>Statistics of datasets for image classification task.</figDesc><table><row><cell cols="6">Datasets CIFAR10 CIFAR100 STL10 ImageNet-100 ImageNet</cell></row><row><cell cols="2">#Train 50,000</cell><cell cols="2">50,000 105,000</cell><cell>130,000</cell><cell>1,281,167</cell></row><row><cell>#Test</cell><cell>10,000</cell><cell>10,000</cell><cell>8,000</cell><cell>50,00</cell><cell>50,000</cell></row><row><cell>#Classes</cell><cell>10</cell><cell>100</cell><cell>10</cell><cell>100</cell><cell>1,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>Statistics of datasets for graph-level classification task.</figDesc><table><row><cell cols="8">Datasets IMDB-B IMDB-M COLLAB REDDIT-B PROTEINS MUTAG NCI1</cell></row><row><cell>#Graphs</cell><cell>1,000</cell><cell>1,500</cell><cell>5,000</cell><cell>2,000</cell><cell>1,113</cell><cell cols="2">188 4,110</cell></row><row><cell>#Classes</cell><cell>2</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell cols="2">Avg. #nodes 19.8</cell><cell>13.0</cell><cell>74.5</cell><cell>429.7</cell><cell>39.1</cell><cell cols="2">17.9 29.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 15 :</head><label>15</label><figDesc>Hyperparameter settings for graph-level representation learning.</figDesc><table><row><cell cols="8">Datasets IMDB-B IMDB-M COLLAB REDDIT-B PROTEINS MUTAG NCI1</cell></row><row><cell>?</cell><cell>256</cell><cell>128</cell><cell>128</cell><cell>128</cell><cell>128</cell><cell>128</cell><cell>128</cell></row><row><cell>Epoch</cell><cell>100</cell><cell>50</cell><cell>20</cell><cell>50</cell><cell>20</cell><cell>20</cell><cell>20</cell></row><row><cell>?</cell><cell>25</cell><cell>25</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell></row><row><cell>?</cell><cell>500</cell><cell>500</cell><cell>1,000</cell><cell>500</cell><cell>500</cell><cell cols="2">100 1000</cell></row><row><cell>?</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>50</cell><cell>100</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://huggingface.co/models</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by <rs type="funder">Technology and Innovation Major Project of the Ministry of Science and Technology of China</rs> under Grant <rs type="grantNumber">2020AAA0108400</rs> and <rs type="grantNumber">2020AAA0108402</rs>, <rs type="funder">NSF of China for Distinguished Young Scholars</rs> (<rs type="grantNumber">61825602</rs>), <rs type="funder">NSF of China</rs> (<rs type="grantNumber">62276148</rs>), and a research fund from Zhipu.AI.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8XMmnd2">
					<idno type="grant-number">2020AAA0108400</idno>
				</org>
				<org type="funding" xml:id="_HVEusGz">
					<idno type="grant-number">2020AAA0108402</idno>
				</org>
				<org type="funding" xml:id="_Nfumnha">
					<idno type="grant-number">61825602</idno>
				</org>
				<org type="funding" xml:id="_AA7aguj">
					<idno type="grant-number">62276148</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Performance Analysis on CIFAR100</head><p>Here we compare the Uniform Sampler, kNN Sampler, and Batch-Sampler regarding cosine similarity, false negatives, and performance comparison on CIFAR100. Specifically, we show the histogram of cosine similarity for all pairs in a sampled batch, the false negative ratio of the mini-batch, and performance comparison between BatchSampler and other two sampling strategies (e.g. Uniform Sampler and kNN Sampler) in Figure <ref type="figure">8</ref>. It can be found that BatchSampler exhibits a balance of Uniform Sampler and kNN Sampler, which can sample the hard negative pair but only brings a slightly greater number of false negatives than Uniform Sampler. More analysis can be found in Section 5.2.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on interpretability</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Montse</forename><surname>Maritxalar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
	<note>In SemEval&apos;15</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SemEval-2014 Task 10: Multilingual Semantic Textual Similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Se-mEval&apos;14</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semeval-2016 task 1: Semantic textual similarity, monolingual and cross-lingual evaluation</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Rigau Claramunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>In SemEval&apos;16</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 6: A pilot on semantic textual similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval&apos;12</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">* SEM 2013 shared task: Semantic textual similarity</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>In SemEval&apos;13. 32-43</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Local graph partitioning using pagerank vectors</title>
		<author>
			<persName><forename type="first">Reid</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Personalized pagerank with node-dependent restart</title>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Avrachenkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Remco Van Der Hofstad</surname></persName>
		</author>
		<author>
			<persName><surname>Sokol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WAW&apos;14</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;20</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9912" to="9924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector</title>
		<author>
			<persName><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIST&apos;</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;20</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An empirical study of training self-supervised vision transformers</title>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9640" to="9649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Debiased Contrastive Learning</title>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Yen-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NIPS&apos;20</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finding and visualizing graph clusters using pagerank optimization</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tsiatas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WAW&apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="86" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PageRank and random walks on graphs</title>
		<author>
			<persName><forename type="first">Fan</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fete of combinatorics and computer science</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="43" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL&apos;19</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Simcse: Simple contrastive learning of sentence embeddings</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingcheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;16</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise-Contrastive Estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS&apos;10</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Contrastive multi-view representation learning on graphs</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Hosein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khasahmadi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4116" to="4126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In CVPR&apos;20</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;16</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Embeddingbased retrieval in facebook search</title>
		<author>
			<persName><forename type="first">Jui-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuying</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Pronin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janani</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Ottaviano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
		<idno>KDD&apos;20. 2553-2561</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems</title>
		<author>
			<persName><forename type="first">Tinglin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenzheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Boosting contrastive self-supervised learning with false negative cancellation. In WACV&apos;22</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matthew R Walter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maryam</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><surname>Khademi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2785" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A survey on contrastive self-supervised learning</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Ashwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Zaki</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debapriya</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fillia</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><surname>Makedon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technologies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Billion-scale similarity search with GPUs</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Hard Negative Mixing for Contrastive Learning</title>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bulent</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noe</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Pion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName><surname>Larlus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NIPS&apos;20</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for opendomain question answering</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barlas</forename><surname>O?uz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP&apos;20</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;15</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The art of computer programming: Fundamental Algorithms</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Ervin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Knuth</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Pearson Education</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A SICK cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC&apos;14</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Coco-lm: Correcting and contrasting text sequences for language model pretraining</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Payal</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>In NIPS&apos;21</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">2017. graph2vec: Learning distributed representations of graphs</title>
		<author>
			<persName><forename type="first">Annamalai</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahinthan</forename><surname>Chandramohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajasekar</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shantanu</forename><surname>Jaiswal</surname></persName>
		</author>
		<idno>MLG&apos;17</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The PageRank citation ranking: Bringing order to the web</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University Technical</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep graph infomax</title>
		<author>
			<persName><forename type="first">Veli?kovi?</forename><surname>Petar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;19</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Gcc: Graph contrastive coding for graph neural network pre-training</title>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In KDD&apos;20. 1150-1160</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Contrastive Learning with Hard Negative Samples</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno>ICLR&apos;21</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A local clustering algorithm for massive graphs and its application to nearly linear time graph partitioning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shang-Hua</forename><surname>Spielman</surname></persName>
		</author>
		<author>
			<persName><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on computing</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization</title>
		<author>
			<persName><forename type="first">Fan-Yun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;20</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Hard negative sampling strategies for contrastive representation learning</title>
		<author>
			<persName><forename type="first">Afrina</forename><surname>Tabassum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muntasir</forename><surname>Wahed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoda</forename><surname>Eldardiry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismini</forename><surname>Lourentzou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01197</idno>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Ecnu at semeval-2017 task 1: Leverage kernel-based traditional nlp features and neural networks to build a universal model for multilingual and cross-lingual semantic textual similarity</title>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>In SemEval&apos;17. 191-197</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fast random walk with restart and its applications</title>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia-Yu</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Solving inefficiency of self-supervised representation learning</title>
		<author>
			<persName><forename type="first">Guangrun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangcong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Hs Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9505" to="9515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Conditional negative sampling for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Mosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxu</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;21</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Enabling on-device self-supervised contrastive learning with selective data contrast</title>
		<author>
			<persName><forename type="first">Yawen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhepeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dewen</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingtong</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 58th ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="655" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Zhuofeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15466</idno>
		<title level="m">Contrastive learning for sentence representation</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR&apos;18</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Approximate nearest neighbor negative contrastive learning for dense text retrieval</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
		<idno>ICLR&apos;21</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Infogcl: Information-aware graph contrastive learning</title>
		<author>
			<persName><forename type="first">Dongkuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="30414" to="30425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;19</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName><forename type="first">Pinar</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;15</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Understanding negative sampling in graph representation learning</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;20</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1666" to="1676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;18</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Graph contrastive learning automated</title>
		<author>
			<persName><forename type="first">Yuning</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12121" to="12132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Graph Contrastive Learning with Augmentations</title>
		<author>
			<persName><forename type="first">Yuning</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongduo</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;20</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5812" to="5823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Large batch optimization for deep learning</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sashank</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Hseu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinadh</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00962</idno>
	</analytic>
	<monogr>
		<title level="m">Training bert in 76 minutes</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Graph information bottleneck for subgraph recognition</title>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR&apos;21</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Recognizing predictive substructures with subgraph information bottleneck</title>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yatao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">M-Mix: Generating Hard Negatives via Multi-sample Mixing for Contrastive Learning</title>
		<author>
			<persName><forename type="first">Shaofeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingxiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pinyan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2461" to="2470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Optimizing top-n collaborative filtering via dynamic negative item sampling</title>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;13</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="785" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Weakly supervised contrastive learning</title>
		<author>
			<persName><forename type="first">Mingkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV&apos;21</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10042" to="10051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Debiased Contrastive Learning of Unsupervised Sentence Representations</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL&apos;22</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">An empirical study of graph contrastive learning</title>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01116</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with adaptive augmentation</title>
		<author>
			<persName><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2069" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">On the np-completeness of some graph cluster measures</title>
		<author>
			<persName><forename type="first">Ji??</forename><surname>??ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Satu</surname></persName>
		</author>
		<author>
			<persName><surname>Schaeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Current Trends in Theory and Practice of Computer Science</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
