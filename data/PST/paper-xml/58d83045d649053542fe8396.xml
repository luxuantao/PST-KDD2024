<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Impact of Feature Selection on Defect Prediction Performance: An Empirical Comparison</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhou</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Engineering</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan, Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Liu</surname></persName>
							<email>jinliu@whu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Engineering</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan, Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijiang</forename><surname>Yang</surname></persName>
							<email>zijiang.yang@wmich.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Engineering</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan, Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Western Michigan University</orgName>
								<address>
									<settlement>Kalamazoo</settlement>
									<region>Michigan</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gege</forename><surname>An</surname></persName>
							<email>gegean@whu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Xiangyang</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Engineering</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan, Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Impact of Feature Selection on Defect Prediction Performance: An Empirical Comparison</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6AA97494CD6389A29EC49765D8D408CA</idno>
					<idno type="DOI">10.1109/ISSRE.2016.13</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>defect prediction</term>
					<term>feature selection</term>
					<term>Scott-Knott test</term>
					<term>2016 IEEE 27th International Symposium on Software Reliability Engineering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Software defect prediction aims to determine whether a software module is defect-prone by constructing prediction models. The performance of such models is susceptible to the high dimensionality of the datasets that may include irrelevant and redundant features. Feature selection is applied to alleviate this issue. Because many feature selection methods have been proposed, there is an imperative need to analyze and compare these methods. Prior empirical studies may have potential controversies and limitations, such as the contradictory results, usage of private datasets and inappropriate statistical test techniques. This observation leads us to conduct a careful empirical study to reinforce the confidence of the experimental conclusions by considering several potential source of bias, such as the noise in the dataset and the dataset types. In this paper, we investigate the impact of 32 feature selection methods on the defect prediction performance over two versions of the NASA dataset (i.e., the noisy and clean NASA datasets) and one open source AEEEM dataset. We use a state-of-the-art double Scott-Knott test technique to analyze these methods. Experimental results show that the effectiveness of these feature selection methods on defect prediction performance varies significantly over all the datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Software defect prediction utilizes historical defect data mined from software repositories to determine the quality of software modules for software quality assurance (SQA). Defect prediction can be reviewed as a binary classification problem, i.e., building a prediction model with software metrics (i.e., features) to label new software modules as defect-prone or not <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>.</p><p>In defect prediction, each software module is characterized by a class label and a set of metrics. The class label denotes whether this module is defective. The metrics are used to build classification models. Effective defect prediction can help SQA team efficiently inspect the potentially defective modules by allocating more software development and maintenance resources <ref type="bibr" target="#b41">[42]</ref>.</p><p>Due to the increased prevalence of data mining and machine learning, a number of classification models have * Corresponding author been introduced during the past decade <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Nevertheless, a challenge that threatens the modeling process is the high dimensionality of defect datasets, i.e., datasets with excessive features including irrelevant and redundant ones. Existing studies have shown that the high dimensionality problem can lead to extensive computational cost and degradation of the performance of certain specific models <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b71">[73]</ref>. For the foregoing reasons, a variety of feature selection methods were proposed to alleviate this issue of high dimensionality by eliminating irrelevant and redundant features.</p><p>Feature selection aims to select a feature subset to replace the original feature set <ref type="bibr" target="#b10">[11]</ref>. This feature subset is more effective to distinguish the class labels of software modules. The mainstreams of current research topics focus on proposing and evaluating the effectiveness of a new feature selection method on the performance of defect prediction models. Since there exist a vast variety of feature selection methods, it is critical to compare the effectiveness of different feature selection methods and identify the effective ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>Despite that some researchers have conducted empirical studies to explore the impact of feature selection on the defect prediction performance <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b72">[74]</ref>, <ref type="bibr" target="#b73">[75]</ref>, the findings of previous studies are not always consistent regarding the superiority of one feature selection method over others. For example, Gao et al <ref type="bibr" target="#b72">[74]</ref> explored the effectiveness of seven feature ranking methods and four feature subset selection methods on a private defect dataset. The results showed that Chi-Square method performs the worst. Wang et al. <ref type="bibr" target="#b73">[75]</ref> investigated the effectiveness of six feature ranking methods and two ensemble methods on a private dataset and two open source datasets. The results indicated that Chi-Square method has very good performance. Using different datasets may be the main reason for the inconsistent results <ref type="bibr" target="#b2">[3]</ref>.</p><p>In addition, the results of prior studies <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b72">[74]</ref>, <ref type="bibr" target="#b73">[75]</ref> show that the effectiveness of different feature selection methods are not significantly different from each other. These findings may be susceptible to the statistical test techniques used, such as the Nemenyi test in <ref type="bibr" target="#b9">[10]</ref> and Tukey's honestly significant difference test in <ref type="bibr" target="#b72">[74]</ref>. As Ghotra et al. <ref type="bibr" target="#b62">[64]</ref> stated that these techniques have limitations for multiple comparison analysis. Furthermore, the datasets, like the NASA dataset, used in some prior studies <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b73">[75]</ref> are known to be noisy as they contain several erroneous software modules <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b62">[64]</ref>, <ref type="bibr" target="#b66">[68]</ref>, but no studies have focused on the impact of the noise on the experimental conclusions in the context of feature selection in defect prediction. Thus, the conclusions may be misleading since the noise can affect the conclusions of the empirical studies in software engineering domain <ref type="bibr" target="#b62">[64]</ref>.</p><p>Motivated by the aforementioned observations, we conduct a large-scale empirical study on 32 feature selection methods and strive to designate a set of excellent feature selection methods that are significantly distinct to others. We apply a novel double Scott-Knott test technique <ref type="bibr" target="#b69">[71]</ref> to rank and cluster these feature selection methods into nonoverlapping groups with statistically significant differences. Further, to observe whether the noise in dataset affects the conclusions of our empirical study, we perform experiments on both noisy and clean NASA datasets. Meanwhile, to diminish the potential impact of dataset types on the conclusions, we use an additional open source AEEEM dataset that was developed in a different setting from that of the NASA dataset.</p><p>In this study, we choose the random forest classifier as the defect prediction model and AUC as the evaluation measure. The analytic results show that these feature selection methods can be divided into different groups without overlapping across the groups on all three datasets. This indicates that the effectiveness of these methods is significantly different on the defect prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contribution</head><p>The main contributions of our empirical study are highlighted in the following four aspects:</p><p>(1) We conduct an extensive comparative study on the impact of 32 feature selection methods on the defect prediction performance. To the best of our knowledge, this is the first attempt to perform such a large-scale empirical study on feature selection methods that cover a variety of families.</p><p>(2) We employ a state-of-the-art multiple comparison technique to rank and cluster the feature selection methods into distinct groups. Different from the results derived from the post hoc statistical tests in <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b72">[74]</ref>, the Scott-Knott test can yield a nonoverlapping groups with significant differences.</p><p>(3) We employ two versions of the NASA dataset and one AEEEM dataset as our study benchmarks to investigate the impact of the noise and the dataset types on the experimental results.</p><p>(4) We attempt to identify a group of excellent feature selection methods instead of a single method so it gives practitioners more choices in practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Organization</head><p>The reminder of this paper is organized as follows. Section II introduces the preliminaries, i.e., the feature selection methods studied in this work. In section III, we elaborate the experimental setup. Section IV reports the analytic results. In section V, we present the discussion of the experimental results. Section VI and VII state the threats to validity and related work. In Section VIII, we describe the conclusion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRELIMINARIES</head><p>In this section, we only provide a brief description of the 32 feature selection methods studied in this work due to the space limit. These methods cover five families including 14 filter-based feature ranking methods, two filter-based feature subset evaluation methods, 12 wrapper-based feature subset evaluation methods, three clustering-based feature selection methods and one extraction-based feature selection method. Readers can consult with the corresponding references for further details. Table <ref type="table" target="#tab_1">I</ref> provides an overview of these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Filter-Based Feature Ranking Methods</head><p>Filter-based feature ranking methods evaluate each feature separately by assigning individual feature a score according to an indicator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Statistic-Based Methods</head><p>• Chi-Square (CS): CS <ref type="bibr" target="#b13">[14]</ref> measures the merit of a feature by computing its chi-squared statistic to the class label. • Correlation (Cor): Cor <ref type="bibr" target="#b14">[15]</ref> method measures the merit of a feature by computing its Pearson correlation coefficient to the class label. • Clustering Variation (CV): CV <ref type="bibr" target="#b15">[16]</ref> method ranks the features according to their variation coefficients.</p><p>Higher variance coefficient of a feature means that its values vary across a wide range, which benefits to build a more effective prediction model <ref type="bibr" target="#b16">[17]</ref>. • Signal-to-Noise (S2N): S2N <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>  </p><formula xml:id="formula_0">ܹܶܵ ൌ ߤ െ ߤ ே ට ߪ ଶ ݊ ߪ ே ଶ</formula><p>݊ ே where ݊ and ݊ ே denote the number of instances that belong to positive class and negative class, respectively.</p><p>• Fisher Score (FS): FS <ref type="bibr" target="#b20">[21]</ref> method ranks the features based on their fisher scores. This statistic is defined as follows:</p><formula xml:id="formula_1">ൌ ು ሺఓ ು ିఓ ሻ మ ା ಿ ሺఓ ಿ ିఓ ሻ మ ఙ మ</formula><p>where ߤ ் and ߪ ் denote the mean value and standard deviation of the feature over all instances. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Probability-Based Methods</head><p>• Probabilistic Significance (PS): PS <ref type="bibr" target="#b21">[22]</ref> is a conditional-probability-based method. Each feature is assigned a significance score according to its contribution to discriminate different class labels. A feature is significant if both the two-way associations between the feature and class label are high. • Information Gain (IG): IG <ref type="bibr" target="#b22">[23]</ref> is an entropy-based method. IG measures the reduction of uncertainty about class label after observing the feature. The bias of IG is that it tends to select the features with more values. • Gain Ratio (GR): GR <ref type="bibr" target="#b23">[24]</ref> compensates for the bias of IG by penalizing the multivalued features. • Symmetrical Uncertainty (SU): SU <ref type="bibr" target="#b24">[25]</ref> compensates for the bias of IG by being divided by the sum of the entropies of the two variables (i.e., the feature and class label in this work).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Maximal Information Coefficient (MIC): MIC [26],</head><p>[27] is a novel measure of relevance based on entropy. MIC has the advantage of exploring the hidden relationship between two variables and resisting noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Instance-Based Methods</head><p>ReliefF <ref type="bibr" target="#b27">[28]</ref>, an extension of Relief method, is an instance-based method. ReliefF is available in WEKA suite. When the parameter 'WeightByDistance' is set as false, the method is abbreviated to RF, otherwise, it is abbreviated to RFW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Classifier-based Methods</head><p>One Rule (OneR): OneR <ref type="bibr" target="#b28">[29]</ref> generates one-level decision rule for individual feature and evaluates the discrimination ability of this rule. The classification error rate is used to rank features separately.</p><p>For all above methods, the larger indicator value signifies stronger relevance between the feature and class label. <ref type="bibr" target="#b29">[30]</ref> aims to identify a feature subset in which these features have a high correlation with respect to the class label while have a low correlation within each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Filter-Based Feature Subset Evaluation 1) Correlation-based Feature Subset Selection (CFS) CFS</head><p>2) Consistency-based Feature Subset Selection (ConFS) ConFS <ref type="bibr" target="#b30">[31]</ref> uses an indicator, called consistency <ref type="bibr" target="#b31">[32]</ref>, to measure the merit of a feature subset. This method aims to search the minimal subset whose consistency is equal to that of all the features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Wrapper-Based Feature Subset Evaluation</head><p>Wrapper-based methods evaluate the merit of a feature subset with predetermined classifiers and evaluation measures. In this work, we construct 12 methods by employing four classifiers and three evaluation measures that are commonly used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Classifiers</head><p>• Naïve Bayes (NB): NB <ref type="bibr" target="#b32">[33]</ref> is a probability-based classifier. It assumes that the features are conditional independence. This assumption is not always valid, but it can still yield satisfactory result <ref type="bibr" target="#b33">[34]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Area Under the Precision-Recall Curve (AUPRC):</head><p>AUPRC <ref type="bibr" target="#b49">[51]</ref> is a trade-off between precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Clustering-Based Feature Selection Methods 1) FECAR:</head><p>FECAR <ref type="bibr" target="#b51">[53]</ref> first applies the k-medoids clustering to group the features, and then selects a certain number of features with higher IG scores (cf. Section II.A) from each cluster to constitute the final feature subset.</p><p>2) TC: TC <ref type="bibr" target="#b50">[52]</ref> first uses SU method (cf. Section II.A) to select the top-ranked features as the initial feature subset, and then employs a threshold-based clustering to eliminate redundant features.</p><p>3) MICHAC: MICHAC <ref type="bibr" target="#b52">[54]</ref> first employs MIC method (cf. Section II.A) to select the features that have a higher correlation with the class labels, then applies Hierarchical Agglomerative Clustering (HAC) <ref type="bibr" target="#b54">[56]</ref> to group the selected features into clusters, finally, it selects one feature with the highest MIC value from each cluster to construct the final feature subset.</p><p>All the three methods were recently designed for defect prediction. The first two methods need predetermine the number of selected features while the last method automatically determines the number with a statistic measure called inconsistency coefficient <ref type="bibr" target="#b55">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Extraction-based Feature Selection Methods</head><p>Principal Component Analysis (PCA): PCA <ref type="bibr" target="#b56">[58]</ref> is an extraction-based dimension reduction methods. It transforms original variables (i.e. feature set in this work) that may exist correlations within each other into a set of new orthogonal variables. These new variables are known as principal components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>This subsection describes the datasets used in this work. First, we conduct experiment on the noisy NASA dataset. The noise can refer to the incorrect software data caused by some unexpected reasons, such as unintentional errors in collecting or transferring the values of software features <ref type="bibr" target="#b46">[47]</ref>. To investigate whether the noise in the dataset affects the experimental conclusion, we further use the clean NASA dataset.</p><p>Each project of NASA dataset consists of a set of features characterized by static code metrics, such as LOC counts, Halstead and McCabe complexity metrics <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b57">[59]</ref>, <ref type="bibr" target="#b58">[60]</ref>. Many prior studies used the noisy NASA dataset over the last decade <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b62">[64]</ref>, <ref type="bibr" target="#b63">[65]</ref>, <ref type="bibr" target="#b64">[66]</ref>, <ref type="bibr" target="#b65">[67]</ref>. To improve the quality of the noisy NASA dataset, Shepperd et al. <ref type="bibr" target="#b66">[68]</ref> cleaned the original NASA dataset with some preprocessing criteria. The clean NASA dataset is also prevalent in software engineering domain <ref type="bibr" target="#b62">[64]</ref>, <ref type="bibr" target="#b67">[69]</ref>, <ref type="bibr" target="#b68">[70]</ref>. Table <ref type="table" target="#tab_3">II</ref> presents the statistical information of the two versions of NASA dataset, including the language used in each project, number of features, modules, and the percentage of defective modules. Table <ref type="table" target="#tab_3">III</ref> reports the changes of each project after removing noise, where '¨ Features', '¨ Modules', '¨ Defective' denote the number of features, modules and defective modules deleted, respectively. The '% Noise' represents the noise percentage in term of module level. Both versions of NASA dataset are derived from Shepperd et al. <ref type="bibr" target="#b66">[68]</ref>.</p><p>To investigate whether dataset types affect the conclusions that are drew from the two versions of NASA dataset, we use four projects of AEEEM dataset <ref type="bibr" target="#b39">[40]</ref>. This dataset was developed in a different setting compared with the NASA dataset and collected with modules measured at class level. Features in AEEEM dataset include source code metrics, such as the change metrics, source code metrics, entropy of source code metrics and churn of source code metrics. Note that no common features exist in these two datasets.</p><p>Table <ref type="table" target="#tab_5">IV</ref> shows the statistical information of the projects. All the projects were written in Java.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Research Questions</head><p>RQ1: Do different feature selection methods have significantly distinct effectiveness on defect prediction performance over noisy NASA dataset? RQ2: Is the conclusion consistent with that in RQ1 when using the clean NASA dataset? RQ3: What is the impact of the noise on the effectiveness of feature selection methods over NASA dataset? RQ4: Do dataset types affect the conclusions drew from the two versions of the NASA dataset?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Classifier</head><p>In this work, we use the Random Forest classifier <ref type="bibr" target="#b40">[41]</ref> as the defect prediction model. This classifier constructs multiple classification trees during model training. The training set of each tree stems from sampling the whole training set with replacement. Each internal node of a tree is split using a random subset of the whole features. This randomly split-ting assures low correlations within all the decision trees. The class label of the output relies on the class labels of all trees with majority voting. Random forest classifier has been widely used for defect prediction with promising prediction ability <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Evaluation measure</head><p>In this work, we apply AUC to measure the prediction performance of random forest classifier built with the selected features. This measure is robust to imbalance class distribution and misclassification costs that are the characteristics of defect prediction <ref type="bibr" target="#b59">[61]</ref>. Therefore, it is widely used as an evaluation measure for defect prediction performance <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b60">[62]</ref>, <ref type="bibr" target="#b71">[73]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experimental Procedure</head><p>Let m denote the number of original features. For filterbased feature ranking methods, we select the top ‫݈݃ڿ‬ ଶ ‫ۀ݉‬ features to build random forest classifier. This parameter follows prior studies <ref type="bibr" target="#b47">[49]</ref>, <ref type="bibr" target="#b72">[74]</ref> which suggested that various classifiers for imbalance defect datasets are appropriate to this setting. For FECAR and TC methods, we follow the original work to set the number of selected features as ‫݈݃ڿ‬ ଶ ‫.ۀ݉‬ For PCA, filter-based and wrapper-based feature subset evaluation methods, we use WEKA suite to implement them with default parameter settings, except for the wrapper-based methods with the ݇NN classifier. In this case, we find that among the five test options (i.e., 10, 20, 30, 40, and 50), ݇ ൌ 20, 10, 30 can achieve a lower RMSE , a higher AUC and PRAUC for most projects on AEEEM dataset, noisy and clean NASA datasets respectively. So we choose these parameters for the wrapper-based methods with ݇NN classifier on the three datasets respectively. Moreover, for MIC and MICHAC, we implement them with MINE toolkit <ref type="bibr">[48]</ref>.</p><p>In the experiment, 10-fold cross validation strategy is performed when evaluating the performance of random forest classifier with the selected features. To mitigate the effect of module orders on the feature selection methods and random forest classifier, we randomize the module orders of the dataset 10 times before performing each feature selection method. Thus, we obtain 10 AUC values of the cross validation. Figure <ref type="figure">1</ref> depicts the overall framework of the experimental procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Statistic Comparison Tests 1) Friedman Test:</head><p>Friedman <ref type="bibr" target="#b61">[63]</ref> is a non-parametric statistical test based on the rankings of performance values rather than the actual values. In this work, we use this test to detect whether the performance differences among the 32 feature selection methods are random. This statistic is calculated as follows:</p><formula xml:id="formula_2">ɖ ி ଶ ൌ ‫ʹͳ‬ ‫ݍ‪ሺ‬ݍ‬ ͳሻ ሾሺ ͳ ‫‬ ‫ݎ‬ ୀଵ ሻ ଶ െ ‫ݍ‪ሺ‬ݍ‬ ͳሻ ଶ Ͷ ୀଵ ሿ</formula><p>where ‫‬ denotes the total number of projects of the dataset, ‫ݍ‬ denotes the total number of feature selection methods, while ‫ݎ‬ denotes the ranking of the ݅th method over the ݆th project.</p><p>2) Scott-Knott Test: Scott-Knott test <ref type="bibr" target="#b69">[71]</ref> is a multiple comparison technique using hierarchical clustering algorithm for statistical analysis. This test ranks and clusters the methods into significantly different groups in which the methods in the same group have no significant differences while the methods in distinct groups have significant differences. The advantage of the test is that it results completely distinct groups without any overlapping. Borges et al. <ref type="bibr" target="#b70">[72]</ref> evaluated Scott-Knott test using Monte Carlo method and found that this test presents an excellent performance. In this work, we employ the novel double Scott-Knott test <ref type="bibr" target="#b62">[64]</ref> to cluster these methods into different groups at the significance level of 0.05. Thus, we can find a set of feature selection methods that is superior to others, The detailed steps of the double Scott-Knott test are described as follows: in the first round, we rank and cluster these methods into significantly distinct groups with the 10 AUC values on each project as the inputs. As a result, each method obtains ‫‬ ‫(‬ denotes the number of projects of the dataset) different rankings. In the second round, we get the final rankings of these methods with all the rankings of each method as the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>In this section, we present the experimental results to answer the four research questions (cf. Section III.B) of this empirical study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. RQ1</head><p>To answer this question, we apply the 32 feature selection methods to the 11 projects of the noisy NASA dataset. For each method of a project, we obtain 10 AUC values of 10 times cross validation. Then we conduct the Friedman test. The ‫-‬value of 6.72 ‫61-ܧ‬ indicates that the differences in performance values of these methods are not random.</p><p>Figure <ref type="figure" target="#fig_0">2</ref> shows the standardized box-plots of AUC values for each project on all methods to illustrate the suitability of the double Scott-Knott test for the experimental results. From the figure, we can observe that even the worst methods for MC1 project and PC4 project perform better than the best-performing methods for other projects, except for PC1 project. Also, many of the methods for PC1 project outperform the best-performing methods for many other projects. This observation manifests that it is appropriate to use the double Scott-Knott test to analyze the results on the noisy NASA dataset.</p><p>Figure <ref type="figure" target="#fig_1">3</ref> depicts the result of the double Scott-Knott test on the noisy NASA dataset. Each number on ‫-ݔ‬axis represents a feature selection method while the corresponding relationship is illustrated in table I. The ‫-ݕ‬axis represents the range of the rankings of each method on all projects. The dot on the line corresponds to the average ranking of each method. Different colors represent different groups. From the figure, we can observe that the 32 feature selection methods are clustered into four distinct groups without overlapping, which implies that there exist clear separations between these methods on the noisy NASA dataset.</p><p>Table <ref type="table" target="#tab_5">V</ref> reports the methods that belong to the same group and the statistical properties of the method rankings for each group, including the median ranking, average ranking and standard deviation.</p><p>From the table, we can observe that filter-based feature subset evaluation methods, i.e., ConFS and CFS, belong to the first group in which the methods achieve the best performance.</p><p>For filter-based feature ranking methods, most of them belong to the second group or the third group. More specifically, all the probability-based methods, i.e., PS, SU, GR, MIC, and IG, belong to the second group. All the instancebased methods, i.e., RFW and RF, also belong to the second group. Most of the statistic-based methods belong to the second group as well, except FS and S2N methods which belong to the first group and the third group, respectively. The classifier-based method, i.e., OneR, belongs to the third  For clustering-based feature selection methods, MICHAC method can achieve the best performance compared with most of the filter-based feature ranking methods and other two clustering-based methods, i.e., FECAR and TC. This observation is consistent with the conclusion in <ref type="bibr" target="#b52">[54]</ref>. In addition, the FECAR and TC belong to the second group.</p><p>For extraction-based feature selection method, PCA is outperformed by nearly all other methods. The reason may be that PCA aims to find the optimal linear projection of the feature set by minimizing the mean square error, but it ignores the class label, so when there exist nonlinear properties in the feature set, the projection direction may not necessarily benefit for classification. In addition, PCA performs well when the dataset follows Gaussian distribution, but the premise is not always established. Thus, PCA may not achieve an anticipated performance. RQ1 Summary. As mentioned above, the analytic results indicate that the differences between the effectiveness of the 32 methods on the defect prediction performance are significant over the noisy NASA dataset. These methods are clearly divided into four groups with statistically significant differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. RQ2</head><p>This question aims to explore whether the conclusion stays consistent after removing noise from the NASA dataset. We apply 32 feature selection methods to the 11 projects of clean NASA dataset. The ‫-‬value of ‫91-ܧ71.3‬ for Friedman test indicates that the performance differences among these methods are also not random.</p><p>Figure <ref type="figure" target="#fig_2">4</ref> also shows the standardized box-plots of AUC values for each project on all the methods. From the figure, we can find that the worst methods for PC4 project perform well than the best-performing methods for all other projects, and many of the methods for PC1 project outperform the best-performing methods for many other projects, except for PC4 project. So the double Scott-Knott test is also suitable to analyze our experimental results on the clean NASA dataset.</p><p>Figure <ref type="figure" target="#fig_3">5</ref> depicts the result of the double Scott-Knott test on the clean NASA dataset. From the figure, we can observe that the 32 feature selection methods are also clustered into four non-overlapping groups. It indicates that these methods are also distinct from each other on the clean NASA dataset.</p><p>Table <ref type="table" target="#tab_6">VI</ref> reports the methods that belong to each group and the statistics of the method rankings for each group.</p><p>From the table, we can observe that filter-based feature subset evaluation methods belong to the best group again.</p><p>Most of the filter-based feature ranking methods also belong to the second or third group. More specifically, most of the probability-based methods belong to the second group, except that MIC belongs to the third group. All the instancebased methods belong to the second group. Most of the statistic-based methods belong to the second group, with two exceptions of S2N and CV which belong to the third group   </p><formula xml:id="formula_3">M 1 J M 1 K C 1 K C 3 M C 1 M C 2 M W 1 P C 1 P C 2 P C 3 P C 4</formula><p>and the worst group, respectively. The classifier-based method belongs to the third group again.</p><p>For wrapper-based evaluation methods, eight out of twelve methods belong to the best group. More specifically, the methods based on the ݇NN classifier and the LR classifier have the best performance again. Two of the methods based on the NB classifier belong to the best group expect the NB+RMSE method. The methods based on the RIPPER classifier belong to the second group (for RIPPER+PRAUC and RIPPER+AUC) and the worst group (for RIPPER+RMSE). This observation is relatively consistent with the experimental results on the noisy NASA dataset.</p><p>For clustering-based methods, TC method achieves the best performance while other two methods, i.e., MICHAC and FECAR, belong to the second group. This observation is quite different from that on the noisy NASA dataset, where the MICHAC method performs the best.</p><p>For extraction-based feature selection method, PCA is also outperformed by nearly all the other methods. RQ2 Summary. To sum up, the above observations show that the effectiveness of these feature selection methods exhibits significant differences on the defect prediction performance over the clean NASA dataset with four distinct groups. It also indicates that the conclusion drew from the noisy NASA dataset is not affected by the noise in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. RQ3</head><p>Although the noise does not affect the conclusion that the differences of the effectiveness of these feature selection methods are significant, it has some impacts on the actual effectiveness of these methods. We explore the question from two aspects.</p><p>By observing the change of the rankings of the feature selection methods before and after removing the noise from NASA dataset, we find that the rankings of most methods remain unchanged with six exceptions, i.e., FS, CV, MIC, TC, MICHAC, and NB+RMSE. From this perspective, it implies that most methods exhibit stably distinguishable abilities in spite of the noise in the dataset.</p><p>By observing the change of the actual performance values of the feature selection methods, we find that the performance of all methods declines, varying from 0.3% (for NB+RMSE method) to 7.9% (for CV method) after cleaning the dataset. From table III, we observe that the noise percentage varies from 12.48% to 86.87% with an average percentage of 43.20%. It indicates that nearly half of the software modules are removed from the original dataset on average. However, these deleted modules may contain important information that is beneficial to distinguish the class labels of the modules. Thus it may lead to the reduction of the performance due to the loss of information. RQ3 Summary. To conclude the above observations, we find that noise in the dataset has little impact on the rankings of the group for most methods. However, the performance of all methods declines after removing the noise from the dataset due to the loss of some important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. RQ4</head><p>This question investigates whether dataset types affect the conclusions drew from the two versions of the NASA dataset. In this work, we apply the 32 feature selection methods to a publicly open source AEEEM dataset. The dataset was developed in a different setting compared with the NASA dataset. The ‫-‬value of ‫61-ܧ03.3‬ for Friedman test also indicates that the performance differences among these methods are not random.</p><p>Figure <ref type="figure" target="#fig_4">6</ref> also provides an explanation of the suitability for the double Scott-Knott test to analyze the experimental results. As we can see that many of the methods for Eclipse JDT Core project (JDT) outperform the best method for Eclipse PDE UI project (PDE).</p><p>Figure <ref type="figure">7</ref> depicts the result of the double Scott-Knott test on the AEEEM dataset. The figure shows that the 32 feature selection methods are clustered into three distinct groups without overlapping. This indicates that these methods have significantly different effectiveness on the defect prediction performance over the AEEEM dataset.</p><p>Table <ref type="table" target="#tab_7">VII</ref> reports relevant statistics of the method rankings for each group.</p><p>From the table, we can observe that the filter-based feature subset evaluation methods belong to the best group again.  Nearly all the filter-based feature ranking methods belong to the second group or the worst group, except the WTS method. More specifically, two out of five probabilitybased methods, i.e., IG and MIC, belong to the second group, while others belong to the worst group. All the instance-based methods belong to the second group. Four out of six statistic-based methods belong to the second group with two exceptions of WTS and CV which belong to the best group and the worst group, respectively. The classifierbased method belongs to the second group.</p><p>Eight out of the twelve wrapper-based feature subset evaluation methods belong to the best group. The methods based on the ݇NN classifier and the LR classifier achieve the best performance. Two of the methods based on the NB classifier belong to the best group expect the NB+RMSE method. The methods based on the RIPPER classifier belong to the worst group. This observation is also similar to that on the two versions of NASA dataset.</p><p>All the three clustering-based feature selection methods belong to the second group.</p><p>For extraction-based feature selection method, PCA belongs to the second group. This observation is contrary to that on two versions of the NASA dataset. The reason may be that the feature set of the AEEEM dataset has a higher linearity or follows Gaussian distribution compared with the NASA dataset. So, for the AEEEM dataset, the features extracted by PCA are more conductive to defect prediction. RQ4 Summary. The experimental results on the AEEEM dataset show that the effectiveness of the 32 feature selection methods on defect prediction performance can be significantly different from each other. It also indicates that the conclusions drew from the two versions of the NASA dataset are little affected by the dataset types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION</head><p>All the results of RQ1, RQ2 and RQ4 show that the effectiveness of different feature selection methods on the performance of random forest classifier exhibits significant differences, even among the methods of the same family. In addition, we also observe similarities and differences from the experimental results over the three benchmarks. More specifically, the filter-based subset evaluation methods can always achieve the best performance. The wrapper-based methods that based on the ݇NN, LR and NB also always perform the best except the NB+RMSE method. The wrapper-based methods based on the RIPPER never perform well regardless of evaluation measures. It seems to imply that the classifiers affect the performance of the wrapperbased methods more than the evaluation measures. The clustering-based methods always belong to the best group or the second best group. The MICHAC method performs particularly well on the noisy NASA dataset. It confirms the previous work <ref type="bibr" target="#b52">[54]</ref> that the MICHAC method is not sensitive to the noise in the dataset due to the characteristics of MIC and HAC. For the filter-based feature ranking methods, the effectiveness of some methods is affected by the dataset types and the noise. For extraction-based method, i.e., PCA, its effectiveness is affected by the dataset types due to its own limitations, such as the linear constraint and the demand for the distribution of the dataset.</p><p>Generally, the wrapper-based methods outperform others. However, they are more time-consuming during the experimental process, especially when the feature space becomes larger. This observation is consistent with the previous study <ref type="bibr" target="#b53">[55]</ref>. In addition, although the filter-based feature subset evaluation methods can always perform best, they tend to select more features than other methods. This  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. THREATS TO VALIDITY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Construct Validity</head><p>Threats to construct validity focus on the bias of the measures used to evaluate the prediction performance. In the work, we employ the widely used AUC as the evaluation measure. Nonetheless, other comprehensive measures, such as F-measure and g-measure can also be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Internal Validity</head><p>Threats to internal validity refer to the bias of the choice of defect prediction classifiers and feature selection methods. In this work, we only use the random forest classifier due to its popularity in defect prediction. In addition, we choose 32 methods covering five feature selection families to make our empirical study more fruitful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. External Validity</head><p>Threats to external validity mainly concern the generalization of the experimental results. Although the datasets used in this work have been extensively studied in defect prediction, we still cannot claim that our conclusions can be generalized to other software projects. Nevertheless, this work provides a detailed experimental description, including parameter settings, thus other researchers can easily replicate this empirical study on new datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Conclusion Validity</head><p>Threats to conclusion validity focus on the statistical analysis method used. In this work, we use the Scott-Knott test to statistically analyze the 32 feature selection methods. Existing work has suggested that the Scott-Knott test is superior to other post-hoc tests <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b62">[64]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. RELATED WORK</head><p>Feature selection is introduced into software engineering domain to alleviate the high dimensionality issue by eliminating irrelevant and redundant features. Many prior studies have investigated the effectiveness of feature selection methods on the performance of defect prediction models. Shivaji et al <ref type="bibr" target="#b71">[73]</ref> explored the impact of four feature ranking methods and two wrapper methods on the code changebased bug prediction over 11 software projects. They found that feature selection can improve the prediction performance even eliminating 90 percent of original features. Muthukumaran et al. <ref type="bibr" target="#b9">[10]</ref> investigated seven feature ranking methods, two wrapper methods and one embedded method on the noisy NASA dataset and AEEEM dataset. They found that there have no significant differences among the 10 methods. Gao et al. <ref type="bibr" target="#b72">[74]</ref> applied seven feature ranking methods and four feature subset selection methods to a private dataset. They found that various feature ranking meth-ods, except for CS method, have similar effectiveness. Wang et al. <ref type="bibr" target="#b73">[75]</ref> conducted an empirical study on six feature ranking methods and two ensemble methods over three datasets. The results on NASA dataset indicated that the effectiveness of the eight methods has no significant separations.</p><p>Different from the work of the above studies, in this work, we do not aim to propose a new feature selection method or compare the performance of a few feature selection methods on a small number of datasets, but to conduct an extensive comparison of 32 feature selection methods on three publicly available datasets and consider the impact of noise and the dataset types on the experimental conclusions.</p><p>In addition, this work is also inspired by two analogous studies in defect prediction <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b62">[64]</ref>. Lessmann et al. <ref type="bibr" target="#b41">[42]</ref> conducted an empirical study to investigate the performance of 22 prediction models on noisy NASA dataset and Ghotra et al. <ref type="bibr" target="#b62">[64]</ref> extended this study by investigating 31 prediction models on two versions of the NASA dataset and an open source software dataset. Different from this two studies, we focus on the effectiveness of feature selection methods rather than prediction models in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION AND FUTURE WORK</head><p>In this paper, we conduct a large-scale empirical study to investigate the impact of 32 feature selection methods on the defect prediction performance on account of some potential controversies and limitations in previous studies. To explore whether the noise in the dataset and the dataset types affect the analytic conclusions, we employ two versions of the NASA dataset and one public AEEEM dataset as our study benchmarks. To compare different feature selection methods and identify a set of outstanding methods, we use a state-ofthe-art multiple comparison technique to analyze these methods.</p><p>The analytic results indicate that the effectiveness of these feature selection methods exhibits significant differences on all the three datasets. It also shows the noise and the dataset types have little impact on the conclusions. Generally, the filter-based and wrapper-based feature subset evaluation methods can achieve the best performance. However, these methods tend to select more features or spend more time. The clustering-based method and most of the filter-based feature ranking methods can achieve acceptable results with fewer features and less time. These methods are also easy to understand. Thus, this empirical study can offer a valuable guideline for practitioner to select appropriate feature selection methods based on some additional criteria, such as computational overhead and simplicity.</p><p>In the future, we plan to employ other classifiers to validate the generalization of the derived conclusions and explore the interactions between the classifiers used for the wrapper-based methods and for the defect prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The box-plots of AUC values for each project on all methods over the noisy NASA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The result of double Scott-Knott test on the noisy NASA dataset.</figDesc><graphic coords="7,54.00,70.93,243.34,154.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The box-plots of AUC values for each project on all methods over the clean NASA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The result of double Scott-Knott test on the clean NASA dataset.</figDesc><graphic coords="8,59.05,71.65,239.81,152.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The box-plots of AUC values for each project on all methods over the AEEEM dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I .</head><label>I</label><figDesc>OVERVIEW OF THE FEATURE SELECTION METHODS STUDIED IN OUR WORK</figDesc><table><row><cell>Family</cell><cell></cell><cell>Methods</cell><cell>Abbreviation</cell><cell>Label</cell></row><row><cell></cell><cell></cell><cell>Chi-Square</cell><cell>CS</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell>Correlation</cell><cell>Cor</cell><cell>2</cell></row><row><cell></cell><cell>Statistic-based Methods</cell><cell>Clustering Variation Signal-to-Noise</cell><cell>CV S2N</cell><cell>3 4</cell></row><row><cell></cell><cell></cell><cell>Welch T-Statistic</cell><cell>WTS</cell><cell>5</cell></row><row><cell></cell><cell></cell><cell>Fisher Score</cell><cell>FS</cell><cell>6</cell></row><row><cell>Filter-based Feature Ranking</cell><cell></cell><cell>Probabilistic Significnace Information Gain</cell><cell>PS IG</cell><cell>7 8</cell></row><row><cell></cell><cell>Probability-based Methods</cell><cell>Gain Ratio</cell><cell>GR</cell><cell>9</cell></row><row><cell></cell><cell></cell><cell>Symmetrical Uncertainty</cell><cell>SU</cell></row><row><cell></cell><cell></cell><cell>Maximal Information Coefficient</cell><cell>MIC</cell></row><row><cell></cell><cell>Instance-based Methods</cell><cell>ReliefF ReliefF-Weight</cell><cell>RF RFW</cell></row><row><cell></cell><cell>Classifier-based Techniques</cell><cell>One Rule</cell><cell>OneR</cell></row><row><cell>Filter-based Subset Selection</cell><cell cols="2">Correlation-based Feature Subset selection Consistency-based Feature Subset selection</cell><cell>CFS ConFS</cell></row><row><cell></cell><cell></cell><cell>Root Mean Squared Error</cell><cell>NB+RMSE</cell></row><row><cell></cell><cell>Naïve Bayes</cell><cell>Area Under the ROC Curve</cell><cell>NB+AUC</cell></row><row><cell></cell><cell></cell><cell>Area Under the Precision-Recall Curve</cell><cell>NB+PRAUC</cell></row><row><cell>Wrapper-based Subset Selection</cell><cell>Repeated Incremental Pruning to Produce Error Reduction</cell><cell>Root Mean Squared Error Area Under the ROC Curve Area Under the Precision-Recall Curve Root Mean Squared Error</cell><cell>RIPPER+RMSE RIPPER+AUC RIPPER+PRAUC LR+RMSE</cell></row><row><cell></cell><cell>Logistic Regression</cell><cell>Area Under the ROC Curve</cell><cell>LR+AUC</cell></row><row><cell></cell><cell></cell><cell>Area Under the Precision-Recall Curve</cell><cell>LR+PRAUC</cell></row><row><cell></cell><cell></cell><cell>Root Mean Squared Error</cell><cell>kNN+RMSE</cell></row><row><cell></cell><cell>k-Nearest Neighbor</cell><cell>Area Under the ROC Curve</cell><cell>kNN+AUC</cell></row><row><cell></cell><cell></cell><cell>Area Under the Precision-Recall Curve</cell><cell>kNN+PRAUC</cell></row><row><cell></cell><cell>FECAR</cell><cell></cell><cell>FECAR</cell></row><row><cell>Clustering-based Methods</cell><cell>TC</cell><cell></cell><cell>TC</cell></row><row><cell></cell><cell>MICHAC</cell><cell></cell><cell>MICHAC</cell></row><row><cell>Extraction-based Method</cell><cell>Principal Component Analysis</cell><cell></cell><cell>PCA</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>• Repeated Incremental Pruning to Produce Error Reduction (RIPPER): RIPPER<ref type="bibr" target="#b34">[35]</ref> is a rule-based classifier. This classifier generates a rule to randomly split the training set into growing set and pruning set, then improves the fitness of the rule on the training set through the generation and prune phase<ref type="bibr" target="#b35">[36]</ref>.• Logistic Regression (LR): LR<ref type="bibr" target="#b36">[37]</ref> improves linear regression model with a logical function. This classifier is originally designed for binary classification. • ݇-Nearest Neighbor (݇NN): ݇NN [38] is an instancebased classifier. This classifier assigns the class label of the test instance based on the labels of its ݇ nearest training instances with majority voting.</figDesc><table /><note><p>2) Evaluation measures • Root Mean Squared Error (RMSE): RMSE [39] measures the deviations of the predicted values and the corresponding true values. • Area Under the ROC Curve (AUC): AUC [50] is a trade-off between true positive rate (TPR) and false positive rate (FPR).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II .</head><label>II</label><figDesc>STATISTICS OF THE TWO VERSIONS OF THE NASA DATASETS The double Scott-Knott test first ranks the methods with the AUC values at project level, then ranks the methods again with their rankings from the former step at global level. The two-step ranking strategy ensures the rankings are independent of the actual AUC values. Thus, the double Scott-Knott test can perform well when the AUC values on different projects vary greatly.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Noisy NASA Dataset</cell></row><row><cell>Project</cell><cell cols="2">Language</cell><cell># Features</cell><cell>#Modules</cell><cell>%Defective</cell></row><row><cell>CM1</cell><cell>C</cell><cell></cell><cell></cell><cell>505</cell><cell>9.50%</cell></row><row><cell>JM1</cell><cell>C</cell><cell></cell><cell></cell><cell>10878</cell><cell>19.32%</cell></row><row><cell>KC1</cell><cell>C++</cell><cell></cell><cell></cell><cell>2107</cell><cell>15.42%</cell></row><row><cell>KC3</cell><cell>Java</cell><cell></cell><cell></cell><cell>458</cell><cell>9.39%</cell></row><row><cell>MC1</cell><cell cols="2">C &amp; C++</cell><cell></cell><cell>9466</cell><cell>0.72%</cell></row><row><cell>MC2</cell><cell>C</cell><cell></cell><cell></cell><cell>161</cell><cell>32.30%</cell></row><row><cell>MW1</cell><cell>C</cell><cell></cell><cell></cell><cell>403</cell><cell>7.69%</cell></row><row><cell>PC1</cell><cell>C</cell><cell></cell><cell></cell><cell>1107</cell><cell>6.87%</cell></row><row><cell>PC2</cell><cell>C</cell><cell></cell><cell></cell><cell>5589</cell><cell>0.41%</cell></row><row><cell>PC3</cell><cell>C</cell><cell></cell><cell></cell><cell>1563</cell><cell>10.24%</cell></row><row><cell>PC4</cell><cell>C</cell><cell></cell><cell></cell><cell>1458</cell><cell>12.21%</cell></row><row><cell></cell><cell></cell><cell cols="3">Clean NASA Dataset</cell></row><row><cell>Project</cell><cell cols="2">Language</cell><cell># Features</cell><cell cols="2"># Modules % Defective</cell></row><row><cell>CM1</cell><cell>C</cell><cell></cell><cell></cell><cell>327</cell><cell>12.84%</cell></row><row><cell>JM1</cell><cell>C</cell><cell></cell><cell></cell><cell>7720</cell><cell>20.88%</cell></row><row><cell>KC1</cell><cell>C++</cell><cell></cell><cell></cell><cell>1162</cell><cell>25.30%</cell></row><row><cell>KC3</cell><cell>Java</cell><cell></cell><cell></cell><cell>194</cell><cell>18.56%</cell></row><row><cell cols="3">MC1 not just a single one. C &amp; C++</cell><cell></cell><cell>1847</cell><cell>1.95%</cell></row><row><cell>MC2</cell><cell>C</cell><cell></cell><cell></cell><cell>125</cell><cell>35.20%</cell></row><row><cell>MW1</cell><cell>C</cell><cell></cell><cell></cell><cell>251</cell><cell>9.96%</cell></row><row><cell>PC1</cell><cell>C</cell><cell></cell><cell></cell><cell>696</cell><cell>7.90%</cell></row><row><cell>PC2</cell><cell>C</cell><cell></cell><cell></cell><cell>734</cell><cell>2.18%</cell></row><row><cell>PC3</cell><cell>C</cell><cell></cell><cell></cell><cell>1073</cell><cell>12.30%</cell></row><row><cell>PC4</cell><cell>C</cell><cell></cell><cell></cell><cell>1276</cell><cell>13.79%</cell></row><row><cell cols="6">TABLE III. DIFFERENCES OF THE NOISY NASA DATASET AND CLEAN</cell></row><row><cell></cell><cell></cell><cell cols="2">NASA DATASET</cell><cell></cell></row><row><cell>Project</cell><cell cols="2">ο Features</cell><cell cols="2">ο Modules ο Defective</cell><cell>% Noise</cell></row><row><cell>CM1</cell><cell>3</cell><cell></cell><cell>178</cell><cell>6</cell><cell>35.25%</cell></row><row><cell>JM1</cell><cell>0</cell><cell></cell><cell>3158</cell><cell>508</cell><cell>29.03%</cell></row><row><cell>KC1</cell><cell>0</cell><cell></cell><cell>945</cell><cell>31</cell><cell>44.85%</cell></row><row><cell>KC3</cell><cell>1</cell><cell></cell><cell>264</cell><cell>7</cell><cell>57.64%</cell></row><row><cell>MC1</cell><cell>1</cell><cell></cell><cell>7619</cell><cell>32</cell><cell>80.49%</cell></row><row><cell>MC2</cell><cell>1</cell><cell></cell><cell></cell><cell>8</cell><cell>22.36%</cell></row><row><cell>MW1</cell><cell>3</cell><cell></cell><cell>152</cell><cell>6</cell><cell>37.72%</cell></row><row><cell>PC1</cell><cell>3</cell><cell></cell><cell>411</cell><cell>21</cell><cell>37.13%</cell></row><row><cell>PC2</cell><cell>4</cell><cell></cell><cell>4855</cell><cell>7</cell><cell>86.87%</cell></row><row><cell>PC3</cell><cell>3</cell><cell></cell><cell>490</cell><cell>28</cell><cell>31.35%</cell></row><row><cell>PC4</cell><cell>3</cell><cell></cell><cell>182</cell><cell>2</cell><cell>12.48%</cell></row><row><cell cols="6">TABLE IV. STATISTICS OF THE AEEEM DATASET</cell></row><row><cell>Project</cell><cell cols="5">Release # Features # Modules % Defective</cell></row><row><cell cols="2">Eclipse JDT Core</cell><cell>3.4</cell><cell>76</cell><cell>997</cell><cell>20.66%</cell></row><row><cell cols="2">Apache Lucene</cell><cell>2.4.0</cell><cell>76</cell><cell>691</cell><cell>9.26%</cell></row><row><cell>Mylyn</cell><cell></cell><cell>3.1</cell><cell>76</cell><cell>1862</cell><cell>13.16%</cell></row><row><cell cols="2">Eclipse PDE UI</cell><cell>3.4.1</cell><cell>76</cell><cell>1497</cell><cell>13.96%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V .</head><label>V</label><figDesc>STATISTICAL RESULTS OF DOUBLE SCOTT-KNOTT TEST ON NOISY NASA DATASET</figDesc><table><row><cell>Overall Ranking</cell><cell>Feature Selection Methods</cell><cell>Median Ranking</cell><cell>Average Ranking</cell><cell>Standard Deviation</cell></row><row><cell></cell><cell>ConFS, kNN+AUC, MICHAC,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>NB+PRAUC, NB+AUC, CFS, kNN+RMSE, LR+AUC, LR+RMSE,</cell><cell>1.86</cell><cell>1.90</cell><cell>0.29</cell></row><row><cell></cell><cell>kNN+PRAUC, LR+PRAUC, FS</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>FECAR, RIPPER+PRAUC, WTS,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell>3.09</cell><cell>3.08</cell><cell>0.31</cell></row><row><cell>3</cell><cell>OneR, S2N</cell><cell>4.18</cell><cell>4.18</cell><cell>0</cell></row><row><cell>4</cell><cell>RIPPER+RMSE, NB+RMSE, PCA</cell><cell>5.36</cell><cell>5.33</cell><cell>0.41</cell></row></table><note><p>RFW, PS, TC, Cor, SU, GR, IG, RIPPER+AUC, RF, CV, CS, MIC,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI .</head><label>VI</label><figDesc>STATISTICAL RESULTS OF DOUBLE SCOTT-KNOTT TEST ON CLEAN NASA DATASET</figDesc><table><row><cell>Overall Ranking</cell><cell>Feature Selection Methods</cell><cell>Median Ranking</cell><cell>Average Ranking</cell><cell>Standard Deviation</cell></row><row><cell></cell><cell>NB+PRAUC, ConFS, NB+AUC,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>LR+RMSE, kNN+PRAUC, kNN+RMSE, TC, kNN+AUC, CFS,</cell><cell>2.09</cell><cell>2.03</cell><cell>0.31</cell></row><row><cell></cell><cell>LR+PRAUC, LR+AUC</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>GR, MICHAC, SU, PS, FECAR,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>WTS, Cor, CS, FS, RIPPER+PRAUC, RFW, RF, IG,</cell><cell>3.27</cell><cell>3.25</cell><cell>0.26</cell></row><row><cell></cell><cell>RIPPER+AUC</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell>NB+RMSE, S2N, OneR, MIC</cell><cell>4.27</cell><cell>4.25</cell><cell>0.27</cell></row><row><cell>4</cell><cell>CV, RIPPER+RMSE, PCA</cell><cell>5.64</cell><cell>5.82</cell><cell>0.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII .</head><label>VII</label><figDesc>STATISTICAL RESULTS OF DOUBLE SCOTT-KNOTT TEST ON AEEEM DATASET lead to more complex models. The effectiveness of the filter-based feature ranking methods and clustering-based methods is not as good as that of wrapper-based and filterbased feature subset evaluation methods. However, these methods are faster and simpler to understand. Furthermore, they can still yield satisfactory results with less features.</figDesc><table><row><cell></cell><cell>0.85</cell><cell></cell><cell></cell><cell>Overall Ranking</cell><cell>Feature Selection Methods</cell><cell>Ranking Median</cell><cell>Ranking Average</cell><cell>Deviation Standard</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell>1</cell><cell>WTS, kNN+RMSE, kNN+PRAUC, LR+PRAUC, kNN+AUC , LR+AUC, NB+AUC, NB+PRAUC,</cell><cell>2</cell><cell>2</cell><cell>0.55</cell></row><row><cell>AUC</cell><cell>0.75</cell><cell></cell><cell></cell><cell>2</cell><cell>CFS, LR+RMSE, ConFS MICHAC, Cor, S2N, CS, FS, RFW, OneR, FECAR, IG, MIC, RF, TC,</cell><cell>4</cell><cell>4.02</cell><cell>0.31</cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell>PCA</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CV, GR, PS, NB+RMSE,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>RIPPER+AUC, SU,</cell><cell>5.5</cell><cell>5.66</cell><cell>0.53</cell></row><row><cell></cell><cell>0.65</cell><cell></cell><cell></cell><cell></cell><cell>RIPPER+RMSE, RIPPER+PRAUC</cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>J D T</cell><cell>L u c e n e</cell><cell>M y l y n</cell><cell>P D E</cell><cell></cell><cell></cell></row></table><note><p><p>Figure 7. The result of double Scott-Knott test on the AEEEM dataset.</p>may</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work is partly supported by National Natural Science Foundation of China (NSFC) (grant No. 61572374, U1135005, 61472318), and National Science Foundation (DGE-1522883, CCF-1500365).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic literature review on fault prediction performance in software engineering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beecham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bowes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Counsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1276" to="1304" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Data mining static code attributes to learn defect predictors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparing software prediction techniques using simulation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kadoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1014" to="1022" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reliability and validity in comparative studies of software prediction models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Myrtveit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stensrud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="380" to="391" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Defect Prediction between Software Versions with Active Learning and Dimensionality Reduction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kocaguneli</surname></persName>
		</author>
		<author>
			<persName><surname>Cukic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Software Reliability Engineering (ISSRE)</title>
		<meeting>the 25th International Symposium on Software Reliability Engineering (ISSRE)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="312" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dictionary learning based software defect prediction</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 36th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="414" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using Pre-Release Test Failures to Build Early Post-Release Defect Prediction Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Herzig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Symposium on Software Reliability Engineering (ISSRE)</title>
		<meeting>the 25th International Symposium on Software Reliability Engineering (ISSRE)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="300" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Predicting defect-prone software modules using support vector machines</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Elish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Elish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Software defect prediction using semisupervised learning with dimension reduction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Culp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering (ASE)</title>
		<meeting>the 27th IEEE/ACM International Conference on Automated Software Engineering (ASE)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="314" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Impact of feature selection techniques on bug prediction models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Muthukumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rallapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th India Software Engineering Conference(ISEC)</title>
		<meeting>the 8th India Software Engineering Conference(ISEC)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Feature selection for knowledge discovery and data mining</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ranking and clustering software cost estimation models through a multiple comparisons algorithm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mittas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Angelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="537" to="551" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prioritizing the devices to test your app on: A case study of android game apps</title>
		<author>
			<persName><forename type="first">H</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shihab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering(FSE)</title>
		<meeting>the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering(FSE)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="610" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chi2: Feature selection and discretization of attributes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Setiono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Tools with Artificial Intelligence (ICTAI)</title>
		<meeting>the 7th International Conference on Tools with Artificial Intelligence (ICTAI)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">388</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An introduction to variable and feature selection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1157" to="1182" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel feature selection by clustering coefficients of variations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghanavati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Digital Information Management (ICDIM)</title>
		<meeting>the 9th International Conference on Digital Information Management (ICDIM)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="205" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving classification accuracy using Fuzzy Clustering Coefficients of Variations (FCCV) feature selection algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Symposium on Computational Intelligence and Informatics (CINTI)</title>
		<meeting>the 15th International Symposium on Computational Intelligence and Informatics (CINTI)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="147" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combating the small sample class imbalance problem using feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wasikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1388" to="1400" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A novel gataguchi-based feature selection method</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Intelligent Data Engineering and Automated Learning-(IDEAL)</title>
		<meeting>the 9th International Conference on Intelligent Data Engineering and Automated Learning-(IDEAL)<address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="112" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Study on First Order Statistics-Based Feature Selection Techniques on Software Metric Data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Napolitano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Software Engineering and Knowledge Engineering (SEKE)</title>
		<meeting>the 25th International Conference on Software Engineering and Knowledge Engineering (SEKE)</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="467" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Generalized fisher score for feature selection</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1202.3725</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A feature selection technique for classificatory analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="56" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">C4.5: programs for machine learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A novel hybrid feature selection via Symmetrical Uncertainty ranking based local memetic search algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramaraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="580" to="585" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Detecting Novel Associations in Large Data Sets</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Reshef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Reshef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Finucane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="issue">6062</biblScope>
			<biblScope unit="page" from="1518" to="1524" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Equitability, mutual information, and the maximal information coefficient</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3354" to="3359" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Estimating attributes: analysis and extensions of RELIEF</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Very simple classification rules perform well on most commonly used datasets</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Holte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="90" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Correlation-based feature selection for discrete and numeric class machine learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Machine Learning (ICML)</title>
		<meeting>the 17th International Conference on Machine Learning (ICML)<address><addrLine>Stanford University</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="359" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Consistency based feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>PAKDD</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="98" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Consistency-based search in feature selection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="176" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimating continuous distributions in Bayesian classifiers</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th conference on Uncertainty in artificial intelligence</title>
		<meeting>the 11th conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="338" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics Education Library</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="27" to="71" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast effective rule induction</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Machine Learning (ICML)</title>
		<meeting>the 12th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Performance Study on Rulebased Classification Techniques across Multiple Database Relations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Vijayalakshmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundation of Computer Science FCS</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Building and applying logistic regression models. Categorical Data Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agresti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="211" to="266" />
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Root mean square error (RMSE) or mean absolute error (MAE)?-Arguments against avoiding RMSE in the literature</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Draxler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geoscientific Model Development</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1247" to="1250" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An extensive comparison of bug prediction approaches</title>
		<author>
			<persName><forename type="first">M</forename><surname>D'ambros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lanza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Robbes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE Working Conference on Mining Software Repositories (MSR)</title>
		<meeting>the 7th IEEE Working Conference on Mining Software Repositories (MSR)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="31" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Benchmarking classification models for software defect prediction: A proposed framework and novel findings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lessmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baesens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pietsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="485" to="534" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Elblocker: Predicting blocking bugs with ensemble imbalance learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shihab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Crossproject build co-change prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shihab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on. Software Analysis, Evolution and Reengineering (SANER)</title>
		<meeting>the 22nd International Conference on. Software Analysis, Evolution and Reengineering (SANER)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Characterizing and predicting blocking bugs in open source projects</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shihab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Working Conference on Mining Software Repositories (MSR)</title>
		<meeting>the 11th Working Conference on Mining Software Repositories (MSR)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mining cochange information to understand when build changes are necessary</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference Software Maintenance and Evolution (ICSME)</title>
		<meeting>the 30th International Conference Software Maintenance and Evolution (ICSME)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Data sets and data quality in software engineering</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Liebchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Predictor Models in Software Engineering</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="39" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An empirical study of learning from imbalanced data using random forest</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Golawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hulse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Tools with Artificial Intelligence (ICTAI)</title>
		<meeting>the 19th International Conference on Tools with Artificial Intelligence (ICTAI)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="310" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The relationship between Precision-Recall and ROC curves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning (ICML)</title>
		<meeting>the 23rd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A two-stage data preprocessing approach for software defect prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference Software Security and Reliability (SERE)</title>
		<meeting>the 8th International Conference Software Security and Reliability (SERE)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="20" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">FECAR: A feature selection framework for software defect prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Computer Software and Applications Conference (COMPSAC)</title>
		<meeting>the 38th Annual Computer Software and Applications Conference (COMPSAC)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="426" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">MICHAC: Defect Prediction via Feature Selection based on Maximal Information Coefficient with Hierarchical Agglomerative Clustering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Software Analysis, Evolution and Reengineering (SANER)</title>
		<meeting>the 23rd International Conference on Software Analysis, Evolution and Reengineering (SANER)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="370" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A hybrid genetic algorithm for feature selection wrapper based on mutual information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1825" to="1844" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Zepeda-Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Resendis-Antonio</surname></persName>
		</author>
		<title level="m">Hierarchical agglomerative clustering. Encyclopedia of Systems Biology</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="886" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hierarchical clustering to measure connectivity in fMRI resting-state data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Haughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Carew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Arfanakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maravilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic resonance imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="317" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Principal component analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Bro</surname></persName>
		</author>
		<author>
			<persName><surname>Smilde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytical Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2812" to="2831" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Halstead</surname></persName>
		</author>
		<title level="m">Elements of Software Science</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier North Holland</publisher>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A complexity measure</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Mccabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="page" from="308" to="320" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Robust classification for imprecise environments</title>
		<author>
			<persName><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="231" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A general software defect-proneness prediction framework</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="356" to="370" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Nonparametric statistics: a step-bystep approach</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Corder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Foreman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Revisiting the impact of classification techniques on the performance of defect prediction models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ghotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 37th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="789" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Data mining static code attributes to learn defect predictors</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="13" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Defect prediction from static code features: current results, limitations, new approaches</title>
		<author>
			<persName><forename type="first">T</forename><surname>Menzies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Milton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Turhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cukic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automated Software Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="375" to="407" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Reducing false alarms in software defect prediction by decision threshold optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tosun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Symposium on Empirical Software Engineering and Measurement</title>
		<meeting>the 3rd International Symposium on Empirical Software Engineering and Measurement</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="477" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Data Quality: Some Comments on the NASA Software Defect Datasets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1208" to="1215" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Automated parameter optimization of classification techniques for defect prediction models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tantithamthavorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering (ICSE)</title>
		<meeting>the 38th International Conference on Software Engineering (ICSE)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="321" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Heterogeneous defect prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Joint Meeting on Foundations of Software Engineering(FSE)</title>
		<meeting>the 10th Joint Meeting on Foundations of Software Engineering(FSE)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="508" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A cluster analysis method for grouping means in the analysis of variance</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="page" from="507" to="512" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Power and type I errors rate of Scott-Knott, Tukey and Newman-Keuls tests under normal and no-normal distributions of the residues</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revista de Matemática e Estatística</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="83" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Reducing features to improve code change-based bug prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shivaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Akella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="552" to="569" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Choosing software metrics for defect prediction: an investigation on feature selection techniques. Software: Practice and Experience</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Seliya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="579" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Metric selection for software defect prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hulse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Software Engineering and Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="237" to="257" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
