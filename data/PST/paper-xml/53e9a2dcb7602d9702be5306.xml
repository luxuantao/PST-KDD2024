<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A swarm intelligence approach to the quadratic minimum spanning tree problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shyam</forename><surname>Sundar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Hyderabad</orgName>
								<address>
									<postCode>500 046</postCode>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Alok</forename><surname>Singh</surname></persName>
							<email>alokcs@uohyd.ernet.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Hyderabad</orgName>
								<address>
									<postCode>500 046</postCode>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A swarm intelligence approach to the quadratic minimum spanning tree problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8EC5276B3E1B43320774F79D5FF87766</idno>
					<idno type="DOI">10.1016/j.ins.2010.05.001</idno>
					<note type="submission">Received 2 October 2009 Received in revised form 9 March 2010 Accepted 1 May 2010</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T10:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Artificial bee colony algorithm Constrained optimization Heuristic Quadratic minimum spanning tree problem Swarm intelligence</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The quadratic minimum spanning tree problem (Q-MST) is an extension of the minimum spanning tree problem (MST). In Q-MST, in addition to edge costs, costs are also associated with ordered pairs of distinct edges and one has to find a spanning tree that minimizes the sumtotal of the costs of individual edges present in the spanning tree and the costs of the ordered pairs containing only edges present in the spanning tree. Though MST can be solved in polynomial time, Q-MST is NP-Hard. In this paper we present an artificial bee colony (ABC) algorithm to solve Q-MST. The ABC algorithm is a new swarm intelligence approach inspired by intelligent foraging behavior of honey bees. Computational results show the effectiveness of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The quadratic minimum spanning tree problem (Q-MST) is an extension of the well known minimum spanning tree problem (MST) in graphs. In Q-MST, costs are associated not only with edges of the graph but also with ordered pairs of distinct edges and the objective is to find a spanning tree that minimizes the sumtotal of the costs associated with individual edges and the costs resulting from ordered pairs consisting of those edges present in the spanning tree. Formally, let G = (V, E) be a connected undirected graph, where V denotes the set of nodes and E denotes the set of edges. Given a non-negative cost function w : E ! R þ associated with edges of G and a non-negative cost function c : ðE Â E À fðe; eÞ; 8e 2 EgÞ ! R þ associated with ordered pairs of distinct edges, the Q-MST problem seeks a spanning tree T # E that minimizes</p><formula xml:id="formula_0">X e 1 2T X e 2 2T e 2 -e 1 cðe 1 ; e 2 Þ þ X e2T<label>wðeÞ</label></formula><p>Q-MST has several practical applications. It occurs when transferring oil from one pipe to another in a situation where the cost depends on the type of interface between two pipes. This quadratic cost structure also arises in the connection of overground and underground cables or in a transportation or road network with turn penalties. The presence of quadratic costs in all these cases leads to the minimum spanning tree problem with quadratic cost instead of the usual linear cost <ref type="bibr" target="#b18">[16]</ref>.</p><p>Q-MST problem was introduced and proved NP-Hard by Asad and Xu <ref type="bibr" target="#b3">[1,</ref><ref type="bibr" target="#b17">15]</ref>. Due to the NP-Hard nature of Q-MST, any exact method is not practical even for moderately large instances and one has to look for heuristics.</p><p>Assad and Xu <ref type="bibr" target="#b3">[1,</ref><ref type="bibr" target="#b17">15]</ref> proposed a branch-and-bound based exact method and two heuristic for the Q-MST and applied them on graph instances with number of nodes between 6 and 15. Even on these small instances, the solutions obtained by the two heuristics were far from optimal. Zhou and Gen <ref type="bibr" target="#b18">[16]</ref> proposed a genetic algorithm based on Prüfer encoding <ref type="bibr" target="#b13">[11]</ref> for the Q-MST problem and observed that this genetic algorithm is superior to two heuristic algorithms of <ref type="bibr" target="#b3">[1,</ref><ref type="bibr" target="#b17">15]</ref> on random instances with number of nodes between 6 and 50. Soak et al. <ref type="bibr" target="#b16">[14]</ref> proposed edge-window-decoder encoding and showed that a genetic algorithm based on this encoding performs much better than genetic algorithms based on other encodings on Q-MST and other problems. All algorithms were tested by Soak et al. on Euclidean instances with number of nodes between 50 and 100.</p><p>In this paper, we have proposed an artificial bee colony algorithm (ABC) to solve Q-MST. The ABC algorithm is a new swarm intelligence technique based on the intelligent foraging behavior of honey bees. This technique was proposed by Karaboga <ref type="bibr">[2]</ref>. We have compared our ABC approach with the best approaches. Computational results demonstrate the effectiveness of our approach.</p><p>The rest of this paper is organized as follows: Section 2 provides a brief introduction to the artificial bee colony algorithm. Section 3 describes our ABC approach for Q-MST. Computational results are reported in Section 4, whereas Section 5 contains some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Artificial bee colony algorithm</head><p>The artificial bee colony (ABC) algorithm is a new swarm intelligence technique inspired by intelligent foraging behavior of honey bees. The first framework of ABC algorithm mimicking the foraging behavior of honey bee swarm in finding good solutions to combinatorial optimization problems was presented by Karaboga <ref type="bibr">[2]</ref>. Further developments in the ABC Algorithm have been carried out by , Singh <ref type="bibr" target="#b15">[13]</ref> and Pan et al. <ref type="bibr" target="#b11">[9]</ref>. On the basis of their foraging behaviors, real bees are classified into three groups -employed, scouts and onlookers. All bees which are presently exploiting a food source are termed ''employed". The employed bees bring loads of nectar from the food source to the hive and may share the information about their food sources with onlooker bees. ''Onlookers" are those bees that wait in the hive for employed bees to share information about their food sources. Those bees, which are presently searching for new food sources in the neighborhood of the hive, are termed ''scouts". Employed bees share information about their food sources by dancing in a common area in the hive called dance area. The nature and the duration of a dance depends on the nectar content of the food source currently being tapped by the dancing bee. Onlooker bees observe numerous dances before selecting a food source. The onlookers have a tendency to select a food source according to a probability proportional to the nectar content of that food source. Therefore, good food sources attract more bees than the bad ones. Whenever a scout or a onlooker finds a food source it becomes employed. Whenever a food source is exhausted fully, all those employed bees, which are currently exploiting it, abandon it and become scouts or onlookers. Therefore, employed bees and onlookers bees do the job of exploitation, whereas exploration is left to scouts.</p><p>Karaboga <ref type="bibr">[2]</ref> modeled this intelligent foraging behavior of real honey bee swarm into artificial bee colony (ABC) algorithm to solve real world optimization problems. In ABC algorithm model, Karaboga also classified the colony of artificial bees into same three groups -employed, onlookers and scouts. First half of the colony consists of employed bees, whereas the latter half consists of onlookers. In ABC algorithm, each food source represents a candidate solution to the problem. Each employed bee is associated with a unique food source, and, therefore in ABC algorithm, the number of employed bees is equal to the number of food sources. The nectar amount of a food source is a function of the quality (fitness) of the candidate solution being represented by that food source.</p><p>ABC algorithm is an iterative algorithm. It starts by associating each employed bee with a randomly generated food source (solution). Then, during each iteration, each employed bee determines a new neighboring food source of its currently associated food source and computes the nectar amount (fitness) of this new food source. If the nectar amount of this new food source is higher than that of its currently associated food source, then this employed bee moves to this new food source abandoning the old one, otherwise it continues with the old one. When this process is completed by all employed bees, then they start sharing information about their food sources with onlookers. Each onlooker selects a food source probabilistically according to the nectar amount (fitness) of that food source. The probability p i of selecting a food source i is computed as:</p><formula xml:id="formula_1">p i ¼ f i P k j¼1 f j</formula><p>where f i is the fitness of the candidate solution associated with the food source i and k is the total number of food sources. This selection method is known by the name ''roulette wheel selection method" in genetic algorithm community. In roulette wheel selection method, candidate solutions are selected from the population randomly, with their probability of selection proportional to their relative fitness in the population. Thus, fitter candidate solutions have a greater chance of survival than the weaker ones. Therefore, rich food source attracts more onlookers than the poor ones. Once all onlookers have selected their food sources in the aforementioned way, each of them determines a new neighboring food source of its selected food source and computes the nectar amount of this new food source. Among all the neighboring food sources determined by onlookers associated with a particular food source i and food source i itself, best food source will be the new location of food source i. If a candidate solution represented by a food source i does not improve for a predetermined number of iterations, then the solution represented by food source i is considered to be explored fully and hence food source i is presumed to be exhausted and its associated employed bee abandons it to become scout. This scout is transformed into an employed bee immediately by associating it with a randomly generated new solution. When the new locations of all food sources are determined, then the next iteration of the ABC algorithm begins. This process is repeated again and again until termination criterion is satisfied.</p><p>The procedure for determining a new food source in the neighborhood of a particular food source is problem-specific. Initially, Karaboga <ref type="bibr">[2]</ref> designed the ABC algorithm for real parameter optimization, and, accordingly a new neighboring food source of a particular food source is generated by changing the value of one randomly chosen solution parameter, while keeping other parameters unchanged. This is done by adding to the current value of the chosen parameter the product of a uniform variate in [À1, 1] and the difference in values of this parameter for this food source and some other randomly chosen food source. But, this approach cannot be used for discrete optimization problems for which it generates at best a random effect. Singh <ref type="bibr" target="#b15">[13]</ref> subsequently proposed a method which is appropriate for subset selection problems. In his method, to generate a neighboring solution, an object is randomly dropped from the solution and in its place another object, which is not already present in the solution is added. The object to be added is selected from another randomly chosen solution. If there are more than one candidate object for addition then ties are broken arbitrarily. This approach is based on the idea that if an object is present in one good solution then in all likelihood this object is present in many good solutions. Another advantage of this method is that it keeps in control the number of duplicate solutions in the population. If this method fails to find an object in the randomly chosen solution different from the objects in the original solution then that means that the two solutions are identical. Such a situation was termed ''collision" and was resolved by making the employed bee associated with the original solution scout. This eliminates one duplicate solution.</p><p>A good survey on the ABC and other algorithms simulating bee swarm intelligence can be found in <ref type="bibr" target="#b10">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ABC algorithm for Q-MST</head><p>The main features of our ABC algorithm for Q-MST are described below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Solution encoding</head><p>Edge-set encoding <ref type="bibr" target="#b14">[12]</ref> has been used to represent a spanning tree. In edge-set encoding a spanning tree is represented directly by the set of its n À 1 edges, where n is the number of nodes in the graph. The reason for this choice is that this encoding offers high locality and the problem-specific heuristics can be easily incorporated within the metaheuristic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Initialization</head><p>The algorithm is initialized by associating a randomly generated solution to each employed bee. For the purpose of initialization phase, we have defined a special cost, called potential cost, which is associated with each edge. The potential cost of an edge e is the sum of all costs that can be attributed to e, i.e., wðeÞ þ P</p><formula xml:id="formula_2">e 1 2E e 1 -e</formula><p>ðcðe; e 1 Þ þ cðe 1 ; eÞÞ. Each initial random solution is generated by an iterative process that is similar to Prim's Algorithm <ref type="bibr" target="#b12">[10]</ref>. However, instead of picking a least cost edge connecting a node in the partially constructed tree to a node not in the tree, an edge is picked at random from all the candidate edges using the roulette wheel selection, where the probability of selection of an edge is inversely proportional to the potential cost of that edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Probability of selecting a food source</head><p>In our ABC algorithm, for selecting a food source for an onlooker bee, we have used the binary tournament selection method in place of the usual roulette wheel selection method. In the binary tournament selection method, two different food sources are picked at random and better of the two food sources (according to cost function defined in Section 1) is selected with probability bt, otherwise worse of two food sources is selected with probability 1 À bt. Roulette wheel selection method was also tried, but computational experiments showed that the performance of the binary tournament selection method is better than the roulette wheel selection method in terms of solution quality. Another advantage of the binary tournament selection method is that it is computationally efficient than the roulette wheel selection method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Determination of a food source in the neighborhood of a food source</head><p>Our method follows from the ideas presented in <ref type="bibr" target="#b15">[13]</ref>. In order to generate a solution in the neighborhood of a particular solution say solution i, first we create a copy i 0 of solution i. An edge e is randomly deleted from i 0 . This delete operation results into partitioning of the spanning tree into two components and makes solution i 0 infeasible. To make i 0 feasible again, we randomly select another solution j different from solution i 0 . An edge e 0 , different from edge e is searched in j, which can connect the two components of i 0 and has minimum cost among all such candidate edges in solution j. Here cost of edge e 0 means the sum of cost of edge e 0 itself and the intercost with remaining edges of i 0 . If there is no edge e 0 in solution j different from edge e, which can connect the two components of solution i 0 , then solution i 0 is restored by adding the deleted edge e into it. The edge e is placed in a tabu list so that it cannot be selected again in subsequent trials and another edge is deleted randomly and the whole procedure is repeated. Note that searching for an edge connecting the two components in another solution is more efficient than searching all possible edges connecting the two components. This is based on the observation that if an edge occurs in one good solution then the same edge will occur in many good solutions. If the above procedure fails even after t t trials then it shows a lack of diversity in the population. If such a situation arises while determining a new neighboring solution for an employed bee, then employed bee associated with this food source abandons it to become scout so that the population can be made more diversified. This scout is immediately made employed by associating it with a new randomly generated food source. However, if such a situation arises while determining a new neighboring solution for an onlooker, then we discard this solution by artificially assigning it an objective value higher than the associated employed bee solution, so that it cannot be selected in next generation. It should be noted that it is worthless to generate a food source randomly for an onlooker, because for survival this randomly generated food source has to compete with the original food source as well as with the food sources of all onlookers which are associated with the same original food source. Hence, it is highly unlikely that such a randomly generated solution survives.</p><p>Algorithm 1 gives the pseudo-code of the aforementioned procedure for determining a neighboring solution. The algorithm returns the newly determined neighboring solution if it succeeds in finding one within t t trials, otherwise it returns the ;. Fig. <ref type="figure" target="#fig_0">1</ref> explains the procedure for determining the neighboring food source with the help of an example. Suppose we have a complete graph with 6 nodes. Fig. <ref type="figure" target="#fig_0">1</ref>(a) and (b) respectively shows the intercost matrix and the graph itself. The diagonal elements of this intercost matrix represent the costs of individual edges, whereas off diagonal elements represent the intercosts among edges. Consider the spanning tree shown in Fig. <ref type="figure" target="#fig_0">1(c</ref>). It has a cost of 374. In order to generate a solution in the neighborhood of this solution, we first delete an edge say e15 (as shown in Fig. <ref type="figure" target="#fig_0">1(d</ref>) by dashed line). This creates two components. The one component contains nodes 1, 2, 6, whereas the other contains nodes 3, 4, 5. Now, another solution is chosen randomly say the solution shown in Fig. <ref type="figure" target="#fig_0">1(e</ref>). This solution contains 3 candidate edges e6, e8 and e12, which can be inserted in place of e15. The total costs of e6, e8, e12 are 172 (88 + 16 + 12 + 9+6 + 8 + 19 + 9+5), 68 (2 + 13 + 16 + 13 + 12 + 2 + 1 + 7+2), 117 (28 + 8 + 17 + 11 + 9+11 + 17 + 4+12) respectively. Among these three candidate edges, edge e8 has the least cost. Therefore, edge e8 is selected for insertion in place of e15. This leads to a tree shown in Fig. <ref type="figure" target="#fig_0">1(f</ref>), which has a total cost of 333.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Other features</head><p>If a food source (solution) does not improve for a predetermined number of iterationslimit, then employed bee associated with that food source abandons it and becomes a scout. The parameter limit is an important control parameter of the ABC algorithm as it is responsible for maintaining the delicate balance between exploration and exploitation. A small value of limit parameter favors exploration over exploitation whereas reverse is true for large value. There is also a second possibility in which an employed bee can become a scout as described in Section 3.4. This second possibility is introduced as an autocorrection measure as it forces the ABC algorithm to move towards exploration whenever there is a lack of diversity in the population. Unlike the traditional ABC algorithm, in our ABC algorithm there is no upper limit on the number of scouts in a single iteration. In fact, number of scout in an iteration depends on the aforementioned two condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Local search</head><p>After completion of ABC algorithm, an attempt is made to further ameliorate the quality of the best solution obtained through ABC algorithm by using a local search. Our local search follows an iterative process. During each iteration the local search considers each edge of the solution one-by-one. It deletes the edge in consideration from the solution and evaluates each graph edge connecting the two resulting components for inclusion. The edge that yields a solution of least cost will be selected for inclusion. The local search is applied again and again till a complete iteration fails to ameliorate the solution. We have also experimented with this local search by placing it inside the ABC algorithm but the resulting approach was found to be too slow to be of any practical use.</p><p>Algorithm 2 gives the pseudo-code of our ABC approach for the Q-MST.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Computational results</head><p>Our ABC algorithm for the Q-MST problem has been implemented in C and executed on a Linux based 3.0 GHz core 2 duo system with 2 GB RAM. In all our computational experiments with our ABC algorithm we have used a population of 400 bees, 200 of these bees are employed and the remaining 200 are onlookers. We have set limit = 150, t t = 5 and bt = 0.8. All these parameter values are set empirically after a large number of trials. These parameter values provide good results though they may not be optimal for all instances. In subsequent subsections, we compare the performance of our ABC approach with genetic algorithms proposed in <ref type="bibr" target="#b18">[16,</ref><ref type="bibr" target="#b16">14]</ref>, which are the best heuristics known for the Q-MST Problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Comparison of our ABC approach with genetic algorithm of Zhou and Gen</head><p>First, we will compare our ABC approach with genetic algorithm of Zhou and Gen <ref type="bibr" target="#b18">[16]</ref>. As the test instances used in <ref type="bibr" target="#b18">[16]</ref> were not available, therefore, to compare our ABC approach with the genetic algorithm proposed in <ref type="bibr" target="#b18">[16]</ref>, we have reimple-mented this genetic algorithm. This also facilitated comparison on larger instances as Zhou and Gen originally tested their genetic algorithm on smaller instances with number of nodes between 6 and 50. Hereafter, the genetic algorithm of Zhou and Gen will be referred to as ZG-GA. All parameter settings for ZG-GA are same as used in <ref type="bibr" target="#b18">[16]</ref> except the termination condition.</p><p>We have compared our ABC approach with ZG-GA on a set of 18 instances that were generated exactly in the manner as in <ref type="bibr" target="#b18">[16]</ref>. All instances represent complete graphs with integer edge-costs uniformly distributed in <ref type="bibr" target="#b3">[1,</ref><ref type="bibr">100]</ref>. The intercosts between edges are also integers and uniformly distributed in <ref type="bibr">[1,2_0]</ref>. For each value of n 2 25, 50, 100, 150, 200, 250, there are 3 instances leading to a total of 18 instances. We have experimented only up to instances with n = 250 due to the prohibitive size of intercost matrix at higher values of n.</p><p>We have allowed our ABC approach to execute till the best solution fails to improve over max(10n, 1000) iterations. To allow a fair comparison, ZG-GA terminates when the best solution does not improve over an equivalent number of solution generated. The ZG-GA uses a population of 300, therefore, it terminates when the best solution does not improve over max <ref type="bibr">(13.33n, 1333)</ref> iterations. Each approach is executed 20 times on each instance. The local search described in Section 3.6 can be used to improve the best solution of ZG-GA also. Therefore, to compare the ABC algorithm with local search, we have incorporated local search with ZG-GA also.</p><p>Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table">2</ref> compare the performance of ZG-GA with ABC. Table <ref type="table" target="#tab_0">1</ref> reports the performance of two approaches without using the local search, whereas Table <ref type="table">2</ref> reports the same when the local search described in Section 3.6 is used to improve the best solution obtained by the two approaches. For each instance these tables report the best and average solution found by each of the two methods, standard deviation of solution values and average execution time in seconds. These tables clearly show the superiority of ABC over ZG-GA in terms of solution quality. Best and average solutions found by ABC are always better than ZG-GA. Moreover, standard deviations of solution values are also less for ABC. This shows its robustness. Except for small instances, ZG-GA is faster than the ABC approach. This is due to the premature convergence of ZG-GA at suboptimal solutions in many cases.</p><p>4.2. Comparison of our ABC approach with two best genetic algorithms of Soak et al.</p><p>We have used the same set of Euclidean instances as used in <ref type="bibr" target="#b16">[14]</ref>. This set contains 6 instances each representing a complete graph with number of nodes between 50 and 100. In all these instances, nodes are distributed uniformly at random on a 500 Â 500 grid. The edge costs are the integer Euclidean distance between these points. The intercost between edges are uniformly distributed between <ref type="bibr" target="#b3">[1,</ref><ref type="bibr">20]</ref>. Soak et al. presented a number of genetic algorithms and we have taken the two best performing genetic algorithms (EWD + CGPX with dK-TCR and EWD + ANX with dK-TCR) for comparison with our ABC approach. We have also included the ZG-GA in this comparison. To allow a fair comparison we have not used the local search of Section 3.6 with our ABC approach or with ZG-GA. The genetic algorithms in Soak et al. generates a total of 10,00,000 solutions, therefore, we have also allowed our ABC approach and ZG-GA to generate only 10,00,000 solutions. Like EWD + CGPX with dK-TCR and EWD + ANX with dK-TCR, we have also executed our ABC approach and ZG-GA 20 times on each instance.</p><p>Table <ref type="table" target="#tab_1">3</ref> reports the performance of ZG-GA, EWD + CGPX with dK-TCR, EWD + ANX with dK-TCR along with our ABC approach. The results reported for EWD + CGPX with dK-TCR, EWD + ANX with dK-TCR are obtained from the results presented in Table <ref type="table">IX</ref> of <ref type="bibr" target="#b16">[14]</ref>. As table IX of <ref type="bibr" target="#b16">[14]</ref> presents the results in terms of gap, we have converted the results presented there to our format before reporting. As shown by this table, ABC approach has performed best in terms of solution quality followed by EWD + ANX with dK-TCR and EWD + CGPX with dK-TCR. ZG-GA has performed the worst. Best and average solution quality of our approach are always better than other approaches. Moreover, its standard deviation of solution values is also the smallest among all the four approaches. EWD + CGPX with dK-TCR and EWD + ANX with dK-TCR were executed on Pentium 4, 1.6 GHz, therefore, it is not possible to compare their execution times with our ABC approach and ZG-GA. However, we can safely say that even after compensating for processing speed, ABC approach and ZG-GA are faster than the two genetic algorithms. Though ZG-GA is fastest, it has performed the worst.</p><p>We have also executed our ABC approach and ZG-GA on these 6 Euclidean instances with the same termination condition as used in Section 4.1. Table <ref type="table" target="#tab_2">4</ref> reports the results obtained without using the local search, whereas Table <ref type="table" target="#tab_3">5</ref> reports the results with local search. Best and average solutions obtained by our ABC approach improved slightly in comparison to Table <ref type="table" target="#tab_1">3</ref> at the expense of increased computation times. Except for one instance where the best solution found by ZG-GA with local search is better than the ABC with local search, solution quality of our ABC approach is always better. However, on the same instance ABC without local search found the better best solution than ZG-GA without local search. Therefore, even on this instance the superiority of ZG-GA with local search over ABC with local search is purely due to the local search. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper we have presented an artificial bee colony algorithm for the Q-MST problem. We have compared our approach against the genetic algorithms proposed in <ref type="bibr" target="#b18">[16,</ref><ref type="bibr" target="#b16">14]</ref>. Our approach obtained better quality solutions than other approaches. Though, the genetic algorithm of <ref type="bibr" target="#b18">[16]</ref> is faster than our ABC approach, it performed worst in terms of solution quality among all the approaches considered in this paper.</p><p>As a future work, we intend to extend our approach to other NP-Hard constrained spanning tree problems such as diameter-constrained minimum spanning tree (DCMST) problem, bounded-diameter minimum spanning tree (BDMST) problem, etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example illustrating the determination of a neighboring food source.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Results of ABC algorithm without local search and ZG-GA without local search on 18 random instances.</figDesc><table><row><cell>Instance</cell><cell>ZG-GA</cell><cell></cell><cell></cell><cell></cell><cell>ABC</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell></row><row><cell>25.1</cell><cell>5301</cell><cell>5460.05</cell><cell>81.37</cell><cell>1.14</cell><cell>5085</cell><cell>5085.85</cell><cell>3.71</cell><cell>0.91</cell></row><row><cell>25.2</cell><cell>5293</cell><cell>5431.10</cell><cell>73.57</cell><cell>1.00</cell><cell>5081</cell><cell>5101.50</cell><cell>6.81</cell><cell>1.02</cell></row><row><cell>25.3</cell><cell>5273</cell><cell>5389.50</cell><cell>63.58</cell><cell>1.16</cell><cell>4962</cell><cell>4962.00</cell><cell>0.00</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Results of ABC algorithm, EWD + CGPX with dK-TCR, EWD + ANX with dK-TCR and ZG-GA on 6 Euclidean instances.</figDesc><table><row><cell>Instance</cell><cell>ZG-GA</cell><cell></cell><cell></cell><cell></cell><cell cols="2">EWD + CGPX (dK-TCR) a</cell><cell></cell><cell></cell><cell cols="2">EWD + ANX (dK-TCR) a</cell><cell></cell><cell></cell><cell>ABC</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>Results of ABC algorithm without local search and ZG-GA without local search on 6 Euclidean instances using the termination criterion of Section 4.1.</figDesc><table><row><cell>Instance</cell><cell>ZG-GA</cell><cell></cell><cell></cell><cell></cell><cell>ABC</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell></row><row><cell>50</cell><cell>27,229</cell><cell>27821.15</cell><cell>391.84</cell><cell>2.87</cell><cell>25,200</cell><cell>25201.30</cell><cell>2.37</cell><cell>4.35</cell></row><row><cell>60</cell><cell>37,921</cell><cell>38698.10</cell><cell>456.02</cell><cell>4.41</cell><cell>35,487</cell><cell>35615.35</cell><cell>42.91</cell><cell>8.44</cell></row><row><cell>70</cell><cell>51,760</cell><cell>52556.15</cell><cell>515.70</cell><cell>7.04</cell><cell>48,125</cell><cell>48173.10</cell><cell>31.28</cell><cell>16.84</cell></row><row><cell>80</cell><cell>67,732</cell><cell>68751.25</cell><cell>496.28</cell><cell>10.53</cell><cell>63,057</cell><cell>63150.85</cell><cell>46.24</cell><cell>20.83</cell></row><row><cell>90</cell><cell>84,154</cell><cell>85886.20</cell><cell>797.53</cell><cell>16.02</cell><cell>78,879</cell><cell>79090.15</cell><cell>129.69</cell><cell>37.49</cell></row><row><cell>100</cell><cell>103,976</cell><cell>105257.60</cell><cell>645.33</cell><cell>19.37</cell><cell>96,750</cell><cell>97038.70</cell><cell>154.05</cell><cell>76.92</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5</head><label>5</label><figDesc>Results of ABC algorithm with local search and ZG-GA with local search on 6 Euclidean instances using the termination criterion of Section 4.1.</figDesc><table><row><cell>Instance</cell><cell>ZG-GA</cell><cell></cell><cell></cell><cell></cell><cell>ABC</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell><cell>Min</cell><cell>Avg</cell><cell>SD</cell><cell>TET</cell></row><row><cell>50</cell><cell>25,262</cell><cell>25414.30</cell><cell>99.48</cell><cell>2.87</cell><cell>25,200</cell><cell>25201.30</cell><cell>2.37</cell><cell>4.35</cell></row><row><cell>60</cell><cell>35,447</cell><cell>35860.55</cell><cell>129.93</cell><cell>4.43</cell><cell>35,466</cell><cell>35603.10</cell><cell>48.31</cell><cell>8.45</cell></row><row><cell>70</cell><cell>48,365</cell><cell>48609.95</cell><cell>195.97</cell><cell>7.12</cell><cell>48,125</cell><cell>48166.20</cell><cell>27.71</cell><cell>16.86</cell></row><row><cell>80</cell><cell>63,248</cell><cell>63664.60</cell><cell>215.92</cell><cell>10.72</cell><cell>63,022</cell><cell>63130.30</cell><cell>47.55</cell><cell>20.89</cell></row><row><cell>90</cell><cell>79,361</cell><cell>79828.60</cell><cell>282.68</cell><cell>16.40</cell><cell>78,879</cell><cell>79076.65</cell><cell>122.44</cell><cell>37.59</cell></row><row><cell>100</cell><cell>97,414</cell><cell>98021.35</cell><cell>397.91</cell><cell>20.07</cell><cell>96,750</cell><cell>97018.75</cell><cell>139.48</cell><cell>77.12</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>S. Sundar, A. Singh / Information Sciences 180 (2010) 3182-3191</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are thankful to Dr. Sang-Moon Soak for providing the Q-MST instances used in <ref type="bibr" target="#b16">[14]</ref>. We also thank three anonymous reviewers for their valuable comments and suggestions, which helped in improving the presentation of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">16 Table 2 Results of ABC algorithm with local search and ZG-GA with local search on 18 random instances</title>
		<idno>826 614209.00 1219.67 1819.58 587</idno>
	</analytic>
	<monogr>
		<title level="j">Instance ZG-GA ABC Min Avg SD TET Min Avg SD TET</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">5085</biblScope>
			<date type="published" when="2322">10 483.73 2322</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="3182" to="3191" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The quadratic minimum spanning tree problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Assad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="399" to="417" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An idea based on honey bee swarm for numerical optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<idno>TR06</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Turkey</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering Department, Erciyes University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An artificial bee colony (ABC) algorithm for numeric function optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE swarm intelligence symposium</title>
		<meeting>the IEEE swarm intelligence symposium<address><addrLine>Indianapolis, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">May 12-14, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Artificial bee colony (ABC) optimization algorithm for solving constrained optimization problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4529</biblScope>
			<biblScope unit="page" from="789" to="798" />
			<date type="published" when="2007">2007</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the performance of artificial bee colony (ABC) algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Basturk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="687" to="697" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comparative study of artificial bee colony algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="page" from="108" to="132" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey: algorithms simulating bee swarm intelligence</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karaboga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="61" to="85" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A discrete artificial bee colony algorithm for the lot-streaming flow shop scheduling problem</title>
		<author>
			<persName><forename type="first">Q.-K</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Tasgetiren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2009.12.025</idno>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shortest connection networks and some generalizations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Prim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Systems Technical Journal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1389" to="1401" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<author>
			<persName><forename type="first">H</forename><surname>Prüfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neuer beweis eines satzes über permutationen</title>
		<imprint>
			<date type="published" when="1918">1918</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="742" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Edge-sets: an effective evolutionary coding of spanning trees</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Raidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Julstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="225" to="239" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An artificial bee colony algorithm for the leaf-constrained minimum spanning tree problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="625" to="631" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The edge-window-decoder representation for tree-based problems</title>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Soak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Corne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="124" to="144" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the quadratic minimum spanning tree problem</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1995 Japan-China International Workshops on Information Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Gen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ashikaga</surname></persName>
		</editor>
		<meeting>1995 Japan-China International Workshops on Information Systems</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="141" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An effective genetic algorithm approach to the quadratic minimum spanning tree problem</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Operations Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="229" to="237" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
