<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge-Based Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Oscar</forename><surname>Araque</surname></persName>
							<email>o.araque@upm.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Systems Group</orgName>
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">Avenida Complutense</orgName>
								<address>
									<addrLine>30</addrLine>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ganggao</forename><surname>Zhu</surname></persName>
							<email>gzhu@dit.upm.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Systems Group</orgName>
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">Avenida Complutense</orgName>
								<address>
									<addrLine>30</addrLine>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
							<email>carlosangel.iglesias@upm.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Systems Group</orgName>
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">Avenida Complutense</orgName>
								<address>
									<addrLine>30</addrLine>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge-Based Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F8DA2D6DFF161ABEADE07D4521DA4182</idno>
					<idno type="DOI">10.1016/j.knosys.2018.12.005</idno>
					<note type="submission">Received 11 July 2018 Received in revised form 3 December 2018 Accepted 4 December 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T11:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Sentiment analysis Sentiment lexicon Semantic similarity Word embeddings</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Lexical resources are widely popular in the field of Sentiment Analysis, as they represent a resource that directly encodes sentimental knowledge. Usually sentiment lexica are used for polarity estimation through the matching of words contained in a text and their associated lexicon sentiment polarities. Nevertheless, such resources have limitations in vocabulary coverage and domain adaptation. Besides, many recent techniques exploit the concept of distributed semantics, normally through word embeddings. In this work, a semantic similarity metric is computed between text words and lexica vocabulary. Using this metric, this paper proposes a sentiment classification model that uses the semantic similarity measure in combination with embedding representations. In order to assess the effectiveness of this model, we perform an extensive evaluation. Experiments show that the proposed method can improve Sentiment Analysis performance over a strong baseline, being this improvement statistically significant. Finally, some characteristics of the proposed technique are studied, showing that the selection of lexicon words has an effect in cross-dataset performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The consistent growth of users and user-generated content in many web sites, social networks, and online consumer platforms such as Twitter, Amazon, and Yelp has incremented the quantity of opinionated information available in the internet. Such content has inherent value for a number of online and offline businesses, since online opinions can directly affect future sales in a wide range of fields such as hotels, e-commerce, restaurants, and electronics <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Consequently, interest towards opinion mining techniques as a way of automatically extracting and analyzing user-generated opinions has risen <ref type="bibr" target="#b2">[3]</ref>. In this context, Sentiment Analysis (SA) plays a key role.</p><p>Sentiment Analysis centers around the classification of sentiments, opinions or attitudes expressed in human-generated texts. For this end, text can be labeled into several categories, being positive and negative the most common. Since the study of opinions in text comprises a broad range of possibilities, SA can be classified into three categories, attending to the granularity level <ref type="bibr" target="#b2">[3]</ref>. Literature considers the following categorization, in increasing order of specificity: document level, as in a movie review that can span one or more paragraphs; sentence level, where sentiment is bounded to a singular sentence of text; and aspect level, in which case sentiment is associated with a word or small group of words (e.g., good food).</p><p>Due to the subjective nature of Sentiment Analysis, it is of no surprise that a key indicator of sentiment polarity are sentiment words. Good, great and brilliant can be considered positive words while bad, worse and disastrous can express negative attitudes. Consequently, sentiment lexicons, which gather sentiment words, are used extensively by the research community <ref type="bibr" target="#b3">[4]</ref>. Sentiment lexicons can be organized in three types, attending to which information is contained in them <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>: (i) those who contain only sentiment words (a list of words), (ii) the ones that are formed by both sentiment words and polarity orientations (a list of words with only positive and negative annotations), and (iii) the lexicons that offer sentiment words with orientation and intensity <ref type="bibr" target="#b6">[7]</ref> (a list of words with scalar numerical values).</p><p>The most popular approach that makes use of sentiment lexicons is keyword matching, also called keyword spotting <ref type="bibr" target="#b7">[8]</ref>. Basically, this technique consists in detecting the presence of certain sentiment bearer words, thus obtaining the sentiment estimation as an aggregate of the associated sentiment values. Although this method is certainly simple and computationally cheap, it is also limited, as it happens in the case of domain adaptation. Sentiment words can display variations in their polarity values depending on the contextual domain <ref type="bibr" target="#b8">[9]</ref>, language <ref type="bibr" target="#b9">[10]</ref> or even context <ref type="bibr" target="#b10">[11]</ref>, causing lexicon-based approaches to decrease their classification performance.</p><p>An additional challenge that arises in relation to the use of sentiment lexicons is the selection between the variety of these https://doi.org/10.1016/j.knosys.2018.12.005 0950-7051/© 2018 Published by Elsevier B.V. resources. It is still an open question how to select and process sentiment lexicons <ref type="bibr" target="#b11">[12]</ref>, and how this selection affects the performance of sentiment classification tasks.</p><p>Furthermore, distributed representations, or word embeddings <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, are considered a key characteristic of state-of-the-art Sentiment Analysis systems. These techniques encode text into fixedlength vectors that can be used directly by machine-learning methods, being neural networks the most used recently <ref type="bibr" target="#b14">[15]</ref>. The use of (deep) neural networks enables the system to learn complex features automatically extracted from data, minimizing manual domain-oriented efforts <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. Nevertheless, a requirement of these approaches is the use of large amounts of data, normally annotated <ref type="bibr" target="#b12">[13]</ref>. Efficiently training neural networks in small datasets is still an open challenge, whose resolutions could improve SA systems.</p><p>In light of such trends, it is reasonable to think that in order to improve sentiment analysis systems, lexicon exploitation methods should be improved, and that embedding models can be used to overcome lexicon limitations. This work addresses these challenges by proposing a method that exploits the similarity of sentiment lexicon words to input text. Particularly, the aforementioned approach makes use of the lexicon as a space to which analyzed text is projected, effectively representing text by how similar its component words are to lexicon words. Also, given that this method is based on the similarity measure, the proposed approach is not limited to the use of embedding models, but it can incorporate word to word similarity from additional sources, such as taxonomy sources like WordNet <ref type="bibr" target="#b17">[18]</ref>.</p><p>In this paper, we propose a semantic similarity based, sentiment classification model, which makes use of both sentiment lexicons and semantic models (e.g., embedding models, WordNet). Instead of keyword matching, features from text are extracted by computing the semantic similarity between input words and lexicon words. In this way, a lexicon is considered as a set of target words that can be used as a projective space, computing its similarity (semantic distance) with the input text. Besides these similarity-based features, our proposal is complemented with word embedding representations of the text. Both semantic distance and embeddings-based features are use in conjunction to feed a machine-learning algorithm with the objective of sentiment classification.</p><p>With the aim of studying the effectiveness of the proposed system and features, the evaluation makes use of seven public datasets, from both Twitter 1 and movie review domains. Moreover, several statistical studies are performed with the aim of characterizing the improvement of using semantic similarity features. Finally, we study how some characteristics of sentiment lexicons affect the system's performance.</p><p>With these proposals, we seek answer to the following research questions:</p><p>• Q1. Are the proposed semantic distance features more effective than word-matching approaches?</p><p>• Q2. How do embedding and taxonomy based similarity measures compare in terms of performance?</p><p>• Q3. How does lexicon characteristics affect the proposed feature extraction process?</p><p>The rest of the paper is structured as follows. Section 2 summarizes the previous work regarding semantic similarity and sentiment lexica. In Section 3, the proposed sentiment classification model is described. Following, in Section 4, we describe the experimental setup, aimed at empirically evaluating the proposed model, as well as these experimental results and discussion. Finally, the paper concludes with Section 5, that depicts the conclusions drawn from the evaluation and outlines the possible future lines of work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Overview of semantic similarity</head><p>Semantic similarity methods give numerical similarity scores to words in order to represent their semantic distance. In computational linguistics, semantic relatedness is inverse of semantic distance and assumes that two objects are semantically related if they have any kind of semantic relation <ref type="bibr" target="#b18">[19]</ref>. Semantic similarity is a special metric that represents the commonality of two concepts relying on their hierarchical relations <ref type="bibr" target="#b19">[20]</ref>. In general, semantic similarity is a special case of semantic relatedness <ref type="bibr" target="#b19">[20]</ref> which is a more general concept and does not necessarily rely on hierarchical relations. This work covers both semantic similarity and semantic relatedness. For convenience we call them semantic similarity interchangeably in the following sections and categorize them into corpus-based methods and knowledge-based methods <ref type="bibr" target="#b20">[21]</ref>. Corpus-based methods mainly rely on contextual information of words appearing in the corpus, thus they mainly measure general semantic relatedness between words. Knowledge-based methods derive semantic similarity of words based on hierarchical relations encoded in WordNet. Corpus-based methods have wider computational applications because they consider all kinds of semantic relations between words, while knowledge-based methods would be more useful when applications need to encode hierarchical relations between words. We review both types of methods in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Corpus-based methods</head><p>Corpus-based semantic similarity methods are based on word associations learned from large text collections following the distributional hypothesis <ref type="bibr" target="#b19">[20]</ref>. Two words are assumed to be more similar if their surrounding contexts are more similar or they appear together more frequently. The computation of corpusbased methods is based on statistics of word distributions or word co-occurrences. According to different computational models, there are count-based methods, e.g. Pointwise Mutual Information <ref type="bibr" target="#b21">[22]</ref> or Normalized Google Distance <ref type="bibr" target="#b22">[23]</ref>, and predictive methods, e.g. Word2Vec <ref type="bibr" target="#b12">[13]</ref>. Count-based methods count word co-occurrences and construct a word-word matrix, in which those co-occurrence statistics are directly applied with probabilistic models <ref type="bibr" target="#b21">[22]</ref>, matrix factorization <ref type="bibr" target="#b23">[24]</ref> and dimension reduction <ref type="bibr" target="#b24">[25]</ref>. Predictive-based methods directly learn dense vectors through predicting a word from its surrounding context. We use the predictive-based word embedding tool Word2Vec <ref type="bibr" target="#b12">[13]</ref> to learn dense vector representation of words, because it has been reported to have good performance in many applications <ref type="bibr" target="#b25">[26]</ref>. As suggested by the Word2Vec authors <ref type="bibr" target="#b12">[13]</ref>, the Continuous Bag of Words (CBOW) model is more computationally efficient and suitable for larger corpus than the skip-gram model. Thus, the CBOW model is used to train word vectors in a neural network architecture which consists of an input layer, a projection layer, and an output layer to predict a word given its surrounding words with a certain context window size. Formally, given a sequence of training words {w 1 , w 2 , . . . w T }, each word vector is trained to maximize the average log probability:</p><formula xml:id="formula_0">1 T T ∑ t=1 ∑ -c≤k≤c,k̸ =0 logp(w t |w t-k , . . . , w t+k ) (1)</formula><p>where k is the context window size and p(w t |w t-k , . . . , w t+k ) is the hierarchical softmax of the word vectors <ref type="bibr" target="#b12">[13]</ref>. Having the trained word vectors (the dimension is predefined empirically and we set 300 in our experiments), word similarity is computed using standard cosine similarity. Although the training process relies on a neural network based supervised prediction model, the real training results are the vector representation of words instead of the neural network prediction model. Because of such idea, the training of word embedding is unsupervised and can be applied in various textual corpus without labeled datasets. Furthermore, due to the simple neural network architecture and the use of hierarchical softmax, Word2Vec is able to address large corpus and the training is very efficient. However, since the training of word vectors only use word sequences, a wide variety of word relations are considered as equally related according to their cooccurrences, which makes the similarity between trained word vectors coarse and unable to address synonymous words and hierarchical relations accurately. In consequence, knowledge-based semantic similarity methods are considered to enrich some commonsense knowledge of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Knowledge-based methods</head><p>Knowledge-based semantic similarity methods measure the semantic similarity between words based on an ontology. Two words are considered to be more similar if they are located closer in the given ontology. The lexical database WordNet <ref type="bibr" target="#b17">[18]</ref> is used as background ontology, which is organized through synsets, being each synset a set of words sharing one common sense (synonyms). The hierarchical relations between synsets (i.e. hypernym and hyponymy), organize WordNet into a concept taxonomy. Having synonymous words in synsets and human defined hierarchical relations, knowledge-based semantic similarity methods are designed to encode this information to improve semantic similarity between words. Those semantic similarity methods are directly used for synsets rather than words, therefore, they need to be converted into word similarity by taking the maximal similarity score over all the synsets which are the senses of the words <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref>. This is based on the intuition that human would pay more attention to word similarities (i.e., most related senses) rather than their differences <ref type="bibr" target="#b27">[28]</ref>, which has been demonstrated in psychological studies <ref type="bibr" target="#b28">[29]</ref>. As polysemous words can be mapped to a set of synsets, let s(w) denote a set of synsets that are senses of word w, then word similarity is defined as:</p><formula xml:id="formula_1">sim word (w i , w j ) = max c i ∈s(w i ),c j ∈s(w j ) sim synset (c i , c j ) (2)</formula><p>where sim synset can be any semantic similarity methods used for WordNet synsets which are presented in the following of this section.</p><p>Many knowledge-based methods have been proposed in the literature <ref type="bibr" target="#b29">[30]</ref> for measuring similarity in WordNet exploiting various information such as shortest path length, depth, and Information Content (IC). The basic idea is counting the number of nodes or edges (shortest path) between two concepts (synsets) in WordNet. Two concepts are assumed to be more similar if they are closer to each other in WordNet. Let path(c i , c j ) be the shortest path length between c i and c j , the Path <ref type="bibr" target="#b30">[31]</ref> method defines semantic similarity method as:</p><formula xml:id="formula_2">sim Path (c i , c j ) = 1 1 + path(c i , c j ) (3)</formula><p>Another common information used to compute semantic similarity is depth, which is defined as shortest path length between root concept and a given concept through hierarchical relations. The intuition behind depth is that the upper-level concepts in a taxonomy are supposed to be more general. Thus, the similarity between lower-level concepts should be considered more similar than those concepts between upper-level concepts. This method described in <ref type="bibr" target="#b31">[32]</ref> measures the semantic similarity between concepts based on concept depth in a taxonomy, and a special concept Least Common Subsume (LCS), which is the most specific ancestor concept shared by two concepts. Let LCS(c i , c j ) be the LCS of concepts c i and c j , the method of <ref type="bibr" target="#b31">[32]</ref> measures semantic similarity of given concepts using the following formula:</p><formula xml:id="formula_3">sim Wu&amp;Palmer (c i , c j ) = 2depth(LCS(c i , c j )) depth(c i ) + depth(c j ) (4)</formula><p>where depth(c i ) computes the path(c root , c i ) given c root is the root concept of the taxonomy. The two similarity methods described above consider the structural knowledge of a taxonomy which have a common drawback of uniform distance between concepts. Some methods consider IC to overcome the uniform distance drawback. The IC is defined as the probability of encountering the concept in a corpus IC (c i ) = -log Prob(c i ). Note that Brown Corpus <ref type="bibr" target="#b32">[33]</ref> is used to compute IC because words in BC are annotated with WordNet concepts. The method described in <ref type="bibr" target="#b26">[27]</ref> only considers the IC of LCS concept, while the consequent works by <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b34">[35]</ref> extend the IC-based method by including the IC of concepts.</p><formula xml:id="formula_4">sim Resnik (c i , c j ) = IC (LCS(c i , c j )) (5) sim Lin (w i , w j ) = 2IC (LCS(c i , c j )) IC (c i ) + IC (c j )<label>(6)</label></formula><p>sim Jiang&amp;Conrad (w i , w j ) =</p><formula xml:id="formula_5">1 1 + IC (c i ) + IC (c j ) -2IC (LCS(c i , c j ))<label>(7)</label></formula><p>Note that Eq. ( <ref type="formula" target="#formula_5">7</ref>) transforms original semantic distance into similarity and solves the division by zero problem. As IC-based methods lack the important information of path and depth, they are not able to represent concept's distance and specificity accurately.</p><p>WPath <ref type="bibr" target="#b20">[21]</ref> combines structural knowledge and statistical IC to have hybrid semantic representation between concepts.</p><formula xml:id="formula_6">sim wpath (c i , c j ) = 1 1 + path(c i , c j ) * k LCS(c i ,c j )<label>(8)</label></formula><p>where k ∈ (0, 1] and k = 1 means that IC has no contribution in shortest path length. The parameter k (k = 0.8 is used as the original proposal) represents the contribution of the LCS's IC which indicates the common information shared by two concepts. WPath aims to give different weights of the shortest path length between concepts based on their shared information, where the path length is viewed as difference and the IC is viewed as commonality.</p><p>For identical concepts, their path length is 0 so their semantic similarity reaches the maximum similarity 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Word embeddings</head><p>Continuous word vector representations contain syntactic and semantic regularities present in the language, expressed as relation offsets in the vector space <ref type="bibr" target="#b12">[13]</ref>. Most common approaches train unsupervised word embeddings models without a specific objective, but rather with the aim of capturing language knowledge. This type of word vectors, that are trained using co-occurrence information, are normally called generic or pre-trained word vectors. In this work, pre-trained word vectors are used for all types of proposed feature extraction methods.</p><p>In the same way that bag-of-words features are exploited for textual representation in sentiment analysis, word embeddings can be similarly used <ref type="bibr" target="#b12">[13]</ref>. Some straight-forward approaches that use embeddings as features for classification have been studied. The work contained in <ref type="bibr" target="#b35">[36]</ref> studies the effectiveness of using word embeddings applied to several tasks, one of them being sentiment analysis. This study offers an overview of unsupervised embedding techniques, and how they can obtain meaningful text representations. In the work by <ref type="bibr" target="#b36">[37]</ref> an SVM classifier is trained over embedding representations to predict sentiment polarity. Through their results, authors argue that embeddings contain deep semantic features between words, which results beneficial in sentiment analysis. Also, as shown in <ref type="bibr" target="#b37">[38]</ref>, word embeddings can be combined with surface features, such as n-grams, sentiment lexicons and lexical features in order to improve sentiment analysis performance. Authors also demonstrate that using embeddings in a schema of model ensembling can yield higher accuracy in the predictions. On top of this, word embeddings based techniques are extensively used in public challenges where competitors aim at obtaining the highest scores in the task of sentiment analysis <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>. An interesting work that uses embedding with a special consideration to the reduction the computational complexity is shown in <ref type="bibr" target="#b40">[41]</ref>; curiously enough, the authors report a similar accuracy to that of more complex neural models in several tasks, including sentiment analysis. In addition, a model that uses both a semantic similarity measure and embedding representations is presented in <ref type="bibr" target="#b41">[42]</ref> This work addresses the task of aspect-based sentiment analysis by using the similarity information for detecting the aspect of a certain text, while exploiting embedding representations for performing the sentiment classification. For a more detailed description on how to train and use word embeddings, we refer to <ref type="bibr" target="#b42">[43]</ref>.</p><p>In the line of using embedding-based approaches, many authors have proposed complex neural architectures that are able to successfully exploit word vectors. One architecture family is Recurrent Neural Networks, which are able to adapt to different sequence sizes; this results specially useful in text processing, as a document can be modeled as a sequence of sentences, words or even characters. As shown by <ref type="bibr" target="#b43">[44]</ref>, the study of compositionality in sentiment classification tasks has proven to be relevant. This work proposes the Recursive Neural Tensor Network (RNTN) model, and it also shows how RNTN outperforms previous models on both fine-grained and binary sentiment analysis tasks. The RNTN model represents a phrase using word vectors composed from the structure given by a parse tree, computing vectors for higher nodes in the tree using a tensor-based composition function. Another interesting work <ref type="bibr" target="#b44">[45]</ref> tackles the use of Long Short-Term Memory (LSTM) networks, which read the input sequence into a vector. These vectors are used then to predict the sentiment label. A similar approach <ref type="bibr" target="#b45">[46]</ref> leverages the use of both LSTM and parse trees, outperforming previous systems and strong baselines in sentence relatedness and sentiment classification tasks. As an additional technique, attention mechanism are normally used in recurrent architectures <ref type="bibr" target="#b46">[47]</ref>, which allows models to search for parts of the input that are relevant to the problem. Building on top of this, the work in <ref type="bibr" target="#b47">[48]</ref> incorporates knowledge of document structure, developing a attention-based approach under the assumption that not all parts of a document are equally important. In this way, the model is allowed to distinguish the importance of the different parts that compose a document, resulting in benefits in sentiment analysis.</p><p>Another studied family of neural networks is Convolutional Neural Network (CNN) architectures. CNN models were initially proposed in the field of computer vision <ref type="bibr" target="#b48">[49]</ref>, although they have been successfully applied to a range of NLP tasks <ref type="bibr" target="#b14">[15]</ref>. A representative study of the use of CNN models in sentiment analysis is described in <ref type="bibr" target="#b49">[50]</ref>. This work uses pre-trained vectors as well as embeddings that are allowed to be fined-tuned during training, which improves the model. Similarly, the work in <ref type="bibr" target="#b50">[51]</ref> shows that the parameter initialization technique in the embeddings of a CNN model highly affects the final result. Also, this work incorporated noisy annotations from data to further refine the weights of the model, optimizing it to perform better in the task at hand. In <ref type="bibr" target="#b51">[52]</ref>, the authors propose a character-based CNN model that can be trained for several languages, without requiring any machine processes, comparing these results with the more traditional wordbased encoding.</p><p>Taking this into consideration, it seems natural that some authors have studied the applicability of hybrid architectures, with the aim of leveraging both RNN and CNN models. In <ref type="bibr" target="#b52">[53]</ref>, the proposed model aims at combining these two types of architectures into a unified approach that firstly classifies documents according to the number of opinion targets with a recurrent model, and later applies a convolutional network to perform sentiment analysis. The work in <ref type="bibr" target="#b53">[54]</ref> tackles the encoding of semantic relations between sentences in a document by combining, on one hand, a convolutional network that learns sentence representations, and on the other hand, a recurrent network that encodes the sentence relations.</p><p>Although the described neural architectures have a high representational power, there have been efforts towards adapting embeddings models to the task of sentiment analysis. A pioneer work that uses embeddings applied to sentiment analysis is that of <ref type="bibr" target="#b54">[55]</ref>. In this work, both semantic and sentiment knowledge is captured in the embeddings. In a similar way, the work in <ref type="bibr" target="#b55">[56]</ref> proposes a model that generates semantic sentiment embeddings, capturing context of sentiment together with co-occurrence information. In this way, generated sentiment vectors can be directly used for sentiment analysis tasks without feature engineering. Sentiment signals that are incorporated to word embeddings can come from different sources, as in the case of the work in <ref type="bibr" target="#b56">[57]</ref>, where the model includes sentiment information from both word and document level. An alternative method for generating sentiment embeddings is possible: refining a pre-trained embeddings model <ref type="bibr" target="#b57">[58]</ref>. This work adjusts the original word embeddings, allowing them to be closer to both semantically and sentimentally similar words; while at the same time moving them further away to dissimilar words also in the semantic and sentiment plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Sentiment lexicons</head><p>How to use a sentiment lexicon is a common problem that appears in the vast majority of Sentiment Analysis works. An interesting survey that tackles the use of sentiment lexicons for Sentiment Analysis is done in <ref type="bibr" target="#b3">[4]</ref>. There are numerous sentiment lexicons that can be used, and determining which characteristics determine the final performance of a system that uses them is an open challenge. In this sense, the work in <ref type="bibr" target="#b11">[12]</ref> treats some of these issues, analyzing a number of sentiment lexicons and how they can be complemented in a sentiment analysis system.</p><p>One relevant attribute of sentiment lexicons is the creation methodology, which can be divided in three main categories <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b59">60]</ref>: (i) manual approach, (ii) dictionary-based approach and (iii) corpus-based approach. The manual approach is done by humans, resulting in a very time-consuming process; thus, lexicons generated in such a manner are normally combined with the other two, that make use of automatic strategies. Many dictionary-based methods involve bootstrapping from a small set of opinionated words, and using them as seeds in a process of searching related words in a known dictionary such as WordNet <ref type="bibr" target="#b17">[18]</ref> or SentiWord-Net <ref type="bibr" target="#b60">[61]</ref>. Traditionally, dictionary-based approaches are not able to obtain domain specific orientations <ref type="bibr" target="#b58">[59]</ref>. Although, in order to generate domain-adapted dictionaries, some recent works use unsupervised pattern-based approach <ref type="bibr" target="#b61">[62]</ref>, as well as morphosyntactic information <ref type="bibr" target="#b62">[63]</ref>. In spite of this, corpus-based techniques can be used to alleviate the aforementioned issue. This last type of lexicon generation method relies on co-occurrence patterns detected on an unsupervised corpus, as well as a seed set of opinion words to locate opinionated words in the corpus <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65]</ref>.</p><p>As done in this paper, sentiment lexicons have been used as features in supervised machine learning scenarios. In <ref type="bibr" target="#b65">[66]</ref>, lexical resources are complemented with n-gram, Part-of-Speech (PoS) and micro-blogging specific features, such as the presence of emoticons. In this way, authors show that both lexicon and microblogging features result of utility in their validation. Similarly, the work in <ref type="bibr" target="#b66">[67]</ref> makes use of two sentiment lexicons, combining this information with n-grams, PoS. All these features are used by a SVM-based classifier, resulting in a state-of-the-are system in a SA competition. In some cases, lexicon features have been complemented with domain specific features, as in <ref type="bibr" target="#b67">[68]</ref>, where the domain is determined by a search query. Also, several lexicons can be used at the same time, as in the case of <ref type="bibr" target="#b68">[69]</ref>. This work integrates several lexicons using Markov logic with information about relations between neighboring words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed model</head><p>This section introduces the proposed sentiment analysis model, describing its submodules. The semantic similarity feature extraction method is detailed in-depth; as well as its integration with additional embedding-based representations. These two processing steps constitute a full machine learning sentiment analysis system.</p><p>Fig. <ref type="figure" target="#fig_0">1</ref> shows a diagram of the proposed model. As shown, the text is processed by two different submodules: (i) word/document embeddings and (ii) semantic similarity. Both use the natural language as input, outputting a feature vector. Feature vectors from both submodules are concatenated and then fed to a machine learning algorithm, which is trained with the sentiment annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Semantic similarity features</head><p>As stated, in general word embeddings contain semantic and syntactic information. Arguably, it is accepted that pre-trained word vectors do not enclose specific sentiment information, as no sentiment-related signal has been included in the training process. In order to include subjective sentiment information into the proposed model, additional information sources must be included in the feature extraction process. In this way, semantic similarity features exploit the aforementioned word embeddings regularities using a selection of sentiment words, namely, a sentiment lexicon vocabulary.</p><p>This work proposes the representation of a certain word, that may be outside of the lexicon vocabulary, by a projection to a set of sentiment words extracted from a sentiment lexicon. Such projection is computed using the semantic similarity between words, which can be computed by means of a word embedding model or a word taxonomy. In this way, a certain word is represented by its similarities to the selection of lexicon words.</p><p>To illustrate the concept of projection, Fig. <ref type="figure" target="#fig_1">2</ref> shows a conceptual case where only two words (good and bad) are selected from a sentiment lexicon; it can be seen that several words are projected in then in a two-dimensional space. As described, the values of that space correspond to the semantic similarity of each word (e.g., horrible, cat, mat, excellent) to the lexicon words.</p><p>More formally, let</p><formula xml:id="formula_7">W (i) = {w (i) 1 , w (i) 2 , . . . , w (i) i , . . . , w (i) I } (9)</formula><p>be the set of length I, formed by input tokens that constitute the text to be analyzed. This text can be a sentence, a paragraph or a whole document. Also, we consider that a lexicon is formed by tuples of sentiment word and polarity value: (w (s) j , s j ). In this way, we define the selection of target sentiment words,</p><formula xml:id="formula_8">W (s) = {w (s) 1 , w (s) 2 , . . . , w (s) i , . . . , w (s) L }<label>(10)</label></formula><p>which is extracted from a sentiment lexicon. Similarly, the vector l = [l 1 , l 2 , . . . , l L ] comprises the numerical sentiment values of the word in W (s) , as given by a sentiment lexicon. In this work, the selection process that generates the set of words W (s) is done in two steps, following different criteria: (i) frequency of appearance in the training data, and (ii) informativeness of each word towards the training annotation.</p><p>The process to generate the features is as follows. For each word</p><formula xml:id="formula_9">w (i) i ∈ W (i)</formula><p>and for each sentiment word w (s) j ∈ W (s) , a similarity value is computed so that</p><formula xml:id="formula_10">S i,j = sim(w (i) i , w (s) j ),<label>(11)</label></formula><p>with S i,j ∈ [0, 1]. This value represents that w (i) i and w (s) j are no similar at all if the result is 0, and completely similar if the result is exactly 1. After iterating over all the input words W (i) and all sentiment words W (s) , a matrix S ∈ R I×L can be constructed, containing all similarity values.</p><p>Following, a pooling function (maximum) is applied columnwise over S, obtaining the semantic similarity feature vector p of L-length: p j = max S :,j = max sim(w (i)  k , w (s) j )</p><p>for k ∈ {1, 2, . . . , I} <ref type="bibr" target="#b11">(12)</ref> Additionally, we consider feature weighting via the sentiment words associated polarity values through a simple element-wise product, so that l • p contains the vector of length L, with the weighted features extracted from the input text.</p><p>An illustration of how the similarity scores are computed and passed through the pooling function is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. It can be seen that the pooling function transforms the dimension of the matrix (that is dependent of the number of words of the input text) to a fixed-dimension vector, defined by the number of selected lexicon words.</p><p>Regarding the similarity metric function, two variants are proposed: (i) WordNet semantic similarity <ref type="bibr" target="#b69">[70]</ref> and (ii) embeddingbased word vector similarity.</p><p>The first type of similarity makes use of WordNet taxonomy. In this sense, any of the metrics described in Section 2.1 can be used in this approach. Still, WPath yields better results than the rest of metrics, as detailed in Section 5</p><p>Regarding the embedding-based measure, a previously trained word embedding model is used. In this paper, we used the pretrained word vectors of Word2Vec approach. 2 Nevertheless, similarity measures can be computed using any word embedding model and are not dependent on embedding dimension either. The embedding similarity is implemented using the dot product between an input word w i and a sentiment word l j : sim(w</p><formula xml:id="formula_11">(i) i , w (s) j ) = E T w (i) i E w (s) j (<label>13</label></formula><formula xml:id="formula_12">)</formula><p>2 https://code.google.com/archive/p/word2vec/. Accessed 23 June 2018. Algorithm description. The proposed method for extracting similarity features can be expressed as an algorithm, as shown below (Algorithm 1). We call this method SIMilarity-based sentiment projectiON (SIMON).</p><formula xml:id="formula_13">Result: Weighted feature vector v Let W (i)</formula><p>= {w (i) 1 , . . . , w (i) i , . . . , w (i) I } be the set of instance input words Let SL be a sentiment lexicon</p><formula xml:id="formula_14">W (s) , l ← selection(SL),<label>being</label></formula><formula xml:id="formula_15">W (s)</formula><p>= {w (s) 1 , . . . , w (s) j , . . . , w (s) L } the word selection and l = [l 1 , l 2 , . . . l L ] the sentiment scores of the word selection foreach w (i)  i ∈ W (i) do foreach w (s) j ∈ W (s) do compute similarity: S i,j = sim(w (i)  i , w (s) j ), end end for k ∈ {1, 2, ..., I} do compute feature vector p: p j = max S :,j = max sim(w (i) k , w (s)</p><formula xml:id="formula_16">j ) end compute sentiment weighting: v = l • p Algorithm 1: Similarity-based feature extraction SIMON algo- rithm.</formula><p>The function ''selection'' is implemented as described in Algorithm 2. Such algorithm is done in two steps. In the first step, words are filtered by frequency of appearance in a certain dataset, being the frequency cutoff a parameter to adjust. The second step makes use of an ANOVA statistical test between features (which correspond to selected words) and labels. In this way, the F-value is computed for each feature, and the features are selected based on their informativeness regarding the classification task of a certain dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Embedding text representation</head><p>The proposed model uses an embedding-based textual representation that transforms the input text into a fixed-length feature Result: Selection of words from a sentiment lexicon SL: W (s) and l Let dataset be the training dataset</p><formula xml:id="formula_17">W (s) , l := selection(SL, dataset) tmp ← frequencyFiltering(SL, dataset) W (s) , l ← ANOVAFiltering(tmp, dataset)</formula><p>Algorithm 2: Selection over a lexicon method implementation.</p><p>vector. As previously studied <ref type="bibr" target="#b37">[38]</ref>, the number of words in a text directly affects the effectiveness of embedding-based representations. Accordingly, this work makes use of two variations of the same feature extraction method. The first one is aimed at short texts, as the ones found in the Twitter platform. In this variation, word vectors are extracted for each word in the input text. Following the study in <ref type="bibr" target="#b37">[38]</ref>, the average pooling operation is performed on all word vectors, resulting in a vector of the same dimension as the original word vectors that is then fed to a logistic regressor. As for the second variation, the representation of a text uses Paragraph Vector <ref type="bibr" target="#b13">[14]</ref>, and it is used in long texts. This distinction between short texts (typical of online sources) and long texts (more commonly found in review sites) has shown an improvement in the performance of the presented sentiment analysis models <ref type="bibr" target="#b37">[38]</ref>.</p><p>This approach can be used either independently, or in combination with semantic similarity features. Also, the embedding-based text representation method serves as a comparison baseline for the rest of the proposed techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental evaluation and discussion</head><p>The proposed approaches have been validated against the datasets listed in Section 4.1, and the lexicons described in Section 4.2. Using these datasets and the training evaluation strategy described in Section 4.3, these first experiments are aimed at the characterization of the proposed methods for SA classification.</p><p>In order to evaluate the proposed model performance, an extensive experimental evaluation has been made. For this end, eight public datasets have been selected that are widely used in the SA community. Throughout all experiments, results are expressed using the F1 score metric. Also, in order to facilitate replication of this work and to foster research in the field, we make public the implementation of the SIMON method. 3   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Following, the datasets used for the evaluation are presented. Moreover, Table <ref type="table" target="#tab_1">1</ref> shows some of the datasets' statistics.</p><p>• Sentiment140 <ref type="bibr" target="#b70">[71]</ref>, that contains 1,600,000 messages extracted from Twitter using a distant supervision approach. For this, the authors collected tweets that were later filtered using emoticons expressing positive and negative sentiments as noisy labels.</p><p>• SemEval 2013 <ref type="bibr" target="#b71">[72]</ref> and SemEval 2014 <ref type="bibr" target="#b72">[73]</ref>. Both datasets are composed of English comments extracted from Twitter and describing a range of topics: entities, products and several entities. Also, these datasets are not directly accessible, as it must be downloaded firstly from the source. Since a number of users have deleted their original comments from the platform, we have not been able to recover the whole dataset, but a subset of it. Obtained sizes are detailed in Table <ref type="table" target="#tab_1">1</ref>.</p><p>3 https://github.com/gsi-upm/simon-paper. • Vader <ref type="bibr" target="#b73">[74]</ref>. This dataset contains 4200 tweet-like messages that are originally inspired by real Twitter texts. A subset of the dataset instances are intentionally designed to capture a number of syntactical and grammatical attributes that appear in natural language.</p><p>• STS-Gold <ref type="bibr" target="#b74">[75]</ref>, which has been generated as a complement for sentiment analysis evaluation in the Twitter domain. In this way, through a different annotation strategy, this dataset considers the presence of individual entities in tweet labeling process.</p><p>• IMDB <ref type="bibr" target="#b54">[55]</ref>. As of the time of writing, this dataset is widely used in machine learning evaluations. It contains 50,000 annotated reviews from the review site <ref type="foot" target="#foot_0">4</ref> that gives the name, as well as 50,000 unlabeled reviews. The object of the reviews are movies in the online platform.</p><p>• PL04 <ref type="bibr" target="#b75">[76]</ref> and PL05 <ref type="bibr" target="#b76">[77]</ref>. Similarly to the previous one, these datasets contain labeled movie reviews. While in the PL04 dataset the instances included whole reviews, for the PL05 these reviews have been split into sentences. Consequently, the average number of words per instance is greatly reduced from one version to another, as it can be seen in Table <ref type="table" target="#tab_1">1</ref>.</p><p>When considering the selected datasets, a qualitative distinction that can be made is the domain attribute. For the evaluation, we consider the division of the datasets into two groups, Twitterrelated (Sentiment140, SemEval 2014, SemEval 2014, Vader and STS-Gold); and movie reviews (IMDB, PL04, PL05). As described in Section 3.2, the embedding text representation is made differently for each dataset group. For the Twitter-related, the representation is made through average pooling of the word vectors, while Paragraph Vector is used for movie review datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Lexicons</head><p>As previously described in Section 3.1, the extraction of semantic similarity features requires the use of a lexicon vocabulary and, optionally, the associated sentiment values. In order to extensively study the effect of different sentiment lexica, for this evaluation we have selected four of them. For this work the positive and negative sentiment words and associated scalar values have been selected, discarding the neutral values (see Table <ref type="table" target="#tab_2">2</ref>).</p><p>• Bing Liu's <ref type="bibr" target="#b77">[78]</ref>. Formed by positive and negative words, it can be found online. 5 This lexicon contains a number of frequent sentimental words, as well as misspelled words, slang words and common variants. It is worth to highlight that this lexicon has no range in its polarity values, since its two possibilities are either positive (+1) and negative (-1) terms.</p><p>• SentiWordNet <ref type="bibr" target="#b60">[61]</ref>, which is a lexical resource specifically designed for sentiment and opinion mining. The version used in this word (SentiWordNet 3.0) 6 is an improvement over an earlier version (SentiWordNet 1.0) <ref type="bibr" target="#b78">[79]</ref>. SentiWordNet extends WordNet <ref type="bibr" target="#b17">[18]</ref>, a well-known English lexical database where words are organized into a tree-like structure. Consequently, in SentiWordNet each word is automatically annotated in the range [0, 1] according to its positivity, negativity and neutrality. For the experiments, we compute the aggreggated polarity value by subtracting the negative value from the positive value of a word. For example, the word dangerous has a positive value of 0.0 and a negative value of 0.75, resulting in -0.75 of aggregated polarity value. 7 Due to the fact that SentiWordNet annotations have a value for both positive and negative polarities (e.g., the word easy has a positive score of 0.625 and a negative score of 0.25), this operation is done to aggregate the overall polarity value.</p><p>• Affective Norms for English Words (ANEW) <ref type="bibr" target="#b79">[80]</ref> provides emotional ratings for a large number of English words. Said ratings have been calculated by means of measuring the psychological reaction of a person to an specific word. From these, we select the valence rating as the most useful for sentiment analysis, with the scale ranging from pleasant to unpleasant.</p><p>• AFINN <ref type="bibr" target="#b80">[81]</ref>. Since the ANEW lexicon does not contain specific microblogging words, we also consider for the evaluation the AFINN lexicon, that is more focused in this type of language. AFINN word list comprises a number of slang and obscene words, and typical web acronyms. Positive words are scored from 1 to 5, while negative ones have a sentiment score ranging from -5 to -1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation methodology</head><p>Given the different characteristics of the evaluation datasets, for this evaluation we have designed a evaluation strategy datasetwise. In this way, we try to evaluate each dataset so that the best results can be obtained. Consequently, the training and test procedure is done as follows.</p><p>Firstly, the sentiment140 dataset is not used for testing, but only for training and development. The training and development split is done randomly with a 70/30 distribution. In particular, the method implemented for the twitter-domain datasets is to trained the logistic regressor with the extracted features from sen-timent140 dataset, and test the performance of the obtained classifier with the SemEval2013, SemEval2014, Vader and STS datasets. Note that these last datasets are not used for training or development, only for testing.</p><p>As for the movie review datasets, two different strategies have been used. The authors of the IMDB dataset have defined training and testing splits, so those have been used for the experiments. Besides, the PL04 has associated cross-validation splits, and we have followed them. Lastly, the PL05 dataset has no pre-defined splits so, inspired by the PL04 dataset, we have used cross-validation with random splits. Finally, the embedding-based text representations have been trained in the following manner. The word vector model used is Skip-gram <ref type="bibr" target="#b12">[13]</ref>, and it has been trained with the sentiment140 dataset. For the Paragraph Vector model, we have used the unsupervised split of the IMDB dataset.</p><p>In reference to the implementation of the word-matching method, it has been done as explained in <ref type="bibr" target="#b2">[3]</ref>. Given a text and a certain lexicon, the words in the text are selected if they appear in the lexicon, and their opinion score summed along all the text. Resulting polarity is then normalized to match that of the dataset annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Semantic similarity feature extraction</head><p>As explained in Section 3.1, a selection over the vocabulary of a sentiment lexicon is done. Such selection is recommended in order to: (i) reduce the output dimensionality in an attempt to avoid overfitting; and (ii) increase overall performance, as it has been seen that in the experiments the performance in sentiment classification improves if this selection is implemented. As described, this selection is done in two steps. For the first step, which select words by frequency of appearance, we have experimentally set the cutoff to 200 words, distributing equally along polarities, resulting in a selection of 100 positive words and 100 negative words.</p><p>As for the second selection step, Fig. <ref type="figure" target="#fig_3">4</ref> illustrates the shape of the importance curves of the 200 most common words for each lexicon and dataset, as computed by the ANOVA test. As seen, the most informative features are concentrated in a low percentile. Based on these results and on a cross-validation exploration of this parameter, we have adjusted the percentile of highest feature scores, setting it to 25.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Semantic similarity evaluation</head><p>Firstly, we evaluate the approach that uses embedding-based similarity. In Table <ref type="table" target="#tab_4">3</ref>, the results are shown. We include the performance of the logistic regression learner trained with different features: embedding-based text representations (W2V/D2V), lexicon-based similarity (Liu, SentiWordNet, ANEW, AFINN), and the combination of both embedding representations and lexiconbased similarity features (as in Liu + W2V/D2V). It can be seen that the proposed approaches surpass the baseline in all datasets excepting STS. This is indicative of the usefulness of these features for sentiment analysis, as the defined baseline constitutes a fairly strong method <ref type="bibr" target="#b37">[38]</ref>. Also, results indicate that the combination of the features extracted using the embedding distances with the Liu lexicon and embedding representations yield, in the majority of the datasets, the best performances. In order to further support this result, we have performed the Friedman test <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b81">82]</ref>. The ''Rank'' columns in the result tables express the ranking of methods as computed by the Friedman test. In this test, less ranking means a method results better in comparison to the rest. All Friedman tests in this work have been performed with (α = 0.01). Regarding Table <ref type="table" target="#tab_4">3</ref>, the Friedman test points the combination of distance features using Liu lexicon and embedding representations as the best ones for our experiments.</p><p>Following, in order to compare the embedding-based and the Wordnet-based features, the performance of this last type of methods is computed, as shown in Table <ref type="table" target="#tab_5">4</ref>. With respect to the choice of similarity metric, as already explained, there are several metrics that can be used. For this, we have run en extensive set of experiments, computing the performance on all datasets for each of the similarity metrics, and we have seen that WPath yields better results than the rest of metrics; we use a k value of 0.8, as indicated  in <ref type="bibr" target="#b82">[83]</ref>. This observation is consistent with previous results tackling WPath metric <ref type="bibr" target="#b82">[83]</ref>. The results obtained with the other WordNetbased can be found online, 8 and have been omitted for extension reasons.</p><p>When comparing the WPath similarities with the embeddingbased ones, one can see that WPath performances are surpassed by that of embedding-based. This can be explained by attending at the difference in the vocabulary coverage. While the WordNet-based approach benefits from the WordNet vocabulary, embedding-based methods use a much more extensive vocabulary. In this particular case, WordNet has a vocabulary of 155,327 words, while the word embedding model used constitutes a vocabulary of 3 million words. A plausible explanation is that the more extended vocabulary allows the embedding-based method 8 https://github.com/gsi-upm/simon-paper.</p><p>to capture more word variations, and thus capturing more relevant information.</p><p>In addition to this, we have observed that further combining WPath and embedding-based distance features does not improve the sentiment classification performance. Table <ref type="table" target="#tab_6">5</ref> shows the results of this experiment. One possible explanation for this decrease in performance is the effect of overfitting. When performing the combination, more features are being added, and this could cause the machine learning algorithm that learns from these features to overfit.</p><p>Given that the embedding-based distance yields better results, a natural extension of this approach tackles the use of the sentiment scores that are included in each lexicon. That is, the numerical value that a lexicon associates with each word. While in Table <ref type="table" target="#tab_4">3</ref> no sentiment scores are used, Table <ref type="table" target="#tab_8">6</ref> shows the performance obtained by the methods that use these scores, as explained in Section 3.1. With the aim of optimizing the results, a normalization in the range [-1,1] is done to the semantic distance features, as the insertion of the lexicon sentiment scores can augment the feature range, worsening the results. We observe that, although the sentiment information from the lexicon is added to the feature extraction process, it does not necessarily improve the performance result. As can be seen, when using the Liu lexicon, adding the sentiment scores does not improve, but worse the results. This is to be expected, as Liu lexicon only contains 1 and -1 as polarity values, with no variation; thus, this new information does not affect the obtained features. The reason why the performance decreases in the case of Liu lexicon is that the normalization operation affects the process, decreasing the resulting performance.</p><p>Nevertheless, in the case of the SentiWordNet lexicon the addition of sentiment scores and normalization effectively improves the final performance metrics. This, again, can be explained by attending to the granularity of the sentiment annotations in Sen-tiWordNet, that vary in the range of [-1, 1]. In the case of ANEW, no relevant effects in performance have been found. Moreover, in AFINN lexicon, the classifier trained with only the distance features improves when using sentiment scores, but it does not surpass the better metric in any dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison to word-matching</head><p>In order to compare the proposed use of the sentiment lexicon against a word-matching baseline, we perform additional experiments that tackle this issue. Table <ref type="table" target="#tab_9">7</ref> shows the results for the wordmatching approach (Section 4.5). As expected, this type of use of a sentiment lexicon does not surpass our proposal in any of the evaluation datasets. Nevertheless, the word-matching methods constitute an interesting baseline, as it represents an approach that is commonly taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Effect of lexicons</head><p>Aiming at characterizing the effect of different lexicons on the feature extraction process and the final sentiment classification performance, additional experiments have been performed. With this study, we intend to deep the understanding of the proposed methods, as well as define some mechanisms that can be useful for the performance estimation of these approaches when facing new datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1.">Vocabulary selection</head><p>Attending at the process of selection of lexicon words, we firstly study the frequency-based filtering and the assigned informativeness score distribution. In this step of the process, the most common words from a lexicon are selected using this statistical data from the dataset. This selection of words forms the target set to which the features are extracted. Consequently, we have experimentally discovered that latent information regarding dataset characteristics can be inferred. For this, we have used two metrics that are computed from the set of lexicon target words in two datasets. These metrics are: number of common words in the two set of words (n cw ), and (ii) the Jensen-Shannon divergence between the informativeness scores of these words (div JS ).</p><p>Following, a cross-dataset evaluation has been done. In this experiment, a learning algorithm trained in a certain dataset is evaluated in all datasets. In order to evaluate the cross-dataset performance variation, the performance difference is defined as:</p><formula xml:id="formula_18">d = m c m o -1 (14)</formula><p>where m o is the metric obtained in the original dataset, and m c is the metric value obtained in the crossed dataset.</p><p>Following, we see if from variables n cw and div JS , the difference of performance d can be estimated. To assess the effect of the cross-dataset evaluation, we have performed a Least Squares study over variables d (difference of performance), the number of common words in the two selections (variable n cw ) and Jensen-Shannon divergence (variable div JS ). As expected, the number of common words in the selections has been found to be significative. Nevertheless, the Least Squares study shows that Jensen-Shannon divergence has no significance. In this way, the R 2 values of the Least Squares for each lexicon are the following:  the selection of the most suitable trained classifier to this new domain, leading to a reduction in the cross-dataset error. That is, attending to the number of common words between the new and the training datasets, as selected by our approach, such metric offers an estimation of the cross-dataset performance decrement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2.">Vocabulary similarity</head><p>In order to further study the relations between the proposed method and the different lexicons used, and inspired by <ref type="bibr" target="#b11">[12]</ref>, we have defined a number of metrics that measure the similarity between target words extracted from different lexicons. In order to evaluate the informativeness of these metrics, we perform a crossdomain evaluation.</p><p>As explained, for a dataset the SIMON method extracts different target words if using different initial lexicons. Let L 1 be the set of words from the first lexicon to be compared, and L 2 be the set of words of the second studied lexicon. Also, let t(•) be the selection operation over a set of words. Given this, the metrics we use to outline the lexicon similarities are as follows.</p><p>• Total overlap (Overlap total ), which is simply the number of words that the two lexicons originally share, as defined in <ref type="bibr" target="#b11">[12]</ref>. More formally, this metric is defined as |L 1 ∩ L 2 |.</p><p>• Target overlap Overlap target . Similarly, this metric defines the number of words that are common for the target sets from both lexicons. That is, the set |t(L 1 ) ∩ t(L 2 )| • Total distance Distance total . This metric defines the distance, as defined by a word embedding model, between all the words from the two lexicons. We can write this metric as dist(L 1 , L 2 ). To the extent of our knowledge, this distance measurement of two set of words is a novel approach.</p><p>• Target distance Distance target , which defines the distance between the sets of target words from both lexicons: dist</p><formula xml:id="formula_19">( t(L 1 ), t(L 2 )</formula><p>) . Moreover, we define the distance between two sets of words in a word vector space as:</p><formula xml:id="formula_20">dist(L 1 , L 2 ) = 1 |L 1 ∪ L 2 | ∑ w i ∈L 1 ∑ w j ∈L 2 sim(w i , w j ) (15)</formula><p>where the similarity function sim(•, •) is embedding-based, as defined in Section 3.1 (Eq. ( <ref type="formula" target="#formula_11">13</ref>)).</p><p>The result of the computation of these metrics is shown in Table <ref type="table" target="#tab_10">8</ref>. Due to the reason that the comparison is between lexicons, the metrics are compared over lexicon pairs (as in Liu -SentiWord-Net). Also, when the metrics are dataset-dependent, the average over the datasets is done. We have verified that this simplification does not affect the results, since the metric values practically do not change for the same lexicon pair. Table <ref type="table" target="#tab_11">9</ref> shows the correlation between all four defined metrics, as obtained from the values of Table <ref type="table" target="#tab_10">8</ref>. As it stands, we can observe that the total distance does not highly correlate with the rest of metrics. This is probably due to that computing embedding similarity over a great number of words (as in the case of the entire lexicon vocabulary) loses, at least in part, the information contained in the word vectors, as explained in <ref type="bibr" target="#b37">[38]</ref>.</p><p>Following, the last step of the experiment is oriented to assess the performance change in a cross-lexicon evaluation. In this way, a learning algorithm is trained using the proposed method in a certain lexicon, and then used for prediction in a different lexicon. Please note that in this experiment, datasets are not changed in an iteration of the experiment. With this, we intend to gain insight of how the performance is affected when interchanging the sentiment lexicon used for the proposed sentiment analysis method. To measure the difference in two performance metrics, we use the metric defined in Section 4.6.1.</p><p>The idea is to check if similar lexicons yield similar sentiment analysis performances. For this, we have correlated the values of the target distance metric and the difference of performance crosslexicon. As a result, the obtained value is -0.71 (p &lt; 0.01). This result highly indicates that similar lexicons yield similar performances in sentiment analysis. Consequently, when confronted with a new lexicon, one could have a sense of the efficiency of the new lexicon by comparing it with already studied lexicons via the defined lexicon similarity metrics. In this sense, we emphasize the utility of the target distance, as it highly correlates with almost all the rest of metrics, and it makes use of the information contained in a word embedding model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This paper proposes a novel method of utilizing sentiment lexicons, which is based on a semantic similarity metric between text words and lexicon vocabulary. An additional proposal consists of a sentiment analysis that uses this lexicon-based semantic similarity as features, as well as embedding-based representations. In order to evaluate the effectiveness of the model, an extensive experimental evaluation is performed. With the intention of conducting a comparable study, seven public datasets are used, as well as four sentiment lexicons. Also, several statistical tests empirically verify the effectiveness of the proposed feature extraction and its combination to embedding representations. With the aim of further characterizing the feature extraction method, the effect of the lexicon characteristics on the extracted features is studied in depth by means of cross-dataset and cross-lexicon evaluations.</p><p>There were three main research questions that drove this work. The first question was whether the proposed semantic distance features are more effective than word-matching methods. Experimental results show that the proposed feature extraction method yields fairly good performances when used with a simple classifier. We consider this result a promising one, since more complex learning architectures can probably boost the overall performance. In addition, attending to both Tables <ref type="table" target="#tab_8">6</ref> and<ref type="table" target="#tab_9">7</ref>, it can be seen that the word-matching does not improve over the performance of semantic distance features. This difference in performance is specially relevant for the movie review datasets, where word-matching yields much lower scores. This indicates that the use of semantic distance method is able to better extract subjective sentiment information from a lexicon.</p><p>The second question tackled the comparison between embedding and taxonomy based semantic similarity. In this way, we have evaluated the performance of both WordNet and embedding based features. As shown, embedding features yield better results in our evaluation. We argue that this contrast is due to the difference in vocabulary coverage, which is intimately related to the generation process of both WordNet and embedding models resources. While WordNet is a manually-generated lexical resource, thus it is limited in coverage; embedding models are automatically inferred, which leads to more coverage in terms of vocabulary.</p><p>Lastly, we raised the concern of how the lexicon characteristics affect the proposed feature extraction process. This question is oriented to predict the performance of the model when confronted with a new dataset. For this, several similarity metrics between vocabularies have been defined, determining the correlation between these metrics and the difference of performance in cross-dataset and cross-lexicon experiments. In this regard, the experiments point that the lexicon words largely determines the resulting sentiment analysis performance. That is, similar lexicon word selections yield similar sentiment analysis performances.</p><p>To summarize, this work proposes a semantic distance feature extraction method that is combined with embedding-based representations. Nevertheless, we believe that a possible line of future work lies in extending this model to emotion analysis, studying the effects of using emotion lexicons. Furthermore, we intend to extend the domain of this work to a multilingual environment. Finally, we believe that this method can be easily adapted to any domain by adapting the word selection mechanism with domainoriented data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System architecture diagram.</figDesc><graphic coords="5,330.11,370.91,213.87,194.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Conceptual diagram of word projection over a lexicon formed only by the set of words {good, bad}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. SIMON similarity computation: similarities are computed against a selection of lexicon words (in green and red), and a max function is applied column-wise, obtaining a feature vector . (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. words importance curves for all the lexicons and datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Statistics of the datasets used for the evaluation: number of positive, negative and total instances and average number of words per instance.</figDesc><table><row><cell>Dataset</cell><cell>Positive</cell><cell>Negative</cell><cell>Total</cell><cell>Average no. words</cell></row><row><cell>Sentiment140</cell><cell>800,000</cell><cell>800,000</cell><cell>1,600,000</cell><cell>15</cell></row><row><cell>SemEval2013</cell><cell>2,315</cell><cell>861</cell><cell>3,176</cell><cell>23</cell></row><row><cell>SemEval2014</cell><cell>2,509</cell><cell>932</cell><cell>3,441</cell><cell>22</cell></row><row><cell>Vader</cell><cell>2,901</cell><cell>1,299</cell><cell>4,200</cell><cell>16</cell></row><row><cell>STS-Gold</cell><cell>632</cell><cell>1,402</cell><cell>2,034</cell><cell>16</cell></row><row><cell>IMDB</cell><cell>25,000</cell><cell>25,000</cell><cell>50,000</cell><cell>255</cell></row><row><cell>PL04</cell><cell>1,000</cell><cell>1,000</cell><cell>2,000</cell><cell>723</cell></row><row><cell>PL05</cell><cell>5,346</cell><cell>5,349</cell><cell>10,695</cell><cell>20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Statistics of the lexicons used for the evaluation: number of positive, negative and total instances and total number of words.</figDesc><table><row><cell>Lexicon</cell><cell>No. positive words</cell><cell>No. negative</cell><cell>Total no. words</cell></row><row><cell>Liu's</cell><cell>2006</cell><cell>4783</cell><cell>6789</cell></row><row><cell>SentiWordNet</cell><cell>2236</cell><cell>3732</cell><cell>5968</cell></row><row><cell>ANEW</cell><cell>576</cell><cell>454</cell><cell>1030</cell></row><row><cell>AFINN</cell><cell>878</cell><cell>1598</cell><cell>2476</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>F1-scores for the embedding semantic similarity method (SIMON), without sentiment scores. In bold, best score for each dataset.</figDesc><table><row><cell>Dataset</cell><cell>SemEval13</cell><cell>SemEval14</cell><cell>Vader</cell><cell>STS</cell><cell>IMDB</cell><cell>PL04</cell><cell>Pl05</cell><cell>Rank</cell></row><row><cell>W2V/D2V</cell><cell>84.54</cell><cell>84.14</cell><cell>88.02</cell><cell>83.75</cell><cell>88.53</cell><cell>88.65</cell><cell>76.43</cell><cell>3.7</cell></row><row><cell>Liu</cell><cell>79.61</cell><cell>78.75</cell><cell>85.48</cell><cell>78.69</cell><cell>82.13</cell><cell>84.02</cell><cell>74.15</cell><cell>7.1</cell></row><row><cell>Liu + W2V/D2V</cell><cell>87.09</cell><cell>86.48</cell><cell>90.39</cell><cell>82.60</cell><cell>88.99</cell><cell>89.45</cell><cell>78.25</cell><cell>1.6</cell></row><row><cell>SentiWordNet</cell><cell>76.62</cell><cell>74.31</cell><cell>84.77</cell><cell>79.15</cell><cell>81.66</cell><cell>80.11</cell><cell>73.95</cell><cell>8.3</cell></row><row><cell>SentiWordNet + W2V/D2V</cell><cell>82.45</cell><cell>81.29</cell><cell>87.66</cell><cell>81.72</cell><cell>88.82</cell><cell>88.03</cell><cell>78.26</cell><cell>4.3</cell></row><row><cell>ANEW</cell><cell>79.39</cell><cell>78.75</cell><cell>86.91</cell><cell>76.60</cell><cell>79.42</cell><cell>76.66</cell><cell>74.21</cell><cell>7.8</cell></row><row><cell>ANEW + W2V/D2V</cell><cell>86.30</cell><cell>85.65</cell><cell>90.08</cell><cell>77.54</cell><cell>88.88</cell><cell>88.09</cell><cell>78.29</cell><cell>3.6</cell></row><row><cell>AFINN</cell><cell>81.53</cell><cell>79.17</cell><cell>86.13</cell><cell>80.60</cell><cell>81.99</cell><cell>82.27</cell><cell>74.16</cell><cell>6.4</cell></row><row><cell>AFINN + W2V/D2V</cell><cell>86.68</cell><cell>85.92</cell><cell>90.26</cell><cell>83.29</cell><cell>88.97</cell><cell>88.84</cell><cell>78.09</cell><cell>2.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>F1-scores on all datasets for the WPath SIMON semantic similarity metric. In bold, best score for each dataset.</figDesc><table><row><cell>Dataset</cell><cell>SemEval13</cell><cell>SemEval14</cell><cell>Vader</cell><cell>STS</cell><cell>IMDB</cell><cell>PL04</cell><cell>Pl05</cell><cell>Rank</cell></row><row><cell>W2V/D2V</cell><cell>84.64</cell><cell>84.11</cell><cell>88.19</cell><cell>83.75</cell><cell>88.55</cell><cell>88.75</cell><cell>76.25</cell><cell>2.7</cell></row><row><cell>Liu</cell><cell>56.45</cell><cell>51.55</cell><cell>72.10</cell><cell>62.79</cell><cell>72.90</cell><cell>68.31</cell><cell>57.47</cell><cell>7.7</cell></row><row><cell>Liu + W2V/D2V</cell><cell>84.31</cell><cell>83.00</cell><cell>88.44</cell><cell>83.07</cell><cell>88.51</cell><cell>88.87</cell><cell>75.98</cell><cell>4.1</cell></row><row><cell>SentiWordNet</cell><cell>66.49</cell><cell>61.18</cell><cell>73.23</cell><cell>62.68</cell><cell>71.47</cell><cell>72.23</cell><cell>56.19</cell><cell>7.4</cell></row><row><cell>SentiWordNet + W2V/D2V</cell><cell>85.06</cell><cell>83.75</cell><cell>88.22</cell><cell>83.29</cell><cell>88.52</cell><cell>88.78</cell><cell>76.39</cell><cell>2.7</cell></row><row><cell>ANEW</cell><cell>63.11</cell><cell>54.84</cell><cell>71.88</cell><cell>59.75</cell><cell>71.50</cell><cell>68.50</cell><cell>56.61</cell><cell>8.3</cell></row><row><cell>ANEW + W2V/D2V</cell><cell>84.31</cell><cell>83.08</cell><cell>87.58</cell><cell>83.58</cell><cell>88.58</cell><cell>88.85</cell><cell>75.99</cell><cell>3.5</cell></row><row><cell>AFINN</cell><cell>66.97</cell><cell>58.56</cell><cell>75.80</cell><cell>66.28</cell><cell>72.61</cell><cell>69.05</cell><cell>56.76</cell><cell>6.6</cell></row><row><cell>AFINN + W2V/D2V</cell><cell>84.83</cell><cell>83.25</cell><cell>88.95</cell><cell>83.64</cell><cell>88.54</cell><cell>89.23</cell><cell>76.26</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5</head><label>5</label><figDesc>F1-scores on all datasets for the combination of WPath and embedding similarity, and embedding-based representations features. In bold, best score for each dataset.</figDesc><table><row><cell>Dataset</cell><cell cols="3">SemEval13 SemEval14 Vader STS</cell><cell>IMDB PL04</cell><cell>Pl05</cell></row><row><cell>Liu_WPath + Liu_Embedding + W2V/D2V</cell><cell>86.20</cell><cell>85.49</cell><cell cols="2">90.28 82.95 89.06 89.17 78.19</cell></row><row><cell cols="2">SentiWordNet_WPath + SentiWordNet_Embedding + W2V/D2V 86.70</cell><cell>86.23</cell><cell cols="2">89.85 82.01 88.80 88.28 78.08</cell></row><row><cell>ANEW_WPath + ANEW_Embedding + W2V/D2V</cell><cell>87.34</cell><cell>85.87</cell><cell cols="2">86.91 79.91 88.85 88.21 78.03</cell></row><row><cell>AFINN_WPath + AFINN_Embedding + W2V/D2V</cell><cell>86.26</cell><cell>84.81</cell><cell cols="2">90.41 83.39 89.00 87.97 78.29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>These results indicate that, if performing inference over a new dataset, the number of common words of the selection of our method highly indicates the change in performance metrics of the subsequent learning algorithm. This can be useful when applying sentiment classifiers trained with different datasets to a new domain where a dataset is not annotated. The method can guide</figDesc><table><row><cell>• Liu: 0.93 (p &lt; 0.01)</cell></row><row><cell>• SentiWordNet: 0.94 (p &lt; 0.01)</cell></row><row><cell>• ANEW: 0.92 (p &lt; 0.01)</cell></row><row><cell>• AFINN: 0.89 (p &lt; 0.01)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>F1-scores for the embedding semantic distance method, with sentiment scores. In bold, best score for each dataset.</figDesc><table><row><cell>Dataset</cell><cell>SemEval13</cell><cell>SemEval14</cell><cell>Vader</cell><cell>STS</cell><cell>IMDB</cell><cell>PL04</cell><cell>Pl05</cell><cell>Rank</cell></row><row><cell>W2V/D2V</cell><cell>84.64</cell><cell>84.11</cell><cell>88.19</cell><cell>83.75</cell><cell>88.54</cell><cell>88.71</cell><cell>76.32</cell><cell>4.3</cell></row><row><cell>Liu</cell><cell>80.80</cell><cell>79.61</cell><cell>86.18</cell><cell>78.75</cell><cell>82.11</cell><cell>83.79</cell><cell>74.15</cell><cell>7.1</cell></row><row><cell>Liu + W2V/D2V</cell><cell>85.42</cell><cell>85.06</cell><cell>89.21</cell><cell>85.05</cell><cell>89.01</cell><cell>86.61</cell><cell>78.27</cell><cell>2.6</cell></row><row><cell>SentiWordNet</cell><cell>79.44</cell><cell>78.71</cell><cell>86.40</cell><cell>79.24</cell><cell>81.65</cell><cell>79.48</cell><cell>74.04</cell><cell>8</cell></row><row><cell>SentiWordNet + W2V/D2V</cell><cell>85.49</cell><cell>84.11</cell><cell>89.29</cell><cell>84.46</cell><cell>88.86</cell><cell>88.38</cell><cell>78.33</cell><cell>3.1</cell></row><row><cell>ANEW</cell><cell>78.74</cell><cell>78.59</cell><cell>86.70</cell><cell>76.52</cell><cell>79.43</cell><cell>76.63</cell><cell>74.24</cell><cell>8.3</cell></row><row><cell>ANEW + W2V/D2V</cell><cell>85.66</cell><cell>84.95</cell><cell>89.55</cell><cell>83.44</cell><cell>88.88</cell><cell>88.21</cell><cell>78.38</cell><cell>2.6</cell></row><row><cell>AFINN</cell><cell>83.13</cell><cell>81.28</cell><cell>87.71</cell><cell>80.02</cell><cell>81.99</cell><cell>82.08</cell><cell>74.14</cell><cell>6.6</cell></row><row><cell>AFINN + W2V/D2V</cell><cell>85.81</cell><cell>84.62</cell><cell>89.11</cell><cell>84.78</cell><cell>88.99</cell><cell>88.74</cell><cell>78.11</cell><cell>2.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc>F1-scores for the word-matching method. In bold, best score for each dataset.</figDesc><table><row><cell>Dataset</cell><cell cols="3">SemEval13 SemEval14 Vader STS</cell><cell>IMDB PL04 PL05</cell></row><row><cell>Liu</cell><cell>76.53</cell><cell>73.36</cell><cell cols="2">80.25 67.78 73.49 68.33 61.98</cell></row><row><cell cols="2">SentiWordNet 69.88</cell><cell>68.36</cell><cell cols="2">67.21 50.00 66.24 64.73 55.64</cell></row><row><cell>ANEW</cell><cell>71.75</cell><cell>69.26</cell><cell cols="2">66.43 54.17 66.41 65.96 54.24</cell></row><row><cell>AFINN</cell><cell>80.55</cell><cell>78.76</cell><cell cols="2">87.22 67.10 73.58 68.90 60.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8</head><label>8</label><figDesc>Defined metrics results for all the lexicon pairs.</figDesc><table><row><cell>Lexicon</cell><cell cols="4">Total overlap Target overlap Total distance Target distance</cell></row><row><cell>Liu -</cell><cell>1483</cell><cell>0.41</cell><cell>0.076</cell><cell>0.151</cell></row><row><cell>SentiWordNet</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SentiWordNet -</cell><cell>583</cell><cell>0.39</cell><cell>0.070</cell><cell>0.150</cell></row><row><cell>AFINN</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">AFINN -ANEW 298</cell><cell>0.28</cell><cell>0.083</cell><cell>0.131</cell></row><row><cell>ANEW -Liu</cell><cell>425</cell><cell>0.24</cell><cell>0.081</cell><cell>0.128</cell></row><row><cell>Liu -AFINN</cell><cell>1314</cell><cell>0.65</cell><cell>0.095</cell><cell>0.165</cell></row><row><cell>SentiWordNet -</cell><cell>242</cell><cell>0.21</cell><cell>0.065</cell><cell>0.123</cell></row><row><cell>ANEW</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9</head><label>9</label><figDesc>Correlation between defined metrics over all datasets.</figDesc><table><row><cell></cell><cell cols="4">Total overlap Target overlap Total distance Target distance</cell></row><row><cell>Total overlap</cell><cell>1.00</cell><cell></cell><cell></cell></row><row><cell cols="2">Target overlap 0.79</cell><cell>1.00</cell><cell></cell></row><row><cell cols="2">Total distance 0.43</cell><cell>0.66</cell><cell>1.00</cell></row><row><cell cols="2">Target distance 0.84</cell><cell>0.96</cell><cell>0.52</cell><cell>1.00</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>http://www.imdb.com/. Accessed 1 June 2018.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research work is partially supported by the Spanish Ministry of Economy, Spain through the project EmoSpaces (RTC-2016-5053-7) and the European Union with Trivalent (H2020 Action Grant No. 740934, SEC-06-FCT-2016), and the project Somedi (ITEA 15011).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The effect of word of mouth on sales: Online book reviews</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
		<idno type="DOI">10.1509/jmkr.43.3.345</idno>
		<ptr target="http://dx.doi.org/10.1509/jmkr.43.3.345" />
	</analytic>
	<monogr>
		<title level="j">J. Mark. Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="354" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Impact of online consumer reviews on sales: The moderating role of product and consumer characteristics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1509/jmkg.74.2.133</idno>
		<ptr target="http://dx.doi.org/10.1509/jmkg.74.2.133" />
	</analytic>
	<monogr>
		<title level="j">J. Mark</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="148" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139084789</idno>
		<ptr target="http://dx.doi.org/10.1017/CBO9781139084789" />
		<title level="m">Sentiment Analysis: Mining Opinions, Sentiments, and Emotions</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on opinion mining and sentiment analysis: Tasks, approaches and applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ravi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2015.06.015</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2015.06.015" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="14" to="46" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building a graded chinese sentiment dictionary based on commonsense knowledge for sentiment analysis of song lyrics</title>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>-R. Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-J</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Inf. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="662" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Csenticnet: a concept-level resource for sentiment analysis in chinese language, in: Computational Linguistics and Intelligent Text Processing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-77116-8_7</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-77116-8_7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of CICLing: International Conference onComputational Linguistics and Intelligent Text Processing</title>
		<meeting>CICLing: International Conference onComputational Linguistics and Intelligent Text Processing</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>p. in press</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lexicon-based methods for sentiment analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stede</surname></persName>
		</author>
		<idno type="DOI">10.1162/COLI_a_00049</idno>
		<ptr target="http://dx.doi.org/10.1162/COLI_a_00049" />
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New avenues in opinion mining and sentiment analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIS.2013.30</idno>
		<ptr target="http://dx.doi.org/10.1109/MIS.2013.30" />
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073153</idno>
		<ptr target="http://dx.doi.org/10.3115/1073083.1073153" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning sentiment lexicons in spanish</title>
		<author>
			<persName><forename type="first">V</forename><surname>Perez-Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.18180/tecciencia.2017.22.5</idno>
		<ptr target="http://dx.doi.org/10.18180/tecciencia.2017.22.5" />
	</analytic>
	<monogr>
		<title level="j">LREC</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A holistic lexicon-based approach to opinion mining</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1341531.1341561</idno>
		<ptr target="http://dx.doi.org/10.1145/1341531.1341561" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 international conference on web search and data mining</title>
		<meeting>the 2008 international conference on web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Meta-level sentiment models for big social data analysis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bravo-Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poblete</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.knosys.2014.05.016</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2014.05.016" />
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="86" to="99" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08">Aug. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.1561/2200000006</idno>
		<ptr target="http://dx.doi.org/10.1561/2200000006" />
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Alpaydin</surname></persName>
		</author>
		<title level="m">Introduction to Machine Learning</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1145/219717.219748</idno>
		<ptr target="http://dx.doi.org/10.1145/219717.219748" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic distance in wordnet: An experimental, application-oriented evaluation of five measures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Budanitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on WordNet and other Lexical Resources</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.2934</idno>
		<ptr target="http://dx.doi.org/10.1613/jair.2934" />
	</analytic>
	<monogr>
		<title level="j">J. Artificial Intelligence Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computing semantic similarity of concepts in knowledge graphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2016.2610428</idno>
		<ptr target="http://dx.doi.org/10.1109/TKDE.2016.2610428" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="85" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using google distance to weight approximate ontology matches</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gligorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Aleksovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Harmelen</surname></persName>
		</author>
		<idno type="DOI">10.1145/1242572.1242676</idno>
		<ptr target="http://dx.doi.org/10.1145/1242572.1242676" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web</title>
		<meeting>the 16th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="767" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empiricial Methods in Natural Language Processing</title>
		<meeting>the Empiricial Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving distributional similarity with lessons learned from word embeddings</title>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="238" to="247" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using information content to evaluate semantic similarity in a taxonomy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cmp-lg/9511007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 14th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="448" to="453" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;95</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ontology-based semantic similarity: A new feature-based approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Batet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Isern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Valls</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2012.01.082</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2012.01.082" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="7718" to="7728" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Features of similarity, Psychological Rev</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.84.4.327</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-295X.84.4.327" />
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="327" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluating wordnet-based measures of lexical semantic relatedness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Budanitsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli.2006.32.1.13</idno>
		<ptr target="http://dx.doi.org/10.1162/coli.2006.32.1.13" />
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="47" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Development and application of a metric on semantic nets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bicknell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blettner</surname></persName>
		</author>
		<idno type="DOI">10.1109/21.24528</idno>
		<ptr target="http://dx.doi.org/10.1109/21.24528" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Verbs semantics and lexical selection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<idno type="DOI">10.3115/981732.981751</idno>
		<ptr target="http://dx.doi.org/10.3115/981732.981751" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual meeting on Association for Computational Linguistics, in: ACL &apos;94</title>
		<meeting>the 32nd annual meeting on Association for Computational Linguistics, in: ACL &apos;94<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Brown corpus manual</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kucera</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>Brown University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An information-theoretic definition of similarity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Conference on Machine Learning, in: ICML &apos;98</title>
		<meeting>the Fifteenth International Conference on Machine Learning, in: ICML &apos;98<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Conrath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cmp-lg/9709008</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist. (Rocling X)</title>
		<imprint>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Evaluation methods for unsupervised word embeddings</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="298" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Chinese comments sentiment classification based on word2vec and svmperf</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2014.09.011</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2014.09.011" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1857" to="1863" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Enhancing deep learning sentiment analysis with ensemble techniques in social applications</title>
		<author>
			<persName><forename type="first">O</forename><surname>Araque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Corcuera-Platas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sánchez-Rada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2017.02.002</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2017.02.002" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="236" to="246" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
	<note>Semeval-2016 task 4: Sentiment analysis in twitter</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2017">SemEval-2017. 2017</date>
			<biblScope unit="page" from="502" to="518" />
		</imprint>
	</monogr>
	<note>Semeval-2017 task 4: Sentiment analysis in twitter</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mining the opinionated web: Classification and detection of aspect contexts for aspect based sentiment analysis</title>
		<author>
			<persName><forename type="first">O</forename><surname>Araque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>García-Amado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDMW.2016.0132</idno>
		<ptr target="http://dx.doi.org/10.1109/ICDMW.2016.0132" />
	</analytic>
	<monogr>
		<title level="m">Data Mining Workshops (ICDMW), 2016 IEEE 16th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="900" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How to generate a good word embedding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/MIS.2016.45</idno>
		<ptr target="http://dx.doi.org/10.1109/MIS.2016.45" />
	</analytic>
	<monogr>
		<title level="j">IEEE Intell. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3079" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00075</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1174</idno>
		<ptr target="http://dx.doi.org/10.18653/v1/N16-1174" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter</title>
		<meeting>the 2016 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
		<ptr target="http://dx.doi.org/10.1109/5.726791" />
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<title level="m">Convolutional neural networks for sentence classification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Twitter sentiment analysis with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<idno type="DOI">10.1145/2766462.2767830</idno>
		<ptr target="http://dx.doi.org/10.1145/2766462.2767830" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, in: SIGIR &apos;15</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, in: SIGIR &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="959" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A character-based convolutional neural network for language-agnostic twitter sentiment analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E L</forename><surname>Cagnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2017.7966145</idno>
		<ptr target="http://dx.doi.org/10.1109/IJCNN.2017.7966145" />
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2384" to="2391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improving sentiment analysis via sentence type classification using bilstm-crf and cnn</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2016.10.065</idno>
		<ptr target="http://dx.doi.org/10.1016/j.eswa.2016.10.065" />
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="221" to="230" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1167</idno>
		<ptr target="http://dx.doi.org/10.18653/v1/D15-1167" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sentiment embeddings with applications to sentiment analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="496" to="509" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning word representations for sentiment analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12559-017-9492-2</idno>
		<ptr target="http://dx.doi.org/10.1007/s12559-017-9492-2" />
	</analytic>
	<monogr>
		<title level="j">Cogn. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="843" to="851" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Refining word embeddings for sentiment analysis</title>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1056</idno>
		<ptr target="http://dx.doi.org/10.18653/v1/D17-1056" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="534" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">A survey of opinion mining and sentiment analysis, in: Mining Text Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4614-3223-4_13</idno>
		<ptr target="http://dx.doi.org/10.1007/978-1-4614-3223-4_13" />
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="415" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Neural domain adaptation of sentiment lexicons</title>
		<author>
			<persName><forename type="first">O</forename><surname>Araque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACIIW.2017.8272598</idno>
		<ptr target="http://dx.doi.org/10.1109/ACIIW.2017.8272598" />
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos</title>
		<imprint>
			<publisher>ACIIW</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="105" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LREC</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2200" to="2204" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning patterns for discovering domain-oriented opinion words</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agathangelou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Katakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Koutoulakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kokkoras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gunopulos</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10115-017-1072-y</idno>
		<ptr target="http://dx.doi.org/10.1007/s10115-017-1072-y" />
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="77" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Generating linked-data based domainspecific sentiment lexicons from legacy language and semantic resources</title>
		<author>
			<persName><forename type="first">G</forename><surname>Vulcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Negi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coughland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Sánchez Rada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Fernandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">th International Workshop on EMOTION, SOCIAL SIGNALS, SENTIMENT and2 LINKED OPEN DATA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Current state of text sentiment analysis from opinion to emotion mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Yadollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Shahraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Zaiane</surname></persName>
		</author>
		<idno type="DOI">10.1145/3057270</idno>
		<ptr target="http://dx.doi.org/10.1145/3057270" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Inducing domain-specific sentiment lexicons from unlabeled corpora</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1057</idno>
		<ptr target="http://dx.doi.org/10.18653/v1/D16-1057" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing. Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing. Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">595</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Twitter sentiment analysis: The good the bad and the omg!</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kouloumpis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Icwsm</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">538-541</biblScope>
			<biblScope unit="page">164</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Nrc-canada: Building the state-of-theart in sentiment analysis of tweets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013">SemEval 2013. 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="321" to="327" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (* SEM)</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Target-dependent twitter sentiment classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Fine-grained sentiment analysis with structural features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zirn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="336" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Corpus-based and knowledgebased measures of text semantic similarity</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="775" to="780" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">CS224N Project Report</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 2: Sentiment analysis in twitter</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013">SemEval 2013. 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="312" to="320" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (* SEM)</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Semeval</surname></persName>
		</author>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2014">2014 task 9. SemEval 2014. 2014</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
	<note>Sentiment analysis in twitter</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><surname>Vader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="216" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Evaluation datasets for twitter sentiment analysis: a survey and a new dataset, the sts-gold</title>
		<author>
			<persName><forename type="first">H</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.3115/1218955.1218990</idno>
		<ptr target="http://dx.doi.org/10.3115/1218955.1218990" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">271</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.3115/1219840.1219855</idno>
		<ptr target="http://dx.doi.org/10.3115/1219840.1219855" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1014052.1014073</idno>
		<ptr target="http://dx.doi.org/10.1145/1014052.1014073" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Sentiwordnet: a high-coverage lexical resource for opinion mining</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evaluation</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Affective norms for english words (anew): Instruction manual and affective ratings</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<editor>Tech. Rep, Citeseer</editor>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Å</forename><surname>Nielsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1103.2903</idno>
		<title level="m">A new anew: Evaluation of a word list for sentiment analysis in microblogs</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006-01">Jan. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Computing semantic similarity of concepts in knowledge graphs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Iglesias</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2016.2610428</idno>
		<ptr target="http://dx.doi.org/10.1109/TKDE.2016.2610428" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="85" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
