<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linearizing Irregular Memory Accesses for Improved Correlated Prefetching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Akanksha</forename><surname>Jain</surname></persName>
							<email>akanksha@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Calvin</forename><surname>Lin</surname></persName>
							<email>lin@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linearizing Irregular Memory Accesses for Improved Correlated Prefetching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>B.3 [Memory Structures]: Miscellaneous Design</term>
					<term>Performance</term>
					<term>Experimentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces the Irregular Stream Buffer (ISB), a prefetcher that targets irregular sequences of temporally correlated memory references. The key idea is to use an extra level of indirection to translate arbitrary pairs of correlated physical addresses into consecutive addresses in a new structural address space, which is visible only to the ISB. This structural address space allows the ISB to organize prefetching meta-data so that it is simultaneously temporally and spatially ordered, which produces technical benefits in terms of coverage, accuracy, and memory traffic overhead.</p><p>We evaluate the ISB using the Marss full system simulator and the irregular memory-intensive programs of SPEC CPU 2006 for both single-core and multi-core systems. For example, on a single core, the ISB exhibits an average speedup of 23.1% with 93.7% accuracy, compared to 9.9% speedup and 64.2% accuracy for an idealized prefetcher that overapproximates the STMS prefetcher, the previous best temporal stream prefetcher; this ISB prefetcher uses 32 KB of on-chip storage and sees 8.4% memory traffic overhead due to meta-data accesses. We also show that a hybrid prefetcher that combines a stride-prefetcher and an ISB with just 8 KB of on-chip storage exhibits 40.8% speedup and 66.2% accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Prefetching is an important technique for hiding the long memory latencies of modern microprocessors. For regular memory access patterns, prefetching has been commercially successful because stream and stride prefetchers are effective, small, and simple. For irregular access patterns, prefetching has proven to be more problematic. Numerous solutions have been proposed <ref type="bibr">[3-4, 8-15, 17, 19, 22-23, 25-28, 32-34, 37-44]</ref>, but there appears to be a basic design tradeoff between storage and effectiveness, with large storage required to achieve good coverage and accuracy <ref type="bibr" target="#b39">[40]</ref>.</p><p>For example, prefetchers based on address correlation, the subject of this paper, identify sequences of correlated memory addresses-also known as temporal streams-by learning the most likely successor for a given memory reference. Because this correlation information grows in proportion to the application's memory footprint, the fundamental challenge for these prefetchers is the management of megabytes of off-chip correlation information <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>. Access to this off-chip meta-data increases prediction latency and memory traffic, which reduces the effectiveness of prefetching.</p><p>Recent solutions use the Global History Buffer (GHB) <ref type="bibr" target="#b27">[28]</ref>, which organizes correlation information by storing recent memory accesses in a time-ordered circular history buffer; a spatially organized index table is used to find addresses within the history buffer (see Figure <ref type="figure" target="#fig_1">1</ref>). With the temporally ordered history buffer, temporal streams can be efficiently prefetched because each stream is stored contiguously. For address correlation, GHB-based prefetchers can amortize the cost of off-chip meta-data access by fetching long temporal streams <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b8">9]</ref>. Unfortunately, temporal organizations cannot effectively hide the latency of fetching meta-data for short streams, and even the most optimized implementations incur an average memory traffic overhead of 35% on commercial and scientific workloads <ref type="bibr" target="#b41">[42]</ref>.</p><p>One way to reduce the cost of these off-chip accesses would be to cache only the meta-data that correspond to the TLBresident pages of memory. The movement of this cached meta-data to and from DRAM could then be synchronized with expensive TLB evictions, largely hiding the latency of these off-chip accesses.</p><p>Unfortunately, this proposed caching scheme is ill-suited to temporally organized structures such as the GHB. For example, assume in Figure <ref type="figure" target="#fig_1">1</ref> that physical addresses B, X, and D reside on the same page; we see that these addresses are scattered throughout the history buffer and are likely to appear multiple times in the history buffer, so there is no efficient way to evict these entries from the history buffer  when their TLB entry is evicted, nor is it easy to reuse the scattered evicted entries of the history buffer. This paper introduces the Irregular Stream Buffer (ISB), a new correlation-based prefetcher that employs just such a caching scheme and that provides other significant benefits with respect to coverage and accuracy. The main idea is to introduce an extra level of indirection to create a new structural address space in which correlated physical addresses are assigned consecutive structural addresses. The key point is that in this structural address space, streams of correlated memory addresses are both temporally ordered and spatially ordered. For example, we see in Figure <ref type="figure" target="#fig_2">2</ref> that a sequential traversal of the structural address space visits the elements of the irregular temporal stream-A, B, C, D and E-in temporal order. Thus, the problem of prefetching irregular streams is reduced to sequential prefetching in the structural address space. The mapping to and from structural addresses is performed at a cache line granularity by two spatially indexed on-chip address caches whose contents can be easily synchronized with that of the TLB. In addition to the reduced memory traffic provided by our caching scheme, the ISB enjoys several other significant benefits:</p><p>• Improved Prediction Capability: Unlike GHB-based solutions (see Section 3), the ISB can use PC localization, a technique that segregates the prefetcher input into multiple streams based on the PC of the loading instruction, which is known to improve coverage and accuracy <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b24">25]</ref>. In particular, the ISB can combine PC localization and address correlation because any PC-localized temporal stream is stored consecutively in the on-chip address cache (see Figure <ref type="figure" target="#fig_2">2</ref>), i.e., the localization is performed before physical addresses are translated to structural addresses.</p><p>• Training on the Reference Stream: Because the vast majority of its meta-data accesses are on-chip, the ISB can train on the LLC (last level cache) access stream instead of its miss stream, which significantly improves the predictability of the reference stream. By contrast, most previous prefetchers that use address correlation train on the LLC miss stream to avoid the significant off-chip traffic that would be generated by accessing off-chip meta-data on every LLC access. • Support for Short Streams: The ISB's caching scheme greatly reduces memory traffic overhead for all streams, not just for long streams.</p><p>This paper makes the following contributions:</p><p>1. We introduce the ISB, the first prefetcher to combine the use of PC localization and address correlation.</p><p>2. We show-using the irregular, memory-intensive subset of the SPEC 2006 benchmarks-that the ISB significantly advances the state-of-the-art in temporal stream prefetching.</p><p>The ISB obtains 23.1% speedup and 93.7% accuracy, while an idealized STMS prefetcher, which over-approximates the previous state-of-the-art (STMS) <ref type="bibr" target="#b41">[42]</ref>, obtains 9.9% speedup and 64.2% accuracy. We also show that the ISB is superior to two other recent prefetchers, SMS <ref type="bibr" target="#b38">[39]</ref>, which exploits spatial locality, and PC/DC <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b12">13]</ref>, which uses delta correlation instead of address correlation.</p><p>3. We introduce a method of organizing data that synchronizes the movement of prefetcher meta-data with TLB misses to reduce memory traffic overhead. For a single core with DDR2 memory, the ISB incurs an average of 8.4% memory traffic overhead due to metadata access. As a point of comparison, Wenisch, et al. report that the STMS prefetcher produces an average memory traffic overhead of roughly 35% for a mix of commercial and scientific workloads <ref type="bibr" target="#b41">[42]</ref>.</p><p>4. We show that the ISB performs well when combined with a state-of-the-art stride prefetcher (AMPM) <ref type="bibr" target="#b19">[20]</ref>.</p><p>A hybrid that uses an 8 KB ISB achieves a 40.8% speedup over a baseline with no prefetching.</p><p>This paper is organized as follows. Section 2 places our work in the context of prior work. Section 3 motivates our solution by describing the technical issues with pure spatial and purely temporal organizations of correlation information. Section 4 then describes our solution, and Section 5 evaluates our solution, before we conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>We now place our work in the context of prior work, first discussing techniques for improving spatial locality, and then discussing the considerable prior work in prefetching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improving Spatial Locality.</head><p>Spatial locality can be improved by re-ordering the layout of pointer-based data structures during memory allocation <ref type="bibr" target="#b6">[7]</ref> or garbage collection <ref type="bibr" target="#b17">[18]</ref>, but both techniques involve expensive memory copying, and the former relies on programmer hints. Carter, et al., re-order memory accesses in a shadow address space <ref type="bibr" target="#b3">[4]</ref> to improve locality and initiate prefetching, but their technique is limited to statically allocated data structures and requires both OS and programmer intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stride Prefetching.</head><p>Stride prefetchers generally target regular memory access patterns, building on Jouppi's next-line prefetcher <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b23">24]</ref> by adding non-unit strides <ref type="bibr" target="#b28">[29]</ref> and by predicting strides <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>. Ishii, et al., introduce a clever data structure that compactly captures information about multiple stride lengths <ref type="bibr" target="#b19">[20]</ref>. Sair, et al., support irregular streams by introducing a stride length predictor <ref type="bibr" target="#b33">[34]</ref>.</p><p>Hur and Lin enhance stream prefetchers by adding a small histogram of the stream lengths of recently seen memory accesses <ref type="bibr" target="#b18">[19]</ref>. These histograms allow stream buffers to accurately prefetch tiny "streams" that might be as short as two cache lines, thereby providing some coverage for irregular memory accesses that stream buffers alone cannot prefetch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pointer-based Prefetching.</head><p>Pointer-based data structures are an important source of irregular memory accesses, so many techniques focus on prefetching pointers.</p><p>Compilers can insert prefetch instructions-known as jump pointers-for all children of a visited node of a linked data structure <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b31">32]</ref>. The key issue with compiler-based solutions is poor timeliness; to hide long memory latencies, the software prefetches need to be inserted far from their use.</p><p>Hardware solutions, such as pointer caches <ref type="bibr" target="#b9">[10]</ref> and hardware jump pointer tables <ref type="bibr" target="#b32">[33]</ref>, can issue timely prefetches but incur storage overheads of up to 1 MB; some also require compiler support and modifications to the ISA. Content Directed Prefetching (CDP) <ref type="bibr" target="#b10">[11]</ref> is a stateless mechanism that searches through cache lines for pointer addresses that are then greedily prefetched. CDP is attractive in terms of storage requirements, but it wastes memory bandwidth because of its low accuracy.</p><p>Cooperative hardware-software approaches can combine the accuracy of software prefetching and the timeliness of hardware prefetching <ref type="bibr" target="#b32">[33]</ref>. Guided Region Prefetching <ref type="bibr" target="#b39">[40]</ref> uses static analysis to annotate load instructions with hints to the hardware prefetcher. Ebrahimi, et al. use compilerguided filtering mechanisms to inform a CDP prefetcher about the pointers that are most likely to be fetched <ref type="bibr" target="#b13">[14]</ref>.</p><p>There are two key differences between the ISB and pointer-based approaches: (1) The ISB does not give special treatment to pointers, so it can exploit other sources of irregular memory accesses; (2) pointer-based approaches can prefetch compulsory misses, while the ISB cannot.</p><p>Prefetching Based on Spatial Locality.</p><p>Irregular memory accesses can also be prefetched by detecting spatial locality <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5]</ref>. Variations of the Spatial Locality Detection Table <ref type="bibr" target="#b21">[22]</ref> track accesses to different regions of memory so that spatially correlated data can be prefetched together. These approaches typically need large tables to detect locality, but Somogyi, et al. <ref type="bibr" target="#b38">[39]</ref> show how smaller tables can be used by correlating spatial locality with the program counter in addition to parts of the data address. As a result, Spatial Memory Streaming (SMS) can use tables as small as 64 KB, while achieving good performance improvements for commercial workloads.</p><p>Prefetching Based on Temporal Locality.</p><p>Joseph and Grunwald introduce the notion of correlationbased prefetching with their Markov Prefetcher <ref type="bibr" target="#b22">[23]</ref>, which uses a table to record possible successors of a given memory address. The presence of address correlation in applications has been studied both quantitatively <ref type="bibr" target="#b5">[6]</ref> and qualitatively <ref type="bibr" target="#b40">[41]</ref> for scientific and commercial workloads. Studies find that the length of correlated streams can vary from two to several hundred <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b43">44]</ref>, which implies that large amounts of storage are needed to prefetch these workloads effectively. While some designs reduce this on-chip table requirement <ref type="bibr" target="#b16">[17]</ref>, the table size still grows in proportion to the application's active memory footprint. Thus, a variety of solutions store the Markov table off-chip and optimize the memory bandwidth requirements and prefetch look-ahead distance for off-chip table access <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Nesbit and Smith introduce the GHB as a general structure for prefetching streams of temporally correlated memory requests <ref type="bibr" target="#b27">[28]</ref>. However, when used to record address correlation <ref type="bibr" target="#b41">[42]</ref>, the GHB is quite large, requiring about 4 MB of off chip storage for scientific workloads and about 48 MB for commercial server workloads. Thus, Wenisch, et al.'s STMS prefetcher introduces latency and memory traffic optimizations for reading and updating the off-chip history buffer and index table <ref type="bibr" target="#b42">[43]</ref>. These techniques reduce the memory traffic from 3× <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44]</ref> to 1.05-1.75× <ref type="bibr" target="#b42">[43]</ref> for long streams. Rather than use address correlation, other GHBbased prefetchers use delta correlation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27]</ref>, whose space requirements are dramatically smaller, but we show that for irregular accesses, delta correlation leads to low coverage and accuracy.</p><p>PC localization has been used to improve the accuracy and coverage of correlation-based prefetchers <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b37">38]</ref>, but until now, the combination of PC localization and address correlation has been too expensive to be practically considered.</p><p>Finally, Diaz et al. propose a method of chaining PClocalized streams for better prefetch timeliness <ref type="bibr" target="#b11">[12]</ref>. The ISB is orthogonal to these ideas, so it is possible to use stream chaining to link various PC-localized streams in an ISB design, but we do not explore this option in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spatial-Temporal Prefetching.</head><p>The best known irregular prefetcher, Somogyi, et al.'s STeMS prefetcher <ref type="bibr" target="#b37">[38]</ref>, exploits temporal correlation at a coarse granularity and spatial correlation at a finer granularity, essentially learning temporal sequences of spatial regions. The ISB could be employed in a similar fashion to identify the coarse-grain temporal stream, but we do not explore this idea in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE PROBLEM</head><p>To motivate the benefits of the ISB's structural address space, this section explains the problems caused by purely spatial and purely temporal organizations of correlation information.</p><p>Early solutions organize correlated address pairs spatially in a Markov table, which is indexed by memory address <ref type="bibr" target="#b22">[23]</ref>. Unfortunately, Markov tables require multiple table lookups to prefetch temporal streams. To reduce the number of table lookups, each table entry could store a fixed-length stream <ref type="bibr" target="#b7">[8]</ref>, but because temporal stream lengths vary widely from two to several hundred <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b43">44]</ref>, it is difficult to optimize for any single stream length. Thus, fixed-length stream entries lead to inefficient use of on-chip storage, with short streams wasting space (see the entries for Tag X and Y in Figure <ref type="figure" target="#fig_3">3</ref>), and long streams storing data redundantly (see the entries for Tags A, B, C in Figure <ref type="figure" target="#fig_3">3</ref>). The GHB instead stores correlation information temporally, which supports efficient temporal stream prefetching. Unfortunately, this temporal organization makes it prohibitively expensive for GHB-based solutions to combine PC localization with address correlation, because linked list traversals are needed to find past occurrences of the triggering memory request (see Figure <ref type="figure" target="#fig_4">4</ref>). Alternatively, we could imagine allocating a separate fixed-size GHB for each PC, but this solution has issues similar to those of Markov tables: Short streams would waste space, while long streams would require us to chain together multiple GHBs and to follow multiple pointer dereferences to traverse the entire chain. As a result, GHB-based designs forsake either PC localization <ref type="bibr" target="#b42">[43]</ref> or address correlation <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b11">12]</ref>, sacrificing significant coverage for design simplicity.</p><formula xml:id="formula_0">Tag Temporal Stream B C D E F G -- X Y Z -- -- -- -- D E F G -- -- -- A B C D E F G C D E F G -- -- Y Z -- -- -- -- -- Physical Address Fixed length Temporal Stream Temporal Stream 1 : A B C D E F G Temporal Stream 2 : X Y Z</formula><p>The ISB's structural address space allows the correlation information to be organized both spatially and temporally to provide the advantages of both approaches: (1) Temporal streams can be efficiently prefetched; (2) the ISB can combine PC localization and address correlation; and (3) the ISB can cache correlation information for just the TLBresident pages and synch the management of this correlation information with TLB misses.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OUR SOLUTION</head><p>This section describes our solution by first summarizing the overall ISB design and then providing technical details.</p><p>The ISB prediction mechanism mimics the simplicity of stream buffers. Just as stream buffers predict regular memory access patterns, the ISB predicts sequences of memory addresses that are consecutive in the structural address space. Thus, the ISB's prediction step is much simpler than that of other correlation-based prefetchers, which can involve traversals through the GHB.</p><p>To enable these predictions, the ISB training mechanism translates correlated physical memory addresses to consecutive structural addresses. The mapping from the physical address space to the structural address space is cached onchip only for pages that are resident in the TLB, and the prefetcher updates these caches during long latency TLB misses to effectively hide the latency of accessing off-chip meta-data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ISB Components</head><p>The key components of the ISB are shown in Figure <ref type="figure" target="#fig_5">5</ref> and are described below.  Training Unit.</p><p>The training unit takes as input the load PC and the load address, and it maintains the last observed address in each PC-localized stream. It learns pairs of correlated physical addresses and maps these to consecutive structural addresses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Address Mapping Caches (AMCs).</head><p>The ISB uses two on-chip caches to maintain the mapping between physical and structural addresses. The Physicalto-Structural AMC (PS-AMC) stores the mapping from the physical address space to the structural address space; it is indexed by physical addresses. The Structural-to-Physical AMC (SP-AMC) stores the inverse mapping as the PS-AMC and is indexed by structural addresses. While the SP-AMC is not strictly necessary, it enables efficient temporal stream prediction because each cache line in the SP-AMC can yield in a single lookup 16 prefetch candidates from the current temporal stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stream Predictor.</head><p>The stream predictor manages streams in the structural address space. It is analogous to stream buffers that are used for prefetching regular memory accesses <ref type="bibr" target="#b23">[24]</ref>. Each entry in the stream predictor stores the starting structural address of the temporal stream, a counter to indicate the length of the observed stream, and a counter to indicate the current prefetch look-ahead distance. Like a stream buffer, the stream predictor can be configured for various prefetch degrees and look-ahead distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Prefetcher Operation</head><p>We now discuss in more detail each of the ISB's three key functions-training, prediction, and TLB eviction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training.</head><p>The training process assigns consecutive structural addresses to the correlated physical addresses that are observed by the training unit. When a correlated pair (A,B) is observed, the PS-AMC is queried to see if A and B have previously been assigned structural addresses. If A and B already have consecutive structural addresses, the ISB increments the confidence counter for B's entry in the PS-  AMC. If instead A and B have previously been assigned non-consecutive structural addresses, then the confidence in B's mapping is decremented. When the confidence counter hits 0, B is assigned the structural address following A's structural address. If there is no existing mapping for A in the PS-AMC, the ISB generates a new structural address for A and assigns B the subsequent structural address.</p><p>Structural addresses are allocated in fixed size chunks of size c to facilitate temporal streams. To keep track of unassigned structural addresses, the ISB maintains a 64-bit counter and increments it by c after every new allocation. Structural addresses are not de-allocated for future reuse, because the 32-bit structural address space is large enough to map 256 GB of physical address space. Fixed size allocation allows every temporal stream to grow up to length c in the structural address space. Temporal streams of length greater than c must request a new allocation in the structural address space for every (c + 1)th element. Shorter temporal streams, on the other hand, can lead to internal fragmentation of the structural address space. Our experiments show that c = 256 is a good choice that supports efficient temporal stream prediction without suffering from excessive internal fragmentation.</p><p>As an example of the training process, consider a localized stream as shown in Figure <ref type="figure" target="#fig_6">6</ref>, where the Training Unit's last observed address is 0xba1f00, whose structural address is 0x1100. When the Training Unit receives the physical address 0xca4b00 in the same localized stream, it performs three steps. (1) It assigns 0xca4b00 the structural address following 0xba1f00's structural address, namely 0x1101. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction.</head><p>One goal of the ISB design is to keep the prediction process (Figure <ref type="figure" target="#fig_7">7</ref>) as simple as possible. There are three steps.</p><p>(1) Each L2 cache access becomes a trigger address for the prefetcher, causing the PS-AMC to retrieve the trigger address' structural address. In our above example, an access to physical address 0xba1f00 is translated to structural address 0x1100 by the PS-AMC. <ref type="bibr" target="#b1">(2)</ref> The Stream Predictor predicts the next consecutive structural addresses to prefetch, which for degree 1 prefetching is 0x1101. For degree k prefetching, the prediction would include the next k structural addresses, which in this example would be 0x1102, 0x1103, 0x1104 and so forth. (3) The SP-AMC retrieves the physical addresses for each of the predicted structural addresses to prefetch. So, 0x1101 is mapped back to 0xca4b00, and a prefetch request is initiated for this physical address. This mechanism, which consists of two cache lookups, can be used to predict temporal streams efficiently since a single cache line in the SP-AMC contains the translation for 16 consecutive structural addresses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TLB evictions.</head><p>During a TLB eviction, the ISB writes to DRAM any modified mappings for the evicted page, and it fetches from DRAM the structural mapping for the incoming page. The writeback mechanism invalidates the PS-AMC cache lines corresponding to the evicted page, and it initiates a write to memory if the dirty bit is set. Since the PS-AMC and SP-AMC store redundant information, the contents of the SP-AMC need not be written to memory on an eviction. The fetch mechanism initiates a read request for the structural mapping of the newly inserted page and updates both caches appropriately. Since a TLB miss is a long latency operation involving multiple cache and DRAM accesses, these main memory reads and writes are off the critical path and small enough to not interfere with the core-initiated memory requests. In particular, the ISB is able to overlap its off-chip access with the latency of a TLB miss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Details of the Address Mapping Caches</head><p>To optimize the use of on-chip storage, the ISB uses a compressed representation of the physical/structural addresses in its AMCs. Because the AMCs hold only TLB-resident cache lines, the ISB can use the 7-bit index in the TLB to replace the high order 42 bits of the physical address. The SP-AMC can then store the 13-bit physical address formed by concatenating the 7-bit physical page index and the 6bit offset in the physical page. Similarly, the PS-AMC can store the 13-bit structural address formed by concatenating the 7-bit structural page index and the 6-bit offset in the structural page. The structural page indices are maintained in a CAM which is updated on a TLB miss or on a new allocation in the structural address space. This compressed representation is used for all internal ISB operations, such as training and prediction. The 13-bit physical address is expanded to the original 64-bit address only when the ISB schedules a prefetch request, and the 13-bit structural page index needs to be expanded only when the off-chip structural mapping is updated on a TLB eviction.</p><p>The PS-AMC and SP-AMC are organized as setassociative caches with 32-byte cache lines. Each cache line in the PS-AMC contains the structural mapping for 16 consecutive physical addresses, with each mapping using 2 bytes to store a 13-bit structural address, a 2-bit confidence counter, and a valid bit. Similarly, each 32-byte cache line in the SP-AMC contains the physical address maps for 16 consecutive structural addresses. If we were to fully provision each cache to map all pages in a 128 entry data TLB, the SP-AMC and PS-AMC would store 8K mapping entries, requiring a total of 32 KB of storage. However, our evaluation shows that in a hybrid setting, provisioning for more than 2K entries has diminishing performance gains and that an 8 KB ISB provides an attractive trade-off between on-chip storage and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Off-chip Storage</head><p>To organize the ISB's off-chip meta-data, we use the Predictor Virtualization framework proposed by Burcea at al <ref type="bibr" target="#b1">[2]</ref>. In particular, we use a dedicated region of physical memory to maintain the mapping from the physical to the structural address space, which precludes the need for virtual address translation or OS intervention for meta-data accesses.</p><p>For our workloads, it suffices to reserve for the ISB 8 MB of off-chip storage. By contrast, the GHB-based prefetchers that we simulate require up to 128 MB of off-chip storage for the same workloads. This discrepancy in off-chip storage arises because the ISB's meta-data grows with the application's memory footprint, whereas the GHB's meta-data is proportional to the number of memory requests made by the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methodology</head><p>We evaluate the ISB using Marss, a cycle accurate fullsystem x86 simulator <ref type="bibr" target="#b29">[30]</ref>, to model single-core, 2-core, and 4-core systems (see Table <ref type="table" target="#tab_4">1</ref> for details). Our simulation infrastructure faithfully models cache queue contention, port conflicts and memory traffic due to prefetch requests. Our TLB simulation allows page entries to be cached in the lastlevel cache and accurately accounts for the latency of TLB misses. For single-core simulations, we disable timer interrupts. For multi-core simulations, we account for the occasional variation in IPC due to kernel interrupts by taking the median of five runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmarks.</head><p>Because we are interested in irregular memory accesses, our evaluation uses the memory-intensive benchmarks from SPECint2006, which generally use irregular pointer-based data structures. We consider a benchmark to be memoryintensive if it has a CPI &gt; 2 and an L2 miss rate &gt; 50%, according to Jaleel's careful characterization of SPEC2006 <ref type="bibr" target="#b20">[21]</ref>. We also use two benchmarks from SPECfp2006, soplex and sphinx3, which contain a mix of both regular and irregular memory accesses. The benchmarks are compiled using gcc-4.2 with the -O2 option. We compile the benchmarks disabling SSE3/4 instructions because our simulator lacks SSE support. All benchmarks are run using the reference input set. We use the SimPoint sampling methodology, generating for each benchmark multiple SimPoints of 250 million instructions to accurately capture all phases of the benchmark. The SimPoints are generated using the SimPoint Tool <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b15">16]</ref>. We choose a SimPoint length of 250 million instruction because it is large enough to capture long-range behavior, including multiple L2 cache misses on a given address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-programmed Workloads.</head><p>We simulate multi-programmed workloads by choosing different combinations of our existing benchmarks, simulating two benchmarks at a time on our 2-core configuration and four benchmarks at a time on our 4-core configuration. For each benchmark, we fast-forward to a single SimPoint of 250 million instructions. We then simulate the simultaneous execution of the SimPoint regions for the particular benchmark combinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluated Prefetchers.</head><p>In addition to the ISB, we simulate four other prefetchers that target irregular memory accesses.</p><p>First, we simulate Idealized STMS, an idealized version of Wenisch, et al's Sampled Temporal Memory Streaming (STMS) prefetcher <ref type="bibr" target="#b41">[42]</ref>). Rather than implement all of the STMS optimizations, we simply simulate an idealized prefetcher, <ref type="foot" target="#foot_1">2</ref> which represents an upper bound on STMS' performance. In particular, the performance of STMS has been shown to approach that of an idealized G/AC prefetcher for long streams <ref type="bibr" target="#b41">[42]</ref>. Idealized STMS uses a 64 MB GHB with 8M index table entries and optimistically assumes that its accesses to the DRAM-resident GHB are free in terms of access latency, DRAM traffic, and memory controller contention. In terms of accuracy and coverage, Idealized STMS primarily differs from STMS in two ways. First, Idealized STMS performs well for short streams, while STMS does not. Second, Idealized STMS trains on the L2 access stream instead of the L2 miss stream.</p><p>Second, we simulate an idealized PC/AC prefetcher that represents an upper bound for what any GHB-based prefetcher could achieve, because it uses the combination of PC localization and address correlation. This idealized PC/AC prefetcher is completely unrealistic. In addition to the optimistic assumptions that we make for Idealized STMS, we give PC/AC-when possible-an infinite number of linked list traversals per prediction, which is essential to its speedup. For example, when limited to 10,000 linked list traversals per prediction, coverage falls by 50%. However, for mcf and libquantum, we limit the linked list traversals per prediction to 10,000 to allow our simulations to finish within 3 days.</p><p>Third, we simulate Nesbit and Smith's PC/DC prefetcher, which which learns the deltas, or differences, between consecutive memory addresses <ref type="bibr" target="#b27">[28]</ref>. Delta correlation allows PC/DC to store all meta-data on chip, so this prefetcher can realistically train on the L2 access stream. We tune PC/DC using all of the optimizations described by Dimitrov and Zhou <ref type="bibr" target="#b12">[13]</ref>, who submitted the best GHB-based prefetcher in the 2009 Data Prefetching Competition. As with Dimitrov and Zhou's design, our PC/DC prefetcher uses the GHB to exploit delta correlation in both the local and global streams.</p><p>Fourth, we simulate the Spatial Memory Streaming (SMS) prefetcher <ref type="bibr" target="#b38">[39]</ref>, the best known prefetcher that purely exploits spatial locality. The SMS prefetcher realistically trains on the L2 access stream.</p><p>We also study the benefit of using irregular prefetchers in conjunction with regular stride prefetchers. For this study, we use Ishii et al.'s AMPM prefetcher <ref type="bibr" target="#b19">[20]</ref>, the winner of the 2009 Data Prefetching Competition. AMPM identifies hot zones in memory and stores a bitmap to infer strided patterns in the access stream. AMPM is extremely effective and aggressive because it can detect regular memory accesses independent of the order in which they are observed. We give the AMPM 4 KB of storage and tune it by adjusting its threshold and associativity parameters to produce the best coverage.</p><p>For the hybrid experiments, we use an 8 KB ISB, because a 32 KB ISB provides only a small speedup improvement. For the non-hybrid experiments, we use a 32 KB ISB, which contains a 16 KB direct-mapped PS-AMC with 32-byte cache lines, and which uses an 8-way set-associative SP-AMC with 32-byte cache lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Single-Core Results</head><p>Figure <ref type="figure" target="#fig_9">8</ref> compares the speedup, accuracy, and coverage of our five prefetchers on a single core. We see that the two PC/AC-based prefetchers-ISB and idealized PC/ACachieve significantly better speedup and accuracy than the others. In particular, the speedups over a baseline with no prefetching are 26.9% for idealized PC/AC, 23.1% for ISB, 14.1% for PC/DC, 9.97% for Idealized STMS, and 6.9% for SMS. Idealized PC/AC and ISB also see impressive accuracies of 88.0% and 93.7%, respectively, while the other irregular prefetchers observe less than 65% accuracy on average. These results indicate that PC-localized address correlation is superior to the other techniques-global address correlation (STMS), delta correlation (PC/DC), and spatial footprints (SMS)-for prefetching irregular accesses.</p><p>These graphs also show that a practically provisioned ISB approaches the performance of an idealized PC/AC. By contrast, STMS, the previous state-of-the-art in correlation prefetching <ref type="bibr" target="#b41">[42]</ref>, approaches the performance of idealized G/AC. Figure <ref type="figure" target="#fig_9">8</ref> shows two anomalies, namely, that the ISB performs better than the idealized PC/AC on mcf and libquantum. Idealized PC/AC performs poorly on these two benchmarks because it is prohibitively expensive to completely idealize the PC/AC prefetcher for these two benchmarks due to their large memory footprint, so for these two benchmarks, we limited the number of linked list iterations to 10,000 and used the largest possible GHB that allowed the simulations to complete in 3 days.</p><p>If we make Idealized PC/AC a bit more realistic by letting it train on the L2 miss stream instead of the L2 access stream, its speedup falls to 10.4% and its accuracy falls to 86.3%. Similarly, if Idealized STMS trains on the L2 miss stream, its speedup falls to 8.3% and its accuracy to 58.6%. Finally, we note that the ISB sees speedup of just 2.3% on the remaining SPEC FP benchmarks, because the ISB cannot predict compulsory misses, whereas many stride prefetchers can. The ISB does not slow down any of the benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Memory Traffic Overhead</head><p>The ISB's memory traffic overhead approaches that of prefetchers, such as SMS and PC/DC. that store all of their meta-data on chip. In particular, the ISB incurs an average of 14.7% memory traffic overhead, while Dimitrov and Zhou's PC/DC prefetcher <ref type="bibr" target="#b12">[13]</ref> incurs 12.6% overhead and SMS just 10.5% overhead. The highly accurate ISB incurs just 6.3% overhead due to useless prefetches. The ISB accesses off-chip meta-data only during a TLB miss, reading at most 256 bytes of mapping information per page. Assuming a bus width of 64-bytes with DDR2, this information can be fetched from DRAM in four requests. Since not all cache lines in a page are necessarily mapped, the actual traffic per page can vary from one to four requests. As seen in Table <ref type="table" target="#tab_5">2</ref>, the ISB's access to off-chip correlation data increases memory traffic by an average of 8.4%. With DDR3's 128-byte bus width, the traffic would be reduced to 4.2% because the information for the entire page could be fetched in a single DRAM request. By contrast, the STMS prefetcher incurs about 35% overhead due to meta-data access <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Degree Evaluation</head><p>Figures 9 and 10 show how the speedup and accuracy of four prefetchers-ISB, PC/DC SMS, and Idealized STMSvary as the prefetch degree is increased from 1 to 8, revealing several trends:</p><p>• The ISB performs well as the degree increases: With degree 8, its speedup rises from 23.1% to 38.6%, and its accuracy decreases by just 3.8%.   • By contrast, the SMS prefetcher has the best tradeoff between speedup and accuracy, as it improves in both speedup and accuracy as the degree is increased, indicating that prefetches from higher density spatial regions are more accurate, but even for degree 8, the ISB exhibits significantly better speedup and accuracy than SMS.</p><p>• Finally, except at degree 1, Idealized STMS has the worst performance of all of the prefetchers, and its accuracy curve closely matches that of PC/DC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Hybrid Design with AMPM</head><p>Vendors that implement an irregular prefetcher will undoubtedly also implement a regular prefetcher, so we now consider hybrid designs that combine an irregular prefetcher with an AMPM stride prefetcher. Here, we only consider the three practical prefetchers, namely, ISB, PC/DC, and SMS.</p><p>When combined with a regular prefetcher, the ISB is much less sensitive to the size of the AMC. As a result, in a hybrid setting with AMPM, an ISB with 8 KB of storage sees  speedup of 40.8%, whereas an ISB with 32 KB of storage sees an additional speedup of only 6.3%. This behavior can be understood by observing that in our workloads, phases of regular and irregular accesses see little overlap and that the ISB requires large on-chip memory to prefetch long regular streams. In a hybrid setting, 8 KB is sufficient for the ISB to prefetch the irregular phases, while AMPM can prefetch the regular phases.</p><p>Figure <ref type="figure" target="#fig_13">11</ref> compares AMPM against hybrid prefetchers that combine AMPM with an 8 KB ISB, an 8K SMS, and an 8K PC/DC, respectively. The AMPM + SMS hybrid achieves a 24.3% speedup over a baseline with no prefetching, the AMPM + PC/DC achieves a 33.5% speedup, while AMPM alone achieves 15.4% speedup. The AMPM + ISB hybrid achieves a speedup of 40.8% over a baseline with no prefetching, which is an improvement of 25.4% over AMPM. The coverage graph shows that SMS achieves just 4.5% coverage and PC/DC only 9.4% additional coverage over AMPM, while ISB achieves an extra 21.6% coverage over AMPM. A closer inspection of Figure <ref type="figure" target="#fig_13">11</ref> indicates several other key points.</p><p>1. For libquantum, the AMPM + PC/DC hybrid outperforms the AMPM + ISB hybrid because the ISB is not capable of prefetching cold misses, while PC/DC is.</p><p>2. The three benchmarks that contain both regular and irregular accesses-soplex, sphinx, and gcc-see good speedups over AMPM with all hybrids.</p><p>3. For four of the benchmarks-mcf, omnetpp, astar, and xalan-only the AMPM + ISB hybrid achieves a significant improvement over AMPM. These benchmarks are dominated by pointer-based accesses to a graph, a graph, a tree, and a tree, respectively. This indicates that delta correlation and spatial footprints are not very effective for irregular accesses. Moreover, poor coverage combined with poor accuracy causes the AMPM + SMS hybrid and the AMPM + PC/DC hybrid to slow down omnetpp and astar.</p><p>4. The AMPM + ISB hybrid has the highest accuracy among the hybrids at 66.2%. This accuracy is significantly lower than the ISB's accuracy of 93.7% because of AMPM's poor accuracy of 56.6%. For chips with a larger number of cores, a less aggressive stride prefetcher than AMPM would probably be wise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Multi-Core Results</head><p>Figure <ref type="figure" target="#fig_15">12</ref> compares the ISB with SMS, PC/DC, and Idealized STMS on a multi-core system using multi-programmed workloads as described in Section 5.1. We see that the ISB outperforms the three prefetchers on both the 2-core and 4-core machines. On the 2-core machine, the ISB sees a speedup of 23.69%, whereas SMS, PC/DC and Idealized STMS see average speedups of 11.9%, 13.9% and 15.7%, respectively. The average speedup for all prefetchers is lower on the 4-core machine, with the ISB observing a 10.3% speedup, and with SMS, PC/DC, and Idealized STMS achieving 3.7%, 5.8% and 6.5% speedup, respectively. The ISB's accuracy is consistently above 95% for both configurations, which makes it attractive in a multi-core setting, since useless prefetches increase both memory traffic and cache pollution. As the number of cores increase, prefetching accuracy can have a significant bearing on system performance. For example, Ebrahimi, et al. show that in a multi-core environment with 4 cores, any prefetcher whose accuracy is below 40% needs to be throttled down to preserve overall system performance <ref type="bibr" target="#b13">[14]</ref>.</p><p>Figure <ref type="figure" target="#fig_17">13</ref> evaluates hybrid prefetchers by combining AMPM with the ISB, SMS and PC/DC. In a hybrid setting, only the ISB is able to significantly outperform AMPM on both machines, which supports our claim that the ISB is more effective at irregular prefetching than PC/DC and SMS. The AMPM + ISB hybrid observes speedups of 28.6% and 13% on 2-core and 4-core machines, respectively, which is much less than the 40.8% speedup that it achieved on the single-core machine. This decline can be attributed to AMPM, which generates considerable useless traffic due to its poor accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Power Evaluation</head><p>While training on the L2 reference stream provides significant coverage and accuracy benefits, its increased activity increases the prefetcher's power consumption. We thus evaluate the power and energy consumption of the ISB by comparing them against that of the GHB-based PC/DC prefetcher that trains on the L2 miss stream. This discussion will not consider the power impact of useless prefetches on cache and memory subsystem behavior. We use CACTI <ref type="bibr" target="#b34">[35]</ref> to estimate the energy consumed by the prefetching hardware per read/write operation, and we then multiply that cost by the activity counters of the prefetching hardware. We find that the ISB consumes 0.77 times the energy of PC/DC but 1.07 times the power. The increase in average power consumption can be attributed to the faster execution time with the ISB. The ISB generates more activity by training on the L2 access stream, but uses a simple training and prediction logic. By contrast, PC/DC consumes far more energy per input due to its linked list traversals through the GHB, so for the same energy budget, the ISB is able to use localization and exploit the information available in the entire L2 access stream with minimal power overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>In this paper, we have introduced the Irregular Stream Buffer, which represents a significant milestone in the long quest to build prefetchers for irregular memory accesses: The ISB is the first practical prefetcher that combines address correlation with PC localization. While the previous state-of-the-art in temporal stream prefetching, STMS, approaches the behavior of an idealized G/AC prefetcher for long streams, the ISB approaches the superior coverage and accuracy of an idealized PC/AC prefetcher for all streams.</p><p>The key idea behind the ISB is an extra level of indirection that translates correlated physical addresses to consecutive addresses in a new structural address space. Thus, in the structural address space, the elements of a temporal stream appear in sequential order, which greatly simplifies prediction.</p><p>The structural address space provides three important benefits.</p><p>1. It allows the ISB to manage meta-data efficiently by caching TLB-resident meta-data on chip and synchronizing the contents of this cache with TLB misses.  The result is just 8.4% memory traffic overhead for accessing off-chip meta-data, significantly lower than the overheads reported for other address correlationbased prefetchers, such as STMS <ref type="bibr" target="#b41">[42]</ref>, which itself represented an order of magnitude improvement over its predecessors <ref type="bibr" target="#b7">[8]</ref>.</p><p>2. It improves coverage and accuracy by supporting the combination of PC localization and address correlation. For example, on a single core, an idealized PC/AC prefetcher obtains 26.9% average speedup and 88% accuracy, compared with 14.1% speedup and 65% accuracy for PC/DC; an idealized G/AC prefetcher (ie, Idealized STMS) sees 9.97% speedup and 65% accuracy.</p><p>3. Our caching scheme improves coverage and accuracy by allowing the ISB to train on the LLC reference stream instead of the LLC miss stream, which in our experiments more than doubles the observed speedup. For example, the idealized PC/AC prefetcher sees 26.9% speedup when trained the L2 access stream, as opposed to just 10.4% when trained on the L2 miss stream.</p><p>Looking to the future, we plan to evaluate the ISB on commercial workloads. We expect that the ISB will perform well on these workloads, because unlike the GHB, the ISB's on-chip storage and memory traffic overhead depend only on the size of the TLB, not the application's memory footprint. To extend the ISB's benefits to TLBs with large pages, including superpages, we plan to explore a two-level ISB design that can synchronize with pages of any size without undermining the ISB's small on-chip budget. We also plan to evaluate the use of ISB as the temporal component of spatial-temporal prefetchers similar to Somogyi, et al.'s STeMS prefetcher <ref type="bibr" target="#b37">[38]</ref>. More broadly, we believe that the use of a linearized structural address space can be used to drive other micro-architectural optimizations for irregular programs.  international conference on Architectural support for programming languages and operating systems, ASPLOS XIII, pages 157-167. ACM, 2008.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Address correlation using the GHB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Structural address space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: MarkovTable with fixed length temporal streams.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: PC-localized address correlation using the GHB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Block diagram of the Irregular Stream Buffer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: ISB training mechanism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: ISB prediction mechanism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>( 2 )</head><label>2</label><figDesc>It updates the PS-AMC entry indexed by physical address 0xca4b00, and it updates the SP-AMC entry indexed by structural address 0x1101. (3) It changes the last observed address in the Training Unit to 0xca4b00.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparison of irregular prefetchers on single core (degree 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Impact of prefetch degree on speedup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Impact of prefetch degree on accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>SMS (8 KB)Hybrid AMPM + PC/DC (8 KB) Hybrid AMPM + ISB(8 KB)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Comparison of hybrid prefetchers</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Comparison of irregular prefetchers on 2-core (left) and 4-core (right) systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Comparison of hybrid prefetchers on 2-core (left) and 4-core (right) systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Baseline configuration.</figDesc><table><row><cell>Core</cell><cell>Out-of-order, 4 Int/2 Mem/4 FP Func Units,</cell></row><row><cell></cell><cell>128-entry ROB, 4-wide dispatch/commit,</cell></row><row><cell></cell><cell>80-entry LSQ, 256 physical registers</cell></row><row><cell cols="2">Front-End 4-wide Fetch, 32-entry Fetch Queue,</cell></row><row><cell></cell><cell>4K entry BTB, 1K entry RAS,</cell></row><row><cell></cell><cell>Hybrid Two-Level Branch Predictor,</cell></row><row><cell></cell><cell>128 KB 8-way L1 I-Cache</cell></row><row><cell>L1</cell><cell>64 KB 8-way, 2-cycle latency</cell></row><row><cell>L2</cell><cell>2 MB 8-way, 18-cycle latency, 64 MSHRs</cell></row><row><cell>DTLB</cell><cell>128 entries per core</cell></row><row><cell>DRAM</cell><cell>50 ns latency</cell></row><row><cell>Two-core</cell><cell>Private L1 cache, 4 MB shared L2 cache</cell></row><row><cell>Four-core</cell><cell>Private L1 cache, 8 MB shared L2 cache</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Memory traffic overhead of the ISB with DDR2.</figDesc><table><row><cell>• PC/DC has the most severe tradeoff between speedup</cell></row><row><cell>and accuracy: With degree 8, its speedup almost dou-</cell></row><row><cell>bles to 28.8%, but its accuracy falls down to 46.8%,</cell></row><row><cell>which is the worst among all prefetchers.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The STeMS prefetcher can train on the access stream because it searches for coarse-grained temporal streams, relying on a complex spatial prefetcher to fill in the gaps<ref type="bibr" target="#b37">[38]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">Using Nesbit and Smith's terminology<ref type="bibr" target="#b27">[28]</ref>, in which the name before the slash describes the reference scheme and the name after the slash describes the type of correlation that is used, a G/AC prefetcher trains on a Global reference stream and uses Address Correlation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments.</head><p>We thank Curtis Dunham, Ibrahim Hur, Don Fussell, and Daniel Jimenez for their valuable comments on early drafts of this paper. This work was funded in part by NSF grant CNS-1138506.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Effective hardware-based data prefetching for high-performance processors</title>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Baer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="609" to="623" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Predictor virtualization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Burcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th</title>
				<meeting>the 13th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Filtering superfluous prefetches using density vectors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Puzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCD &apos;01: Proceedings of the International Conference on Computer Design: VLSI in Computers &amp; Processors</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Impulse: Building a smarter memory controller</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunvand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kuramkote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schaelicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tateyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
				<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accurate and complexity-effective spatial pattern prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Symposium on High Performance Computer Architecture, HPCA &apos;04</title>
				<meeting>the 10th International Symposium on High Performance Computer Architecture, HPCA &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="276" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient representations and abstractions for quantifying and exploiting data reference locality</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PLDI</title>
				<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cache-conscious structure layout</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Larus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGPLAN 1999 conference on Programming Language Design and Implementation, PLDI &apos;99</title>
				<meeting>the ACM SIGPLAN 1999 conference on Programming Language Design and Implementation, PLDI &apos;99</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Low-cost epoch-based correlation prefetching for commercial applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="301" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Application data prefetching on the ibm blue gene/q supercomputer</title>
		<author>
			<persName><forename type="first">I.-H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;12</title>
				<meeting>the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pointer cache assisted prefetching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Tullsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 35th Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="62" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A stateless, content-directed data prefetching mechanism</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cooksey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jourdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="279" to="290" />
			<date type="published" when="2002-10">October 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stream chaining: exploiting multiple levels of correlation in data prefetching</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cintra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="81" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining local and global history for high performance data prefetching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Instruction-Level Parallelism Data Prefetching Championship</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Techniques for bandwidth-efficient prefetching of linked data structures in hybrid prefetching systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Patt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="7" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Memory-system design considerations for dynamically-scheduled processors</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Vranesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;97: Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
				<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simpoint 3.0: Faster and more flexible program phase analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Instruction Level Parallelism</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TCP: tag correlating prefetchers</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martonosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kaxiras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The garbage collection advantage: improving program locality</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E B</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, OOPSLA &apos;04</title>
				<meeting>the 19th annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, OOPSLA &apos;04</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Memory prefetching using adaptive stream detection</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Symposium on Microarchitecture</title>
				<meeting>the 39th International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="397" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Access map pattern matching for high performance data cache prefetch</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hiraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Instruction-Level Parallelism</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Memory characterization of workloads using instrumentation-driven simulation -a pin-based memory characterization of the SPEC CPU2000 and SPEC CPU2006 benchmark suites</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaleel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Run-time spatial locality detection and optimization</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Merten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-M</forename><forename type="middle">W</forename><surname>Hwu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual ACM/IEEE International Symposium on Microarchitecture</title>
				<meeting>the 30th Annual ACM/IEEE International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prefetching using markov predictors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
				<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3a</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="1990-05">May 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting spatial locality in data caches using spatial footprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="357" to="368" />
			<date type="published" when="1998-04">April 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Compiler-based prefetching for recursive data structures</title>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Luk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Mowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="222" to="233" />
			<date type="published" when="1996-09">September 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ac/dc: An adaptive data cache prefetcher</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Dhodapkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE PACT</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="135" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Data cache prefetching using a global history buffer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Nesbit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="90" to="97" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evaluating stream buffers as a secondary cache replacement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Architecture</title>
				<meeting>the International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1994-04">April 1994</date>
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">MARSSx86: A Full System Simulator for x86 CPUs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Afram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ghose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference 2011 (DAC&apos;11)</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using simpoint for accurate and efficient simulation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Biesbrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems</title>
				<meeting>the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="318" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dependence based prefetching for linked data structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth international conference on Architectural support for programming languages and operating systems, ASPLOS-VIII</title>
				<meeting>the eighth international conference on Architectural support for programming languages and operating systems, ASPLOS-VIII</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="115" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Effective jump-pointer prefetching for linked data structures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Sohi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Symposium on Computer Architecture, ISCA &apos;99</title>
				<meeting>the 26th Annual International Symposium on Computer Architecture, ISCA &apos;99</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="111" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A decoupled predictor-directed stream prefetching architecture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="276" />
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Cacti 3.0: An integrated cache timing, power, and area model</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shivakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jouppi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<publisher>Compaq Computer Corporation</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sequential program prefetching in memory hierarchies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7" to="12" />
			<date type="published" when="1978-12">December 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Using a user-level memory thread for correlation prefetching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Solihin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture</title>
				<meeting>the 29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spatio-temporal memory streaming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spatial memory streaming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA &apos;06: Proceedings of the 33rd Annual International Symposium on Computer Architecture</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Guided region prefetching: a cooperative hardware/software approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Weems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="388" to="398" />
			<date type="published" when="2003-05">May 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Temporal streams in commercial server applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IISWC</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Practical off-chip meta-data for temporal memory streaming</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Making address-correlated prefetching practical</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferdman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moshovos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="59" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Temporal streaming of shared memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wenisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somogyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hardavellas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ailamaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falsafi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Computer Architecture News</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="222" to="233" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
