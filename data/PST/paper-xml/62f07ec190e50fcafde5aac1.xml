<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Semantic Alignment System for Multilingual Query-Product Retrieval The first-place entry for Query-Product Ranking of ESCI Challenge at KDD Cup 2022</title>
				<funder ref="#_QxQJuKC #_5gVHvC6">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-08-05">5 Aug 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qi</forename><surname>Zhang</surname></persName>
							<email>zhangqi21@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Yang</surname></persName>
							<email>yangzijian@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Yilun</forename><surname>Huang</surname></persName>
							<email>huangyilun@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Ze</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Cai</surname></persName>
							<email>caizijian01@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Kangxu</forename><surname>Wang</surname></persName>
							<email>wangkangxu@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Jiewen</forename><surname>Zheng</surname></persName>
							<email>zhengjiewen@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Jiarong</forename><surname>He</surname></persName>
							<email>gzhejiarong@corp.netease.com</email>
						</author>
						<author>
							<persName><forename type="first">Jin</forename><surname>Gao</surname></persName>
							<email>jgao@corp.netease.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Interactive Entertainment Group of Netease Inc. Guangzhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Final Winners</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">KDD&apos;22</orgName>
								<address>
									<postCode>2022</postCode>
									<settlement>Aug</settlement>
									<region>Washington D.C</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Semantic Alignment System for Multilingual Query-Product Retrieval The first-place entry for Query-Product Ranking of ESCI Challenge at KDD Cup 2022</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-08-05">5 Aug 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2208.02958v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T08:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Shopping Queries Data Set</term>
					<term>Query-Product Ranking</term>
					<term>KDD Cup</term>
					<term>Multilingual Language Model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper mainly describes our winning solution (team name: www) to Amazon ESCI Challenge of KDD CUP 2022, which achieves a NDCG score of 0.9043 and wins the first place on task 1: the queryproduct ranking track. 1  In this competition, participants are provided with a real-world large-scale multilingual shopping queries data set and it contains query-product pairs in English, Japanese and Spanish. Three different tasks are proposed in this competition, including ranking the results list as task 1, classifying the query/product pairs into Exact, Substitute, Complement, or Irrelevant (ESCI) categories as task 2 and identifying substitute products for a given query as task 3.</p><p>We mainly focus on task 1 and propose a semantic alignment system for multilingual query-product retrieval. Pre-trained multilingual language models (LM) are adopted to get the semantic representation of queries and products. Our models are all trained with cross-entropy loss to classify the query-product pairs into ESCI 4 categories at first, and then we use weighted sum with the 4-class probabilities to get the score for ranking. To further boost the model, we also do elaborative data preprocessing, data augmentation by translation, specially handling English texts with English LMs, adversarial training with AWP and FGM, self distillation, pseudo labeling, label smoothing and ensemble. Finally, Our solution outperforms others both on public and private leaderboard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Amazon ESCI Challenge <ref type="bibr" target="#b1">[2]</ref> for Improving Product Search of KDD CUP 2022 is aiming to improve the customer experience and their engagement when searching for products. The primary objective of this competition is to build new ranking strategies and, simultaneously, to identify interesting categories of results by using their real-world Shopping Queries Dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Dataset Description</head><p>The provided Shopping Queries Dataset <ref type="bibr" target="#b15">[16]</ref> involves 3 languages: English (about 54.5% of the total training sets) , Japanese (about 26.5% of the total training sets) and Spanish (about 19% of the total training sets). In online shopping applications, the notion of binary relevance limits the customer experience. To keep high accuracy in ranking, the competition organizers break down relevance into the following four classes (ESCI) which are used to measure the relevance of the items in the search results. Exact (E) and Substitute (S), stands for the item is relevant and somewhat relevant to the query respectively. Complement (C) and Irrelevant (I) denotes respectively the item does not fulfill the query and the item is irrelevant.</p><p>For each query, the dataset provides a list of up to 40 potentially relevant product results, together with ESCI relevance judgements and an annotated locale label. For each product, the dataset provides associated information such as product title, description, bullet points, brand, color and locale.</p><p>A total of about 1.2 million products and 2 million query-product pairs are provided in this challenge, which are used for model training and offline validating. Online test set is split into public and private ones, and the final ranking is based on the score on the private leaderboard.</p><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, the label distribution is very imbalanced. Most of the labels are Exact with the percentage up to 62.78%, while Complement class only accounts for 3.16%, Substitute and Irrelevant class account for 23.28% and 10.78% respectively. And according to our statistics, 54% of product brands focus on providing only one product, while only 7.1% of brands provide more than 10 products. At the same time, more than 80% of the color names are only customized for a single product. Such results help us to further understand and quantify the characteristics and distributions of the corpora provided in this competition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Task Description</head><p>There are three tasks in this competition and we mainly involved in task 1: Query-Product Ranking. The goal of this task is to rank a list of matched products of a specified user query. NDCG is used as relevance metric in this task, with a class gain of 1.0, 0.1, 0.01, 0.0 setting for ESCI respectively. The input for this task is a list of queries with their product identifiers. And the participants is asked to build a system to sort the product candidates, with the most relevant product in the first row and the least relevant product in the last.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work is mainly related to the pre-trained LMs and some specific strategies on Learning-to-Rank(LTR) systems, such as adversarial training, model ensemble and so on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cross-Encoder Models</head><p>Neural approaches have greatly improved the information retrieval results in recent years. Prior to this, similarity metrics primarily rely on keyword matching, with some limited thesaurus and phrasebased expansion. BERT <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref> uses Cross-Encoder architecture to achieve further improvements in the field of text understanding by passing the query and product simultaneously to the transformer networks and producing an output representation that indicates the similarity of the input pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multilingual Language Model</head><p>Defining textual features in a cross-lingual representation space has always been a challenge. The more languages there are, the confusing the representation contents will be. XLM <ref type="bibr" target="#b11">[12]</ref> use Byte-Pair Encoding that splits the input into the most common sub-words across different languages instead of using word or characters as the input of the model. On the other hand, the Translation Language Modeling (TLM) task also increases the ability of contextual encoding. Nowadays, a set of large-scale Transformer-based pretrained language models, such as RemBERT <ref type="bibr" target="#b4">[5]</ref>, XLM-RoBERTa <ref type="bibr" target="#b5">[6]</ref>,</p><p>InfoXLM <ref type="bibr" target="#b3">[4]</ref> and mDeBERTa <ref type="bibr" target="#b9">[10]</ref> have created new state of the art in many downstream fields. It turns out that training cross-lingual language models can improve performance on many NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning to Rank</head><p>Learning to rank (LTR) is a class of algorithmic techniques which are used to solve ranking problems in search relevancy <ref type="bibr" target="#b2">[3]</ref>. For a specific query, we can use the model to do the ranking so that the relevant products will be ranked above the non-relevant ones. During the modeling process, query embedding and product embedding are concatenated as input to refine the self-attention mechanism for learning semantic alignments between queries and product descriptions. It is significant for the ranking task to establish a strong semantic alignment between the queries and the products <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>Our solution to this task mainly consists of 3 parts, which are data preprocessing, model training and ensemble. The overall framework is shown in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Processing</head><p>Given that datasets from the 3 tasks are exactly in the same format, we use all of the data from 3 tasks to train the model for task 1. The raw data is quite noisy containing many useless html tags, symbols and emojis, so we do some data cleaning work before model training by simply remove these trivial stuffs. After data cleaning, we use Google API to translate all of the data into English, Spanish and Japanese separately to do data augmentation. We also use typed entity marker <ref type="bibr" target="#b18">[19]</ref> to incorporate the NER information into the input of models. We add special tokens [TYPE], [/TYPE] near the entities in input text, where TYPE is the entity type recognized by a named entity tagger. For example, given the query "I want to buy an iPhone 8 Plus", it will be modified to "I want to buy an [Product] iPhone 8 Plus [/Product]".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>The single model architecture is shown in the Figure <ref type="figure" target="#fig_1">2</ref>, we use the cross-encoder architecture based on DeBERTa, XLMs, and RemBERT. For the downstream task, [CLS] embedding is used to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Details</head><p>We found that lots of mislabeling cases may exist in the dataset when doing bad cases analysis based on our local validation set in ESCI classification task. We realize that the data, labeled by crowdsourcing, could be quite noisy inevitably. To avoid misleading by the mislabeling, we use label smoothing to make the model less confident to the labels, which is proven to be effective. Training models in complex and ambiguous contexts can badly affects its generalization. To improve the model robustness, some training tricks are adopted during our experiments. <ref type="bibr" target="#b17">[18]</ref>. Given that the data is labeled by crowdsourcing, it could be quite noisy for the model to extract the real information. To make the model more robust, we use self-distillation training to further boost our single model. The model itself is used as its own teacher to do distillation training. To be specific, we use 3-fold bagging training and make prediction on the out-offold datasets to generate the soft labels for all of the training examples. And then we merge the soft labels with the ground true hard labels with weights 0.3 and 0.7 to get the new training labels:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Self Distillation</head><formula xml:id="formula_0">?_??? = 0.7 * ???? ?????? + 0.3 * ?? ? ? ??????</formula><p>We also tried to use two loss functions to compute the soft label loss and hard label loss separately and sum it with different weights. Unfortunately, it didn't work better than directly merge the labels as mentioned above. <ref type="bibr" target="#b12">[13]</ref>. We also use our trained models to generate pseudo labels from the public test set to do further training. To avoid making the training data more noisy, only samples from the public test set with predicted probabilities above 0.7 are used as pseudo labels, as shown in Figure <ref type="figure" target="#fig_2">3</ref>. And soft labels work better than hard labels during most of our experiments, we guess that hard labels may increase the risk of overfitting to some extent. <ref type="bibr" target="#b10">[11]</ref>. Dropout is a simple but efficient regularization technique for achieving better generalization. By  <ref type="bibr" target="#b13">[14]</ref>. In addition to increasing the robustness and recall of the model, we also make some adjustments to improve the precision. On the step of data processing, we prepared a series of specific tokens as implicit templates to provide extended reference features during encoding. By introducing this information, our model can have a better performance to handle diverse features. <ref type="bibr" target="#b6">[7]</ref>. Furthermore, it is obviously to found that the textual information between the query and the content of product are different in most cases (the text length of the product is much longer than the query). In order to prevent the query information vanishing after the neural transmission, our model automatically generates an attended attention over original self-attention, which makes the feature of latent distribution not only contain the queryto-product part, but also the query-to-mix_sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Pseudo Label</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Multi Sample Dropout</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Prompt Tuning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Cross Attention</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.6">Adversarial</head><p>Training. Adversarial-training let us train networks with significantly improved resistance to adversarial attacks, thus improving robustness of models.</p><p>When the loss is below some threshold (like 0.6), we start using Adversarial Weight Perturbation (AWP) <ref type="bibr" target="#b16">[17]</ref> in training steps that adversarially perturbs both model weights and the embeddings. In addition, the feature distribution of input data is attacked in each step. Besides, we also tried Fast Gradient Method (FGM) <ref type="bibr" target="#b8">[9]</ref> which performs slightly worse than AWP does in public leaderboard.</p><p>3.3.7 English BERT Model. Although the task is multilingual, the English part is of large proportion, accounting for 54.5% of the total training sets. Take this into account, we also use DeBERTa-v3-large to train and predict for the English queries and products only besides the cross-lingual models. Combining with adversarial training, our single model gets improved from 0.899 to 0.9022 in the public leaderboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ensemble</head><p>At last, model ensemble is used to get the final improvement. In detail, we use DeBERTa, RemBERT and XLM based models trained with different settings mentioned above as our base models for ensemble.</p><p>The weights for summing different model predictions are mainly determined by the public scores of the models and also the local cross-validation scores. We also lower the weights of the models with high correlation coefficients. Our score is improved from 0.9022 to 0.9057 on the public leaderboard, and from 0.9015 to 0.9043 on the private leaderboard after ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS &amp; DISCUSSION</head><p>Some results of our experiments in Task 1 are shown in Table <ref type="table" target="#tab_1">2</ref>. The scores of our single models without any pre-processing or postprocessing are around 0.8930 in the public leaderboard. DeBERTa, InfoXLM, XLM-RoBERTa, and RemBERT are used as the model backbone, then we concatenate the texts of query, title, description, bullet point together and truncate it with max_length=128 after tokenizing as the model inputs.</p><p>After doing some data cleaning and hyper-parameters tuning, our single model is improved to 0.8960 on the public leaderboard. Batch size and learning rate are quite important in this task based on our experiments, we use batch size=64, learning rate=3e-5 and gradient accumulation=8 to train the model after tuning. Self distillation, pseudo labels and label smoothing help us further boost the model performance to 0.8990 on the public leaderboard.</p><p>With English pre-trained LMs and adversarial training, we can achieve 0.9022 in the public leaderboard and 0.9015 for the private, and this is our best single model. At last, we do model ensemble to get the final boost from 0.9022 to 0.9057 on the public leaderboard, and from 0.9015 to 0.9043 on the private leaderboard. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overall framework and pipeline of our solution</figDesc><graphic url="image-1.png" coords="2,317.96,83.69,240.24,269.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model architecture for a single model</figDesc><graphic url="image-2.png" coords="3,53.80,83.68,240.25,142.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Train model with pseudo-labelled subset</figDesc><graphic url="image-3.png" coords="3,317.96,83.68,240.24,123.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Distribution of ESCI Labels</figDesc><table><row><cell># (E) Exact</cell><cell>62.78%</cell></row><row><cell># (S) Substitute</cell><cell>23.28%</cell></row><row><cell cols="2"># (C) Complement 3.16%</cell></row><row><cell># (I) Irrelevant</cell><cell>10.78%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Some results of our experiments in Task 1In this paper, we detailed our winning solution to the Query-Product Ranking task in Amazon ESCI Challenge of KDD Cup 2022. We use multilingual and English pre-trained LMs as backbone, with the combination of data processing, data augmentation, self-distillation, pseudo-labelling, label-smoothing and adversarial training, we improve the model step by step. For single model, we achieve NDCG score of 0.9022 on the public leaderboard and 0.9015 on the private leaderboard. At last, we do model ensemble to get the final boost from 0.9022 to 0.9057 on the public leaderboard, and from 0.9015 to 0.9043 on the private leaderboard, which ensures us to win the first place.</figDesc><table><row><cell>Methods</cell><cell>NDCG</cell><cell>NDCG</cell></row><row><cell></cell><cell>(Public)</cell><cell>(Private)</cell></row><row><cell>mDeBERTa Baseline</cell><cell>0.8930</cell><cell>-</cell></row><row><cell>+ Data Clean + Parameter Tuning</cell><cell>0.8960</cell><cell>-</cell></row><row><cell>+ Self Distillation + Pseudo Labeling</cell><cell>0.8982</cell><cell>0.8975</cell></row><row><cell>+ Label Smoothing</cell><cell>0.8990</cell><cell>-</cell></row><row><cell>+ DeBERTa-v3-large + AWP/FGM</cell><cell>0.9022</cell><cell>0.9015</cell></row><row><cell>+ InfoXLM</cell><cell>0.9032</cell><cell>0.9032</cell></row><row><cell>+ XLM-RoBERTa</cell><cell>0.9041</cell><cell>0.9026</cell></row><row><cell>+ RemBERT</cell><cell></cell><cell></cell></row><row><cell>+ DeBERTa-v3-large</cell><cell></cell><cell></cell></row><row><cell>+ Translation augmentation + 2 of 7 folds bagging</cell><cell>0.9059*</cell><cell>0.9039</cell></row><row><cell>+ Weighted multi-layer Pooling</cell><cell></cell><cell></cell></row><row><cell>+ Multi sample dropout</cell><cell></cell><cell></cell></row><row><cell>Model Ensemble Re-weighting</cell><cell>0.9057</cell><cell>0.9043*</cell></row><row><cell>5 CONCLUSION</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACM Reference Format:</head><p><rs type="person">Qi Zhang</rs>, <rs type="person">Zijian Yang</rs>, <rs type="person">Yilun Huang</rs>, <rs type="person">Ze Chen</rs>, <rs type="person">Zijian Cai</rs>, <rs type="person">Kangxu Wang</rs>, <rs type="person">Jiewen Zheng</rs>, <rs type="person">Jiarong He</rs>, <rs type="person">Jin Gao</rs>. <rs type="grantNumber">2022</rs>. A Semantic Alignment System for Multilingual Query-Product Retrieval: The first-place entry for Query-Product Ranking of <rs type="institution">ESCI Challenge at KDD Cup 2022. In Proceedings of the ACKNOWLEDGMENTS Amazon and AIcrowd</rs> organizing team paid a lot of efforts during the whole process of the competition, we really appreciate it for hosting this fantastic competition. And we would like to thank everyone associated with organizing and sponsoring the <rs type="grantNumber">KDD Cup 2022</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QxQJuKC">
					<idno type="grant-number">2022</idno>
				</org>
				<org type="funding" xml:id="_5gVHvC6">
					<idno type="grant-number">KDD Cup 2022</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving BERTbased query-by-document retrieval with multi-task optimization</title>
		<author>
			<persName><forename type="first">Amin</forename><surname>Abolghasemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://www.aicrowd.com/challenges/esci-challenge-for-improving-product-search" />
		<title level="m">ESCI Challenge for Improving Product Search</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Feng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Zewen</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saksham</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian-Ling</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heyan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.07834</idno>
		<title level="m">InfoXLM: An information-theoretic framework for cross-lingual language model pre-training</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Rethinking embedding coupling in pre-trained language models</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12821</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Attention-over-attention neural networks for reading comprehension</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04423</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.09543</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Multi-sample dropout for accelerated training and better generalization</title>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Inoue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09788</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07291</idno>
		<title level="m">Cross-lingual language model pretraining</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semisupervised learning method for deep neural networks</title>
		<author>
			<persName><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Que2Search: fast and accurate query and document understanding for search at Facebook</title>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Rangadurai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddarth</forename><surname>Malreddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xunlong</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Borisyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3376" to="3384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Llu?s</forename><surname>Chandan K Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fran</forename><surname>M?rquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sambaran</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnab</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anlu</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><surname>Subbian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.06588</idno>
		<title level="m">Shopping Queries Dataset: A Large-Scale ESCI Benchmark for Improving Product Search</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial weight perturbation helps robust generalization</title>
		<author>
			<persName><forename type="first">Dongxian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yisen</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2958" to="2969" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Improving bert fine-tuning via self-ensemble and self-distillation</title>
		<author>
			<persName><forename type="first">Yige</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ligao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10345</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A frustratingly easy approach for entity and relation extraction</title>
		<author>
			<persName><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12812</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
