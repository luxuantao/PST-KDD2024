<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Denoising Based on SURE Risk</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiao-Ping</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Mita</forename><forename type="middle">D</forename><surname>Desai</surname></persName>
						</author>
						<title level="a" type="main">Adaptive Denoising Based on SURE Risk</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4B1B9703B91F4155780C7C5CAD3BD255</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-27T07:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Denoising</term>
					<term>thresholding functions</term>
					<term>wavelet shrinkage</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, a new adaptive denoising method is presented based on Stein's unbiased risk estimate (SURE) and on a new class of thresholding functions. First, we present a new class of thresholding functions that has continuous derivative while the derivative of standard soft-thresholding function is not continuous. The new thresholding functions make it possible to construct the adaptive algorithm whenever using the wavelet shrinkage method. By using the new thresholding functions, a new adaptive denoising method is presented based on SURE. Several numerical examples are given. The results indicated that for denoising applications, the proposed method is very effective in adaptively finding the optimal solution in mean square error (MSE) sense. It is also shown that this method gives better MSE performance than those conventional wavelet shrinkage methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>F OR denoising applications with known noisy function, it is often necessary to search for the optimal minimum mean-square error ( risk) estimate using a priori information. Recently, Donoho and others have developed wavelet shrinkage methods for denoising for the function estimation applications <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref>. Of these wavelet shrinkage methods, SureShink is an optimized hybrid scale dependent thresholding scheme based on Stein's unbiased risk estimate (SURE) <ref type="bibr" target="#b6">[7]</ref> risk <ref type="bibr" target="#b1">[2]</ref>. It combines the universal threshold selecting scheme and the scale dependent adaptive threshold selecting scheme and provides the best estimation results in the sense of risk. SURE risk is a very good estimation of the true risk when the true function is not known <ref type="bibr" target="#b6">[7]</ref>. However, since the standard soft-thresholding function is weakly differentable only in the first order, it does not allow for the gradient based optimization method to search for the optimal solution for SURE risk. To this end, Donoho's scheme <ref type="bibr" target="#b1">[2]</ref> roughly searches for the optimal threshold within a finite threshold set.</p><p>In this paper, first a new class of thresholding functions with continuous derivative is presented. Note that the derivative of standard soft-thresholding function is not continuous. The new thresholding functions do the similar manipulation as the standard soft-thresholding function, and they make it possible to search for optimal thresholds using gradient-based adaptive algorithms. Next, by using the new thresholding functions, a new adaptive denoising method is presented based on SURE risk. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ADAPTIVE DENOISING METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Objective</head><p>Assume the observed data vector given by: <ref type="bibr" target="#b0">(1)</ref> where is samples of a determinstic function and is Gaussian white noise with independent identical distribution (i.i.d.)</p><p>Our denoising objective is to estimate function with minimum mean square error (MSE), i.e., to minimize risk for a given noisy function, as follows:</p><p>(2)</p><p>Note that here we use mean instead of the mathematical expectation, because the optimal solution is desired for each individual noisy function. The conventional wavelet shrinkage methods are shown to be effective in minimax MSE sense and retain a good visual effect <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Following are the three steps in wavelet shrinkage methods.</p><p>1) Apply the discrete wavelet transform (DWT) <ref type="bibr" target="#b7">[8]</ref> to the vector and obtain the empirical wavelet coefficients at scale where Note represents the scaling coefficients and will not be shrunk in the next step.</p><p>2) Apply the nonlinearity, such as soft-thresholding function, to the empirical wavelet coefficients at each scale Then the estimate coefficients are obtained based on the selected threshold Note is the threshold for wavelet coefficients at scale In universal thresholding scheme, the same threshold is used at all scales. In scale dependent schemes such as SureShrink, the thresholds at different scales are generally different.</p><p>3) Use the inverse DWT on thresholded wavelet coefficients and obtain the estimate of the function. The wavelet shrinkage method relies on the basic idea that the energy of a function (with some smoothness) will often be concentrated in a few coefficients in wavelet domain while the energy of noise is spread among all coefficients in wavelet domain. Therefore, the nonlinear thresholding function in wavelet domain will tend to keep a few larger coefficients representing the function, while the noise coefficients will tend to reduce to zero.</p><p>In the wavelet shrinkage methods, the orthogonal DWT is often used. If orthogonal DWT is used, then the risk function given in (2) can be expressed as (3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. A New Class of Differentable Thresholding Functions</head><p>The widely used soft thresholding function are continuous with discontinuous derivative. However, the continuous derivative or higher order derivatives are often desired for optimization problems. A new class of nonlinear soft-like thresholding functions, motivated by the differentiable sigmoid function which replaces the undifferentiable hard-limited function in traditional neural network <ref type="bibr" target="#b8">[9]</ref>, with continuous derivatives are constructed as follows: <ref type="bibr" target="#b3">(4)</ref> where is a positive integer. Note that the limit of when is just the commonly used soft-thresholding function</p><p>The thresholding functions and are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. It can be seen that the new shrinkage functions perform the similar operations to the standard soft-thresholding function. Therefore, the similar smoothness of the estimate using the new thresholding functions can be expected. The new thresholding functions will have better numerical properties as will be shown in the examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Adaptive Denoising Using SURE Risk</head><p>SURE risk is defined for function estimation <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b6">[7]</ref>. For function estimation problem shown as in (1), assume <ref type="bibr" target="#b4">(5)</ref> where is a function from to Stein <ref type="bibr" target="#b6">[7]</ref> showed that when is weakly differentiable, then</p><p>where SURE is an unbiased estimator of the above risk, defined as (7) Donoho <ref type="bibr" target="#b1">[2]</ref> used the standard soft-thresholding function and selected a threshold in set <ref type="bibr" target="#b7">(8)</ref> Note that is a suboptimal threshold for the risk because it is selected within a finite set.</p><p>Although the standard soft-thresholding function is weakly differentiable in Stein's sense <ref type="bibr" target="#b6">[7]</ref>, it does not have the second derivative (see Fig. <ref type="figure" target="#fig_0">1</ref>). Therefore, it is not possible to look for the optimal solution for the risk using gradient based adaptive algorithm as the case in neural network using hard-limited function. However, the proposed soft-thresholding function is twice deferentiable in Stein's sense. Then the gradients of can be calculated as follows. From ( <ref type="formula">7</ref>), we obtain <ref type="bibr" target="#b8">(9)</ref> From ( <ref type="formula">5</ref>), Using ( <ref type="formula">4</ref>) and ( <ref type="formula">5</ref>), we obtain <ref type="bibr" target="#b9">(10)</ref> and ( <ref type="formula">11</ref>)</p><p>Using (3), the SURE risk at each scale can be calculated in wavelet domain independently. Then the gradient based learning algorithm can be used to search for the optimal scale-dependent threshold in wavelet domain under the estimated risk</p><p>The threshold can be adjusted toward the optimal solution under SURE risk using following adaptive steps:</p><p>(12) where the adjustment of threshold at step is (13) in each step, where is the learning rate. Note that should be selected so that Since the SURE risk is also an estimate of the risk defined in (2), the optimal solution under SURE risk will be an estimate of the optimal solution for risk <ref type="bibr" target="#b1">(2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. NUMERICAL EXAMPLES</head><p>The artificial functions such as Blocks, Bumps, HeaviSine and Doppler, created by Donoho et al. <ref type="bibr" target="#b1">[2]</ref> are selected as test functions. Assume the length of all the functions is 2048 with the signal-to-noise ratio (SNR)</p><p>The Daubechies 8 least asymmetrical wavelet is used and the largest DWT level is selected. The risks (MSE's) in (2) of different wavelet shrinkage methods for estimation are given in Table <ref type="table" target="#tab_1">I</ref>. WaveShrink is the universal thresholding scheme proposed by Donoho <ref type="bibr" target="#b0">[1]</ref>. SureShrink is an optimized hybrid scale dependent thresholding scheme based on SURE risk <ref type="bibr" target="#b1">[2]</ref>. ADPSURE represents the proposed adaptive denoise method using</p><p>The initial value of the adaptive method is selected as Convergence criterion for our optimal threshold selection is For comparison, the numerical optimal solutions under risk (2) are also calculated for universal and scale-dependent wavelet shrinkage schemes. SOPT0 represents the numerical optimal scale-dependent threshold selection using standard soft-thresholding function SOPT1 represents the numerical optimal scale-dependent threshold selection using the proposed soft-thresholding function</p><p>As can be seen in Table <ref type="table" target="#tab_1">I</ref>, the optimal solutions using the proposed new thresholding function (SOPT1) are better than the optimal solutions using the standard soft-thresholding function (SOPT0). Note that in Table I that the ADPSURE method performs better for all functions and the results of the ADPSURE method are very close to the optimal solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In this work, a new class of nonlinear thresholding functions was presented. Unlike the standard soft-thresholding function, these functions have continuous derivatives. Since the new thresholding functions perform similar operations to the standard thresholding function, similar smoothness property of the estimate using the new thresholding functions can be expected. The significance of the new thresholding functions is that they make it possible to search for optimal thresholds using gradient-based adaptive algorithms. Based on SURE risk, an adaptive wavelet shrinkage method has been presented. The numerical results show that the proposed method performs better than the conventional wavelet shrinkage method. It can also be seen that the optimal solution using the new thresholding function is better than the standard soft-thresholding function for the given examples. The new thresholding functions can also be used for other shrinkage methods, such as undecimated wavelet shrinkage methods in <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Furthermore, the adaptive wavelet shrinkage method using new thresholding functions can be used in real-time adaptive signal processing <ref type="bibr" target="#b10">[11]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Different thresholding functions s (x; t); 1 (x; t) and 3 (x; t):</figDesc><graphic coords="2,44.04,59.58,249.12,215.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Several numerical examples are given.</figDesc><table><row><cell>Manuscript received December 2, 1997. This work was supported in part</cell></row><row><cell>by the National Aeronautics and Space Administration under Grant NAG10-</cell></row><row><cell>0155 and Texas Advanced Research Program under Grant ARP 002-1996.</cell></row><row><cell>The authors are with the Division of Engineering, University of Texas at</cell></row><row><cell>San Antonio, San Antonio, TX 78249 USA (e-mail: desai@runner.utsa.edu).</cell></row><row><cell>Publisher Item Identifier S 1070-9908(98)07565-8.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I MSE</head><label>I</label><figDesc>RISK FOR DIFFERENT DENOISING SCHEMES</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>1070-9908/98$10.00 Â© 1998 IEEE</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">De-noising by soft-thresholding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="613" to="627" />
			<date type="published" when="1995-05">May 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adapting to unknown smoothness via wavelet shrinkage</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="1200" to="1224" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Translation-invariant de-noising</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Coifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<editor>Wavelets and Statistics, A. Antoniadis</editor>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Statistics, Stanford Univ.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wavelet shrinkage by cross-validation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Nason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="463" to="479" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding WaveShrink: Variance and bias estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Noise reduction using an undecimated discrete wavelet transform</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Odegard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Burrus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="10" to="12" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Estimation of the mean of a multivariate normal distribution</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1135" to="1151" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast algorithms for discrete and continuous wavelet transforms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Rioul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duhamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="569" to="586" />
			<date type="published" when="1992-03">Mar. 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neural Networks: A Comprehensive Foundation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Ten Lectures on Wavelets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Nonlinear adaptive noise suppression based on wavelet transform</title>
		<author>
			<persName><forename type="first">X.-P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Desai</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted for publication</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
