<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-02-28">28 Feb 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>zhang-jing@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaokang</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Zhang-Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijun</forename><surname>Yao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zeyao</forename><surname>Ma</surname></persName>
							<email>mazeyao@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiqi</forename><surname>Xu</surname></persName>
							<email>xuyiqi@ruc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haohua</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaohan</forename><surname>Zhang</surname></persName>
							<email>xiaohan.zhang@aminer.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Zhipu.AI</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nianyi</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sunrui</forename><surname>Lu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
							<email>juanzi@tsinghua.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaokang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">https</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaohan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Zhipu.AI</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-02-28">28 Feb 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2302.14401v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-01-03T09:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dialogue System</term>
					<term>Dialogue Evaluation</term>
					<term>Large Language Model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters capable of knowledge-grounded conversation in Chinese using a search engine to access the Internet knowledge. GLM-Dialog offers a series of applicable techniques for exploiting various external knowledge including both helpful and noisy knowledge, enabling the creation of robust knowledge-grounded dialogue LLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we also propose a novel evaluation method to allow humans to converse with multiple deployed bots simultaneously and compare their performance implicitly instead of explicitly rating using multidimensional metrics. Comprehensive evaluations from automatic to human perspective demonstrate the advantages of GLM-Dialog comparing with existing open source Chinese dialogue models. We release both the model checkpoint and source code, and also deploy it as a WeChat application to interact with users 1 . We offer our evaluation platform online 2 in an effort to prompt the development of open source models and reliable dialogue evaluation systems. The additional easy-to-use toolkit that consists of short text entity linking, query generation, and helpful knowledge classification is also released to enable diverse applications. All the source code is available on Github 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Computing methodologies ? Discourse, dialogue and pragmatics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A single conversation with a wise man across a table is better than ten years mere study of books. The impressive performance of a series of recent English dialogue systems such as Google's LaMDA <ref type="bibr" target="#b22">[23]</ref>, Microsoft's GODEL <ref type="bibr" target="#b16">[17]</ref> and Meta AI's Blenderbot 3 <ref type="bibr" target="#b21">[22]</ref> show the bright prospect of grounding the large-scale language models (LLMs) with external knowledge <ref type="bibr" target="#b34">[35]</ref>, also known as knowledgegrounded dialogue. Empowered by such technical architecture, these dialogue systems are able to generate more faithful and informative responses, thereby supporting services in a wide range of applications, such as Educational Assistance <ref type="bibr" target="#b0">[1]</ref>, Medical Diagnosis <ref type="bibr" target="#b35">[36]</ref> and Role-playing Games <ref type="bibr" target="#b20">[21]</ref>.</p><p>Despite the prosperity of the research direction, it is still struggling for contributors in other language communities to develop robust and applicable knowledge-grounded dialogue LLMs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13]</ref> due to the following primary challenges:</p><p>? Limited Scale of High-quality Datasets. As the external knowledge is heterogeneous to the pre-training corpus, directly injecting external knowledge into the conversation may cause severe hallucinations <ref type="bibr" target="#b11">[12]</ref>. To achieve better performance, current efforts usually employ dozens of public datasets during various stages of fine-tuning <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22]</ref>. However, few non-English languages have such an ample accumulation of high-quality knowledge-grounded dialogue datasets as opposed to raw social media dialogue data to support such kind of solutions.</p><p>? Diverse Exploitation of External Knowledge. Except for the typical scenario where the retrieved knowledge is determined to explicitly benefit the generation <ref type="bibr" target="#b31">[32]</ref>, there are more complex ways to exploit knowledge in real-world conversations <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. We demonstrate these various exploitation ways in Figure <ref type="figure" target="#fig_0">1</ref>, where an example of a 3-turn conversation between a human and a bot about the science fiction "The Three Body Problem" is shown. In contrast to the second turn where the helpful knowledge is injected to implicitly benefit the response (i.e., the response is taken from the knowledge and processed further rather than being purely extracted), the first turn is more chatty and doesn't need the knowledge to be infused about the explanation "Hello", while the third turn requires knowledge about "The Hugo Award" rather than "Victor Hugo". The first and third knowledge is noisy, which might cause the responses to deviate from the user's intention. Since it is not so applicable to decide whether knowledge is needed and since noisy knowledge is unavoidable, an elaborate way to exploit knowledge is worthwhile to investigate. Present Work. We release GLM-Dialog-an open-source, knowledgegrounded dialogue model in Chinese. GLM-Dialog provides an open platform for researchers with empirical insight to overcome the aforementioned challenges that prevent the development of the appropriate LLM services in non-English languages. It is obtained by fine-tuning GLM10B <ref type="bibr" target="#b6">[7]</ref>, an open-source, pre-trained Chinese LLM with 10B parameter. We devise a series of data augmentation and model training strategies for taking advantage of external knowledge under the constraints of the insufficient knowledgegrounded dataset. To be more precise, we augment the knowledge for the knowledge-missing dialogue dataset in order to overcome the dataset limitation. We equip the LLM with an auxiliary classification loss to jointly generate the response and decide whether to use the external knowledge. We also bootstrap the knowledgeaugmented training instances in an iterative way.</p><p>We conduct comprehensive evaluations of the created GLM-Dialog ranging from automatic to human evaluations: <ref type="bibr" target="#b0">(1)</ref> We update an existing benchmark by adding more ellipses, coreferences, and question types, so that it can cover a wider range of knowledgerelated conversation forms. <ref type="bibr" target="#b1">(2)</ref> We create 50 chit-chat and 100 knowledge-grounded opening utterances encompassing a wide range of topics and question types to inspire self-chat and humanbot dialogues for in-depth human evaluation. (3) Most importantly, we publish an open and online evaluation platform so that humans can simultaneously converse with the multiple bots deployed in the platform and implicitly compare them without using the typical heavy rating system. Thanks to such central conversation and implicit rating, this evaluation is simpler than the conventional explicit human rating using multidimensional metrics, which reduces conversation bias and improves evaluation fairness. We hope this platform can encourage more efforts to open source models and participate in building reliable dialogue evaluation systems. Impact and Beneficial Groups. For research of knowledge-grounded dialogue systems, our contributions include: (1) a series of applicable techniques and guidance for developing robust dialogue LLMs with limited datasets; (2) a novel evaluation platform for comparing the dialogue models in real-world applications.</p><p>We believe that GLM-Dialog preserves a more positive impact on the industrial developers in Chinese, as we contribute: (3) a large-scale, open-source dialogue model for building downstream dialogue service and (4) an easy-to-use toolkit that consists of tools such as short text entity linking, query generation, helpful knowledge classification, as well as an online service on WeChat platform for supporting convenient usage and experience.</p><p>In the following sections, we briefly review the trend of knowledgegrounded dialogue in Section 2, and then introduce the detailed implementation of our GLM-Dialog in Section 3. After introducing the evaluation protocol (Section 4), we present a comprehensive experimental report of the model performance (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES 2.1 Background</head><p>Grounding the dialogue with external knowledge has been a goal for generations of researchers <ref type="bibr" target="#b25">[26]</ref>, but until Ghazvininejad et al. <ref type="bibr" target="#b7">[8]</ref> formally proposed the task of knowledge-grounded dialogue, it was not standardized enough to be fully explored. Since then, a series of benchmarks has been proposed, which take into account various kinds of knowledge (such as persona <ref type="bibr" target="#b32">[33]</ref>, commonsense <ref type="bibr" target="#b28">[29]</ref>, facts <ref type="bibr" target="#b4">[5]</ref>) to enhance and evaluate the models. Despite some early attempts using small models, in the new era of LLM, it was swiftly occupied by the techniques of combining the large models and abundant external knowledge <ref type="bibr" target="#b29">[30]</ref>. As dialogue service has a giant potential market, the top AI corporations propose their own knowledge-grounded dialogue models respectively <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>, which enables English-speaking developers to conveniently build robust chatbots for various applications. Except for the excellent capacity of LLMs, it is worth noting that the accumulation of such a wealth of high-quality datasets is essential for the current performance of these models.</p><p>However, for the developers in other language communities, it is hard to follow up this promising trend. Even for the second largest language-Chinese-the amount and quality of labeled datasets are not so competitive enough to build and open source a knowledgegrounded dialogue LLM. Some other pioneer efforts, such as CDial-GPT <ref type="bibr" target="#b24">[25]</ref>, EVA2.0 <ref type="bibr" target="#b8">[9]</ref>, PLATO-XL <ref type="bibr" target="#b1">[2]</ref>, only attempt to build LLM for general open-domain dialogue, while few knowledge-grounded </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??</head><p>The Three-Body Problem ???????????"????"? ???????? Liu Cixin's "The Three-Body Problem" has gained notoriety after winning the science fiction "Nobel Prize", aka the Hugo Award.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preparation Model Training Model Deployment</head><p>Figure <ref type="figure">2</ref>: The overview framework of GLM-Dialog. First, we prepare a large-scale Chinese dialogue-related training corpus, a pre-trained GLM 10B branch, and a query generation model. Second, we perform a continual dialogue pre-training and knowledge-infused fine-tuning. Third, we deploy GLM-Dialog as an online service on a single GLM10B.</p><p>dialogue models are not publicly available due to commercial reasons <ref type="bibr" target="#b2">[3]</ref>. Therefore, it is crucial and urgent to share empirical findings and implementation examples to call for more contributors in building such models upon limited high-quality datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task Formulation</head><p>Definition 2.1. Dialogue History is a set of conversational utterances between two speakers, formally denoted as D ? = {? 1 , ? 1 , ..., ? ? -1 , ? ? -1 , ? ? }, where ? ? and ? ? are sentences made of words, belonging to the user and the dialogue system respectively. Especially, ? ? from the user is also called the ?-th round User Utterance. Definition 2.2. External Knowledge Pool contains multiple pieces of information associated with the dialogue topics in the system, which is denoted as K = {? ? } ? ?=1 , where ? ? is a piece of knowledge information and ? is the pool size. We employ the texts from all the Internet as the knowledge pieces. To obtain the knowledge, we need an external search engine ?(?), which retrieves ? relevant documents relevant to the given Web Query ? ? . Problem 1. Knowledge-grounded Dialogue Generation task: Given the dialogue history D ? , the target of task is to first generate an appropriately web query ? ? for search engine ?(?), obtain external knowledge from K, and then generate a response ? ? for the ?-th round user utterance ? ? based on the history and background knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACH</head><p>The design and implementation of GLM-Dialog aim to mitigate the aforementioned technical challenges from three different aspects. The overall framework is shown in Figure <ref type="figure">2</ref>.</p><p>(1) Preparation. Facing the limited high-quality knowledgegrounded dialogue corpora in Chinese, we collect large-scale Chinese dialogue training corpora from multiple sources with different purposes, which are publicly available. We also compare among language models and prepare the backbone language model to undertake the knowledge-grounded dialogue task. Lastly, we prepare a query generation module, which is used to search for dialoguerelevant knowledge from the Internet.</p><p>(2) Model Training. Facing the complex situation on exploiting external knowledge during dialogue response generation, we propose a two-stage training strategy-large-scale dialogue pretraining and delicate knowledge-intensive tuning <ref type="bibr" target="#b2">[3]</ref>. We inject dialogue response generation skill and knowledge infusion skill into GLM-Dialog progressively from the previously prepared training corpora, achieving a robust, knowledge-grounded dialogue model. Moreover, we propose several solutions to the challenges raising from the training stages correspondingly, including catastrophic forgetting <ref type="bibr" target="#b13">[14]</ref> and noise discrimination <ref type="bibr" target="#b36">[37]</ref>.</p><p>(3) Model Deployment. We deploy GLM-Dialog as an efficient dialogue service on a single GLM10B with both query generation and response generation functions. The final presented system includes not only an online dialogue service but also a toolkit for convenient personalization adaption, which makes our model easyto-use for developers and researchers with diverse needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preparation</head><p>We prepare corpora that facilitates the training for blended skills. Then, we prepare backbone language model that is suitable for diverse training objectives. Finally, we prepare query generation module to retrieve knowledge snippets from the search engine.</p><p>Corpora Preparation. The training corpora consists of three parts from different sources with special purposes. We show data statistics in Table <ref type="table" target="#tab_6">6</ref> of Appendix 7.1. In particular, social media data are conversations happening in the comment section of online platforms. They can be obtained through blog websites (e.g., Weibo), video sharing platform (e.g., Bilibili), discussion communities (e.g., Zhihu), etc. We use social media data to train GLM-Dialog to generate fluent Chinese dialogue responses from massive social media conversations. Benchmark data are converted into dialogue form from open-sourced benchmark dataset for different tasks, such as knowledge-grounded dialogue task and question answering (including reading comprehension) task. These benchmarks usually come with supplemented knowledge snippets, which we use as the knowledge context. The dialogue benchmark datasets are used to close the discrepancy between social media conversation and natural dialogue that is potentially inherited from the social media data. The overall benchmark data is used to train GLM-Dialog to read the knowledge context and generate knowledgeable responses accordingly. Online service data are continually collected from our deployed online chatbot platform with XDAI <ref type="bibr" target="#b29">[30]</ref> from Sept 1st, 2022 to Dec 15th, 2022. They are 800k real-world dialogues happening between users and dialogue services, which are used to further train GLM-Dialog by automatically injecting Wikipedia knowledge to generate more natural and knowledge-grounded responses. Backbone Preparation. We take GLM, which completes the input sentence from the special token [sMASK], as our backbone to design both the query generation and dialogue generation model. The main advantages of GLM are two folds. First, GLM implements both bidirectional attention mechanism and unidirectional attention mechanism for the context and the generated content, respectively 4 . The flexible attention mechanism allows both to classify input sentences with bidirectional attention and auto-regressively generate sentences with unidirectional attention. Second, GLM provides a consistent model architecture and an open-sourced checkpoint for various model scales, allowing for the deploying GLM-Dialog on different computing devices. Query Generation Module Preparation. The query generation module takes dialogue history as input and generates an appropriate search query, which is passed to an online search engine for retrieving dialogue-relevant knowledge snippets. In particular, we prepare the query generation module by maximizing the probability of the ground-truth query ? ? associated with the dialogue history D ? in DuSinc <ref type="bibr" target="#b37">[38]</ref>. We use a prompt ? ? to control the model to generate queries. ? ? is defined as</p><formula xml:id="formula_0">"???? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? . ? ??????[sMask] (dialogue: ? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? . need to search [sMask]</formula><p>)" where [sMask] denotes the query to be generated. This is achieved by optimizing the following objective: max</p><formula xml:id="formula_1">? GLM |? ? | ?? ?=1 log GLM ? ?,? |? ?,? &lt;? , D ? , ? ? .<label>(1)</label></formula><p>We obtain external knowledge pool K = ?(? ? ) by executing the query on the web search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Training</head><p>Basically, we leverage previously prepared corpora towards training the knowledge-grounded dialogue model. However, as these corpora differ in both the perspective of skills that are highlighted and the format that they are presented, it is difficult to directly mingle 4 Also known as "causal with prefix attention" in some other literatures <ref type="bibr" target="#b17">[18]</ref>. There exists a natural discrepancy in the style of languages between spoken languages frequently used in dialogue and web-crawled text from general domain <ref type="bibr" target="#b9">[10]</ref>. Inspired by recent dialogue language models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref>, we observe that social media data, as a special kind of web-crawled text, serves as a bridge for the language style gap due to the following two reasons. (1) Social media data constitutes a portion of the pre-training data for GLM, making GLM easy to adapt to the newly introduced training data. <ref type="bibr" target="#b1">(2)</ref> The language style of social media shares many characteristics with natural dialogue (e.g., multi-turn, concise). The final training corpora include our collected social media data.</p><p>In particular, we compile the conversation based on the responses and timing information. Each social media conversation is presented in dialogue format with dialogue history D ? and response ? ? . The training objective is defined by maximizing the probability of generating ? ? given the dialogue history D ? as input: max</p><formula xml:id="formula_2">? GLM |? ? | ?? ?=1 log GLM ? ?,? |? ?,? &lt;? , D ? , ? ? ,<label>(2)</label></formula><p>where ? ? is the prompt for controlling the response generation. ? ? is defined as</p><formula xml:id="formula_3">"???? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? , [sMask] (dialogue: ? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? , [sMask]</formula><p>)" where [sMask] denotes the response to be generated. As GLM implements hybrid attention mechanisms, we apply bidirectional attention to the dialogue history and the prompt, and unidirectional attention to the response.</p><p>To avoid the notorious catastrophic forgetting problem <ref type="bibr" target="#b13">[14]</ref>, we propose to continue the pre-training task of GLM with original pre-training corpora as a side task in the first training stage. We follow Du et al. <ref type="bibr" target="#b6">[7]</ref> to corrupt the input sentence x ? x corrupt and urge GLM to generate a span s that can fill in the corruption and optimize the following training objective: max</p><formula xml:id="formula_4">? GLM |s| ?? ?=1 log GLM(? ? |x corrupt , ? ? &lt;? ).<label>(3)</label></formula><p>Training Stage 2: Knowledge Infused Fine-tuning. To build a knowledge-grounded dialogue model, we supplement the input with context related background knowledge snippets to aid the model to generate more informative response. However, it is challenging to directly leverage the supplemented snippets and build the knowledge-grounded dialogue model. First, it is not easy to determine whether the knowledge is required because chitchat is usually blended with information-seeking conversation. Second, it is extremely difficult to locate the helpful background knowledge from the open domain environment.</p><p>The response generation model is required to identify and discard the noisy background knowledge and use the helpful knowledge on demands when generating the response. Thus, training stage 2 requires to <ref type="bibr" target="#b0">(1)</ref>  We first convert each training instance from benchmark datasets and online service into 4 parts: ? = {D ? , ? ? , K ? , L ? }. L ? are the knowledge labels associated with the external knowledge pool K ? . For ? ? ? L ? , we label ? ? = 1 if ? ? ? K ? is considered useful in generating the response ? ? . If ? ? is not useful (i.e., irrelevant to the dialogue context or even incorrect), we set ? ? = 0. In particular, we set ? ? = 1 for the knowledge snippets in knowledge-grounded dialogue benchmarks. For question answering benchmarks, we take the provided document ? as the corresponding knowledge and set its label as 1. Finally, for dialogue corpus collected from our online service, we design a data augmentation strategy to extract knowledge snippets. We perform entity linking over dialogue history D ? with HOSMEL <ref type="bibr" target="#b33">[34]</ref> and excerpt corresponding entity descriptions from Wikipedia as the external knowledge pool.</p><p>We inject negative knowledge snippets into the external knowledge pool of all the training instances. Their knowledge labels are set to 0 accordingly. Similar to the data augmentation process, we perform entity linking with HOSMEL on the training instances but identify entities with low confidence, whose entity descriptions are used as the negative knowledge samples.</p><p>The training objective of GLM-Dialog consists of two parts. The main training objective aims to maximize the probability of generating the desired response given the dialogue history concatenated with the external knowledge pool as input:</p><formula xml:id="formula_5">loss main = |? ? | ?? ?=1 log GLM ? ?,? |? ?,? &lt;? , K ? , D ? , ? ?? ,<label>(4)</label></formula><p>where ? ?? is the prompt to control the knowledge infused response generation. ? ?? is defined as</p><formula xml:id="formula_6">"? ? ?? 1 , ? 2 , ? ? ? , ? ? . ? ??? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? , [sMask] (background: ? 1 , ? 2 , ? ? ? , ? ? dialogue: ? 1 , ? 1 , ? ? ? , ? ? -1 , ? ? -1 , ? ? , [sMask]</formula><p>)". GLM-Dialog applies the bidirectional attention to D ? , K ? , and ? ?? , based on which we apply an extra multi-layer perceptron (MLP) to the hidden representation of the [CLS] token to predict the knowledge labels of input knowledge snippets. The MLP layer serves as an ?-way binary knowledge classifier, where ? denotes the size of the knowledge pool K ? . The auxiliary loss is thus defined as the binary cross entropy loss between the predictions and the ground truth:</p><formula xml:id="formula_7">loss aux = ? ?? ?=1 ? ? ? log MLP GLM (K ? , D ? ) [CLS] ? .<label>(5)</label></formula><p>The training objective of stage 2 is defined as: max loss main + ?loss aux , where ? is a hyper-parameter. We empirically set ? = 1.</p><p>To further enlarge the training corpora for knowledge infusion, we design an iterative training scheme to collect dialogue data from the interaction between GLM-Dialog and human users. In particular, we deploy GLM-Dialog in an online environment to converse with human users. The external knowledge pool is constructed from the web search results, where the query is generated by the prepared query generation module. Dialogue histories associated with external knowledge are preserved if they have high scores from the knowledge classifier. Finally, we manually inspect the preserved dialogue histories and annotate high-quality corpus for training. The training and intermediate deployment of GLM-Dialog are executed iteratively to obtain more fine-tuning data. We perform such bootstrap training once in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Deployment</head><p>GLM-Dialog is deployed with three components-the query generation module, the external search engine, and the response generation module. A typical workflow for generating the ? th response ? ? starts from users posed utterance, denoted as ? ? . The ? th dialogue history is D ? = D ? -1 ? {? ? -1 , ? ? }. GLM-Dialog first generates the web search query with the query generation module:</p><formula xml:id="formula_8">? ?,? = arg max GLM ? ?,? |? ?,? &lt;? , D ? , ? ? .<label>(6)</label></formula><p>The GLM-Dialog constructs the external knowledge pool K = ?(? ? ) from the web search engine and only keeps the top searching results (a.k.a., the external knowledge pool size is set to ? = 1). Multiple search results could be filtered by additional models, which is left for future improvement. The final response is generated based on the dialogue history and the supplemented knowledge:</p><formula xml:id="formula_9">? ?,? = arg max GLM ? ?,? |? ?,? &lt;? , K ? , D ? , ? ?? .<label>(7)</label></formula><p>It is worth noting that, both the query generation in Eq. 6 and the response generation in Eq. 7 are undertaken by a single backbone language model after training. GLM-Dialog uses different prompts to instruct the language model to behave accordingly. This deployment strategy relieves the hardware requirement to host multiple language models. Moreover, the workflow of GLM-Dialog computes exactly 2 times of inference for query and response generation. We release the model checkpoint and the implemented code for the researchers of interest to continue the dialogue LLM investigation. We also encapsulate the modules including query generation, entity linking, and knowledge classification as toolkits for developers to easily deploy diverse dialogue applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION METHODS</head><p>We perform a comprehensive evaluation in both automatic and human evaluation. For better evaluation, we create a new benchmark DuSincR upon the current DuSinc benchmark <ref type="bibr" target="#b37">[38]</ref> by supplementing 50 diverse chit-chat, 100 knowledge-grounded opening utterances, and a novel implicit human evaluation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Automatic evaluation</head><p>Automatic evaluation is entirely automated and requires no human involvement. Specifically, given any ? -1 continuous utterances from a dialogue benchmark, the ?-th utterance is produced by a dialogue model and is evaluated by a number of pre-defined metrics. Specifically, we use Bleu-4, F1, Rouge-L, Rouge-1, Rouge-2, and Bert-Score to measure how similar it is to the labeled response <ref type="bibr" target="#b38">[39]</ref>. We describe the definition of these metrics in Appendix 7.3. We carry out the automatic evaluation on DuSincR, which is built on top of DuSinc <ref type="bibr" target="#b37">[38]</ref> to incorporate more comprehensive forms of queries as well as increase sentence ellipses and coreferences. DuSincR-an enhanced knowledge-grounded dialogue benchmark. Knowledge-based human conversations present a significant challenge to the dialogue system because they contain a variety of questions about entities, attributes, and logic as well as many sentence ellipses and coreferences. However, these kinds of utterances are rarely included in the existing dialogue benchmarks. By revising the test set of DuSinc <ref type="bibr" target="#b37">[38]</ref>, an existing knowledge-grounded dialogue benchmark in Chinese with high quality, we maintain the consistency and informativeness of dialogues and save more manpower while improving the evaluating ability on sentence ellipses, coreferences, and various types of questions. Each DuSinc discourse is broken up into a number of QA pairs. Annotators can select one of the pairs to modify or add a new pair to ensure the question involves ellipses, coreferences, or is a pre-defined type. Additionally, they need to respond to the question by conducting an online search. <ref type="bibr">Appendix</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Explicit Human Evaluation</head><p>The outcomes of bot-bot communication are evaluated by human. To be more precise, we permit a dialogue model to converse with itself given an opening utterance. We create 50 chit-chat opening utterances that contain positive, negative, and neutral statements. Furthermore, we construct 100 knowledge-grounded opening utterances that cover topics related to entertainment, life, history and culture, education, health, sports, science and technology, and finance. The questions can also be categorized into the same types used to create DuSinc. The above 50+100 chitchat and knowledgegrounded utterances are presented in Appendix 7.4 and 7.5.</p><p>We hire three annotators to score the dialogues in terms of coherence, informativeness, safety, inspiration, hallucination in utterance-level, and engagingness and faithfulness in session-level, from 50 self-chat chit-chat dialogues to 100 knowledge-grounded dialogues produced by each dialogue model. As the final scores, the three annotators' averages are used. We provide the definition of these metrics in Appendix 7.6.</p><p>We also allow humans to access the outcomes of human-bot communication. To be more specific, we employ three annotators and allow each of them to communicate with each dialogue model in order to produce 50 chit-chat dialogues and 100 knowledgegrounded dialogues using the above same opening utterances. Then, we hire three more annotators to evaluate these chat conversations between humans and bots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implicit Human Evaluation</head><p>The automatic evaluation cannot faithfully reflect the quality of the dialogues. The human evaluation measures are more widely used; however, bias between different annotators on the results of different bots affects human evaluation. Therefore, we provide a Three deployed anonymous bots react to the human user after he sends a message. Their replies are displayed after shuffling. The user is then free to choose one of the responses to carry on the conversation. The dialogue history at each turn for all the bots is unified. A bot is deemed superior to others if its responses are chosen more frequently.</p><p>simpler human evaluation strategy that enables a human to centrally converse with several dialogue models at once and implicitly compare these bots during the conversation process. We provide details on the evaluation tool and implementation. Evaluation Tool Design. The platform will offer responses from all the deployed bots whenever a human delivers a message. The decision to proceed with one of the responses is made by humans, and in our method, this is regarded as the implicit evaluation. A bot is considered to have superior performance if its responses are chosen from other bots more frequently. We maintain the same dialogue history for all the bots at each turn in order to compare their responses fairly. To make this possible, we record each turn's message from the annotator and its selected response in the dialogue history. It's worth noting that the name of the bot is not disclosed to users and the order of messages will be shuffled before being displayed on the platform in order to prevent potential annotation bias. Figure <ref type="figure" target="#fig_4">3</ref> illustrates the idea of the proposed tool. This tool is also deployed online <ref type="foot" target="#foot_0">5</ref> to encourage more efforts to open source their models and take part in reliable dialogue evaluation. A screenshot of the tool is shown in Figure <ref type="figure" target="#fig_10">6</ref> in Appendix 7.7.</p><p>Evaluation Implementation We employ 20 annotators to use our designed evaluation tool in order to lessen the preference bias of various annotators. Each annotator is free to initiate a dialogue on his or her own or using the platform's recommendations. By clicking the "topic tips" button, the platform can recommend the opening utterances, which are drawn at random from the dialogue benchmarks DuConv <ref type="bibr" target="#b26">[27]</ref>, DuSinc <ref type="bibr" target="#b37">[38]</ref>, and Diamante <ref type="bibr" target="#b15">[16]</ref> since these dialogue benchmarks contain dialogues on a variety of topics. The annotators are required to discourse on the subject of the opening utterance and deliver a message of 10 words on average, free of sensitive, retaliatory, and disrespectful terms. The annotators may use the "close" button to stop the current conversation.</p><p>Only dialogues lasting more than five turns are regarded as useful information. The total number of response selections by users determines each bot's rating. We can click the "Ranking List" button to examine all of the involved bots' evaluation results.</p><p>Advantages. The proposed implicit human evaluation has two main advantages:</p><p>? Central conversation. In contrast to discussions that are dispersed across multiple bots, we chat with all the bots centrally and maintain the same conversation history between turns, which not only speeds up dialogue collection and lowers the cost of hiring annotators, but also lowers conversation bias and improves evaluation fairness. ? Implicit rating. We consider the choice of the response to be the implicit evaluation, which is simpler than the explicit rating using multidimensional metrics as the conventional human evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>We evaluate the proposed GLM-Dialog and the comparison models via the methods introduced in Section 4 to demonstrate the advantages of GLM-Dialog. We also perform various ablation studies to verify the effectiveness of different components in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison Methods.</head><p>We compare GLM-Dialog with the following well-known dialogue models in Chinese:</p><p>? CDial-GPT <ref type="bibr" target="#b24">[25]</ref> is a GPT model with 104M parameters trained on LCCC, a 12M Chinese dialogue sessions, where a session denotes multiple continuous turns of utterances. ? EVA2.0 <ref type="bibr" target="#b9">[10]</ref> is a transformer-based bidirectional encoder and a unidirectional decoder with 2.8B parameters trained on 0.4B Chinese dialogue sessions. ? PLATO-2 <ref type="bibr" target="#b1">[2]</ref> is a PrefixLM <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19]</ref>, i.e., a unified transformer with 11B parameters trained on 1.2B (context, response) samples.</p><p>Although both EVA and PLATO have released updated versions, they do not share their models or source codes. As a result, they cannot be compared. Since our model is a pre-trained GLM model <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b30">31]</ref> with 10B parameters that is fine-tuned on Chinese dialoguerelated dataset, we also compare with the corresponding GLM10B and GLM130B models <ref type="foot" target="#foot_1">6</ref> with 10B and 130B parameters respectively, but without any fine-tuning on the dialogue dataset. We select the 10B model as the backbone considering the training and deployment cost. For training GLM-Dialog, we set the learning rate as 5 ? 10 -5 with a cosine learning rate decay. The batch size is set as 256 and the maximal input length is set to 512. We perform the two-stage training on an 8?80G A100 server. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>Automatic Evaluation Results. Table <ref type="table" target="#tab_1">1</ref> present the automatic evaluation results on DuSincR, which demonstrate that GLM-Dialog outperforms the baselines on most of the automatic metrics.</p><p>Human-evaluation Results. Table <ref type="table" target="#tab_2">2</ref> presents the human evaluation results for self-chat dialogues centered around 50 chit-chat and 100 knowledge-grounded opening utterances respectively. For this evaluation, the dialogues are automatically generated by bots via chatting with itself, while the ratings are provided by human annotators from both the utterance-level and session-level. Because GLM130B always repeats its own words when speaking to itself, the results are ignored. Table <ref type="table" target="#tab_3">3</ref> presents the human evaluation results for human-bot dialogues centered around the same 50 chit-chat and 100 knowledge-grounded opening utterances respectively. For this evaluation, both the dialogues and the ratings must be provided by humans.</p><p>The findings from these two tables show that, of all the comparison models, the proposed GLM-Dialog performs the best in terms of the majority of the metrics. Particularly, GLM-Dialog consistently outperforms other models in terms of informativeness because, in contrast to other models, we inject external knowledge from the search engine, which can help generate more informative responses. By doing this, the informative response has a greater chance of inspiring the subsequent question, and as a result, our model consistently has the highest inspiration score.</p><p>Although the responses are very insightful and inspiring and the dialogue as a whole is very appealing (having the highest faithfulness and engagement scores), we still need to lessen the model's hallucination. We speculate that the knowledge introduced might not be sufficiently pertinent to the ongoing conversation, which might harm the responses' factual correctness, although the model has already made an effort to exploit any kind of knowledge well. We present an analysis of the generated queries and search results in Section 5.4. Implicit Human Evaluation Results. Figure <ref type="figure" target="#fig_6">4</ref>(a) presents the results gathered by the proposed implicit human evaluation method in Section 4.3. In total, 10,000 selections are produced by the 20 hired annotators. The annotators need to choose a response from the six deployed models to continue the conversation. Each time a response is chosen, a score is accumulated for the model which produces the response. We rank the models according to their results. The highest score is achieved by our model, which suggests that it can produce more appealing responses than the comparison models. The annotation bias can be effectively reduced by this evaluation  method since it collects ratings implicitly through a selecting action, which is easier than explicit rating using multidimensional metrics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Studies of Response Generation</head><p>We conduct ablation tests on response generation to confirm the impact of injected external knowledge and knowledge classification, where the four major model variants include:</p><p>? w/o stage-2 training. We only keep training stage 1 on social media data, but delete training stage 2. The knowledge injection is also excluded during inference. We conduct the human evaluation on 100 randomly selected conversations from DuSincR. To be more specific, we use each model variant to re-generate the last utterance based on the dialogue history and evaluate the generation by the same utterance-level metrics. We add knowledgeability <ref type="bibr" target="#b2">[3]</ref>, an additional utterance-level metric, to evaluate whether the utterance contains factual information that can be verified by the injected knowledge. The definition is given in Table <ref type="table" target="#tab_15">19</ref>.</p><p>Table <ref type="table" target="#tab_4">4</ref> shows the effects of different components for knowledge injection, which reveals that (1) without the 2nd training on the knowledge-grounded conversations, the model is unable to combine the injected background knowledge with the dialogue history, resulting in significant drops in all the metrics; (2) The amount of the knowledge-grounded benchmarks is extremely limited as compared with the online gathered dialogue. Thus, without injecting knowledge into the online large-scale service data, the knowledge integration ability mainly relies on the knowledge-grounded benchmarks, which affect the final performance; (3) Even if we introduce knowledge into online service data, there is much noisy knowledge that is irrelevant to the response, which could have an adverse influence on response production. The performance declines as a result of the knowledge classification being removed; (4) Without using the classifier to repeatedly sort helpful knowledge, the performance is also worse than GLM-Dialog. We also compare with the following two model variants to confirm the advantage of the proposed knowledge integration way.</p><p>? GLM10B with knowledge prompting. We inject the same external knowledge as the proposed GLM-Dialog as the prompts on GLM10B without any fine-tuning on dialogue datasets. ? Pre-classifier. We maintain the same training stages 1 and 2 and add external knowledge to the online service data. We train a classifier based on the human-annotated knowledge snippet of each dialogue in DuSinc and then use it to determine whether the knowledge is needed or not before injecting knowledge. The query and search processes are the same with GLM-Dialog.</p><p>The comparison with different knowledge integration ways yields the results in Table <ref type="table" target="#tab_4">4</ref>, which reveal that (1) Even though the same knowledge is injected into GLM10B as prompts, the performance is poorer than the proposed GLM-Dialog, which demonstrates the advantages of fine-tuning; (2) Pre-classifier decreases the performance compared with the proposed GLM-Dialog. The pre-classifier discards some knowledge-seeking before injection. On the contrary, GLM-Dialog injects knowledge into any dialogue. Its capacity to classify knowledge at the moment of response generation enables such complete injection, which is more suited to the real-world situation when chit-chat conversation and knowledgegrounded conversation are frequently blended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Studies of Query Generation</head><p>We first create a model variant "w/o query generation" by removing the query generation step but directly using the user-posted utterance to search information snippets from the Internet. The human evaluation results of the variant are shown in Table <ref type="table" target="#tab_4">4</ref>. The results demonstrate that without the generated query, the performance drops significantly, because the ellipses, coreferences, and long utterances cannot serve as a good query for search engines.</p><p>To directly demonstrate the usefulness of the generated queries, we compute the similarities between the created queries and the human-annotated actual queries on DuSinc by the cosine similarity of their embeddings produced by sentence-BERT <ref type="bibr" target="#b3">[4]</ref>. The frequency histogram of the query similarity scores on 9,353 test cases of DuSinc is displayed in the upper part of Figure <ref type="figure" target="#fig_6">4</ref>(b). The created queries are of good quality, as shown by the mean score of 0.85. We determine the similarities between the retrieved knowledge snippets and the human-annotated knowledge snippets provided in DuSinc test cases using the same query similarity computing method. The frequency histogram of these knowledge similarity scores on 9,353 test cases is displayed in the right part of Figure <ref type="figure" target="#fig_6">4(b)</ref>. The mean score of 0.86 indicates that the retrieved knowledge is of high quality. It is also shown from the figure that query quality is positively correlated with knowledge quality. More examples of query generation and search results are shown in Appendix 7.8 and 7.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Online Statistics</head><p>User Involvement. We deploy GLM-Dialog as a WeChat official account named "AI?????/??? (AI XDAI likes chatting / knowledge XDAI)" to enable both one-one and group conversations with it and other bots. From January 12th, 2023 to February 1st, 2023, over 100 users have created 34 single chats and 63 group chats, resulting in 837 dialogue sessions in total, with an average of 50 utterances per session and an average of 22 tokens per utterance. Efficiency. We analyze the online time cost of GLM-Dialog by comparing the average time cost with GLM10B without knowledge injection and pre-classifier introduced in Section 5.4 on the same 100 selected conversations from DuSincR for ablation studies. Table <ref type="table" target="#tab_5">5</ref> shows the time cost of different stages, where that of the individual steps is recorded on the server side and the overall time, which also includes network latency, is recorded on the client side. Compared with GLM10B, GLM-Dialog takes an additional 1.09 and 0.92 seconds to build the query and complete the search, respectively, which can meet the needs of an online service. As opposed to pre-classifier, we do not need to classify whether the knowledge is needed beforehand, saving an average of 0.47 seconds of time. However, the pre-classifier discards the creation and search of queries if the classifier determines that the information is not needed, the average query and search time are saved, leading to modest gains in the overall time cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We present a 10B parameter LLM for knowledge-grounded dialogue generation. The model deals with the challenges of limited datasets by offering a series of augmentation and training techniques for exploiting helpful and noisy knowledge. We also develop a new human evaluation tool that allows humans to evaluate bots implicitly while interacting with them. We anticipate that the proposed techniques could inspire the researchers of interest to prompt the development of the knowledge-grounded dialogue LLM. We hope the published dataset, model, code, and evaluation tool can provide an easy-to-use and cost-effective solution for industrial developers to create various knowledge-grounded applications easily. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">APPENDIX 7.1 Training Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">DuSincR</head><p>Ellipses and Coreferences. Table <ref type="table">7</ref> shows examples of ellipses and coreferences in utterances. Question Types. Table <ref type="table">8</ref> shows examples for eight types of questions, including asking entities (what, who), asking attributes (when, where), count, comparison, select among, verify, how, and why. Figure <ref type="figure" target="#fig_8">5</ref> shows the distribution of question types in DuSincR. Annotation Way. Table <ref type="table" target="#tab_12">9</ref> presents a dialogue example to illustrate how to add new utterances into the original dialogue of DuSinc with the above question types or ellipses and coreferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Automatic Evaluation Metrics</head><p>We provide the following explanations for each automatic metric.</p><p>? BLEU-N BLEU is used to evaluate the precision of the generated text comparing with the reference text. BLEU-N combines the values of BLEU for different n-grams, i.e.,</p><formula xml:id="formula_10">???? -? = ?? ? exp ? ?? ?=1 ? ? ? log ? ? ,<label>(8)</label></formula><formula xml:id="formula_11">?? = 1, ?? &gt; ?? exp 1-?? ?? , ?? ? ?? ,<label>(9)</label></formula><formula xml:id="formula_12">? ? = #{????????? ????????? ?-????} #{????????? ?-????} ,<label>(10)</label></formula><p>where ? ? is the precision of n-gram, i.e., the percentage of the predicted n-grams that are found in the reference text. The term ? ? refers to the weight of n-gram, which is typically specified to be uniform weight, i.e., ? ? = 1 ? for any ?. ?? is the penalty factor. ?? is less than 1 if the predicted length ?? is less than the reference length ?? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? F1</head><p>The F1 score can be regarded as a harmonic average of accuracy and recall, with a maximum value of 1 and a minimum value of 0.</p><formula xml:id="formula_13">? 1 = 2 ? ? 1 ? ? 1 ? 1 + ? 1 ,<label>(11)</label></formula><p>where ? 1 and ? 1 denote the precision and recall of the correctly predicted 1-gram respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? Rouge-x</head><p>Rouge prioritizes recall over accuracy. It counts how many n-grams from the reference text are present in the generated text. Rouge-n is defined as:</p><formula xml:id="formula_14">?????-? = #{????????? ????????? ?-????} #{?-???? ?? ?? ? ?????? ???? }<label>(12)</label></formula><p>ROUGE-L computes the rouge value of the longest common subsequence (LCS) between the generated text and the reference text. We denote LCS as ?. ROUGE-L is computed as follows:</p><formula xml:id="formula_15">?????-? = (1 + ? 2 )? ??? ? ??? ? ??? + ? 2 ? ??? ,<label>(13)</label></formula><formula xml:id="formula_16">? ??? = #{1-???? ?? ?} #{1-???? ?? ????????? ???? } , (<label>14</label></formula><formula xml:id="formula_17">)</formula><formula xml:id="formula_18">? ??? = #{1-???? ?? ?} #{1-???? ?? ?? ? ?????? ???? } , (<label>15</label></formula><formula xml:id="formula_19">)</formula><p>where ? is a weighting coefficient and ? ??? and ? ??? stand for the precision and recall of ?, respectively. Rouge-L will focus more on recall rate rather than accuracy rate if ? is greater. Here, ? is set to 1.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? Bert-Score</head><p>Bert-score is used to calculate the similarity between the generated text and the reference text. To be more precise, it generates a similarity matrix by first computing the inner product between each word in the two texts based on the BERT embeddings. Then, using this matrix, it computes the precision and recall by averaging the maximal similarity scores of the reference and generated texts weighted by word idf value. In the end, we combine them to report F1 of Bert-Score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Chit-chat Opening Utterances</head><p>We present the designed 50 chit-chat opening utterances with 25 positive, 12 negative, and 13 neutral statements in Table <ref type="table" target="#tab_13">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Knowledge-grounded Opening Utterances</head><p>We present the designed 100 knowledge-grounded opening utterances in Table <ref type="table" target="#tab_1">11</ref>. These utterances involve 14 topics related to entertainment, 14 topics related to life, 12 topics related to history and culture, 10 topics related to education, 12 topics related to health, 12 topics related to sports, 13 topics related to science and technology, and 13 topics related to finance. Additionally, they can be broken into the types of "what", "who", "where", "when", "how", "why", "compare", "count", and "verify".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Human Evaluation Metrics</head><p>In Table <ref type="table" target="#tab_15">19</ref>, we define each human evaluation metric's values and their accompanying meanings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">Implicit Human Evaluation Tool</head><p>Figure <ref type="figure" target="#fig_10">6</ref> shows the screenshot of our online implicit human evaluation tool.  KDConv <ref type="bibr" target="#b38">[39]</ref> Knowledge-grounded 4.5K DuConv <ref type="bibr" target="#b26">[27]</ref> Knowledge-grounded 20K NaturalConv <ref type="bibr" target="#b23">[24]</ref> Knowledge-grounded 20K DuSinc <ref type="bibr" target="#b37">[38]</ref> Knowledge-grounded 8K WebQA <ref type="bibr" target="#b14">[15]</ref> Question answering 42K Dureader <ref type="bibr" target="#b10">[11]</ref> Question answering 200K DRCD <ref type="bibr" target="#b19">[20]</ref> Question answering 30K Online Service Data XDAI <ref type="bibr" target="#b29">[30]</ref> from Sept 1st, 2022 to Dec 15th, 2022 800K Examples of Different Score Ranges on DuSinc. Table <ref type="table" target="#tab_16">20</ref> to Table <ref type="table" target="#tab_20">24</ref> present 3 examples for each similarity score range tested on DuSinc. Each example includes the dialogue history (with the most recent user-posted utterance), the ground-truth query, and the produced query. The similarity score is computed between the produced query and the ground-truth query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.8">Query Generation Examples</head><p>Examples of Coreference Dialogues on DuSinc. Table <ref type="table" target="#tab_21">25</ref> presents example queries generated from dialogues which consist of coreference on DuSinc. The coreference is referenced in the dialogue as a "underline" (and is always in the most recent user-posted utterance); a similarity score is provided at the end of each example.</p><p>Examples of Ellipsis Dialogues on DuSinc. Table <ref type="table" target="#tab_22">26</ref> presents example queries generated from dialogues which consist of ellipsis on DuSinc. The sentence containing ellipsis is referenced in the dialogue (which is always in the most recent user-posted utterance); a similarity score is provided at the end of each example.</p><p>Examples of Complete Query Dialogues on DuSinc. Table <ref type="table" target="#tab_23">27</ref> presents example queries generated from dialogues which consist of a complete query on DuSinc. The complete query is referenced in the dialogue (which is always in the most recent user-posted utterance); a similarity score is provided at the end of each example.</p><p>Examples of 8 Different Question Types on DuSincR. Table 28 to Table <ref type="table" target="#tab_31">35</ref> present 3 examples for each question type tested on DuSincR, which contains ellipsis or coreference in every test case. Each example includes the dialogue history (with the most recent user-posted utterance) and the produced query. The ellipsis or coreference is referenced in the dialogue (which is always in the most recent user-posted utterance).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.9">Search Result Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.10">Case Studies</head><p>Table <ref type="table" target="#tab_40">41</ref> shows four examples of generated responses given the noisy knowledge snippet being injected.     -The response contains significant logical inconsistencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>-Small conflicts between the response and the context.</p><p>-The response contains slight logical inconsistencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The response is coherent with the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score Informativeness</head><p>0 -There is no information in the response.</p><p>-This response only restates the context without adding any new information.</p><p>-The coherence score is zero, hence the information is invalid.</p><p>1 -The information in the response is in disagreement with common sense.</p><p>-The response contains factual mistakes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The response contains pertinent and accurate information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score Safety</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>-The response includes negative, slanted, or deceptive information.</p><p>-The coherence score is 0, hence the safety is invalid.</p><p>1 -There is a chance that the response will offend or unnerve some people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The response is safe.</p><p>Score Inspiration 0 -The response doesn't inspire the next question the user can ask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">-</head><p>The response inspires a topic or related content, and questions can be raised based on the content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The response inspires users to immediately ask the next question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score Hallucination</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">-</head><p>The response is accurate in its facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>-The response contains some factually erroneous information.</p><p>-Since the coherence and informativeness ratings are all zero, the response is invalid.</p><p>Score Engagingness 0 -The user do not have the willing to talk with this speaker.</p><p>1 -It's still ok for the user to talk with this speaker though it is somewhat dull.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The user wants to have a lengthy conversation with this speaker.</p><p>Score Faithfulness 0 -The user does not believe the chatbot's reply at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>-The user partially trusts the chatbot's reply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-</head><p>The user trusts the chatbot's reply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Score Knowledgeability</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0</head><p>-There is not much information in the response, which is uninteresting and general.</p><p>-This response contains personalized information that cannot be verified by the injected knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>-The response includes factual information that can be verified by the injected knowledge.  </p><formula xml:id="formula_20">???????????????????????????????????????? ???????????????????????????????????????? ????????????????????????????</formula><p>Well, in addition to understanding current events, you should also read more, read in a planned way, and read some books about philosophy, sociology, and history, which can often lead you to the answers of many questions. Reporters are news writers. Only by accumulating more and raising awareness can the things written stand the test, and can your news be objective and true. ????????????????????????????? Wow, I have been taught. From now on, I will gradually accumulate my knowledge. What else?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Being a reporter</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????? ???????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What qualities should a journalist possess</head><p>These examples, which only make up 0.5% of the entire 9,353 examples and have scores in the range of 0.5 to 0.6, have a high ability to generate queries despite their low score. The reason why these 0.5% scores low, is mainly due to the differences between the ground-truth queries provided in DuSinc and the queries generated from our model, instead of the incorrectness of the query generated. The differences include (1) the ground-truth query provided in DuSinc gives an answer to the most recent user-posted utterance directly, while our model generates the query according to the context of the dialogue, as shown in the 1st example above (2) the query generated by our model is more specific than the ground-truth query provided, containing more information from the dialogue, as shown in the 2nd and 3rd example above.   </p><formula xml:id="formula_21">????????????????????????????????????? ????????????????????????????????????? ??????????</formula><p>Avocado is not only delicious, but also rich in vitamins and unsaturated fat, which can resist aging and prevent cardiovascular disease. It also contains oleic acid. Oleic acid is a very valuable vegetable oil, which can help improve dry and irritated hair and help restore the hair to its moist state. ???????????????????(coreference)??????? So many benefits that I want to buy some myself to eat. Isn't this (coreference) very expensive.  The benefits of anaerobic exercise to the body are that it can increase muscle strength, improve cardiopulmonary function, and prevent diseases of cardiopulmonary system system and respiratory system.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????????????????????????????????????????????? ??????????</head><p>Ha ha, then this will be the first time. When two people are together, the comfort is particularly important. So go to some places with good environment and beautiful scenery. Make sure you two are in good mood at all times! ?????? Mm-hmm. Yes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Where are you going? ???????</head><p>We haven't decided yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????????????</head><p>Try Xi'an, it's a world famous historical and cultural city. Go and play! ???????????????(coreference)??????????(when or where question type)</p><p>It is a very famous city. Do you know any interesting places in it (coreference)? (when or where question type)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interesting landmarks in Xi'an</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????????????</head><p>You've got good taste. I have seen it too. I think he is very humorous and interesting. ?????????????????????? Yes, I think he speaks interestingly and his singing is very ethereal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????????????????????????????????????????</head><p>I have heard his songs, such as Big Fish, Irrelevant, Blooming Flowers, The Shape of Water, If You Love Me, and so on. I knew him by listening to his Big Fish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I've heard all of what you've said. ????????????????????????????????????????????????????? ?????</head><p>Yes, and I have to tell you, Zhou Shen's Big Fish is very good, and it is definitely a classic moment that cannot be forgotten. Such an ethereal and pure voice is really rare. It's rare to hear it even in a hundred years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????????????????????????</head><p>Right, I was attracted by this ethereal voice, and I also think he treats people very well. ?????????????????????????????????????????????????? Yes, he is very modest and gentle when dealing with people and things. I have obtained a lot of positive energy from him, which can be reflected in many details on him.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????????(coreference)???????(count question type)</head><p>Yes, and he is also very smart. Do you know how many languages he (coreference) can speak? (count question type)  Dialogue History Generated Query ??????????? Can fake eyelashes harm people? ????????????????????? Using glue can easily cause eye irritation, so be careful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How many languages Zhou Shen knows</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????????????</head><p>Well, it seems better to get eyelash extension. ?????????? Yes. I also plan to go.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???(coreference)??????????? (comparison question type)</head><p>What's the difference between this one (coreference) and sticking fake eyelashes? (comparison question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????</head><p>The difference between eyelash extension and fake eyelashes ????????????????????????????? Well, besides Huangshan, do you know any other places suitable for taking pictures of sunrise and sunset? ??????????????????? Mount Tai is also very good. Yuhuangding is a good shooting location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????(coreference)???????????(comparison question type)</head><p>Speaking of Mount Tai, do you know which is higher, it (coreference) or Mount Huang? (comparison question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????</head><p>Which is higher, Mount Tai or Mount Huang ?????????? I'm going shopping, and buying some fruit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????????????????</head><p>Go buy Yantai apples, red Fuji with sweet and crisp pulp. ??????????????????????????? I have to get some apples, but I also plan to buy other fruits, maybe some bananas. ???????????????????????????????? It's good to eat more bananas, which can supplement energy, moisten intestines and relieve constipation, help sleep and prevent hypertension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ah, bananas can prevent hypertension?</head><p>????????????????????????????????????????????????????? ???????????????????????????????????????????? Yes, bananas are rich in potassium ions, which can antagonize the contraction of blood vessels by sodium ions. Eating bananas regularly helps to maintain the balance of sodium, potassium and acid-base in the body, in order to maintain the normal neuromuscular function and the coordination of myocardial contraction, thus preventing and treating hypertension. Surely widening your horizon, right? Ha ha! ?????????????? Indeed, I didn't expect bananas to have this effect. ???????????????????????????????????????????????? However, pay special attention to the difference between raw bananas and ripe bananas. Ripe bananas can relieve constipation, but raw bananas stop diarrhea, so eating too much can cause constipation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????(coreference)??????????????(comparison question type)</head><p>Oh, which nutritional value do you think is higher, them (coreference) or apples? (comparison question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????? ??</head><p>Which is more nutritious, banana or apple </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue History</head><p>Generated Query ???????????????????????? I think everyone has a green vine in the office. Green vines must have many advantages.</p><formula xml:id="formula_22">????????????????????????????????????????????????????? ??????????????</formula><p>Yeah, the shining green gives a good mood. In addition to beautifying the environment, green vine can also reduce pressure and purify the air. It can absorb formaldehyde in the air and so on. It is suitable for a newly decorated house to have a green vine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????????????????????????</head><p>No wonder there are green vines in offices, homes and business districts. The green vine seems easy to look after.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????????????????</head><p>Well, it's easy to look after. Doesn't need much sunshine. Just water it regularly. ??????????????????????????????? It's good. If I'm busy at ordinary times, I don't have much time to take care of it. I have a strong ability of self-reliance, which is suitable for me. ??????????????????? Yes, it will bring you a lot of happiness and good luck.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue History</head><p>Generated Query ???????????????????? I just bought a sugar cane and it turned out not to be sweet at all and too tough to bite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????</head><p>Ah, really, the one I bought the day before yesterday was quite good. ??????????????????(coreference)??(how question type) </p><formula xml:id="formula_23">????????????????????????????????????????????????????? ???????????????????????????????????????</formula><p>Newbies who raises a dog sure have to prepare a lot of things, such as food basin, kennel, dog food, pet toilet, pet dry-cleaning powder, small toys, and traction rope. Besides these things, you should also consider whether you have a long-term persistence psychology before you can adopt a dog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????????(coreference)??(how question type)</head><p>If I go for a long trip, how can I arrange them (coreference)? (how question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????</head><p>What to do with the dog when going for a long trip ?????????????????????????????????? I often have a stomachache. My colleague suggested that I go to have a gastroscopy examination. But is the gastroscopy very uncomfortable?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????????????????????????????????????????????? ????????????????????????????????????????????????</head><p>There are many kinds of gastroscopy. You can consider the painless external gastrointestinal imaging scanner, which uses the principle of ultrasound to examine without pain. Or you can also consider capsule endoscopy, swallowing it is equivalent to swallowing a miniature camera. It will take pictures to check your stomach and intestines, and there will be no discomfort. ???????????????????????????????????????????? It doesn't sound so terrible. Is it possible that I have H.pylori? More than one friend of mine has this disease. ???????????????????????????????????? Besides a stomachache, check if you have these symptoms, including acid reflux, heartburn, bad breath, nausea, vomiting, etc. ????????????????????????????? I really do, I have acid reflux and heartburn. Can H.pylori infection be eradicated? ????????????????????????????????????????????????????? ?? It can be eradicated, but it should be treated as soon as possible. H.pylori infection is related to the incidence of gastric cancer. Early treatment can prevent gastric cancer, or else the best treatment opportunity will be missed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??(coreference)?????????(how question type)</head><p>How to treat this (coreference) infection? (how question type) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????? ???</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Treatment of H.pylori infection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dialogue History</head><p>Generated Query ??????????????????????????????? Why can people be allergic? I'm really fed up with this kind of body that sneezes crazily every spring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????????????????????????????????????????????????????? ???????????????</head><p>You mean allergic rhinitis. This is because the immune system produces excessive immune protein, which leads to over-sensitivity to some substances, and the body reacts. Generally, it is due to the result of the joint action of genes and environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????????????????</head><p>Ah, if it's a genetic problem, isn't it very rare to cure? It's so annoying. ?????????????????????????????????????????? Hereditary allergy cannot be eradicated at present, but your kind is usually not very serious. Be sure to avoid allergens when the season comes. ????????????????????????(coreference)???????(why question type) That's the only way. If you are not careful enough, you will be suffering. Why this (coreference) attacks less frequent in recent years? (why question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????? ???</head><p>Why does the incidence rate of allergic rhinitis decrease ????????????????????????????????? So adoption is a good choice, but where can I find the kitten waiting to be adopted? ????????????????????????????????????????????????????? ???????????? You can go to the Zhangzhou Small Animal Science Conservation and Rescue Center, which is a reliable non-governmental organization providing free rescue and adoption services. I hope you can find the kitten that you are destined for there. ??????????????(coreference)????(why question type)</p><p>By the way, why should they (coreference) be sterilized for adoption? (why question type)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????</head><p>Why should pet cats be sterilized ??????????????????? I'm not feeling well recently, which leads to irregular menstruation.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????</head><p>The Great Wall of Qin Shihuang</p><formula xml:id="formula_24">?????????????????????????? ?????????????????????????? ?????????????????????????? ?????????????????????????? ?????????????????????????? ????????????????????????</formula><p>The Great Wall was not built by Qin Shihuang. Qin Shihuang just mentioned the Great Wall by connecting them together. The first thing we thought of was Qin Shihuang. Qin Shihuang built the Great Wall, which is one of his many achievements, which everyone agrees with. However, in fact, this is not the case. Although Emperor Qin Shihuang has many achievements and is known as the Emperor for ever, he did not build the Great Wall. Qin Shihuang just connected the Great Wall together by the way. These things are already there.  </p><formula xml:id="formula_25">? ? ? ( ? ? ? ? ? ? ? ) ? ? ? ? ? ? ? ? ( ? ?<label>?214?</label></formula><formula xml:id="formula_26">????????4?????????????????? ?????????????????????????"? ???"??????????????????</formula><p>Jiangsu Shangfangshan National Forest Park is located in the Stone Lake Scenic Spot of the National Taihu Lake Scenic Spot, 4 kilometers away from the center of Suzhou. It is a natural park that is famous for the relics of Wu and Yue and the idyllic scenery of Jiangnan Watertown. With picturesque landscapes and scenic spots, it is known as the "Wuzhong Scenic Spot" and is a bright pearl in the Taihu Lake Scenic Spot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????(??AAA???)????????</head><formula xml:id="formula_27">????????????????????????? ?4????????????????????????? ??????????????????"????"??? ???????????????1992?7???????? ????????</formula><p>Shangfangshan National Forest Park (National AAA Scenic Spot): Suzhou Shangfangshan National Forest Park is located in the Stone Lake Scenic Spot of the National Taihu Lake Scenic Spot, which is 4 kilometers away from the center of Suzhou. It is a natural park that is famous for the relics of Wu and Yue and the idyllic scenery of Jiangnan Watertown. With picturesque landscapes and scenic spots, it is known as the "Wuzhong Scenic Spot" and is a bright pearl in the Taihu Lake Scenic Spot. In July 1992, it was approved as a national forest park by the Ministry of Forestry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>????</head><p>The Wandering Earth</p><formula xml:id="formula_28">??????(???The Wandering Earth)?????? ?????????????????????????? ?????????????????????????? ????????????????????2019?2?5? ????????????????????????? ?????2075?????????????????? ???????????????"????"????? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?2021?10?17? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??</formula><p>The Wandering Earth (English: The Wandering Earth) is a sci-fi disaster film jointly produced by China Film Co., Ltd., Beijing Jingxi Culture and Tourism Co., Ltd., directed by Guo Fan, and starred by Qu Chuxiao, Zhao Jinmai, Li Guangjie, Wu Mengda, etc., with Wu Jing specially starring. The film was released in mainland China on February 5, 2019. The film is based on Liu Cixin's novel of the same name, and the story background is set in 2075. It tells the story that the sun is about to be destroyed and is no longer suitable for human survival. In the face of desperate circumstances, human beings will start the "wandering earth" plan, trying to escape the solar system with the earth and find a new home for human beings. As of October 17, 2021, "Wandering Earth" ranked fifth in the box office list of Chinese film history.</p><formula xml:id="formula_29">????: ??????? ????? ????????? ?????????????????????????? ????????????????????????? ?????????????2075?????????? ???????????????????????"??? ?"????????????????????????? ??????2019?2?5?????????</formula><p>The Wandering Earth: type: film director: Guo Fan Profile: Wandering Earth is a sci-fi adventure film directed by Guo Fan, starring Qu Chuxiao, Zhao Jinmai, Li Guangjie, Wu Mengda and other actors. The film is based on Liu Cixin's novel of the same name, and the story background is set in 2075. It tells the story that the sun is about to be destroyed and is no longer suitable for human survival. In the face of desperate circumstances, human beings will start the "wandering earth" plan, trying to escape the solar system with the earth and find a new home for human beings. The film was released in mainland China on February 5, 2019.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>??????????</head><formula xml:id="formula_30">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? (Temperate oceanic monsoon climate)?????????????? ?????????????????????????? ?????????????????????????? ?????????????????????????? ?????????????????????????</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????,?????????????</head><p>Now that King of Glory has been revamped, it takes less than half an hour to play a game. ?,?????????????? Oh, then I probably haven't played it for too long.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????????????????</head><p>You know which company is behind of King of Glory? ?????,?????? The company is Tencent, Tianmei Studio. ?,?????????????????,????????? Oh, so that's the company behind. How much money can the game make? ?????????????_????:? ?????????????????? ???????????????=1550.7? ?*2.97%*235?=1.08?,????????? ??394.2?? King of Glory can earn how much money a year_BaiduQA:King of Glory became the first mobile game in history to break 10 billion dollars in revenue. For the game, " daily flow = 15.507 million people * 2.97% * 235 = 108 million", so the King of Glory's annual revenue is 39.42 billion. </p><formula xml:id="formula_31">? ? ? ? ? ? ? ? ?394?? I heard</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of a 3-turn dialogue between a human and a bot. It is required to carefully exploit a variety of knowledge, including unnecessary, incorrect, and helpful knowledge, to produce rational responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Of course I have, the first book of series won the Hugo Award.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>them together and train the model in a single pass. Thus, we design a two-stage training scheme to progressively inject blended skills into the language model. The first stage trains GLM-Dialog to generate fluent dialogue responses from massive social media corpora. The second stage aims to teach GLM-Dialog to use supplemented external knowledge with noise tolerance. Training Stage 1: Continual Dialogue Pre-training. Although off-the-shelf LLMs show their ability in generating fluent dialogue responses<ref type="bibr" target="#b22">[23]</ref>, they are still far from building a dialogue model as the original pre-training corpora are usually web-crawled text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>construct dialogue training instances with external knowledge and negative knowledge samples; (2) design training objective with auxiliary adversarial loss to encourage the model to jointly generate the response and decide whether to use the external knowledge; (3) bootstrap training instances in an iterative training scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: An illustration of our implicit human evaluation tool. Three deployed anonymous bots react to the human user after he sends a message. Their replies are displayed after shuffling. The user is then free to choose one of the responses to carry on the conversation. The dialogue history at each turn for all the bots is unified. A bot is deemed superior to others if its responses are chosen more frequently.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Implicit human evaluation (b) Query and search similarity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) The evaluation of implicit human evaluation; (b) Frequency histogram and scatter plot on query/knowledge similarity between GLM-Dialog's produced queries/knowledge and the ground truth on DuSinc test set.</figDesc><graphic url="image-8.png" coords="8,57.03,411.20,116.01,95.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>?</head><label></label><figDesc>w/o knowledge injection. Based on "w/o stage-2 training", we add training stage 2, but do not inject any knowledge in the online service data. ? w/o knowledge classification. Based on "w/o knowledge injection", we add knowledge to the online service data, but do not classify knowledge. The knowledge is injected during inference. ? w/o iterative knowledge injection. Based on "w/o knowledge classification", we add the knowledge classification but remove the iterative knowledge injection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The distribution of question types in DuSincR.</figDesc><graphic url="image-10.png" coords="13,98.26,318.95,151.33,127.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>present 3 examples for each similarity score range tested on DuSinc. Each example includes the query used to search on web, the ground-truth web knowledge provided in DuSinc, and the web knowledge retrieved from Baidu search. The similarity score is computed between the retrieved knowledge and the ground-truth knowledge. It should be noted that the provided ground-truth query from DuSinc and the produced query are the same in the examples provided from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: An screenshot of our online implicit human evaluation tool. Users are allowed to interact with six deployed anonymous bots and evaluate their performance by selecting a single response from all their responses to continue the conversation.</figDesc><graphic url="image-11.png" coords="25,79.02,83.68,453.96,343.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>???????????????? Oily skin refers to the skin with strong secretion, oily forehead and nose, and the skin absorbs ultraviolet rays easily. ??????????(coreference)????????? Yes, my skin is like this (coreference). What should I do? ??????? What to do with oily skin ??????? What to do with oily skin 1.00</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>constellations. There are twelve constellations. ????????????9?1??????????(ellipse) I'm an Aquarius. I remember you were born on September 1. What should that be? (ellipse) going on a date this afternoon! ??????????????? Wow, congratulations, put on a beautiful makeup. ????????????????????????? Yes, but my makeup skills are not good enough, and I know little about cosmetics. ???????????????????????????? Then I can give you some suggestions for buying cosmetics, both on foundation makeup and beauty makeup. ????????????????(ellipse) I'm a dry skin. It's hard to find something suitable for me. (ellipse) ???????? Dry skin suited cosmetics ????????? Cosmetics suitable for dry skin 0.96</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>I recently learned about an actor named Dilraba. She is so beautiful! ??????????????????? I also think she is beautiful. She is from a minority ethnic group. ??????????????(coreference)???????(who or what question type) No wonder she is a little exotic. Which minority ethnic group is she (coreference) from? (who or what question type) ?????????? Which ethnic group is Dilraba from OK???????????????????????? OK, then I'll boil some for her to drink. How long does this astragalus angelica water need to be taken? ?????=1?????????????????????? Astragalus : Angelica = 1, boil for about half an hour. I'll check how long it needs to be taken, wait a moment. ???????????????????????? Ok, take your time, it doesn't matter. I've already arrived at the drugstore, and I'll go buy it first. ???????????????????????1?2??????????? OK, all right. I got it. It is not suitable for long-term drinking. Generally, it should be stopped after one to two months. ???????????(coreference)??????????(who or what question type) Ok, I see. Is there any contraindications when drinking this (coreference) water? (who or what question type) ???????? Contraindications of drinking astragalus and angelica water ?????????????????????? However, I still can't imagine what the metaverse is like. ????????????????????"??"?????????? For example, have you seen The Number One Player? The Oasis in it is actually a metaverse. ????????????????????????????????? I see. Now I understand more. I really hope that one day we can have our own metaverse! ???????????????? Yes, I'm also looking forward to that day. ????????????????????? But according to the current development level, it will probably take a long time! ??????????????????????????????? That's not necessarily true. When the technology of intelligent cloud devices is mature, the implementation of the metaverse should not be far away. ?(coreference)???????????(who or what question type) Who put forward its (coreference) concept? (who or what question type) ?????????? ? Who put forward the concept of metaverse</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>It's easy to raise! It has strong adaptability and can be propagated with leaf cuttings. ??????????????????????????? Is it? Then I will go to the market now. Do you know where they sell this kind of flower? ?????????????????????????? You can go to the flower and bird market in Wanliutang Park on the second floor of the flower market in Quanyuan 2nd Road. ???????????????????????????? But I can't buy only one kind of flower. Please recommend some flowers that are easy to grow. ??????????????????????????? You can buy some sunflowers, hydrocotyle, and longevity flowers, which are especially easy to grow. ??(coreference)??????????????(when or where question type) When does that (coreference) flower and bird market usually open? (when or where question type) ?????????? ??? Opening hours of flower and bird market in Wanliutang Park ????????????????????????? Is there anything suitable for girls to play? I think this is a little more for boys. ??????????????????? Haha! Do you know the game Sky: Children of the Light? ?????? What is this? ????????????????????????????????????????? It's a game that girls may play more. The goal is to find citizens in the game and collect candles. Is it easy, right? ??(coreference)???????????(when or where question type) When was this (coreference) game released? (when or where question type) ?????????? The release time of the game Sky: Children of the Light ??????????????? Oh my god, I'm going to go on a trip with my boyfriend! ???????? Wow, I'm so happy for you! ??????????????? Chuckle, I've never went on a trip with a boy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>?????????????????????????????????? Red roses represent passionate love, white roses represent pure love, but people usually give red ones. ????????????????????(ellipse) (count question type) Okay, I guess she would like it. How many should I give? (ellipse) (count question type) ?????????? ? How many roses are suitable to give for Valentine's Day ???????????????????????????????? I don't want to play in Anhui. What about Harbin? What's the weather like in Harbin recently? I want to go to the Ice and Snow World! ????????????????????-21??-12?????????????? Ah, it's very cold in Harbin. It's sunny recently. The temperature is between -21 degrees and -12 degrees. Go there and add more clothes! ?????????????????????????? You are so sweet. By the way, is the Ice and Snow World open recently? Don't go for nothing. ????????????????????????????????????????????? As far as I know, it is open. Generally, it is open from Christmas to early March of the next year! Now January is just the time for fun! ??(coreference)???????????(count question type) Do you know how much the tickets cost there (coreference)? (count question type) ?????????? Tickets for Harbin Ice and Snow World ???????offer3???????? I was attracted by Zhou Shen after watching The Amazing Offer 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>??(coreference)???????(verify question type) Then will it (coreference) bloom? (verify question type) ?????? Can green vines bloom ?????????? What game do you like to play? ??????????? I like to play Sky: Children of the Light. Do you know? ??????? What is this? ???????????????????????? Companion makes the way forward no longer lonely, which is the feature of this game. ????????????? Can you make friends in it? ????????????????????? Yes, I recommend you to play! It's a really warm game. ??(coreference)????????(verify question type) Do we need to top up money to this (coreference) game? (verify question type) ???? Top on money to Sky: Children of the Light ????????????????? I don't like cookies very much. Eating cookies are easy to dehydrate. ???????????????????? Then you can buy jelly or yogurt, which won't make you dehydrate. ?????????????????? It makes sense. I'll buy some yogurt. I haven't drunk it for a long time. ????????????????????????? I recommend you Classy Kiss yogurt, which has cream in it. It tastes very good. ??????????(coreference)????????(verify question type) I haven't drunk this yet. Is this (coreference) imported yogurt? (verify question type) ??????? Is Classy Kiss yogurt imported</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Sigh, I don't know how to choose. Do you know how to choose it (coreference)? (how question type) ?????? How to choose sugarcane ??????????????????? Having rented a single house, it's time to raise a dog. ?????????????? Indeed, having a dog is more reassuring. ????????????????? What kind of dog do you think is better for me? ????????????????????????????????????????????????????? ?????????? I think if you want to keep one to look after the house and protect you, then you can try a Chinese Pastoral Dog, a Rottweiler German Shepherd Dog or a Doberman. They have a strong sense of protection and are very smart. ?????????????????????????????? Let me go and see these three kinds. It's my first time raising dogs and I have no experience. I don't know what to prepare.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Irregular menstruation seems to be a common illness among young people nowadays. ???????????????? Oh, yes you're right. I'm going to see a traditional Chinese medicine doctor.??????????????????????The doctor may prescribe some modified Xiaoyao pills, Wuji Baifeng pills.???????????????????(coreference)????(why question type)Aha, why are many young people suffering from this (coreference) illness now? (why question type) ?????????? ? Why young people have irregular menstruation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Automatic evaluation results on DuSincR.</figDesc><table><row><cell>Model</cell><cell>Bleu-4</cell><cell>F1</cell><cell cols="4">Rouge-L Rouge-1 Rouge-2 Bert-Score</cell></row><row><cell cols="2">CDial-GPT 0.792</cell><cell>14.652</cell><cell>12.011</cell><cell>48.212</cell><cell>15.707</cell><cell>0.580</cell></row><row><cell>PLATO-2</cell><cell>1.959</cell><cell>16.967</cell><cell>15.396</cell><cell>67.397</cell><cell>24.011</cell><cell>0.607</cell></row><row><cell>EVA2.0</cell><cell>0.737</cell><cell>13.548</cell><cell>11.589</cell><cell>54.270</cell><cell>14.211</cell><cell>0.591</cell></row><row><cell>GLM10B</cell><cell>2.723</cell><cell>15.517</cell><cell>12.538</cell><cell>83.832</cell><cell>33.743</cell><cell>0.599</cell></row><row><cell>GLM130B</cell><cell>4.177</cell><cell>18.905</cell><cell>16.047</cell><cell>79.562</cell><cell>28.897</cell><cell>0.615</cell></row><row><cell cols="3">GLM-Dialog 4.190 22.010</cell><cell>19.464</cell><cell>72.471</cell><cell>28.206</cell><cell>0.630</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Human-evaluation on self-chat dialogues.</figDesc><table><row><cell></cell><cell cols="5">50 chit-chat opening utterances</cell><cell></cell><cell cols="2">100 knowledge-grounded opening utterances</cell></row><row><cell>Model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Cohe. Info.</cell><cell>Safe.</cell><cell cols="3">Insp. Hall.? Enga.</cell><cell>Fait.</cell><cell>Cohe. Info.</cell><cell>Safe.</cell><cell>Insp. Hall.? Enga.</cell><cell>Fait.</cell></row><row><cell>CDial-GPT</cell><cell cols="3">0.860 0.851 0.913 0.515</cell><cell>0.291</cell><cell cols="2">0.500 0.473</cell><cell cols="2">1.140 1.069 1.478 0.591</cell><cell>0.221</cell><cell>0.603 0.690</cell></row><row><cell>PLATO-2</cell><cell cols="6">1.455 1.438 1.448 1.129 0.062 1.260 1.220</cell><cell cols="2">1.698 1.614 1.793 1.090 0.032 1.420 1.413</cell></row><row><cell>EVA2.0</cell><cell cols="3">1.386 1.336 1.362 0.902</cell><cell>0.068</cell><cell cols="2">1.213 1.093</cell><cell cols="2">1.488 1.413 1.674 0.832</cell><cell>0.089</cell><cell>1.230 1.223</cell></row><row><cell>GLM10B</cell><cell cols="3">1.371 1.296 1.539 0.932</cell><cell>0.130</cell><cell cols="2">1.187 1.160</cell><cell cols="2">1.513 1.497 1.669 1.157</cell><cell>0.093</cell><cell>1.460 1.340</cell></row><row><cell cols="9">GLM-Dialog 1.515 1.517 1.656 1.171 0.098 1.383 1.383 1.759 1.742 1.816 1.223 0.046 1.550 1.473</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Human-evaluation on human-bot chat dialogue.</figDesc><table><row><cell></cell><cell cols="5">50 chit-chat opening utterances</cell><cell></cell><cell cols="2">100 knowledge-grounded opening utterances</cell></row><row><cell>Model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Cohe. Info.</cell><cell>Safe.</cell><cell cols="3">Insp. Hall.? Enga.</cell><cell>Fait.</cell><cell>Cohe. Info.</cell><cell>Safe.</cell><cell>Insp. Hall.? Enga.</cell><cell>Fait.</cell></row><row><cell>CDial-GPT</cell><cell cols="3">1.138 0.984 1.310 0.690</cell><cell>0.272</cell><cell cols="2">0.696 0.660</cell><cell cols="2">0.956 0.777 1.194 0.543</cell><cell>0.363</cell><cell>0.562 0.542</cell></row><row><cell>PLATO-2</cell><cell cols="6">1.725 1.610 1.741 1.239 0.068 1.392 1.316</cell><cell cols="2">1.585 1.387 1.650 1.086 0.129 1.244 1.128</cell></row><row><cell>EVA2.0</cell><cell cols="3">1.690 1.494 1.743 1.107</cell><cell>0.077</cell><cell cols="2">1.312 1.292</cell><cell cols="2">1.524 1.275 1.616 0.961</cell><cell>0.151</cell><cell>1.150 1.096</cell></row></table><note><p><p>GLM10B</p>1.439 1.436 1.513 1.249 0.164 1.236 1.208 1.543 1.528 1.570 1.329 0.174 1.324 1.282 GLM130B 1.232 1.179 1.378 1.000 0.257 0.816 0.784 1.177 1.128 1.315 0.954 0.303 0.852 0.832 GLM-Dialog 1.660 1.641 1.688 1.376 0.127 1.440 1.460 1.668 1.624 1.688 1.393 0.134 1.412 1.368</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Ablation studies by human evaluation on 100 randomly selected knowledge-grounded dialogues on DuSincR.</figDesc><table><row><cell>Model</cell><cell cols="4">Cohe. Info. Hall.? Know. Safe.</cell><cell>Insp.</cell></row><row><cell>GLM-Dialog</cell><cell cols="5">1.820 1.840 0.107 0.727 1.840 1.400</cell></row><row><cell cols="5">Effects of different components for knowledge injection</cell></row><row><cell>w/o stage-2 training</cell><cell>1.437 1.413</cell><cell>0.293</cell><cell>0.447</cell><cell cols="2">1.603 1.127</cell></row><row><cell>w/o know. injection</cell><cell>1.527 1.503</cell><cell>0.223</cell><cell>0.483</cell><cell cols="2">1.687 1.173</cell></row><row><cell>w/o know. class.</cell><cell>1.730 1.633</cell><cell>0.167</cell><cell>0.633</cell><cell cols="2">1.743 1.303</cell></row><row><cell>w/o iter. know.</cell><cell>1.757 1.770</cell><cell>0.137</cell><cell>0.660</cell><cell cols="2">1.810 1.313</cell></row><row><cell cols="5">Comparing with different knowledge integration ways</cell></row><row><cell>GLM10B w. know.</cell><cell>1.563 1.523</cell><cell>0.227</cell><cell>0.500</cell><cell cols="2">1.623 1.150</cell></row><row><cell>Pre-classifier</cell><cell>1.593 1.567</cell><cell>0.217</cell><cell>0.490</cell><cell cols="2">1.697 1.167</cell></row><row><cell cols="3">Effect of Query Generation</cell><cell></cell><cell></cell></row><row><cell>w/o query generation</cell><cell>1.637 1.593</cell><cell>0.190</cell><cell>0.523</cell><cell cols="2">1.737 1.187</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Average online time cost of different stages (second).</figDesc><table><row><cell>Model</cell><cell cols="5">Know. Class. Query Gen. Search Response Overall</cell></row><row><cell>GLM10B</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.73</cell><cell>2.25</cell></row><row><cell>Pre-classifier</cell><cell>0.47</cell><cell>0.79</cell><cell>0.68</cell><cell>1.62</cell><cell>4.17</cell></row><row><cell>GLM-Dialog</cell><cell>-</cell><cell>1.09</cell><cell>0.92</cell><cell>1.64</cell><cell>4.22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6</head><label>6</label><figDesc>presents the statistics of the datasets used for different training stages.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Training data statistics. We state the number of sessions for dialogue data and the number of QA pairs for question answering data.</figDesc><table><row><cell>Type</cell><cell>Dataset</cell><cell>Characteristic</cell><cell>Size</cell></row><row><cell></cell><cell>Weibo</cell><cell>Blog [25]</cell><cell>6.8M</cell></row><row><cell>Social</cell><cell>Bilibili</cell><cell>Video sharing</cell><cell>10K</cell></row><row><cell>Media</cell><cell>Baidu Tieba</cell><cell>Online discussion</cell><cell>300K</cell></row><row><cell>Data</cell><cell>Zhihu [28]</cell><cell>Online discussion</cell><cell>4.1M</cell></row><row><cell></cell><cell>Douban</cell><cell>Online discussion</cell><cell>280K</cell></row><row><cell>Benchmark</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Data</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 36 to</head><label>36</label><figDesc>Table 40</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 36</head><label>36</label><figDesc></figDesc><table /><note><p><p><p>to Table</p>40</p>, therefore only one search query is provided, and the web knowledge given and retrieved are comparable.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>An illustration of a dialogue session from the DuSincR dataset. A-1 to B-5 are the original DuSinc dialogue session, while A-6 and B-6 are the newly annotated utterances with sentence coreference and the comparison question type. ???????????????????????????????????????????????????? First, apply mascara to the real lashes and curl them to shape them. Then, cut off the false lashes and knead them to soften them. Then, attach the lashes to the eyelids with glue.</figDesc><table><row><cell>A Dialogue Session</cell></row><row><cell>A-1 ????????????</cell></row><row><cell>It is hard for me to apply false eyelashes.</cell></row><row><cell>B-1 A-2 ????????????</cell></row><row><cell>That's amazing. Can you do that?</cell></row><row><cell>B-2 ???????????????????</cell></row><row><cell>Actually, neither can I.</cell></row><row><cell>A-3 ??????????????????</cell></row><row><cell>I do watch a lot of videos. But I still can't do it.</cell></row><row><cell>B-3 ?????????</cell></row><row><cell>Neither do I.</cell></row><row><cell>A-4 ???????????</cell></row><row><cell>Can false eyelashes hurt people?</cell></row><row><cell>B-4 ?????????????????????</cell></row><row><cell>Using glue can easily cause eye irritation, so be careful.</cell></row><row><cell>A-5 ???????????????</cell></row><row><cell>I think it's better to apply the eyelash extension.</cell></row><row><cell>B-5 ??????????</cell></row><row><cell>Me too.</cell></row></table><note><p><p><p>The newly annotated utterances</p>A-6 ???(coreference)???????????(comparison question type)</p>What's the difference between them? B-6 ????????????????????????????????????????? Eyelash extensions may cause itchy eyes due to poor cleaning. False eyelashes look unnatural and can not be reused.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>50 chit-chat opening utterances with 25 positive, 12 negative, and 13 neutral statements. The price of gold has risen a lot in the past two days. 22. ????????????????? I just bought a jigsaw puzzle, do you want to play with me together? 23. ?????????????????? What a wonderful thing to be born into a happy family. 24. ??????????? I love the sugar and oil mixture so much. 25. ?????????? I kind of miss my college roommates.</figDesc><table><row><cell>Type</cell><cell>Utterance</cell><cell>Translated Utterance</cell></row><row><cell></cell><cell>01. ?????????</cell><cell>What is your favorite singer?</cell></row><row><cell></cell><cell>02. ????????????????</cell><cell>My uncle raised a kitten. It's so cute.</cell></row><row><cell></cell><cell>03. ????????????</cell><cell>I hope to travel after the epidemic!</cell></row><row><cell></cell><cell>04. ?????????????</cell><cell>Have you had any highlight moments in your life?</cell></row><row><cell></cell><cell>05. ?????????????</cell><cell>I've been running recently and I've made great progress!</cell></row><row><cell></cell><cell>06. ????????????</cell><cell>What would your ideal partner be like?</cell></row><row><cell></cell><cell>07. ??????????????</cell><cell>It's sunny today, and I'd like to go out and play.</cell></row><row><cell></cell><cell>08. ????????????</cell><cell>The drool chicken in the old canteen tastes good.</cell></row><row><cell></cell><cell>09. ?????????</cell><cell>What should I do if I want to fall in love?</cell></row><row><cell></cell><cell>10. ????????????</cell><cell>I really want to go to the music festival.</cell></row><row><cell></cell><cell>11. ??????????????</cell><cell>I just bought vitamins with medical insurance and it was so cheap.</cell></row><row><cell></cell><cell>12. ??????????????</cell><cell>I like exercise most, how about you?</cell></row><row><cell>Positive</cell><cell>13. ?????????</cell><cell>Do you usually play musical instruments?</cell></row><row><cell></cell><cell>14. ????????</cell><cell>I love watch short videos.</cell></row><row><cell></cell><cell>15. ?????????????</cell><cell>Summer is coming and I need to lose weight.</cell></row><row><cell></cell><cell>16. ??????????????</cell><cell>There are many people enjoying flowers in the park now.</cell></row><row><cell></cell><cell>17. ???????????</cell><cell>The birds outside are singing nicely.</cell></row><row><cell></cell><cell>18. ???????????????</cell><cell>Spring is coming, and there are so many beautiful flowers outside.</cell></row><row><cell></cell><cell>19. ??????????</cell><cell>What variety shows do you like?</cell></row><row><cell></cell><cell>20. ?????????</cell><cell>I found myself handsome these days.</cell></row><row><cell></cell><cell>21. ???????????</cell><cell></cell></row><row><cell></cell><cell>26. ?????????</cell><cell>Have you studied astrology?</cell></row><row><cell></cell><cell>27. ??????</cell><cell>Can you cook?</cell></row><row><cell></cell><cell>28. ???????</cell><cell>Are you going to the supermarket?</cell></row><row><cell></cell><cell>29. ???????</cell><cell>I want to learn a musical instrument.</cell></row><row><cell></cell><cell>30. ??????????????</cell><cell>May I ask how do you manage your money?</cell></row><row><cell></cell><cell>31. ???????????</cell><cell>Many trees have been planted in the community this year.</cell></row><row><cell>Neural</cell><cell>32. ??????????? 33. ??????????????????</cell><cell>Are you going home this summer vacation? Have you heard the word moderation a lot in your life?</cell></row><row><cell></cell><cell>34. ?????????</cell><cell>How are you feeling today?</cell></row><row><cell></cell><cell>35. ??????????????</cell><cell>How can I make my roommates pay attention to hygiene??</cell></row><row><cell></cell><cell>??????????????</cell><cell>without embarrassment or damaging the relationship with them?</cell></row><row><cell></cell><cell>36. ??????????</cell><cell>Do you listen to some music before bed?</cell></row><row><cell></cell><cell>37. ?????????????</cell><cell>What social software do you usually use?</cell></row><row><cell></cell><cell>38. ???????</cell><cell>Have you ever dyed your hair?</cell></row><row><cell></cell><cell>39. ?????????????</cell><cell>I was so speechless by my roommate's behavior recently??</cell></row><row><cell></cell><cell>?????????</cell><cell>that I really wanted to change dorms.</cell></row><row><cell></cell><cell>40. ?????????????????</cell><cell>What if you can't realize your dreams in life?</cell></row><row><cell></cell><cell>41. ??????</cell><cell>It's so hard to make money!</cell></row><row><cell></cell><cell>42. ???????????????</cell><cell>I failed the postgraduate entrance examination,??</cell></row><row><cell></cell><cell></cell><cell>and I have to prepare to find a job.</cell></row><row><cell></cell><cell>43. ????????</cell><cell>It's hard to use my phone recently.</cell></row><row><cell>Negative</cell><cell>44. ??????????????????</cell><cell>Baby snacks, adding the word baby will double the price.</cell></row><row><cell></cell><cell>45. ?????????????</cell><cell>I have enough time recently and want to learn something,??</cell></row><row><cell></cell><cell>???????</cell><cell>but I have no idea.</cell></row><row><cell></cell><cell>46. ????????</cell><cell>I had a nightmare last night.</cell></row><row><cell></cell><cell>47. ?????????????</cell><cell>Listen to me, you have to be cautious about employment.</cell></row><row><cell></cell><cell>48. ????????4??????</cell><cell>No matter what time you go to sleep, ??</cell></row><row><cell></cell><cell></cell><cell>what should you do if you wake up at 4 o'clock?</cell></row><row><cell></cell><cell>49. ?????????????</cell><cell>I feel like I'm procrastinating so badly!</cell></row><row><cell></cell><cell>50. ?????????????</cell><cell>I really can't appreciate the current fashion.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Knowledge-grounded utterances of life.</figDesc><table><row><cell>Question Type</cell><cell>Utterance</cell></row><row><cell></cell><cell>15. ???????????????????????????????</cell></row><row><cell>What</cell><cell>Do you know about the Sanlu milk powder incident?</cell></row><row><cell></cell><cell>It's a nightmare for many parenting mothers!</cell></row><row><cell></cell><cell>16. ?????????????????????</cell></row><row><cell></cell><cell>Uniqlo's design is quiet good. Which country's brand is this?</cell></row><row><cell>Where</cell><cell>17. ????????????????</cell></row><row><cell></cell><cell>Autumn in Beijing is so beautiful. Where can I go to enjoy the red leaves?</cell></row><row><cell>When</cell><cell>18. ???????????????????</cell></row><row><cell></cell><cell>Recently, I have been greedy for crabs. Do you know what is the best time to to eat crabs?</cell></row><row><cell></cell><cell>19. ???????????????</cell></row><row><cell></cell><cell>Dental floss is popular now, do you know how to use it?</cell></row><row><cell></cell><cell>20. ????????????????????????????????????</cell></row><row><cell>How</cell><cell>I want to become a psychological counselor in the future, but I don't know</cell></row><row><cell></cell><cell>what preparations I can make now, do I need to take any other certificates?</cell></row><row><cell></cell><cell>21. ???????????????????</cell></row><row><cell></cell><cell>I bought a piece of raw beef today, what should I do?</cell></row><row><cell></cell><cell>22. ????????????????????????????????</cell></row><row><cell>Why</cell><cell>When I was young, my mother always made me cassia chrysanthemum tea,</cell></row><row><cell></cell><cell>but now my eyesight is still so poor, why?</cell></row></table><note><p>SelectAmong 23. ????????????????????????????????? I am obsessed with high-rise buildings recently. Do you know which are the top ten buildings in the world and what country do they belong to? 24. ??????????????????????????????? I like to visit places of interest, do you know which city has the most places of interest in China? 25. ????????????????? I am about to graduate, which city is better to develop? Comparision 26. ?????????????????????????? Where do you want to live in the future? Compared with Beijing and Shenzhen, which city do you like more? 27. ?????????????? Who is stronger in animation industry, Japan or China? Verify 28. ???????????????????? There are so many advertisements for SK2, is it really effective?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 19 :</head><label>19</label><figDesc>Human evaluation metrics.</figDesc><table><row><cell>Score</cell><cell>Coherence</cell></row><row><cell>-The response is not relevant to the context.</cell><cell></cell></row><row><cell>-The response only restates the context.</cell><cell></cell></row><row><cell>0</cell><cell></cell></row><row><cell>-The response clearly clashes with the context.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 20 :</head><label>20</label><figDesc>Query generation examples with score range 0.5-0.6 on DuSinc, account for 0.5% of the total dataset.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell></row><row><cell></cell><cell></cell><cell>???????hu?n?</cell></row><row><cell>????????hu?n??????????hu?n?????</cell><cell>??</cell><cell>????</cell></row><row><cell>I saw The Legend of Zhen Huan the other day. Is there a real Zhen Huan in history?</cell><cell>Noble Consort Xi</cell><cell>Is there a real Zhen Huan</cell></row><row><cell></cell><cell></cell><cell>in history?</cell></row><row><cell>??????????</cell><cell></cell><cell></cell></row><row><cell>Hi, can you chat with me?</cell><cell></cell><cell></cell></row><row><cell>??????????</cell><cell>???? Methods to reduce pres-</cell><cell>???????? How to reduce pressure</cell></row><row><cell>Sure, what do you want to talk about?</cell><cell></cell><cell></cell></row><row><cell></cell><cell>sure</cell><cell>when having a bad mood</cell></row><row><cell>?????????????????????</cell><cell></cell><cell></cell></row><row><cell>I'm in a bad mood recently. Do you know any methods to reduce pressure?</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 21 :</head><label>21</label><figDesc>Query generation examples with score range 0.6-0.7 on DuSinc, account for 6.3% of the total dataset.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell></row><row><cell>???????????????????????????????????????</cell><cell></cell><cell></cell></row><row><cell>??</cell><cell></cell><cell></cell></row><row><cell>Yes, our Chinese team is the world top in table tennis. Ma Long, Zhang Jike and Fan Zhendong are all</cell><cell>????</cell><cell>??????</cell></row><row><cell>world famous players.</cell><cell>Xu Xin's records</cell><cell>How good is Xu Xin?</cell></row><row><cell>?????</cell><cell></cell><cell></cell></row><row><cell>And Xu Xin!</cell><cell></cell><cell></cell></row><row><cell>???????1688???????????????????</cell><cell></cell><cell></cell></row><row><cell>Then buy tissues. It's very cheap to buy them on 1688 Wholesale Network and Pinduoduo Wholesale</cell><cell></cell><cell></cell></row><row><cell>Network.</cell><cell></cell><cell></cell></row><row><cell>?????????????????</cell><cell>??????????</cell><cell></cell></row><row><cell>It happened that Pinduoduo was downloaded on my mobile phone. I'll go and take a look.</cell><cell>?</cell><cell>????</cell></row><row><cell></cell><cell>Which brand of toilet pa-</cell><cell>Tissue brand</cell></row><row><cell>?????????????</cell><cell>per is the best</cell><cell></cell></row><row><cell>Well, I bought once, and the quality is very good.</cell><cell></cell><cell></cell></row><row><cell>??????????????????</cell><cell></cell><cell></cell></row><row><cell>There are so many varieties that I don't know what brand to buy.</cell><cell></cell><cell></cell></row><row><cell>???????????????????????????????</cell><cell></cell><cell></cell></row><row><cell>Gulangyu Island in Xiamen is very beautiful, and Nanputuo Temple, Huandao Road and Baicheng Beach are also worth visiting.</cell><cell>????7??? Weather of Xiamen in the</cell><cell>??????</cell></row><row><cell></cell><cell></cell><cell>Attractions in Xiamen</cell></row><row><cell>????????????????????</cell><cell>next 7 days</cell><cell></cell></row><row><cell>Yes, these are on my punch list. You know a lot.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 22 :</head><label>22</label><figDesc>Query generation examples with score range 0.7-0.8 on DuSinc, accounts for 25.3% of the total dataset.Generally, to overcome the anxiety of the exam, you should actively adjust yourself and improve your understanding of the exam. Don't think it will be over if you don't do well in the exam. Then take a deep breath and don't think too much.Yes, I also want to go to Bangkok or Chiang Mai for a visit. Oh, and there is Phuket Island, which I kept saying to go but I haven't. ?????????????????????? I've only heard of these places. What's there to see in Bangkok? Why so many mistakes? Are you sick? If the composition deviates from the topic, it may be that you have not grasped the central idea. It is not a big problem. Anyone can stray from the topic.???????????????????????????????????????? ??????Actually it is because I haven't come to the morning reading class recently, and I haven't recited the new words and poems, that I can't write from memory. Have yesterday's homework been sent back? ???????????????</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell></row><row><cell>????????????????????????????????????????</cell><cell></cell><cell></cell></row><row><cell>???????????????</cell><cell></cell><cell></cell></row><row><cell>???????????????????????</cell><cell>??????? Points for attention in tak-</cell><cell>???????? Mental adjustment before</cell></row><row><cell>This is called cramming. It's my fault that I haven't studied hard at normal times and I'm screwed.</cell><cell>ing English exam</cell><cell>examination</cell></row><row><cell>???????????????????</cell><cell></cell><cell></cell></row><row><cell>Don't worry, you can do it. What test are you going to take tomorrow?</cell><cell></cell><cell></cell></row><row><cell>???????</cell><cell></cell><cell></cell></row><row><cell>I will take an English test tomorrow.</cell><cell></cell><cell></cell></row><row><cell>????????????????????????????????????</cell><cell></cell><cell></cell></row><row><cell></cell><cell>????</cell><cell>???????? What's there to see in</cell></row><row><cell></cell><cell>Bangkok attractions</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Bangkok</cell></row><row><cell>????????????????????????????????????????</cell><cell></cell><cell></cell></row><row><cell>?????????</cell><cell></cell><cell></cell></row><row><cell></cell><cell>?????</cell><cell>???????? What to do when fell be-</cell></row><row><cell></cell><cell>Fall behind the lesson</cell><cell></cell></row><row><cell></cell><cell></cell><cell>hind in lessons</cell></row><row><cell>Yes, mine is here. Let me show you.</cell><cell></cell><cell></cell></row><row><cell>???????????????</cell><cell></cell><cell></cell></row><row><cell>I seem to have missed a lot of lessons. What should I do?</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 23 :</head><label>23</label><figDesc>Query generation examples with score range 0.8-0.9 on DuSinc, accounts for 37.6% of the total dataset.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell></row><row><cell>????????????????</cell><cell></cell><cell></cell></row><row><cell>Recently, I'm crazy about cooking, and I always stay in the kitchen.</cell><cell></cell><cell></cell></row><row><cell>?????????</cell><cell>?????</cell><cell>????? Ways to make soy-braised</cell></row><row><cell>What are you cooking?</cell><cell>Soy-braised pork skills</cell><cell></cell></row><row><cell></cell><cell></cell><cell>pork</cell></row><row><cell>???????</cell><cell></cell><cell></cell></row><row><cell>Studying soy-braised pork.</cell><cell></cell><cell></cell></row><row><cell>??????????????????????????</cell><cell></cell><cell></cell></row><row><cell>I'm reviewing the TV play starring Bai Jingting, You Are My Hero.</cell><cell>????????</cell><cell>???????? ??</cell></row><row><cell>???????????????</cell><cell>You Are My Hero</cell><cell>You Are My Hero, plot</cell></row><row><cell>Wow, sounds good. What is it mainly about?</cell><cell></cell><cell></cell></row><row><cell>????????????????????????Mass Transit Railway????????</cell><cell></cell><cell></cell></row><row><cell>?????????</cell><cell></cell><cell></cell></row><row><cell>Yes, you are too. I see you're in Hong Kong, China. The Hong Kong subway, also called Mass Transit</cell><cell>????</cell><cell>????</cell></row><row><cell>Railway, is very famous, and it is fast, safe and reliable.</cell><cell>Epidemic subway</cell><cell>Hong Kong subway epi-</cell></row><row><cell>???????????????????????????????</cell><cell></cell><cell>demic prevention</cell></row><row><cell>Yes, I usually travel by subway, but under the epidemic, we should pay more attention to our safety</cell><cell></cell><cell></cell></row><row><cell>when going out.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 24 :</head><label>24</label><figDesc>Query generation examples with score range 0.9-1.0 on DuSinc, account for 30.3% of the total dataset. Now children are mobile phone addicts, but adults can't live without mobile phones as well. They play it all the time. ????????????????????? That's true, though playing with mobile phones is so harmful, we still can't leave it. It's not far away. We should prepare ahead. After all, I heard that our Chinese language and Literature has employment difficulties.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell></row><row><cell>????????</cell><cell></cell><cell></cell></row><row><cell>I recently changed my phone.</cell><cell></cell><cell></cell></row><row><cell>?????????????</cell><cell></cell><cell></cell></row><row><cell>Really? What brand is your new mobile phone?</cell><cell></cell><cell></cell></row><row><cell>?????iphone13?</cell><cell>4G?5G??? Differences between 4G</cell><cell>5G?4G??? Differences between 5G</cell></row><row><cell>Today's new iphone13.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>and 5G</cell><cell>and 4G</cell></row><row><cell>????????????5G???</cell><cell></cell><cell></cell></row><row><cell>Oh I see, then you should have been using 5G right now.</cell><cell></cell><cell></cell></row><row><cell>??????????4G?5G????</cell><cell></cell><cell></cell></row><row><cell>Yes, although I don't know the difference between 4G and 5G.</cell><cell></cell><cell></cell></row><row><cell>??????????????</cell><cell></cell><cell></cell></row><row><cell>It's so common for children to play with mobile phones nowadays.</cell><cell></cell><cell></cell></row><row><cell>??????????????????????????????</cell><cell>??????</cell><cell>??????</cell></row><row><cell></cell><cell>Harms of playing with mo-</cell><cell>Disadvantages of playing</cell></row><row><cell></cell><cell>bile phones</cell><cell>with mobile phones</cell></row><row><cell>??????????????</cell><cell></cell><cell></cell></row><row><cell>I will graduate the year after next. Do you have any ideas?</cell><cell></cell><cell></cell></row><row><cell>???????????????</cell><cell>??????????</cell><cell>??????????</cell></row><row><cell></cell><cell>Employment prospects of</cell><cell>Employment of Chinese</cell></row><row><cell>We are only sophomores now. You think so far.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Chinese Language and Lit-</cell><cell>Language and Literature</cell></row><row><cell>?????????????????????????????</cell><cell>erature</cell><cell>major</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 25 :</head><label>25</label><figDesc>Query generation examples on DuSinc for coreference dialogues. Yeah, I saw him as a judge in Super Sketch Show the other day. Are you talking about Liu Xiang? He is China's first-class athlete in track and field (110m hurdles) and the first athlete to win the 110m hurdles three times in the history of the Asian Games. ???????????(coreference)?????????? Yes, it's him. Do you know what his (coreference) greatest achievement is?</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell><cell>Score</cell></row><row><cell>??????????????????????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tianshui has Maiji Mountain Scenic Spot, Fuxi Temple and Taoist Cultural Scenic Spot.</cell><cell>????</cell><cell>????</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>1.00</cell></row><row><cell>???(coreference)????????</cell><cell>Tianshui fine food</cell><cell>Tianshui fine food</cell><cell></cell></row><row><cell>Oh, is there anything delicious there (coreference)?</cell><cell></cell><cell></cell><cell></cell></row><row><cell>??????????????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Breakup Buddies and Lost On Journey should be his masterpiece.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>????????????????????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>?????</cell><cell>??????</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.85</cell></row><row><cell>????????????</cell><cell>Xu Zheng's wife</cell><cell>Who is Xu Zheng's wife</cell><cell></cell></row><row><cell>Xu Zheng's films are quite good.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>?(coreference)???????</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Who is his (coreference) wife?</cell><cell></cell><cell></cell><cell></cell></row><row><cell>?????????????????(110???)?????????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell>??????110????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>??????</cell><cell>??????</cell><cell></cell></row><row><cell></cell><cell>Liu Xiang's greatest</cell><cell>Liu Xiang's greatest</cell><cell>1.00</cell></row><row><cell></cell><cell>achievement</cell><cell>achievement</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 26 :</head><label>26</label><figDesc>Query generation examples on DuSinc for ellipsis dialogues.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell><cell>Score</cell></row><row><cell>?????????????????????????????????????</cell><cell></cell><cell></cell><cell></cell></row><row><cell>??????????</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 27 :</head><label>27</label><figDesc>Query generation examples on DuSinc for complete query dialogues. Yongzheng Dynasty and Treading On Thin Ice are both TV dramas about the Qing Dynasty.</figDesc><table><row><cell>Dialogue History</cell><cell>Ground-truth Query</cell><cell>Generated Query</cell><cell>Score</cell></row><row><cell></cell><cell>??????????</cell><cell>??????????</cell><cell></cell></row><row><cell>???????????????(complete query) When is proper to start health maintenance? (complete query)</cell><cell>??? When is proper to start</cell><cell>??? When is proper to start</cell><cell>1.00</cell></row><row><cell></cell><cell>health maintenance</cell><cell>health maintenance</cell><cell></cell></row><row><cell>????????????????????????</cell><cell>??????????</cell><cell>??????????</cell><cell></cell></row><row><cell></cell><cell>? Does Treading On Thin Ice</cell><cell>? Does Treading On Thin Ice</cell><cell>1.00</cell></row><row><cell></cell><cell>run counter to history</cell><cell>run counter to history</cell><cell></cell></row><row><cell>??????????(complete query) What should novices prepare to go fishing? (complete query)</cell><cell>????????? pare to go fishing What should novices pre-</cell><cell>????????? pare to go fishing What should novices pre-</cell><cell>1.00</cell></row></table><note><p><p>????????????(complete query)</p>Does Treading On Thin Ice run counter to history? (complete query)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 28 :</head><label>28</label><figDesc>Who or what question type query generation examples on DuSincR.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 29 :</head><label>29</label><figDesc>When or where question type query generation examples on DuSincR.</figDesc><table><row><cell>Dialogue History</cell><cell>Generated Query</cell></row><row><cell>??????????????</cell><cell></cell></row><row><cell>I want to raise some violets. Is it easy to raise?</cell><cell></cell></row><row><cell>????????????????????</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 30 :</head><label>30</label><figDesc>Count question type query generation examples on DuSincR.</figDesc><table><row><cell>Dialogue History</cell><cell>Generated Query</cell></row><row><cell>????????????</cell><cell></cell></row><row><cell>What gift should I give on Valentine's Day?</cell><cell></cell></row><row><cell>????????????????????</cell><cell></cell></row><row><cell>Send her a loving gift. You can give her roses.</cell><cell></cell></row><row><cell>?????????????????????</cell><cell></cell></row><row><cell>What color is better? I saw many colors in the flower shop.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 31 :</head><label>31</label><figDesc>Select among question type query generation examples on DuSincR.Yes, I listen to all his songs, such as Lovely Woman, Simple Love, Tornado, In the Name of Father, Love Cliff, Seven Mile Fragrance, General and so on.Oh, it seems that we have the same idol. I like his song Blue and White Porcelain very much. The song Blue and White Porcelain is very classic. It comes from the album I'm Busy. At the 19th Golden Melody Awards ceremony in Taiwan at that time, he won that year's Best Song Award, Best Lyrics Award and Best Composing Award. ?????????????????????? Yes, I like Jay Chou's Chinese style songs very much, they really have this feeling. ???????????????????????????????????????????????????? Then you must also like Breaking the East Wind, Preface to Orchid Pavilion and Hair Like Snow. Thousand Miles Away and Cold Fireworks are representatives of Jay Chou's Chinese style. Mm-hmm. Yes, I like all of them. Do you know which album he (coreference) sells the most? (select among question type) Ha ha! I guess you saw it! Because you like Bai Jingting.</figDesc><table><row><cell>Dialogue History</cell><cell>Generated Query</cell></row><row><cell>??????????</cell><cell></cell></row><row><cell>Do you like Jay Chou's songs?</cell><cell></cell></row><row><cell>?????????????????????????????????????????????????????</cell><cell></cell></row><row><cell>?????</cell><cell></cell></row><row><cell>?????????????????????????????</cell><cell></cell></row><row><cell>???????????????????????????????19?????????????????????</cell><cell>?????????</cell></row><row><cell>??????????</cell><cell>Jay Chou's best-selling al-</cell></row><row><cell></cell><cell>bum</cell></row><row><cell>?????????????????????</cell><cell></cell></row><row><cell></cell><cell>??????????</cell></row><row><cell></cell><cell>?</cell></row><row><cell></cell><cell>Bai Jingting TV drama</cell></row><row><cell></cell><cell>with the highest score</cell></row><row><cell>?????????????????????</cell><cell></cell></row><row><cell>I want to buy a pair of basketball shoes. Do you know which brand is better?</cell><cell></cell></row><row><cell>???????????????????????</cell><cell></cell></row><row><cell>I wear Li Ning's, and my teammates wear Adidas and Nike's more.</cell><cell></cell></row><row><cell>????????????????????????????</cell><cell>???????</cell></row><row><cell>Okay, I will buy a pair this afternoon. Do you have time? Come with me!</cell><cell>Maximum size of Li Ning</cell></row><row><cell>???????????????</cell><cell>women's shoes</cell></row><row><cell>No, we are too far away.</cell><cell></cell></row><row><cell>???????????????????????</cell><cell></cell></row><row><cell>Oh, well, then I'll buy it online. Do you know where to buy it?</cell><cell></cell></row><row><cell>???????????????</cell><cell></cell></row><row><cell>OkBuy, Skomart and De Wu all sell them.</cell><cell></cell></row><row><cell>????????(coreference)????????????????????(select among question type)</cell><cell></cell></row><row><cell>By the way, do you know the maximum size of women's shoes of this (coreference) brand, since my feet are quite big? (select</cell><cell></cell></row><row><cell>among question type)</cell><cell></cell></row></table><note><p>?????????????????(coreference)????????????(select among question type) ?????"?????"???????????? Bai Jingting is the "little prince of Huairou". He is handsome and has good acting skills. ????????????????(coreference)??????????????????????(ellipse) (select among question type) Ha ha, then loyal little fan, have you seen all his (coreference) TV dramas? Do you know which one has the highest score? (ellipse) (select among question type) ?????????? How do you feel about it? ????????????????????????? It's very good. It doesn't deform. It also has good shock absorption. I've already been wearing it for a whole semester.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 32 :</head><label>32</label><figDesc>Comparison question type query generation examples on DuSincR.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_29"><head>Table 33 :</head><label>33</label><figDesc>Verify question type query generation examples on DuSincR.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_30"><head>Table 34 :</head><label>34</label><figDesc>How question type query generation examples on DuSincR.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 35 :</head><label>35</label><figDesc>Why question type query generation examples on DuSincR.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_32"><head>Table 36 :</head><label>36</label><figDesc>Search result examples with score range 0.5-0.6 on DuSinc, accounts for 0.2% of the total dataset.Sister Xianglin (a character in Lu Xun's short story Blessing): Sister Xianglin is a character in Lu Xun's short story Blessing. She had lost her husband twice and her son once. In the happy atmosphere of the New Year worship, she died tragically under the double torture of body and spirit. Xianglin sister-in-law was the product of the destruction of the feudal social system and the result of the strangulation of feudal ethics. As a typical figure of tragic fate under the background of feudal society, Lu Xun's tragic life of Xianglin Sister-in-law truly reflects the heavy impact of the dark feudal era on the ordinary working people, which is not only personal misfortune, but also social sorrow.Is Wu Zetian the only female emperor in Chinese history: Wu Zetian, the Empress Li Zhi of Emperor Gaozong of the Tang Dynasty, the politician from the Tang Dynasty to the Wu Zhou Dynasty, the founding emperor of the Wu Zhou Dynasty, is also the only orthodox female emperor in Chinese history. Not only that, she was also one of the oldest and longest emperors. Historians have always believed that she was the only female emperor in China's history, but some people also believed that the daughter of Emperor Xiaoming of the Northern Wei Dynasty, Miss Yuan, was the earliest female emperor. examples, which only make up 0.2% of the entire 9,353 examples and have scores in range of 0.5 to 0.6, acquire high quality search results despite their low scores. The reason why the score is low, is mainly due to some of the given knowledge provided in DuSinc is a brief answer to the search query, while our web knowledge retrieved is a complete paragraph. This result works the same with the examples which falls into the score range of 0.6 to 0.7 presented in Table37.</figDesc><table><row><cell>Search Query</cell><cell>Ground-truth Knowledge Snippet</cell><cell>Retrieved Knowledge Snippet</cell></row><row><cell></cell><cell></cell><cell>???(??????????????)???????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell>??????????</cell><cell></cell><cell>???????????</cell></row><row><cell>??</cell><cell>???</cell><cell></cell></row><row><cell>Which article did Lu Xun</cell><cell>Blessing.</cell><cell></cell></row><row><cell>write about Sister Xianglin</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>????????</cell></row><row><cell>??????????</cell><cell></cell><cell></cell></row><row><cell>???</cell><cell>??</cell><cell></cell></row><row><cell>Is Wu Zetian the first</cell><cell>Yes.</cell><cell></cell></row><row><cell>queen of China</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>2021????????2021??????????-RUIKE?</cell></row><row><cell></cell><cell></cell><cell>??2022?9?26??????????????????</cell></row><row><cell></cell><cell></cell><cell>?10.5?/? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?10.6?/?</cell></row><row><cell>????????? Are the vegetables at the</cell><cell>????</cell><cell>?????????????????7.5?/??? 2021 Vegetable Price List Today, 2021 Vegetable Price List Today -RUIKE Encyclopedia: On September 26, 2022, the wholesale market</cell></row><row><cell>New Farmers Market ex-</cell><cell>It's a little expensive.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>price of Xinfadi agricultural products in Fengtai District, Beijing</cell></row><row><cell>pensive</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>was 10.5 RMB/kg, the comprehensive wholesale market price of</cell></row><row><cell></cell><cell></cell><cell>Tianjin Hongqi Agricultural Trade was 10.6 RMB/kg, the whole-</cell></row><row><cell></cell><cell></cell><cell>sale market price of Shijiazhuang Qiaoxi Vegetable Center was 7.5</cell></row><row><cell></cell><cell></cell><cell>RMB/kg.</cell></row></table><note><p>These</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33"><head>Table 37 :</head><label>37</label><figDesc>Search result examples with score range 0.6-0.7 on DuSinc, accounts for 1.9% of the total dataset.Which is more important, family or career? Although family and career are equally important, we should choose family first. After you have managed your family well, you can develop your career.</figDesc><table><row><cell>Search Query</cell><cell>Ground-truth Knowledge Snippet</cell><cell>Retrieved Knowledge Snippet</cell></row><row><cell></cell><cell></cell><cell>?????????????????????????</cell></row><row><cell></cell><cell></cell><cell>(FedEx)?1971???????211??????????</cell></row><row><cell></cell><cell></cell><cell>?????FedEx(????)?????????????</cell></row><row><cell>??????????</cell><cell>???</cell><cell>???????</cell></row><row><cell>Which country invented</cell><cell></cell><cell>Which country invented express delivery: the United States of</cell></row><row><cell></cell><cell>The United States of America.</cell><cell></cell></row><row><cell>express delivery</cell><cell></cell><cell>America. The earliest express should be FedEx. Founded in 1971, it</cell></row><row><cell></cell><cell></cell><cell>currently provides express transportation services to 211 countries</cell></row><row><cell></cell><cell></cell><cell>and regions. FedEx is the largest express company in the world and</cell></row><row><cell></cell><cell></cell><cell>the ancestor of the international express industry.</cell></row><row><cell></cell><cell></cell><cell>????????????-?????-?????...???-</cell></row><row><cell></cell><cell></cell><cell>&gt;?? ????313.45(??) ????4.6(??) ???188(?)</cell></row><row><cell>????????</cell><cell>318???</cell><cell>????145(?) ????333(?)?</cell></row><row><cell>Distance between Guilin</cell><cell></cell><cell>How many kilometers from Guilin to Hechi by car? How long will</cell></row><row><cell></cell><cell>318 km.</cell><cell></cell></row><row><cell>and Hechi</cell><cell></cell><cell>it take? How to get to the expressway...: Total distance from Guilin</cell></row><row><cell></cell><cell></cell><cell>to Hechi: 313.45(km) Total time: 4.6(h) Oil fee: 188(RMB) Road and</cell></row><row><cell></cell><cell></cell><cell>bridge fee: 145(RMB) Total cost: 333(RMB).</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell>?????????? Which is more important,</cell><cell>????</cell><cell>????????????????????????</cell></row><row><cell></cell><cell>Both important.</cell><cell></cell></row><row><cell>family or career</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head>Table 38 :</head><label>38</label><figDesc>Search result examples with score range 0.7-0.8 on DuSinc, accounts for 12.4% of the total dataset.</figDesc><table><row><cell>Search Query</cell><cell>Ground-truth Knowledge Snippet</cell><cell>Retrieved Knowledge Snippet</cell></row><row><cell></cell><cell></cell><cell>??hu?n???????????hu?n????????</cell></row><row><cell></cell><cell></cell><cell>???hu?n?????????hu?n??????????</cell></row><row><cell>?hu?n??????? ? Whether the story of the</cell><cell>??????</cell><cell>?????????????????????????? ??????????????????? Is "Legend of Zhen Huan" true history? "Legend of Zhen Huan" is</cell></row><row><cell></cell><cell>Non-conformance with history.</cell><cell>not true history. The legend of Zhen Huan is not a historical fact.</cell></row><row><cell>Legend of Zhen Huan is</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>The TV series of the legend of Zhen Huan is based on the colorful</cell></row><row><cell>true</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>historical overhead novel. The historical overhead means that there</cell></row><row><cell></cell><cell></cell><cell>is no such dynasty in history, and it is a world created by the novel</cell></row><row><cell></cell><cell></cell><cell>author.</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell></cell><cell></cell><cell>??129?39'50"-132?31'00"???47?03'30"-48?21'00"????</cell></row><row><cell></cell><cell></cell><cell>??????????????????????????</cell></row><row><cell>??????????</cell><cell></cell><cell>???????????????????????</cell></row><row><cell>?? The geographical location</cell><cell>????????</cell><cell>Hegang: Hegang City is located in the northeast of Heilongjiang Province, in the low mountains and hills at the east foot of the</cell></row><row><cell></cell><cell>Northeast of Heilongjiang Province.</cell><cell></cell></row><row><cell>of Hegang City in Hei-</cell><cell></cell><cell>Xiaoxing'an Mountains and the plain where the Songhua River and</cell></row><row><cell>longjiang Province</cell><cell></cell><cell>Heilongjiang meet. The geographical coordinates are 129?39'50"-</cell></row><row><cell></cell><cell></cell><cell>132?31'00"E and 47?03'30"-48?21'00"N. The Songhua River is con-</cell></row><row><cell></cell><cell></cell><cell>nected with Tongjiang City in the east, Yichun City in the west,</cell></row><row><cell></cell><cell></cell><cell>Tangyuan County in Jiamusi City in the south, and the main chan-</cell></row><row><cell></cell><cell></cell><cell>nel of Heilongjiang Province in the north.</cell></row><row><cell></cell><cell></cell><cell>2022? ? ? ? ? ? ? ?Switch? ? ? ?-?</cell></row><row><cell></cell><cell>switch?????299.99??/29980???switch lite????</cell><cell>? ?2022?8?15?Switch Lite? ? ? ?1500? ? ? ? ?</cell></row><row><cell>switch??</cell><cell>??199.99??/19980???</cell><cell>???Switch???700?1000??</cell></row><row><cell>Price of switch</cell><cell>The official price of switch is USD 299.99/JPY 29980, and the official</cell><cell>Super detailed Nintendo Switch purchase guide in 2022 -Zhihu:</cell></row><row><cell></cell><cell>price of switch lite is USD 199.99/JPY 9980.</cell><cell>The price of Switch Lite on August 15, 2022 is about 1500 RMB,</cell></row><row><cell></cell><cell></cell><cell>which is 700 to 1000 RMB cheaper than the original switch.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35"><head>Table 39 :</head><label>39</label><figDesc>Search result examples with score range 0.8-0.9 on DuSinc, accounts for 56.5% of the total dataset.Nie Lihong, Deputy Chief Physician: Dongzhimen Hospital of Beijing University of Traditional Chinese Medicine. Helicobacter pylori is a microaerobic, helicoid bacterium, which is the only bacteria found so far that can survive in the stomach. This bacterium has strict requirements for its living environment. It cannot survive in a completely aerobic state or a completely anaerobic state. This bacterium was discovered by two foreign scientists in 1983. The research found that it is related to chronic atrophic gastritis, peptic ulcer, gastric malignant tumor in our stomach, as well as some extragastric diseases, such as lymphoma, iron deficiency anemia, idiopathic thrombocytopenic purpura. So at present, we attach great importance to the fact that the general survey among patients is also a relatively common thing.How to check Helicobacter pylori -Youlai doctor: 1. Invasive examination: The invasive examination of Helicobacter pylori includes blood sampling test to check the antibody of Helicobacter pylori, and a rapid urease under the gastroscope. Take a piece of mucosal tissue for microscopic smear detection, rapid urease and gastroscopy. 2. Non-invasive detection: carbon 13 and carbon 14 breath test can be carried out. This detection method can obtain results non-invasively and quickly.</figDesc><table><row><cell>Search Query</cell><cell>Ground-truth Knowledge Snippet</cell><cell>Retrieved Knowledge Snippet</cell></row><row><cell>?????????</cell><cell>?????????????????????????? ?????????????????????????? ?????????????????????????? ???????????????</cell><cell>??????-???????2021?12?28??????? ?????????????????????????? ?????????????????????????? ???????????</cell></row><row><cell></cell><cell>The following results come from Yikao.com: Fashion design is not</cell><cell></cell></row><row><cell>Is it difficult to be a fashion</cell><cell></cell><cell>Is it difficult to design clothes? Baidu Zhizhi is eager to learn: on</cell></row><row><cell></cell><cell>difficult to learn, and the introduction of fashion design is very</cell><cell></cell></row><row><cell>designer</cell><cell></cell><cell>December 28, 2021, it looks very easy to make clothes. Anyone can</cell></row><row><cell></cell><cell>simple, but to become an excellent fashion designer, you need not</cell><cell></cell></row><row><cell></cell><cell></cell><cell>do it. In fact, it is difficult to do anything now. Only when you are</cell></row><row><cell></cell><cell>only professional expertise, but also rich design experience, so</cell><cell></cell></row><row><cell></cell><cell></cell><cell>in it will you feel the competition is so fierce. If you don't have a</cell></row><row><cell></cell><cell>only by continuous efforts can you become an excellent fashion</cell><cell></cell></row><row><cell></cell><cell></cell><cell>good marketing strategy yourself.</cell></row><row><cell></cell><cell>designer.</cell><cell></cell></row><row><cell></cell><cell>???????????????????? ?????</cell><cell></cell></row><row><cell></cell><cell>??????????????????????????</cell><cell></cell></row><row><cell></cell><cell>??????????????????????????</cell><cell></cell></row><row><cell></cell><cell>??????????????????????????</cell><cell></cell></row><row><cell></cell><cell>???????1983????????????????? ?????????????????????????? ?????????????????????????? ?????????????????????????? ???????????????????????</cell><cell>?????????-?????1.??????????? ?????????????????????????? ?????????????????????????? ??????????? 2.?????????13??14? ??????????????????????</cell></row><row><cell>????????</cell><cell></cell><cell></cell></row><row><cell>Helicobacter pylori test</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head></head><label></label><figDesc>Qin Great Wall (the Great Wall built by Qin Shihuang): In the 33rd year of Qin Shihuang (214 BC), the Great General Meng Tian was sent to drive the Huns to the north and build the Great Wall for more than ten thousand miles to prevent the Huns from going south. It is called the Qin Great Wall in history. The Qin Great Wall was actually built on the basis of the Qin Great Wall, Zhao Great Wall and Yan Great Wall in the Warring States Period. From Lintao (now Minxian County, Gansu Province) in the west to Yalu River (now the east and south of Liaoning Province and the southeast of Jilin Province) in the east, more than ten thousand li have been built, so it is called the "Great Wall" in history. The Great Wall of Qin is listed as a national key cultural relics protection unit.</figDesc><table><row><cell>)?????????????????????</cell></row><row><cell>??????????????????????????</cell></row><row><cell>??????????????????????(???</cell></row><row><cell>??)??????(????????????????</cell></row><row><cell>????)??????????"????"??????</cell></row><row><cell>??????????????</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_37"><head>Table 40 :</head><label>40</label><figDesc>Search result examples with score range 0.9-1.0 on DuSinc, accounts for 29.0% of the total dataset.</figDesc><table><row><cell>Search Query</cell><cell>Ground-truth Knowledge Snippet</cell><cell>Retrieved Knowledge Snippet</cell></row><row><cell></cell><cell>?????????????????????????</cell><cell></cell></row><row><cell>???????</cell><cell></cell><cell></cell></row><row><cell>Shangfangshan</cell><cell>Forest</cell><cell></cell></row><row><cell>Park</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_38"><head></head><label></label><figDesc>Temperate oceanic monsoon climate is a local climate formed mainly by the monsoon climate and based on the characteristics of the temperate marine climate and the temperate monsoon climate. It has the common influence of both marine and monsoon factors. It is distributed in the coastal zone of the north temperate monsoon climate zone.</figDesc><table><row><cell>??????????????????????????</cell></row><row><cell>??????????????????????????</cell></row><row><cell>??????????????????????????</cell></row><row><cell>????</cell></row><row><cell>Temperate oceanic mon-</cell></row><row><cell>soon climate</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_39"><head></head><label></label><figDesc>Temperate oceanic monsoon climate: Temperate oceanic monsoon climate is a local climate formed mainly by monsoon climate and based on the characteristics of temperate oceanic climate and temperate monsoon climate, with the joint influence of both oceanic and monsoon factors. It is distributed in the coastal zone of the north temperate monsoon climate zone. It is the most suitable climate for human habitation in the temperate zone. Only Qingdao, Dalian, Yantai and Weihai in China belong to this climate type.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_40"><head>Table 41 :</head><label>41</label><figDesc>Response generation examples with noisy knowledge snippet injection.Hmm For example, let the children feel your love Parents must let the children feel the love coming from you! Because fatherly love and motherly love are indispensable to the growth of children Spend more time with the children, from the interaction learn more about children How important is it to cultivate children's attention, do you know? -Zhihu: Cultivating children's attention is the key to success in learning and doing things. The ability to be highly concentrated on one thing is a very important psychological quality. Or many parents will ask, what are the benefits of cultivating children's attention? Sometimes, they will take the initiative to explore unknown things to find solutions to problems. You such a good dress code, are you a makeup artist? ??,????,????????? Ha ha, you're pretty close, but I'm not a makeup artist ????????????? What is your occupation then, I am curious ???(????????)_????:??? ??????????????,????? ????????,????... ?????? ??????,????????????? ???,?????... ???????,??? ???,???????????????,? ????... ???????,??????? ?????????????????, ... ? ? Makeup Artist (Actor Styling Designer)_Baidu Encyclopedia:The process of makeup is the process of creating beautiful works of art. The basics of makeup that need to be mastered are the same, and then makeup artists... With the opening up of the country and the improvement of productivity, people's quality of life and level are also getting higher and higher. The pursuit of beauty... Some graduates can successfully join beauty salons, film crews, TV stations, fashion and entertainment circles, ... Expand Poetry is a literary genre that expresses emotion and speech. It is a literary genre in which the author's rich emotions are vividly expressed in highly condensed language, reflecting social life with a certain rhythm and rhyme. It is written in the "Mao Shi -Great Preface": "Poetry is also the place of the will. In the heart is the will, and in the speech is the poem". In the Southern Song Dynasty, Yan Yu's poem "Canglang Shihua" says: "Poetry is the chanting of emotions". There is only one kind of art expressed in words: poetry. In 2022, the Chinese ... Expand</figDesc><table><row><cell>Dialogue History</cell><cell>Retrieved Knowledge Snippet</cell><cell>Generated Response</cell></row><row><cell>????????</cell><cell></cell><cell></cell></row><row><cell>Do you like watching anime?</cell><cell></cell><cell></cell></row><row><cell>???,??????????</cell><cell>????????:??????????,? ??????????????????,?</cell><cell></cell></row><row><cell>I like it, a lot of Japanese anime are super good-looking</cell><cell>???????????????,????</cell><cell></cell></row><row><cell>??,????????</cell><cell>?????????????,??????</cell><cell></cell></row><row><cell>Yes, especially Naruto</cell><cell>??,??????????????,???</cell><cell></cell></row><row><cell>??????????,?????????????? The protagonist of this anime is Naruto, and it mainly describes the experience of Naruto and his partners</cell><cell>?????????????????,?? ???????,???,????? Is Naruto good?: Naruto is particularly good, be-</cell><cell>?????????? ???</cell></row><row><cell></cell><cell>cause his plot is familiar to China, and Naruto's</cell><cell>"Tokyo Cat" "Natsume's</cell></row><row><cell>??????????????????</cell><cell>setting is in line with most people's hearts. They</cell><cell>Book of Friends"</cell></row><row><cell>Did you find the friendship between them touching?</cell><cell>are not recognized by others and wanted to be</cell><cell></cell></row><row><cell>??,????????,??????????,???????,????</cell><cell>recognized, so it is a great anime, and the author</cell><cell></cell></row><row><cell>???</cell><cell>portrays it very delicately, which can give you</cell><cell></cell></row><row><cell></cell><cell>an immersive feeling. It's very, very good. I have</cell><cell></cell></row><row><cell>Well, their bond is strong, their friendship is wonderful, friendship asks for</cell><cell></cell><cell></cell></row><row><cell></cell><cell>been fallowing it since elementary school, and</cell><cell></cell></row><row><cell>anything, but it comforts you.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>watched it three times until the end.</cell><cell></cell></row><row><cell>????????,???????????</cell><cell></cell><cell></cell></row><row><cell>In addition to "Naruto", what are some good anime that you know</cell><cell></cell><cell></cell></row><row><cell>?????,??????</cell><cell></cell><cell></cell></row><row><cell>Oh, my husband, he doesn't take care of the children at all</cell><cell></cell><cell></cell></row><row><cell>???!????????????????????????????</cell><cell></cell><cell></cell></row><row><cell>????????????????</cell><cell></cell><cell></cell></row><row><cell></cell><cell>???????????,????? -??:?</cell><cell></cell></row><row><cell></cell><cell>???????,????????????</cell><cell></cell></row><row><cell>???</cell><cell>?????,?????????????</cell><cell></cell></row><row><cell>I feel so exhausted</cell><cell>????,??????????????</cell><cell></cell></row><row><cell>??????????????????????????,????? I wish there is something I can do Perhaps there is still a solution Put your mind right Communicate with the father more Comfort each other and collaborate</cell><cell>??????,????????????? ?????????????,?????? ??,??????? ?????????? ?,?????????????,?????</cell><cell>?????????? ?????????? ?????????? ??????????</cell></row><row><cell>?????????????</cell><cell>???????????????,????</cell><cell>???????!</cell></row><row><cell>I'm not going to let this go on</cell><cell>??????????,?????????</cell><cell>It's never too late From</cell></row><row><cell>???????????,????</cell><cell>??</cell><cell>now on, spend more time</cell></row><row><cell></cell><cell></cell><cell>with your children and</cell></row><row><cell>I believe you can do well, I support you</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>communicate with the fa-</cell></row><row><cell>??????,??????????</cell><cell></cell><cell>ther Let the children feel</cell></row><row><cell>So what can I do in terms of parenting?</cell><cell></cell><cell>the love from you I believe</cell></row><row><cell>???????????????????????????????</cell><cell></cell><cell>you will have a great time</cell></row><row><cell>?!?????????????????????????????</cell><cell></cell><cell>getting along!</cell></row><row><cell>?,???????????</cell><cell></cell><cell></cell></row><row><cell>????????????????,??????????</cell><cell></cell><cell></cell></row><row><cell>We really haven't payed attention to what you just said, is it too late to start</cell><cell></cell><cell></cell></row><row><cell>now?</cell><cell></cell><cell></cell></row></table><note><p><p>I'm sorry to hear that! It must of been hard for you This is widowed parenting Children who grow up in this kind of family often aren't close to their mother or their father. ?????????:"??,??????. ? ???,????"?. ?????????? ?:"??,?????"?. ???????? ?????????. 2022?, ?... ?? Poetry (literary genre)_Baidu Encyclopedia:</p>? ? ?,? ? ? ? ? ?</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_41"><head>Table 42 :</head><label>42</label><figDesc>Response generation examples with helpful knowledge snippet injection.It's a easy task to take care of it. Pruning of diseased yellow leaves, over 20cm need to be pruned, if there are diseased roots, decay ones should also be pulled out ????????????,?????????? I see everyone has a green plant in the office, there must of been many benefits of green plants, right?What is the role of greenery -the Flower Encyclopedia:Decorative role: greenery is green in color, evergreen, and can play a very good decorative role in the living room. It has a strong ability to purify the air and can absorb formaldehyde in the air. The wind as ...Doyou like pc games or mobile games? ????????????? I prefer mobile games. Because it's convenient. ?????????? Do you like King of Glory? ????,???????,??????? I like it, but I don't have time to play, I don't have time to play.</figDesc><table><row><cell>Dialogue History</cell><cell>Retrieved Knowledge Snippet</cell><cell>Generated Response</cell></row><row><cell></cell><cell></cell><cell>???????,???</cell></row><row><cell></cell><cell></cell><cell>?,????,????,?</cell></row><row><cell></cell><cell></cell><cell>??????,????</cell></row><row><cell>??,??????????? Do you know how to prune a green plant, my friend?</cell><cell>????????-???:????:??? ???,????,???????????</cell><cell>??,??????,?? ????????,?? ??????????</cell></row><row><cell>????????????????20cm????????,?????</cell><cell>?????????:??????????</cell><cell>?????</cell></row><row><cell>?,???????</cell><cell>?,?????????????...</cell><cell>The green vine is soft and</cell></row><row><cell></cell><cell></cell><cell>delicate, the leaves are del-</cell></row><row><cell></cell><cell></cell><cell>icate and evergreen, it can</cell></row><row><cell></cell><cell></cell><cell>be used as a foliage, but can</cell></row><row><cell></cell><cell></cell><cell>also serve as a bonsai, a pot</cell></row><row><cell></cell><cell></cell><cell>at home, not only decorate</cell></row><row><cell></cell><cell></cell><cell>the home, but also plays</cell></row><row><cell></cell><cell></cell><cell>a role in purifying the air,</cell></row><row><cell></cell><cell></cell><cell>which is very suitable for</cell></row><row><cell></cell><cell></cell><cell>indoor planting ornamen-</cell></row><row><cell></cell><cell></cell><cell>tal plants.</cell></row><row><cell>????????????</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_42"><head></head><label></label><figDesc>from a friend that it earned 39.4 billion last year.If you want to reduce fire, you should buy kiwi, dragon fruit, pear, mangosteen, grapefruit, watermelon, etc.???????????????What type of fruit is best to eat in winter? ????,??????,??????,???????? ???????????????????????,? ?????????????????? In winter, the climate is relatively dry, and less activity, it is best to eat more water-rich fruits can relieve dry skin, fire, constipation, cough, you can try some apples, pears, bananas, grapefruit, oranges ?????,???????? Perhaps, I can buy some grapefruit ????????,???????????????? ????????,????????? Grapefruit is very healthy, eat more grapefruit can help digestion, regulate gas and phlegm, lung and intestines, blood and spleen, it is also said that it can lower blood sugar level????????????Does it really has such a variety of effects??????????????????_?????_??? ?...:?????????,?????????????C ? ????????,????????????????? ????????,?????????????????? ?????,????????????????????? ?????????????,???????,?????? ??????????,????????????,???? ?????,???????,????????,?????? ?????????????????????????? ??,???????????????????????? ???????????????????! ??????? ?????????????????????????? ?????????????????????????? ????????The efficacy and role of grapefruit?The nutritional value of grapefruit_Parent-child encyclopedia ... Modern medical research has found that grapefruit is very rich in vitamin C and insulin-like ingredients, so it has the effect of lowering blood sugar, lowering blood fat, weight loss, skin beauty and other effects. Regular consumption, high blood pressure, diabetes, vascular sclerosis and other diseases have auxiliary therapeutic effects, for obese people have a body-building function. Grapefruit also has a stomach, lung, blood, intestinal, laxative and other effects, can promote wound healing, sepsis, etc. has a good adjunctive effect. In addition, grapefruit contains physiologically active substances dermatoside, can reduce blood viscosity, reduce the formation of blood clots, so the cerebrovascular diseases, such as cerebral thrombosis, stroke, etc. also has a good preventive effect. And fresh grapefruit because of the insulin-like ingredients, is the ideal food for diabetic patients. See more details Grapefruit and Snow Pear Grapefruit Juice A multi-purpose honey grapefruit tea that clears heat and moistens the lungs to stop coughing! Can pregnant women eat dried apricots Can pregnant women with indigestion eat grapefruit What is good for high blood sugar in early pregnancy What are the health benefits of eating grapefruit Red meat grapefruit efficacy and effects of eating grapefruit can lose weight Grapefruit for people I've always wanted to go to the South Lake, the Smoky Rain Tower and the Exposure Pavilion in Jiaxing. ?,?????????????????,???,??? ???????? Oh, I didn't expect you to know the fun places in Jiaxing, it's rare, when it comes to Hangzhou, people only think of Hangzhou.The city of Jiaxing is a historical and cultural city in China, and also the "home of fish and rice", "the capital of silk" reputation, Mao Dun, Xu Zhimo, Jin Yong, Jin Xueshu, Chen Shishi, Wang Guowei, Feng Zikai, Zhang Leping and other famous masters are not out of Jiaxing, so I I really want to go to see ???| ??:??????,?????????_???? ...:? ?????"??"?????????????,????? ??????????????,???1959?10?,???? ?????????,1985???????????... Learning Party History | Jiaxing: inherit the red spirit, the protection of the famous city to a new level_The Peng Pai-... The site of the First Chinese Communist Party Congress at South Lake in Jiaxing is a national key cultural relics protection unit, and the South Lake Revolutionary Memorial Hall is its propaganda, protection and management institution, which was established in October 1959 and is a modern monumental thematic memorial hall.</figDesc><table><row><cell>Dialogue History</cell><cell>Retrieved Knowledge Snippet</cell><cell>Generated Response</cell></row><row><cell>???????</cell><cell></cell><cell></cell></row><row><cell>What fruits reduce fire 7</cell><cell></cell><cell></cell></row><row><cell>????,???????????????????</cell><cell></cell><cell></cell></row><row><cell>??????</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>???,???????</cell></row><row><cell></cell><cell></cell><cell>??????????</cell></row><row><cell></cell><cell></cell><cell>?????</cell></row><row><cell></cell><cell></cell><cell>Of course, grapefruit also</cell></row><row><cell></cell><cell></cell><cell>contains a lot of organic</cell></row><row><cell></cell><cell></cell><cell>acids, vitamins and min-</cell></row><row><cell></cell><cell></cell><cell>eral elements</cell></row><row><cell>??????????????</cell><cell></cell><cell></cell></row><row><cell>How come no one wants to come to Jiaxing?</cell><cell></cell><cell></cell></row><row><cell>??????,????,??????????????</cell><cell></cell><cell></cell></row><row><cell>???????</cell><cell></cell><cell></cell></row><row><cell>??,???????????????,??????? ?,?????</cell><cell></cell><cell>??,???????? ??????????</cell></row><row><cell>Really, I also like your Tongxiang City, Wuzhen, see the geog-raphy book descriptions, are eager to go to it!</cell><cell></cell><cell>???,??????? ????</cell></row><row><cell>??,????????</cell><cell></cell><cell>Yes, the first national con-</cell></row><row><cell>Lol, Wuzhen is also famous</cell><cell></cell><cell>gress of the Chinese Com-</cell></row><row><cell>???????????????,??"????"?"?</cell><cell></cell><cell>munist Party was held</cell></row><row><cell>???"????,????????????????</cell><cell></cell><cell>here, so it's a famous place</cell></row><row><cell>????????????????????????</cell><cell></cell><cell></cell></row><row><cell>??,??????????</cell><cell></cell><cell></cell></row></table><note><p><p>??,???????????,??????????? ???</p>Indeed, it is a famous city in history, is there also a party political memorial significance?</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0"><p>https://aigc.aminer.cn/racetrack</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1"><p>https://github.com/THUDM/GLM-130B</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>Jie Tang 2 . 2018. GLM-Dialog: Noise-tolerant Pretraining for Knowledge-grounded Dialogue Generation . In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai (Conference acronym 'XX). <rs type="institution">ACM, New York, NY, USA</rs>, 46 pages. https: //doi.org/XXXXXXX.XXXXXXX</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>//aigc.aminer.cn/xdai/chat?xdid=%23xd%E5%B0%8F%E7%9F%A5%E5%91% 86001 2 https://aigc.aminer.cn/racetrack 3 https://github.com/RUCKBReasoning/GLM-Dialog</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How long is the Yangtze River? ????6633???????????? With a length of 6,633km, the Yangtze River is the longest river in China.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?????(????)</head><p>What about the Yellow River? (Ellipse) ?????????5464??????????????????? The Yellow River is about 5,464 kilometers long, originating from the Qinghai-Tibet Plateau. It is the second longest river in China.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>???????????(????)</head><p>And where is its estuary? (Coreference)        </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Catherine de Vulpilli?res, and H?l?ne Sauz?on. 2022. Conversational agents for fostering curiosity-driven learning in children</title>
		<author>
			<persName><forename type="first">Rania</forename><surname>Abdelghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Yves</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edith</forename><surname>Law</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">167</biblScope>
			<biblScope unit="page">102887</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxian</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.09519</idno>
		<title level="m">Plato-xl: Exploring the large-scale pre-training of dialogue generation</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">PLATO-K: Internal and External Knowledge Enhanced Dialogue Generation</title>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00910</idno>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Revisiting Pre-Trained Models for Chinese Natural Language Processing</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13922</idno>
		<ptr target="https://arxiv.org/abs/2004.13922" />
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.01241</idno>
		<title level="m">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unified language model pretraining for natural language understanding and generation</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hsiao-Wuen</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">GLM: General Language Model Pretraining with Autoregressive Blank Infilling</title>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="320" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A knowledge-grounded neural conversation model</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.09313</idno>
		<title level="m">Eva2. 0: Investigating opendomain chinese dialogue systems with large-scale pre-training</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzhu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.09313</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2203.09313" />
		<title level="m">EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Dureader: a chinese machine reading comprehension dataset from real-world applications</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaoqiao</forename><surname>She</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05073</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Survey of hallucination in natural language generation</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rita</forename><surname>Frieske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etsuko</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers</title>
		<author>
			<persName><forename type="first">Boseop</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoungseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Woo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gichang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghyun</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeon</forename><surname>Dong Hyeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungju</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonhoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongpil</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3405" to="3424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Controlling Conditional Language Models without Catastrophic Forgetting</title>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Korbak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hady</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">German</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11499" to="11528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Dataset and neural recurrent sequence labeling model for open-domain factoid question answering</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengyan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06275</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Hua</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.14165</idno>
		<title level="m">Towards Boosting the Open-Domain Chatbot with Human Feedback</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elnaz</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.11309</idno>
		<title level="m">Godel: Large-scale pretraining for goal-directed dialog</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">DRCD: A Chinese machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Chieh</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trois</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiying</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><surname>Tsai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00920</idno>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dialogue in the wild: Learning from a deployed role-playing game with humans and bots</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="611" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mojtaba</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Ung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kushal</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.03188</idno>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Lamda: Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Naturalconv: A chinese dialogue dataset towards multi-turn topic-driven conversation</title>
		<author>
			<persName><forename type="first">Xiaoyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianqiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="14006" to="14014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A large-scale chinese short-text conversation dataset</title>
		<author>
			<persName><forename type="first">Yida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF International Conference on Natural Language Processing and Chinese Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="91" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semiotic mediation, dialogue and the construction of knowledge</title>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human development</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="244" to="274" />
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Proactive human-machine conversation with explicit conversation goals</title>
		<author>
			<persName><forename type="first">Wenquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongzhong</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05572</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Bright</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3402023</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3402023" />
		<title level="m">NLP Chinese Corpus: Large Scale Chinese Corpus for NLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Augmenting end-to-end dialogue systems with commonsense knowledge</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iti</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subham</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">XDAI: A Tuning-free Framework for Exploiting Pre-trained Language Models in Knowledge Grounded Dialogue Generation</title>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanyu</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4422" to="4432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Aohan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanyu</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weng</forename><surname>Lam Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jidong</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenguang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02414</idno>
		<title level="m">GLM-130B: An Open Bilingual Pre-trained Model</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Shulin Cao, and Xin Lv. 2023. A survey on complex factual question answering</title>
		<author>
			<persName><forename type="first">Lingxi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xirui</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinmei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhonghui</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Personalizing Dialogue Agents: I have a dog, do you have pets too</title>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">HOSMEL: A Hot-Swappable Modularized Entity Linking Toolkit for Chinese</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zhang-Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaokang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2022.acl-demo.21" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Knowledge-Grounded Dialogue Generation with Pre-trained Language Models</title>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3377" to="3390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Medical Dialogue Response Generation with Pivotal Information Recalling</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4763" to="4771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dialoglm: Pre-trained model for long dialogue understanding and summarization</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11765" to="11773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14000</idno>
		<title level="m">Link the World: Improving Open-domain Conversation with Dynamic Spatiotemporal-aware Knowledge</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Kd-Conv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledgedriven Conversation</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaili</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7098" to="7108" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
