<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Asynchronous spiking neural P systems with local synchronization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012-07-24">24 July 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tao</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Laboratory of Image Processing and Intelligent Control</orgName>
								<orgName type="department" key="dep2">Department of Control Science and Engineering</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<addrLine>Wuhan 430074</addrLine>
									<settlement>Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Linqiang</forename><surname>Pan</surname></persName>
							<email>lqpan@mail.hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Key Laboratory of Image Processing and Intelligent Control</orgName>
								<orgName type="department" key="dep2">Department of Control Science and Engineering</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<addrLine>Wuhan 430074</addrLine>
									<settlement>Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gheorghe</forename><surname>Pa ˘un</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">University of Sevilla</orgName>
								<orgName type="institution" key="instit2">Avda. Reina Mercedes, s/n</orgName>
								<address>
									<postCode>41012</postCode>
									<settlement>Sevilla</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Mathematics of the Romanian Academy</orgName>
								<address>
									<addrLine>014700 Bucures ßti</addrLine>
									<postBox>PO Box 1-764</postBox>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Asynchronous spiking neural P systems with local synchronization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2012-07-24">24 July 2012</date>
						</imprint>
					</monogr>
					<idno type="MD5">5C77D934AAEBFE7601D72F3F138A80BE</idno>
					<idno type="DOI">10.1016/j.ins.2012.07.023</idno>
					<note type="submission">Received 6 February 2012 Received in revised form 9 June 2012 Accepted 15 July 2012</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T02:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Bio-inspired computing Spiking neural P system Turing completeness Asynchronization Local synchronization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spiking neural P systems (SN P systems, for short) are a class of distributed parallel computing devices inspired from the way neurons communicate by means of spikes. Asynchronous SN P systems are non-synchronized systems, where the use of spiking rules (even if they are enabled by the contents of neurons) is not obligatory. It remains open whether asynchronous SN P systems with standard spiking rules are equivalent with Turing machines. In this paper, with a biological inspiration (in order to achieve some specific biological functioning, neurons from the same functioning motif or community work synchronously to cooperate with each other), we introduce the notion of local synchronization into asynchronous SN P systems. The computation power of asynchronous SN P systems with local synchronization is investigated. Such systems consisting of general neurons (respectively, unbounded neurons) and using standard spiking rules are proved to be universal. Asynchronous SN P systems with local synchronization consisting of bounded neurons and using standard spiking rules characterize the semilinear sets of natural numbers. These results show that the local synchronization is useful, it provides some ''programming capacity'' useful for achieving a desired computation power.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Membrane computing is one of the recent branches of natural computing. It was initiated in <ref type="bibr" target="#b15">[16]</ref> and has developed rapidly (already in 2003, Information Sciences Institute considered membrane computing as a ''fast emerging research area in computer science'', see http://esi-topics.com). The aim is to abstract computing ideas (data structures, operations with data, ways to control operations, computing models, etc.) from the structure and the functioning of a single cell and from complexes of cells, such as tissues and organs, including the brain. The obtained models are distributed and parallel computing devices, usually called P systems. There are three main classes of P systems investigated: cell-like P systems (based on a cell-like (hence hierarchical) arrangement of membranes delimiting compartments where multisets of chemicals evolve according to given evolution rules) <ref type="bibr" target="#b15">[16]</ref>, tissue-like P systems (instead of hierarchical arrangement of membranes, one considers arbitrary graphs as underlying structures, with membranes placed in the nodes, and with the edges corresponding to communication channels) <ref type="bibr" target="#b10">[11]</ref>, and neural-like P systems. Many variants of all these systems have been considered; an overview of the field can be found in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, with up-to-date information available at the membrane computing website (http:// ppage.psystems.eu). For an introduction to membrane computing, one may consult <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. The present work deals with a class of neural-like P systems, called spiking neural P systems (SN P systems, for short), introduced in <ref type="bibr" target="#b6">[7]</ref>.</p><p>SN P systems are a class of distributed and parallel computing models inspired by spiking neurons. As we know, neurons are one of the most interesting cell-types in the human body. A large number of neurons working in a cooperative manner are able to perform tasks (such as thought, self-awareness, intuition) that are not yet matched by the tools we can build with our current technology. However, we believe that the distributed manner in which the brain processes information is important in obtaining better performance for electronic computers, that is why we are interested in SN P systems defined as a computation model. We stress that in this work SN P systems are a subject of a theoretical computer science investigation, without any intention to propose a platform for modeling biological processes.</p><p>Briefly, an SN P system consists of a set of neurons placed in the nodes of a directed graph, where neurons send signals (called spikes and denoted by the symbol a in what follows) along synapses (arcs of the graph). Spikes evolve by means of standard spiking rules, which are of the form E/a c ? a; d, where E is a regular expression over {a} and c, d are natural numbers, c P 1, d P 0. The meaning is that if a neuron contains k spikes such that a k 2 L(E) and k P c, then it can consume c spikes and produce one spike after a delay of d steps. This spike is sent to all neurons connected by an outgoing synapse starting in the neuron where the rule was applied. There are also standard forgetting rules, of the form a s ? k, with the meaning that s P 1 spikes are forgotten if the neuron contains exactly s spikes. Extended rules were considered in <ref type="bibr" target="#b2">[3]</ref>: these rules are of the form E/a c ? a p ; d, with the meaning that when using this rule, c spikes are consumed and p spikes are produced. Because p can be 0 or greater than 0, we obtain a generalization of both standard spiking and forgetting rules.</p><p>A rule is bounded if it is of the form a i /a c ? a p ; d, where 0 &lt; c 6 i, 0 &lt; p 6 c, d P 0. A neuron is bounded if it contains only bounded rules. A rule is called unbounded if it is of the form a i (a j ) ⁄ /a c ? a p ; d, with i P 0, j P 1, c P p &gt; 0, d P 0. (Note that also rules of the form a i (a j ) + /a c ? a p ; d are covered, as they can be rewritten in the form a i+j (a j ) ⁄ /a c ? a p ; d.) A neuron is unbounded if it contains only unbounded rules. A neuron is general if it contains both bounded and unbounded rules. An SN P system is bounded if all neurons in the system are bounded. It is unboundedif it has both bounded and unbounded neurons. An SN P system is general if it contains at least one general neuron (i.e., a neuron containing both bounded and unbounded rules).</p><p>An SN P system works in a synchronized manner. A global clock is assumed, and in each time unit, the rule to be applied in each neuron is non-deterministically chosen; one rule must be applied in each neuron with applicable rules. The work of the system is sequential in each neuron: only (at most) one rule is applied in each neuron. One of the neurons is considered to be the output one, and its spikes are also sent to the environment. The moments of time when a spike is emitted by the output neuron are marked with 1, and the other moments are marked with 0. This binary sequence is called the spike train of the system; it might be infinite if the computation does not stop. Various numbers can be associated with a spike train, which can be considered as computed (or generated) by an SN P system.</p><p>Synchronized SN P systems using standard rules were proved to be computationally complete both in the generating and the accepting case <ref type="bibr" target="#b6">[7]</ref>. In the proof of these results, the synchronization plays a crucial role. The investigation of synchronization is an important and well studied topic in networks as shown in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>.</p><p>Both from a mathematical point of view and from a neuro-biological point of view, it is rather natural to consider non-synchronized systems, where the use of rules is not obligatory. Even if a neuron has a rule enabled in a given time unit, this rule is not obligatorily used. The neuron may remain unfired, maybe receiving spikes from the neighboring neurons. If the unused rule may be used later, it is used later, without any restriction on the interval when it has remained unused. If further spikes made the rule non-applicable, then the computation continues in the new circumstances (maybe other rules are enabled now). With this motivation, asynchronous SN P systems were introduced in <ref type="bibr" target="#b1">[2]</ref>. It was proved that asynchronous general SN P systems with extended rules are equivalent with Turing machines; asynchronous unbounded SN P systems with extended rules are not universal. The languages generated by asynchronous spiking neural P systems were investigated in <ref type="bibr" target="#b25">[26]</ref>. Small asynchronous general SN P systems were investigated in <ref type="bibr" target="#b14">[15]</ref>, where it was proved that there is an asynchronous spiking neural P system with 76 neurons that is equivalent to a universal register machine for computing functions. In <ref type="bibr" target="#b13">[14]</ref>, astrocytes were introduced into asynchronous SN P systems, where astrocytes have excitatory and inhibitory influence on synapses; it was proved that asynchronous spiking neural P systems with astrocytes and using extended spiking rules are universal.</p><p>It is an open problem whether asynchronous general SN P systems with standard rules are universal. In this work, with a biological inspiration, we introduce the notion local synchronization into asynchronous SN P systems. Actually, the notion local synchronization was already considered in other fields such as artificial neural networks <ref type="bibr" target="#b4">[5]</ref> and complex networks <ref type="bibr" target="#b24">[25]</ref>.</p><p>In a biological neural system, motifs with 4-5 neurons and communities with 12-15 neurons, associated with some specific functioning, are rather common <ref type="bibr" target="#b0">[1]</ref>. The neurons from the same motif or community will work synchronously to cooperate with each other. That is, in a biological neural system, neurons work asynchronously at the global level, but neurons from the same functioning motif or community work synchronously at the local level. With this biological inspiration, we introduce asynchronous SN P systems with local synchronization, where a family of sets of neurons (we call them ls-sets) is specified; if one of the neurons from an ls-set fires, then all neurons from this set should fire, provided that they have enabled rules. Of course, it is possible that all neurons from an ls-set remain unfired even if they have enabled rules, because of the global asynchronous mode.</p><p>In this work, we prove that asynchronous general or unbounded SN P systems with local synchronization using standard rules are universal; in the bounded case a characterization of semilinear sets of numbers is obtained.</p><p>In the asynchronous SN P systems constructed in <ref type="bibr" target="#b1">[2]</ref>, the non-determinism comes from two resources: (1) the asynchronous mode; (2) the non-deterministic choice of enabled rules to be applied. Each neuron of a system constructed in the present paper works in a deterministic way, in the sense that at each step each neuron has at most one enabled rule; however, the whole system works in a non-deterministic way because of the asynchronous mode.</p><p>In the proofs of the universality results in this work, the feature of local synchronization plays a crucial role. An asynchronous general SN P system with standard rules loses this ''programming capacity'' ensured by the extended rules and the local synchronization. So, our research gives some hint to support the conjecture that an asynchronous general SN P system with standard rules is non-universal <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>It is useful for readers to have some familiarity with basic elements of language theory, e.g., from <ref type="bibr" target="#b19">[20]</ref>, as well as basic membrane computing <ref type="bibr" target="#b16">[17]</ref>. We here only introduce the necessary prerequisites.</p><p>The set of natural numbers is denoted by N.</p><p>For an alphabet V, V ⁄ denotes the set of all finite strings of symbols from V; the empty string is denoted by k, and the set of all non-empty strings over V is denoted by V + . When V = {a} is a singleton, we write simply a ⁄ and a + instead of {a} ⁄ , {a} + .</p><p>A regular expression over an alphabet V is defined as follows: (i) k and each a 2 V is a regular expression, (ii) if E 1 , E 2 are regular expressions over V, then (E 1 ) (E 2 ), (E 1 ) [ (E 2 ), and (E 1 ) + are regular expressions over V, and (iii) nothing else is a regular expression over V. With each regular expression E we associate a language L(E), defined in the following way: (i) L(k) = {k} and L(a) = {a}, for all a 2 V, (ii)</p><formula xml:id="formula_0">L((E 1 ) [ (E 2 )) = L(E 1 ) [ L(E 2 ), L((E 1 )(E 2 )) = L(E 1 )L(E 2 )</formula><p>, and L((E 1 ) + ) = (L(E 1 )) + , for all regular expressions E 1 , E 2 over V. Unnecessary parentheses can be omitted when writing a regular expression, and (E) + [ {k} can also be written as E ⁄ .</p><p>By SLIN, NRE we denote the families of semilinear and of Turing computable sets of numbers. (SLIN is the family of length sets of regular languages -languages characterized by regular expressions; NRE is the family of length sets of recursively enumerable languages -those recognized by Turing machines.)</p><p>In the proofs of the results about universality in this work, the notion of a register machine is used. A register machine is a construct M = (m, H, l 0 , l h , R), where m is the number of registers, H is the set of instruction labels, l 0 is the start label, l h is the halt label (assigned to instruction HALT), and R is the set of instructions; each element of H labels only one instruction from R, thus precisely identifying it. The instructions are of the following forms: l i : (ADD(r), l j , l k ) (add 1 to register r and then go to one of the instructions with labels l j , l k ), l i : (SUB(r), l j , l k ) (if register r is non-zero, then subtract 1 from it, and go to the instruction with label l j ; otherwise, go to the instruction with label l k ), l h : HALT (the halt instruction).</p><p>A register machine M computes (generates) a number n in the following way. The register machine starts with all registers empty (i.e., storing the number zero). It applies the instruction with label l 0 and proceeds to apply instructions as indicated by labels (and, in the case of SUB instructions, by the contents of registers). If the register machine reaches the halt instruction, then the number n stored at that time in the first register is said to be computed by M. The set of all numbers computed by M is denoted by N(M). It is known that register machines compute all sets of numbers which are Turing computable, hence they characterize NRE <ref type="bibr" target="#b11">[12]</ref>.</p><p>Without loss of generality, it can be assumed that l 0 labels an ADD instruction, that in the halting configuration all registers different from the first one are empty, and that the output register is never decremented during the computation (its content is only added to).</p><p>A strongly monotonic register machine is a non-deterministic machine with only one register (this is also the output register). This register is initially zero and can only be incremented by 1 at each computation step (that is why we call such a machine strongly monotonic). When the machine halts, the value stored in the register is said to be generated. It is known that a set of natural numbers is semilinear if and only if it can be generated by a strongly monotonic register machine.</p><p>A register machine can also be used in the accepting mode: one starts with all registers empty, except one specified register, the input one, where a number x is introduced; the computation starts (with instruction with label l 0 ) and, if it halts, then the number x is accepted. In this way, again all sets of numbers from NRE are characterized. Furthermore, a register machine can be used for computing functions u : N ! N: certain registers are designated as input registers and a specific one as the output register; numbers x 1 , . . ., x k are introduced in the input registers and the value of a function u(x 1 , . . ., m k ) is obtained in the output register -providing that u is defined for x 1 , x 2 , . . ., x k , otherwise the computation never halts. Turing computable functions can be computed in this way.</p><p>We use the following convention. When the power of two number generating/accepting devices D 1 and D 2 are compared, number zero is ignored, that is, N(D 1 ) = N(D 2 ) if and only if N(D 1 ) À {0} = N(D 2 ) À {0} (this corresponds to the usual practice of ignoring the empty string in language and automata theory).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Asynchronous spiking neural P systems with local synchronization</head><p>In this section, we introduce the variant of SN P systems investigated in this work -asynchronous spiking neural P systems with local synchronization. The definition is complete, but familiarity with the basic elements of classic SN P systems (e.g., from <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>) is helpful.</p><p>An asynchronous spiking neural P system (without delay) with local synchronization is a construct of the form: P ¼ ðO; r 1 ; r 2 ; . . . ; r m ; Loc; syn; outÞ; where m P 1 is the degree of the system; O = {a} is the singleton alphabet (a is called spike); r 1 , r 2 , . . ., r m are neurons of the form r i = (n i , R i ) with 1 6 i 6 m, where 1. n i P 0 is the initial number of spikes contained in r i ; 2. R i is a finite set of extended rulesof the following form: E/a c ? a p , where E is a regular expression over O, c P 1 and c P p P 0;</p><p>Loc ¼ floc 1 ; loc 2 ; . . . ; loc l g # Pðfr 1 ; r 2 ; . . . ; r m gÞ is the family of sets of locally synchronous neurons (we call these sets lssets), where Pðfr 1 ; r 2 ; . . . ; r m gÞ is the power set of {r 1 , r 2 , . . ., r m }; the number max{jloc 1 j, jloc 2 j, . . . , jloc l j} is the local synchronization degree of the system; syn # {1, 2, . . . , m} Â {1, 2, . . ., m} with (i, i) R syn is the set of synapses between neurons; out 2 {1, 2, . . . , m} indicates the output neuron.</p><p>A rule E/a c ? a p with p P 1 is called extended firing (we also say spiking) rule; a rule E/a c ? a p with p = 0 is written in the form E/a c ? k and is called a forgetting rule. If L(E) = {a c }, then the rules are written in the simplified forms a c ? a p and a c ? k. A rule of the type E/a c ? a and a c ? k is said to be standard.</p><p>The rules are applied as follows. If neuron r i contains k spikes and a k 2 L(E), k P c, then the rule E/a c ? a p 2 R i is enabled and can be applied. This means that c spikes are consumed (thus k À c spikes remain in neuron r i ), the neuron is fired, and it produces p spikes. The p spikes emitted by a neuron r i are replicated and they go to all neurons r j such that (i, j) 2 syn (each neuron r j receives p spikes). Every neuron can contain several rules. Because two firing rules, E 1 =a c 1 ! a p 1 and E 2 =a c 2 ! a p 2 , can have L(E 1 ) \ L(E 2 ) -;, it is possible that two or more spiking rules are enabled in a neuron at some moment, and then one of them is chosen non-deterministically.</p><p>If the rule is a forgetting one of the form E/a c ? k, then, when it is applied, c P 1 spikes are removed. A global clock is assumed, marking the time for all neurons. In each time unit, any neuron is free to use a rule or not, i.e., a neuron can remain still in spite of the fact that it contains rules which are enabled by its contents. If the content of the neuron is not changed, a rule which is enabled in a given step can fire later. If new spikes are received, then it is possible that other rules will be enabled and applied or not. Furthermore, for neurons in the same ls-set loc j , if one of these neurons fires, then all neurons in loc j that have enabled rules should fire. Of course, it is possible that all neurons from loc j remain unfired even if they have enabled rules. That is, all neurons from loc j may remain still, or all neurons from loc j with enabled rules fire at a same step (of course, neurons without enabled rules cannot fire). Hence, neurons work asynchronously at the global level, but neurons in each ls-set work synchronously.</p><p>The ''state'' of the system at a given time is described by the number of spikes present in each neuron. That is, the configuration of the system is of the form hr 1 , r 2 , . . ., r m i for r i P 0, which indicates that neuron r i contains r i spikes. With this notation, the initial configuration of the system is hn 1 , n 2 , . . . , n m i. By using the rules as described above, one can define transitions among configurations. Any series of transitions starting from the initial configuration is called a computation. A computation is successful if it reaches a configuration where no rule can be applied in any neuron (i.e., the SN P system has halted). The result of a computation is defined here as the total number of spikes sent into the environment by the output neuron. (Because of the asynchronous mode, now ''the time does not matter''. The output neuron can remain still for any number of steps between two consecutive spikes, therefore the result of a computation can no longer be defined in terms of the steps between two consecutive spikes as in the standard SN P systems definition.) Specifically, a number x is generated by an SN P system if there is a halting computation of the system where the output neuron emits exactly x spikes (if several spikes are emitted at the same time, all of them are counted). Because of the nondeterminism in using the rules, a given system computes in this way a set of numbers.</p><p>The rules, the neurons, and the SN P systems are called bounded, unbounded, or general as defined in the Introduction -the definitions are obvious, so we do not recall them here.</p><p>Asynchronous SN P systems with local synchronization can be used as computing devices in various ways, but here we consider them only as generators of numbers. We denote by N(P) the set of numbers generated by an asynchronous SN P system with local synchronization P, and by NSpik out P locsyn m ða; lsÞ with a 2 {gen, boun, unb} and ls P 0, the family of such sets of numbers generated by systems of type a (gen stands for general, boun for bounded, unb for unbounded), with at most m neurons, and local synchronization degree at most ls. If one of the parameters m and ls is not bounded, then it is replaced with ⁄. The subscript out reminds us of the fact that we count all spikes sent into the environment as computation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Asynchronous general SN P systems with local synchronization</head><p>In this section, we investigate the computation power of asynchronous general SN P systems with local synchronization, and we prove that such systems using standard rules are universal. It was formulated as an open problem whether asynchronous SN P systems with standard rules are universal and it was conjectured that the answer is negative in <ref type="bibr" target="#b1">[2]</ref>. So, the feature of local synchronization provides a useful ''programming capacity''.</p><p>As it is usual in the area of spiking neural P systems, asynchronous SN P systems with local synchronization are represented graphically, which may be easier to understand than in a symbolic way. We use an oval with rules inside to represent a neuron, and a directed graph to represent the structure of the system: the neurons are placed in the nodes of the graph and the edges represent the synapses; the output neuron has an outgoing arrow, suggesting its communication with the environment.</p><p>Theorem 4.1. NRE ¼ NSpik out P locsyn Ã ðgen; ÃÞ. Proof 1. We only have to prove that NRE # NSpik out P locsyn Ã ðgen; ÃÞ, since the converse inclusion is straightforward (or we can invoke for it the Turing-Church thesis). To this aim, we use the characterization of NRE by means of generating register machines. Let us consider a register machine M = (m, H, l 0 , l h , I). As mentioned in Section 2, without any loss of generality, we may assume that in the halting configuration, all registers different from register 1 are empty, and that the output register is never decremented during a computation. For each register r of M, let s r be the number of SUB instructions acting on register r. If there is no such SUB instruction, then s r = 0, which is the case for the first register r = 1. In what follows, a specific asynchronous SN P system with local synchronization P will be constructed to simulate the register machine M, where each neuron in system P has only standard rules.</p><p>The system P consists of three types of modules -ADD modules, SUB modules, and a FIN module. ADD modules and SUB modules are used to simulate the ADD and SUB instructions of M, respectively; the FIN module is used to output a computation result.</p><p>In general, a neuron r r is associated with each register r of M; the number stored in register r is encoded by the number of spikes in neuron r r . Specifically, if register r holds the number n P 0, then neuron r r contains 2n spikes. With each label l i of an instruction in M, a neuron r l i is associated. In the initial configuration, all neurons are empty, with the exception of neuron r l 0 associated with the initial instruction l 0 of M, which contains one spike. During a computation, a neuron r l i having one spike inside will become active and starts to simulate an instruction l i : (OP(r), l j , l k ) of M: starting with neuron r l i activated, one changes neuron r r as requested by OP, then one introduces one spike into neuron r l j or neuron r l k , which becomes active in this way. When neuron r l h (associated with the label l h of the halting instruction of M) is activated, a computation in M is completely simulated in P; the FIN module starts to output the computation result (the number of spikes sent into the environment by the output neuron corresponds to the number stored in register 1 of M).</p><p>In what follows, the modules ADD, SUB, and FIN are given in the standard graphical way, also specifying their ls-sets, and their work is briefly analyzed.</p><p>Module ADD (shown in Fig. <ref type="figure">1</ref>) -simulating an ADD instruction l i : (ADD(r), l j , l k ). The initial instruction of M, the one with label l 0 , is an ADD instruction. Let us assume that at step t, an instruction l i :</p><p>(ADD(r), l j , l k ) has to be simulated, with one spike present in neuron r l i (like r l 0 in the initial configuration) and no spike in any other neurons, except in those neurons associated with registers. Having one spike inside, the rule a ? a is enabled, neuron r l i can fire, and at some time it will do it (otherwise, the computation does not halt), sending one spike to neurons r l ð1Þ way, the number of spikes in neuron r r is increased by two, which corresponds to the fact that the number stored in register r is increased by one. For neuron r l ð3Þ i , we have two possible cases.</p><p>( step by the rule a 3 ? a, and send one spike to neuron r l j . After neuron r l j receives one spike, it becomes active, starting to simulate the instruction l j of M.</p><p>When neuron r l j fires, it is possible that neuron r l ð6Þ i still contains three spikes because of non-synchronization. In this case, neuron r l ð6Þ i should also fire (because they are in the same ls-set) at the same step removing all three spikes, which insures that no spike remains in the module (except those in r r ).</p><p>( Therefore, after firing neuron r l i , the system adds two spikes to neuron r r and non-deterministically fires one of neurons r l j and r l k , which correctly simulates the ADD instruction l i : (ADD(r), l j , l k ).</p><p>Module SUB (shown in Fig. <ref type="figure">2</ref>) -simulating a SUB instruction l i : (SUB(r), l j , l k ).</p><p>A SUB instruction l i is simulated in P in the following way. Initially, neuron r l i has one spike, and other neurons are empty, except the neurons associated with registers. With one spike inside, the rule a ? a in neuron r l i is enabled, and it will fire at some step sending one spike to neurons r l ð1Þ i ; r l ð2Þ i , and r r . These neurons will fire simultaneously, because they are in the same ls-set. For neuron r r , there are two cases.</p><p>(1) Before receiving one spike from neuron r l i , neuron r r contains 2n (n &gt; 0) spikes (corresponding to the fact that the number stored in register r is n, and n &gt; 0). In this case, neuron r r gets 2n + 1 spikes and the rule a(a 2 ) + /a 3 ? a is enabled. So, when neurons r l ð1Þ i ; r l ð2Þ i , and r r fire at some step, they send three spikes to each of neurons r l ð3Þ i and r l ð4Þ i . In neuron r r , three spike are consumed, ending with 2n + 1 À 3 = 2(n À 1) spikes, which simulates the fact that the number stored in register r is decreased by one. With three spikes inside, neuron r l ð3Þ i can fire, sending one spike to neuron r l j , hence neuron r l j will become active, and the system P starts to simulate instruction l j of M. When neuron r l j fires, it is possible that neuron r l ð4Þ i also contains three spikes because of non-synchronization. In this case, all neurons r l ð4Þ s should also fire (because they are in the same ls-set r l ð4Þ 1 ; r l ð4Þ 2 ; . . . ; r l ð4Þ sr ; r l j n o ) removing simultaneously the three spikes, hence these neurons return to the initial state, with no spike inside.</p><p>(2) When receiving one spike from neuron r l i , neuron r r has no spike inside (corresponding to the fact that the number stored in register r is 0). In this case, after neuron r r receives one spike from neuron r l i , the rule a ? k in neuron r r is enabled. When neurons r l ð1Þ i ; r l ð2Þ i , and r r fire at some step, they send two spikes to each of neurons r l ð3Þ i and r l ð4Þ i . In neuron r r , one spike is consumed, ending with 0 spikes, which means that the number stored in register r of M is zero.</p><p>With two spikes inside, neuron r l ð4Þ i can fire, sending one spike to neuron r l k , hence neuron r l k will become active, and the system P starts to simulate instruction l k of M. Similar to case (1), the ls-set r l ð3Þ 1 ; r l ð3Þ 2 ; . . . ; r l ð3Þ sr ; r l k n o ensures that no ''wrong'' step is done in system P. The simulation of SUB instruction is correct: system P starts from spiking neuron r l i and ends in firing neuron r l j (if the number stored in register r is greater than 0 and it was decreased by one), or in firing neuron r l k (if the number stored in register r is 0).</p><p>Note that there is no interference between the ADD modules and the SUB modules, other than correctly firing the neurons r l j or r l k , which may label instructions of the other kind. However, it is possible to have interferences between two SUB modules. Specifically, if there are several SUB instructions l v that act on the same register r, then neuron r r has synapses to all neurons r l ð3Þ v and r l ð4Þ v</p><p>. When a SUB instruction l i : (SUB(r), l j , l k ) is simulated, in the SUB module associated with l v (l v -l i ) all neurons receive no spike except for neurons r l ð3Þ v and r l ð4Þ v , each of them having one spike inside. Because we have the ls-sets ) (l v -l i ) should also fire at the same step removing its spike. Consequently, the interference among SUB modules will not cause undesired steps in P (i.e., steps that do not correspond to correct simulations of instructions of M).</p><formula xml:id="formula_3">r l<label>ð3Þ</label></formula><formula xml:id="formula_4">1 ; r l<label>ð3Þ</label></formula><p>Module FIN (shown in Fig. <ref type="figure" target="#fig_6">3</ref>) -outputting the result of computation.</p><p>The functioning of this module is obvious: after activating the neuron r l h , neuron r 1 outputs one spike for each two spikes present inside; the last spike remains idle in the system. From the above description of the modules and of their work, it is clear that the register machine M is correctly simulated by the system P. Therefore, N(P) = N(M), and this completes the proof. h</p><p>In Theorem 4.1, the number m of neurons and the local synchronization degree ls are not bounded (thus, denoted by ⁄). As expected, these parameters can be bounded by making use of the fact that there are (small) universal register machines. Such machines are given, e.g., in <ref type="bibr" target="#b7">[8]</ref>, but they are used in the accepting mode: the code of a particular register machine is introduced in register 1, an input for the particular machine is introduced in register 2, and the result is obtained in register 0. The universal machine halts if and only if the particular machine halts for the given input. The problem which remains to be solved is to pass from such an universal register machine to a generative SN P system. Proof 2. Consider the universal register machine M u from <ref type="bibr" target="#b7">[8]</ref> as shown in Fig. <ref type="figure">4</ref>. It takes the code code(M) of a particular register machine M which computes a function u in register 1 and a number x in register 2, and outputs the value of u(x) in register 0. Take an arbitrary set K in NRE and consider its membership function u K : N ! f0; 1g. There is a register machine M K computing this function. Starting with a number x in its input register, M K halts if and only if x 2 K, hence u K (x) = 1. Let code(M K ) be its code; we introduce code(M K ) in register 1 of M u , thus obtaining a register machine M u (K). It takes any natural number n (in register 2) and halts (with 1 in register 0) if and only if n 2 K. We modify M u (K) as follows. A further register is added, labeled with 8; consider two further labels, l À1 , l À2 , with l À1 being the initial label of the machine we want to obtain. Consider also the instructions l À1 : (ADD(2), l À2 , l À2 ), l À2 : (ADD(8), l À1 , l 0 ), where l 0 is the start label of M u . The register machine M 0 obtained in this way has 9 registers, 11 ADD and 13 SUB instructions, and 25 labels; the result of a computation is stored </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>A universal register machine M u from Korec <ref type="bibr" target="#b7">[8]</ref>.</p><p>in register 8, which is never decremented during a computation. Clearly, n 2 N(M 0 ) if and only if u K (n) = 1, hence n 2 K, therefore N(M 0 ) = K: M 0 first ''proposes'' a number x to machine M u (K), by introducing it both in register 2, as needed for M u and in register 8, the output one of M 0 ; when the computation of M u (K) halts, also the computation of M 0 halts. Therefore, the number x is accepted and the computation of M 0 halts if and only if x 2 K.</p><p>As in the proof of Theorem 4.1, we can construct an asynchronous SN P system with local synchronization P M 0 to simulate the register machine M 0 . The system P M 0 has 9 neurons for the 9 registers, 25 neurons for the 25 labels, 6 Â 11 neurons for the 11 ADD instructions, 4 Â 13 neurons for the 13 SUB instructions, which gives a total of 152 neurons. The maximal size of ls-sets in the ADD module shown in Fig. <ref type="figure">1</ref> is 2; the maximal size of ls-sets in the SUB module shown in Fig. <ref type="figure">2</ref> is max{3, s r + 1}, where s r is the number of SUB instructions acting on register r; the maximal size of ls-sets in the FIN module shown in Fig. <ref type="figure" target="#fig_6">3</ref> is 0. So, the local synchronization degree is not more than max{3, s r + 1}. We can check that register 5 in M 0 u has 4 SUB instructions, which is maximal, hence max{3, s r + 1} = 5. Therefore, our corollary holds. h</p><p>The above way of passing from computing universal register machines to register machines used in the generative way can be used in all results in membrane computing which show the computational completeness of a class of P systems by means of proofs based on the simulation of register machines. In this way, bounds on many parameters of the resulting P systems can be obtained. Note that many such bounds were reported in membrane computing (obtained by directly simulating a generating register machine), but no such result was reported for the number of neurons in SN P systems which characterize NRE. For instance, all universality results given in Chapter 13 of <ref type="bibr" target="#b17">[18]</ref> are stated for SN P systems with arbitrarily many neurons. All these results can be improved from this point of view by using the technique from the proof of the previous corollary. Actually, also the number of rules in an SN P system should be considered (neurons can be saved by putting in the same neuron several rules), hence a double hierarchy should be discussed: number of neurons and number of rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Asynchronous unbounded SN P system with local synchronization</head><p>In <ref type="bibr" target="#b1">[2]</ref> it was proved that asynchronous unbounded SN P systems with extended rules can only characterize SLIN. In this section, making use of the ''programming capability'' of local synchronization, we prove that asynchronous unbounded SN P systems with local synchronization can achieve the Turing completeness. Proof 3. We only have to prove that NRE # NSpik out P locsyn Ã ðunb; ÃÞ, since the converse inclusion is straightforward (or we can invoke for it the Turing-Church thesis). As in the proof of Theorem 4.1, let us consider a register machine M = (m, H, l 0 , l h , I), with the properties specified in Section 2. For each register r of M, let s r be the number of instructions of the form l i : (SUB(r), l j , l k ).</p><p>As in the proof of Theorem 4.1, we construct an SN P system P 0 consististing of three types of modules -ADD, SUB, and FIN. The first and the third types of modules can be easily obtained by modifying the ADD and FIN modules from Figs. <ref type="figure">1</ref> and<ref type="figure" target="#fig_6">3</ref>, respectively, while the SUB module is given in Fig. <ref type="figure">5</ref>.</p><p>Specifically, we observe that in the ADD and FIN modules from the proof of Theorem 3, all bounded neurons never contain more than three spikes. Then, each bounded rule a c ? a, a c ? k can be replaced with the unbounded rule a c (a 4 ) ⁄ /a c ? a, a c (a 4 ) ⁄ /a c ? k, respectively, and the functioning of modules ADD and FIN is not changed.</p><p>The difficulty with the module SUB from Fig. <ref type="figure">2</ref> is that the neurons r r contain both unbounded rules and the bounded rule a ? k, which we do not see how can be turned to an unbounded rule. That is why we present a different module SUB, more complex than that from Fig. <ref type="figure">2</ref>.</p><p>It is given in Fig. <ref type="figure">5</ref> and it works as follows.</p><p>The simulation of a SUB instruction l i : (SUB(r), l j , l k ) is started with neuron r l i having one spike. The rule a(a 2 ) ⁄ /a ? a is enabled and neuron r l i fires at some step, sending a spike to neurons r l ð1Þ i ; r l ð2Þ i and r r , respectively. For neuron r r , there are two cases.</p><p>(1) Neuron r r has 2n (n &gt; 0) spikes (corresponding to the fact that the number stored in register r is n, and n &gt; 0) before it receives one spike from neuron r l i . In this case, neuron r r gets 2n + 1 spikes and the rule a(a 2 ) + /a 3 ? a is enabled. When neurons r l ð1Þ i ; r l ð2Þ i , and r r fire at some step, they send three spikes to neuron r l ð3Þ i , as well as two spikes to neuron r l ð4Þ i . (Note that neuron r l ð8Þ i is in the same ls-set with neurons r l ð1Þ i , r l ð2Þ i , and r r , but it has no spike inside, so it cannot fire.) In neuron r r , three spikes are consumed, ending with 2n + 1 À 3 = 2(n À 1) spikes, which simulates the fact that the number stored in register r is decreased by one. Neuron r l ð3Þ i removes the three spikes inside by the forgetting rule a(a 2 ) + /a 3 ? k, meanwhile neuron r l ð4Þ i fires by the rule (a 2 ) + /a 2 ? a, sending one spike to neuron r l j , hence neuron r l j will become active, and the system P starts to simulate instruction l j of M.</p><p>(2) Neuron r r has no spike inside (corresponding to the fact that the number stored in register r is 0) before it receives one spike from neuron r l i .In this case, after neuron r r receives one spike from neuron r l i , it keeps inactive for no rule is enabled.Neurons r l ð1Þ . Therefore, neuron r l k becomes active, and the system P starts to simulate instruction l k of M. In neuron r r , there is no spike inside, which means that the number stored in register r of M is zero.</p><p>Note that it is possible to have interferences between two SUB modules. Specifically, if there are several SUB instructions l v that act on the same register r, then neuron r r has synapses to all neurons r l ð3Þ v and r l ð4Þ v . When a SUB instruction l i :</p><p>(SUB(r), l j , l k ) is simulated, in the SUB module associated with l v (l v -l i ) all neurons receive no spike except for neurons r l ð3Þ ðl v -l i Þ should also fire at the same step removing its spike. Consequently, the interference among SUB modules will not cause undesired steps in P (i.e., steps that do not correspond to correct simulations of instructions of M). Therefore, the simulation of SUB instruction is correct.</p><p>With the above description, we can see that the unbounded SN P system P 0 can correctly simulate register machine M, hence N(M) = N(P 0 ). h Similar with Corollary 4.1, we can also have the following corollary.  of spikes matter. In the above sense, SN P systems fall into the the third generation of neural network models <ref type="bibr" target="#b9">[10]</ref>. In contrast with the relatively rich theoretical results, the practical applications of SN P systems are few (although some attempts are already made, e.g., Hebbian learning in the framework of SN P systems <ref type="bibr" target="#b3">[4]</ref>). However, as a representative of the third generation of neural network models, spiking neural networks have very hands-on applications such as speech recognition, learning, associative memory, function approximation (e.g., in the full issue of Information Processing Letters, 95, 2005, and <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24]</ref>), and have proved useful in neuroscience. It is a research line for the future to make SN P systems towards applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>i ; r l ð2Þ i and r l ð3Þ i ,; r l ð2Þ i and r l ð3Þ i can fire; neurons r l ð1Þ i and r l ð2Þ iFig. 1 .;</head><label>ið2Þ1</label><figDesc>Fig. 1. Module ADD with four ls-sets r l ð1Þ i ; r l ð2Þ i n o ; r l ð3Þ i ; r l ð4Þ i n o ; r l ð5Þ i ; r l k n o and r l ð6Þ i ; r l j n o for simulating l i : (ADD(r), l j , l k ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>) Neuron r l ð3Þ i fires before neurons r l ð1Þ i and r l ð2Þ i; r l ð4Þ i n o . Neurons r l ð5Þ i and r l ð6Þ i receive one spike from neuron r l ð3Þ i and they keep inactive. After neurons r l ð3Þ i and r l ð4Þ i receive two spikes from neurons r l ð1Þ i and r l ð2Þ i , both of neurons r l ð3Þ i and r l ð4Þ i</head><label>ð2Þð4Þ</label><figDesc>fire. Note that, in this case, when neuron r l ð3Þ i fires, neuron r l ð4Þ i does not fire (it has no enabled rule), although neurons r l ð3Þ i and r l ð4Þ i are in the same ls-set r l ð3Þ i can fire, and they will fire at a same step, sending two spikes to neurons r l ð5Þ i and r l ð6Þ i . In this way, both of neurons r l ð5Þ i and r l ð6Þ i accumulate 3 spikes. With 3 spikes inside, neuron r l ð5Þ i can fire at any</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>) Neuron r l ð3Þ i fires after neurons r l ð1Þ i and r l ð2Þ i</head><label>ð2Þ</label><figDesc>fire. In this case, neuron r l ð3Þ i accumulates three spikes and neuron r l ð4Þ i has two spikes. Neurons r l ð3Þ i and r l ð4Þ i will fire at a same step. Similar to case (1), neuron r l k will become active, starting to simulate the instruction l k of M (at the same step ''cleaning'' neuron r l ð5Þ i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .; r l ð2Þ i ; rr n o ; r l ð3Þ 1 ; r l ð3Þ 2 ;; r l k n o and r l ð4Þ 1 ; r l ð4Þ 2 ;</head><label>21212</label><figDesc>Fig. 2. Module SUB with three ls-sets r l ð1Þ i ; r l ð2Þ i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 ;; r l k n o and r l ð4Þ 1 ; r l ð4Þ 2 ;</head><label>212</label><figDesc>. . . ; r l ð3Þ sr . . . ; r l ð4Þ sr ; r l j n o , when neuron r l ð3Þ i (resp. r l ð4Þ i ) fires, each of neurons r l ð3Þ v (resp. r l ð4Þ v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Corollary 4 . 1 .</head><label>41</label><figDesc>NRE ¼ NSpik out P locsyn 152 ðgen; 5Þ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The FIN module of P.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Theorem 5 . 1 .</head><label>51</label><figDesc>NRE ¼ NSpik out P locsyn Ã ðunb; ÃÞ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>i and r l ð2Þ i</head><label>ð2Þ</label><figDesc>fire at some step, sending two spikes to neuron r l ð3Þ i , as well as one spike to neuron r l ð4Þ i .With two spikes inside, neuron r l ð3Þ i can fire at some step, sending one spike to neurons r l ð5Þ i ; r l ð6Þ i , and r l ð7Þ i , respectively.At the same moment, neuron r l ð4Þ i removes the spike inside by the forgetting rule a(a 2 ) ⁄ /a ? k.Neurons r l ð5Þ i ; r l ð6Þ i , and r l ð7Þ i fire at some step sending two spikes to neuron r r and one spike to neuron r l ð8Þ i .After neuron r r receives the two spikes, it has three spikes inside and the rule a(a 2 ) + /a 3 ? a is enabled.Neurons r r and r l ð8Þ i fire at some moment, sending one spike to each of the neurons r l ð3Þ i ; r l ð4Þ i , and r l ð9Þ i .Neurons r l ð3Þ i ; r l ð4Þ i , and r l ð9Þ i fire at some step, removing the spikes in neurons r l ð3Þ i ; r l ð4Þ i and sending one spike to neuron r l k fromr l ð9Þ i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>v and r l ð4Þ v . 1 ; r l ð3Þ 2 ;; r l ð4Þ 1 ; n r l ð4Þ 2 ;; r l ð9Þ 1 ; r l ð9Þ 2 ;</head><label>v121212</label><figDesc>Each of neurons r l ð3Þ v and r l ð4Þ v has one spike inside. Because we have the ls-set r l ð3Þ . . . ; r l ð3Þ sr . . . ; r l ð4Þ sr . . . ; r l ð9Þ sr g, when neuron r l ð3Þ i and r l ð4Þ i fire, each of neurons r l ð3Þ v and r l ð4Þ v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Corollary 5 . 1 .</head><label>51</label><figDesc>NRE ¼ NSpik out P locsyn 217 ðunb; 12Þ. Indeed, the system P 0 has 9 neurons for the 9 registers, 25 neurons for the 25 labels, 6 Â 11 neurons for the 11 ADD instructions, 9 Â 13 neurons for the 13 SUB instructions, which gives a total of 217 neurons. The reader can easily check that the local synchronization degree is 12.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 5 .;, r l ð3Þ 1 ; r l ð3Þ 2 ;; r l ð4Þ 1 ; r l ð4Þ 2 ;; r l ð9Þ 1 ; r l ð9Þ 2 ;</head><label>5121212</label><figDesc>Fig. 5. The SUB module of P 0 with ls-sets rr; r l ð1Þ i ; r l ð2Þ i ; r l ð8Þ i n o , r l ð5Þ i ; r l ð6Þ i ; r l ð7Þ i n o , r l ð3Þ 1 ; r l ð3Þ 2 ; . . . ; r l ð3Þ sr ; r l ð4Þ 1 ; r l ð4Þ 2 ; . . . ; r l ð4Þ sr ; r l ð9Þ 1 ; r l ð9Þ 2 ; . . . ; r l ð9Þ sr n o .</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>T. Song et al. / Information Sciences 219 (2013) 197-207</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>A series of suggestions made by the anonymous referees, who carefully read the paper, are gratefully acknowledged. This work of the first two authors was supported by National Natural Science Foundation of China (61033003, 91130034 and 30870826), Ph.D. Programs Foundation of Ministry of Education of China (20100142110072), Fundamental Research Funds for the Central Universities (2010ZD001 and 2010MS003), and National Science Foundation of Hubei Province (2008CDB113 and 2011CDA027). The work of G. Pa ˘un is supported by Proyecto de Excelencia con Investigador de Reconocida Valía, de la Junta de Andalucía, Grant P08 -TIC 04200.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Asynchronous bounded SN P systems with local synchronization</head><p>In this section, we investigate the computation power of asynchronous bounded SN P systems with local synchronization. It was shown that asynchronous bounded SN P systems with extended rules can characterize semilinear sets of numbers <ref type="bibr" target="#b5">[6]</ref>, but it is open whether this result holds when the systems are restricted to use only standard rules. In the following, we prove that a set of natural numbers is semilinear if and only if it can be generated by asynchronous bounded SN P systems with local synchronization using standard rules. Lemma 6.1. NSpik out P locsyn Ã ðboun; ÃÞ # SLIN.</p><p>Proof 4. Take an asynchronous bounded SN P system with local synchronization using standard rules, P. The number of neurons is fixed, and the number of spikes in each neuron is bounded, hence the number of configurations reached by P is finite. Let C be the set of configurations of P, and C 0 be the initial configuration of P.</p><p>We construct the right-linear grammar G ¼ ðC; fag; C 0 ; PÞ, where P contains the following productions:</p><p>(1) C ? C 0 , for C; C 0 2 C such that there is a transition C ) C 0 in P during which the output neuron does not spike;</p><p>(2) C ? a C 0 , for C; C 0 2 C such that there is a transition C ) C 0 in P during which the output neuron spikes;</p><p>(3) C ? k, for any C 2 C in which all neurons have no enabled rules.</p><p>Clearly, the construction of G ensures the fact that N(P) is the length set of the regular language L(G), hence it is semilinear. Therefore, NSpik out P locsyn Ã (boun, ⁄) # SLIN. h Lemma 6.2. SLIN # NSpik out P locsyn Ã ðboun; ÃÞ.</p><p>Proof 5. Since a set of natural numbers is semilinear if and only if it can be generated by a strongly monotonic register machine, it is enough to prove that any strongly monotonic register machine can be simulated by an asynchronous bounded SN P system with local synchronization using standard rules. Let M be a strongly monotonic register machine. Clearly, the machine M has only register 1 and the ADD instructions of the forms l i : (ADD(1), l j , l k ).</p><p>An asynchronous bounded SN P system with local synchronization using standard rules P can be constructed as in the proof of Theorem 4.1 to simulate the strongly monotonic register machine M: we place the rule a 2 ? a in neuron r 1 (it is associated with register 1 and it is also the output neuron), also considering the ls-set consisting of neurons r 1 and r l ð3Þ v ; r l ð4Þ v for all ADD instructions l v of M. Moreover, in neuron r l h we provide no rule (when M halts, also P halts, so the FIN module is here not necessary). The above mentioned new ls-set make sure that as soon as the simulation of an ADD instruction of M reaches the neurons r l ð3Þ j ; r l ð4Þ j , then also neuron r 1 spikes, thus getting empty, ready for a further increment by one. That is, neuron r 1 is either empty or it contains two spikes -in the latter case, one spike is sent to the environment. Thus, the equivalence of M and P is obvious. h By Lemmas 6.1 and 6.2, the following theorem holds. h Theorem 6.1. NSpik out P locsyn Ã ðboun; ÃÞ ¼ SLIN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and remarks</head><p>In this work, inspired by the fact that neurons in the same functioning brain motif or community work synchronously to achieve some specific biological functions, we introduce local synchronization into the framework of SN P systems. The computation power of asynchronous SN P systems with local synchronization is investigated. Asynchronous SN P systems with local synchronization consisting of general neurons (resp. unbounded neurons) and using standard spiking rules are proved to be universal. Asynchronous SN P systems with local synchronization consisting of bounded neurons and using standard spiking rules can characterize the semilinear sets of natural numbers. It was already known that (1) asynchronous general SN P systems with extended rules are universal; (2) asynchronous unbounded SN P systems with extended rules can only characterize semilinear sets of natural numbers <ref type="bibr" target="#b1">[2]</ref>. However, the computation power of asynchronous general (resp. unbounded) SN P systems with standard rules is unknown. The results from this paper show that such systems can reach universality if they are provided with the ''programming capability'' of local synchronization. So, local synchronization is a powerful ingredient for achieving Turing computation power.</p><p>The local synchronization degrees in Corollarys 4.1 and 5.1 are 5 and 12, respectively. It remains open whether or not these values can be improved. In the systems constructed in Theorems 4.1 and 5.1, forgetting rules are used. It remains open whether forgetting rules can be removed without any loss of computation power.</p><p>In SN P systems, spiking neurons are employed as computation units, where neurons use spatial and temporal information of incoming spikes to encode their message sent to other neurons. In such computation models, the number and timing</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<title level="m">An Introduction to Systems Biology: Design Principles of Biological Circuits</title>
		<imprint>
			<publisher>Chapman&amp; Hall/CRC</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Asynchronous spiking neural P systems: decidability and undecidability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cavaliere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Egecioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">H</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woodworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Int. Meeting on DNA Computing</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Garzon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</editor>
		<meeting>13th Int. Meeting on DNA Computing<address><addrLine>Memphis, USA; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4848</biblScope>
			<biblScope unit="page" from="246" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spiking neural P systems with extended rules: universality and languages</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ishdorj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pa ˘un</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pérez-Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="166" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hebbian learning from spiking neural P systems view</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gutiérrez-Naranjo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><forename type="middle">J</forename><surname>Pérez-Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMC9 2008</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Corne</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5391</biblScope>
			<biblScope unit="page" from="217" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rapid local synchronization of action potentials: toward computation with coupled integrate-and-fire neurons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Herz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Science</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="6655" to="6662" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spiking neural P systems: some characterizations</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">H</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woodworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pre-proceedings of 16th International Symposium on Fundamentals of Computation Theory (FCT 2007)</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Csuhaj-Varjú</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ésik</surname></persName>
		</editor>
		<meeting><address><addrLine>Budapest, Hungary; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4639</biblScope>
			<biblScope unit="page" from="23" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spiking neural P systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yokomori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamenta Informaticae</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="279" to="308" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Small universal register machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Korec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="267" to="301" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Synchronization stability for discrete-time stochastic complex networks with probabilistic interval time-varying delays</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing, Information and Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="697" to="708" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Third Generation of Neural Network Models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Technische Universitat Gräz</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Martin-Vide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pazos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez-Patón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="295" to="326" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>Tissue P systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<title level="m">Computation -Finite and Infinite Machines</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural network and genetic programming for modelling coastal algal blooms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Muttil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Environment and Pollution</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="223" to="238" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Asynchronous extended spiking neural P systems with astrocytes</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Hoogeboom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CMC 2011</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Gheorghe</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7184</biblScope>
			<biblScope unit="page" from="243" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Small universal asynchronous spiking neural P systems</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications</title>
		<meeting><address><addrLine>Changsha</addrLine></address></meeting>
		<imprint>
			<publisher>BIC-TA</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="622" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computing with membranes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="143" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<title level="m">Membrane Computing: An Introduction</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<title level="m">The Oxford Handbook of Membrane Computing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rozenberg</surname></persName>
		</editor>
		<editor>
			<persName><surname>Salomaa</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Pa ˘un</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pérez-Jiménez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advancing Artificial Intelligence through Biological Process Applications</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Porto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pazos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Buno</surname></persName>
		</editor>
		<meeting><address><addrLine>Hershey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="60" to="73" />
		</imprint>
	</monogr>
	<note>Spiking neural P systems: an overview</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m">Handbook of Formal Languages</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Rozenberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Salomaa</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Synchronization chaotic communications with closed cryptographic systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Skander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nadjim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIC Express Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust delay-dependent a-synchronization of a class of uncertain noise-perturbed time-delayed chaotic and hyper-chaotic systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sojoodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Refan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing, Information and Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7B</biblScope>
			<biblScope unit="page" from="4435" to="4464" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Synchronization control of united complex dynamical networks with multi-links</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovative Computing, Information and Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="927" to="940" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A hybrid adaptive time-delay neural network model for multi-step-ahead prediction of sunspot activity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Environment and Pollution</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="364" to="381" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Local synchronization of a complex network model</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="230" to="241" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On languages generated by asynchronous spiking neural P systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">410</biblScope>
			<biblScope unit="page" from="2478" to="2488" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
