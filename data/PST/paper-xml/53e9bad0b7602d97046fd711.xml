<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Medical Computer Science Group</orgName>
								<orgName type="laboratory">Knowledge Systems Laboratory</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305-5479</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2022-12-25T13:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bayesian belief networks provide a natural, efficient method for representing probabilistic dependencies among a set of variables. For these reasons, numerous researchers are exploring the use of belief networks as a knowledge representation m artificial intelligence. Algorithms have been developed previously for efficient probabilistic inference using special classes of belief networks. More general classes of belief networks, however, have eluded efforts to develop efficient inference algorithms. We show that probabilistic inference using belief networks is NP-hard. Therefore, it seems unlikely that an exact algorithm can be developed to perform probabilistic inference efficiently over all classes of belief networks. This result suggests that research should be directed away from the search for a general, efficient probabilistic inference algorithm, and toward the design of efficient special-case, average-case, and approximation algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The graphical representation of probabilistic relationships among events has been the subject of considerable research. In the field of artificial intelligence, several classical systems, such as PROSPECTOR <ref type="bibr" target="#b8">[9]</ref> and CASNET <ref type="bibr" target="#b29">[30]</ref>, have used a directed graph to represent probabilistic relationships among events. Recently, a particular type of probabilistic graphical representation, called the Bayesian belief network, has been defined and explored by numerous researchers. In addition to being called a Bayesian belief network <ref type="bibr" target="#b19">[20]</ref>, it has been termed a causal net <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, causal network <ref type="bibr" target="#b16">[17]</ref>, probabilistic causal network <ref type="bibr" target="#b5">[6]</ref>, probabilistic cause-effect model <ref type="bibr" target="#b27">[28]</ref>, and probabilistic influence Artificial Intelligence <ref type="bibr">42 (1990)</ref> 393-405 0004-3702/90/$3.50 © 1990, Elsevier Science Publishers B.V. <ref type="bibr">(North-Holland)</ref> diagram <ref type="bibr" target="#b28">[29]</ref>. In this paper, we refer to a Bayesian belief network simply as a belief network.</p><p>A key advantage of belief networks is that they represent probabilistic relationships concisely. It is necessary to consider only the known dependencies among variables in a domain, rather than to assume that all variables are dependent on all other variables <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref>. This provides an efficient and expressive language for acquiring and representing knowledge in many domains. These advantages have been key motivations behind the development of several expert systems that use belief networks for diagnosis and for data interpretation <ref type="bibr">[1-3, 6, 15, 16]</ref>.</p><p>Probabilistic inference using some topological classes of belief networks has been resistant to any efficient algorithmic solution <ref type="bibr" target="#b19">[20]</ref>. In particular, multiply connected belief networks form the most general class of such problems. A multiply connected belief network contains at least one pair of nodes (variables) that have more than one undirected path connecting them. A singly connected belief network contains no pair of nodes that have more than one undirected path between them. It appears that large multiply connected networks are needed for some complex domains, such as medicine. In this paper, we show that probabilistic inference using multiply connected networks is NP-hard. Therefore, it is unlikely that a general, efficient probabilistic inference algorithm can be developed for belief networks. Knowing that the problem is NP-hard is useful because it directs research away from the quest for a general, efficient algorithm, and toward the design of good special-case, average-case, and approximation algorithms.</p><p>In the remainder of this paper, we first briefly review the belief-network representation and the kinds of probabilistic inference that typically are performed using belief networks. Then, we show that probabilistic inference using belief networks is NP-hard, and we extend this result in several ways. Finally, we conclude with a discussion of the significance of this result for future research on the design of probabilistic inference algorithms for belief networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Belief Networks</head><p>A belief network consists of a graphical structure that is augmented by a set of probabilities. The graphical structure is a directed, acyclic graph in which nodes represent domain variables. Without loss of generality, we will assume that the nodes represent propositional variables with values of either true (T) or false (F). Prior probabilities are assigned to source nodes, and conditional probabilities are associated with arcs. In particular, for each source node xg (i.e., a node without any incoming arcs), there is a prior probability function P(xg); for each node x~ with one or more direct predecessors ~-~, there is a conditional probability function P(x~l~r~). We assume that probability func-tions are represented in the form of explicit function tables, although this assumption is by no means necessary for the proof in Section 4. We shall represent a general belief network as (V, A, P), where V is the set of variables (i.e., vertices or nodes). A the set of arcs between variables, and P the set of probabilities. Figure <ref type="figure" target="#fig_0">1</ref> contains a belief-network structure corresponding to a problem that is discussed in detail in Section 4.</p><p>Belief networks are capable of representing the probabilities over any discrete sample space, such that the probability of any sample point in that space can be computed from the probabilities in the belief network. The key feature of belief networks is their explicit representation of the conditional independence among events. A belief network represents a full joint-probability space over the n event variables in the network. In particular, investigators have shown <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29]</ref> that the joint probability of some particular instantiation 1 of all n variables in a belief network can be calculated as follows: P(X~,. . . , X,) = ~I P(Xi I 7ri).</p><p>(1)</p><p>i-1</p><p>Therefore, the joint probability of any instantiation of all the variables in a belief network can be computed as the product of only n probabilities. We can recover the complete joint-probability space from the belief-network representation by calculating the joint probabilities that result from every possible instantiation of the n variables in the network. Instead of our having to represent explicitly all 2" probabilities in the joint-probability space, the conditional independencies expressed among the variables in a belief network require only that we represent P(xi[ 7ri) for each node x~; this representation may require a total of many fewer than 2" probabilities. In addition, algorithms have been developed that often do not require the explicit reconstruction of the underlying joint-probability space to perform probabilistic inference <ref type="bibr">[17, 20,</ref> Although an arc from a node x to a node y frequently is used to express that x causes y, this interpretation of arcs in belief networks is not the only one possible. For example, y may be only correlated with x, but not caused by x. Thus, although belief networks are able to represent causal relationships, they are not restricted to such causal interpretations. In this regard, belief networks can be viewed as a representation for probabilistic rule-based systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>= component clause-satisfaction-testing component overall-satisfaction-testing ( t~).~.~( component</head><p>In summary, belief networks allow an explicit graphical representation of the probabilistic conditional dependencies and independencies among variables that may represent events, states, objects, propositions, or other entities. Generally, a belief network greatly reduces the number of probabilities that must be assessed and stored (relative to the full joint-probability space).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Probabilistic Inference</head><p>The phrase probabilistic inference using belief networks typically has been used to mean the calculation of P(Sj [$2), where S 1 is either a single instantiated variable or a conjunction of instantiated variables, and S 2 is a conjunction of instantiated variables. A simple form of probabilistic inference results when both S 1 and S 2 are single instantiated variables. For example, in the context of the belief network in Fig. <ref type="figure" target="#fig_0">1</ref>, we might request the calculation of P(u 2 = T I Y = T). More commonly, S 2 can be a conjunction of instantiated variables--as for example, P(u 2 = T] Y= T ^ u 4 = F). A more general form of probabilistic inference exists when S~ and S 2 can be propositions in propositional logic <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref>. An example of inference using a probabilistic proposition is the calculation of P(Cj = T v C~ = FlY = T). The most restricted form of probabilistic inference results when there is no explicit conditioning information and the task is to determine P(Y = T) for some propositional variable Y; the other forms of probabilistic inference described in this section are generalizations of the computation of P(Y= T). It is this restricted form of inference that we shall call probabilistic inference in the remainder of this paper. By proving that computing P(Y= T) is NP-hard we will prove that the other more general forms of probabilistic inference are NP-hard as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Proving that the Problem Is NP-Hard</head><p>To prove that a problem Q' is NP-hard, it is sufficient to transform a known NP-complete problem Q to Q' and to show that this transformation can be done efficiently (i.e., in time that is polynomial in the size of Q). In this paper, we shall transform a well-known NP-complete problem, called 3-Satisfiability (3SAT) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>, to a Decision-problem version of Probabilistic Inference using Belief NETworks (PIBNETD). The transformation from the PIBNETD decision problem to the probabilistic inference problem, called simply PIBNET, will then be straightforward. Thus, we will show that PIBNET is NP-hard.</p><p>There are numerous other ways that we could prove that PIBNET is NP-hard.</p><p>In particular, different known NP-complete problems can be reduced to PIBNET. As an example, consider the s-t network reliability problem. Here a network consists of a graph in which edges are assigned a probability of failure. The problem is to determine the probability that there is a path of unfailed edges in the graph between two nodes s and t. Rosenthal has shown this problem to be NP-hard for undirected networks <ref type="bibr" target="#b26">[27]</ref>. More pertinent to PIBNET, Provan and Ball have shown the s-t network reliability problem to be NP-hard for directed, acyclic graphs <ref type="bibr" target="#b24">[25]</ref>. It is possible to reduce the s-t network reliability problem for directed, acyclic graphs to the PIBNET problem. In this paper, however, we shall use a reduction from 3SAT, because this strategy yields a very simple proof and demonstrates that PIBNET is NP-hard even for belief networks that are significantly restricted topologically. Rosenthai has applied a related reduction using the general satisfiability problem to show that solving fault trees is NP-hard <ref type="bibr" target="#b25">[26]</ref>. Finally, by using 3SAT to prove that PIBNET is NP-hard, we can readily derive additional complexity results on belief-network inference, as discussed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The definition of 3SAT</head><p>The 3SAT problem involves a collection C = {c~, c2,..., Cm} of clauses on a finite set U of n Boolean variables. If u is a variable in U, then u and --1 u are literals over U. The literal u is true if and only if the variable u is true (T). The literal --1 u is true if and only if the variable u if false (F). Each clause c i contains a disjunction of three literals over U, for example, (7 u 2 v u 6 v --7 us). The clause in this example will be satisfied (i.e., true) unless u 2 = T, u 6 = F, and u 8 = T. A collection C of clauses over U is satisfiable if and only if there exists some truth assignment for U that simultaneously satisfies all the clauses in C. The 3SAT decision problem involves determining whether there is a truth assignment for U that satisfies all the clauses in C.</p><p>For example, consider an instance of 3SAT in which U = {u~, u 2, u3, u4} and</p><formula xml:id="formula_1">c = {(u, v v ul v "2 v v u3 v u,,)}.</formula><p>One satisfying truth assignment is given by ul = T, //2 = F, u 3 = F, and u 4 = T. Thus, the decision problem has the answer "yes" for this example. This example will be called 3SATex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Transforming 3SAT to PIBNETD</head><p>We now transform 3SAT to PIBNETD. PIBNETD is a decision problem that determines, for some variable Y in a given belief network, whether P(Y= T) &gt; 0. PIBNETD returns "yes" if P(Y = T) &gt; 0; it returns "no" otherwise. Let U = {ul, u2,... , un} and C= {cl, c2,... , Cm} be any instance of 3SAT. We must construct a belief network BN containing variable Y such that G.F. COOPER P(Y = T) &gt; 0 if and only if C is satisfiable. BN will consist of several components, including those that set the truth values of U and those that test whether C is satisfied given a particular truth-value setting of U. In this construction, the terms vertex, node, and variable will be used interchangeably. All variables will be propositional.</p><p>There is a truth-setting component (V t, pt) that probabilistically instantiates the values of each of the variables in U. In particular, and vt=v,</p><formula xml:id="formula_2">pt= { P(u, =T)= ½, e(u 2 = T) = ½, . . . , e(u. =T)= 1}.</formula><p>The truth-setting component for example 3SATex is shown in Fig. <ref type="figure" target="#fig_0">1</ref>, with nodes represented by circles. The belief-network substructure for the clause-satisfaction-testing component for example 3SATex is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Finally, there is an overall-satisfaction-testing component (V °, A °, po), which tests whether all the m clauses in C are satisfied. In particular, there is an arc from each variable Cj to a variable Y. Furthermore, a probability P(Y= T I C1, C a ..... C m) is defined as a component of the belief network, such that P(Y=TIC1, C2,...,Cm)=I if and only if C1=T, C2=T ..... Cm=T; otherwise, P(Y = T I C 1, C 2, . . . , Cm) = O.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> demonstrates that we can achieve the same result of conjunctively linking each variable Cj to Y by using a set of intermediate dummy variables designed as D k. Each dummy variable has the value T with probability 1, if each of its parents has the value T; otherwise, it has the value T with probability 0. The variable Y is related to its parents in the same conjunctive manner as are the dummy nodes. In essence, numerous small component AND-gates can be used to construct a large AND-gate linking each Cj to Y. For the case of using dummy variables to link each Cj to Y, the construction of (V o, A o, po) is informally defined as follows. Set V ° contains the dummy nodes, the node Y, and the nodes C 1, Ca,..., C m. Set A ° contains the arcs between nodes in V °, as exemplified in Fig. <ref type="figure" target="#fig_0">1</ref>. Finally, po contains the conjunctive probability functions just described.</p><p>The construction using dummy variables is important for two reasons. First, it allows us to construct the belief network corresponding to a 3SAT problem using only small probability tables. This construction allows the NP-hardness result to apply to the restricted case of belief networks constructed using only tables, and not closed-form functions. Second, the dummy-variable construction renders the indegree of any node in the belief network to be less than 4. Thus, the NP-hardness result will apply to belief networks with an indegree restricted to be less than 4.</p><p>We complete the construction of the PIBNETD belief network BN by setting BN = (V, A, P), where</p><formula xml:id="formula_3">V = V t U V s U V ° , A = A S 0 A ° , p = pt U P~ U po .</formula><p>The construction of a belief network corresponding to an instance of 3SAT can be accomplished in time polynomial in the size of the 3SAT problem. In particular, the construction of the truth-setting component is O(n), the construction of the clause-satisfaction-testing component is O(m), and the construction of the overall-satisfaction-testing component is O(m). All that remains to be shown is that clause set C is satisfiable if and only if P(Y = T) &gt; 0.</p><p>Define U~ to be the ath instantiation of the variables in U, where for 1 ~&lt; i ~&lt; n, if the ith digit (from the right) of the binary representation of a is 1, then u i = T; and, if the ith digit of the binary representation of a is 0, then u i = F. For instance, in the 3SATex example, U 5 represents the instantiation (2) a=0 /3-0 Suppose C is satisfiable. In this case, one term of the sum in equation ( <ref type="formula">2</ref>) is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(Y = T] Cs)P(C~] U~)P(Us), and thus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(Y = T) 1&gt; P(Y = T IC~)P(Csl U,)P(U~).</head><p>(3)</p><p>From the construction of BN, P(Y = T] Cs) = 1 and P(Us) = (½)". It remains to show that P(C S I Us) &gt; 0. Based on the conditional independencies expressed in the representation of BN, the probability P(Cs]U~) can be expanded as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P(Cs I Us) = P(C1 = T I w~, w~, w3~) -.. P(C., = T I w~, w~, w~), (4)</head><p>3 where herel we :use w~, w~, and wj to represent the instantiation of the variables w j, w j, and w j, respectively, as designated by U S. Because U S represents a satisfying truth assignment for C, it also must represent a satisfying truth assignment for each clause cj in C. Therefore, by the construction of BN, P(q=T]w~,w~,w~)=l, l~&lt;j~&lt;m.</p><p>Thus, P(C S I Us) = 1, and therefore, P(Y = T) &gt; 0.</p><p>Conversely, suppose that C is not satisfiable. Then, for every truth assignment U----&gt; {T, F}, there is at least one clause cj that is not satisfied. Thus, by the construction of BN, for every instantiation of U~, there is at least one variable Cj for which P(C i = T]wj, wj, wj)= 0. Therefore, P(C s lUg)= 0 for all U~; this implies that the only possible positive terms in the sum of (2) must exist when C, ~C S. However, when C,~Cs, the term P(Y=T I C~)=O. Therefore, from (2), P(Y--T) --0. Thus, we have shown that any instance of 3SAT can be transformed to PIBNETD. This result implies that PIBNETD is NP-hard.</p><p>In addition, PIBNETD is in the class NP because an instantiation of all the variables in a belief-network (including some designated variable assignment Y = T) can serve as an efficient certificate for the PIBNET decision problem (i.e., as sufficient evidence to verify that P(Y--T) &gt; 0 in polynomial time), as indicated by <ref type="bibr" target="#b0">(1)</ref>. Thus, because PIBNETD is both NP-hard and in NP, it is NP-complete. Futhermore, PIBNETD is NP-complete in the strong sense <ref type="bibr" target="#b9">[10]</ref> because all the numbers in the problem can be assigned a fixed precision.</p><p>Recall that PIBNET is a computational version of PIBNETD. That is, PIBNET produces a numerical answer corresponding to the probability P(Y = T), rather than merely determining whether this probability is greater than 0. It is clear that PIBNETD can be readily transformed to PIBNET by simply having PIBNET return "yes" if P(Y = T)&gt; 0, and "no" otherwise. Thus, PIBNET is NP-hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Additional Complexity Results</head><p>In this section, the results of Section 4 are used as a framework for developing several additional complexity results.</p><p>The use of 3SAT to prove that PIBNET is NP-hard has several advantages. 3SAT generically transforms to a belief-network problem that has a relatively restricted network topology. Therefore, the computational complexity of PIBNET clearly does not depend on the complexity of inference using arbitrarily compiex belief-network topologies. For example, consider the composition of the truth-setting component and clause-satisfaction-testing component of PIB-NETD. This portion of PIBNETD defines a bipartite belief network that can be used as one type of restricted diagnostic system model, where each node u s corresponds to a disease and each node Cj corresponds to an item of evidence. The definition of conditional probability often is applied as follows to calculate the probability of a disease ui given a set of evidence variables {CI, C2 .... , Cm} that are each instantiated to a particular value: </p><p>Therefore, determining the value of P(C 1, C2,..., Cm) is of key importance to determining the posterior probability of each u i. Recall that C s is the set of instantiated variables that results from instantiating each Cj in {C1, (2;2,..., Cm} to the value T. Inferring the value of P(Cs) using a bipartite belief-network representation answers the PIBNETD decision problem, and therefore this inference task is NP-hard. Additionally, in <ref type="bibr" target="#b6">[7]</ref> we show that computing P(ui =T]C 1, C 2 ..... Cm) using a bipartite belief network is NPhard, even if (1) each item of evidence Cj has at most three disease predecessors, and (2) the conditional probability of each item of evidence given its disease predecessors is described by a noisy OR-gate model <ref type="bibr">[21, p. 184</ref>].</p><p>In addition to its structural simplicity, 3SAT is a problem that has been studied extensively, and restricted versions of 3SAT have been proved NPcomplete. These restrictions can be used to derive direct corresponding restrictions for probabilistic inference using belief networks. For example, PLANAR 3SAT <ref type="bibr" target="#b17">[18]</ref> can be used to show that inferring P(Cs) in a bipartite belief network is NP-hard, even if the bipartite belief network is restricted to be a planar graph. Another known restriction states that 3SAT remains NP-hard when, for each u s in U, there are at most 5 clauses in C that contain either u i = T or u s = F <ref type="bibr">[10, p. 259</ref>]. This restriction implies that the nodes in the clause-satisfaction-testing component of the corresponding PIBNET problem need only to have an outdegree of at most 5. Figure <ref type="figure" target="#fig_0">1</ref> indicates that the clause-satisfaction-testing component of PIBNET determines the maximum outdegree and indegree of nodes in a PIBNET network. Thus, PIBNET remains NP-hard when the outdegree of any node is at most 5 and the indegree is at most 3. Similarly, the problem of inferring P(C~) in a bipartite belief network remains NP-hard when the outdegree is at most 5 and the indegree is at most 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>Probabilistic inference using certain restricted types of belief networks can be performed efficiently. For example, there are known algorithms that can perform probabilistic inference using singly connected networks in time that is linear as a function of the size of the belief network <ref type="bibr" target="#b19">[20]</ref>. Probabilistic inference using multiply connected networks with all variables instantiated to specific values also requires only time linear in the size of the network. This fact is apparent from equation <ref type="bibr" target="#b0">(1)</ref>, which demonstrates that only n products are needed to calculate a particular instantiation of the n variables in any belief network. However, inference using multiply connected networks containing uninstantiated variables appears to be much more computationally difficult.</p><p>Currently, there are several algorithms for performing probabilistic inference using multiply connected networks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29]</ref>. All of them have a time complexity that, in the worst case, is exponential as a function of the number of uninstantiated variables in the network.</p><p>This paper has shown that probabilistic inference using general belief networks is NP-hard. In particular, probabilistic inference using multiply connected belief networks with uninstantiated variables is NP-hard. Knowing that a problem is NP-hard is important, because it suggests that any attempt at a general, exact, efficient solution is unlikely to be successful. Thus, attempts to develop such an algorithm should be given very low priority.</p><p>Unfortunately, the representations of many complex, real-world domains, such as medicine <ref type="bibr" target="#b23">[24]</ref>, seem generally to require large multiply connected networks; furthermore, probabilistic inference using these networks typically involves many uninstantiated variables--for example, the intermediate pathophysiological states in medical belief networks. This situation suggests that we should use different strategies, besides seeking a general, exact algorithm, in attempting to achieve computationally tractable probabilistic inference in such complex domains. Alternative strategies include averagecase, special-case, and approximation algorithms. We shall briefly discuss some current research directions in developing approximation and special-case methods.</p><p>Approximation algorithms produce an inexact, bounded solution, but guarantee that the exact solution is within those error bounds. For example, algorithms have been developed that bound a probability of the form P(xl z), where x is an instantiated variable and Z is a set of instantiated variables <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23]</ref>. The bounds are tightened incrementally as computation proceeds. The question is then whether such absolute bounds can be made sufficiently tight in an acceptable amount of time for the probability inference problems in the domain. Researchers are just beginning to address this important empirical question for certain domains, such as medicine.</p><p>A related method uses Monte Carlo simulation techniques to produce a point-valued probability estimate, plus a standard error of that estimate <ref type="bibr" target="#b12">[13]</ref>. As more computation time is expended, the standard error decreases. In this case, the error bound is statistical, rather than absolute. Although Monte Carlo simulation methods appear promising, current algorithms have extremely slow convergence properties in some cases <ref type="bibr" target="#b3">[4]</ref>, and thus are not always practical to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Special-case algorithms are capable of efficient probabilistic inference for</head><p>special types of belief networks. For instance, as already mentioned, there are linear-time algorithms for probabilistic inference using singly connected networks. A second example is an algorithm that is able to perform probabilistic inference efficiently on many multiply connected networks that contain small clusters of nodes <ref type="bibr" target="#b16">[17]</ref>. Such techniques take advantage of the decomposability of certain networks into node clusters. Similar techniques have been used to solve some types of fault-tree problems <ref type="bibr" target="#b25">[26]</ref> and network reliability problems <ref type="bibr" target="#b26">[27]</ref>. Decomposability is a powerful technique in solving many kinds of network problems; we may be able to exploit it further in developing new special-case belief-network inference algorithms. Belief networks that contain restricted classes of probability functions or values also may be amenable to efficient inference. Researchers are beginning to investigate the detailed classes of belief networks for which current special-case inference algorithms are computationally tractable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A belief-network structure. The probabilities in this belief network are defined in Section 4; the annotations on the right of the figure also are explained there.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>For 3 wj, clause cj and 1 ,</head><label>31</label><figDesc>each clause c/E C, 1 ~&lt; j ~&lt; m, there is a clause-satisfaction-testing subcomponent (V~, A~, P~) that tests whether a given instantiation of the paris ables in U satisfies clause cj in C. The components of (V~, Aj, P~) are defined as follows: is the variable corresponding to the first literal in clause cj. Similarly, 2 and wj are the variables corresponding to the second and third literals in cj, respectively; for instance, in example 3SATex , clause c 2 = (7 u 1 v 7 u 2 v u3), and therefore w~ = Ul, w~ = u2, and w~ = u 3. The variable Cj represents the truth value of clause cj.s Aj : {(w~, q), (w~, Cj), (w~, q)}, P~ = { P( Cj = TI %)}, where ~'c represents the conjunction of the three variables w I w~ wj 3 of j ' if gj(rrc) =T, P(Cj=T]~'c)= 0, ifgi(~) F, where gj(Trc) is the truth function for clause cj. For example, for clause c 3 in the 3SATex example, there is a corresponding s s subcomponent (V~, A3, P3), where s V3 = {•2, u3, u4, C3} , A; = {(u 2, Ca), (u 3, C3), (u4, C3)}, P~ = {P(C3 = T I uz = F, u~ = T, U 4 = F) = 0, P(C3 = T I u: = T, u 3 = T, U 4 = T) = 1, P(C 3 =T[ u 2 =T, u 3 = T, u 4 = F) = 1, P(C3 = T I U 2 = T, u 3 = F, U 4 = T) = 1, P(C 3 = T I u 2 = T, u 3 = F, u 4 = F) = 1 , P(C3 = T I//2 = F, U 3 = T, U 4 = T) = 1,P(C3 =TI u2 = F, u3 =F, u4 =T) = 1, P(C 3 = T[/'/2 = F, u 3 = F, u 4 = F) = 1}.The clause-satisfaction-testing component (V s, A s, P~) is composed of the union of the clause-satisfaction-testing subcomponents corresponding to each clause cj. In particular,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>u 4 =</head><label>4</label><figDesc>F, u 3 = T, u 2 = F, and u I = T, because the binary representation of 5 is 0101. U s denotes a truth assignment to the variables in U that satisfies all the clauses in C. C s denotes the set of instantiated variables that results from assigning the value T to each variable Cj, 1 ~&lt;j~&lt; m. C a denotes the /3th instantiation of the Cj variables, and is defined analogously to U~. By the construction of BN and the definition of belief networks, 2 n 1 2 m-I P(Y=T)= ~', ~ P(Y=TIC~)P(C~IU~)P(U~).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>P</head><label></label><figDesc>(u s = T lCl, C 2 ..... Cm) = P(C1, C2 ..... Cm I US = T)P(u~ = T) P(C,, C2 ..... C,,,)</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">The term instantiated variable is used to denote a variable that has a known, assigned value. For example, an instantiated propositional variable would have an assigned value of either true (T) or false (F).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGEMENT I thank Marty Chavez, Lyn Dupre, David Heckerman, Eddie Herskovits, Eric Horvitz, Richard Lin, Judea Pearl, and Mike Wellman for valuable comments on earlier versions of this paper. This work has been supported by grant IRI-8703710 from the National Science Foundation, grant P-25514-EL from the U.S. Army Research Office, and grant LM-07033 from the National Library of Medicine. Computer facilities were provided by the SUMEX-AIM resource under grant RR-00785 from the National Institutes of Health.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">IDES: Influence diagram based expert system</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Agogino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Modelling</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="227" to="233" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MUNIN: A causal probabilistic network for interpretation of electromyographic findings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Woldbye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IJCAI-87</title>
				<meeting>IJCAI-87<address><addrLine>Milan, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">KNET: Integrating hypermedia and normative Bayesian modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Chavez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings Workshop on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bayesian belief network inference using simulation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<editor>L.N. Kanal, T.S. Levitt and J.F. Lemmer</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="129" to="147" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The complexity of theorem-proving procedures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Third Annual ACM Symposium on Theory of Computing</title>
				<meeting>Third Annual ACM Symposium on Theory of Computing<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">NESTOR: A computer-based mecfical diagnostic aid that integrates causal and probabilistic knowledge</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The computational complexity of probabilistic inference using belief networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<idno>Rept. KSL-87-27</idno>
		<imprint>
			<date type="published" when="1987">1987</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Medical Computer Science Group, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An algorithm for computing probabilistic propositions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<editor>L.N. Kanal, T.S. Levitt and J.F. Lemmer</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>Amsterdam</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Subjective Bayesian methods for rule-based inference systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1976 National Computer Conference</title>
				<meeting>1976 National Computer Conference</meeting>
		<imprint>
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Garey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">Computers and Intractability: A Guide to the Theory of NP-Completeness</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Freeman</publisher>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A causal calculus I</title>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">J</forename><surname>Good</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Philos. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="305" to="318" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A causal calculus II</title>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">J</forename><surname>Good</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Philos. Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="43" to="51" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Propagating uncertainty by logic sampling in Bayes&apos; networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<editor>L.N. Kanal and J.F. Lemmer</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards efficient probabilistic diagnosis in multiply-connected belief networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Conference on Influence Diagrams</title>
				<meeting>Conference on Influence Diagrams<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An experimental comparison of knowledge engineering for expert systems and for decision analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cooley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings AAA1-87</title>
				<meeting>AAA1-87<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Intelligent Decision Systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Holtzman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Local computations with probabilities on graphical structures and their application to expert systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="157" to="224" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Planar formulae and their uses</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lichtenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SlAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="329" to="343" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic logic</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="71" to="87" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fusion, propagation, and structuring in belief networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="241" to="288" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
				<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The logic of representing dependencies by directed graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings AAAI-87</title>
				<meeting>AAAI-87<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A comfort measure for diagnostic problem-solving</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reggia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Heuristic methods for imposing structure on ill-structured problems: The structuring of medical diagnostics</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Pople</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence in Medicine</title>
				<editor>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</editor>
		<meeting><address><addrLine>Boulder, CO</addrLine></address></meeting>
		<imprint>
			<publisher>Westview Press</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="119" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The complexity of counting cuts and of computing the probability that a graph is connected</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Provan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ball</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SlAM J. Cornput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="777" to="788" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A computer scientist looks at reliability computations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reliability and Fault Tree Analysis</title>
				<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Barlow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Fussell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Singpurwalla</surname></persName>
		</editor>
		<meeting><address><addrLine>SIAM, Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="133" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Computing the reliability of complex networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SlAM J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="384" to="393" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A method for computing probabilities in complex situations</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Rousseau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Systems Research, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Rept. 6252-2</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Intelligent probabilistic inference</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
				<editor>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Kanal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Lemmer</surname></persName>
		</editor>
		<meeting><address><addrLine>North-Holland, Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="371" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A model-based method for computeraided medical decision-making</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Kulikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amarel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Safir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="145" to="172" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
