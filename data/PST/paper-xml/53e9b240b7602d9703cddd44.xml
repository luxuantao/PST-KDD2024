<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-Speed Policy-based Packet Forwarding Using Efficient Multi-dimensional Range Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Lakshman</surname></persName>
							<email>lakshman@bell-labs.com</email>
							<affiliation key="aff0">
								<orgName type="department">Bell Laboratories 101</orgName>
								<orgName type="institution">Crawfords Corner Rd. HolmdeP</orgName>
								<address>
									<postCode>07733</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Stiliadis</surname></persName>
							<email>stiliadi@bell-labs.com</email>
							<affiliation key="aff0">
								<orgName type="department">Bell Laboratories 101</orgName>
								<orgName type="institution">Crawfords Corner Rd. HolmdeP</orgName>
								<address>
									<postCode>07733</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">High-Speed Policy-based Packet Forwarding Using Efficient Multi-dimensional Range Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">638F9AB6A2AD3BD043A95B43B4E51824</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-07-28T16:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ability to provide differentiated services to users with widely varying requirements is becoming increasingly important, and Internet Service Providers would like to provide these differentiated services using the same shared network infrastructure.</p><p>The key mechanism, that enables differentiation in a connectionless network, is the packet classification function that parses the headers of the packets, and after determining their context, classifies them based on administrative policies or real-time reservation decisions. Packet classification, however, is a complex operation that can become the bottleneck in routers that try to support gigabit link capacities.</p><p>Hence, many proposals for differentiated services only require classification at lower speed edge routers and also avoid classification based on multiple fields in the packet header even if it might be advantageous to service providers. In this paper, we present new packet classification schemes that, with a worst-case and trafficindependent performance metric, can classify packets, by checking amongst a few thousand filtering rules, at rates of a million packets per second using range matches on more than 4 packet header fields. For a special case of classification in two dimensions, we present an algorithm that can handle more than 128K rules at these speeds in a traffic independent manner. We emphasize worst-case performance over average case performance because providing differentiated services requires intelligent queueing and scheduling of packets that precludes any significant queueing before the differentiating step (i.e., before packet classification). The presented filtering or classification schemes can be used to classify packets for security policy enforcement, applying resource management decisions, flow identification for RSVP reservations, multicast look-ups, and for source-destination and policy based routing. The scalability and performance of the algorithms have been demonstrated by implementation and testing in a prototype system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The transformation of the Internet into an important commercial infrastructure has significantly changed user expec-Permission to mahe digital or hard copies of all or pert of thos work for personal or classroom use is granted without fee provided that copses are not made or distributed for profit or commewal adven tage end that copies bear this notice and the full cotat~on on the first page. To copy otherwise.</p><p>to republish. to post on swvers or to redlstributs to ksts. reqwres prior specific permissoon and/or B fee. SIGCOMM '98 Vancouver. B.C. 0 1999 ACM l-58113.003.1/98/0008...85.00 tations in terms of performance, security, and services. Internet Service Providers, while using a shared backbone infrastructure, would like to provide different services to different customers based on different service pricing or based on widely varying customer requirements. For providing this differentiated service, service providers need mechanisms for isolating traffic from different customers, for preventing unauthorized users from accessing specific parts of the network, and for providing customizable performance and bandwidth in accordance with customer expectations and pricing. In addition, service providers need mechanisms that allow routing decisions to be made not just based on destination addresses and the shortest path to it, but also based on contracts between service providers or between a service provider and a customer <ref type="bibr">[14]</ref>. Consequently, routers (or packet forwarding engines in general) used in both enterprise and backbone environments should be able to provide network managers with the proper mechanisms that will allow the provisioning of these features.</p><p>Forwarding engines must be able to identify the context of packets and must be able to apply the necessary actions so as to satisfy the user requirements. Such actions may be the dropping of unauthorized packets, redirection of packets to proxy servers, special queueing and scheduling actions, or routing decisions based on a criteria other than the destination address. In the paper, we use interchangeably the terms packet filtering or packet class$cation to denote the mechanisms that support the above functions.</p><p>Specifically, the packet filtering mechanisms should parse a large portion of the packet header, including information on the transport protocols, before a forwarding decision is made*. The parsing results in the incoming packet being classified using a set of rules that have been defined by network management software or real-time reservation protocols such as RSVP.</p><p>Packet filtering functionality is required for example when a router is placed between an enterprise network and a core backbone network. The router must have the ability to block all unauthorized accesses that are initiated from the public network and are destined to the enterprise network.</p><p>On the other hand, if accesses are initiated from a remote site of the enterprise network, they can be forwarded into the intranet and this requires filtering ability.</p><p>If this level of security is not enough, another policy requirement might be that authorized access attempts from the public network be forwarded to an application level proxy server that will *Forwarding based on transport level information is also referred to as layer-4 forwarding. authenticate the access. Clearly, filtering mechanisms are very useful at the edge of an enterprise network. In an edge network node, the router might need to identify the traffic that is initiated from specific customers, and either police it or shape it to meet a predefined contract. Indeed, these are the actions that are required by some of the differentiated services model proposals that are being considered for standardization by the IETF <ref type="bibr">[lo]</ref>. It is evident that most filter rules naturally apply to a whole range of addresses, port numbers, or protocols, and not just to single predefined hosts or applications.</p><p>Aggregation, for instance of addresses, is not only required because customers are usually allocated blocks of addresses, but also because it is necessary to keep the network manageable. Therefore, the specification of the packet classification policies must allow aggregations in their definitions. This means that packet classification algorithms must be be able to process rules that define combinations of ranges of values. If the algorithms can only handle exact values and do not support aggregation, preprocessing is required to translate the ranges to exact values. This is infeasible since ranges can grow exponentially with length of the packet field on which the ranges are defined.</p><p>A trend worth noting is that even though packet filtering was thought of as a tool necessary only at the network access points and mainly for firewall or security applications, it is now becoming apparent that it is a valuable tool for performing traffic engineering and meeting the new service requirements of the commercial Internet. Filtering policies that use the full information of the packet header can be defined for distributing the available system or network resources. The main consequence of these new uses is that all packet classification actions must be performed at wirespeed, i.e., the forwarding engines must have enough processing power to be able to process every arriving packet without queueing since without header processing it is not possible to differentiate packets to provide differentiated services.</p><p>The main contributions of this paper are algorithms that use multi-dimensional range matching that enable Gigabit routers to provide wire-speed packet filtering and classification in a traffic independent manner (i.e. we do not rely on traffic dependent caching or average case results to achieve fast execution times). To our knowledge, our proposed schemes are the first schemes that allow thousands of filter rules to be processed at speeds of millions of packets per second with range matches on 5 or more packet fields in a traffic independent manner. Specifically, we present three algorithms:</p><p>The first algorithm takes advantage of bit-level parallelism which combined with very elementary bit-operations results in a scheme that supports a large number of filter rules. The second algorithm extends the performance of the first algorithm by making efficient use of memory. It provides a means for balancing the the time-space tradeoff in implementation, and allows optimization for a particular system taking into account the available time for packet processing, the available memory, and the number of filter rules to be processed. Furthermore, the algorithm allows on-chip memory to be used in an efficient and traffic independent manner for reducing worst-case execution time. This is unlike typical caching schemes which are heavily traffic dependent and only improve average case performance. The performance metric for all our schemes is worst-case execution time, simple operations to make it amenable to hardware implementation if necessary, and space requirements which are feasible with current memory technology and costs. The implementation simplicity, scalability and performance of our filtering have been demonstrated in a prototype router with interfaces operating at a million packets per second.</p><p>Our third algorithm considers the special case of filter rules on two fields. This is motivated by important applications such look-ups for multicast traffic forwarding and policy-based routing. To elaborate on this example, when a forwarding engine supports a multicast protocol like PIM (sparse mode or dense mode) <ref type="bibr">[13]</ref> or DVMRP <ref type="bibr" target="#b23">[26]</ref>, the forwarding decision has to be made on both the source address value and the multicast group value. Depending on the protocol, the forwarding engine may have a forwarding entry for a given group value irrespective of source addresses, and also have forwarding entries for a given group value and source subnet. Given the increasing importance of multicast forwarding in the Internet, it would be ideal if a simple algorithm could be used for making multicast forwarding decisions. Since the search for the source addresses may use the same forwarding information base as that used for unicast routing, the same type of CIDR (Classless Inter-Domain Routing) aggregations <ref type="bibr">[15]</ref> are likely to be used. CIDR aggregations introduced the notion of prefix in the definition of routing entries. In other words an entry in the forwarding base is defined as a value and a mask. The mask defines the number of bits of the destination address of a packet that can be ignored when trying to match the destination address of the packet to the particular entry of the forwarding base. The bits that can be masked-out are always in the less significant portion of the address. Thus, the values in the forwarding engines can thought as prefixes. For the case of IPv4, prefixes can have a length between 1 and 32 bits. We present a linear space, O(prefix length) scheme which can be used to implement P-dimensional lookups at rates of millions of packets per second for more than 128K entries in the forwarding table. Considering that multicast forwarding tables in the core backbone might include several hundreds of thousands of entries, even a solution that uses O(n log n) space with a moderate constant or O(Zog2n) time may not be feasible when the number of entries n is that high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Design Goals</head><p>We first try to identify the main requirements that a packet classification algorithm must satisfy in order to be useful in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1</head><p>The Requirement for Real-Time Operation</p><p>Traditional router architectures are based on flow-cache architectures to classify packets. The basic idea is that packet arrivals define flows [9, 171, in the sense that if a packet belonging to a new flow arrives, then more packets belonging to that flow can be expected to arrive in the near future. With this expected behavior, the first packet of a flow is processed through a slow path that analyzes the complete header. The header of the packet is then inserted into a cache or hash table together with the action that must be applied to the first packet as well as to all other packets of the flow. When subsequent packets of that flow arrive the corresponding action can be determined from the cache or hash table.</p><p>There are three main problems associated with this architecture or any similar cache-based architecture when applied to current Internet requirements:</p><p>1. In current backbone routers, the number of flows that are active at a given interface is extremely high. Recent studies have shown that an OC-3 interface might have an average of 256K flows active concurrently <ref type="bibr">[24]</ref> t" For this many number of flows, use of hardware caches is extremely difficult, especially if we consider the fact that a fully-associative hardware cache may be required. Caches of such size will most likely be implemented as hash tables since hash tables can be scaled to these sizes. However, the O(1) look-up time of a hash table is an average case result and the worst-case performance of a hash table can be poor since multiple headers might hash into the same location. The number of bits in the packet headers that must be parsed is typically between 100 and 200 bits, and even hash tables are limited to only a couple of million entries. So any hash function that is used must be able to randomly distribute 100 to 200 bit keys of the header to no more than 20-24 bits of hash index. Since there is no knowledge about the distribution of the header values of the packets that arrive to the router, the design a good hash function is not trivial.</p><p>2. Due to the large number of flows that are simultaneously active in a router and due to the fact that hash tables generally cannot guarantee good hashing under all arrival patterns, the performance of cache based schemes is heavily traffic dependent. If a large number of new flows arrive at the same time, the slow path of the system that implements the complete header matching can be temporarily overloaded. This will result in queueing of packets before they are processed. But in this case, no intelligent mechanism can be applied for buffering and scheduling of these packets because without header processing there is no information available about the destination of the packets or about any other fields relevant to differentiation. So it is possible that congestion and packet dropping happen due to processing overload and not due to output link congestion.</p><p>To better illustrate this, consider the model in Figure <ref type="figure" target="#fig_0">1</ref>. Packets arrive to the interfaces and are placed in a queue for processing. After the packet classification and next-hop lookup operations are performed, they are forwarded to the outgoing interfaces where they are queued for transmission. Clearly, some interfaces may be idle even though there are packets waiting to be transmitted in the input queues. For example, all packets destined for output 1 can be blocked in the slow path processing module behind packets that are destined to other outputs. Output 1 remains idle, although there are packets in the buffers available for transmission. Obviously such a system will suffer from Head-of-Line blocking that will limit the throughput substantially.</p><p>Note, that the Head-of-Line problem can be diminished, if there is knowledge about the destination of more than one enqueued packet <ref type="bibr">[20]</ref>. However, the fundamental problem of the system of Figure <ref type="figure" target="#fig_0">1</ref> is that the destination or the context of the packet is not actually known before the packet is processed. Thus, it is impossible to apply any intelligent 'Note the by active we do not imply that the flow currently has a backlog of packets to be served.</p><p>The definition of active flows for caching look-up information is different from the definition for scheduling because caching information changes at a slower time scale.</p><p>3.</p><p>queueing mechanisms at the input queues and headof-line blocking cannot be eliminated.</p><p>A commercial Internet infrastructure should be robust and should provide predictable performance at all times. Variations in the throughput of forwarding engines based on traffic patterns are undesirable and make network traffic engineering more difficult. In addition, the network should not be vulnerable to attacks from malicious users. A malicious user or group of users discovering the limitations of the hash algorithms or caching techniques, can generate traffic patterns that force the router to slow down and drop a large portion of the packets arriving at a particular interface.</p><p>Summarizing, we claim that any packet queueing delays are only acceptable after the classification step is performed, if provisioning of differentiated services and robustness are important.</p><p>In particular, the queueing delays before the complete processing of a packet can be no larger than the maximum allowed delay for the flow with the minimum delay requirement (which could be extremely small if constant bit rate flows are supported). This no-qzleueing before pro- cessing principle applies because it is the header processing (including packet filtering) operation that enables the router to determine the quality-of-service (&amp;OS) level to be accorded to a particular packet. Hence, large queues formed while waiting for the filtering operation can violate qualityof-service for some flows even before the router determines the QoS to be accorded to the flow. The implication that this has on the design of packet filtering algorithms is that it is the worst-case performance of the algorithms that determines the true maximum packet processing rate and not the average case performance (the averaging being done on filter rule combinations and traffic arrival patterns). If average case performance is used to determine supported packet processing speeds, then buffering is needed before filtering. To estimate delays in this undifferentiated-traffic buffer, we need a characterization of the the variance in execution times (which is difficult to determine) and we need to predict traffic patterns at different interfaces. The delay in this pre-filtering buffer can cause QoS to be violated for flows with stringent delay constraints if there is any error in estimating these quantities.</p><p>Hence, it is preferable to avoid queueing before header processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Criteria for efFicient packet classification and system constraints</head><p>We can now outline, based on the prior discussion, the criteria that an efficient classification algorithm must meet:</p><p>The algorithm must be fast enough for use in routers with Gigabit links. Internet Service Providers are envisaged to build networks with link capacities of 2.4 Gigabits/s and more. Any packet classification scheme for use in core networks must be scalable to these speeds.</p><p>The algorithm must be able to process every packet arriving to the physical interfaces at wire-speed. Recent traffic studies have shown that 75% of the packets are smaller than the typical TCP packet size of 552 bytes. In addition, nearly half the packets are 40 to 44 bytes in length, comprising of TCP acknowledgments and TCP control segments <ref type="bibr">[24]</ref>. Since the algorithm cannot use buffering to absorb variation in execution times, it must operate at wire-speed when all packets are as small as 44 bytes. This means that the algorithm must have provably small worst-case execution times which are independent of traffic patterns.</p><p>3. Classification rules must be based on several fields of the packet header, including among others source and destination IP addresses, source and destination port numbers, protocol type and Type-of-Service.</p><p>The rules must be able to specify ranges and not just exact values or simple prefixes 4. For some applications, it might be possible to limit the requirements to only two dimensions and to have ranges defined only as prefixes.</p><p>This is a more restricted problem than the general classification problem but it has a very useful application in both multicast lookups and in RSVP reservations that use either wild-card filters or CIDR aggregations <ref type="bibr">[15, 281. 5</ref>. It is possible that some packets may match more than one rule. The algorithm must allow arbitrary priorities to be imposed on these rules, so that only one of these rules will finally be applicable to the packet.</p><p>6. Updates of rules are rare compared to searches in the data structures.</p><p>In particular, the frequency of updates is in the time-scale of tens of seconds or longer whereas look-ups happen for every processed packet. At a packet processing rate of lo6 packets per second, the ratio of look-ups to updates is 107. Hence, the algorithms can be optimized for lookups even if it means degrading update performance to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Memory accesses are expensive and are the dominant</head><p>factor in determining the worst-case execution time.</p><p>8. Memory is organized in words of size w and the cost of accessing a word is the same as the cost of accessing any subset of bits in a word. 9. Memory cost can be relatively low if technologies such as Synchronous Dynamic RAMS (SDRAMs) are used. These devices can provide very large capacity combined with a high access speed, provided that accesses are sequential. A packet classifier implementation that requires multiple sequential accesses in a high-speed SDRAM memory might be more affordable than an algorithm of lower time-complexity that uses highercost, lower capacity memories like SRAMs. 10. For operation at very high speed the algorithm must be amenable to hardware implementation. While we do not preclude software implementations of our proposed algorithms, we are primarily interested in algorithms that are implementable in hardware as well and are not restricted to only a software implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Previous Work</head><p>The idea for packet filtering, or classification in general, was initiated in <ref type="bibr">[16]</ref> and was later expanded in [19, 271. The architectures and algorithms presented in these papers were targeted mainly for an end-point and their main goal was to isolate packets that are destined to specific protocols or to specific connections. The algorithms used, although they involved a linear parsing of all the filters, were fast enough to operate at end-point link capacities. Obviously these implementations do not scale to very high speeds.</p><p>An interesting variation was presented in <ref type="bibr">[l]</ref> where the first hardware implementation of packet filters was reported. The implementation, although fast enough to support an OC-12 link, is restricted to only a small number of rules (&lt; 12) and is not general enough for a commercial highspeed router. The implementation uses a pipelined architecture, resulting in O(1) performance using O(N) processing elements for O(N) rules. Clearly, such an algorithm cannot scale to a large number of filter rules since it requires a linear number of processing elements. Moreover, this scheme was designed for rules that required exact matching and not for rules defined as ranges.</p><p>The general packet classification problem that we consider can be viewed as a point location problem in multidimensional space. This is a classic problem in Computational Geometry and numerous results have been reported in the literature <ref type="bibr">[5,</ref><ref type="bibr">6,</ref><ref type="bibr">111</ref>. The point-location problem is defined as follows: Given a point in a d-dimensional space, and a set of n d-dimensional objects, find the object that the point belongs to. Most algorithms reported in the literature deal with the case of non-overlapping objects or specific arrangements of hyperplanes or hypersurfaces of bounded degree 1221. When considering the general case of d &gt; 3 dimensions, as is the problem of packet classification, the best algorithms considering time or space have either an O(logd-' n) complexity with O(n) space, or an O(log n) time-complexity with O(nd) space. <ref type="bibr">[22]</ref>. Though algorithms with these complexity bounds are useful in many applications, they are mostly not directly useful for packet filtering.</p><p>For packet filtering, the algorithms must complete within a specified small amount, of time for n, the number of filters, in the range of a few thousands to tens of thousands. So even the algorithms with poly-logarithmic time bounds are not practical for use in a high-speed router.</p><p>To illustrate this, let us assume that we would like the router to be able to process 1K rules of 5 dimensions within 1~s (to sustain a 1 million packets per second throughput). An algorithm with log4 n execution time and O(n) space requires 10K memory accesses per packet. This is impractical with any current technology. If we use an O(logn) time O(n4) space algorithm, then the space requirement becomes prohibitively large since it is in the range of 1000 Gigabytes. To the best of our knowledge, there is no algorithm reported in the literature for the general d-dimensional problem, of point-location with non-overlapping object, with lower asymptotic space-time bounds. In addition, our requirements are not for point location given non-overlapping objects, but for point location with overlaps being permitted and prioritization used to pick one object out of many overlapping solutions.</p><p>For the special case of two dimensions and non-overlapping rectangles a number of solutions have been reported with logarithmic complexity and near-linear space complexity <ref type="bibr">[12]</ref>. However, these algorithms do not consider the special problem related to longest-prefix matches where arbitrary overlaps may be present and overlaps are resolved through the longest prefix priority.</p><p>An even better solution has been reported in <ref type="bibr">[2]</ref> where the time complexity is O(log log N). However, the algorithm is based on the stratified trees proposed by van Emde Boas [23, 31 for searches in a finite space of discrete values. The data structures used require a perfect hashing operation in every level of the tree. The preprocessing complexity, without using a randomized algorithm, of calculating the perfect hash is O(min(hV,  n3)) where h is the number of hash functions that must be calculated and V is the size of the space. Note, that for 2-dimensional longestprefix lookups this can result, even for a small number of rules, in executions requiring 232 cycles which is impractical, even if preprocessing is only required once every several seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">General Packet Classification Algorithms</head><p>A simple approach to the problem of multi-dimensional search, as used for packet filtering, is to use decomposable search. Here the idea is to state the original query as the intersection of a few numbers of simpler queries. The challenge then, for instance to obtain a poly-logarithmic solution, is to decompose the problem such that the intersection step does not take time more than the required bound. To achieve these poly-logarithmic execution times, various sophisticated decompositions and query search data structures have been proposed. However, as was pointed out before, even a log4 n solution for 5 dimensional packet filtering is not practical for our application where n can be in the thousands. Therefore, we need to employ parallelism of some sort. Moreover, we require simple elemental operations to make the algorithm amenable to hardware implementation.</p><p>Our cost metric of memory accesses being of unit cost till a word length is exceeded implies that bit level parallelism in the algorithm would give speed-ups. Instead of looking for data structures which give the best asymptotic bounds, we are interested in decomposing the queries such that sub-query intersection can be done fast (as per our memory-access cost metric) for n in the thousands and memory word-lengths that are feasible with current technology.</p><p>The first point to note is that our packet-filtering problem involves orthogonal rectangular ranges. This means that a natural decomposition of a k-dimensional query in a kdimensional orthogonal rectangular range is to decompose it into a set of l-dimensional queries on l-dimensional intervals. The problem is that when we do this for our problem, each simple query can generate a solution of O(n) size. This is because we can have arbitrary overlaps and so O(n) ranges may overlap a query point in 1 dimension. Consequently, the intersection step can take time O(n). Nevertheless, this solution is far more practical for our packet filtering problem than other poly-log solutions because we can take advantage of bit-level parallelism.</p><p>To summarize, given our constraints (particularly the need for hardware implementation)</p><p>and cost metrics (in particular memory access cost per bit incrementing only at word boundaries), the number of filter rules being of the order of a few thousands, and the number of dimensions being 5, the simple approach of decomposing the search in each dimension (which can be done in parallel) followed by a linear time combining step is more useful than a sophisticated O(log4 n) (n being the number of filter rules) time algorithm.</p><p>Below, we describe an algorithm which needs k*n'+O(n) bits of memory for each dimension, rlog(2n)l + I comparisons per dimension (which can be done in parallel for each dimension), and [n/w1 memory accesses for a pairwise combining operation. We then present a second algorithm which can reduce memory requirements to O(nlog n) bits while increasing the execution time by only a constant (as long as logn &lt;= w which would certainly be the case). This second algorithm has two other benefits. The constant increase in execution time can be traded off for increased memory, allowing the algorithm to be optimized for the available time and memory budget. Also, it can exploit on-chip memory in a traffic independent manner to speed up worst-case bounds (unlike typical caching schemes which only speed up average-case bounds and are traffic dependent). Specifically, if there is (Ic * n2)/1 bits of on-chip memory then the number of off-chip memory accesses is [log(n)/wl/(21)1 where w is the word length. The number of on-chip memory accesses is [n/won+,+,1</p><p>where U&amp;-&amp;p is the on-chip memory word length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1</head><p>Packet Classification based on Bit-Parallelism</p><p>Although, the algorithm we will describe has linear time complexity, its use of bit-level parallelism significantly accelerates the filtering operation for any practical implementation. The filtering rules are changed very infrequently in comparison to the frequency of search operations.</p><p>Hence, extra preprocessing can be used to speed up searches.</p><p>We assume that a set of n packet filtering rules in Ic dimensions are defined. Let rm = { ei ,m, ee,m, , ek,m} denote the set of ranges that define rule rm in the k: dimensions.</p><p>The preprocessing part of the algorithm is as follows:</p><p>For each dimension j, 1 &lt;= j &lt;= Ic, project all intervals ej,i, 1 &lt;= i &lt;= n on the j-axis, by extracting 'th the J element of every filter rule for all n filter rules. There are a maximum of 2n + 1 non-overlapping intervals that are created on each axis. Let us denote by Pj, 1 &lt;= j &lt;= k the k sets of such intervals.</p><p>For each interval i E Pj, Vj E (1 k}, create sets of rules Ri,j, 1 5 i 5 2n + I, 1 5 j &lt; k, such that a rule TV belongs in set &amp;,j if and onlyif, the corresponding Without loss of generality, we assume that rules are sorted based on their priorities. Assume that a packet with fields Ei, Ez, El, arrives to the system. The classification of the packet involves the following steps.</p><p>1. For each dimension j, find the interval, say ij on set I'3 that E3 belongs to. This is done using binary search (requiring [log(2n + l)] + 1 comparisons) or using any other efficient search algorithm.</p><p>2. Create intersection of all sets Rzj,J, ij E {1,2,. . .2n+ l}" This can be done by taking the conjunction of the corresponding bit vectors in the bit arrays associated with each dimension and then determining the highest priority entry in the resultant bit vector (see explanation below).</p><p>3. The rule corresponding to the highest priority entry must be applied to the arriving packet.</p><p>Note, that the on-line processing step involves an intersection among the potential sets of applicable filter rules which are obtained considering only one dimension at a time. These potential solution sets may have cardinality O(n) since we have assumed that rules may have arbitrary overlaps. The intersection step involves examining each of these rules at least once and hence the algorithm has time complexity O(n).</p><p>To accelerate the execution time, we can take advantage of bit-level parallelism.</p><p>Each set R;,, is represented by a bitmap n-bits long which acts as t,he indicator function for the set. Let Bj [i, m] be a (2n+l) x n array of bits associated with each dimension j. We can store each set Ri,j as a bit vector in column i of the bit array Bj [i, m], 1 &lt;= m &lt;= n, where bit Bj <ref type="bibr">[i, m]</ref> is set if and only if, the rule rm. belongs in set R;,,. The intersection operation is then reduced to a logical-AND among the bitmaps that are retrieved after the search in each direction. To be able to select the highest priority rule, we rely on the rules being ordered based on priorities. The bitmaps are organized in memory into words of width w where each word is the unit of memory access. We can implement the intersection by reading sequentially the words of all dimensions and implementing the logical-AND. The first rule that we find through this process is the highest priority rule. Clearly this takes [k * n/w] memory accesses. By making w large, the worst-case execution time can be reduced further. Let us consider the example in 2-dimensions, shown in Figure <ref type="figure" target="#fig_1">2</ref>, to illustrate the functioning of the algorithm. Rules are represented by 2-dimensional rectangles that can be arbitrarily overlapped. The preprocessing step of the algorithm projects the edges of the rectangles to the corresponding axis. In the example shown, the four rectangles create seven intervals in each axis. In the worst case, the projection results in a maximum of 2n + 1 intervals on each dimension. We next associate a bitmap with each dimension, as is shown in Figure <ref type="figure" target="#fig_1">2</ref>. A bit in the bitmap is set, if and only if, the corresponding rectangle overlaps with the interval that the bitmap corresponds to. Note, that because of the method by which the intervals were created, it is not possible for a rectangle to overlap, say, only with half an interval. Assume that the packet represented by point Pl arrives to the system. During the first on-line step, we locate the intervals in both axis that contain this point. In the example, these are intervals X2 and Y4 for the X and Y axis respectively. In the second step, we use the bitmaps to locate the highest priority rectangle that covers this point. Note that rectangles are numbered based on their priorities. After the logical-AND of the bitmaps, the first bit that is set in the resulting bitmap is that corresponding to rectangle 3 which is the highest priority rectangle, amongst all those overlapping point Pl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Hardware Implementation</head><p>The key point behind the hardware implementation is that the algorithm performs only very simple operations. Since the only hardware elements that are required for the binary search operation ( to locate enclosing intervals) are an inte- ger comparator and counter, and the only operation for the intersection is a parallel AND operation, the complexity of such a processing element is very low. The straightforward approach is to use a different processing element for each dimension (see Figure <ref type="figure">3</ref>). Each processing element consists of a single comparator, a state machine and 2 local registers. The processing elements implement the binary search on all intervals in parallel. The result of this search is a pointer to a bitmap for each direction. The second step of the algorithm requires a parallel access to all bitmaps and a logical AND operation amongst them. The first time that this operation results in a non-zero value, the corresponding filter has been located. The algorithm requires one more access to the memory to retrieve the actions that may be associated with this filter.</p><p>The algorithm has been implemented in 5 dimensions in a high-speed router prototype using a single FPGA device and five 128 Kbyte Synchronous SRAMs chips supporting up to 512 rules and processing 1 million packets per second in the worst case. This is achievable despite the device being run at a very low speed of 33 MHz. Since we used the same memory chips as those used in the LZ-caches of personal computers, the cost of the memories is trivial. The device can be used as a co-processor, next to a general purpose processor that handles all the other parts of IP forwarding or firewall functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Packet Classification based on Incremental Reads</head><p>The next algorithm we propose uses incremental reads to reduce the space requirements. The algorithm allows designers to optimize time-complexity and space. Since the dominant factor determining execution times is off-chip memory accesses, the availability of on-chip memory and the use of the proposed algorithm can significantly increase the number of filter rules that can be applied within the given time constraint.</p><p>The main idea used in developing the proposed algorithm is the following. Consider a specific dimension j. There are at most 2n + 1 non-overlapping intervals that are projected onto this dimension. Corresponding to each of these intervals there is a bitmap of n bits with the positions of the Is in this bitmap indicating the filter rules that overlap this interval. The boundary between intervals is a point where some the projections of some filter rules terminate and those of some filter rules start. If we have exactly 2n + 1 intervals, then the set of filter rules that overlap any two adjacent intervals 1 and m differ by only one rule (i.e., at the boundary between interval I and m either a filter rule's projection starts, or a filter rule's projection ends). This implies that the corresponding bitmaps associated with these two intervals differ in only bit. Hence the second bit map can be reconstructed from the first by just storing, in place of the second bit map, a pointer of size logn which indicates the position of the single bit which is different between these two bit maps. Carrying this argument further, a single bit map and 2n pointers of size log n can be used to reconstruct any bit map. This cuts the space requirement to O(nlogn) from <ref type="bibr">O(n2)</ref> but increases the number of memory accesses by T(2nlogn)lw)l.</p><p>The above argument is not changed when more than one filter starts or terminates at a particular boundary point between two adjacent intervals. This is because if a boundary point has more than one, say i, filters terminating or starting at that point then the number of intervals in that dimension is reduced by i -1. Hence, we still need only 2n pointers (each filter terminating or starting needs exactly one pointer even if they all terminate or start at the same boundary point).</p><p>We can now generalize this basic idea by storing (2n + 1)/1 complete bitmaps instead of just one bitmap. These bitmaps are stored such that at most only [(2n + 1)/211 pointers (pointer are stored such that retrieval starts from the nearest lower or higher position where a complete bitmap is stored) need to be retrieved to construct the bitmap for any interval. The preprocessing phase is as follows:</p><p>1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>For each dimension j E (1.. k) do Determine the, at most 2n + 1, non-overlapping intervals for dimension j by projecting all intervals ej,i, P &lt;= i &lt;= n on the j-axis. This step is the same as the projection step for the algorithm proposed in the previous sections.</p><p>Generate set of overlapping rules for first interval and store its bit map in storage associated with this interval.</p><p>For all intervals i E (2 . .2n + 1) do Generate set of overlapping rules for interval i. If this bit map has 1 or more bits different from most recent bit map which was stored, then store this bit map in storage associated with interval i. Otherwise, increment i. At most [2n + l/11 bit maps are stored since there are n bits, each bit can change at most twice, and the successive bit maps have at least 1 bits which are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fill in pointers indicating changed bits from previous interval.</head><p>There are at most k -I intervals between intervals for which bitmaps have been stored. Starting from each bit map, store pointers which indicate the bits which have changed from the preceding interval. "Preceding interval" is the interval with lower index for bit maps in lower half of the l-1 intervals between stored bit maps and it is the interval with the higher index for bit maps at the mid-point or upper half of the I -1 intervals.</p><p>The per-packet processing performed to find the appli-:able filter rule, if any, is as follows:</p><p>1. For each dimension j E { 1. k} do 2. Find the interval, say i, on set Pj that EJ belongs to. This is done by binary search (requiring rlog(2n + l)] + 1 comparisons) or using any other efficient search algorithm.</p><p>3. If this interval has its complete bit map, bi, stored then retrieve this bit map. This require [n/w] memory accesses. Otherwise, first retrieve the bit map for the interval closest to i with a stored bit map. This bit map has at most [(l -1)/2] bits different from the retrieved bit map. Fetch the, at most [(l-1)/2] pointers corresponding to all intervals in between i and the interval whose bit map was received. This case requires ~n/w] + [((1-1)/2)*(log n)/w] memory accesses. Construct the bit map for i using the pointers in sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Create a new bit map as the logical-AND</head><p>of the retrieved bit maps for all Ic dimensions. Note that the AND operation can be done progressively as the bit maps are being constructed and does not necessarily require the entire bit map for each dimension to be completely retrieved.</p><p>5. The index of the leading 1 in this bit map gives the applicable filter rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Choice of 1</head><p>One possible criteria for choice of I is to lower the memory requirement from O(n'). Setting 1 = 2n + 1 is an extreme case which reduces memory requirements to O(n log n) but requires retrieving n -1 pointers. Let us present the tradeoff with an example. If we assume that bits of the bitmap are retrieved through pointers, as is the case when 1 = 2n + 1, then the total time for retrieving the bitmaps in each direction becomes r2n log nf w] which can be much higher than the [n/w] time required by the first algorithm. However, at the expense of higher execution time, the space requirement is reduced substantially. If on-chip memory is available however, complete bitmaps may be retrieved together with the pointers. The basic assumption behind the utilization of on-chip RAMS is that they be designed to be extremely wide. It is thus possible to increase the data bus width by at least a factor of 4 over an off-chip RAM. Current technologies, such as the ones offered by major ASIC vendors <ref type="bibr" target="#b22">[25,</ref><ref type="bibr">211</ref>, allow large portions of Synchronous Dynamic RAMS (SDRAMs) to be allocated in the same chip as logic. Note, that SDRAMs are ideal for retrieving bitmaps since they offer the best performance when accesses are sequential.</p><p>So, let us assume that on-chip memory can be QI times as wide as off-chip memory. Let us assume that a full bitmap is kept in the on-chip memory for every 1 words. The total time required for retrieving this bitmap can be calculated as t = n/cyw. This time must be equal to the time required to retrieve at least l/2 pointers from the off-chip memory, or t = 1 log n/2w off-chip memory accesses. From the above two relations, we can easily calculate the optimal value of 1 for a given technology as For example, if we assume (Y = 4 and n = 8K we get 1 = 315 and we will need approximately 64 cycles to complete the operation.</p><p>This will translate, using a 66MHz clock, to a processing rate of 1 million packets per second. Note, that, the total space requirement for the 8K filters is 32 Kbytes of on-chip memory and 32 Kbytes of off-chip memory for each dimension. This is definitely within the capabilities of current technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Classification in Two Dimensions</head><p>The 2-dimensional classification problem is of increasing importance in the evolving Internet architecture of the future. Drastically changing user expectations will necessitate the offering of different types of services and service guarantees by the network. Although RSVP, or similar reservation protocols, can offer end-to-end Quality-of-Service guarantees for specific flows, it is not clear whether such a reservation based model can be scaled for operation over highspeed backbones where a very large number of flows can be concurrently active. An alternative approach that has been proposed is route aggregated flows along specific traffic engineered paths. This directed routing is based not only on the destination address of packets, but on the source address as well <ref type="bibr">[18]</ref>. RSVP or similar reservation protocols can be used for setting the aggregation and routing rules [18, 41. However, the key mechanism needed to support such a scheme in a high-speed core router is a 2-dimensional classification or lookup scheme that determines the next hop, and the associated resource allocations, for each packet as a function of both the source and destination addresses. In addition, multicast forwarding requires lookups based on both the source address and multicast groups [13, 261.</p><p>The P-dimensional look-up problem is defined as follows: A query point p is a pair (s,d). For the forwarding problem, these values could correspond to source and destination addresses. For the multicast look-up application, the query point can correspond to the source address of a packet and to a group id that identifies the multicast group that the packet belongs to. A 2-dimensional look-up table consists of pairs (si,&amp;) where each sI is a prefix of possible source addresses and each di is a contiguous range or point, of possible group identifiers or destination addresses. Each pair defines a rectangle in 2-dimensions.</p><p>Note that rectangles can have arbitrary overlaps. Given a query point p, the search or look-up problem is to find an enclosing rectangle (if any), say rj = (sj, dj), such that p = (s, d) is contained in r3, and such that sj is the most specific (longest) matching prefix of s. The dj can be ranges including prefix ranges. The matching dj, when multiple matches occur for a specific sj due to overlaps in the d direction, is taken to be the one of highest priority.</p><p>Note that the d dimension allows any contiguous range and is not restricted to prefix ranges only. Therefore, if the d direction corresponds to destination addresses, then ranges in the destination addresses do not have to be in powers of 2 (which would be the case with prefix ranges). This might be particularly useful if destination addresses are concatenated with layer-4 destination ports or some other similar header field (to form a"2 l/2 dimensional" lookup).</p><p>We are interested in solutions for use in IP routers. This means that the look-up tables may have as many as 216 entries and perhaps more. Also, we are interested in only worst-case performance of the algorithms since we want to avoid queueing for header processing in order to provide QoS guarantees.</p><p>Let n denote the number of entries in the multicast forwarding table. A simple solution that takes only O(logn) time and O(n') space is to have an n x n array with each entry representing the highest priority rectangle that encloses the point corresponding to the coordinates represented by the entry. The look-up is done with two binary searches. However, this is clearly impractical in space when the number of filtering rules is n = 216. The O(n2) space is because the same rectangle can be represented in O(n) locations. We would like to maintain the same time complexity while storing all the rectangles using only O(n) space. We cannot directly use known solutions to the problem of rectangular point location since we can have arbitrary overlapping rectangles. In the proposed algorithm, we make use of the fact that in the s dimension our rectangles have lengths which are in powers of 2. This is because these s ranges are always prefix ranges.</p><p>The restriction of ranges in one dimension to be prefix ranges provides constraints that can be exploited. To illustrate this consider Figure <ref type="figure" target="#fig_3">4</ref>. All prefix range intervals can only have sizes which are powers of two and totally arbitrary overlaps are not possible (two prefixes of the same length do not overlap). also, a range can only start from an even point and terminate at an odd point. Based on these observations, we can split the set of ranges into several distinct cells distinguished by the length of the prefix (or, equivalently the size of the range).</p><p>Let the s field be of length 1s bits and the d field be of length Id bits. Let RI, Rs, , Rl, denote subsets of the set R of n rectangles such that subset Ri consists of all rectangles formed from prefixes that are i bits long. Let nz denote the number of prefixes of length i that are present in the lookup table. Assume that these prefixes in the s dimension are numbered in ascending order of values obtained by extending all prefixes to their maximum length 1s by adding sufficient zero bits to each of the specified prefixes. Denote the ni prefixes of length i by P,', P,", . . . , PF'. With each prefix P: there is an associated set of rectangles, Ri = {(P,j,d,I),(P~,dT),......,}, that have Pi as one of their sides. Here, the {df,dF,..".. ,}, Are ranges in the d dimension and can overlap. The set of rectangles R,i is the union of sets Ri, Rp, , , Rtyi where each of the R;' is the set of rectangles associated with the jth prefix of length i. Note that the sets R: are disjoint and that all rectangles in Ri that match p have higher priority than rectangles in R{ that match p if i &gt; t. This is because rectangles in Ri are formed with longer prefixes than those in Ri since i &gt; t.</p><p>In the example of Figure <ref type="figure" target="#fig_3">4</ref>, the set of rectangles with prefix equal to 1 is RI = {{el}, {e6}}. Note that each prefix of length m covers l/Zm of the total s range. There is a 1 total of 7~2 = 1 prefixes of length 2. The set Rz of rectangles formed with prefixes of length 2 consists of the rectangles (e2, e3, e4). From Figure <ref type="figure" target="#fig_3">4</ref>, we see that these rectangles can overlap in the d dimension. There is one prefix of length 3 and one rectangle formed using it. So set R3 has one set of rectangles and that set contains one rectangle e5.</p><p>Let us assume that the size of the list of ranges d{ is denoted by l~i. From each list of ranges consisting of di s, we derive a list of non-overlapping intervals D{s. The size of this new set l?{ is Kf &lt;= 2ki + 1, i.e. by representing the original ki overlapping intervals as non-overlapping intervals we increase the space by only a constant factor of 2. The purpose of replacing overlapping intervals by non-overlapping intervals is to locate the d from the query point into one of these non-overlapping rectangles during the search procedure and then to find the associated enclosing rectangle. Hence, when many intervals overlap a given interval, the rectangle associated with the interval (during the overlap eliminating phase) is the one with the highest priority that overlaps the interval. In Figure <ref type="figure" target="#fig_3">4</ref>, the set of intervals that are created after this overlap elimination for d$ is 0; = {ae, ai, &amp;j}. Let us also assume that from the set of rectangles Ri, rectangle e3 has the highest priority. Then this will be the rectangle associated with interval ~2, although there are other rectangles overlapping this range.</p><p>The preprocessing phase of the algorithm is as follows:</p><p>Store the set of prefixes Pj using any efficient trie representation.</p><p>i := 1</p><p>For each prefix, P!, store the list of non-overlapping intervals D!s in sorted sequence using either an array or a binary tree.</p><p>Repeat for all prefix lengths i Essentially, in the preprocessing step we perform two operations: First, we separate the rectangles based on the prefix length in the s dimension.</p><p>Then, for each prefix, we project all its associated rectangles to the corresponding axis to obtain first the overlapping intervals d: in the d dimension. From these we create the non-overlapping sets 0:. The non-overlapping intervals are created by a scan of the overlapping intervals from lower to higher co-ordinates in the d dimension. The procedure is:</p><p>1. doforalli 2. Sort the set of overlapping intervals d{ into ascending sequence of their starting points.</p><p>3. If an interval starts or ends, generate Us for previous interval. Store the interval and pointer to actions for highest priority rectangle that overlaps this interval" If newly created interval, and its previously stored adjacent interval point to the same rectangle, merge these two intervals. Since a new interval 0;' is created, at most, when an overlapping interval begins or terminates, the size of this new set 0: is Kf &lt;= 2$ + 1 where ki is the size of the set of overlapping intervals d;</p><p>At the end of the pre-processing step each rectangle is stored in exactly one location on the s-axis, i.e, it is stored in a structure associated with the the prefix used to form this rectangle. Its d range is in sorted sequence within the structure, with the other entries in this structure being the d intervals of other rectangles formed using the same prefix. The set of rectangles associated with a prefix is stored as a list of non-overlapping intervals and requires space only proportional to the size of the set. Only O(n) space is needed to store all the rectangles since each rectangle appears only in one set and therefore the size of the union of all sets is O(n).</p><p>The look-up algorithm operates in the following phases.</p><p>i := 1; solution := nil Let Pi = {P,',P,",... , PFi} be the set of all prefixes of length i. Find the prefix P! of length i which matches s determined by the query point. If match Pj is found then search in the structure associated with P/ to find the non-overlapping interval 0," that contains d given by the query point. Solution = rectangle associated with <ref type="bibr">(Pi, Dp)</ref>. This is the best solution among all prefixes searched so far.</p><p>Repeat till all prefix lengths have been searched.</p><p>The total execution time of the algorithm as presented is O(Zs log n). This is because the number of iterations of the algorithm in the worst case is equal to the number of possible prefix lengths Is. If use a trie structure ( note that the use of other data structures is not precluded) to determine prefixes of each length then total cost in time for determining prefixes is O(ls). The list of 0:s can be of size O(n). Hence, O(logn) time is needed to search each list for a matching entry (we will later show this factor can be eliminated for all but one list by cascading the search through these multiple lists). The search could have been started from the longest possible prefix so as to improve average execution times but since we are only interested in worst-case performance this optimization is not used.</p><p>Consider the example of Figure reflpexample. Assume that a packet with header Pl = (OllO,OlOl) arrives. We first find a matching prefix (0) of length 1 and search for enclosing rectangles formed with this prefix. We search the d dimension and we find that rectangle el is a first candidate solution. Note that rectangles el, e6 are the only rectangles in the set of rectangles with prefixes of length equal to 1. Next, we search using prefixes of length 2. The matching prefix is (01). We now get rectangle e3 as a better candidate since the d field of the arriving packet overlaps with the range a2, and this rectangle is formed with a longer prefix and e3 has higher priority than other rectangles formed with prefixes of equal or lower length. e3 becomes the best solution found until now. Finally, we locate a matching prefix (OlI) of length 3. We search among rectangles formed with this prefix and get e5 as the best solution.</p><p>The time-complexity of O(Zs log n) obtained with this algorithm can be too large for use in a high-speed router. Assume that the the number of possible prefix lengths Is = 32 and that the number of table entries n = 218 = 256K. This requires 576 memory accesses in the worst case (the measure of execution time for our algorithms). Hence, the time is prohibitively high. In the next section, we show how the log n factor can be eliminated, and so reducing the number of memory accesses in the above example to about 50 which makes it practical for high-speed implementation. With a trie implementation, the space requirement of the above look-up scheme is O(n). Furthermore, the order of search of the sets from the lists RI, Rz, . . . , etc. is in increasing order of prefix lengths, i.e., a set from RI is searched before searching a list from Rz and so on. The search proceeds in levels with sets belonging to RI being on the first level, those in Rz being on the second level and so on. Let the number of non-overlapping intervals in all of RI be iVi , in all of R2 be Nz etc. The bottom most level Rl, has Nl, nonoverlapping intervals. Note that the number of overlapping intervals at each level can be O(n). Suppose that we had a serendipitous arrangement of intervals where only the size of RI is O(n) and for all Ri,i &gt; 1 the sizes are O(1). Clearly, in this case the worst case execution time is O(ls + logn). Of course, we cannot count on such a good arrangement of intervals. However, we can make this happen by introducing some "virtual" intervals using a technique used in computational geometry to speed up searches in multiple ordered lists <ref type="bibr">[7,</ref><ref type="bibr">8]</ref> When we perform a search on the list at level say i, the information we get is that the given d lies in an interval Q. When we next search the lists at level i + 1, instead of searching through all the intervals, we can use the information learned in the previous search and search amongst only those intervals that fall in the range given by q. While this may improve the average case performance, unfortunately, the worst case is not affected by this heuristic. This is because at level i + 1 there may be O(n/ls) intervals which fall within the range determined by 0: and this can happen at all levels. Hence, an O(log(n/Zs)) = O(log n) search may be needed at every level. Now suppose we introduce "virtual intervals" at levels i &lt; Zs in the following manner. There are Nl, intervals at level Is. Let us also denote by y:", yk . ., the boundary points that demarcate the Nl, intervals in the d dimension at level 1s. There are 2 * iVl, such points at most. We replicate every other point at level Zs to level Zs -1, i.e 2 * Nl, points are moved to level Zs -1. The points that were propagated together with the points defining the original intervals, define the intervals at level Zs -1. These are stored as nonoverlapping intervals at level 1s -1. Next we take all the intervals now at level Is -1 and their associated points and replicate every other point and move them as virtual points to level Es -2. We repeat this process till we reach the root level. Note that the propagation is only used to speed up the search. At each level, the rectangles associated with each interval are as described in the preprocessing described before. We can ignore the virtual intervals and points that result from propagation as far as the association of rectangles to intervals is concerned.</p><p>Note that this propagation process only increases the space requirements by a constant factor, i.e, the total space requirement is still O(n). It can be shown that the maximum amount of virtual intervals created (and hence extra space) is when Ni, = n, in which case the number of boundary points at level Is is 2n. The extra space due to the propagations is then 2(n + 5 + a + .) &lt;= 4n</p><p>However, by increasing the space by a constant factor, we gain the advantage that we can search the multiple lists in a more efficient manner. We search the level 1 list as before taking O(logn) time in the worst case. This results in locating the given d in some interval 0:. This interval can possibly be a virtual interval propagated up from the level 2. Now that we have localized d to the interval O{, the search in level 2 need only search in the range given by D3 1. Because every other point has been propagated up from level 2, only 2 intervals can fall in range 0: to which d has been localized. Hence, the search at level 2 can be done in O(1) time. In general, in moving from level i to level z + 1, the propagation of intervals ensures that there is enough information gained in the search at level i that the search at level i + 1 takes only O(1) time. Hence, the worst case execution time of the look-up algorithm is O(Zs+log n).</p><p>To illustrate the algorithm, let us consider the example of Figure <ref type="figure" target="#fig_5">5</ref>. For illustration purposes, we restrict ourselves to only three squares. We start from the rectangles with the longest prefix and we propagate only point al. As a result, on the axis corresponding to prefix of size two, there are now three points. We propagate points 51 and b2 only. There are four points now in the axis for prefixes of length 1. Assume that a packet with header Pl arrives. During the search operation, we start from the prefixes of length 1 and locate rectangle el as a candidate solution. When we move to prefixes of size 2, however, we use a pointer to the set of intervals that were possibly propagated. Note, that from the propagation we have lost the information of whether Pl has a d dimension smaller or larger than the point al. But it can only be one of the two solutions. There are two candidate intervals that are retrieved and only one corresponds to the incoming d value. Thus, we use the pointer associated with this interval to continue our search on the prefixes of length three. The final solution can be now retrieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding Remarks</head><p>Packet filtering or classification, using multiple packet-header fields and allowing range matches, has been considered a difficult operation to implement at high-speeds and with a large number of filter rules. However, it is a very useful primitive in connectionless networks for associating a policy-defined context with each incoming packet, so as to permit packet handling using various policy-based routing, security, and differentiated services actions. We presented three new schemes for packet classification. The first two are for implementing generalized packet filters allowing range matches in many dimensions. The schemes allow processing of thousands of filter rules at the rates of millions of packets per second using simple hardware technology and moderate clock speeds. These processing rates are based on traffic and filter-rule-pattern independent worst-case bounds, unlike cache-oriented schemes which are heavily traffic dependent. We are interested in only worst-case performance of the schemes since we want to avoid queueing for header processing in order to use the packet classifier for providing differentiated services and &amp;OS. The third scheme is for the special case of two-dimensional lookups where the ranges in one direction are restricted to being prefix ranges. For this case, we present an algorithm which in the worst case requires only O(number-of-prefix-lengths + log n). This scheme allows 2-dimensional classification to be performed with hundreds of thousands of entries at speeds sufficient for operation in network backbones. This two-dimensional lookup has many applications including the important one of supporting multicast. In the multicast case, since the group identifier range is either a specific group identifier or a wildcard range, our algorithm needs only 2 memory accesses beyond what is needed for the longest prefix match needed for unicast forwarding.</p><p>The ability to filter on thousands of rules in many dimensions, and hundreds of thousands of rules in two dimensions, widens the range of options feasible for evolving the current best-effort Internet to the Internet of the future, capable of providing customized differentiated services. Specifically, our algorithms demonstrate that there may be no need to restrict filtering to the edges or to very simple operations such as using only the Type-of-Service bits in the IP packet header. Contrarily, the whole network, including the backbone, can participate in the enforcement of policies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Queueing model of a system that uses a cache-based architecture for packet classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: General packet classification using bit-parallelism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>Figure 3: Architecture block diagram of a parallel implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Operation of the 2-dimensional algorithm when one dimension includes only intervals created by prefixes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>dFigure 5 :</head><label>5</label><figDesc>Figure 5: Operation of the 2-dimensional algorithm when one dimension includes only intervals created by prefixes and the propagation technique is used.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>20.5</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank the anonymous reviewers for the their detailed and insightful comments. The authors would also like to thank K. J. Singh and B. Suter who implemented the five-dimensional algorithm in the Bell Labs Router prototype.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PATHFINDER: A pattern-based packet classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Pagels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Symposium on Operating Systems Design adn Implementation</title>
		<meeting>the First Symposium on Operating Systems Design adn Implementation</meeting>
		<imprint>
			<date type="published" when="1994-11">November 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Twoand three-dimensional point location in rectangular subdivisions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">De</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Kreveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="256" to="277" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Design and implementation of an efficient priority queue</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Emde Boas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zijlstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Systems Theory</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">RSVP Extensions for CIDR Aggregated Data Flows</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boyle</surname></persName>
		</author>
		<ptr target="http://www.internic.net/internet-drafts/draft-ietf-rsvp-cidr-ext-Ol.txt" />
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Internet Draft</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">How to search in history</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chazelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="77" to="99" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Point location among hyperplanes and unidirectional ray shooting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chaaelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Geometry: Theory and Applications</title>
		<imprint>
			<biblScope unit="page" from="4153" to="4162" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fractional cascading. i. a data structuring technique</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="162" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fractional cascading. ii. applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="191" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Internet Trafic Characterization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Claffy</surname></persName>
		</author>
		<ptr target="http://www.internic.net/internet-drafts/draft-Clark-diff-svc-allot-OO.txt" />
		<editor>D. Clark</editor>
		<imprint>
			<date type="published" when="1994">1994. 1997</date>
		</imprint>
		<respStmt>
			<orgName>University of California, San Diego</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Service Allocation Profiles. Internet Draft</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New applications of random sampling in computational geometry</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete &amp; Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="195" to="222" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal point location in a monotone subdivision</title>
		<author>
			<persName><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stolfi</surname></persName>
		</author>
		<idno>I131 1141 I151 PI 1171 PI P91 WI Pll PI 1231 1241</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="317" to="340" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protocol independent multicast -sparse mode : Protocol specification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Farinacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Helmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RFC 2117</title>
		<imprint>
			<date type="published" when="1997-06">June 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Routing arbiter architecture</title>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Postel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rekhter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ConneXions</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Classless Inter-Domain Routing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Fuller</surname></persName>
		</author>
		<ptr target="ftp://ds.internic.net/rfc/rfc1519.txt" />
	</analytic>
	<monogr>
		<title level="m">RFC1519</title>
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The packet filter: An efficient mechanism for user level network code</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Mogul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Accetta</surname></persName>
		</author>
		<idno>87.2</idno>
	</analytic>
	<monogr>
		<title level="j">Digital WRL</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Application of sampling methodologies to network traffic characterization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Claffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Polyzos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGCOMM&apos;SS</title>
		<meeting>ACM SIGCOMM&apos;SS</meeting>
		<imprint>
			<date type="published" when="1993-09">September 1993</date>
			<biblScope unit="page" from="194" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Provider Architecture for Differentiated Services and Traffic Engineering (PASTE)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rekhter</surname></persName>
		</author>
		<ptr target="http://www.internic.net/internet-drafts/draft-li-paste-OO.txt" />
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note>Internet Draft</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The BSD packet filter: A new architecture for user-level packet capture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mccanne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Technical Conference Proceedings</title>
		<meeting><address><addrLine>Winter</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="259" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Achieving 100% throughput in an input-queued switch</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anantharam</surname></persName>
		</author>
		<author>
			<persName><surname>Walrand</surname></persName>
		</author>
		<ptr target="http://www.mitsubishichips.com/eram/eram.htm.eRAM" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of INFOCOM&apos;SG</title>
		<meeting>INFOCOM&apos;SG</meeting>
		<imprint>
			<date type="published" when="1996-03">March 1996. 1997</date>
			<biblScope unit="page" from="296" to="302" />
		</imprint>
	</monogr>
	<note>Mitsubishi</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Range searching and point location among fat objects</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Overmars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Van Der Stappen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="656" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Preserving order in a forest in less than logarithmic time</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Emde</surname></persName>
		</author>
		<author>
			<persName><surname>Boas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th IEEE Conference on Foundations of Computer Science</title>
		<meeting>16th IEEE Conference on Foundations of Computer Science</meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wide-area traffic patterns and characteristics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Toshiba America Electronic Components. CMOS dRA-MASIC Families</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Waitzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Partridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deering</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Distance Vector Multicast Routing Protocol</title>
		<ptr target="ftp://ds.internic.net/rfc/rfc1075.txt" />
		<imprint>
			<date type="published" when="1993-06">June 1993</date>
			<biblScope unit="volume">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient packet demultiplexing for multiple endpoints and large messages</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuhara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Bershad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eliot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Technical Conference Proceedings</title>
		<meeting><address><addrLine>Winter</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">RSVP: A new resource reservation protocol</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zappala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="8" to="18" />
			<date type="published" when="1993-09">September 1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
